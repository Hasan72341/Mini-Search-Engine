{"id": "15120", "revid": "7903804", "url": "https://en.wikipedia.org/wiki?curid=15120", "title": "Interferon", "text": "Signaling proteins released by host cells in response to the presence of pathogens\nInterferons (IFNs, ) are a group of signaling proteins made and released by host cells in response to the presence of several viruses. In a typical scenario, a virus-infected cell will release interferons causing nearby cells to heighten their anti-viral defenses.\nIFNs belong to the large class of proteins known as cytokines, molecules used for communication between cells to trigger the protective defenses of the immune system that help eradicate pathogens. Interferons are named for their ability to \"interfere\" with viral replication by protecting cells from virus infections. However, virus-encoded genetic elements have the ability to antagonize the IFN response, contributing to viral pathogenesis and viral diseases. IFNs also have various other functions: they activate immune cells, such as natural killer cells and macrophages, and they increase host defenses by up-regulating antigen presentation by virtue of increasing the expression of major histocompatibility complex (MHC) antigens. Certain symptoms of infections, such as fever, muscle pain and \"flu-like symptoms\", are also caused by the production of IFNs and other cytokines.\nMore than twenty distinct IFN genes and proteins have been identified in animals, including humans. They are typically divided among three classes: Type I IFN, Type II IFN, and Type III IFN. IFNs belonging to all three classes are important for fighting viral infections and for the regulation of the immune system.\nTypes of interferon.\nBased on the type of receptor through which they signal, human interferons have been classified into three major types.\nIn general, type I and II interferons are responsible for regulating and activating the immune response. Expression of type I and III IFNs can be induced in virtually all cell types upon recognition of viral components, especially nucleic acids, by cytoplasmic and endosomal receptors, whereas type II interferon is induced by cytokines such as IL-12, and its expression is restricted to immune cells such as T cells and NK cells.\nFunction.\nAll interferons share several common effects: they are antiviral agents and they modulate functions of the immune system. Administration of Type I IFN has been shown experimentally to inhibit tumor growth in animals, but the beneficial action in human tumors has not been widely documented.\nA virus-infected cell releases viral particles that can infect nearby cells. However, the infected cell can protect neighboring cells against a potential infection of the virus by releasing interferons. In response to interferon, cells produce large amounts of an enzyme known as protein kinase R (PKR). This enzyme phosphorylates a protein known as eIF-2 in response to new viral infections; the phosphorylated eIF-2 forms an inactive complex with another protein, called eIF2B, to reduce protein synthesis within the cell. Another cellular enzyme, RNAse L\u2014also induced by interferon action\u2014destroys RNA within the cells to further reduce protein synthesis of both viral and host genes. Inhibited protein synthesis impairs both virus replication and infected host cells. In addition, interferons induce production of hundreds of other proteins\u2014known collectively as interferon-stimulated genes (ISGs)\u2014that have roles in combating viruses and other actions produced by interferon.\nThey also limit viral spread by increasing p53 activity, which kills virus-infected cells by promoting apoptosis. The effect of IFN on p53 is also linked to its protective role against certain cancers.\nAnother function of interferons is to up-regulate major histocompatibility complex molecules, MHC I and MHC II, and increase immunoproteasome activity. All interferons significantly enhance the presentation of MHC I dependent antigens. Interferon gamma (IFN-gamma) also significantly stimulates the MHC II-dependent presentation of antigens. Higher MHC I expression increases presentation of viral and abnormal peptides from cancer cells to cytotoxic T cells, while the immunoproteasome processes these peptides for loading onto the MHC I molecule, thereby increasing the recognition and killing of infected or malignant cells. Higher MHC II expression increases presentation of these peptides to helper T cells; these cells release cytokines (such as more interferons and interleukins, among others) that signal to and co-ordinate the activity of other immune cells.\nInterferons can also suppress angiogenesis by down regulation of angiogenic stimuli deriving from tumor cells. They also suppress the proliferation of endothelial cells. Such suppression causes a decrease in tumor angiogenesis, a decrease in its vascularization and subsequent growth inhibition. Interferons, such as interferon gamma, directly activate other immune cells, such as macrophages and natural killer cells.\nInduction of interferons.\nProduction of interferons occurs mainly in response to microbes, such as viruses and bacteria, and their products. Binding of molecules uniquely found in microbes\u2014viral glycoproteins, viral RNA, bacterial endotoxin (lipopolysaccharide), bacterial flagella, CpG motifs\u2014by pattern recognition receptors, such as membrane bound toll like receptors or the cytoplasmic receptors RIG-I or MDA5, can trigger release of IFNs.\nToll Like Receptor 3 (TLR3) is important for inducing interferons in response to the presence of double-stranded RNA viruses; the ligand for this receptor is double-stranded RNA (dsRNA). After binding dsRNA, this receptor activates the transcription factors IRF3 and NF-\u03baB, which are important for initiating synthesis of many inflammatory proteins. RNA interference technology tools such as siRNA or vector-based reagents can either silence or stimulate interferon pathways. Release of IFN from cells (specifically IFN-\u03b3 in lymphoid cells) is also induced by mitogens. Other cytokines, such as interleukin 1, interleukin 2, interleukin-12, tumor necrosis factor and colony-stimulating factor, can also enhance interferon production.\nDownstream signaling.\nBy interacting with their specific receptors, IFNs activate \"signal transducer and activator of transcription\" (STAT) complexes; STATs are a family of transcription factors that regulate the expression of certain immune system genes. Some STATs are activated by both type I and type II IFNs. However each IFN type can also activate unique STATs.\nSTAT activation initiates the most well-defined cell signaling pathway for all IFNs, the classical Janus kinase-STAT (JAK-STAT) signaling pathway. In this pathway, JAKs associate with IFN receptors and, following receptor engagement with IFN, phosphorylate both STAT1 and STAT2. As a result, an IFN-stimulated gene factor 3 (ISGF3) complex forms\u2014this contains STAT1, STAT2 and a third transcription factor called IRF9\u2014and moves into the cell nucleus. Inside the nucleus, the ISGF3 complex binds to specific nucleotide sequences called \"IFN-stimulated response elements\" (ISREs) in the promoters of certain genes, known as IFN stimulated genes ISGs. Binding of ISGF3 and other transcriptional complexes activated by IFN signaling to these specific regulatory elements induces transcription of those genes. A collection of known ISGs is available on Interferome, a curated online database of ISGs (https://); Additionally, STAT homodimers or heterodimers form from different combinations of STAT-1, -3, -4, -5, or -6 during IFN signaling; these dimers initiate gene transcription by binding to IFN-activated site (GAS) elements in gene promoters. Type I IFNs can induce expression of genes with either ISRE or GAS elements, but gene induction by type II IFN can occur only in the presence of a GAS element.\nIn addition to the JAK-STAT pathway, IFNs can activate several other signaling cascades. For instance, both type I and type II IFNs activate a member of the CRK family of adaptor proteins called CRKL, a nuclear adaptor for STAT5 that also regulates signaling through the C3G/Rap1 pathway. Type I IFNs further activate \"p38 mitogen-activated protein kinase\" (MAP kinase) to induce gene transcription. Antiviral and antiproliferative effects specific to type I IFNs result from p38 MAP kinase signaling. The \"phosphatidylinositol 3-kinase\" (PI3K) signaling pathway is also regulated by both type I and type II IFNs. PI3K activates P70-S6 Kinase 1, an enzyme that increases protein synthesis and cell proliferation; phosphorylates ribosomal protein s6, which is involved in protein synthesis; and phosphorylates a translational repressor protein called \"eukaryotic translation-initiation factor 4E-binding protein 1\" (EIF4EBP1) in order to deactivate it.\nInterferons can disrupt signaling by other stimuli. For example, interferon alpha induces RIG-G, which disrupts the CSN5-containing COP9 signalosome (CSN), a highly conserved multiprotein complex implicated in protein deneddylation, deubiquitination, and phosphorylation. RIG-G has shown the capacity to inhibit NF-\u03baB and STAT3 signaling in lung cancer cells, which demonstrates the potential of type I IFNs.\nViral resistance to interferons.\nMany viruses have evolved mechanisms to resist interferon activity. They circumvent the IFN response by blocking downstream signaling events that occur after the cytokine binds to its receptor, by preventing further IFN production, and by inhibiting the functions of proteins that are induced by IFN. Viruses that inhibit IFN signaling include Japanese Encephalitis Virus (JEV), dengue type 2 virus (DEN-2), and viruses of the herpesvirus family, such as human cytomegalovirus (HCMV) and Kaposi's sarcoma-associated herpesvirus (KSHV or HHV8). Viral proteins proven to affect IFN signaling include EBV nuclear antigen 1 (EBNA1) and EBV nuclear antigen 2 (EBNA-2) from Epstein-Barr virus, the large T antigen of Polyomavirus, the E7 protein of Human papillomavirus (HPV), and the B18R protein of vaccinia virus. Reducing IFN-\u03b1 activity may prevent signaling via STAT1, STAT2, or IRF9 (as with JEV infection) or through the JAK-STAT pathway (as with DEN-2 infection). Several poxviruses encode soluble IFN receptor homologs\u2014like the B18R protein of the vaccinia virus\u2014that bind to and prevent IFN interacting with its cellular receptor, impeding communication between this cytokine and its target cells. Some viruses can encode proteins that bind to double-stranded RNA (dsRNA) to prevent the activity of RNA-dependent protein kinases; this is the mechanism reovirus adopts using its sigma 3 (\u03c33) protein, and vaccinia virus employs using the gene product of its E3L gene, p25. The ability of interferon to induce protein production from interferon stimulated genes (ISGs) can also be affected. Production of protein kinase R, for example, can be disrupted in cells infected with JEV. Some viruses escape the anti-viral activities of interferons by gene (and thus protein) mutation. The H5N1 influenza virus, also known as bird flu, has resistance to interferon and other anti-viral cytokines that is attributed to a single amino acid change in its Non-Structural Protein 1 (NS1), although the precise mechanism of how this confers immunity is unclear. The relative resistance of hepatitis C virus genotype I to interferon-based therapy has been attributed in part to homology between viral envelope protein E2 and host protein kinase R, a mediator of interferon-induced suppression of viral protein translation, although mechanisms of acquired and intrinsic resistance to interferon therapy in HCV are polyfactorial.\nCoronavirus response.\nCoronaviruses evade innate immunity during the first ten days of viral infection. In the early stages of infection, SARS-CoV-2 induces an even lower interferon type I (IFN-I) response than SARS-CoV, which itself is a weak IFN-I inducer in human cells. SARS-CoV-2 limits the IFN-III response as well. Reduced numbers of plasmacytoid dendritic cells with age is associated with increased COVID-19 severity, possibly because these cells are substantial interferon producers.\nTen percent of patients with life-threatening COVID-19 have autoantibodies against type I interferon.\nDelayed IFN-I response contributes to the pathogenic inflammation (cytokine storm) seen in later stages of COVID-19 disease. Application of IFN-I prior to (or in the very early stages of) viral infection can be protective, which should be validated in randomized clinical trials.\nWith pegylated IFN lambda, the relative risk for hospitalization with the Omicron strains is reduced by about 80 %.\nInterferon therapy.\nDiseases.\nInterferon beta-1a and interferon beta-1b are used to treat and control multiple sclerosis, an autoimmune disorder. This treatment may help in reducing attacks in relapsing-remitting multiple sclerosis and slowing disease progression and activity in secondary progressive multiple sclerosis.\nInterferon therapy is used (in combination with chemotherapy and radiation) as a treatment for some cancers. This treatment can be used in hematological malignancy, such as in leukemia and lymphomas including hairy cell leukemia, chronic myeloid leukemia, nodular lymphoma, and cutaneous T-cell lymphoma. Patients with recurrent melanomas receive recombinant IFN-\u03b12b.\nBoth hepatitis B and hepatitis C can be treated with IFN-\u03b1, often in combination with other antiviral drugs. Some of those treated with interferon have a sustained virological response and can eliminate hepatitis virus in the case of hepatitis C. The most common strain of hepatitis C virus (HCV) worldwide\u2014genotype I\u2014 can be treated with interferon-\u03b1, ribavirin and protease inhibitors such as telaprevir, boceprevir or the nucleotide analog polymerase inhibitor sofosbuvir. Biopsies of patients given the treatment show reductions in liver damage and cirrhosis. Control of chronic hepatitis C by IFN is associated with reduced hepatocellular carcinoma. A single nucleotide polymorphism (SNP) in the gene encoding the type III interferon IFN-\u03bb3 was found to be protective against chronic infection following proven HCV infection and predicted treatment response to interferon-based regimens. The frequency of the SNP differed significantly by race, partly explaining observed differences in response to interferon therapy between European-Americans and African-Americans.\nUnconfirmed results suggested that interferon eye drops may be an effective treatment for people who have herpes simplex virus epithelial keratitis, a type of eye infection. There is no clear evidence to suggest that removing the infected tissue (debridement) followed by interferon drops is an effective treatment approach for these types of eye infections. Unconfirmed results suggested that the combination of interferon and an antiviral agent may speed the healing process compared to antiviral therapy alone.\nWhen used in systemic therapy, IFNs are mostly administered by an intramuscular injection. The injection of IFNs in the muscle or under the skin is generally well tolerated. The most frequent adverse effects are flu-like symptoms: increased body temperature, feeling ill, fatigue, headache, muscle pain, convulsion, dizziness, hair thinning, and depression. Erythema, pain, and hardness at the site of injection are also frequently observed. IFN therapy causes immunosuppression, in particular through neutropenia and can result in some infections manifesting in unusual ways.\nDrug formulations.\nSeveral different types of interferons are approved for use in humans. One was first approved for medical use in 1986. For example, in January 2001, the Food and Drug Administration (FDA) approved the use of PEGylated interferon-alpha in the USA; in this formulation, PEGylated interferon-alpha-2b (\"Pegintron\"), polyethylene glycol is linked to the interferon molecule to make the interferon last longer in the body. Approval for PEGylated interferon-alpha-2a (\"Pegasys\") followed in October 2002. These PEGylated drugs are injected once weekly, rather than administering two or three times per week, as is necessary for conventional interferon-alpha. When used with the antiviral drug ribavirin, PEGylated interferon is effective in treatment of hepatitis C; at least 75% of people with hepatitis C genotypes 2 or 3 benefit from interferon treatment, although this is effective in less than 50% of people infected with genotype 1 (the more common form of hepatitis C virus in both the U.S. and Western Europe). Interferon-containing regimens may also include protease inhibitors such as boceprevir and telaprevir.\nThere are also interferon-inducing drugs, notably tilorone that is shown to be effective against Ebola virus.\nHistory.\nInterferons were first described in 1957 by Alick Isaacs and Jean Lindenmann at the National Institute for Medical Research in London; the discovery was a result of their studies of viral interference. Viral interference refers to the inhibition of virus growth caused by previous exposure of cells to an active or a heat-inactivated virus. Isaacs and Lindenmann were working with a system that involved the inhibition of the growth of live influenza virus in chicken embryo chorioallantoic membranes by heat-inactivated influenza virus. Their experiments revealed that this interference was mediated by a protein released by cells in the heat-inactivated influenza virus-treated membranes. They published their results in 1957 naming the antiviral factor they had discovered \"interferon\". The findings of Isaacs and Lindenmann have been widely confirmed and corroborated in the literature.\nFurthermore, others may have made observations on interferons before the 1957 publication of Isaacs and Lindenmann. For example, during research to produce a more efficient vaccine for smallpox, Yasu-ichi Nagano and Yasuhiko Kojima\u2014two Japanese virologists working at the Institute for Infectious Diseases at the University of Tokyo\u2014noticed inhibition of viral growth in an area of rabbit-skin or testis previously inoculated with UV-inactivated virus. They hypothesised that some \"viral inhibitory factor\" was present in the tissues infected with virus and attempted to isolate and characterize this factor from tissue homogenates. Independently, Monto Ho, in John Enders's lab, observed in 1957 that attenuated poliovirus conferred a species specific anti-viral effect in human amniotic cell cultures. They described these observations in a 1959 publication, naming the responsible factor \"viral inhibitory factor\" (VIF). It took another fifteen to twenty years, using somatic cell genetics, to show that the interferon action gene and interferon gene reside in different human chromosomes. The purification of human beta interferon did not occur until 1977. Y.H. Tan and his co-workers purified and produced biologically active, radio-labeled human beta interferon by superinducing the interferon gene in fibroblast cells, and they showed its active site contains tyrosine residues. Tan's laboratory isolated sufficient amounts of human beta interferon to perform the first amino acid, sugar composition and N-terminal analyses. They showed that human beta interferon was an unusually hydrophobic glycoprotein. This explained the large loss of interferon activity when preparations were transferred from test tube to test tube or from vessel to vessel during purification. The analyses showed the reality of interferon activity by chemical verification. The purification of human alpha interferon was not reported until 1978. A series of publications from the laboratories of Sidney Pestka and Alan Waldman between 1978 and 1981, describe the purification of the type I interferons IFN-\u03b1 and IFN-\u03b2. By the early 1980s, genes for these interferons had been cloned, adding further definitive proof that interferons were responsible for interfering with viral replication. Gene cloning also confirmed that IFN-\u03b1 was encoded by a family of many related genes. The type II IFN (IFN-\u03b3) gene was also isolated around this time.\nInterferon was first synthesized manually at Rockefeller University in the lab of Dr. Bruce Merrifield, using solid phase peptide synthesis, one amino acid at a time. He later won the Nobel Prize in chemistry. Interferon was scarce and expensive until 1980, when the interferon gene was inserted into bacteria using recombinant DNA technology, allowing mass cultivation and purification from bacterial cultures or derived from yeasts. Interferon can also be produced by recombinant mammalian cells.\nBefore the early 1970s, large scale production of human interferon had been pioneered by Kari Cantell. He produced large amounts of human alpha interferon from large quantities of human white blood cells collected by the Finnish Blood Bank. Large amounts of human beta interferon were made by superinducing the beta interferon gene in human fibroblast cells.\nCantell's and Tan's methods of making large amounts of natural interferon were critical for chemical characterisation, clinical trials and the preparation of small amounts of interferon messenger RNA to clone the human alpha and beta interferon genes. The superinduced human beta interferon messenger RNA was prepared by Tan's lab for Cetus. to clone the human beta interferon gene in bacteria and the recombinant interferon was developed as 'betaseron' and approved for the treatment of MS. Superinduction of the human beta interferon gene was also used by Israeli scientists to manufacture human beta interferon.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "15123", "revid": "7903804", "url": "https://en.wikipedia.org/wiki?curid=15123", "title": "Israeli settlement", "text": "Israeli communities built on land occupied in the 1967 Six-Day War\nIsraeli settlements, also called Israeli colonies, are the civilian communities built by Israel throughout the Israeli-occupied territories. They are populated by Israeli citizens, almost exclusively of Jewish identity or ethnicity, and have been constructed on lands that Israel has militarily occupied since the Six-Day War in 1967. The international community considers Israeli settlements to be illegal under international law, but Israel disputes this. In 2024, the International Court of Justice (ICJ) found in an advisory opinion that Israel's occupation was illegal and ruled that Israel had \"an obligation to cease immediately all new settlement activities and to evacuate all settlers\" from the occupied territories. The expansion of settlements often involves the confiscation of Palestinian land and resources, leading to displacement of Palestinian communities and creating a source of tension and conflict. Settlements are often protected by the Israeli military and are frequently flashpoints for violence against Palestinians. Furthermore, the presence of settlements and Jewish-only bypass roads creates a fragmented Palestinian territory, seriously hindering economic development and freedom of movement for Palestinians.\nAs of April 2025, Israeli settlements exist in the West Bank (including East Jerusalem), which is claimed by the Palestine Liberation Organization (PLO) as the sovereign territory of the State of Palestine, and in the Golan Heights, which is internationally recognized as a part of the sovereign territory of Syria. Through the Jerusalem Law and the Golan Heights Law, Israel effectively annexed both territories, though the international community has rejected any change to their status as occupied territory. Although Israel's West Bank settlements have been built on territory administered under military rule rather than civil law, Israeli civil law is \"pipelined\" into the settlements, such that Israeli citizens living there are treated similarly to those living in Israel. Many consider it to be a major obstacle to the Israeli\u2013Palestinian peace process. In \"Legal Consequences of the Construction of a Wall in the Occupied Palestinian Territory\" (2004), the ICJ found that Israel's settlements and the then-nascent Israeli West Bank barrier were both in violation of international law; part of the latter has been constructed within the West Bank, as opposed to being entirely on Israel's side of the Green Line.\nAs of January 2023, there are 144 Israeli settlements in the West Bank, including 12 in East Jerusalem; the Israeli government administers the West Bank as the Judea and Samaria Area, which does not include East Jerusalem. In addition to the settlements, the West Bank is also hosting at least 196 Israeli outposts, which are settlements that have not been authorized by the Israeli government. In total, over 450,000 Israeli settlers reside in the West Bank, excluding East Jerusalem, with an additional 220,000 Israeli settlers residing in East Jerusalem. Additionally, over 25,000 Israeli settlers live in Syria's Golan Heights. Between 1967 and 1982, there were 18 settlements established in the Israeli-occupied Sinai Peninsula of Egypt, though these were dismantled by Israel after the Egypt\u2013Israel peace treaty of 1979. Additionally, as part of the Israeli disengagement from the Gaza Strip in 2005, Israel dismantled all 21 settlements in the Gaza Strip and four settlements in the West Bank.\nPer the Fourth Geneva Convention, the transfer by an occupying power of its civilian population into the territory it is occupying constitutes a war crime, although Israel disputes that this statute applies to the West Bank. On 20 December 2019, the International Criminal Court announced the opening of an investigation of war crimes in the Palestinian territories. The presence and ongoing expansion of existing settlements by Israel and the construction of outposts is frequently criticized as an obstacle to peace by the PLO, and by a number of third parties, such as the Organization of Islamic Cooperation, the United Nations (UN), Russia, the United Kingdom, France, and the European Union. The UN has repeatedly upheld the view that Israel's construction of settlements in the occupied territories constitutes a violation of the Fourth Geneva Convention. For decades, the United States also designated Israeli settlements as illegal, but the first Trump administration reversed this long-standing policy in November 2019, declaring that \"the establishment of Israeli civilian settlements in the West Bank is not \"per se\" inconsistent with international law\"; this new policy, in turn, was reversed to the original by the Biden administration in February 2024, once again classifying Israeli settlement expansion as \"inconsistent with international law\" and matching the official positions of the other three members of the Middle East Quartet.\nName and characterization.\nCertain observers and Palestinians occasionally use the term \"Israeli colonies\" as a substitute for the term \"settlements\". Settlements range in character from farming communities and frontier villages to urban suburbs and neighborhoods. The four largest settlements, Modi'in Illit, Ma'ale Adumim, Beitar Illit and Ariel, have achieved city status. Ariel has 18,000 residents, while the rest have around 37,000 to 55,500 each.\nHousing costs and state subventions.\nSettlement has an economic dimension, much of it driven by the significantly lower costs of housing for Israeli citizens living in Israeli settlements compared to the cost of housing and living in Israel proper. Government spending per citizen in the settlements is double that spent per Israeli citizen in Tel Aviv and Jerusalem, while government spending for settlers in isolated Israeli settlements is three times the Israeli national average. Most of the spending goes to the security of the Israeli citizens living there.\nNumber of settlements and inhabitants.\nMain article: :List of Israeli settlements\nAs of January 2023, there are 144 Israeli settlements in the West Bank, including 12 in East Jerusalem. In addition, there are at least 196 Israeli illegal outposts (not sanctioned by the Israeli government) in the West Bank. In total, over 500,000 Israeli settlers live in the West Bank excluding East Jerusalem, with an additional 220,000 Jewish settlers residing in East Jerusalem.\nAdditionally, over 20,000 Israeli citizens live in settlements in the Golan Heights.\nHistory.\nOccupied territories.\nFollowing the 1967 Six-Day War, Israel occupied a number of territories. It took over the remainder of the Palestinian Mandate territories of the West Bank including East Jerusalem, from Jordan which had controlled the territories since the 1948 Arab-Israeli war, and the Gaza Strip from Egypt, which had held Gaza under occupation since 1949. From Egypt, it also captured the Sinai Peninsula and from Syria it captured most of the Golan Heights, which since 1981 has been administered under the Golan Heights Law.\nSettlement policy.\nAs early as September 1967, Israeli settlement policy was progressively encouraged by the Labor government of Levi Eshkol. The basis for Israeli settlement in the West Bank became the Allon Plan, named after its inventor Yigal Allon. It implied Israeli annexation of major parts of the Israeli-occupied territories, especially East Jerusalem, Gush Etzion and the Jordan Valley. The settlement policy of the government of Yitzhak Rabin was also derived from the Allon Plan.\nThe first settlement was Kfar Etzion, in the southern West Bank, although that location was outside the Allon Plan. Many settlements began as Nahal settlements. They were established as military outposts and later expanded and populated with civilian inhabitants. According to a secret document dating to 1970, obtained by Haaretz, the settlement of Kiryat Arba was established by confiscating land by military order and falsely representing the project as being strictly for military use while in reality, Kiryat Arba was planned for settler use. The method of confiscating land by military order for establishing civilian settlements was an open secret in Israel throughout the 1970s, but publication of the information was suppressed by the military censor.\nIn the 1970s, Israel's methods for seizing Palestinian land to establish settlements included requisitioning for ostensibly military purposes and spraying of land with poison.\nThe Likud government of Menahem Begin, from 1977, was more supportive to settlement in other parts of the West Bank, by organizations like Gush Emunim and the Jewish Agency/World Zionist Organization, and intensified the settlement activities. In a government statement, Likud declared that the entire historic Land of Israel is the inalienable heritage of the Jewish people and that no part of the West Bank should be handed over to foreign rule. Ariel Sharon declared in the same year (1977) that there was a plan to settle 2 million Jews in the West Bank by 2000. The government abrogated the prohibition from purchasing occupied land by Israelis; the \"Drobles Plan\", a plan for large-scale settlement in the West Bank meant to prevent a Palestinian state under the pretext of security became the framework for its policy. The \"Drobles Plan\" from the World Zionist Organization, dated October 1978 and named \"Master Plan for the Development of Settlements in Judea and Samaria, 1979\u20131983\", was written by the Jewish Agency director and former Knesset member Matityahu Drobles. In January 1981, the government adopted a follow-up plan from Drobles, dated September 1980 and named \"The current state of the settlements in Judea and Samaria\", with more details about settlement strategy and policy.\nSince 1967, government-funded settlement projects in the West Bank are implemented by the \"Settlement Division\" of the World Zionist Organization. Though formally a non-governmental organization, it is funded by the Israeli government and leases lands from the Civil Administration to settle in the West Bank. It is authorized to create settlements in the West Bank on lands licensed to it by the Civil Administration. Traditionally, the Settlement Division has been under the responsibility of the Agriculture Ministry. Since the Oslo Accords, it was always housed within the Prime Minister's Office (PMO). In 2007, it was moved back to the Agriculture Ministry. In 2009, the Netanyahu Government decided to subject all settlement activities to additional approval of the Prime Minister and the Defense Minister. In 2011, Netanyahu sought to move the Settlement Division again under the direct control of (his own) PMO, and to curtail Defense Minister Ehud Barak's authority.\nAt the presentation of the Oslo II Accord on 5 October 1995 in the Knesset, PM Yitzhak Rabin expounded the Israeli settlement policy in connection with the permanent solution to the conflict. Israel wanted \"a Palestinian entity, less than a state, which will be a home to most of the Palestinian residents living in the Gaza Strip and the West Bank\". It wanted to keep settlements beyond the Green Line including Ma'ale Adumim and Givat Ze'ev in East Jerusalem. Blocs of settlements should be established in the West Bank. Rabin promised not to return to the 4 June 1967 lines.\nIn June 1997, the Likud government of Benjamin Netanyahu presented its \"Allon Plus Plan\". This plan holds the retention of some 60% of the West Bank, including the \"Greater Jerusalem\" area with the settlements Gush Etzion and Ma'aleh Adumim, other large concentrations of settlements in the West Bank, the entire Jordan Valley, a \"security area\", and a network of Israeli-only bypass roads.\nIn the Road map for peace of 2002, which was never implemented, the establishment of a Palestinian state was acknowledged. Outposts would be dismantled. However, many new outposts appeared instead, few were removed. Israel's settlement policy remained unchanged. Settlements in East Jerusalem and remaining West Bank were expanded.\nWhile according to official Israeli policy no new settlements were built, at least some hundred unauthorized outposts were established since 2002 with state funding in the 60% of the West Bank that was not under Palestinian administrative control and the population growth of settlers did not diminish.\nIn 2005, all 21 settlements in the Gaza Strip and four in the northern West Bank were forcibly evacuated as part of Israeli disengagement from the Gaza Strip, known to some in Israel as \"the Expulsion\". Nevertheless, the total settler population continued to rise.\nAfter the failure of the Roadmap, several new plans emerged to settle in major parts of the West Bank. In 2011, \"Haaretz\" revealed the Civil Administration's \"Blue Line\"-plan, written in January 2011, which aims to increase Israeli \"state-ownership\" of West Bank land (\"state lands\") and settlement in strategic areas like the Jordan Valley and the northern Dead Sea area. In March 2012, it was revealed that the Civil Administration over the years covertly allotted 10% of the West Bank for further settlement. Provisional names for future new settlements or settlement expansions were already assigned. The plan includes many Palestinian built-up sites in the Areas A and B.\nSettlements in the Gaza Strip.\nLand in the Gaza Strip available to its Palestinian inhabitants has historically been limited as a result of Israeli land confiscation and the establishment of settlements. Settlement growth in the Gaza Strip before 1977 was limited, as the Israeli labor party's policy of containment preferred the establishment of a collection of settlements along the border of the Strip. At this point, 6 settlements in the Strip existed, Kfar Darom, Netzarim, Morag, Eretz, Katif, and Netzer Hazani. With the Likud party's revisionist Zionist policies entering with Begin's government, the scale of settlement expansion increased, although the basic policies relating to the settlements did not change. By 1978, 13 settlements had been built as part of a buffer zone along Gaza's southern border in Rafah.\nThe discussions at Camp David that year surrounding the idea of potential future Palestinian autonomy would trigger an increase in settlement expansion in the Gaza Strip, following the Israeli policy of establishing \"facts on the ground\". Political economist Sara Roy described this as a policy intended to make the establishment of an independent Palestinian state more difficult. The locations and size of these new settlements would contribute to geographically isolating Palestinian communities from each other.\nIn the seven years between 1978 and 1985, 11,500 acres of land were confiscated by the Israeli government for the establishment of settlements. By 1991, the settler population in Gaza would reach 3,500 and 4,000 by 1993, or less than 1% of Gaza's population. The land available for use by the Jewish settler community exceeded 25% of the total land in Gaza. The ratio of dunams to people was 23 for Jewish settlers, and 0.27 for Palestinians. Comparing the available built-up area available to each of the two groups in 1993, the ratio is 115 people per square mile for Jewish settlers and over 9,000 people per square mile for Palestinians. Sara Roy estimates the increase in Palestinian population density in Gaza due to Israeli policies alone to be an increase of almost 2,000 people per square mile in 1993.\nAll the settlements were surrounded by electric fences or barbed wire.\nWhile the settlements maintained an isolated economic system, they affected the Gazan economy via land confiscation, the disproportionate consumption of local resources such as water, by overwhelmingly denying work opportunities and through the large disparities in funding (both private and governmental) for economic development.\nGeography and municipal status.\nSome settlements are self-contained cities with a stable population in the tens of thousands, infrastructure, and all other features of permanence. Examples are Beitar Illit (a city of close to 45,000 residents), Ma'ale Adumim, Modi'in Illit, and Ariel (almost 20,000 residents). Some are towns with a local council status with populations of 2,000\u201320,0000, such as Alfei Menashe, Eli, Elkana, Efrat and Kiryat Arba. There are also clusters of villages governed by a local elected committee and regional councils that are responsible for municipal services. Examples are Kfar Adumim, Neve Daniel, Kfar Tapuach and Ateret. Kibbutzim and moshavim in the territories include Argaman, Gilgal, Na'aran and Yitav. Jewish neighborhoods have been built on the outskirts of Arab neighborhoods, for example in Hebron. In Jerusalem, there are urban neighborhoods where Jews and Arabs live together: the Muslim Quarter, Silwan, Abu Tor, Sheikh Jarrah and Shimon HaTzadik.\nUnder the Oslo Accords, the West Bank was divided into three separate parts designated as Area A, Area B and Area C. Leaving aside the position of East Jerusalem, all of the settlements are in Area C which comprises about 60% of the West Bank.\nResettlement of former Jewish communities.\nSome settlements were established on sites where Jewish communities had existed during the British Mandate of Palestine or even since the First Aliyah or ancient times.\nDemographics.\nAt the end of 2010, 534,224 Jewish Israelis lived in the West Bank, including East Jerusalem. 314,132 of them lived in the 121 authorised settlements and 102 unauthorised settlement outposts on the West Bank, 198,629 were living in East Jerusalem, and almost 20,000 lived in settlements in the Golan Heights.\nBy 2011, the number of Jewish settlers in the West Bank excluding East Jerusalem had increased to 328,423 people.\nIn June 2014, the number of Israeli settlers in the West Bank excluding East Jerusalem had increased to 382,031 people, with over 20,000 Israeli settlers in the Golan Heights.\nIn January 2015, the Israeli Interior Ministry gave figures of 389,250 Israeli citizens living in the West Bank outside East Jerusalem.\nBy the end of 2016, the West Bank Jewish population had risen to 420,899, excluding East Jerusalem, where there were more than 200,000 Jews.\nIn 2019, the number of Israeli settlers in the West Bank excluding East Jerusalem had risen to 441,600 individuals, and the number of Israeli settlers in the Golan Heights had risen to 25,261.\nIn 2020, the number of Israeli settlers in the West Bank excluding East Jerusalem had reportedly risen to 451,700 individuals, with an additional 220,000 Jews living in East Jerusalem.\nBased on various sources, population dispersal can be estimated as follows:\n 1 including Sinai\n 2 Janet Abu-Lughod mentions 500 settlers in Gaza in 1978 (excluding Sinai), and 1,000 in 1980\nIn addition to internal migration, in large though declining numbers, the settlements absorb annually about 1000 new immigrants from outside Israel. The American Kulanu organization works with such right-wing Israeli settler groups as Amishav and Shavei Israel to settle \"lost\" Jews of color in such areas where local Palestinians are being displaced. In the 1990s, the annual settler population growth was more than three times the annual population growth in Israel. Population growth has continued in the 2000s. According to the BBC, the settlements in the West Bank have been growing at a rate of 5\u20136% since 2001. In 2016, there were sixty thousand American Israelis living in settlements in the West Bank.\nThe establishment of settlements in the Palestinian territories is linked to the displacement of the Palestinian populations as evidenced by a 1979 Security Council Commission which established a link between Israeli settlements and the displacement of the local population. The commission also found that those who remained were under consistent pressure to leave to make room for further settlers who were being encouraged into the area. In conclusion the commission stated that settlement in the Palestinian territories was causing \"profound and irreversible changes of a geographic and demographic nature\".\nAdministration and local government.\nWest Bank.\nThe Israeli settlements in the West Bank fall under the administrative district of \"Judea and Samaria Area\". Since December 2007, approval by both the Israeli Prime Minister and Israeli Defense Minister of all settlement activities (including planning) in the West Bank is required. Authority for planning and construction is held by the Israel Defense Forces Civil Administration.\nThe area consists of four cities, thirteen local councils and six regional councils.\nThe Yesha Council (, \"Moatzat Yesha\", a Hebrew acronym for Judea, Samaria and Gaza) is the umbrella organization of municipal councils in the West Bank.\nThe actual buildings of the Israeli settlements cover only one percent of the West Bank, but their jurisdiction and their regional councils extend to about 42 percent of the West Bank, according to the Israeli NGO B'Tselem. Yesha Council chairman Dani Dayan disputes the figures and claims that the settlements only control 9.2 percent of the West Bank.\nBetween 2001 and 2007 more than 10,000 Israeli settlement units were built, while 91 permits were issued for Palestinian construction, and 1,663 Palestinian structures were demolished in Area C.\nWest Bank Palestinians have their cases tried in Israel's military courts while Jewish Israeli settlers living in the same occupied territory are tried in civil courts. The arrangement has been described as \"de facto segregation\" by the UN Committee on the Elimination of Racial Discrimination.\nA bill to formally extend Israeli law to the Israeli settlements in the West Bank was rejected in 2012. The basic military laws governing the West Bank are influenced by what is called the \"pipelining\" of Israeli legislation. As a result of \"enclave law\", large portions of Israeli civil law are applied to Israeli settlements and Israeli residents in the occupied territories.\nOn 31 August 2014, Israel announced it was appropriating 400 hectares of land in the West Bank to eventually house 1,000 Israel families. The appropriation was described as the largest in more than 30 years. According to reports on Israel Radio, the development is a response to the 2014 kidnapping and murder of Israeli teenagers.\nIn March 2024 and during the Gaza war, it was announced that Israel was planning on building more than 3,300 new homes in the Kedar and Ma'ale Adumim settlement in the West Bank. The settlement expansion was announced by Israeli Finance Minister Bezalel Smotrich after three Palestinians opened fire near the Ma'ale Adumim settlement, killing one and wounding five, and drew criticism from the US due to increasing tensions. During the Israel-Hamas war, the lines between settlers and the military were described as having become \"indistinguishable\".\nEast Jerusalem.\nEast Jerusalem is defined in the Jerusalem Law of 1980 as part of Israel and its capital, Jerusalem. As such it is administered as part of the city and its district, the Jerusalem District. Pre-1967 residents of East Jerusalem and their descendants have residency status in the city but many have refused Israeli citizenship. Thus, the Israeli government maintains an administrative distinction between Israeli citizens and non-citizens in East Jerusalem, but the Jerusalem municipality does not.\nGolan Heights.\nThe Golan Heights is administered under Israeli civil law as the Golan sub-district, a part of the Northern District. Israel makes no legal or administrative distinction between pre-1967 communities in the Golan Heights (mainly Druze) and the post-1967 settlements.\nSinai Peninsula.\nAfter the capture of the Sinai Peninsula from Egypt in the 1967 Six-Day War, settlements were established along the Gulf of Aqaba and in northeast Sinai, just below the Gaza Strip. Israel had plans to expand the settlement of Yamit into a city with a population of 200,000, though the actual population of Yamit did not exceed 3,000. The Sinai Peninsula was returned to Egypt in stages beginning in 1979 as part of the Egypt\u2013Israel peace treaty. As required by the treaty, in 1982 Israel evacuated the Israeli civilian population from the 18 Sinai settlements in Sinai. In some instances evacuations were done forcefully, such as the evacuation of Yamit. All the settlements were then dismantled.\nGaza Strip.\nBefore Israel's unilateral disengagement plan in which the Israeli settlements were evacuated, there were in the Gaza Strip under the administration of the Hof Aza Regional Council. The land was allocated in such a way that each Israeli settler disposed of 400 times the land available to the Palestinian refugees, and 20 times the volume of water allowed to the peasant farmers of the Strip.\nLegal status.\nThe International Court of Justice delivered a landmark advisory opinion in July 2024 that Israel's occupation of West Bank, East Jerusalem and the Gaza Strip was illegal, that Israel had \"an obligation to cease immediately all new settlement activities and to evacuate all settlers\" from the West Bank and East Jerusalem, and that Israel should \"make reparation for the damage caused to all\" the people of such lands.\nThe consensus view in the international community is that the existence of Israeli settlements in the West Bank including East Jerusalem and the Golan Heights is in violation of international law. The Fourth Geneva Convention includes statements such as \"the Occupying Power shall not deport or transfer parts of its own civilian population into the territory it occupies\". On 20 December 2019, International Criminal Court chief prosecutor Fatou Bensouda announced an International Criminal Court investigation in Palestine into alleged war crimes committed during the Israeli\u2013Palestinian conflict. At present, the view of the international community, as reflected in numerous UN resolutions, regards the building and existence of Israeli settlements in the West Bank, East Jerusalem and the Golan Heights as a violation of international law. UN Security Council Resolution 446 refers to the Fourth Geneva Convention as the applicable international legal instrument, and calls upon Israel to desist from transferring its own population into the territories or changing their demographic makeup. The reconvened Conference of the High Contracting Parties to the Geneva Conventions has declared the settlements illegal as has the primary judicial organ of the UN, the International Court of Justice.\nThe position of successive Israeli governments is that all authorized settlements are entirely legal and consistent with international law. In practice, Israel does not accept that the Fourth Geneva Convention applies \"de jure\", but has stated that on humanitarian issues it will govern itself \"de facto\" by its provisions, without specifying which these are. The scholar and jurist Eugene Rostow has disputed the illegality of authorized settlements.\nUnder Israeli law, West Bank settlements must meet specific criteria to be legal. In 2009, there were approximately 100 small communities that did not meet these criteria and are referred to as illegal outposts.\nIn 2014 twelve EU countries warned businesses against involving themselves in the settlements. According to the warnings, economic activities relating to the settlements involve legal and economic risks stemming from the fact that the settlements are built on occupied land not recognized as Israel's.\nIllegality arguments.\nThe consensus of the international community \u2013 the vast majority of states, the overwhelming majority of legal experts, the International Court of Justice and the UN \u2013 is that settlements are in violation of international law.\nAfter the Six-Day War, in 1967, Theodor Meron, legal counsel to the Israeli Foreign Ministry stated in a legal opinion to the Prime Minister,\n\"My conclusion is that civilian settlement in the administered territories contravenes the explicit provisions of the Fourth Geneva Convention.\"\nThis legal opinion was sent to Prime Minister Levi Eshkol. However, it was not made public at the time. The Labor cabinet allowed settlements despite the warning. This paved the way for future settlement growth. In 2007, Meron stated that \"I believe that I would have given the same opinion today.\"\nIn 1978, the Legal Adviser of the Department of State of the United States reached the same conclusion.\nThe International Court of Justice, in its advisory opinion, has since ruled that Israel is in breach of international law by establishing settlements in Occupied Palestinian Territory, including East Jerusalem. The Court maintains that Israel cannot rely on its right of self-defense or necessity to impose a regime that violates international law. The Court also ruled that Israel violates basic human rights by impeding liberty of movement and the inhabitants' right to work, health, education and an adequate standard of living.\nInternational intergovernmental organizations such as the Conference of the High Contracting Parties to the Fourth Geneva Convention, major organs of the United Nations, the European Union, and Canada, also regard the settlements as a violation of international law. The Committee on the Elimination of Racial Discrimination wrote that \"The status of the settlements was clearly inconsistent with Article 3 of the Convention, which, as noted in the Committee's General Recommendation XIX, prohibited all forms of racial segregation in all countries. There is a consensus among publicists that the prohibition of racial discrimination, irrespective of territories, is an imperative norm of international law.\" Amnesty International, and Human Rights Watch have also characterized the settlements as a violation of international law.\nIn late January 2013 a report drafted by three justices, presided over by Christine Chanet, and issued by the United Nations Human Rights Council declared that Jewish settlements constituted a creeping annexation based on multiple violations of the Geneva Conventions and international law, and stated that if Palestine ratified the Rome Accord, Israel could be tried for \"gross violations of human rights law and serious violations of international humanitarian law.\" A spokesman for Israel's Foreign Ministry declared the report 'unfortunate' and accused the UN's Human Rights Council of a \"systematically one-sided and biased approach towards Israel.\"\nThe Supreme Court of Israel, with a variety of different justices sitting, has repeatedly stated that Israel's presence in the West Bank is subject to international law.\nLegality arguments.\nFour prominent jurists cited the concept of the \"sovereignty vacuum\" in the immediate aftermath of the Six-Day War to describe the legal status of the West Bank and Gaza: Yehuda Zvi Blum in 1968, Elihu Lauterpacht in 1968, Julius Stone in 1969 and 1981, and Stephen M. Schwebel in 1970. Eugene V. Rostow also argued in 1979 that the occupied territories' legal status was undetermined.\nProfessor Ben Saul took exception to this view, arguing that Article 49(6) can be read to include voluntary or assisted transfers, as indeed it was in the advisory opinion of the International Court of Justice which had expressed this interpretation in the Israeli Wall Advisory Opinion (2003).\nIsrael maintains that a temporary use of land and buildings for various purposes is permissible under a plea of military necessity and that the settlements fulfilled security needs. Israel argues that its settlement policy is consistent with international law, including the Fourth Geneva Convention, while recognising that some settlements have been constructed illegally on private land. The Israeli Supreme Court has ruled that the power of the Civil Administration and the Military Commander in the occupied territories is limited by the entrenched customary rules of public international law as codified in the Hague Regulations. In 1998 the Israeli Minister of Foreign Affairs produced \"The International Criminal Court Background Paper\". It concludesInternational law has long recognised that there are crimes of such severity they should be considered \"international crimes.\" Such crimes have been established in treaties such as the Genocide Convention and the Geneva Conventions... The following are Israel's primary issues of concern [i.e. with the rules of the ICC]: The inclusion of settlement activity as a \"war crime\" is a cynical attempt to abuse the Court for political ends. The implication that the transfer of civilian population to occupied territories can be classified as a crime equal in gravity to attacks on civilian population centres or mass murder is preposterous and has no basis in international law.\nA UN conference was held in Rome in 1998, where Israel was one of seven countries to vote against the Rome Statute to establish the International Criminal Court. Israel was opposed to a provision that included as a war crime the transfer of civilian populations into territory the government occupies. Israel has signed the statute, but not ratified the treaty.\nLand ownership.\nA 1996 amendment to an Israeli military order states that land privately owned can not be part of a settlement unless the land in question has been confiscated for military purposes. In 2006 Peace Now acquired a report, which it claims was leaked from the Israeli Government's Civil Administration, indicating that up to 40 percent of the land Israel plans to retain in the West Bank is privately owned by Palestinians. Peace Now called this a violation of Israeli law. Peace Now published a comprehensive report about settlements on private lands. In the wake of a legal battle, Peace Now lowered the figure to 32 percent, which the Civil Administration also denied. \"The Washington Post\" reported that \"The 38-page report offers what appears to be a comprehensive argument against the Israeli government's contention that it avoids building on private land, drawing on the state's own data to make the case.\"\nIn February 2008, the Civil Administration stated that the land on which more than a third of West Bank settlements was built had been expropriated by the IDF for \"security purposes.\" The unauthorized seizure of private Palestinian land was defined by the Civil Administration itself as 'theft.' According to B'Tselem, more than 42 percent of the West Bank are under control of the Israeli settlements, 21 percent of which was seized from private Palestinian owners, much of it in violation of the 1979 Israeli Supreme Court decision.\nIn 1979, the government decided to extend settlements or build new ones only on \"state lands\".\nA secret database, drafted by a retired senior officer, Baruch Spiegel, on orders from former defense minister Shaul Mofaz, found that some settlements deemed legal by Israel were illegal outposts, and that large portions of Ofra, Elon Moreh and Beit El were built on private Palestinian land. The \"Spiegel report\" was revealed by Haaretz in 2009. Many settlements are largely built on private lands, without approval of the Israeli Government. According to Israel, the bulk of the land was vacant, was leased from the state, or bought fairly from Palestinian landowners.\nInvoking the Absentees' Property Laws to transfer, sell or lease property in East Jerusalem owned by Palestinians who live elsewhere without compensation has been criticized both inside and outside of Israel. Opponents of the settlements claim that \"vacant\" land belonged to Arabs who fled or collectively to an entire village, a practice that developed under Ottoman rule. B'Tselem charged that Israel is using the absence of modern legal documents for the communal land as a legal basis for expropriating it. These \"abandoned lands\" are sometimes laundered through a series of fraudulent sales.\nAccording to Amira Hass, one of the techniques used by Israel to expropriate Palestinian land is to place desired areas under a \"military firing zone\" classification, and then issue orders for the evacuation of Palestinians from the villages in that range while allowing contiguous Jewish settlements to remain unaffected.\nEffects on Palestinian human rights.\nAmnesty International argues that Israel's settlement policy is discriminatory and a violation of Palestinian human rights. B'Tselem claims that Israeli travel restrictions impact on Palestinian freedom of movement and Palestinian human rights have been violated in Hebron due to the presence of the settlers within the city. According to B'Tselem, over fifty percent of West Bank land expropriated from Palestinians has been used to establish settlements and create reserves of land for their future expansion. The seized lands mainly benefit the settlements and Palestinians cannot use them. The roads built by Israel in the West Bank to serve the settlements are closed to Palestinian vehicles' and act as a barrier often between villages and the lands on which they subsist.\nHuman Rights Watch and other human rights observer volunteer regularly file reports on \"settler violence\", referring to stoning and shooting incidents involving Israeli settlers. Israel's withdrawal from Gaza and Hebron have led to violent settler protests and disputes over land and resources. Meron Benvenisti described the settlement enterprise as a \"commercial real estate project that conscripts Zionist rhetoric for profit.\"\nThe construction of the Israeli West Bank barrier has been criticized as an infringement on Palestinian human and land rights. The United Nations Office for the Coordination of Humanitarian Affairs estimated that 10% of the West Bank would fall on the Israeli side of the barrier.\nIn July 2012, the UN Human Rights Council decided to set up a probe into Jewish settlements. The report of the independent international fact-finding mission which investigated the \"implications of the Israeli settlements on the civil, political, economic, social and cultural rights of the Palestinian people throughout the Occupied Palestinian Territory\" was published in February 2013.\nIn February 2020, the Office of the United Nations High Commissioner for Human Rights published a list of 112 companies linked to activities related to Israeli settlements in the occupied West Bank.\nEconomy.\nGoods produced in Israeli settlements are able to stay competitive on the global market, in part because of massive state subsidies they receive from the Israeli government. Farmers and producers are given state assistance, while companies that set up in the territories receive tax breaks and direct government subsidies. An Israeli government fund has also been established to help companies pay customs penalties. Palestinian officials estimate that settlers sell goods worth some $500 million to the Palestinian market. Israel has built 16 industrial zones, containing roughly 1000 industrial plants, in the West Bank and East Jerusalem on acreage that consumes large parts of the territory planned for a future Palestinian state. According to Jodi Rudoren these installations both entrench the occupation and provide work for Palestinians, even those opposed to it. The 16 parks are located at Shaked, Beka'ot, Baran, Karnei Shomron, Emmanuel, Barkan, Ariel, Shilo, Halamish, Ma'ale Efraim, Sha'ar Binyamin, Atarot, Mishor Adumim, Gush Etzion, Kiryat Arba and Metarim (2001).\nIn spite of this, the West Bank settlements have failed to develop a self-sustaining local economy. About 60% of the settler workforce commutes to Israel for work. The settlements rely primarily on the labor of their residents in Israel proper rather than local manufacturing, agriculture, or research and development. Of the industrial parks in the settlements, there are only two significant ones, at Ma'ale Adumim and Barkan, with most of the workers there being Palestinian. Only a few hundred settler households cultivate agricultural land, and rely primarily on Palestinian labor in doing so.\nSettlement has an economic dimension, much of it driven by the significantly lower costs of housing for Israeli citizens living in Israeli settlements compared to the cost of housing and living in Israel proper. Government spending per citizen in the settlements is double that spent per Israeli citizen in Tel Aviv and Jerusalem, while government spending for settlers in isolated Israeli settlements is three times the Israeli national average. Most of the spending goes to the security of the Israeli citizens living there.\nExport to EU.\nAccording to Israeli government estimates, $230 million worth of settler goods including fruit, vegetables, cosmetics, textiles and toys are exported to the EU each year, accounting for approximately 2% of all Israeli exports to Europe. A 2013 report of Profundo revealed that at least 38 Dutch companies imported settlement products.\nEuropean Union law requires a distinction to be made between goods originating in Israel and those from the occupied territories. The former benefit from preferential custom treatment according to the EU-Israel Association Agreement (2000); the latter do not, having been explicitly excluded from the agreement. In practice, however, settler goods often avoid mandatory customs through being labelled as originating in Israel, while European customs authorities commonly fail to complete obligatory postal code checks of products to ensure they have not originated in the occupied territories.\nIn 2009, the United Kingdom's Department for the Environment, Food and Rural Affairs issued new guidelines concerning labelling of goods imported from the West Bank. The new guidelines require labelling to clarify whether West Bank products originate from settlements or from the Palestinian economy. Israel's foreign ministry said that the UK was \"catering to the demands of those whose ultimate goal is the boycott of Israeli products\"; but this was denied by the UK government, who said that the aim of the new regulations was to allow consumers to choose for themselves what produce they buy. Denmark has similar legislation requiring food products from settlements in the occupied territories to be accurately labelled. In June 2022, Norway also stated that it would begin complying with EU regulation to label produce originating from Israeli settlements in the West Bank and Golan Heights as such.\nOn 12 November 2019 the Court of Justice of the European Union in a ruling covering all territory Israel captured in the 1967 war decided that labels on foodstuffs must not imply that goods produced in occupied territory came from Israel itself and must \"prevent consumers from being misled as to the fact that the State of Israel is present in the territories concerned as an occupying power and not as a sovereign entity\". In its ruling, the court said that failing to inform EU consumers they were potentially buying goods produced in settlements denies them access to \"ethical considerations and considerations relating to the observance of international law\".\nIn January 2019 the Dail (Ireland's lower house) voted in favour, by 78 to 45, of the Control of Economic Activity (Occupied Territories) Bill. This piece of legislation prohibits the purchasing of any good and/or service from the Golan Heights, East Jerusalem or West Bank settlements. The Bill made no further progress until 2024 when the then government sought legal advice from the Attorney General in response to the International Court of Justice's advisory opinion on Israel's occupation of the Palestinian territories. Following the Attorney General's advice the T\u00e1naiste and Minister for Foreign Affairs, Miche\u00e1l Martin confirmed on 22 October 2024 that the Bill would be \"reviewed and amendments prepared in order to bring in into line with the Constitution and EU Law\". On 31 October 2024, it was reported that a technical blockage of the Bill would be removed to allow it to proceed to committee stage, however the Bill was not passed before the D\u00e1il was suspended \"sine die\" on the 7 November 2024 marking the end of the 33rd D\u00e1il.\nA petition under the European Citizens' Initiative, submitted in September 2021, was accepted on 20 February 2022. The petition seeks the adoption of legislation to ban trade with unlawful settlements. The petition requires a million signatures from across the EU and has received support from civil society groups including Human Rights Watch.\nPalestinian economy and resources.\nA Palestinian report argued in 2011 that settlements have a detrimental effect on the Palestinian economy, equivalent to about 85% of the nominal gross domestic product of Palestine, and that the \"occupation enterprise\" allows the state of Israel and commercial firms to profit from Palestinian natural resources and tourist potential. A 2013 report published by the World Bank analysed the impact that the limited access to Area C lands and resources had on the Palestinian economy. While settlements represent a single axis of control, it is the largest with 68% of the Area C lands reserved for the settlements. The report goes on to calculate that access to the lands and resources of Area C, including the territory in and around settlements, would increase the Palestinian GDP by some $3.5 billion (or 35%) per year.\nThe Israeli Supreme Court has ruled that Israeli companies are entitled to exploit the West Bank's natural resources for economic gain, and that international law must be \"adapted\" to the \"reality on the ground\" of long-term occupation.\nPalestinian labour.\nDue to the availability of jobs offering twice the prevailing salary of the West Bank (as of \u00a02013[ [update]]), as well as high unemployment, tens of thousands of Palestinians work in Israeli settlements. According to the Manufacturers Association of Israel, some 22,000 Palestinians were employed in construction, agriculture, manufacturing and service industries. An Al-Quds University study in 2011 found that 82% of Palestinian workers said they would prefer to not work in Israeli settlements if they had alternative employment in the West Bank.\nPalestinians have been highly involved in the construction of settlements in the West Bank. In 2013, the Palestinian Central Bureau of Statistics released their survey showing that the number of Palestinian workers who are employed by the Jewish settlements increased from 16,000 to 20,000 in the first quarter. The survey also found that Palestinians who work in Israel and the settlements are paid more than twice their salary compared to what they receive from Palestinian employers.\nIn 2008, Kav LaOved charged that Palestinians who work in Israeli settlements are not granted basic protections of Israeli labor law. Instead, they are employed under Jordanian labor law, which does not require minimum wage, payment for overtime and other social rights. In 2007, the Supreme Court of Israel ruled that Israeli labor law does apply to Palestinians working in West Bank settlements and applying different rules in the same work place constituted discrimination. The ruling allowed Palestinian workers to file lawsuits in Israeli courts. In 2008, the average sum claimed by such lawsuits stood at 100,000 shekels.\nAccording to the Palestinian Center for Policy and Survey Research, 63% of Palestinians opposed PA plans to prosecute Palestinians who work in the settlements. However, 72% of Palestinians support a boycott of the products they sell. Although the Palestinian Authority has criminalized working in the settlements, the director-general at the Palestinian Ministry of Labor, Samer Salameh, described the situation in February 2014 as being \"caught between two fires\". He said \"We strongly discourage work in the settlements, since the entire enterprise is illegal and illegitimate...but given the high unemployment rate and the lack of alternatives, we do not enforce the law that criminalizes work in the settlements.\"\nViolence.\nIsraeli settler violence.\nGush Emunim Underground was a militant organization that operated in 1979\u20131984. The organization planned attacks on Palestinian officials and the Dome of the Rock. In 1994, Baruch Goldstein of Hebron, a member of Kach carried out the Cave of the Patriarchs massacre, killing 29 Muslim worshipers and injuring 125. The attack was widely condemned by the Israeli government and Jewish community. The Palestinian leadership has accused Israel of \"encouraging and enabling\" settler violence in a bid to provoke Palestinian riots and violence in retaliation. Violence perpetrated by Israeli settlers against Palestinians constitutes terrorism according to the U.S. Department of State, and former IDF Head of Central Command Avi Mizrahi stated that such violence constitutes \"terror.\"\nIn mid-2008, a UN report recorded 222 acts of Israeli settler violence against Palestinians and IDF troops compared with 291 in 2007. This trend reportedly increased in 2009. Maj-Gen Shamni said that the number had risen from a few dozen individuals to hundreds, and called it \"a very grave phenomenon.\" In 2008\u20132009, the defense establishment adopted a harder line against the extremists. This group responded with a tactic dubbed \"price tagging\", vandalizing Palestinian property whenever police or soldiers were sent in to dismantle outposts. From January through to September 2013, 276 attacks by settlers against Palestinians were recorded.\nLeading religious figures in the West Bank have harshly criticized these tactics. Rabbi Menachem Froman of Tekoa said that \"Targeting Palestinians and their property is a shocking thing, ... It's an act of hurting humanity. ... This builds a wall of fire between Jews and Arabs.\" The Yesha Council and Hanan Porat also condemned such actions. Other rabbis have been accused of inciting violence against non-Jews. In response to settler violence, the Israeli government said that it would increase law enforcement and cut off aid to illegal outposts. Some settlers are thought to lash out at Palestinians because they are \"easy victims.\" The United Nations accused Israel of failing to intervene and arrest settlers suspected of violence. In 2008, Haaretz wrote that \"Israeli society has become accustomed to seeing lawbreaking settlers receive special treatment and no other group could similarly attack Israeli law enforcement agencies without being severely punished.\"\nIn September 2011, settlers vandalized a mosque and an army base. They slashed tires and cut cables of 12 army vehicles and sprayed graffiti. In November 2011, the United Nations Office for Coordination of Human Affairs (OCHA) in the Palestinian territories published a report on settler violence that showed a significant rise compared to 2009 and 2010. The report covered physical violence and property damage such as uprooted olive trees, damaged tractors and slaughtered sheep. The report states that 90% of complaints filed by Palestinians have been closed without charge.\nAccording to EU reports, Israel has created an \"atmosphere of impunity\" for Jewish attackers, which is seen as tantamount to tacit approval by the state. In the West Bank, Jews and Palestinians live under two different legal regimes and it is difficult for Palestinians to lodge complaints, which must be filed in Hebrew in Israeli settlements.\nThe 27 ministers of foreign affairs of the European Union published a report in May 2012 strongly denouncing policies of the State of Israel in the West Bank and denouncing \"continuous settler violence and deliberate provocations against Palestinian civilians.\" The report by all EU ministers called \"on the government of Israel to bring the perpetrators to justice and to comply with its obligations under international law.\"\nIn July 2014, a day after the burial of three murdered Israeli teens, Khdeir, a 16-year-old Palestinian, was forced into a car by 3 Israeli settlers on an East Jerusalem street. His family immediately reported the fact to Israeli Police who located his charred body a few hours later at Givat Shaul in the Jerusalem Forest. Preliminary results from the autopsy suggested that he was beaten and burnt while still alive. The murder suspects explained the attack as a response to the June abduction and murder of three Israeli teens. The murders contributed to a breakout of hostilities in the 2014 Israel\u2013Gaza conflict.\nIn July 2015, a similar incident occurred where Israeli settlers made an arson attack on two Palestinian houses, one of which was empty; however, the other was occupied, resulting in the burning to death of a Palestinian infant; the four other members of his family were evacuated to the hospital suffering serious injuries. These two incidents received condemnation from the United States, European Union and the IDF. The European Union criticized Israel for \"failing to protect the Palestinian population\".\nOlive trees.\nWhile the economy of the Palestinian territories has shown signs of growth, the International Committee of the Red Cross reported that Palestinian olive farming has suffered. According to the ICRC, 10,000 olive trees were cut down or burned by settlers in 2007\u20132010. Foreign ministry spokesman Yigal Palmor said the report ignored official PA data showing that the economic situation of Palestinians had improved substantially, citing Mahmoud Abbas's comment to \"The Washington Post\" in May 2009, where he said \"in the West Bank, we have a good reality, the people are living a normal life.\"\n\"Haaretz\" blamed the violence during the olive harvest on a handful of extremists. In 2010, trees belonging to both Jews and Arabs were cut down, poisoned or torched. In the first two weeks of the harvest, 500 trees owned by Palestinians and 100 trees owned by Jews had been vandalized. In October 2013, 100 trees were cut down.\nViolent attacks on olive trees seem to be facilitated by the apparently systematic refusal of the Israeli authorities to allow Palestinians to visit their own groves, sometimes for years, especially in cases where the groves are deemed to be too close to settlements.\nPalestinian violence against settlers.\nIsraeli civilians living in settlements have been targeted by violence from armed Palestinian groups. These groups, according to Human Rights Watch, assert that settlers are \"legitimate targets\" that have \"forfeited their civilian status by residing in settlements that are illegal under international humanitarian law.\" Both Human Rights Watch and B'tselem rejected this argument on the basis that the legal status of the settlements has no effect on the civilian status of their residents. Human Rights Watch said the \"prohibition against intentional attacks against civilians is absolute.\" B'tselem said \"The settlers constitute a distinctly civilian population, which is entitled to all the protections granted civilians by international law. The Israeli security forces' use of land in the settlements or the membership of some settlers in the Israeli security forces does not affect the status of the other residents living among them, and certainly does not make them proper targets of attack.\"\nFatal attacks on settlers have included firing of rockets and mortars and drive-by shootings, also targeting infants and children. Violent incidents include the murder of Shalhevet Pass, a ten-month-old baby shot by a Palestinian sniper in Hebron, and the murder of two teenagers by unknown perpetrators on 8 May 2001, whose bodies were hidden in a cave near Tekoa, a crime that Israeli authorities suggest may have been committed by Palestinian terrorists. In the Bat Ayin axe attack, children in Bat Ayin were attacked by a Palestinian wielding an axe and a knife. A 13-year-old boy was killed and another was seriously wounded. Rabbi Meir Hai, a father of seven, was killed in a drive-by shooting. In August 2011, five members of one family were killed in their beds. The victims were the father Ehud (Udi) Fogel, the mother Ruth Fogel, and three of their six children\u2014Yoav, 11, Elad, 4, and Hadas, the youngest, a three-month-old infant. According to David Ha'ivri, and as reported by multiple sources, the infant was decapitated.\nPro-Palestinian activist violence.\nPro-Palestinian activists who hold regular protests near the settlements have been accused of stone-throwing, physical assault and provocation. In 2008, Avshalom Peled, head of the Israel Police's Hebron district, called \"left-wing\" activity in the city dangerous and provocative, and accused activists of antagonizing the settlers in the hope of getting a reaction.\nEnvironmental issues.\nMunicipal Environmental Associations of Judea and Samaria, an environmental awareness group, was established by the settlers to address sewage treatment problems and cooperate with the Palestinian Authority on environmental issues. According to a 2004 report by Friends of the Earth Middle East, settlers account for 10% of the population in the West Bank but produce 25% of the sewage output. Beit Duqqu and Qalqilyah have accused settlers of polluting their farmland and villagers claim children have become ill after swimming in a local stream. Legal action was taken against 14 settlements by the Israeli Ministry of the Environment. The Palestinian Authority has also been criticized by environmentalists for not doing more to prevent water pollution. Settlers and Palestinians share the mountain aquifer as a water source, and both generate sewage and industrial effluents that endanger the aquifer. Friends of the Earth Middle East claimed that sewage treatment was inadequate in both sectors. Sewage from Palestinian sources was estimated at 46\u00a0million cubic meters a year, and sources from settler sources at 15\u00a0million cubic meters a year. A 2004 study found that sewage was not sufficiently treated in many settlements, while sewage from Palestinian villages and cities flowed into unlined cesspits, streams and the open environment with no treatment at all.\nIn a 2007 study, the Israel Nature and Parks Authority and Israeli Ministry of Environmental Protection, found that Palestinian towns and cities produced 56\u00a0million cubic meters of sewage per year, 94 percent discharged without adequate treatment, while Israeli sources produced 17.5\u00a0million cubic meters per year, 31.5 percent without adequate treatment.\nAccording to Palestinian environmentalists, the settlers operate industrial and manufacturing plants that can create pollution as many do not conform to Israeli standards. In 2005, an old quarry between Kedumim and Nablus was slated for conversion into an industrial waste dump. Pollution experts warned that the dump would threaten Palestinian water sources.\nImpact on Palestinian demographics.\nThe Consortium for Applied Research on International Migration (CARIM) has reported in their 2011 migration profile for Palestine that the reasons for individuals to leave the country are similar to those of other countries in the region and they attribute less importance to the specific political situation of the occupied Palestinian territory. Human Rights Watch in 2010 reported that Israeli settlement policies have had the effect of \"forcing residents to leave their communities\".\nIn 2008, Condoleezza Rice suggested sending Palestinian refugees to South America, which might reduce pressure on Israel to withdraw from the settlements. Sushil P. Seth speculates that Israelis might feel that increasing settlements will force many Palestinians to flee to other countries and that the remainder will be forced to live under Israeli terms. Speaking anonymously with regard to Israeli policies in the South Hebron Hills, a UN expert said that the Israeli crackdown on alternative energy infrastructures like solar panels is part of a deliberate strategy in Area C.\n\"From December 2010 to April 2011, we saw a systematic targeting of the water infrastructure in Hebron, Bethlehem and the Jordan valley. Now, in the last couple of months, they are targeting electricity. Two villages in the area have had their electrical poles demolished. There is this systematic effort by the civil administration targeting all Palestinian infrastructure in Hebron. They are hoping that by making it miserable enough, they [the Palestinians] will pick up and leave.\"\nApproximately 1,500 people in 16 communities are dependent on energy produced by these installations duct business are threatened with work stoppage orders from the Israeli administration on their installation of alternative power infrastructure, and demolition orders expected to follow will darken the homes of 500 people.\nEducational institutions.\nAriel University, formerly the College of Judea and Samaria, is the major Israeli institution of higher education in the West Bank. With close to 13,000 students, it is Israel's largest public college. The college was accredited in 1994 and awards bachelor's degrees in arts, sciences, technology, architecture and physical therapy. On 17 July 2012, the Council for Higher Education in Judea and Samaria voted to grant the institution full university status.\nTeacher training colleges include Herzog College in Alon Shvut and Orot Israel College in Elkana. Ohalo College is located in Katzrin, in the Golan Heights. Curricula at these institutions are overseen by the Council for Higher Education in Judea and Samaria (CHE-JS).\nIn March 2012, The Shomron Regional Council was awarded the Israeli Ministry of Education's first prize National Education Award in recognizing its excellence in investing substantial resources in the educational system. The Shomron Regional Council achieved the highest marks in all parameters (9.28 / 10). Gershon Mesika, the head of the regional council, declared that the award was a certificate of honour of its educators and the settlement youth who proved their quality and excellence.\nStrategic significance.\nIn 1983 an Israeli government plan entitled \"Master Plan and Development Plan for Settlement in Samaria and Judea\" envisaged placing a \"maximally large Jewish population\" in priority areas to accomplish incorporation of the West Bank in the Israeli \"national system\". According to Ariel Sharon, strategic settlement locations would work to preclude the formation of a Palestinian state.\nPalestinians argue that the policy of settlements constitutes an effort to preempt or sabotage a peace treaty that includes Palestinian sovereignty, and claim that the presence of settlements harm the ability to have a viable and contiguous state. This was also the view of the Israeli Vice Prime Minister Haim Ramon in 2008, saying \"the pressure to enlarge Ofra and other settlements does not stem from a housing shortage, but rather is an attempt to undermine any chance of reaching an agreement with the Palestinians ...\"\nThe Israel Foreign Ministry asserts that some settlements are legitimate, as they took shape when there was no operative diplomatic arrangement, and thus they did not violate any agreement. Based on this, they assert that:\nDismantling of settlements.\nAn early evacuation took place in 1982 as part of the Egypt\u2013Israel peace treaty, when Israel was required to evacuate its settlers from the 18 Sinai settlements. Arab parties to the conflict had demanded the dismantlement of the settlements as a condition for peace with Israel. The evacuation was carried out with force in some instances, for example in Yamit. The settlements were demolished, as it was feared that settlers might try to return to their homes after the evacuation.\nIsrael's unilateral disengagement from the Gaza Strip took place in 2005. It involved the evacuation of settlements in the Gaza Strip and part of the West Bank, including all 21 settlements in Gaza and four in the West Bank, while retaining control over Gaza's borders, coastline, and airspace. Most of these settlements had existed since the early 1980s, some were over 30 years old; the total population involved was more than 8,000. There was significant opposition to the plan among parts of the Israeli public, and especially those living in the territories. George W. Bush said that a permanent peace deal would have to reflect \"demographic realities\" in the West Bank regarding Israel's settlements.\nThe Israeli human rights group GISHA maintains that despite the disengagement, Israel continues to occupy Gaza because it maintains its control over the area. For example, Israel maintains control over Gaza's airspace and waters, its borders (specifically, passage of goods and people to and from Gaza), the population registry, its telecommunications networks, and the collection of customs and tax on imports. GISHA also reports that Israel continues to control Gaza's infrastructure through its control over the supply of resources such as electricity. In addition, under the disengagement plan, Israel can prevent the PA from reopening its airport or seaport.\nWithin the former settlements, almost all buildings were demolished by Israel, with the exception of certain government and religious structures, which were completely emptied. Under an international arrangement, greenhouses were left to assist the Palestinian economy although half had been demolished by the settlers two months prior to the disengagement. The reduction in greenhouse space and increased restrictions on exports reduced the viability of the project. After the redeployment of Israeli troops to the Gaza border, 30% of the greenhouses suffered various degrees of damage due to Palestinian looters stealing, for example, hoses and irrigation equipment. Following the withdrawal, many of the former synagogues were torched and destroyed by Palestinians.\nSome believe that settlements need not necessarily be dismantled and evacuated, even if Israel withdraws from the territory where they stand, as they can remain under Palestinian rule. These ideas have been expressed both by left-wing Israelis, and by Palestinians who advocate the two-state solution, and by extreme Israeli right-wingers and settlers who object to any dismantling and claim links to the land that are stronger than the political boundaries of the state of Israel.\nThe Israeli government has often threatened to dismantle outposts. Some have actually been dismantled, occasionally with use of force; this led to settler violence.\nPalestinian statehood bid of 2011.\nAmerican refusal to declare the settlements illegal was said to be the determining factor in the 2011 attempt to declare Palestinian statehood at the United Nations, the so-called Palestine 194 initiative.\nIsrael announced additional settlements in response to the Palestinian diplomatic initiative and Germany responded by moving to stop deliveries to Israel of submarines capable of carrying nuclear weapons.\nFinally in 2012, several European states switched to either abstain or vote for statehood in response to continued settlement construction. Israel approved further settlements in response to the vote, which brought further worldwide condemnation.\nImpact on peace process.\nThe settlements have been a source of tension between Israel and the U.S. Jimmy Carter regarded the settlements as illegal and tactically unwise. Ronald Reagan stated that they were legal but an obstacle to negotiations. In 1991, the U.S. delayed a subsidized loan to pressure Israel on the subject of settlement-building in the Jerusalem-Bethlehem corridor. In 2005, U.S. declared support for \"the retention by Israel of major Israeli population centers as an outcome of negotiations,\" reflecting the statement by George W. Bush that a permanent peace treaty would have to reflect \"demographic realities\" in the West Bank. In June 2009, Barack Obama said that the United States \"does not accept the legitimacy of continued Israeli settlements.\"\nPalestinians claim that Israel has undermined the Oslo accords and peace process by continuing to expand the settlements. Settlements in the Sinai Peninsula were evacuated and razed in the wake of the peace agreement with Egypt. The 27 ministers of foreign affairs of the European Union published a report in May 2012 strongly denouncing policies of the State of Israel in the West Bank and finding that Israeli settlements in the West Bank are illegal and \"threaten to make a two-state solution impossible.\" In the framework of the Oslo I Accord of 1993 between the Israeli government and the Palestine Liberation Organization (PLO), a modus vivendi was reached whereby both parties agreed to postpone a final solution on the destination of the settlements to the permanent status negotiations (Article V.3). Israel claims that settlements thereby were not prohibited, since there is no explicit interim provision prohibiting continued settlement construction, the agreement does register an undertaking by both sides, namely that \"Neither side shall initiate or take any step that will change the status of the West Bank and the Gaza Strip pending the outcome of the permanent status negotiations\" (Article XXX1 (7)), which has been interpreted as, not forbidding settlements, but imposing severe restrictions on new settlement building after that date. Melanie Jacques argued in this context that even 'agreements between Israel and the Palestinians which would allow settlements in the OPT, or simply tolerate them pending a settlement of the conflict, violate the Fourth Geneva Convention.'\nFinal status proposals have called for retaining long-established communities along the Green Line and transferring the same amount of land in Israel to the Palestinian state. The Clinton administration proposed that Israel keep some settlements in the West Bank, especially those in large blocs near the pre-1967 borders of Israel, with the Palestinians receiving concessions of land in other parts of the country. Both Clinton and Tony Blair pointed out the need for territorial and diplomatic compromise based on the validity of some of the claims of both sides.\nAs Minister of Defense, Ehud Barak approved a plan requiring security commitments in exchange for withdrawal from the West Bank. Barak also expressed readiness to cede parts of East Jerusalem and put the holy sites in the city under a \"special regime.\"\nOn 14 June 2009, Israeli Prime Minister Benjamin Netanyahu, as an answer to U.S. President Barack Obama's speech in Cairo, delivered a speech setting out his principles for a Palestinian-Israeli peace, among others, he alleged \"... we have no intention of building new settlements or of expropriating additional land for existing settlements.\" In March 2010, the Netanyahu government announced plans for building 1,600 housing units in Ramat Shlomo across the Green Line in East Jerusalem during U.S. Vice President Joe Biden's visit to Israel causing a diplomatic row.\nOn 6 September 2010, Jordanian King Abdullah II and Syrian President Bashar al-Assad said that Israel would need to withdraw from all of the lands occupied in 1967 in order to achieve peace with the Palestinians.\nBradley Burston has said that a negotiated or unilateral withdraw from most of the settlements in the West Bank is gaining traction in Israel.\nIn November 2010, the United States offered to \"fight against efforts to delegitimize Israel\" and provide extra arms to Israel in exchange for a continuation of the settlement freeze and a final peace agreement, but failed to come to an agreement with the Israelis on the exact terms.\nIn December 2010, the United States criticised efforts by the Palestinian Authority to impose borders for the two states through the United Nations rather than through direct negotiations between the two sides. In February 2011, it vetoed a draft resolution to condemn all Jewish settlements established in the occupied Palestinian territory since 1967 as illegal. The resolution, which was supported by all other Security Council members and co-sponsored by nearly 120 nations, would have demanded that \"Israel, as the occupying power, immediately and completely ceases all settlement activities in the occupied Palestinian territory, including East Jerusalem and that it fully respect its legal obligations in this regard.\" The U.S. representative said that while it agreed that the settlements were illegal, the resolution would harm chances for negotiations. Israel's deputy Foreign Minister, Daniel Ayalon, said that the \"UN serves as a rubber stamp for the Arab countries and, as such, the General Assembly has an automatic majority,\" and that the vote \"proved that the United States is the only country capable of advancing the peace process and the only righteous one speaking the truth: that direct talks between Israel and the Palestinians are required.\" Palestinian negotiators, however, have refused to resume direct talks until Israel ceases all settlement activity.\nIn November 2009, Israeli Prime Minister Netanyahu issued a 10-month settlement freeze in the West Bank in an attempt to restart negotiations with the Palestinians. The freeze did not apply to building in Jerusalem in areas across the green line, housing already under construction and existing construction described as \"essential for normal life in the settlements\" such as synagogues, schools, kindergartens and public buildings. The Palestinians refused to negotiate without a complete halt to construction. In the face of pressure from the United States and most world powers supporting the demand by the Palestinian Authority that Israel desist from settlement project in 2010, Israel's ambassador to the UN Meron Reuben said Israel would only stop settlement construction after a peace agreement is concluded, and expressed concern were Arab countries to press for UN recognition of a Palestinian state before such an accord. He cited Israel's dismantlement of settlements in both the Sinai which took place after a peace agreement, and its unilateral dismantlement of settlements in the Gaza Strip. He presumed that settlements would stop being built were Palestinians to establish a state in a given area.\nProposals for land swap.\nThe Clinton Parameters, a 2000 peace proposal by then U.S. President Bill Clinton, included a plan on which the Palestinian State was to include 94\u201396% of the West Bank, and around 80% of the settlers were to be under Israeli sovereignty, and in exchange for that, Israel will concede some territory (so called 'Territory Exchange' or 'Land Swap') within the Green Line (1967 borders). The swap would consist of 1\u20133% of Israeli territory, such that the final borders of the West Bank part of the Palestinian state would include 97% of the land of the original borders.\nIn 2010, Palestinian Authority President Mahmoud Abbas said that the Palestinians and Israel have agreed on the principle of a land swap. The issue of the ratio of land Israel would give to the Palestinians in exchange for keeping settlement blocs is an issue of dispute, with the Palestinians demanding that the ratio be 1:1, and Israel insisting that other factors be considered as well.\nUnder any peace deal with the Palestinians, Israel intends to keep the major settlement blocs close to its borders, which contain over 80% of the settlers. Prime Ministers Yitzhak Rabin, Ariel Sharon, and Benjamin Netanyahu have all stated Israel's intent to keep such blocs under any peace agreement. U.S. President George W. Bush acknowledged that such areas should be annexed to Israel in a 2004 letter to Prime Minister Sharon.\nThe European Union position is that any annexation of settlements should be done as part of mutually agreed land swaps, which would see the Palestinians controlling territory equivalent to the territory captured in 1967. The EU says that it will not recognise any changes to the 1967 borders without an agreement between the parties.\nIsraeli Foreign Minister Avigdor Lieberman has proposed a plan which would see settlement blocs annexed to Israel in exchange for heavily Arab areas inside Israel as part of a population exchange.\nAccording to Mitchell G. Bard: \"Ultimately, Israel may decide to unilaterally disengage from the West Bank and determine which settlements it will incorporate within the borders it delineates. Israel would prefer, however, to negotiate a peace treaty with the Palestinians that would specify which Jewish communities will remain intact within the mutually agreed border of Israel, and which will need to be evacuated. Israel will undoubtedly insist that some or all of the \"consensus\" blocs become part of Israel\".\nProposal of dual citizenship.\nA number of proposals for the granting of Palestinian citizenship or residential permits to Jewish settlers in return for the removal of Israeli military installations from the West Bank have been fielded by such individuals as Arafat, Ibrahim Sarsur and Ahmed Qurei. In contrast, Mahmoud Abbas said in July 2013 that \"In a final resolution, we would not see the presence of a single Israeli\u2014civilian or soldier\u2014on our lands.\"\nIsraeli Minister Moshe Ya'alon said in April 2010 that \"\"just as Arabs live in Israel, so, too, should Jews be able to live in Palestine.\" ... \"If we are talking about coexistence and peace, why the [Palestinian] insistence that the territory they receive be ethnically cleansed of Jews?\"\".\nThe idea has been expressed by both advocates of the two-state solution and supporters of the settlers and conservative or fundamentalist currents in Israeli Judaism that, while objecting to any withdrawal, claim stronger links to the land than to the State of Israel.\nSettlement expansion.\nPre Resolution 2334.\nOn 19 June 2011, \"Haaretz\" reported that the Israeli cabinet voted to revoke Defense Minister Ehud Barak's authority to veto new settlement construction in the West Bank, by transferring this authority from the Agriculture Ministry, headed by Barak ally Orit Noked, to the Prime Minister's office.\nIn 2009, newly elected Prime Minister Benjamin Netanyahu said: \"I have no intention of building new settlements in the West Bank... But like all the governments there have been until now, I will have to meet the needs of natural growth in the population. I will not be able to choke the settlements.\" On 15 October 2009, he said the settlement row with the United States had been resolved.\nIn April 2012, four illegal outposts were retroactively legalized by the Israeli government. In June 2012, the Netanyahu government announced a plan to build 851 homes in five settlements: 300 units in Beit El and 551 units in other settlements.\nAmid peace negotiations that showed little signs of progress, Israel issued on 3 November 2013, tenders for 1,700 new homes for Jewish settlers. The plots were offered in nine settlements in areas Israel says it intends to keep in any peace deal with the Palestinians. On 12 November, Peace Now revealed that the Construction and Housing Ministry had issued tenders for 24,000 more settler homes in the West Bank, including 4,000 in East Jerusalem. 2,500 units were planned in Ma'aleh Adumim, some 9,000 in the Gush Etzion Region, and circa 12,000 in the Binyamin Region, including 1,200 homes in the E1 area in addition to 3,000 homes in previously frozen E1 projects. Circa 15,000 homes of the 24,000 plan would be east of the West Bank Barrier and create the first new settlement blocs for two decades, and the first blocs ever outside the Barrier, far inside the West Bank.\nAs stated before, the Israeli government (as of 2015) has a program of residential subsidies in which Israeli settlers receive about double that given to Israelis in Tel Aviv and Jerusalem. As well, settlers in isolated areas receive three times the Israeli national average. From the beginning of 2009 to the end of 2013, the Israeli settlement population as a whole increased by a rate of over 4% per year. A \"New York Times\" article in 2015 stated that said building had been \"at the heart of mounting European criticism of Israel.\"\nResolution 2334 and quarterly reports.\nUnited Nations Security Council Resolution 2334 \"Requests the Secretary-General to report to the Council every three months on the implementation of the provisions of the present resolution;\"\nIn the first of these reports, delivered verbally at a security council meeting on 24 March 2017, United Nations Special Coordinator for the Middle East Peace Process, Nickolay Mladenov, noted that Resolution 2334 called on Israel to take steps to cease all settlement activity in the Occupied Palestinian Territory, that \"no such steps have been taken during the reporting period\" and that instead, there had been a marked increase in statements, announcements and decisions related to construction and expansion.\nRegularization and outpost method.\nThe 2017 Settlement Regularization in \"Judea and Samaria\" Law permits backdated legalization of outposts constructed on private Palestinian land. Following a petition challenging its legality, on June 9, 2020, Israel's Supreme Court struck down the law that had retroactively legalized about 4,000 settler homes built on privately owned Palestinian land. The Israeli Attorney General has stated that existing laws already allow legalization of Israeli constructions on private Palestinian land in the West Bank. The Israeli Attorney General, Avichai Mandelblit, has updated the High Court on his official approval of the use of a legal tactic permitting the de facto legalization of roughly 2,000 illegally built Israeli homes throughout the West Bank. The legal mechanism is known as \"market regulation\" and relies on the notion that wildcat Israeli homes built on private Palestinian land were done so in good faith.\nIn a report of 22 July 2019, PeaceNow notes that after a gap of 6 years when there were no new outposts, establishment of new outposts recommenced in 2012, with 32 of the current 126 outposts set up to date. 2 outposts were subject to eviction, 15 were legalized and at least 35 are in process of legalization.\nUpdates and related matters.\nThe Israeli government announced in 2019 that it has made monetary grants available for the construction of hotels in Area C of the West Bank.\nAccording to Peace Now, approvals for building in Israeli settlements in East Jerusalem expanded by 60% between 2017, when Donald Trump became US president, and 2019.\nOn 9 July 2021, Michael Lynk, U.N. special rapporteur on human rights in the occupied Palestinian territory, addressing a session of the UN Human Rights Council in Geneva, said \"I conclude that the Israeli settlements do amount to a war crime,\" and \"I submit to you that this finding compels the international community...to make it clear to Israel that its illegal occupation, and its defiance of international law and international opinion, can and will no longer be cost-free.\" Israel, which does not recognize Lynk's mandate, boycotted the session.\nA new Israeli government, formed on 13 June 2021, declared a \"status quo\" in the settlements policy. According to Peace Now, as of 28 October this has not been the case. On October 24, 2021, tenders were published for 1,355 housing units plus another 83 in Givat HaMatos and on 27 October 2021, approval was given for 3,000 housing units including in settlements deep inside the West Bank. These developments were condemned by the U.S. as well as by the United Kingdom, Russia and 12 European countries. while UN experts, Michael Lynk, Special Rapporteur on the situation of human rights in the Palestinian Territory occupied since 1967 and Mr. Balakrishnan Rajagopal (United States of America), UN Special Rapporteur on adequate housing said that settlement expansion should be treated as a \"presumptive war crime\".\nIn February 2023, the new Israeli government under Benjamin Netanyahu approved the legalization of nine illegal settler outposts in the West Bank. Finance Minister Bezalel Smotrich took charge of most of the Civil Administration, obtaining broad authority over civilian issues in the West Bank. In March 2023, Netanyahu's government repealed a 2005 law whereby four Israeli settlements, Homesh, Sa-Nur, Ganim and Kadim, were dismantled as part of the Israeli disengagement from Gaza. In June 2023, Israel shortened the procedure of approving settlement construction and gave Finance Minister Smotrich the authority to approve one of the stages, changing the system operating for the last 27 years. In its first six months, construction of 13,000 housing units in settlements, almost triple the amount advanced in the whole of 2022.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "15125", "revid": "50019424", "url": "https://en.wikipedia.org/wiki?curid=15125", "title": "Irrealism (the arts)", "text": "Irrealism is a term that has been used by various writers in the fields of philosophy, literature, and art to denote specific modes of unreality and/or the problems in concretely defining reality. While in philosophy the term specifically refers to a position put forward by the American philosopher Nelson Goodman, in literature and art it refers to a variety of writers and movements. If the term has nonetheless retained a certain consistency in its use across these fields and would-be movements, it perhaps reflects the word's position in general English usage: though the standard dictionary definition of \"irreal\" gives it the same meaning as \"unreal\", \"irreal\" is very rarely used in comparison with \"unreal\". Thus, it has generally been used to describe something which, while unreal, is so in a very specific or unusual fashion, usually one emphasizing not just the \"not real,\" but some form of estrangement from our generally accepted sense of reality.\nIrrealism in literature.\nIn literature, the term irrealism was first used extensively in the United States in the 1970s to describe the post-realist \"new fiction\" of writers such as Donald Barthelme or John Barth. More generally, it described the notion that all forms of writing could only \"offer particular versions of reality rather than actual descriptions of it,\" and that a story need not offer a clear resolution at its end. John Gardner, in \"The Art of Fiction\", cites in this context the work of Barthelme and its \"seemingly limitless ability to manipulate [literary] techniques as modes of apprehension [which] apprehend nothing.\" Though Barth, in a 1974 interview, stated, \"irrealism\u2014not antirealism or unrealism, but irrealism\u2014is all that I would confidently predict is likely to characterize the prose fiction of the 1970s,\" this did not prove to be the case. Instead writing in the United States quickly returned to its realist orthodoxy and the term irrealism fell into disuse.\nIn recent years, however, the term has been revived in an attempt to describe and categorize, in literary and philosophical terms, how it is that the work of an irrealist writer differs from the work of writers in other, non-realistic genres (e.g., the fantasy of J.R.R. Tolkien, the magical realism of Gabriel Garc\u00eda M\u00e1rquez) and what the significance of this difference is. This can be seen in Dean Swinford's essay \"Defining irrealism: scientific development and allegorical possibility\".http:// Approaching the issue from a structuralist and narratological point of view, he has defined irrealism as a \"peculiar mode of postmodern allegory\" that has resulted from modernity's fragmentation and dismantling of the well-ordered and coherent medieval system of symbol and allegory. Thus a lion, when presented in a given context in medieval literature, could only be interpreted in a single, approved way. Contemporary literary theory, however, denies the attribution of such fixed meanings. According to Swinford, this change can be attributed in part to the fact that \"science and technical culture have changed perceptions of the natural world, have significantly changed the natural world itself, thereby altering the vocabulary of symbols applicable to epistemological and allegorical attempts to understand it.\" Thus irreal works such as Italo Calvino's \"Cosmicomics\" and Jorge Luis Borges' \"Ficciones\" can be seen as an attempt to find a new allegorical language to explain our changed perceptions of the world that have been brought about by our scientific and technical culture, especially concepts such as quantum physics or the theory of relativity. \"The Irrealist work, then, operates within a given system,\" writes Swinford, \"and attests to its plausibility, despite the fact that this system, and the world it represents, is often a mutation, an aberration.\"\nThe online journal \"The Cafe Irreal\" http://, on the other hand, has defined irrealism as being a type of existentialist literature in which the means are continually and absurdly rebelling against the ends that we have determined for them. An example of this would be Franz Kafka's story \"The Metamorphosis\", in which the salesman Gregor Samsa's plans for supporting his family and rising up in rank by hard work and determination are suddenly thrown topsy-turvy by his sudden and inexplicable transformation into a man-sized insect. Such fiction is said to emphasize the fact that human consciousness, being finite in nature, can never make complete sense of, or successfully order, a universe that is infinite in its aspects and possibilities. Which is to say: as much as we might try to order our world with a certain set of norms and goals (which we consider our real world), the paradox of a finite consciousness in an infinite universe creates a zone of irreality (\"that which is beyond the real\") that offsets, opposes, or threatens the real world of the human subject. Irrealist writing often highlights this irreality, and our strange fascination with it, by combining the unease we feel because the real world doesn't conform to our desires with the narrative quality of the dream state (where reality is constantly and inexplicably being undermined); it is thus said to communicate directly, \"by feeling rather than articulation, the uncertainties inherent in human existence or, to put it another way... the irreconcilability between human aspiration and human reality.\" http:// If the irreal story can be considered an allegory, then, it would be an allegory that is \"so many pointers to an unknown meaning,\" in which the meaning is felt more than it is articulated or systematically analyzed.\nIrrealism in art.\nVarious writers have addressed the question of Irrealism in Art. Many salient observations on Irrealism in Art are found in Nelson Goodman's \"Languages of Art\". Goodman himself produced some multimedia shows, one of which inspired by hockey and is entitled \"Hockey Seen: A Nightmare in Three Periods and Sudden Death\".\nGarret Rowlan, writing in \"The Cafe Irreal\", writes that the malaise present in the work of the Italian artist Giorgio de Chirico, \"which recalls Kafka, has to do with the sense of another world lurking, hovering like the long shadows that dominate de Chirico's paintings, which frequently depict a landscape at twilight's uncertain hour. Malaise and mystery are all by-products of the interaction of the real and the unreal, the rub and contact of two worlds caught on irrealism's shimmering surface.\" http://\nThe writer Dean Swinford, whose concept of irrealism was described at length in the section \"Irrealism in Literature\", wrote that the artist Remedios Varos, in her painting \"The Juggler\", \"creates a personal allegorical system which relies on the predetermined symbols of Christian and classical iconography. But these are quickly refigured into a personal system informed by the scientific and organized like a machine...in the Irreal work, allegory operates according to an altered, but constant and orderly iconographic system.\"\nArtist Tristan Tondino claims \"There is no specific style to Irrealist Art. It is the result of awareness that every human act is the result of the limitations of the world of the actor.\"\nIn Australia, the art journal \"the art life\" has recently detected the presence of a \"New Irrealism\" among the painters of that country, which is described as being an \"approach to painting that is decidedly low key, deploying its effects without histrionic showmanship, while creating an eerie other world of ghostly images and abstract washes.\" What exactly constituted the \"old\" irrealism, they do not say.\nIrrealist Art, Film and Music Edition.\nIrrealist Art Edition is a publishing company created in the 90s by contemporary plastic artist Fr\u00e9d\u00e9ric Iriarte. Together with the Estonian poet, writer and art critic Ilmar Laaban, they developed their concept of Irrealism through several essays, exhibitions, projects, manifest and a book, \"Irr\u00e9alisation\". http:// "}
{"id": "15127", "revid": "11292982", "url": "https://en.wikipedia.org/wiki?curid=15127", "title": "Internet humor", "text": ""}
{"id": "15129", "revid": "13286072", "url": "https://en.wikipedia.org/wiki?curid=15129", "title": "You have two cows", "text": "Joke pattern pertaining to different economic systems\n\"You have two cows\" is a political analogy and form of early 20th century American political satire to describe various economic systems of government. The setup of a typical joke of this kind is the assumption that the listener lives within a given system and has two cows. The punch line is what happens to the listener and the cows in the system; it offers a brief and humorous take on the subject or locale.\nHistory.\nA 1936 article in \"The Modern Language Journal\" reports that the following definitions of \"isims\" were used in a Chicago political campaign:\nBill Sherk mentions that such lists circulated throughout the United States since around 1936 under the title \"Parable of the Isms\". A column in \"The Chicago Daily Tribune\" in 1938 attributes a version involving socialism, communism, fascism and New Dealism to an address by Silas Strawn to the Economic Club of Chicago on 29 November 1935.\nRichard M Steers and Luciara Nardon in their book about global economy use the \"two cows\" metaphor to illustrate the concept of cultural differences. They write that jokes of this kind, \"Russian company: You have two cows. You drink some vodka and count them again. You have five cows. The Russian Mafia shows up and takes however many cows you have\", are considered funny because they are \"realistic but exaggerated caricatures\" of various cultures, and the pervasiveness of such jokes stems from the significant cultural differences. Steers and Nardon also state that others believe such jokes present cultural stereotypes and must be viewed with caution.\nNotable variants.\nEnron scandal.\nThe economics of the Enron scandal have been a target of the \"two cows\" joke, often describing the accounting fraud that took place in Enron's finances. Much of the beginning of the joke when used to describe Enron resembles the following:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\"Enronism\": You have two cows. You sell three of them to your publicly listed company, using letters of credit opened by your brother-in-law at the bank, then execute a debt/equity swap with an associated general offer so that you get all four cows back, with a tax exemption for five cows. The milk rights of the six cows are transferred via an intermediary to a Cayman Island company secretly owned by your CFO who sells the rights to all seven cows back to your listed company. The annual report says the company owns eight cows, with an option on six more.\nThe ending of the joke varies in most interactions. An article by Bruce Sterling for the magazine \"Wired\" in 2008 had a version of the joke ending with Enron selling one cow to buy a new president of the United States, no balance sheet provided with the annual report, and ultimately the public buying Enron's bull. In 2002, Power Engineering ended the joke by announcing Enron would start trading cows online using the platform COW (cows on web).\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "15134", "revid": "27015025", "url": "https://en.wikipedia.org/wiki?curid=15134", "title": "Lightbulb joke", "text": "Jokes of the form \"How many does it take to change a lightbulb?\"\nA lightbulb joke is a joke cycle that asks how many people of a certain group are needed to change, replace, or screw in a light bulb. Generally, the punch line answer highlights a stereotype of the target group. There are numerous versions of the lightbulb joke satirizing a wide range of cultures, beliefs, and occupations.\nEarly versions of the joke, popular in the late 1960s and the 1970s, were used to insult the intelligence of people, especially Poles (\"Polish jokes\"). Such jokes generally take the form of:\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;&lt;poem&gt;Q. How many [members of the target group] does it take to change a lightbulb?\nA. Three \u2014 one to hold the light bulb and two to turn the ladder around.&lt;/poem&gt;\nAlthough lightbulb jokes tend to be derogatory in tone (\"e.g.\", \"How many drunkards...\" / \"Four: one to hold the light bulb and three to drink until the room spins\"), the people targeted by them may take pride in the stereotypes expressed and are often themselves the jokes' originators. An example where the joke itself becomes a statement of ethnic pride is:\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;&lt;poem&gt;Q. How many Germans does it take to change a lightbulb?\nA. One, we're very efficient but not funny.&lt;/poem&gt;\nLightbulb jokes applied to subgroups can be used to ease tensions between them.\nVariations.\nSome versions of the joke are puns on the words \"change\" or \"screw\", or \"light\":\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;&lt;poem&gt;Q. How many psychiatrists does it take to change a light bulb?\nA. None\u2014the light bulb will change when it's ready.&lt;/poem&gt;\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;&lt;poem&gt;Q. How many flies does it take to screw in a lightbulb?\nA. Two, but don't ask me how they got in there.&lt;/poem&gt;\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;&lt;poem&gt;Q. How many hands does it take to change a lightbulb?\nA. Many.&lt;/poem&gt;\nLightbulb jokes are often responses to contemporary events.\nFor example, the lightbulb may not need to be changed at all due to ongoing power outages.\n\"The Village Voice\" held a $200 lightbulb joke contest around the time of the Iran hostage crisis, with the winning joke being:&lt;templatestyles src=\"Block indent/styles.css\"/&gt;&lt;poem&gt;Q. How many Iranians does it take to change a light bulb?\nA. You send us the prize money and we'll tell you the answer.&lt;/poem&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "15135", "revid": "36767729", "url": "https://en.wikipedia.org/wiki?curid=15135", "title": "Internet humor/Long lightbulb jokes", "text": ""}
{"id": "15139", "revid": "253891", "url": "https://en.wikipedia.org/wiki?curid=15139", "title": "Honor system virus", "text": ""}
{"id": "15144", "revid": "43007828", "url": "https://en.wikipedia.org/wiki?curid=15144", "title": "International Electrotechnical Commission", "text": "International standards organization\nThe International Electrotechnical Commission (IEC; ) is an international standards organization that prepares and publishes international standards for all electrical, electronic and related technologies. IEC standards cover a vast range of technologies from power generation, transmission and distribution to home appliances and office equipment, semiconductors, fibre optics, batteries, solar energy, nanotechnology, and marine energy, as well as many others. The IEC also manages four global conformity assessment systems that certify whether equipment, system or components conform to its international standards.\nAll electrotechnologies are covered by IEC standards, including energy production and distribution, electronics, magnetics and electromagnetics, electroacoustics, multimedia, telecommunications and medical technology, as well as associated general disciplines such as terminology and symbols, electromagnetic compatibility, measurement and performance, dependability, design and development, safety and the environment.\nHistory.\nThe first International Electrical Congress took place in 1881 at the International Exposition of Electricity, held in Paris. At that time the International System of Electrical and Magnetic Units was agreed to.\nThe International Electrotechnical Commission held its inaugural meeting on 26 June 1906, following discussions among the British Institution of Electrical Engineers, the American Institute of Electrical Engineers, and others, which began at the 1900 Paris International Electrical Congress, with British engineer R. E. B. Crompton playing a key role. In 1906, Lord Kelvin was elected as the first President of the International Electrotechnical Commission.\nThe IEC was instrumental in developing and distributing standards for units of measurement, particularly the gauss, hertz, and weber. It was also first to promote the Giorgi System of standards, later developed into the SI, or \"Syst\u00e8me International d'unit\u00e9s\" (in English, the International System of Units).\nIn 1938, it published a multilingual international vocabulary to unify terminology relating to electrical, electronic and related technologies. This effort continues, and the International Electrotechnical Vocabulary is published online as the \"Electropedia\".\nThe CISPR (\"Comit\u00e9 International Sp\u00e9cial des Perturbations Radio\u00e9lectriques\") \u2013 in English, the International Special Committee on Radio Interference \u2013 is one of the groups founded by the IEC.\nCurrently, 89 countries are IEC members while another 85 participate in the Affiliate Country Programme, which is not a form of membership but is designed to help industrializing countries get involved with the IEC. Originally located in London, United Kingdom, the IEC moved to its current headquarters in Geneva, Switzerland in 1948.\nIt has regional centres in Africa (Nairobi, Kenya), Asia (Singapore), Oceania (Sydney, Australia), Latin America (S\u00e3o Paulo, Brazil) and North America (Worcester, Massachusetts, United States).\nThe work is done by some 10,000 electrical and electronics experts from industry, government, academia, test labs and others with an interest in the subject.\nIEC Standards are often adopted as national standards by its members.\nIEC standards.\nThe IEC cooperates closely with the International Organization for Standardization (ISO) and the International Telecommunication Union (ITU). In addition, it works with several major standards development organizations, including the IEEE with which it signed a cooperation agreement in 2002, which was amended in 2008 to include joint development work.\nIEC standards that are not jointly developed with ISO have numbers in the range 60000\u201379999 and their titles take a form such as \"IEC 60417: Graphical symbols for use on equipment\". Following the Dresden Agreement with CENELEC the numbers of older IEC standards were converted in 1997 by adding 60000, for example IEC 27 became IEC 60027. Standards of the 60000 series are also found preceded by EN to indicate that the IEC standard is also adopted by CENELEC as a European standard; for example IEC 60034 is also available as EN 60034.\nStandards developed jointly with ISO, such as ISO/IEC 26300 (\"Open Document Format for Office Applications (OpenDocument) v1.0\"), ISO/IEC 27001 (\"Information technology, Security techniques, Information security management systems, Requirements\") and ISO/IEC 17000 series, carry the acronyms of both organizations. The use of the ISO/IEC prefix covers publications from ISO/IEC Joint Technical Committee 1 \u2013 \"Information Technology\", as well as conformity assessment standards developed by ISO CASCO (Committee on conformity assessment) and IEC CAB (Conformity Assessment Board). Other standards developed in cooperation between IEC and ISO are assigned numbers in the 80000 series, such as IEC 82045\u20131.\nIEC standards are also being adopted by other certifying bodies such as BSI (United Kingdom), CSA (Canada), UL and ANSI/INCITS (United States), SABS (South Africa), Standards Australia, SPC/GB (China) and DIN (Germany). IEC standards adopted by other certifying bodies may have some noted differences from the original IEC standard.\nMembership and participation.\nThe IEC is made up of members, called national committees, and each NC represents its nation's electrotechnical interests in the IEC. This includes manufacturers, providers, distributors and vendors, consumers and users, all levels of governmental agencies, professional societies and trade associations as well as standards developers from national standards bodies. National committees are constituted in different ways. Some NCs are public sector only, some are a combination of public and private sector, and some are private sector only. About 90% of those who prepare IEC standards work in industry. IEC Member countries include:\nAffiliates.\nIn 2001 and in response to calls from the WTO to open itself to more developing nations, the IEC launched the Affiliate Country Programme to encourage developing nations to become involved in the commission's work or to use its International Standards. Countries signing a pledge to participate in the work and to encourage the use of IEC Standards in national standards and regulations are granted access to a limited number of technical committee documents for the purposes of commenting. In addition, they can select a limited number of IEC Standards for their national standards' library. Countries participating in the Affiliate Country Programme are:\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "15145", "revid": "122189", "url": "https://en.wikipedia.org/wiki?curid=15145", "title": "ISO 9660", "text": "File system for CD-R and CD-ROM optical discs\nISO 9660 (also known as ECMA-119) is a file system for optical disc media. The file system is an international standard available from the International Organization for Standardization (ISO). Since the specification is publicly available, implementations have been written for many operating systems.\nISO 9660 traces its roots to the High Sierra Format, which arranged file information in a dense, sequential layout to minimize nonsequential access by using a hierarchical (eight levels of directories deep) tree file system arrangement, similar to Unix file systems and FAT. To facilitate cross platform compatibility, it defined a minimal set of common file attributes (directory or ordinary file and time of recording) and name attributes (name, extension, and version), and used a separate system use area where future optional extensions for each file may be specified. High Sierra was adopted in December 1986 (with changes) as an international standard by Ecma International as ECMA-119 and submitted for fast tracking to the ISO, where it was eventually accepted as ISO 9660:1988. Subsequent amendments to the standard were published in 2013, 2017, 2019, and 2020.\nThe first 16 sectors of the file system are empty and reserved for other uses. The rest begins with a \"volume descriptor set\" (a header block which describes the subsequent layout) and then the path tables, directories and files on the disc. An ISO 9660 compliant disc must contain at least one \"primary volume descriptor\" describing the file system and a \"volume descriptor set terminator\" which is a volume descriptor that marks the end of the descriptor set. The primary volume descriptor provides information about the volume, characteristics and metadata, including a root directory record that indicates in which sector the root directory is located. Other fields contain metadata such as the volume's name and creator, along with the size and number of logical blocks used by the file system. Path tables summarize the directory structure of the relevant directory hierarchy. For each directory in the image, the path table provides the directory identifier, the location of the extent in which the directory is recorded, the length of any extended attributes associated with the directory, and the index of its parent directory path table entry.\nThere are several extensions to ISO 9660 that relax some of its limitations. Notable examples include \"Rock Ridge\" (Unix-style permissions and longer names), \"Joliet\" (Unicode, allowing non-Latin scripts to be used), \"El Torito\" (enables CDs to be bootable) and the \"Apple ISO 9660 Extensions\" (file characteristics specific to the classic Mac OS and macOS, such as resource forks, file backup date and more).\nHistory.\nCompact discs were originally developed for recording musical data, but soon were used for storing additional digital data types because they were equally effective for archival mass data storage. Called CD-ROMs, the lowest level format for these types of compact discs was defined in the \"Yellow Book\" specification in 1983. However, this book did not define any format for organizing data on CD-ROMs into logical units such as files, which led to every CD-ROM maker creating its own format. In order to develop a CD-ROM file system standard (\"Z39.60\" - \"Volume and File Structure of CDROM for Information Interchange\"), the National Information Standards Organization (NISO) set up Standards Committee SC EE (Compact Disc Data Format) in July 1985. In September/ October 1985 several companies invited experts to participate in the development of a working paper for such a standard.\nIn November 1985, representatives of computer hardware manufacturers gathered at the High Sierra Hotel and Casino (currently called the Golden Nugget Lake Tahoe) in Stateline, Nevada. This group became known as the \"High Sierra Group\" (\"HSG\"). Present at the meeting were representatives from Apple Computer, AT&amp;T, Digital Equipment Corporation (DEC), Hitachi, LaserData, Microware, Microsoft, 3M, Philips, Reference Technology Inc., Sony Corporation, TMS Inc., VideoTools (later Meridian), Xebec, and Yelick. The meeting report evolved from the \"Yellow Book\" CD-ROM standard, which was so open ended it was leading to diversification and creation of many incompatible data storage methods. The \"High Sierra Group Proposal\" (\"HSGP\") was released in May 1986, defining a file system for CD-ROMs commonly known as the High Sierra Format.\nA draft version of this proposal was submitted to the European Computer Manufacturers Association (ECMA) for standardization. With some changes, this led to the issue of the initial edition of the ECMA-119 standard in December 1986. The ECMA submitted their standard to the International Standards Organization (ISO) for \"fast tracking\", where it was further refined into the ISO 9660 standard. For compatibility the second edition of ECMA-119 was revised to be equivalent to ISO 9660 in December 1987. \"ISO 9660:1988\" was published in 1988. The main changes from the High Sierra Format in the ECMA-119 and ISO 9660 standards were international extensions to allow the format to work better on non-US markets.\nIn order not to create incompatibilities, NISO suspended further work on Z39.60, which had been adopted by NISO members on 28 May 1987. It was withdrawn before final approval, in favour of ISO 9660.\nJIS X 0606:1998 was passed in Japan in 1998 with much-relaxed file name rules using a new \"enhanced volume descriptor\" data structure. The standard was submitted for ISO 9660:1999 and supposedly fast-tracked, but nothing came out of it. Nevertheless, several operating systems and disc authoring tools (such as Nero Burning ROM, mkisofs and ImgBurn) now support the addition, under such names as \"ISO 9660:1999\", \"ISO 9660 v2\", or \"ISO 9660 Level 4\". In 2013, the proposal was finally formalized in the form of ISO 9660/Amendment 1, intended to \"bring harmonization between ISO 9660 and widely used 'Joliet Specification'.\" In December 2017, a 3rd Edition of ECMA-119 was published that is technically identical with ISO 9660, Amendment 1.\nIn 2019, ECMA published a 4th version of ECMA-119, integrating the Joliet text as \"Annex C\".\nIn 2020, ISO published Amendment 2, which adds some minor clarifying matter, but does not add or correct any technical information of the standard.\nSpecifications.\nThe following is the rough overall structure of the ISO 9660 file system.\nMulti-byte values can be stored in three different formats: little-endian, big-endian, and in a concatenation of both types in what the specification calls \"both-byte\" order. Both-byte order is required in several fields in the volume descriptors and directory records, while path tables can be either little-endian or big-endian.\nTop level.\nThe \"system area\", the first 32,768 data bytes of the disc (16 sectors of 2,048 bytes each), is unused by ISO 9660 and therefore available for other uses. While it is suggested that they are reserved for use by bootable media, a CD-ROM may contain an alternative file system descriptor in this area, and it is often used by hybrid CDs to offer classic Mac OS-specific and macOS-specific content.\nVolume descriptor set.\nThe \"data area\" begins with the \"volume descriptor set\", a set of one or more \"volume descriptors\" terminated with a \"volume descriptor set terminator\". These collectively act as a header for the data area, describing its content (similar to the BIOS parameter block used by FAT, HPFS and NTFS formatted disks).\nEach volume descriptor is 2048 bytes in size, fitting perfectly into a single Mode 1 or Mode 2 Form 1 sector. They have the following structure:\nThe data field of a volume descriptor may be subdivided into several fields, with the exact content depending on the type. Redundant copies of each volume descriptor can also be included in case the first copy of the descriptor becomes corrupt.\nStandard volume descriptor types are the following:\nAn ISO 9660 compliant disc must contain at least one \"primary volume descriptor\" describing the file system and a \"volume descriptor set terminator\" for indicating the end of the descriptor sequence. The \"volume descriptor set terminator\" is simply a particular type of volume descriptor with the purpose of marking the end of this set of structures. The primary volume descriptor provides information about the volume, characteristics and metadata, including a root directory record that indicates in which sector the root directory is located. Other fields contain the description or name of the volume, and information about who created it and with which application. The size of the logical blocks which the file system uses to segment the volume is also stored in a field inside the primary volume descriptor, as well as the amount of space occupied by the volume (measured in number of logical blocks).\nIn addition to the primary volume descriptor(s), \"supplementary volume descriptors\" or \"enhanced volume descriptors\" may be present.\nPath tables.\nPath tables summarize the directory structure of the relevant directory hierarchy. For each directory in the image, the path table provides the directory identifier, the location of the extent in which the directory is recorded, the length of any extended attributes associated with the directory, and the index of its parent directory path table entry. The parent directory number is a 16-bit number, limiting its range from 1 to 65,535.\nDirectories and files.\nDirectory entries are stored following the location of the root directory entry, where evaluation of filenames is begun. Both directories and files are stored as extents, which are sequential series of sectors. Files and directories are differentiated only by a file attribute that indicates its nature (similar to Unix). The attributes of a file are stored in the directory entry that describes the file, and optionally in the extended attribute record. To locate a file, the directory names in the file's path can be checked sequentially, going to the location of each directory to obtain the location of the subsequent subdirectory. However, a file can also be located through the path table provided by the file system. This path table stores information about each directory, its parent, and its location on disc. Since the path table is stored in a contiguous region, it can be searched much faster than jumping to the particular locations of each directory in the file's path, thus reducing seek time.\nThe standard specifies three nested levels of interchange (paraphrased from section 10):\nAdditional restrictions in the body of the standard: The depth of the directory hierarchy must not exceed 8 (root directory being at level 1), and the path length of any file must not exceed 255. (section 6.8.2.1).\nThe standard also specifies the following name restrictions (sections 7.5 and 7.6):\nA CD-ROM producer may choose one of the lower Levels of Interchange specified in chapter 10 of the standard, and further restrict file name length from 30 characters to only 8+3 in file identifiers, and 8 in directory identifiers in order to promote interchangeability with implementations that do not implement the full standard.\nAll numbers in ISO 9660 file systems except the single byte value used for the GMT offset are unsigned numbers. As the length of a file's extent on disc is stored in a 32 bit value, it allows for a maximum length of just over 4.2\u00a0GB (more precisely, one byte less than 4\u00a0GiB). It is possible to circumvent this limitation by using the multi-extent (fragmentation) feature of ISO 9660 Level 3 to create ISO 9660 file systems and single files up to 8\u00a0TB. With this, files larger than 4\u00a0GiB can be split up into multiple extents (sequential series of sectors), each not exceeding the 4 GiB limit. For example, the free software such as InfraRecorder, ImgBurn and mkisofs as well as Roxio Toast are able to create ISO 9660 file systems that use multi-extent files to store files larger than 4 GiB on appropriate media such as recordable DVDs. Linux supports multiple extents.\nSince amendment 1 (or ECMA-119 3rd edition, or \"JIS X 0606:1998 / ISO 9660:1999\"), a much wider variety of file trees can be expressed by the EVD system. There is no longer any character limit (even 8-bit characters are allowed), nor any depth limit or path length limit. There still is a limit on name length, at 207. The character set is no longer enforced, so both sides of the disc interchange need to agree via a different channel.\nVolume size.\nAn ISO 9660 volume can be up to 8 tebibytes (nearly 8.8 terabytes) in size, owing to the 32-bit sector count for the volume size, and its allocation unit size which spans 2048 bytes, matching a logical sector on optical discs. The highest number representable in a 32-bit field is 232-1, limiting the volume size to (232-1)\u00d72048 bytes. \"Logical\" means it is the sector size exposed to the operating system, not necessarily the physical sector size on a disc. DVD and Blu-ray discs have maintained the logical sector size of the CD-ROM, 2048 bytes, to try to maintain reading compatibility with computers and software predating them.\nExtensions and improvements.\nThere are several extensions to ISO 9660 that relax some of its limitations. Notable examples include \"Rock Ridge\" (Unix-style permissions and longer names), \"Joliet\" (Unicode, allowing non-Latin scripts to be used), \"El Torito\" (enables CDs to be bootable) and the \"Apple ISO 9660 Extensions\" (file characteristics specific to the classic Mac OS and macOS, such as resource forks, file backup date and more).\nSUSP.\n\"System Use Sharing Protocol\" (SUSP, IEEE P1281) provides a generic way of including additional properties for any directory entry reachable from the primary volume descriptor (PVD). In an ISO 9660 volume, every directory entry has an optional \"system use area\" whose contents are undefined and left to be interpreted by the system. SUSP defines a method to subdivide that area into multiple system use fields, each identified by a two-character signature tag. The idea behind SUSP was that it would enable any number of independent extensions to ISO 9660 to be created and included on a volume without conflicting. It also allows for the inclusion of property data that would otherwise be too large to fit within the limits of the system use area.\nSUSP defines several common tags and system use fields:\nOther known SUSP fields include:\nThe Apple extensions do not technically follow the SUSP standard; however the basic structure of the AA and AB fields defined by Apple are forward compatible with SUSP; so that, with care, a volume can use both Apple extensions as well as RRIP extensions.\nRock Ridge.\nThe \"Rock Ridge Interchange Protocol\" (RRIP, IEEE P1282) is an extension which adds POSIX file system semantics. The availability of these extension properties allows for better integration with Unix and Unix-like operating systems. The standard takes its name from the fictional town \"Rock Ridge\" in Mel Brooks' film \"Blazing Saddles\". The RRIP extensions are, briefly:\nThe RRIP extensions are built upon SUSP, defining additional tags for support of POSIX semantics, along with the format and meaning of the corresponding system use fields:\n\"Amiga Rock Ridge\" is similar to RRIP, except it provides additional properties used by AmigaOS. It too is built on the SUSP standard by defining an \"AS\"-tagged system use field. Thus both Amiga Rock Ridge and the POSIX RRIP may be used simultaneously on the same volume. Some of the specific properties supported by this extension are the additional Amiga-bits for files. There is support for attribute \"P\" that stands for \"pure\" bit (indicating re-entrant command) and attribute \"S\" for script bit (indicating batch file). This includes the protection flags plus an optional comment field. These extensions were introduced by Angela Schmidt with the help of Andrew Young, the primary author of the Rock Ridge Interchange Protocol and System Use Sharing Protocol. The first publicly available software to master a CD-ROM with Amiga extensions was MakeCD, an Amiga software which Angela Schmidt developed together with Patrick Ohly.\nEl Torito.\n\"El Torito\" is an extension designed to allow booting a computer from a CD-ROM. It was announced in November 1994 and first issued in January 1995 as a joint proposal by IBM and BIOS manufacturer Phoenix Technologies. According to legend, the El Torito CD/DVD extension to ISO 9660 got its name because its design originated in an El Torito restaurant in Irvine, California (). The initial two authors were Curtis Stevens, of Phoenix Technologies, and Stan Merkin, of IBM.\nA 32-bit PC BIOS will search for boot code on an ISO 9660 CD-ROM. The standard allows for booting in two different modes. Either in hard disk emulation when the boot information can be accessed directly from the CD media, or in floppy emulation mode where the boot information is stored in an image file of a floppy disk, which is loaded from the CD and then behaves as a virtual floppy disk. This is useful for computers that were designed to boot only from a floppy drive. For modern computers the \"no emulation\" mode is generally the more reliable method. The BIOS will assign a BIOS drive number to the CD drive. The drive number (for INT 13H) assigned is any of 80hex (hard disk emulation), 00hex (floppy disk emulation) or an arbitrary number if the BIOS should not provide emulation. Emulation is useful for booting older operating systems from a CD, by making it appear to them as if they were booted from a hard or floppy disk.\nUEFI systems also accept El Torito records, as platform 0xEF. The record is expected to be a disk image containing a FAT filesystem, the filesystem being an EFI System Partition containing the usual directory. The image should be marked for \"no emulation\", though it does not actually work like the BIOS \"no emulation\" mode, in which the BIOS would load the image in memory and execute the code from there.\nEl Torito can also be used to produce CDs which can boot up Linux operating systems, by including the GRUB bootloader on the CD and following the Multiboot Specification. While the El Torito spec alludes to a \"Mac\" platform ID, PowerPC-based Apple Macintosh computers don't use it.\nJoliet.\n\"Joliet\" is an extension specified and endorsed by Microsoft and has been supported by all versions of its Windows operating system since Windows 95 and Windows NT 4.0. Its primary focus is the relaxation of the filename restrictions inherent with full ISO 9660 compliance. Joliet accomplishes this by supplying an additional set of filenames that are encoded in UCS-2BE (UTF-16BE in practice since Windows 2000). These filenames are stored in a special supplementary volume descriptor, that is safely ignored by ISO 9660-compliant software, thus preserving backward compatibility. The specification only allows filenames to be up to 64 Unicode characters in length. However, the documentation for mkisofs states filenames up to 103 characters in length do not appear to cause problems. Microsoft has documented it \"can use up to 110 characters.\" The difference lies in whether CDXA extension space is used.\nJoliet allows Unicode characters to be used for all text fields, which includes file names and the volume name. A \"Secondary\" volume descriptor with type 2 contains the same information as the Primary one (sector 16 offset 40 bytes), but in UCS-2BE in sector 17, offset 40 bytes. As a result of this, the volume name is limited to 16 characters.\nMany current PC operating systems are able to read Joliet-formatted media, thus allowing exchange of files between those operating systems even if non-Roman characters are involved (such as Arabic, Japanese or Cyrillic), which was formerly not possible with plain ISO 9660-formatted media. Operating systems which can read Joliet media include:\nRomeo.\n\"Romeo\" was developed by Adaptec and allows the use of long filenames up to 128 characters, written directly into the primary volume descriptor using the current code page. This format is built around the workings of Windows 9x and Windows NT \"CDFS\" drivers. When a Windows installation of a different language opens a \"Romeo\" disk, the lack of code page indication will cause non-ASCII characters in file names to become Mojibake. For example, \"\u00fc\" may become \"\u00b3\". A different OS may encounter a similar problem or refuse to recognize these noncompliant names outright.\nThe same code page problem technically exists in standard ISO 9660, which allows open interpretation of the supplemental and enhanced volume descriptors to any character encoding subject to agreement. However, the primary volume descriptor is guaranteed to be a small subset of ASCII.\nApple extensions.\nApple Computer authored a set of extensions that add ProDOS or HFS/HFS+ (the primary contemporary file systems for the classic Mac OS) properties to the filesystem. Some of the additional metadata properties include:\nIn order to allow non-Macintosh systems to access Macintosh files on CD-ROMs, Apple chose to use an extension of the standard ISO 9660 format. Most of the data, other than the Apple specific metadata, remains visible to operating systems that are able to read ISO 9660.\nOther extensions.\nFor operating systems which do not support any extensions, a name translation file codice_22 must be used. The codice_22 file is a plain ASCII text file. Each line contains three fields, separated by an arbitrary amount of whitespace:\nMost implementations that create TRANS.TBL files put a single space between the file type and ISO 9660 name and some arbitrary number of tabs between the ISO 9660 filename and the extended filename.\nNative support for using codice_22 still exists in many ISO 9660 implementations, particularly those related to Unix. However, it has long since been superseded by other extensions, and modern utilities that create ISO 9660 images either cannot create TRANS.TBL files at all, or no longer create them unless explicitly requested by the user. Since a TRANS.TBL file has no special identification other than its name, it can also be created separately and included in the directory before filesystem creation.\nThe ISO 13490 standard is an extension to the ISO 9660 format that adds support for multiple sessions on a disc. Since ISO 9660 is by design a read-only, pre-mastered file system, all the data has to be written in one go or \"session\" to the medium. Once written, there is no provision for altering the stored content. ISO 13490 was created to allow adding more files to a writeable disc such as CD-R in multiple sessions.\nThe ISO 13346/ECMA-167 standard was designed in conjunction to the ISO 13490 standard. This new format addresses most of the shortcomings of ISO 9660, and a subset of it evolved into the Universal Disk Format (UDF), which was adopted for DVDs. The volume descriptor table retains the ISO9660 layout, but the identifier has been updated.\nDisc images.\nOptical disc images are a common way to electronically transfer the contents of CD-ROMs. They often have the filename extension codice_25 (codice_26 is less common, but also in use) and are commonly referred to as \"ISOs\".\nPlatforms.\nMost operating systems support reading of ISO 9660 formatted discs, and most new versions support the extensions such as Rock Ridge and Joliet. Operating systems that do not support the extensions usually show the basic (non-extended) features of a plain ISO 9660 disc.\nOperating systems that support ISO 9660 and its extensions include the following:\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "15146", "revid": "50507318", "url": "https://en.wikipedia.org/wiki?curid=15146", "title": "Ice skating", "text": "Self-propulsion of a person over ice, wearing bladed skates\nIce skating is the self-propulsion and gliding of a person across a flat ice surface, using metal-bladed ice skates. People skate for various reasons, including recreation (fun), exercise, competitive sports, and commuting. Ice skating may be performed on naturally frozen bodies of water, such as ponds, lakes, canals, and rivers, and on human-made ice surfaces both indoors and outdoors.\nNatural ice surfaces used by skaters can accommodate a variety of winter sports which generally require an enclosed area, but are also used by skaters who need ice tracks and trails for distance skating and speed skating. Man-made ice surfaces include ice rinks, ice hockey rinks, bandy fields, ice tracks required for the sport of ice cross downhill, and arenas.\nVarious formal sports involving ice skating have emerged since the 19th century. Ice hockey, bandy, rinkball, and ringette are team sports played with, respectively, a flat sliding puck, a ball, and a rubber ring. Synchronized skating is a unique artistic team sport derived from figure skating. Figure skating, ice cross downhill, speed skating, and barrel jumping (a discipline of speed skating) are among the sporting disciplines for individuals.\nHistory.\nEarly history of ice skating.\nResearch suggests that the earliest ice skating happened in southern Finland more than 4,000 years ago. This was done to save energy during winter journeys. True skating emerged when a steel blade with sharpened edges was used. Skates now cut into the ice instead of gliding on top of it. The Dutch added edges to ice skates in the 13th or 14th century. These ice skates were made of steel, with sharpened edges on the bottom to aid movement.\nThe fundamental construction of modern ice skates has stayed largely the same since then, although differing greatly in the details, particularly in the method of binding and the shape and construction of the steel blades. In the Netherlands, ice skating was considered proper for all classes of people, as shown in many pictures from Dutch Golden Age painters.\nIce skating was also practiced in China during the Song dynasty, and became popular among the ruling family of the Qing dynasty. Ancient ice skates, made of animal bones, were found at the bronze age Gaotai Ruins in north west China, and are estimated to be likely 3,500 years old. Archeologists say these ancient skates are \"clear evidence for communication between China and Europe\" in the Bronze Age era, as they are very similar to bone skates unearthed in Europe.\nRising popularity and first clubs.\nIn England \"the London boys\" had improvised butcher's bones as skates since the 12th century. Skating on metal skates seems to have arrived in England at the same time as the garden canal, with the English Restoration in 1660, after the king and court returned from an exile largely spent in the Netherlands. In London the ornamental \"canal\" in St James's Park was the main centre until the 19th century. Both Samuel Pepys and John Evelyn, the two leading diarists of the day, saw it on the \"new canal\" there on 1 December 1662, the first time Pepys had ever seen it (\"a very pretty art\"). Then it was \"performed before their Majesties and others, by diverse gentlemen and others, with scheets after the manner of the Hollanders\". Two weeks later, on 15 December 1662, Pepys accompanied the Duke of York, later King James II, on a skating outing: \"To the Duke, and followed him in the Park, when, though the ice was broken, he would go slide upon his skates, which I did not like; but he slides very well.\" In 1711 Jonathan Swift still thinks the sport might be unfamiliar to his \"Stella\", writing to her: \"Delicate walking weather; and the Canal and Rosamund's Pond full of the rabble and with skates, \"if you know what that is\".\"\nThe first organised skating club was the Edinburgh Skating Club, formed in the 1740s; some claim the club was established as early as 1642.An early contemporary reference to the club appeared in the second edition (1783) of the Encyclop\u00e6dia Britannica:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;From this description and others, it is apparent that the form of skating practiced by club members was indeed an early form of figure skating rather than speed skating. For admission to the club, candidates had to pass a skating test where they performed a complete circle on either foot (e.g., a figure eight), and then jumped over first one hat, then two and three, placed over each other on the ice.\nOn the Continent, participation in ice skating was limited to members of the upper classes. Emperor Rudolf II of the Holy Roman Empire enjoyed ice skating so much, he had a large ice carnival constructed in his court in order to popularise the sport. King Louis XVI of France brought ice skating to Paris during his reign. Madame de Pompadour, Napoleon I, Napoleon III, and the House of Stuart were, among others, royal and upper-class fans of ice skating.\nThe next skating club to be established was in London and was not founded until 1830. Members wore a silver skate hanging from their buttonhole and met on The Serpentine, Hyde Park on 27 December 1830.\nBy the mid-19th century, ice skating was a popular pastime among the British upper and middle classes. Queen Victoria became acquainted with her future husband, Prince Albert, through a series of ice skating trips. Albert continued to skate after their marriage and on falling through the ice was once rescued by Victoria and a lady in waiting from a stretch of water in the grounds of Buckingham Palace.\nEarly attempts at the construction of artificial ice rinks were made during the \"rink mania\" of 1841\u201344. As the technology for the maintenance of natural ice did not exist, these early rinks used a substitute consisting of a mixture of hog's lard and various salts. An item in the 8 May 1844 issue of Littell's 'Living Age' headed the 'Glaciarium' reported that \"This establishment, which has been removed to Grafton Street East' Tottenham Court Road, was opened on Monday afternoon. The area of artificial ice is extremely convenient for such as may be desirous of engaging in the graceful and manly pastime of skating.\"\nEmergence as a sport.\nSkating became popular as a recreation, a means of transport and spectator sport in The Fens in England for people from all walks of life. Racing was the preserve of workers, most of them agricultural labourers. It is not known when the first skating matches were held, but by the early nineteenth century racing was well established and the results of matches were reported in the press. Skating as a sport developed on the lakes of Scotland and the canals of the Netherlands. In the 13th and 14th centuries wood was substituted for bone in skate blades, and in 1572 the first iron skates were manufactured. When the waters froze, skating matches were held in towns and villages all over the Fens. In these local matches men (or sometimes women or children) would compete for prizes of money, clothing, or food.\nThe winners of local matches were invited to take part in the grand or championship matches, in which skaters from across the Fens would compete for cash prizes in front of crowds of thousands. The championship matches took the form of a Welsh main or \"last man standing\" contest (single-elimination tournament). The competitors, 16 or sometimes 32, were paired off in heats and the winner of each heat went through to the next round. A course of 660 yards was measured out on the ice, and a barrel with a flag on it placed at either end. For a one-and-a-half-mile race the skaters completed two rounds of the course, with three barrel turns.\nIn the Fens, skates were called pattens, fen runners, or Whittlesey runners. The footstock was made of beechwood. A screw at the back was screwed into the heel of the boot, and three small spikes at the front kept the skate steady. There were holes in the footstock for leather straps to fasten it to the foot. The metal blades were slightly higher at the back than the front. In the 1890s, fen skaters started to race in Norwegian style skates.\nOn Saturday 1 February 1879, a number of professional ice skaters from Cambridgeshire and Huntingdonshire met in the Guildhall, Cambridge, to set up the National Skating Association, the first national ice skating body in the world. The founding committee consisted of several landowners, a vicar, a fellow of Trinity College, a magistrate, two members of parliament, the mayor of Cambridge, the Lord Lieutenant of Cambridge, journalist James Drake Digby, the president of Cambridge University Skating Club, and Neville Goodman, a graduate of Peterhouse, Cambridge (and son of Potto Brown's milling partner, Joseph Goodman). The newly formed Association held their first one-and-a-half-mile British professional championship at Thorney in December 1879.\nFigure skating.\nThe first instructional book concerning ice skating was published in London in 1772. The book titled \"The Art of Figure Skating\", written by a British artillery lieutenant, Robert Jones, describes basic figure skating forms such as circles and figure eights. The book was written solely for men, as women did not normally ice skate in the late 18th century. It was with the publication of this manual that ice skating split into its two main disciplines, speed skating and figure skating.\nThe founder of modern figure skating as it is known today was Jackson Haines, an American. He was the first skater to incorporate ballet and dance movements into his skating, as opposed to focusing on tracing patterns on the ice. Haines also invented the sit spin and developed a shorter, curved blade for figure skating that allowed for easier turns. He was also the first to wear blades that were permanently attached to the boot.\nThe International Skating Union was founded in 1892 as the first international ice skating organisation in Scheveningen, in the Netherlands. The Union created the first codified set of figure skating rules and governed international competition in speed and figure skating. The first Championship, known as the Championship of the Internationale Eislauf-Vereinigung, was held in Saint Petersburg in 1896. The event had four competitors and was won by Gilbert Fuchs.\nPhysical mechanics of skating.\nA skate can glide over ice because there is a layer of ice molecules on the surface that are not as tightly bound as the molecules of the mass of ice beneath. These molecules are in a semiliquid state, providing lubrication. The molecules in this \"quasi-fluid\" or \"water-like\" layer are less mobile than liquid water, but are much more mobile than the molecules deeper in the ice. At about the slippery layer is one molecule thick; as the temperature increases the slippery layer becomes thicker.\nIt had long been believed that ice is slippery because the pressure of an object in contact with it causes a thin layer to melt. The hypothesis was that the blade of an ice skate, exerting pressure on the ice, melts a thin layer, providing lubrication between the ice and the blade. This explanation, called \"pressure melting\", originated in the 19th century. (See Regelation.) Pressure melting could not account for skating on ice temperatures lower than \u22123.5\u00a0\u00b0C, whereas skaters often skate on lower-temperature ice.\nIn the 20th century, an alternative explanation, called \"friction melting\", proposed by Lozowski, Szilder, Le Berre, Pomeau, and others showed that because of the viscous frictional heating, a macroscopic layer of melt ice is in-between the ice and the skate. With this they fully explained the low friction with nothing else but macroscopic physics, whereby the frictional heat generated between skate and ice melts a layer of ice. This is a self-stabilizing mechanism of skating. If by fluctuation the friction gets high, the layer grows in thickness and lowers the friction, and if it gets low, the layer decreases in thickness and increases the friction. The friction generated in the sheared layer of water between skate and ice grows as \"\u221aV\" with \"V\" the velocity of the skater, such that for low velocities the friction is also low.\nWhatever the origin of the water layer, skating is more destructive than simply gliding. A skater leaves a visible trail behind on virgin ice and skating rinks have to be regularly resurfaced to improve the skating conditions. It means that the deformation caused by the skate is plastic rather than elastic. The skate ploughs through the ice in particular due to the sharp edges. Van Leeuwen proposed that another component has to be added to the friction: the \"ploughing friction\". The calculated frictions are of the same order as the measured frictions in real skating in a rink. The ploughing friction decreases with the velocity \"V\", since the pressure in the water layer increases with V and lifts the skate (aquaplaning). As a result the sum of the water-layer friction and the ploughing friction only increases slightly with \"V\", making skating at high speeds (&gt;90\u00a0km/h) possible.\nInherent safety risks.\nA person's ability to ice skate depends on the roughness of the ice, the design of the ice skate, and the skill and experience of the skater. While serious injury is rare, a number of short track speed skaters have been paralysed after a heavy fall when they collided with the boarding. A fall can be fatal if a helmet is not worn to protect against severe head injury. Accidents are rare but there is a risk of injury from collisions, particularly during hockey games or in pair skating.\nA significant danger when skating outdoors on a frozen body of water is falling through the ice into the freezing water underneath. Death can result from shock, hypothermia, or drowning. It is often difficult or impossible for the skater to climb out of the water, due to the weight of their ice skates and thick winter clothing, and the ice repeatedly breaking as they struggle to get back onto the surface. Also, if the skater becomes disoriented under the water, they might not be able to find the hole in the ice through which they have fallen. Although this can prove fatal, it is also possible for the rapid cooling to produce a condition in which a person can be revived up to hours after falling into the water. Experts have warned not to ice skate alone, and also warned parents not to leave children unattended on a frozen body of water.\nCommunal activities on ice.\nA number of recreational and sporting activities take place on ice:\nNo skating.\nThe following sports and games are also played on ice, but players are not required to wear ice skates.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "15147", "revid": "17438340", "url": "https://en.wikipedia.org/wiki?curid=15147", "title": "International Olympic Committee", "text": "Governing body of Olympic sports\n \nInternational Olympic Committee (IOC) is the international, non-governmental, sports governing body of the modern Olympic Games. Founded in 1894 by Pierre de Coubertin and Demetrios Vikelas, it is based in Lausanne, Switzerland. The IOC is the authority responsible for organising the Summer, Winter, and Youth Olympics. The IOC is also the governing body of the National Olympic Committees (NOCs) and the worldwide Olympic Movement, which includes all entities and individuals involved in the Olympic Games. As of 2020[ [update]], 206 NOCs officially were recognised by the IOC. Since 2025, the IOC president has been Kirsty Coventry. \n&lt;templatestyles src=\"Template:TOC limit/styles.css\" /&gt;\nMission.\nIts stated mission is to promote Olympism throughout the world and to lead the Olympic Movement:\nAs defined by the IOC, Sport pertains to a form of competitive and organised physical activity or game; that aims to use or improve physical fitness and skills while providing passion, cooperation, and entertainment to participants and spectators alike.\nIOC member oath.\nAll IOC members must swear to the following:\n\"Honoured to be chosen as a member of the International Olympic Committee,\nI fully accept all the responsibilities that this office brings:\nI promise to serve the Olympic Movement to the best of my ability.\nI will respect the Olympic Charter and accept the decisions of the IOC.\nI will always act independently of commercial and political interests as well as\nof any racial or religious consideration.\nI will fully comply with the IOC Code of Ethics.\nI promise to fight against all forms of discrimination and dedicate myself\nin all circumstances to promote the interests of the International Olympic\nCommittee and Olympic Movement.\"\nHistory.\nThe IOC was created by Pierre de Coubertin, on 23 June 1894 with Demetrios Vikelas as its first president. The IOC is one of the earliest and is still one of the most powerful international NGOs. As of February 2022, its membership consists of 105 active members and 45 honorary members. The IOC is the supreme authority of the worldwide modern Olympic Movement.\nThe IOC organises the modern Olympic Games and Youth Olympic Games (YOG), held in summer and winter every four years. The first Summer Olympics was held in Athens, Greece, in 1896; the first Winter Olympics was in Chamonix, France, in 1924. The first Summer YOG was in Singapore in 2010, and the first Winter YOG was in Innsbruck, Austria in 2012.\nUntil 1992, both the Summer and Winter Olympics were held in the same year. After that year, however, the IOC shifted the Winter Olympics to the even years between Summer Games to help space the planning of the two events from one another, and to improve the financial balance of the IOC, which receives a proportionally greater income in Olympic years.\nSince 1995, the IOC has worked to address environmental health concerns resulting from hosting the games. In 1995, IOC President Juan Antonio Samaranch stated, \"the International Olympic Committee is resolved to ensure that the environment becomes the third dimension of the organization of the Olympic Games, the first and second being sport and culture.\" Acting on this statement, in 1996 the IOC added the \"environment\" as a third pillar to its vision for the Olympic Games.\nIn 2000, the \"Green Olympics\" effort was developed by the Beijing Organizing Committee for the Beijing Olympic Games. The Beijing 2008 Summer Olympics executed over 160 projects addressing the goals of improved air quality and water quality, sustainable energy, improved waste management, and environmental education. These projects included industrial plant relocation or closure, furnace replacement, introduction of new emission standards, and more strict traffic control.\nIn 2009, the UN General Assembly granted the IOC Permanent Observer status. The decision enables the IOC to be directly involved in the UN Agenda and to attend UN General Assembly meetings where it can take the floor. In 1993, the General Assembly approved a Resolution to further solidify IOC\u2013UN cooperation by reviving the Olympic Truce.\nThe IOC received approval in November 2015 to construct a new headquarters in Vidy, Lausanne. The cost of the project was estimated to stand at $156m. The IOC announced on 11 February 2019 that the \"Olympic House\" would be inaugurated on 23 June 2019 to coincide with its 125th anniversary. The Olympic Museum remains in Ouchy, Lausanne.\nSince 2002, the IOC has been involved in several high-profile controversies including taking gifts, its DMCA take down request of the 2008 Tibetan protest videos, Russian doping scandals, and its support of the Beijing 2022 Winter Olympics despite China's human rights violations documented in the Xinjiang Papers.\nDetailed frameworks for environmental sustainability were prepared for the 2018 Winter Olympics and 2020 Summer Olympics in PyeongChang, South Korea, and Tokyo, Japan, respectively.\nIn September 2024, the IOC revealed its list of candidates for the presidency, featuring Sebastian Coe, David Lappartient, Kirsty Coventry, and Juan Antonio Samaranch Salisachs among the seven contenders. The other candidates included Prince Faisal bin Hussein and the Presidents of the International Ski and Snowboard Federation and the International Gymnastics Federation, Johan Eliasch and Morinari Watanabe.\nIn February 2025, the IOC announced the inaugural Olympic Esports Games would take place in 2027 in Riyadh, the capital city of Saudi Arabia. The IOC will collaborate with the Esports World Cup Foundation (EWCF) to produce the event, which President Thomas Bach called \"historic\".\nIn March 2025, Kirsty Coventry became the first woman and the first African to be elected as President of the IOC. Coventry's vision for the Olympics emphasises making the Games accessible to everyone again, no matter where they were born, while aiming to leverage sports as a global unifier. In parallel, the IOC is focused on strengthening its collaboration with BRICS nations, fostering a spirit of unity and cooperation through sports, and encouraging the idea of the Olympics as a truly global event. \nOrganisation.\nIt is an association under the Swiss Civil Code (articles 60\u201379).\nIOC Session.\nThe IOC Session is the general meeting of the members of the IOC, held once a year in which each member has one vote. It is the IOC's supreme organ and its decisions are final.\nExtraordinary Sessions may be convened by the President or upon the written request of at least one third of the members.\nAmong others, the powers of the Session are:\nIOC members.\nThe number of all serving IOC members may not exceed 115. When named they became IOC members in their respective countries rather than representatives of their respective countries to the IOC.\nCategories of the IOC members include:\nCessation of membership.\nMembership ends under the following circumstances:\nSports federations recognised by IOC.\nIOC recognises 82 international sports federations (IFs):\nHonours.\nIOC awards gold, silver, and bronze medals for the top three competitors in each sporting event.\nOther honours:\nOlympic marketing.\nDuring the first half of the 20th century the IOC ran on a small budget. As IOC president from 1952 to 1972, Avery Brundage rejected all attempts to link the Olympics with commercial interests. Brundage believed that corporate interests would unduly impact the IOC's decision-making. Brundage's resistance to this revenue stream left IOC organising committees to negotiate their own sponsorship contracts and use the Olympic symbols.\nWhen Brundage retired the IOC had US$2\u00a0million in assets; eight years later coffers had swollen, to US$45\u00a0million. This was primarily due to a shift in ideology toward expansion of the Games through corporate sponsorship and the sale of television rights. When Juan Antonio Samaranch was elected IOC president in 1980 his desire was to make the IOC financially independent. Samaranch appointed Canadian IOC member Richard Pound to lead the initiative as Chairman of the \"New Sources of Finance Commission\".\nIn 1982 the IOC drafted International Sport and Leisure, a Swiss sports marketing company, to develop a global marketing programme for the Olympic Movement. ISL developed the programme, but was replaced by Meridian Management, a company partly owned by the IOC in the early 1990s. In 1989, a staff member at ISL Marketing, Michael Payne, moved to the IOC and became the organisation's first marketing director. ISL and then Meridian continued in the established role as the IOC's sales and marketing agents until 2002. In collaboration with ISL Marketing and Meridian Management, Payne made major contributions to the creation of a multibillion-dollar sponsorship marketing programme for the organisation which, along with improvements in TV marketing and improved financial management, helped to restore the IOC's financial viability.\nRevenue.\nThe Olympic Movement generates revenue through five major programmes.\nThe OCOGs have responsibility for domestic sponsorship, ticketing and licensing programmes, under the direction of the IOC. The Olympic Movement generated a total of more than US$4\u00a0billion (\u20ac2.5\u00a0billion) in revenue during the Olympic quadrennium from 2001 to 2004.\nThe IOC distributes some of its revenue to organisations throughout the Olympic Movement to support the staging of the Olympic Games and to promote worldwide sport development. The IOC retains approximately 10% of the Olympic marketing revenue for operational and administrative costs. For the 2013\u20132016 period, the IOC had revenues of about US$5.0 billion, of which 73% were from broadcasting rights and 18% were from Olympic Partners. The Rio 2016 organising committee received US$1.5 billion and the Sochi 2014 organising committee received US$833 million. National Olympic committees and international federations received US$739 million each.\nIn July 2000, when the \"Los Angeles Times\" reported on how the IOC redistributes profits from sponsorships and broadcasting rights, historian Bob Barney stated that he had \"yet to see matters of corruption in the IOC\", but noted there were \"matters of unaccountability\". He later noted that when the spotlight is on the athletes, it has \"the power to eclipse impressions of scandal or corruption\", with respect to the Olympic bid process.\nOrganizing Committees for the Olympic Games.\nThe IOC provides TOP programme contributions and broadcast revenue to the OCOGs to support the staging of the Olympic Games:\nNational Olympic Committees.\nNOCs receive financial support for training and developing their Olympic teams, Olympic athletes, and Olympic hopefuls. The IOC distributes TOP programme revenue to each NOC. The IOC also contributes Olympic broadcast revenue to Olympic Solidarity, an IOC organisation that provides financial support to NOCs with the greatest need. The continued success of the TOP programme and Olympic broadcast agreements has enabled the IOC to provide increased support for the NOCs with each Olympic quadrennium. The IOC provided approximately US$318.5\u00a0million to NOCs for the 2001\u20132004 quadrennium.\nInternational Olympic Sports Federations.\nThe IOC is the largest single revenue source for the majority of IOSFs, with contributions that assist them in developing their respective sports. The IOC provides financial support to the 28 IOSFs of Olympic summer sports and the seven IOSFs of Olympic winter sports. The continually increasing value of Olympic broadcasts has enabled the IOC to substantially increase financial support to IOSFs with each successive Games. The seven winter sports IFs shared US$85.8\u00a0million, \u20ac75 million in Salt Lake 2002 broadcast revenue.\nOther organisations.\nThe IOC contributes Olympic marketing revenue to the programmes of various recognised international sports organisations, including the International Paralympic Committee (IPC), and the World Anti-Doping Agency (WADA).\nEnvironmental concerns.\nThe IOC requires cities bidding to host the Olympics to provide a comprehensive strategy to protect the environment in preparation for hosting, and following the conclusion of the Games.\nIOC approaches.\nThe IOC has four major approaches to addressing environmental health concerns.\nVenue construction.\nEffects on air.\nHost cities have concerns about traffic congestion and air pollution, both of which can compromise air quality during and after venue construction. Various air quality improvement measures are undertaken before and after each event. Traffic control is the primary method to reduce concentrations of air pollutants, including barring heavy vehicles.\nBeijing Olympics.\nResearch at the 2008 Summer Olympics identified particulate matter \u2013 measured in terms of PM10 (the amount of aerodynamic diameter of particle \u2264 10 \u03bcm in a given amount of air) \u2013 as a top priority. Particulate matter, along with other airborne pollutants, cause both serious health problems, such as asthma, and damage urban ecosystems. Black carbon is released into the air from incomplete combustion of carbonaceous fluids, contributing to climate change and injuring human health. Secondary pollutants such as CO, NOx, SO2, benzene, toluene, ethylbenzene, and xylenes (BTEX) are also released during construction.\nFor the Beijing Olympics, vehicles not meeting the Euro 1 emission standards were banned, and the odd-even rule was implemented in the Beijing administrative area. Air quality improvement measures implemented by the Beijing government included replacing coal with natural gas, suspending construction, imposing strict dust control on construction sites, closing or relocating the polluting industrial plants, building long subway lines, using cleaner fluid in power plants, and reducing the activity by some of the polluting factories. There, levels of primary and secondary pollutants were reduced, and good air quality was recorded during the Beijing Olympics on most days. Beijing also sprayed silver iodide in the atmosphere to induce rain to remove existing pollutants from the air.\nEffects on soil.\nSoil contamination can occur during construction. The Sydney Olympic Games of 2000 resulted in improving a highly contaminated area known as Homebush Bay. A pre-Games study reported soil metal concentrations high enough to potentially contaminate groundwater. A remediation strategy was developed. Contaminated soil was consolidated into four containment areas within the site, which left the remaining areas available for recreational use. The site contained waste materials that then no longer posed a threat to surrounding aquifers. In the 2006 Games in Torino, Italy, soil impacts were observed. Before the Games, researchers studied four areas that the Games would likely affect: a floodplain, a highway, the motorway connecting the city to Lyon, France, and a landfill. They analysed the chemicals in these areas before and after the Games. Their findings revealed an increase in the number of metals in the topsoil post-Games, and indicated that soil was capable of buffering the effects of many but not all heavy metals. Mercury, lead, and arsenic may have been transferred into the food chain.\nOne promise made to Londoners for the 2012 Olympic Games was that the Olympic Park would be a \"blueprint for sustainable living.\" However, garden allotments were temporarily relocated due to the building of the Olympic stadium. The allotments were eventually returned. However, the soil quality was damaged. Further, allotment residents were exposed to radioactive waste for five months prior to moving, during the excavation of the site for the Games. Other local residents, construction workers, and onsite archaeologists faced similar exposures and risks.\nEffects on water.\nThe Olympic Games can affect water quality in several ways, including runoff and the transfer of polluting substances from the air to water sources through rainfall. Harmful particulates come from natural substances (such as plant matter crushed by higher volumes of pedestrian and vehicle traffic) and man-made substances (such as exhaust from vehicles or industry). Contaminants from these two categories elevate amounts of toxins in street dust. Street dust reaches water sources through runoff, facilitating the transfer of toxins to environments and communities that rely on these water sources.\nIn 2013, researchers in Beijing found a significant relationship between the amount of PM2.5 concentrations in the air and in rainfall. Studies showed that rainfall had transferred a large portion of these pollutants from the air to water sources. Notably, this cleared the air of such particulates, substantially improving air quality at the venues.\nReception and incidences.\nAmateurism and professionalism.\nDe Coubertin was influenced by the aristocratic ethos exemplified by English public schools. The public schools subscribed to the belief that sport formed an important part of education but that practicing or training was considered cheating. As class structure evolved through the 20th century, the definition of the amateur athlete as an aristocratic gentleman became outdated. The advent of the state-sponsored \"full-time amateur athlete\" of Eastern Bloc countries further eroded the notion of the pure amateur, as it put Western, self-financed amateurs at a disadvantage. The Soviet Union entered teams of athletes who were all nominally students, soldiers, or working in a profession, but many of whom were paid by the state to train on a full-time basis. Nevertheless, the IOC held to the traditional rules regarding amateurism.\nNear the end of the 1960s, the Canadian Amateur Hockey Association (CAHA) felt their amateur players could no longer be competitive against the Soviet full-time athletes and other constantly improving European teams. They pushed for the ability to use players from professional leagues, but met opposition from the IIHF and IOC. At the IIHF Congress in 1969, the IIHF decided to allow Canada to use nine non-NHL professional hockey players at the 1970 World Championships in Montreal and Winnipeg, Manitoba, Canada. The decision was reversed in January 1970 after Brundage declared that the change would put ice hockey's status as an Olympic sport in jeopardy. In response, Canada withdrew from international ice hockey competition and officials stated that they would not return until \"open competition\" was instituted.\nBeginning in the 1970s, amateurism was gradually phased out of the Olympic Charter. After the 1988 Games, the IOC decided to make all professional athletes eligible for the Olympics, subject to the approval of the IFOSs.\nBid controversies.\n1976 Winter Olympics.\nThe Games were originally awarded to Denver on 12 May 1970, but a steep rise in costs led to Colorado voters' rejection on 7 November 1972, by 60% of the vote, of a $5\u00a0million bond issue to finance the Games with public funds.\nDenver officially withdrew on 15 November: the IOC then offered the Games to Whistler, British Columbia, Canada, but they too declined due to a change of government following elections.\nSalt Lake City, Utah, a 1972 Winter Olympics final candidate (who eventually hosted the 2002 Winter Olympics) offered itself as a potential host after Denver's withdrawal, but the IOC declined Salt Lake City's offer. On 5 February 1973, the IOC invited Innsbruck, the city that had hosted the Games twelve years earlier.\n1998 Winter Olympics.\nEight years after the 1998 Winter Olympics, a report ordered by the Nagano region's governor said the Japanese city provided millions of dollars in an \"illegitimate and excessive level of hospitality\" to IOC members, including US$4.4\u00a0million spent on entertainment. Earlier reports put the figure at approximately US$14 million. The precise figures are unknown: after the IOC asked that the entertainment expenditures not be made public Nagano destroyed its financial records.\n2002 Winter Olympics.\nA scandal broke on 10 December 1998, when Swiss IOC member Marc Hodler, head of the coordination committee overseeing the organisation of the 2002 Games, announced that several members of the IOC had received gifts from members of the Salt Lake City 2002 bid Committee in exchange for votes. Soon four independent investigations were underway: by the IOC, the United States Olympic Committee (USOC), the SLOC, and the United States Department of Justice. Before any of the investigations could get under way, SLOC co-heads Tom Welch and David Johnson both resigned their posts. Many others soon followed. The Department of Justice filed fifteen counts of bribery and fraud against the pair.\nAs a result of the investigation, ten IOC members were expelled and another ten were sanctioned. Stricter rules were adopted for future bids, and caps were put into place as to how much IOC members could accept from bid cities. Additionally, new term and age limits were put into place for IOC membership, an Athlete's Commission was created and fifteen former Olympic athletes gained provisional membership status.\n2008 Summer Olympics.\nIn 2000, international human rights groups attempted to pressure the IOC to reject Beijing's bid to protest human rights in the People's Republic of China. One Chinese dissident was sentenced to two years in prison during an IOC tour. After the city won the 2008 Summer Olympic Games, Amnesty International and others expressed concerns regarding the human rights situation. The second principle in the Fundamental Principles of Olympism, Olympic Charter states that \"The goal of Olympism is to place sport at the service of the harmonious development of man, with a view to promoting a peaceful society concerned with the preservation of human dignity.\" Amnesty International considered PRC policies and practices as violating that principle.\nSome days before the Opening Ceremonies, in August 2008, the IOC issued DMCA take down notices on Tibetan Protests videos on YouTube. YouTube and the Electronic Frontier Foundation (EFF) pushed back against the IOC, which then withdrew their complaint.\n2016 and 2020 Summer Olympics.\nOn 1 March 2016, Owen Gibson of \"The Guardian\" reported that French financial prosecutors investigating corruption in world athletics had expanded their remit to include the bidding and voting processes for the 2016 Summer Olympics and 2020 Summer Olympics. The story followed an earlier report in January by Gibson, who revealed that Papa Massata Diack, the son of then-IAAF president Lamine Diack, appeared to arrange for \"parcels\" to be delivered to six IOC members in 2008 when Qatar was bidding for the 2016 Summer Olympic Games, though it failed to make it beyond the shortlist. Weeks later, Qatari authorities denied the allegations. Gibson then reported that a \u20ac1.3m (\u00a31m, $1.5m) payment from the Tokyo Olympic Committee team to an account linked to Papa Diack was made during Japan's successful race to host the 2020 Summer Games. The following day, French prosecutors confirmed they were investigating allegations of \"corruption and money laundering\" of more than $2m in suspicious payments made by the Tokyo 2020 Olympic bid committee to a secret bank account linked to Diack. Tsunekazu Takeda of the Tokyo 2020 bid committee responded on 17 May 2016, denying allegations of wrongdoing, and refused to reveal transfer details. The controversy was reignited on 11 January 2019 after it emerged Takeda had been indicted on corruption charges in France over his role in the bid process.\n2022 Winter Olympics.\nIn 2014, at the final stages of the bid process for 2022, Oslo, seen as the favourite, surprised with a withdrawal. Following a string of local controversies over the masterplan, local officials were outraged by IOC demands on athletes and the Olympic family. In addition, allegations about lavish treatment of stakeholders, including separate lanes to \"be created on all roads where IOC members will travel, which are not to be used by regular people or public transportation\", exclusive cars and drivers for IOC members. The differential treatment irritated Norwegians. The IOC demanded \"control over all advertising space throughout Oslo and the subsites during the Games, to be used exclusively by official sponsors.\"\nHuman rights groups and governments criticised the committee for allowing Beijing to bid for the 2022 Winter Olympics. Some weeks before the Opening Ceremonies, the Xinjiang Papers were released, documenting abuses by the Chinese government against the Uyghur population in Xinjiang, documenting what many governments described as genocide.\nMany government officials, notably those in the United States and the Great Britain, called for a boycott of the 2022 Winter Games. The IOC responded to concerns by saying that the Olympic Games must not be politicised. Some nations diplomatically boycotted games, which prohibited a diplomatic delegation from representing a nation at the games, rather than a full boycott that would have barred athletes from competing. In September 2021, the IOC suspended the Olympic Committee of the Democratic People's Republic of Korea, after they boycotted the 2020 Summer Olympics claiming \"COVID-19 Concerns\".\nOn 8 September 2021, after the IOC suspended the North Korean NOC for not being present at the 2020 Summer Olympics, there was speculation about whether the IOC was also intending to send a message to nations considering a boycott of the games that they could be banned from participation in future Olympic Games if they chose to boycott this edition. On 14 October 2021, vice-president of the IOC, John Coates, announced that the IOC had no plans to challenge the Chinese government on humanitarian issues, stating that the issues were \"not within the IOC's remit\".\nSex verification controversies.\nThe IOC uses sex verification to ensure participants compete only in events matching their sex. Verifying the sex of Olympic participants dates back to ancient Greece, when Kallipateira attempted to break Greek law by dressing as a man to enter the arena as a trainer. After she was discovered, a policy was erected wherein trainers, just as athletes, were made to appear naked in order to better assure all were male.\nIn more recent history, sex verification has taken many forms and been subject to dispute. Before sex testing, Olympic officials relied on \"nude parades\" and doctor's notes. Successful women athletes perceived to be masculine were most likely to be inspected. In 1966, IOC implemented a compulsory sex verification process that took effect at the 1968 Winter Olympics where a lottery system was used to determine who would be inspected with a Barr body test. The scientific community found fault with this policy. The use of the Barr body test was evaluated by fifteen geneticists who unanimously agreed it was scientifically invalid. By the 1970s this method was replaced with PCR testing, as well as evaluating factors such as brain anatomy and behaviour. Following continued backlash against mandatory sex testing, the IOC's Athletes' Commission's opposition ended of the practice in 1999.\nAlthough sex testing was no longer mandated, women who did not present as feminine continued to be inspected based on suspicion. This started at 2000 Summer Olympics and remained in use until the 2010 Winter Olympics. By 2011 the IOC created a Hyperandrogenism Regulation, which aimed to standardise natural testosterone levels in women athletes. This transition in sex testing was to assure fairness within female events. This was due to the belief that higher testosterone levels increased athletic ability and gave unfair advantages to intersex and transgender competitors. Any female athlete flagged for suspicion and whose testosterone surpassed regulation levels was prohibited from competing until medical treatment brought their hormone levels within standard levels. It has been argued by press, scholars, and politicians that some ethnicities are disproportionately impacted by this regulation and that the rule excludes too many.\nThe most notable cases of bans testing results are: Maria Jos\u00e9 Mart\u00ednez-Pati\u00f1o (1985), Santhi Soundarajan (2006), Caster Semenya (2009), Annet Negesa (2012), and Dutee Chand (2014).\nBefore the 2014 Asian Games, Indian athlete Dutee Chand was banned from competing internationally having been found to be in violation of the Hyperandrogenism Regulation. Following the denial of her appeal by the Court of Arbitration for Sport, the IOC suspended the policy for the 2016 Summer Olympics and 2018 Winter Olympics.\nLondon 2012 and the Munich massacre.\nBefore the start of the 2012 Summer Olympic Games, the IOC decided not to hold a minute of silence to honour the 11 Israeli Olympians who were killed 40 years prior in the Munich massacre. Jacques Rogge, the then-IOC President, said it would be \"inappropriate\" to do so. Speaking of the decision, Israeli Olympian Shaul Ladany, who had survived the Munich Massacre, commented: \"I do not understand. I do not understand, and I do not accept it\".\nWrestling.\nIn February 2013, the IOC excluded wrestling from its core Olympic sports for the Summer Olympic programme for the 2020 Summer Olympics, because the sport did not offer equal opportunities for men and women. This decision was attacked by the sporting community, given the wrestling's long tradition at the Olympics. After reassessment, however, wrestling was placed among the core Olympic sports again, a status it will hold until at least 2032.\nRussian doping.\nMedia attention began growing in December 2014 when German broadcaster ARD reported on state-sponsored doping in Russia, comparing it to doping in East Germany. In November 2015, the World Anti-Doping Agency (WADA) published a report and the World Athletics (then known as the IAAF) suspended Russia indefinitely from world track and field events. The United Kingdom Anti-Doping agency later assisted WADA with testing in Russia. In June 2016, they reported that they were unable to fully carry out their work and noted intimidation by armed Federal Security Service (FSB) agents.\nAfter a Russian former lab director made allegations about the 2014 Winter Olympics in Sochi, WADA commissioned an independent investigation led by Richard McLaren. McLaren's investigation found corroborating evidence, concluding in a report published in July 2016 that the Ministry of Sport and the FSB had operated a \"state-directed failsafe system\" using a \"disappearing positive [test] methodology\" (DPM) from \"at least late 2011 to August 2015\".\nIn response to these findings, WADA announced that RUSADA should be regarded as non-compliant with respect to the World Anti-Doping Code and recommended that Russia be banned from competing at the 2016 Summer Olympics. The IOC rejected the recommendation, stating that a separate decision would be made for each athlete by the relevant IF and the IOC, based on the athlete's individual circumstances. One day prior to the opening ceremony, 270 athletes were cleared to compete under the Russian flag, while 167 were removed because of doping. In contrast, the entire Kuwaiti team was banned from competing under their own flag (for a non-doping related matter).\nIn contrast to the IOC, the IPC voted unanimously to ban the entire Russian team from the 2016 Summer Paralympics, having found evidence that the DPM was also in operation at the 2014 Winter Paralympics.\nOn 5 December 2017, the IOC announced that the Russian Olympic Committee had been suspended effective immediately from the 2018 Winter Olympics. Athletes who had no previous drug violations and a consistent history of drug testing were allowed to compete under the Olympic Flag as an \"Olympic Athlete from Russia\" (OAR). Under the terms of the decree, Russian government officials were barred from the Games, and neither the country's flag nor anthem would be present. The Olympic Flag and Olympic Anthem would be used instead, and on 20 December 2017 the IOC proposed an alternate uniform logo.\nOn 1 February 2018, the Court of Arbitration for Sport (CAS) found that the IOC provided insufficient evidence for 28 athletes, and overturned their IOC sanctions. For 11 other athletes, the CAS decided that there was sufficient evidence to uphold their Sochi sanctions, but reduced their lifetime bans to only the 2018 Winter Olympics. The IOC said in a statement that \"the result of the CAS decision does not mean that athletes from the group of 28 will be invited to the Games. Not being sanctioned does not automatically confer the privilege of an invitation\" and that \"this [case] may have a serious impact on the future fight against doping\". The IOC found it important to note that the CAS Secretary General \"insisted that the CAS decision does not mean that these 28 athletes are innocent\" and that they would consider an appeal against the court's decision. Later that month, the Russian Olympic Committee was reinstated by the IOC, despite numerous failed drug tests by Russian athletes in the 2018 Olympics. The Russian Anti-Doping Agency was re-certified in September, despite the Russian rejection of the McLaren Report.\n2018 plebiscite in Taiwan.\nOn 24 November 2018, the Taiwanese government held a referendum over a change in the naming of their National Olympic Committee, from \"Chinese Taipei\", a name agreed to in 1981 by the People's Republic of China in the Nagoya Protocol, which denies the Republic of China's legitimacy, to simply \"Taiwan\", after the main island in the Free Area. In the immediate days prior to the referendum, the IOC and the PRC government, issued a threatening statement, suggesting that if the team underwent the name change, the IOC had the legal right to make a \"suspension of or forced withdrawal,\" of the team from the 2020 Summer Olympics. In response to the allegations of election interference, the IOC stated, \"The IOC does not interfere with local procedures and fully respects freedom of expression. However, to avoid any unnecessary expectations or speculations, the IOC wishes to reiterate that this matter is under its jurisdiction.\" Subsequently, with a significant PRC pressure, the referendum failed in Taiwan with 45% to 54%.\nPeng Shuai disappearance.\nIn November 2021, the IOC was again criticised by Human Rights Watch (HRW) and others for its response to the 2021 disappearance of Peng Shuai, following her publishing of sexual assault allegations against a former Chinese vice premier, and high-ranking member of the Chinese Communist Party, Zhang Gaoli.\nThe IOC's response was internationally criticised as complicit in assisting the Chinese government to silence Peng's sexual assault allegations. Zhang Gaoli previously led the Beijing bidding committee to host the 2022 Winter Olympics.\nFencing handshaking controversy.\nIn July 2020 (and reconfirmed in September 2020 and in January 2021), the FIE replaced its previous handshake requirement with a \"salute\" by the opposing fencers, writing in a public notice that handshakes were \"suspended until further notice.\" Nevertheless, in July 2023, the Ukrainian four-time world champion Olga Kharlan was disqualified at the World Fencing Championships for not shaking the hand of her defeated Russian opponent, although Kharlan instead offered a tapping of blades in acknowledgement. The President of the IOC, Thomas Bach, sent a letter to Kharlan in which he expressed empathy for her, and wrote that in light of the situation she was guaranteed a spot in the 2024 Summer Olympics. He wrote further: \"as a fellow fencer, it is impossible for me to imagine how you feel at this moment. The war against your country, the suffering of the people in Ukraine, the uncertainty around your participation at the Fencing World Championships ... and then the events which unfolded yesterday \u2013 all this is a roller coaster of emotions and feelings. It is admirable how you are managing this incredibly difficult situation, and I would like to express my full support to you. Rest assured that the IOC will continue to stand in full solidarity with the Ukrainian athletes and the Olympic community of Ukraine.\"\nRussian invasion of Ukraine.\nOn 12 October 2023, the International Olympic Committee issued a statement stating that after Russia began its full-scale invasion of Ukraine in 2022, the Russian Olympic Committee unilaterally transferred four regions that were originally under the jurisdiction of the National Olympic Committee of Ukraine: Donetsk Oblast, Luhansk Oblast, Kherson Oblast, Zaporizhzhia Oblast were included as members of their own, so the International Olympic Committee announced the suspension of the membership of the Russian Olympic Committee with immediate effect.\nOn 19 March 2024, the IOC announced that, due to their suspension, Russian and Belarusian athletes would be barred from the 2024 Summer Olympics opening ceremony as neither nation's athletes were invited. Russia responded by accusing the IOC of being \"neo-nazis\". Under the ruling, Russian athletes would not be allowed to participate in team events, and are not allowed to display the Russian flag. For 2026 Winter Games the IOC plans to continue this line, with approaching the International Biathlon Union and the International Ski and Snowboard Federation to allow Russian athletes compete in Olympic qualifications under a neutral flag.\nIsrael at the 2024 Summer Olympics.\nIn November 2023, Russia accused the IOC of having double standards by not sanctioning Israel due to its military actions in Gaza and its occupation of Palestine, as Palestine is also an IOC member. In January 2024, over 300 Palestinian sports clubs called for Israel to be barred from the 2024 Olympics after Israeli airstrikes had killed Palestine's Olympic football team coach, and damaged the headquarters of the Palestine Olympic Committee in Gaza. Sports organisations from other Arab countries also called for sanctions to be imposed against Israel and for it to be stopped from participating in the 2024 Summer Olympics, due to the Gaza war. The organisations said their concerns were about the war's impact on Palestinian athletes and sports facilities. The IOC cautioned athletes against boycotting or discriminating against others, stating that immediate action will follow any discriminatory behaviour such as the case of Algerian judoka Fethi Nourine, who received a ten-year ban following his refusal to fight Tohar Butbul, an Israeli, in the 2020 Summer Olympics. The IOC also stated that athletes are not to be held accountable for their government's actions. In March 2024, IOC President Thomas Bach made it clear the IOC would allow Israel to participate at the 2024 Summer Olympics and cautioned athletes against boycotts and discrimination.\n2024 WADA scandal.\nIn July 2024, the IOC threatened to withdraw Salt Lake City's bid to host the 2034 Winter Olympics if U.S. authorities continued to investigate allegations of doping by Chinese swimmers. The IOC insisted that Salt Lake City agree that it may \"terminate Olympic host city contracts in cases where the supreme authority of the World Anti-Doping Agency (WADA) in the fight against doping is not fully respected or if the application of the world antidoping code is hindered or undermined.\" This was intended to undermine the United States Department of Justice's criminal investigation into the allegations that the World Anti-Doping Agency covered up and failed to sanction drug use by Chinese swimmers.\nIOC Executive Board.\nFounded in 1921, The executive board manages the affairs of the IOC. Its members include the President, four Vice Presidents, and ten other members. All members are elected, by secret ballot, by a majority of votes cast, for a four-year term. Meetings can only be conducted if convened by the president or at the request of the majority of its members.\nIts responsibilities include:\nIOC Commissions.\nThese commissions have individual missions in the Olympic Movement. They may be created by the president, the IOC executive board, or the Olympic Charter. The president is an ex officio member of all commissions, designates its members and determines their dissolution once they have fulfilled their mandates. No commission can hold a meeting without permission of the president unless otherwise noted.\nThe Olympic Partner programme.\nThe Olympic Partner (TOP) sponsorship programme includes the following commercial sponsors of the Olympic Games.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "15148", "revid": "11952314", "url": "https://en.wikipedia.org/wiki?curid=15148", "title": "List of Presidents of the International Olympic Committee", "text": ""}
{"id": "15150", "revid": "32634809", "url": "https://en.wikipedia.org/wiki?curid=15150", "title": "Integrated circuit", "text": "Electronic circuit formed on a small, flat piece of semiconductor material\nAn integrated circuit (IC), also known as a microchip or simply chip, is a compact assembly of electronic circuits formed from various electronic components \u2014 such as transistors, resistors, and capacitors \u2014 and their interconnections. These components are fabricated onto a thin, flat piece (\"chip\") of semiconductor material, most commonly silicon. Integrated circuits are integral to a wide variety of electronic devices \u2014 including computers, smartphones, and televisions \u2014 performing functions such as data processing, control, and storage. They have transformed the field of electronics by enabling device miniaturization, improving performance, and reducing cost.\nCompared to assemblies built from discrete components, integrated circuits are orders of magnitude smaller, faster, more energy-efficient, and less expensive, allowing for a very high transistor count.\nThe IC\u2019s capability for mass production, its high reliability, and the standardized, modular approach of integrated circuit design facilitated rapid replacement of designs using discrete transistors. Today, ICs are present in virtually all electronic devices and have revolutionized modern technology. Products such as computer processors, microcontrollers, digital signal processors, and embedded processing chips in home appliances are foundational to contemporary society due to their small size, low cost, and versatility.\nVery-large-scale integration was made practical by technological advancements in semiconductor device fabrication. Since their origins in the 1960s, the size, speed, and capacity of chips have progressed enormously, driven by technical advances that fit more and more transistors on chips of the same size\u00a0\u2013 a modern chip may have many billions of transistors in an area the size of a human fingernail. These advances, roughly following Moore's law, make the computer chips of today possess millions of times the capacity and thousands of times the speed of the computer chips of the early 1970s.\nICs have three main advantages over circuits constructed out of discrete components:\u00a0size, cost and performance. The size and cost is low because the chips, with all their components, are printed as a unit by photolithography rather than being constructed one transistor at a time. Furthermore, packaged ICs use much less material than discrete circuits. Performance is high because the IC's components switch quickly and consume comparatively little power because of their small size and proximity. The main disadvantage of ICs is the high initial cost of designing them and the enormous capital cost of factory construction. This high initial cost means ICs are only commercially viable when high production volumes are anticipated.\nTerminology.\nAn \"integrated circuit\" (IC) is formally defined as:\nA circuit in which all or some of the circuit elements are inseparably associated and electrically interconnected so that it is considered to be indivisible for the purposes of construction and commerce. In its strict sense, the term refers to a single-piece circuit construction \u2014 originally called a \"monolithic integrated circuit\" \u2014 consisting of an entire circuit built on a single piece of silicon. In general usage, the designation \"integrated circuit\" can also apply to circuits that do not meet this strict definition, and which may be constructed using various technologies such as 3D IC, 2.5D IC, MCM, thin-film transistors, thick-film technology, or hybrid integrated circuits. This distinction in terminology is often relevant in debates on whether Moore's law remains applicable. \nHistory.\nThe first integrated circuits.\nA precursor concept to the IC was the development of small ceramic substrates, known as \"micromodules\", each containing a single miniaturized electronic component. These modules could then be assembled and interconnected into a two- or three-dimensional compact grid. The idea, considered highly promising in 1957, was proposed to the U.S. Army by Jack Kilby, leading to the short-lived Micromodule Program (similar in spirit to 1951's Project Tinkertoy). However, as the project gained traction, Kilby devised a fundamentally new approach: the integrated circuit itself.\nNewly employed by Texas Instruments, Kilby recorded his initial ideas concerning the integrated circuit in July 1958, successfully demonstrating the first working example of an integrated circuit on 12 September 1958. In his patent application of 6 February 1959, Kilby described his new device as \"a body of semiconductor material \u2026 wherein all the components of the electronic circuit are completely integrated\". The first customer for the new invention was the US Air Force. Kilby won the 2000 Nobel Prize in physics for his part in the invention of the integrated circuit.\nHowever, Kilby's invention was not a true monolithic integrated circuit chip, as it relied on external gold-wire connections, making large-scale production impractical. About six months later, Robert Noyce at Fairchild Semiconductor developed the first practical monolithic IC chip. The monolithic integrated circuit chip was enabled by the inventions of the planar process by Jean Hoerni and of p\u2013n junction isolation by Kurt Lehovec. Hoerni's invention was built on Carl Frosch and Lincoln Derick's work on surface protection and passivation by silicon dioxide masking and predeposition, as well as Fuller, Ditzenberger's and others work on the diffusion of impurities into silicon.\nUnlike Kilby's germanium-based design, Noyce's version was fabricated from silicon using the planar process by his colleague Jean Hoerni, which allowed reliable on-chip aluminum interconnections. Modern IC chips are based on Noyce's monolithic design, rather than Kilby's early prototype.\nNASA's Apollo Program was the largest single consumer of integrated circuits between 1961 and 1965.\nTTL integrated circuits.\nTransistor\u2013transistor logic (TTL) was developed by James L. Buie in the early 1960s at TRW Inc. TTL became the dominant integrated circuit technology during the 1970s to early 1980s.\nUse of dozens of TTL integrated circuits was the standard method of construction for the processors of minicomputers and mainframe computers. Computers such as IBM 360 mainframes, PDP-11 minicomputers and the desktop Datapoint 2200 were built from bipolar integrated circuits, either TTL or the faster emitter-coupled logic (ECL).\nMOS integrated circuits.\nModern integrated circuits (ICs) are based on the metal\u2013oxide\u2013semiconductor field-effect transistor (MOSFET), forming MOS ICs. The MOSFET was developed at Bell Labs between 1955 and 1960, enabling the creation of high-density ICs. Unlike bipolar transistors, which required additional steps for p\u2013n junction isolation, MOSFETs could be easily isolated from one another without such measures. This advantage for integrated circuits was first highlighted by Dawon Kahng in 1961. The list of IEEE Milestones includes Kilby's first IC in 1958, Hoerni's planar process and Noyce's planar IC in 1959.\nThe earliest experimental MOS IC to be fabricated was a 16-transistor chip built by Fred Heiman and Steven Hofstein at RCA in 1962. General Microelectronics later introduced the first commercial MOS integrated circuit in 1964, a 120-transistor shift register developed by Robert Norman. By 1964, MOS chips had reached higher transistor density and lower manufacturing costs than bipolar chips. MOS chips further increased in complexity at a rate predicted by Moore's law, leading to large-scale integration (LSI) with hundreds of transistors on a single MOS chip by the late 1960s.\nFollowing the development of the self-aligned gate (silicon-gate) MOSFET by Robert Kerwin, Donald Klein and John Sarace at Bell Labs in 1967, the first silicon-gate MOS IC technology with self-aligned gates, the basis of all modern CMOS integrated circuits, was developed at Fairchild Semiconductor by Federico Faggin in 1968. The application of MOS LSI chips to computing was the basis for the first microprocessors, as engineers began recognizing that a complete computer processor could be contained on a single MOS LSI chip. This led to the inventions of the microprocessor and the microcontroller by the early 1970s. During the early 1970s, MOS integrated circuit technology enabled the very large-scale integration (VLSI) of more than 10,000 transistors on a single chip.\nAt first, MOS-based computers only made sense when high density was required, such as aerospace and pocket calculators. Computers built entirely from TTL, such as the 1970 Datapoint 2200, were much faster and more powerful than single-chip MOS microprocessors, such as the 1972 Intel 8008, until the early 1980s.\nAdvances in IC technology, primarily smaller features and larger chips, have allowed the number of MOS transistors in an integrated circuit to double every two years, a trend known as Moore's law. Moore originally stated it would double every year, but he went on to change the claim to every two years in 1975. This increased capacity has been used to decrease cost and increase functionality. In general, as the feature size shrinks, almost every aspect of an IC's operation improves. The cost per transistor and the switching power consumption per transistor goes down, while the memory capacity and speed go up, through the relationships defined by Dennard scaling (MOSFET scaling). Because speed, capacity, and power consumption gains are apparent to the end user, there is fierce competition among the manufacturers to use finer geometries. Over the years, transistor sizes have decreased from tens of microns in the early 1970s to 10 nanometers in 2017 with a corresponding million-fold increase in transistors per unit area. As of 2016, typical chip areas range from a few square millimeters to around 600\u00a0mm2, with up to 25 million transistors per mm2.\nThe expected shrinking of feature sizes and the needed progress in related areas was forecast for many years by the International Technology Roadmap for Semiconductors (ITRS). The final ITRS was issued in 2016, and it is being replaced by the International Roadmap for Devices and Systems.\nInitially, ICs were strictly electronic devices. The success of ICs has led to the integration of other technologies, in an attempt to obtain the same advantages of small size and low cost. These technologies include mechanical devices, optics, and sensors.\nAs of 2018[ [update]], the vast majority of all transistors are MOSFETs fabricated in a single layer on one side of a chip of silicon in a flat two-dimensional planar process. Researchers have produced prototypes of several promising alternatives, such as:\nAs it becomes more difficult to manufacture ever smaller transistors, companies are using multi-chip modules/chiplets, three-dimensional integrated circuits, package on package, High Bandwidth Memory and through-silicon vias with die stacking to increase performance and reduce size, without having to reduce the size of the transistors. Such techniques are collectively known as advanced packaging. Advanced packaging is mainly divided into 2.5D and 3D packaging. 2.5D describes approaches such as multi-chip modules while 3D describes approaches where dies are stacked in one way or another, such as package on package and high bandwidth memory. All approaches involve 2 or more dies in a single package. Alternatively, approaches such as 3D NAND stack multiple layers on a single die. A technique has been demonstrated to include microfluidic cooling on integrated circuits, to improve cooling performance as well as peltier thermoelectric coolers on solder bumps, or thermal solder bumps used exclusively for heat dissipation, used in flip-chip.\nDesign.\nThe cost of designing and developing a complex integrated circuit is quite high, normally in the multiple tens of millions of dollars. Therefore, it only makes economic sense to produce integrated circuit products with high production volume, so the non-recurring engineering (NRE) costs are spread across typically millions of production units.\nModern semiconductor chips have billions of components, and are far too complex to be designed by hand. Software tools to help the designer are essential. Electronic design automation (EDA), also referred to as electronic computer-aided design (ECAD), is a category of software tools for designing electronic systems, including integrated circuits. The tools work together in a design flow that engineers use to design, verify, and analyze entire semiconductor chips. Some of the latest EDA tools use artificial intelligence (AI) to help engineers save time and improve chip performance.\nTypes.\nIntegrated circuits can be broadly classified into analog, digital and mixed-signal, consisting of analog and digital signaling on the same IC.\nDigital integrated circuits can contain billions of logic gates, flip-flops, multiplexers, and other circuits in a few square millimeters. The small size of these circuits allows high speed, low power dissipation, and reduced manufacturing cost compared with board-level integration. These digital ICs, typically microprocessors, DSPs, and microcontrollers, use boolean algebra to process \"one\" and \"zero\" signals.\nAmong the most advanced integrated circuits are the microprocessors or \"cores\", used in personal computers, cell-phones, etc. Several cores may be integrated together in a single IC or chip. Digital memory chips and application-specific integrated circuits (ASICs) are examples of other families of integrated circuits.\nIn the 1980s, programmable logic devices were developed. These devices contain circuits whose logical function and connectivity can be programmed by the user, rather than being fixed by the integrated circuit manufacturer. This allows a chip to be programmed to do various LSI-type functions such as logic gates, adders and registers. Programmability comes in various forms \u2013 devices that can be programmed only once, devices that can be erased and then re-programmed using UV light, devices that can be (re)programmed using flash memory, and field-programmable gate arrays (FPGAs) which can be programmed at any time, including during operation. Current FPGAs can (as of 2016) implement the equivalent of millions of gates and operate at frequencies up to 1 GHz.\nAnalog ICs, such as sensors, power management circuits, and operational amplifiers (op-amps), process continuous signals, and perform analog functions such as amplification, active filtering, demodulation, and mixing.\nICs can combine analog and digital circuits on a chip to create functions such as analog-to-digital converters and digital-to-analog converters. Such mixed-signal circuits offer smaller size and lower cost, but must account for signal interference. Prior to the late 1990s, radios could not be fabricated in the same low-cost CMOS processes as microprocessors. But since 1998, radio chips have been developed using RF CMOS processes. Examples include Intel's DECT cordless phone, or 802.11 (Wi-Fi) chips created by Atheros and other companies.\nModern often further sub-categorize integrated circuits:\nManufacturing.\nFabrication.\nThe semiconductors of the periodic table of the chemical elements were identified as the most likely materials for a \"solid-state vacuum tube\". Starting with copper oxide, proceeding to germanium, then silicon, the materials were systematically studied in the 1940s and 1950s. Today, monocrystalline silicon is the main substrate used for ICs although some III-V compounds of the periodic table such as gallium arsenide are used for specialized applications like LEDs, lasers, solar cells and the highest-speed integrated circuits. It took decades to perfect methods of creating crystals with minimal defects in semiconducting materials' crystal structure.\nSemiconductor ICs are fabricated in a planar process which includes three key process steps\u00a0\u2013 photolithography, deposition (such as chemical vapor deposition), and etching. The main process steps are supplemented by doping and cleaning. More recent or high-performance ICs may instead use multi-gate FinFET or GAAFET transistors instead of planar ones, starting at the 22\u00a0nm node (Intel) or 16/14\u00a0nm nodes.\nMono-crystal silicon wafers are used in most applications (or for special applications, other semiconductors such as gallium arsenide are used). The wafer need not be entirely silicon. Photolithography is used to mark different areas of the substrate to be doped or to have polysilicon, insulators or metal (typically aluminium or copper) tracks deposited on them. Dopants are impurities intentionally introduced to a semiconductor to modulate its electronic properties. Doping is the process of adding dopants to a semiconductor material.\nSince a CMOS device only draws current on the \"transition\" between logic states, CMOS devices consume much less current than bipolar junction transistor devices.\nRandom-access memory (RAM) is the most regular type of integrated circuit; the highest-density ICs are therefore memories, although even a microprocessor typically includes on-chip memory. (See the regular array structure at the bottom of the first image.) Although device structures are highly intricate\u2014with feature widths that have been shrinking for decades\u2014the material layers remain much thinner than the lateral dimensions of the devices. These layers are fabricated using a process analogous to photolithography, but light in the visible spectrum cannot be used for patterning, as its wavelengths are too large. Instead, ultraviolet (UV) photons of shorter wavelength are employed to expose each layer. Because the features are so small, electron microscopes are essential tools for a process engineer working on fabrication process debugging.\nEach device is tested before packaging using automated test equipment (ATE), in a procedure known as wafer testing or wafer probing. The wafer is then cut into rectangular blocks, each known as a \"die\". Each functional die (plural \"dice\", \"dies\", or \"die\") is connected into a package using aluminium (or gold) bond wires, which are attached by thermosonic bonding. Thermosonic bonding, first introduced by A. Coucoulas, provided a reliable means of forming electrical connections between the die and the outside world. After packaging, devices undergo final testing on the same or similar ATE used during wafer probing. In addition, industrial CT scanning can be employed for inspection. Test cost can account for over 25% of total fabrication cost for low-cost products, but is relatively negligible for low-yielding, larger, or higher-cost devices.\nAs of 2022[ [update]], a fabrication facility (commonly known as a \"semiconductor fab\") can cost over US$12 billion to construct. The cost of a fabrication facility rises over time because of increased complexity of new products; this is known as Rock's law. Such a facility features:\nICs can be manufactured either in-house by integrated device manufacturers (IDMs) or using the foundry model. IDMs are vertically integrated companies (like Intel and Samsung) that design, manufacture and sell their own ICs, and may offer design and/or manufacturing (foundry) services to other companies (the latter often to fabless companies). In the foundry model, fabless companies (like Nvidia) only design and sell ICs and outsource all manufacturing to pure play foundries such as TSMC. These foundries may offer IC design services.\nPackaging.\nThe earliest integrated circuits were packaged in ceramic flat packs, which continued to be used by the military for many years due to their reliability and compact size. Commercial packaging rapidly shifted to the dual in-line package (DIP) \u2014 first in ceramic, later in plastic, typically a cresol\u2013formaldehyde\u2013novolac resin.\nIn the 1980s, the pin count of VLSI circuits exceeded the practical limit of DIP packaging, leading to the adoption of pin grid array (PGA) and leadless chip carrier (LCC) packages. Surface-mount technology (SMT) emerged in the early 1980s and gained popularity by the late 1980s, offering finer lead pitch and using leads formed as either gull-wing or J-lead. A common example is the small-outline integrated circuit (SOIC) package \u2014 which occupies about 30\u201350% less board area than an equivalent DIP and is typically 70% thinner \u2014 featuring gull-wing leads extending from its two long sides with a standard lead spacing of 0.050\u00a0inches.\nBy the late 1990s, plastic quad flat pack (PQFP) and thin small-outline package (TSOP) designs became the most common for high pin-count devices, though PGA packages remain in use for high-performance microprocessors.\nBall grid array (BGA) packaging has existed since the 1970s. The flip-chip BGA (FCBGA), developed in the 1990s, enables much higher pin counts than most other package types. In an FCBGA, the die is mounted upside-down and connected to the package balls through a substrate similar to a printed circuit board, rather than by bonding wires. This design allows an array of input/output (I/O) connections \u2014 called Area-I/O \u2014 to be distributed across the entire die instead of being limited to its edges. While BGA devices eliminate the need for a dedicated socket, they are significantly more difficult to replace if they fail.\nIntel transitioned away from PGA to land grid array (LGA) and BGA beginning in 2004, with the last PGA socket released in 2014 for mobile platforms. As of 2018[ [update]], AMD uses PGA packages on mainstream desktop processors, BGA packages on mobile processors, and high-end desktop and server microprocessors use LGA packages.\nElectrical signals leaving the die must pass through the material electrically connecting the die to the package, through the conductive traces (paths) in the package, through the leads connecting the package to the conductive traces on the printed circuit board. The materials and structures used in the path these electrical signals must travel have very different electrical properties, compared to those that travel to different parts of the same die. As a result, they require special design techniques to ensure the signals are not corrupted, and much more electric power than signals confined to the die itself.\nWhen multiple dies are put in one package, the result is a system in package, abbreviated SiP. A multi-chip module (MCM), is created by combining multiple dies on a small substrate often made of ceramic. The distinction between a large MCM and a small printed circuit board is sometimes fuzzy.\nPackaged integrated circuits are usually large enough to include identifying information. Four common sections are the manufacturer's name or logo, the part number, a part production batch number and serial number, and a four-digit date-code to identify when the chip was manufactured. Extremely small surface-mount technology parts often bear only a number used in a manufacturer's lookup table to find the integrated circuit's characteristics.\nThe manufacturing date is commonly represented as a two-digit year followed by a two-digit week code, such that a part bearing the code 8341 was manufactured in week 41 of 1983, or approximately in October 1983.\nIntellectual property.\nThe possibility of copying by photographing each layer of an integrated circuit and preparing photomasks for its production on the basis of the photographs obtained is a reason for the introduction of legislation for the protection of layout designs. The US Semiconductor Chip Protection Act of 1984 established intellectual property protection for photomasks used to produce integrated circuits.\nA diplomatic conference held at Washington, D.C., in 1989 adopted a Treaty on Intellectual Property in Respect of Integrated Circuits, also called the Washington Treaty or IPIC Treaty. The treaty is currently not in force, but was partially integrated into the TRIPS agreement.\nThere are several United States patents connected to the integrated circuit, which include patents by J.S. Kilby https://, https://, https:// and by R.F. Stewart https://.\nNational laws protecting IC layout designs have been adopted in a number of countries, including Japan, the EC, the UK, Australia, and Korea. The UK enacted the Copyright, Designs and Patents Act, 1988, c. 48, \u00a7 213, after it initially took the position that its copyright law fully protected chip topographies. See British Leyland Motor Corp. v. Armstrong Patents Co.\nCriticisms of inadequacy of the UK copyright approach as perceived by the US chip industry are summarized in further chip rights developments.\nAustralia passed the Circuit Layouts Act of 1989 as a \"sui generis\" form of chip protection. Korea passed the \"Act Concerning the Layout-Design of Semiconductor Integrated Circuits\" in 1992.\nGenerations.\nIn the early days of simple integrated circuits, the technology's large scale limited each chip to only a few transistors, and the low degree of integration meant the design process was relatively simple. Manufacturing yields were also quite low by today's standards. As metal\u2013oxide\u2013semiconductor (MOS) technology progressed, the size of individual transistors shrank rapidly. By the 1980s, millions of MOS transistors could be placed on one chip, and good designs required thorough planning, giving rise to the field of electronic design automation, or EDA.\nSome SSI and MSI chips, like discrete transistors, are still mass-produced, both to maintain old equipment and build new devices that require only a few gates. The 7400 series of TTL chips, for example, has become a de facto standard and remains in production.\nSmall-scale integration (SSI).\nThe first integrated circuits contained only a few transistors. Early digital circuits containing tens of transistors provided a few logic gates, and early linear ICs such as the Plessey SL201 or the Philips TAA320 had as few as two transistors. The number of transistors in an integrated circuit has increased dramatically since then. The term \"large scale integration\" (LSI) was first used by IBM scientist Rolf Landauer when describing the theoretical concept; that term gave rise to the terms \"small-scale integration\" (SSI), \"medium-scale integration\" (MSI), \"very-large-scale integration\" (VLSI), and \"ultra-large-scale integration\" (ULSI). The early integrated circuits were SSI.\nSSI circuits were crucial to early aerospace projects, and aerospace projects helped inspire development of the technology. Both the Minuteman missile and Apollo program needed lightweight digital computers for their inertial guidance systems. Although the Apollo Guidance Computer led and motivated integrated-circuit technology, it was the Minuteman missile that forced it into mass-production. The Minuteman missile program and various other United States Navy programs accounted for the total $4 million integrated circuit market in 1962, and by 1968, U.S. Government spending on space and defense still accounted for 37% of the $312 million total production.\nThe demand by the U.S. Government supported the nascent integrated circuit market until costs fell enough to allow IC firms to penetrate the industrial market and eventually the consumer market. The average price per integrated circuit dropped from $50 in 1962 to $2.33 in 1968. Integrated circuits began to appear in consumer products by the turn of the 1970s decade. A typical application was FM inter-carrier sound processing in television receivers.\nThe first application MOS chips were small-scale integration (SSI) chips. Following Mohamed M. Atalla's proposal of the MOS integrated circuit chip in 1960, the earliest experimental MOS chip to be fabricated was a 16-transistor chip built by Fred Heiman and Steven Hofstein at RCA in 1962. The first practical application of MOS SSI chips was for NASA satellites.\nMedium-scale integration (MSI).\nThe next step in the development of integrated circuits introduced devices which contained hundreds of transistors on each chip, called \"medium-scale integration\" (MSI).\nMOSFET scaling technology made it possible to build high-density chips. By 1964, MOS chips had reached higher transistor density and lower manufacturing costs than bipolar chips.\nIn 1964, Frank Wanlass demonstrated a single-chip 16-bit shift register he designed, with a then-incredible 120 MOS transistors on a single chip. The same year, General Microelectronics introduced the first commercial MOS integrated circuit chip, consisting of 120 p-channel MOS transistors. It was a 20-bit shift register, developed by Robert Norman and Frank Wanlass. MOS chips further increased in complexity at a rate predicted by Moore's law, leading to chips with hundreds of MOSFETs on a chip by the late 1960s.\nLarge-scale integration (LSI).\nFurther development, driven by the same MOSFET scaling technology and economic factors, led to \"large-scale integration\" (LSI) by the mid-1970s, with tens of thousands of transistors per chip.\nThe masks used to process and manufacture SSI, MSI and early LSI and VLSI devices (such as the microprocessors of the early 1970s) were mostly created by hand, often using Rubylith-tape or similar. For large or complex ICs (such as memories or processors), this was often done by specially hired professionals in charge of circuit layout, placed under the supervision of a team of engineers, who would also, along with the circuit designers, inspect and verify the correctness and completeness of each mask.\nIntegrated circuits such as 1K-bit RAMs, calculator chips, and the first microprocessors, that began to be manufactured in moderate quantities in the early 1970s, had under 4,000 transistors. True LSI circuits, approaching 10,000 transistors, began to be produced around 1974, for computer main memories and second-generation microprocessors.\nVery-large-scale integration (VLSI).\n\"Very-large-scale integration\" (VLSI) is a development that started with hundreds of thousands of transistors in the early 1980s. As of 2023, maximum transistor counts continue to grow beyond 5.3 trillion transistors per chip.\nMultiple developments were required to achieve this increased density. Manufacturers moved to smaller MOSFET design rules and cleaner fabrication facilities. The path of process improvements was summarized by the International Technology Roadmap for Semiconductors (ITRS), which has since been succeeded by the International Roadmap for Devices and Systems (IRDS). Electronic design tools improved, making it practical to finish designs in a reasonable time. The more energy-efficient CMOS replaced NMOS and PMOS, avoiding a prohibitive increase in power consumption. The complexity and density of modern VLSI devices made it no longer feasible to check the masks or do the original design by hand. Instead, engineers use EDA tools to perform most functional verification work.\nIn 1986, one-megabit random-access memory (RAM) chips were introduced, containing more than one million transistors. Microprocessor chips passed the million-transistor mark in 1989, and the billion-transistor mark in 2005. The trend continues largely unabated, with chips introduced in 2007 containing tens of billions of memory transistors.\nULSI, WSI, SoC and 3D-IC.\n To reflect the continuing increase in complexity, the term \"ULSI\" (\"ultra-large-scale integration\") was introduced for chips containing more than one million transistors. Wafer-scale integration (WSI) is a technique for creating very large integrated circuits by using an entire silicon wafer to fabricate a single \"super-chip.\" By combining large size with reduced packaging, WSI offered the potential for significantly lower costs in certain applications, most notably massively parallel supercomputers. The term itself was derived from \"Very-Large-Scale Integration\" (VLSI), which represented the state of the art at the time WSI was under development.\nA system-on-a-chip (SoC or SOC) is an integrated circuit in which all the components needed for a computer or other system are included on a single chip. The design of such a device can be complex and costly, and whilst performance benefits can be had from integrating all needed components on one die, the cost of licensing and developing a one-die machine still outweigh having separate devices. With appropriate licensing, these drawbacks are offset by lower manufacturing and assembly costs and by a greatly reduced power budget: because signals among the components are kept on-die, much less power is required (see Packaging). Further, signal sources and destinations are physically closer on die, reducing the length of wiring and therefore latency, transmission power costs and waste heat from communication between modules on the same chip. This has led to an exploration of so-called Network-on-Chip (NoC) devices, which apply system-on-chip design methodologies to digital communication networks as opposed to traditional bus architectures.\nA three-dimensional integrated circuit (3D-IC) has two or more layers of active electronic components that are integrated both vertically and horizontally into a single circuit. Communication between layers uses on-die signaling, so power consumption is much lower than in equivalent separate circuits. Judicious use of short vertical wires can substantially reduce overall wire length for faster operation.\nSilicon labeling and graffiti.\nTo allow identification during production, most silicon chips will have a serial number in one corner. It is also common to add the manufacturer's logo. Ever since ICs were created, some chip designers have used the silicon surface area for surreptitious, non-functional images or words. These artistic additions, often created with great attention to detail, showcase the designers' creativity and add a touch of personality to otherwise utilitarian components. These are sometimes referred to as chip art, silicon art, silicon graffiti or silicon doodling.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "15151", "revid": "11292982", "url": "https://en.wikipedia.org/wiki?curid=15151", "title": "I-Link", "text": ""}
{"id": "15152", "revid": "15912645", "url": "https://en.wikipedia.org/wiki?curid=15152", "title": "Impedance match", "text": ""}
{"id": "15153", "revid": "10049", "url": "https://en.wikipedia.org/wiki?curid=15153", "title": "Individual cases of anthrax", "text": ""}
{"id": "15154", "revid": "3587591", "url": "https://en.wikipedia.org/wiki?curid=15154", "title": "IBM 3270", "text": "Family of block-oriented display terminals and printers made by IBM\nThe IBM 3270 is a family of block oriented display and printer computer terminals introduced by IBM in 1971 and normally used to communicate with IBM mainframes. The 3270 was the successor to the IBM 2260 display terminal. Due to the text color on the original models, these terminals are informally known as \"green screen\" terminals. Unlike a character-oriented terminal, the 3270 minimizes the number of I/O interrupts required by transferring large blocks of data known as data streams, and uses a high speed proprietary communications interface, using coaxial cable.\nIBM no longer manufactures 3270 terminals, but the IBM 3270 protocol is still commonly used via TN3270 clients, 3270 terminal emulation or web interfaces to access mainframe-based applications, which are sometimes referred to as \"green screen applications\".\nPrinciples.\nThe 3270 series was designed to connect with mainframe computers, often at a remote location, using the technology then available in the early 1970s. The main goal of the system was to maximize the number of terminals that could be used on a single mainframe. To do this, the 3270 was designed to minimize the amount of data transmitted, and minimize the frequency of interrupts to the mainframe. By ensuring the CPU is not interrupted at every keystroke, a 1970s-era IBM 3033 mainframe fitted with only 16\u00a0MB of main memory was able to support up to 17,500 3270 terminals under CICS.\nMost 3270 devices are \"clustered\", with one or more displays or printers connected to a \"control unit\" (the 3275 and 3276 included an integrated control unit). Originally devices were connected to the control unit over coaxial cable; later Token Ring, twisted pair, or Ethernet connections were available. A \"local\" control unit attaches directly to the channel of a nearby mainframe. A \"remote\" control unit is connected to a communications line by a modem. Remote 3270 controllers are frequently \"multi-dropped\", with multiple control units on a line.\nIBM 3270 devices are connected to a 3299 multiplexer or to the cluster controller, e.g., 3271, 3272, 3274, 3174, using 93ohm RG-62 coaxial cables in a point-to-point configuration with one dedicated cable per terminal. Data is sent with a bit rate of 2.3587 Mbit/s using a slightly modified differential Manchester encoding. Cable runs of up to are supported, although IBM documents routinely stated the maximum supported coax cable length was . Originally devices were equipped with BNC connectors, which were later replaced with special \"dual-purpose connectors\" (\"DPCs\") supporting the IBM shielded twisted-pair cabling system without the need for red baluns.\nIn a data stream, both text and control (or formatting functions) are interspersed allowing an entire screen to be painted as a single output operation. The concept of formatting in these devices allows the screen to be divided into fields (clusters of contiguous character cells) for which numerous field attributes, e.g., color, highlighting, character set, and protection from modification, can be set. A field attribute occupies a physical location on the screen that also determines the beginning and end of a field. There are also character attributes associated with individual screen locations.\nUsing a technique known as \"read modified\", a single transmission back to the mainframe can contain the changes from any number of formatted fields that have been modified, but without sending any unmodified fields or static data. This technique enhances the terminal throughput of the CPU, and minimizes the data transmitted. Some users familiar with character interrupt-driven terminal interfaces find this technique unusual. There is also a read buffer capability that transfers the entire content of the 3270-screen buffer including field attributes. This is mainly used for debugging purposes to preserve the application program screen contents while replacing it, temporarily, with debugging information.\nEarly 3270s offered three types of keyboards. The \"typewriter keyboard\" came in both a 66 key version, with no programmed function (PF) keys, and a 78 key version with twelve. Both versions had two \"Program Attention\" (PA) keys. The \"data entry keyboard\" had five PF keys and two PA keys. The \"operator console keyboard\" had twelve PF keys and two PA keys. Later 3270s had an Attention key, a Cursor Select key, a System Request key, twenty-four PF keys and three PA keys. There was also a TEST REQ key. When one of these keys is pressed, it will cause its control unit to generate an I/O interrupt to the host computer and present an \"Attention ID\" (AID) identifying which key was pressed. Application program functions such as termination, page-up, page-down, or help can be invoked by a single key press, thereby reducing the load on very busy processors.\nA downside to this approach was that vi-like behavior, responding to individual keystrokes, was not possible. For the same reason, a port of Lotus 1-2-3 to mainframes with 3279 screens did not meet with success because its programmers were not able to properly adapt the spreadsheet's user interface to a screen at a time rather than character at a time device. But end-user responsiveness was arguably more predictable with 3270, something users appreciated.\nApplications.\nFollowing its introduction the 3270 and compatibles were by far the most commonly used terminals on IBM System/370 and successor systems. IBM and third-party software that included an interactive component took for granted the presence of 3270 terminals and provided a set of ISPF panels and supporting programs.\nConversational Monitor System (CMS) in VM has support for the 3270 continuing to z/VM.\nTime Sharing Option (TSO) in OS/360 and successors has line mode command line support and also has facilities for full screen applications, e.g., ISPF.\nDevice Independent Display Operator Console Support (DIDOCS) in Multiple Console Support (MCS) for OS/360 and successors supports 3270 devices and, in fact, MCS in current versions of MVS no longer supports line mode, 2250 or 2260 devices.\nThe SPF and \"Program Development Facility\" (ISPF/PDF) editors for MVS and VM/SP (ISPF/PDF was available for VM, but little used) and the XEDIT editors for VM/SP through z/VM make extensive use of 3270 features.\nCustomer Information Control System (CICS) has support for 3270 panels. Indeed, from the early 1970s on, CICS applications were often written for the 3270.\nThe online editing and job submission environment Source Program Maintenance Online II (SPM) was oriented around the 3270.\nVarious versions of Wylbur have support for 3270, including support for full-screen applications.\nMcGill University's MUSIC/SP operating system provided support for 3270 terminals and applications, including a full-screen text editor, a menu system, and a PANEL facility to create 3270 full-screen applications. \nThe modified data tag is well suited to converting formatted, structured punched card input onto the 3270 display device. With the appropriate programming, any batch program that uses formatted, structured card input can be layered onto a 3270 terminal.\nIBM's OfficeVision office productivity software enjoyed great success with 3270 interaction because of its design understanding. And for many years the PROFS calendar was the most commonly displayed screen on office terminals around the world.\nA version of the WordPerfect word processor ported to System/370 was designed for the 3270 architecture.\nSNA.\n3270 devices can be a part of an SNA \u2013 System Network Architecture network or non-SNA network. If the controllers are SNA connected, they appear to SNA as PU \u2013 Physical Unit type 2.0 (PU2.1 for APPN) nodes typically with LU \u2013 Logical Unit type 1, 2, and 3 devices connected. Local, channel attached, controllers are controlled by VTAM \u2013 Virtual Telecommunications Access Method. Remote controllers are controlled by the NCP \u2013 Network Control Program in the Front End Processor i.e. 3705, 3720, 3725, 3745, and VTAM.\nThird parties.\nOne of the first groups to write and provide operating system support for the 3270 and its early predecessors was the University of Michigan, who created the Michigan Terminal System in order for the hardware to be useful outside of the manufacturer. MTS was the default OS at Michigan for many years, and was still used at Michigan well into the 1990s.\nMany manufacturers, such as GTE, Hewlett-Packard, Honeywell/Incoterm Div, Memorex, ITT Courier, McData, Harris, Alfaskop and Teletype/AT&amp;T created 3270 compatible terminals, or adapted ASCII terminals such as the HP 2640 series to have a similar block-mode capability that would transmit a screen at a time, with some form validation capability. The industry distinguished between 'system compatible' and 'plug compatible' controllers, where 'system compatibility' meant that the third-party system was compatible with the 3270 data stream terminated in the unit, but 'plug compatible' equipment was also compatible at the coax level, thereby allowing IBM terminals to be connected to a third-party controller or vice versa.\nModern applications are sometimes built upon legacy 3270 applications, using software utilities to capture (screen scrape) screens and transfer the data to web pages or GUI interfaces.\nIn the early 1990s a popular solution to link PCs with the mainframes was the Irma board, an expansion card that plugged into a PC and connected to the controller through a coaxial cable. 3270 simulators for IRMA and similar adapters typically provide file transfers between the PC and the mainframe using the same protocol as the IBM 3270 PC.\nModels.\nThe IBM 3270 display terminal subsystem consists of displays, printers and controllers.\nOptional features for the 3275 and 3277 are the \"selector-pen\", ASCII rather than EBCDIC character set, an audible alarm, and a keylock for the keyboard. A \"keyboard numeric lock\" was available and will lock the keyboard if the operator attempts to enter non-numeric data into a field defined as numeric. Later an \"Operator Identification Card Reader\" was added which could read information encoded on a magnetic stripe card.\nDisplays.\nGenerally, 3277 models allow only upper-case input, except for the mixed EBCDIC/APL or \"text\" keyboards, which have lower case. Lower-case capability and dead keys were available as an RPQ (\"Request Price Quotation\"); these were added to the later 3278 &amp; 3279 models.\nA version of the IBM PC called the 3270 PC, released in October 1983, includes 3270 terminal emulation. Later, the 3270 PC/G (graphics), 3270 PC/GX (extended graphics), 3270 Personal Computer AT, 3270 PC AT/G (graphics) and 3270 PC AT/GX (extended graphics) followed.\nCUT vs. DFT.\nThere are two types of 3270 displays in respect to where the 3270 data stream terminates:\nIn addition to passing the 3270 data stream directly to the terminal, allowing for features like EAB \u2014 Extended Attributes, Graphics, etc., DFT also enabled multi sessions (up to 5 simultaneous), featured in the 3290 and 3194 multisession displays. This feature was also widely used in 2nd generation 3270 terminal emulation software.\nThe MLT \u2014 Multiple Logical Terminals feature of the 3174 controller also enabled multiple sessions from a CUT type terminal.\n3278.\nThe 3278, along with the 3279 color display and the 3287 printer, introduced the \"Extended Display Stream\" (EDS) as the framework for new features.\n3279.\nThe IBM 3279 was IBM's first color terminal. IBM initially announced four models, and later added a fifth model for use as a processor console.\nThe 3279 was introduced in 1979. The 3279 was widely used as an IBM mainframe terminal before PCs became commonly used for the purpose. It was part of the 3270 series, using the 3270 data stream. Terminals could be connected to a 3274 controller, either channel connected to an IBM mainframe or linked via an SDLC (Synchronous Data Link Control) link. In the Systems Network Architecture (SNA) protocol these terminals were logical unit type 2 (LU2). The basic models 2A and 3A used red, green for input fields, and blue and white for output fields. However, the models 2B and 3B supported seven colors, and when equipped with the optional Programmed Symbol Set feature had a loadable character set that could be used to show graphics. The Programmed Symbol Set feature could be added in the field, and was standard in the model S3G.\nThe IBM 3279 with its graphics software support, Graphical Data Display Manager (GDDM), was designed at IBM's Hursley Development Laboratory, near Winchester, England.\n3290.\nThe 3290 Information Panel a 17\", amber monochrome plasma display unit announced March 8, 1983, capable of displaying in various modes, including four independent 3278 model 2 terminals, or a single 160\u00d762 terminal; it also supports partitioning. The 3290 supports graphics through the use of \"programmed symbols\". A 3290 application can divide its screen area up into as many as 16 separate \"explicit partitions\" (logical screens).\nThe 3290 is a Distributed Function Terminal (DFT) and requires that the controller do a downstream load (DSL) of microcode from floppy or hard disk.\n3180.\nThe 3180 was a monochrome display, introduced on March 20, 1984, that the user could configure for several different basic and extended display modes; all of the basic modes have a primary screen size of 24x80. Modes 2 and 2+ have a secondary size of 24x80, 3 and 3+ have a secondary size of 32x80, 4 and 4+ have a secondary size of 43x80 and 5 and 5+ have a secondary size of 27x132. An application can override the primary and alternate screen sizes for the extended mode. The 3180 also supported a single explicit partition that could be reconfigured under application control.\n3191.\nThe IBM 3191 Display Station is an economical monochrome CRT. Models A and B are 1920 characters 12-inch CRTs. Models D, E and L are 1920 or 2560 character 14-inch CRTs.\n3193.\nThe IBM 3193 Display Station is a high-resolution, portrait-type, monochrome, 380mm (15 inch) CRT image display providing up to letter or A4 size document display capabilities in addition to alphanumeric data.\nCompressed images can be sent to the 3193 from a scanner and decompression is performed in the 3193.\nImage data compression is a technique to save transmission time and reduce storage requirements.\n3194.\nThe IBM 3194 is a Display Station that features a 1.44\u00a0MB 3.5\" floppy drive and IND$FILE transfer.\nNon-IBM Displays.\nSeveral third-party manufacturers produced 3270 displays besides IBM.\nGTE.\nGTE manufactured the IS/7800 Video Display System, nominally compatible with IBM 3277 displays attached to a 3271 or 3272. An incompatibility with the RA buffer order broke the logon screen in VM/SE (SEPP).\nHarris.\nHarris manufactured the 8000 Series Terminal Systems, compatible with IBM 3277 displays attached to a 3271 or 3272.\nHarris later manufactured the 9100\u20139200 Information Processing Systems, which included\nInformer 270 376/SNA.\nInformer Computer Terminals manufactured a special version of their model 270 terminal that was compatible with IBM 3270 and its associated coax port to connect to a 3x74.\nMemorex Telex.\nDocumentation for the following is available at\nAT&amp;T.\nAT&amp;T introduced the Dataspeed 40 terminal/controller, compatible with the IBM 3275, in 1980.\nGraphics models.\nIBM had two different implementations for supporting graphics. The first was implemented in the optional Programmed Symbol Sets (PSS) of the 3278, 3279 and 3287, which became a standard feature on the later 3279-S3G, a.k.a. 3279G, and was based on piecing together graphics with on-the-fly custom-defined symbols downloaded to the terminal.\nThe second later implementation provided All Points Addressable (APA) graphics, a.k.a. Vector Graphics, allowing more efficient graphics than the older technique. The first terminal to support APA / Vector graphics was the 3179G terminal, which was later replaced by first the 3192G, then the 3472G.\nBoth implementations are supported by IBM GDDM \u2014 Graphical Data Display Manager first released in 1979, and by SAS with their SAS/GRAPH software.\nIBM 3279G.\nIBM 3279-S3G, a.k.a. 3279G, terminal, announced in 1979, was IBM's graphics replacement for the 3279-3B with PSS. The terminal supported 7 colors and the graphics were made up of Programmable Symbol sets loaded to the terminal by the graphical application GDDM \u2014 Graphical Data Display Manager using Write Structured Field command.\nProgrammable Symbols is an addition to the normal base character set consisting of Latin characters, numbers, etc. hardwired into the terminal. The 3279G supports six additional sets of symbols each supporting 190 symbols, resulting in a total of 1.140 programmable symbols. Three of the Programmable Symbols sets have three planes each enabling coloring (red, blue, green) the Programmable Symbols downloaded to those sets, thereby supporting a total of seven colors.\nEach 'character' cell consists of a 9x12 or a 9x16 dot matrix depending on the screen model. In order to program a cell with a symbol 18 bytes of data is needed making the data load quite heavy in some instances when compared to classic text screens.\nIf one for example wishes to draw a hyperbola on the screen, the application must first compute the required Programmable Symbols to make up hyperbola and load them to the terminal. The next step is then for the application to paint the screen by addressing the screen cell position and select the appropriate symbol in one of the Programmable Symbols sets.\nThe 3279G could be ordered with Attribute Select Keyboard enabling the operator to select attributes, colors and Programmable Symbols sets, making that version of the terminal quite distinctive.\nIBM 3179G.\nThe IBM 3179G announced June 18, 1985, is an IBM mainframe computer terminal providing 80\u00d724 or 80\u00d732 characters, 16 colors, plus graphics and is the first terminal to support the APA graphics apart from the 3270 PC/G, 3270 PC/GX, PC AT/G and PC AT/GX.\n3179-G terminals combine text and graphics as separate layers on the screen. Although the text and graphics appear combined on the screen, the text layer actually sits over the graphics layer. The text layer contains the usual 3270-style cells which display characters (letters, numbers, symbols, or invisible control characters). The graphics layer is an area of 720\u00d7384 pixels. \"All Points Addressable\" or \"vector graphics\" is used to paint each pixel in one of sixteen colors. As well as being separate layers on the screen, the text and graphics layers are sent to the display in separate data streams, making them completely independent.\nThe application i.e. GDDM sends the vector definitions to the 3179-G, and the work of activating the pixels that represent the picture (the vector-to-raster conversion) is done in the terminal itself. The datastream is related to the number of graphics primitives (lines, arcs, and so on) in the picture. Arcs are split into short vectors, that are sent to the 3179-G to be drawn. The 3179-G does not store graphic data, and so cannot offload any manipulation function from GDDM. In particular, with user control, each new viewing operation means that the data has to be regenerated and retransmitted.\nThe 3179G is a distributed function terminal (DFT) and requires a downstream load (DSL) to load its microcode from the cluster controller's floppy disk or hard drive.\nThe G10 model is a standard 122-key typewriter keyboard, while the G20 model offers APL on the same layout. Compatible with IBM System/370, IBM 4300 series, 303x, 308x, IBM 3090, and IBM 9370.\nIBM 3192G.\n&lt;dfn&gt;The IBM 3192G, announced in&lt;/dfn&gt; 1987 &lt;dfn&gt;was the&lt;/dfn&gt; successor to 3179G. It featured 16 colors, and support for printers (i.e., IBM Proprinter) for local hardcopy with graphical support, or system printer, text only, implemented as an additional LU.\nIBM 3472G.\nThe IBM 3472G announced in 1989 was the successor to 3192G and featured five concurrent sessions, one of which could be graphics. Unlike the 3192-G, it needed no expansion unit to attach a mouse or color plotter, and it could also attach a tablet device for digitised input and a bar code reader.\nAPL / APL2.\nMost IBM terminals, starting with the 3277, could be delivered with an APL keyboard, allowing the operator/programmer to enter APL symbolic instructions directly into the editor. In order to display APL symbols on the terminal, it had to be equipped with an APL character set in addition to the normal 3270-character set. The APL character set is addressed with a preceding Graphic Escape X'08' instruction.\nWith the advent of the graphic terminal 3179G, the APL character set was expandable to 138 characters, called APL2. The added characters were: Diamond, Quad Null, Iota Underbar, Epsilon Underbar, Left Tack, Right Tack, Equal Underbar, Squished Quad, Quad Slope, and Dieresis Dot. Later APL2 symbols were supported by 3191 Models D, E, L, the CUT version of 3192, and 3472.\nPlease note that IBM's version's of APL also is called APL2.\nPrinters.\nIn 1984 announced IPDS \u2013 Intelligent Printer Data Stream for online printing of AFP \u2014 Advanced Function Presentation documents, using bidirectional communications between the application and the printer. IPDS support among others printing of text, fonts, images, graphics, and barcodes. The IBM 4224 is one of the IPDS capable dot matrix printers.\nWith the emergence of printers, including laser printers, from HP, Canon, and others, targeted the PC market, 3270 customers got an alternative to IBM 3270 printers by connecting this type of printers through printer protocol converters from manufactures like I-data, MPI Tech, Adacom, and others. The printer protocol converters basically emulate a 3287 type printer, and later extended to support IPDS.\nThe IBM 3482 terminal, announced in 1992, offered a printer port, which could be used for host addressable printing as well as local screen copy. codice_1\nIn the later versions of 3174 the Asynchronous Emulation Adapter (AEA), supporting async RS-232 character-based type terminals, was enhanced to support printers equipped with a serial interface.\nControllers.\nOn the 3274 and 3174, IBM used the term configuration support \"letter\", sometimes followed by a release number, to designate a list of features together with the hardware and microcode needed to support them.\nBy 1994 the 3174 Establishment Controller supported features such as attachment to multiple hosts via Token Ring, Ethernet, or X.25 in addition to the standard channel attach or SDLC; terminal attachment via twisted pair, Token Ring or Ethernet in addition to 3270 coaxial; and TN3270. They also support attachment of asynchronous ASCII terminals, printers, and plotters alongside 3270 devices.\n3274 controller.\nIBM introduced the 3274 controller family in 1977, replacing the 3271\u20132 product line.\nWhere the features of the 3271\u20132 was hardcoded, the 3274 was controlled by its microcode that was read from the 3274's built-in 8\" floppy drive.\n3274 models included 8, 12, 16, and 32 port remote controllers and 32-port local channel attached units. In total 16 different models were over time released to the market. The 3274-1A was an SNA physical Unit type 2.0 (PU2.0), required only a single address on the channel for all 32 devices and was not compatible with the 3272. The 3274-1B and 3274-1D were compatible with the 3272 and were referred to as local non-SNA models.\nThe 3274 controllers introduced a new generation of the coax protocol, named Category A, to differentiate them from the Category B coax devices, such as the 3277 terminal and the 3284 printer. The first Category A coax devices were the 3278 and the first color terminal, the IBM 3279 Color Display Station.\nEnabling backward compatibility, it was possible to install coax boards, so-called 'panels', in groups of 4 or 8 supporting the now older Category B coax devices. A maximum of 16 Category B terminals could be supported, and only 8 if the controller were fully loaded with a maximum of 4 panels each supporting 8 Category A devices.\nDuring its life span, the 3274 supported several features including:\n3174 controller.\nIBM introduced the 3174 Subsystem Control Unit in 1986, replacing the 3274 product line.\nThe 3174 was designed to enhance the 3270 product line with many new connectivity options and features. Like the 3274, it was customizable, the main difference was that it used smaller (5.25-inch) diskettes than the 3274 (8-inch diskettes), and that the larger floor models had 10 slots for adapters, some of them were per default occupied by channel adapter/serial interface, coax adapter, etc. Unlike the 3274, any local models could be configured as either local SNA or local non-SNA, including PU2.1 (APPN).\nThe models included: 01L, 01R, 02R, 03R, 51R, 52R, 53R, 81R and 82R.\nThe 01L were local channel attached, the R models remotely connected, and the x3R Token Ring (upstream) connected. The 0xL/R models were floor units supporting up to 32 coax devices through the use of internal or external multiplexers (TMA/3299). The 5xR, models were shelf units with 9 coax ports, expandable to 16, by the connection of a 3299 multiplexer. The smallest desktop units, 8xR, had 4 coax ports expandable to 8, by the connection of a 3299 multiplexer.\nIn the 3174 controller line IBM also slightly altered the classical BNC coax connector by changing the BNC connector to DPC \u2013 Dual Purpose Connector. The DPC female connector was a few millimeters longer and with a built-in switch that detected if a normal BNC connector were connected or a newer DPC connector was connected, thereby changing the physical layer from 93 ohm unbalanced coax, to 150 ohm balanced twisted-pair, thereby directly supporting the IBM Cabling system without the need for a so-called red balun.\nConfiguration Support A was the first microcode offered with the 3174. It supported all the hardware modules present at the time, almost all the microcode features found in 3274 and introduced a number of new features including: Intelligent Printer Data Stream (IPDS), Multiple Logical Terminals, Country Extended Code Page (CECP), Response Time Monitor, and Token Ring configured as host interface.\nConfiguration Support S, strangely following release A, introduced that a local or remote controller could act as 3270 Token-Ring DSPU Gateway, supporting up to 80 Downstream PU's.\nIn 1989, IBM introduced a new range of 3174 models and changed the name from 3174 Subsystem Control Unit to 3174 Establishment Controller. The main new feature was support for an additional 32 coax port in floor models.\nThe models included: 11L, 11R, 12R, 13R, 61R, 62R, 63R, 91R, and 92R.\nThe new line of controllers came with Configuration Support B release 1, increased the number of supported DSPU on the Token-Ring gateway to 250 units, and introduced at the same time 'Group Polling' that offloaded the mainframe/VTAM polling requirement on the channel.\nConfiguration Support B release 2 to 5, enabled features like: Local Format Storage (CICS Screen Buffer), Type Ahead, Null/Space Processing, ESCON channel support.\nIn 1990\u20131991, a total of 7 more models were added: 21R, 21L, 12L, 22L, 22R, 23R, and 90R. The 12L offered ESCON fibreoptic channel attachment. The models with 2xx designation were equal to the 1xx models but repacked for rackmount and offered only 4 adapter slots. The 90R was not intended as a coax controller, it was positioned as a Token Ring 3270 DSPU gateway. However, it did have one coax port for configuring the unit, which with a 3299 multiplexer could be expanded to 8.\nThe line of controllers came with Configuration Support C to support ISDN, APPN and Peer Communication. The ISDN feature allowed downstream devices, typically PC's, to connect to the 3174 via the ISDN network. The APPN support enabled the 3174 to be a part of an APPN network, and the Peer Communication allowed coax attached PC's with 'Peer Communication Support' to access resources on the Token-Ring network attached to the 3174.\nThe subsequent releases 2 to 6 of Configuration Support C enables support for: Split screen, Copy from session to session, Calculator function, Access to AS/400 host and 5250 keyboard emulation, Numerous APPN enhancements, TCP/IP Telnet support that allowed 3270 CUT terminals to communicate with TCP/IP servers using Telnet, and at the same time in another screen to communicate with the mainframe using native 3270. TN3270 support where the 3174 could connect to a TN3270 host/gateway, eliminating SNA, but preserving the 3270 data stream. IP forwarding allowing bridging of LAN (Token-Ring or Ethernet) connected devices downstream to the 3174 to route IP traffic onto the Frame Relay WAN interface.\nIn 1993, three new models were added with the announcement of Ethernet Adapter (FC 3045). The models were: 14R, 24R, and 64R.\nThis was also IBM's final hardware announcement of 3174.\nThe floor models, and the rack-mountable units, could be expanded with a range of special 3174 adapters, that by 1993 included: Channel adapter, ESCON adapter, Serial (V.24/V.35) adapter, Concurrent Communication Adapter, Coax adapter, Fiber optic \"coax\" adapter, Async adapter, ISDN adapter, Token-Ring adapter, Ethernet adapter, and line encryption adapter.\nIn 1994, IBM incorporated the functions of RPQ 8Q0935 into Configuration Support-C release 3, including the TN3270 client.\nNon-IBM Controllers.\nGTE.\nThe GTE IS/7800 Video Display Systems used one of two nominally IBM compatible controllers:\nHarris.\nThe Harris 8000 Series Terminal Systems used one of four controllers:\nHome grown.\nAn alternative implementation of an establishment controller exists in form of OEC (Open Establishment Controller). It's a combination of an Arduino shield with a BNC connector and a Python program that runs on a POSIX system. OEC allows to connect a 3270 display to IBM mainframes via TN3270 or to other systems via VT100. Currently only CUT but not DFT displays are supported.\nMemorex.\nMemorex had two controllers for its 3277-compatible 1377; the 1371 for remote connection and the 1372 for local connection.\nLater Memorex offered a series of controllers compatible with the IBM 3274 and 3174\nMultiplexers.\nIBM offered a device called 3299 that acted as a multiplexer between an accordingly configured 3274 controller, with the 9901 multiplexer feature, and up to eight displays/printers, thereby reducing the number of coax cables between the 3x74 controller and the displays/printers.\nWith the introduction of the 3174 controller internal or external multiplexers (3299) became mainstream as the 3174-1L controller was equipped with four multiplexed ports each supporting eight devices. The internal 3174 multiplexer card was named TMA \u2013 Terminal Multiplexer adapter 9176.\nA number of vendors manufactured 3270 multiplexers before and alongside IBM including Fibronics and Adacom offering multiplexers that supported TTP \u2013 Telephone Twisted Pair as an alternative to coax, and fiber-optic links between the multiplexers.\nIn some instances, the multiplexer worked as an \"expansion\" unit on smaller remote controllers including the 3174-81R / 91R, where the 3299 expanded the number of coax ports from four to eight, or the 3174-51R / 61R, where the 3299 expanded the number of coax ports from eight to 16.\nManufacture.\nThe IBM 3270 display terminal subsystem was designed and developed by IBM's Kingston, New York, laboratory (which later closed during in the mid-1990s). The printers were developed by the Endicott, New York, laboratory. As the subsystem expanded, the 3276 display-controller was developed by the Fujisawa laboratory, Japan, and later the Yamato laboratory; and the 3279 color display and 3287 color printer by the Hursley, UK, laboratory. The subsystem products were manufactured in Kingston (displays and controllers), Endicott (printers), and Greenock, Scotland, UK, (most products) and shipped to users in U.S. and worldwide. 3278 terminals continued to be manufactured in Hortol\u00e2ndia, near Campinas, Brazil as far as late 1980s, having its internals redesigned by a local engineering team using modern CMOS technology, while retaining its external look and feel.\nTelnet 3270.\nTelnet 3270, or tn3270 describes both the process of sending and receiving 3270 data streams using the telnet protocol and the software that emulates a 3270 class terminal that communicates using that process. tn3270 allows a 3270 terminal emulator to communicate over a TCP/IP network instead of an SNA network. Telnet 3270 can be used for either terminal or print connections. Standard telnet clients cannot be used as a substitute for tn3270 clients, as they use fundamentally different techniques for exchanging data.\nTN3270 is typically deployed for online IBM mainframe application access via VTAM.\nTechnical Information.\n3270 character set.\nThe 3270 displays are available with a variety of keyboards and character sets. The following table shows the 3275/3277/3284\u20133286 character set for US English EBCDIC (optional characters were available for US ASCII, and UK, French, German, and Italian EBCDIC).\nOn the 3275 and 3277 terminals without the a text feature, lower case characters display as uppercase. NL, EM, DUP, and FM control characters display and print as 5, 9, *, and ; characters, respectively, except by the printer when WCC or CCC bits 2 and 3 = '00'b, in which case NL and EM serve their control function and do not print.\nData stream.\nData sent to the 3270 consist of commands, a Copy Control Character (CCC) or Write Control Character (WCC) if appropriate, a device address for copy, orders, character data and structured fields. Commands instruct the 3270 control unit to perform some action on a specified device, such as a read or write. Orders are sent as part of the data stream to control the format of the device buffer. Structured fields are to convey additional control functions and data to or from the terminal.\nOn a local non-SNA controller, the command is a CCW opcode rather than the first byte of the outbound display stream; on all other controllers, the command is the first byte of the display stream, exclusive of protocol headers.\nCommands.\nThe following table includes datastream commands and CCW opcodes for local non-SNA controllers; it does not include CCW opcodes for local SNA controllers.\nWrite control character.\nThe data sent by Write or Erase/Write consists of the command code itself followed by a \"Write Control Character\" (WCC) optionally followed by a buffer containing orders or data (or both). The WCC controls the operation of the device. Bits may start printer operation and specify a print format. Other bit settings will sound the audible alarm if installed, unlock the keyboard to allow operator entry, or reset all the Modified Data Tags in the device buffer.\nOrders.\nOrders consist of the order code byte followed by zero to three bytes of variable information.\nAttributes.\nThe 3270 has three kinds of attributes:\nField attributes.\nThe original 3277 and 3275 displays used an 8-bit field attribute byte of which five bits were used.\nLater models include \"base color\": \"Base color (four colors) can be produced on color displays and color printers from current 3270 application programs by use of combinations of the field intensify and field protection attribute bits. For more information on color, refer to IBM 3270 Information System: Color and Programmed Symbols, GA33-3056.\"\nExtended attributes.\nThe 3278 and 3279 and later models used \"extended attributes\" to add support for seven colors, blinking, reverse video, underscoring, field outlining, field validation, and programmed symbols.\nCharacter attributes.\nThe 3278 and 3279 and later models allowed attributes on individual characters in a field to override the corresponding field attributes.\nThis allowed programs (such as the LEXX text editor) to assign any font (including the programmable fonts), colour, etc. to any character on the screen.\nBuffer addressing.\n3270 displays and printers have a buffer containing one byte for every screen position. For example, a 3277 model 2 featured a screen size of 24 rows of 80 columns for a buffer size of 1920 bytes. Bytes are addressed from zero to the screen size minus one, in this example 1919. \"There is a fixed relationship between each ... buffer storage location and its position on the display screen.\" Most orders start operation at the \"current\" buffer address, and executing an order or writing data will update this address. The buffer address can be set directly using the \"Set Buffer Address (SBA)\" order, often followed by \"Start Field\" or \"Start Field Extended\". For a device with a 1920 character display a twelve bit address is sufficient. Later 3270s with larger screen sizes use fourteen or sixteen bits.\nAddresses are encoded within orders in two bytes. For twelve bit addresses the high order two bits of each byte are set to form valid EBCDIC (or ASCII) characters. For example, address 0 is coded as X'4040', or space-space, address 1919 is coded as X'5D7F', or '\"'. Programmers hand-coding panels usually keep the table of addresses from the 3270 Component Description or the 3270 Reference Card handy. For fourteen and sixteen-bit address, the address uses contiguous bits in two bytes.\nExample.\nThe following data stream writes an attribute in row 24, column 1, writes the (protected) characters '&gt; ' in row 24, columns 2 and 3, and creates an unprotected field on row 24 from columns 5-79. Because the buffer wraps around an attribute is placed on row 24, column 80 to terminate the input field. This data stream would normally be written using an Erase/Write command which would set undefined positions on the screen to '00'x. Values are given in hexadecimal.\nExtended Data Stream.\nMost 3270 terminals newer than the 3275, 3277, 3284 and 3286 support an extended data stream (EDS) that allows many new capabilities, including:\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "15155", "revid": "2300502", "url": "https://en.wikipedia.org/wiki?curid=15155", "title": "I. M. Pei", "text": "Chinese-American architect (1917\u20132019)\nIeoh Ming Pei ( ; ; April 26, 1917 \u2013 May 16, 2019) was a Chinese-American architect. Born in Guangzhou into a Chinese family, Pei drew inspiration at an early age from the garden villas at Suzhou, the traditional retreat of the scholar-gentry to which his family belonged. In 1935, he moved to the United States and enrolled in the University of Pennsylvania's architecture school, but quickly transferred to the Massachusetts Institute of Technology. Unhappy with the focus on Beaux-Arts architecture at both schools, he spent his free time researching emerging architects, especially Le Corbusier.\nAfter graduating from MIT, Pei enrolled in the Harvard Graduate School of Design (GSD) where he befriended faculty members Walter Gropius and Marcel Breuer, both of whom had formerly taught at the Bauhaus. \nBeginning in 1948, Pei worked as an in-house architect for New York City real estate developer William Zeckendorf. In 1955, he established an independent design firm, I. M. Pei &amp; Associates. In 1966, the firm was reorganized as I. M. Pei &amp; Partners, and in 1989 reorganized \nas Pei Cobb Freed &amp; Partners. Pei retired from full-time practice in 1990. In his retirement, he worked as an architectural consultant primarily with his sons' architectural firm Pei Partnership Architects.\nPei's first major recognition came with the Mesa Laboratory at the National Center for Atmospheric Research in Colorado (designed in 1961, and completed in 1967). His new stature led to his selection as chief architect for the John F. Kennedy Library in Massachusetts. He went on to design Dallas City Hall and the East Building of the National Gallery of Art. He returned to China for the first time in 1975 to design a hotel at Fragrant Hills and, fifteen years later, designed Bank of China Tower, Hong Kong. In the early 1980s, Pei was the focus of controversy when he designed a glass-and-steel pyramid for the Louvre in Paris. He designed the Morton H. Meyerson Symphony Center in Dallas, the Miho Museum in Japan, Shigaraki, near Kyoto, and the chapel of the junior and high school: MIHO Institute of Aesthetics, the Suzhou Museum in Suzhou, Museum of Islamic Art in Qatar, and the Grand Duke Jean Museum of Modern Art in Luxembourg.\nPei won prizes and awards in the field of architecture, including the AIA Gold Medal in 1979, the first Praemium Imperiale for Architecture in 1989, and the Lifetime Achievement Award from the Cooper-Hewitt, National Design Museum, in 2003. In 1983, he won the Pritzker Prize, which is sometimes referred to as the Nobel Prize of architecture.\nChildhood.\nI. M. Pei's ancestry traces back to the Ming dynasty, when his family moved from Anhui to Suzhou. The family made their wealth in medicinal herbs, then joined the ranks of the scholar-gentry. Pei Ieoh Ming was born on April 26, 1917, to Tsuyee and Lien Kwun, and the family moved to Hong Kong one year later. It eventually included five children. As a boy, Pei was very close to his mother, a devout Buddhist, who was recognized for her skills as a flautist. She invited him, but not his brothers or sisters, to join her on meditation retreats. His relationship with his father was less intimate. Their interactions were respectful but distant.\nPei's ancestors' success meant that the family lived in the upper echelons of society, but Pei said his father was \"not cultivated in the ways of the arts\". The younger Pei, drawn more to music and other cultural forms than to his father's domain of banking, explored art on his own. \"I have cultivated myself,\" he said later.\nPei studied in St. Paul's College in Hong Kong as a child. When Pei was 10, his father received a promotion and relocated with his family to Shanghai. Pei attended St. John's Middle School, the secondary school of St. John's University that was run by Anglican missionaries. Academic discipline was rigorous; students were allowed only one half-day each month for leisure. Pei enjoyed playing billiards and watching Hollywood movies, especially those of Buster Keaton and Charlie Chaplin. He also learned rudimentary English by reading the Bible and novels by Charles Dickens.\nShanghai's many international elements gave it the name \"Paris of the East\". The city's global architectural flavors had a profound influence on Pei, from The Bund waterfront area to the Park Hotel, built in 1934. He was also impressed by the many gardens of Suzhou, where he spent the summers with extended family and regularly visited a nearby ancestral shrine. The Shizilin Garden, built in the 14th century by a Buddhist monk and owned by Pei's uncle Bei Runsheng, was especially influential. He spoke later of his fondness for the garden's blending of natural and human-built structures.\nSoon after the move to Shanghai, Pei's mother developed cancer. She was prescribed opium for pain and assigned the task of preparing her pipe to Pei. She died shortly after his thirteenth birthday, and he was profoundly upset. The children were sent to live with extended family, as their father became more consumed by his work. Pei said: \"My father began living his own separate life pretty soon after that.\" His father later married a woman named Aileen, who moved to New York later in her life.\nEducation and formative years.\nAs Pei neared the end of his secondary education, he decided to attend university. He was accepted by a number of schools, but enrolled at the University of Pennsylvania. Pei's choice had two roots. While studying in Shanghai, he had closely examined the catalogs for various institutions of higher learning around the world. The architectural program at the University of Pennsylvania stood out to him. The other major factor was Hollywood. Pei was fascinated by the representations of college life in the films of Bing Crosby, which differed tremendously from the academic atmosphere in China. \"College life in the U.S. seemed to me to be mostly fun and games\", he said in 2000. \"Since I was too young to be serious, I wanted to be part of it\u00a0... You could get a feeling for it in Bing Crosby's movies. College life in America seemed very exciting to me. It's not real, we know that. Nevertheless, at that time it was very attractive to me.\" Pei added that \"Crosby's films in particular had a tremendous influence on my choosing the United States instead of England to pursue my education.\"\nIn 1935, Pei boarded a boat and sailed to San Francisco, then traveled by train to Philadelphia. What he found once he arrived differed vastly from his expectations. Professors at the University of Pennsylvania based their teaching in the Beaux-Arts style, rooted in the classical traditions of ancient Greece and Rome. Pei was more intrigued by modern architecture, and also felt intimidated by the high level of drafting proficiency shown by other students. He decided to abandon architecture and transferred to the engineering program at Massachusetts Institute of Technology (MIT). Once he arrived, however, the dean of the architecture school commented on his eye for design and convinced Pei to return to his original major.\nMIT's architecture faculty was also focused on the Beaux-Arts school, and Pei found himself uninspired by the work. In the library he found three books by the Swiss-French architect Le Corbusier. Pei was inspired by the innovative designs of the new International Style, characterized by simplified form and the use of glass and steel materials. Le Corbusier visited MIT in November 1935, an occasion which powerfully affected Pei: \"The two days with Le Corbusier, or 'Corbu' as we used to call him, were probably the most important days in my architectural education.\" Pei was also influenced by the work of U.S. architect Frank Lloyd Wright. In 1938 he drove to Spring Green, Wisconsin, to visit Wright's famous Taliesin building. After waiting for two hours, however, he left without meeting Wright.\nAlthough he disliked the Beaux-Arts emphasis, Pei excelled in his studies. \"I certainly don't regret the time at MIT\", he said later. \"There I learned the science and technique of building, which is just as essential to architecture.\" Pei received his BArch degree in 1940; his thesis was titled \"Standardized Propaganda Units for War Time and Peace Time China\".\nWhile visiting New York City in the late 1930s, Pei met a Wellesley College student named Eileen Loo. They began dating and married in the spring of 1942. She enrolled in the landscape architecture program at Harvard University, and Pei was thus introduced to members of the faculty at Harvard's Graduate School of Design (GSD). He was excited by the lively atmosphere and joined the GSD in December 1942.\nLess than a month later, Pei suspended his work at Harvard to join the National Defense Research Committee, which coordinated scientific research into U.S. weapons technology during World War\u00a0II. Pei's background in architecture was seen as a considerable asset; one member of the committee told him: \"If you know how to build you should also know how to destroy.\" The fight against Germany was ending, so he focused on the Pacific War. The U.S. realized that its bombs used against the stone buildings of Europe would be ineffective against Japanese cities, mostly constructed from wood and paper; Pei was assigned to work on incendiary bombs. Pei spent two and a half years with the NDRC, but revealed few details of his work.\nIn 1945, Eileen gave birth to a son, T'ing Chung, and she withdrew from the landscape architecture program in order to care for him. Pei returned to Harvard in the autumn of 1945, and received a position as assistant professor of design. The GSD was developing into a hub of resistance to the Beaux-Arts orthodoxy. At the center were members of the Bauhaus, a European architectural movement that had advanced the cause of modernist design. The Nazi regime had condemned the Bauhaus school, and its leaders left Germany. Two of them, Walter Gropius and Marcel Breuer, took positions at the Harvard GSD. Their iconoclastic focus on modern architecture appealed to Pei, and he worked closely with both men.\nOne of Pei's design projects at the GSD was a plan for an art museum in Shanghai. He wanted to create a mood of Chinese authenticity in the architecture without using traditional materials or styles. The design was based on straight modernist structures, organized around a central courtyard garden, with other similar natural settings arranged nearby. It was very well received, with Gropius calling it \"the best thing done in [my] master class.\" Pei received his MArch degree in 1946, and taught at Harvard for another two years.\nCareer.\n1948\u20131956: early career with Webb and Knapp.\nIn the spring of 1948, Pei was recruited by New York real estate magnate William Zeckendorf to join a staff of architects for his firm of Webb and Knapp to design buildings around the country. Pei found Zeckendorf's personality the opposite of his own; his new boss was known for his loud speech and gruff demeanor. Nevertheless, they became good friends and Pei found the experience personally enriching. Zeckendorf was well connected politically, and Pei enjoyed learning about the social world of New York's city planners.\nHis first project for Webb and Knapp was an apartment building, which received funding from the Housing Act of 1949. Pei's design was based on a circular tower with concentric rings. The areas closest to the supporting pillar handled utilities and circulation, and the apartments themselves were located toward the outer edge. Zeckendorf loved the design and even showed it off to Le Corbusier when they met. The cost of such an unusual design was too high, however, and the building never progressed beyond the model stage.\nPei finally saw his architecture come to life in 1949, when he designed a two-story corporate building for Gulf Oil in Atlanta, Georgia. The building was demolished in February 2013 although the front fa\u00e7ade was retained as part of an apartment development. His use of marble for the exterior curtain wall brought praise from the journal \"Architectural Forum\". Pei's designs echoed the work of Mies van der Rohe in the beginning of his career as also shown in his own weekend-house in Katonah, New York in 1952. Soon, Pei was so inundated with projects that he asked Zeckendorf for assistants, which he chose from his associates at the GSD, including Henry N. Cobb and Ulrich Franzen. They set to work on a variety of proposals, including the Roosevelt Field Shopping Mall on Long Island. The team also redesigned the Webb and Knapp office building, transforming Zeckendorf's office into a circular space with teak walls and a glass clerestory. They also installed a control panel into the desk that allowed their boss to control the lighting in his office. The project took one year and exceeded its budget, but Zeckendorf was delighted with the results.\nIn 1952, Pei and his team began work on a series of projects in Denver, Colorado. The first of these was the Mile High Center, which compressed the core building into less than 25 percent of the total site; the rest is adorned with an exhibition hall and fountain-dotted plazas. One block away, Pei's team also redesigned Denver's Courthouse Square, which combined office spaces, commercial venues, and hotels. These projects helped Pei conceptualize architecture as part of the larger urban geography: \"I learned the process of development, and about the city as a living organism.\" These lessons, he said, became essential for later projects.\nPei and his team also designed a united urban area for Washington, D.C., called L'Enfant Plaza (named for French-American architect Pierre Charles L'Enfant). Pei's associate Araldo Cossutta was the lead architect for the plaza's North Building and South Building. Vlastimil Koubek was the architect for the East Building (L'Enfant Plaza Hotel), and for the Center Building (now the United States Postal Service headquarters). The team set out with a broad vision that was praised by both \"The Washington Post\" and \"Washington Star\" (which rarely agreed on anything), but funding problems forced revisions and a significant reduction in scale.\nIn 1955, Pei's group took a step toward institutional independence from Webb and Knapp by establishing a new firm called I.\u00a0M. Pei &amp; Associates. (The name changed later to I.\u00a0M. Pei &amp; Partners.) They gained the freedom to work with other companies, but continued working primarily with Zeckendorf. The new firm distinguished itself through the use of detailed architectural models. They took on the Kips Bay residential area on the East Side of Manhattan, where Pei set up Kips Bay Towers, two large long towers of apartments with recessed windows (to provide shade and privacy) in a neat grid, adorned with rows of trees. Pei involved himself in the construction process at Kips Bay, even inspecting the bags of cement to check for consistency of color.\nThe company continued its urban focus with the Society Hill project in central Philadelphia. Pei designed the Society Hill Towers, a three-building residential block injecting cubist design into the local 18th-century milieu. As with previous projects, abundant green spaces were central to Pei's vision, which added traditional townhouses to aid the transition from classical to modern design.\nFrom 1958 to 1963, Pei and Ray Affleck developed a key downtown block of Montreal in a phased process that involved one of Pei's most admired structures in the Commonwealth, the cruciform tower known as the Royal Bank Plaza (Place Ville Marie). According to \"The Canadian Encyclopedia\" : &lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;its grand plaza and lower office buildings, designed by internationally famous US architect I. M. Pei, helped to set new standards for architecture in Canada in the 1960s ... The tower's smooth aluminum and glass surface and crisp unadorned geometric form demonstrate Pei's adherence to the mainstream of 20th-century modern design.\nAlthough those projects were satisfying, Pei wanted to establish an independent name for himself. In 1959, he was approached by MIT to design a building for its Earth science program. The Green Building continued the grid design of Kips Bay and Society Hill. The pedestrian walkway on the ground floor, however, was prone to sudden gusts of wind, which embarrassed Pei. \"Here I was from MIT,\" he said, \"and I didn't know about wind-tunnel effects.\" At the same time, he co-designed the Luce Memorial Chapel at Tunghai University in Taichung, Taiwan. The soaring structure, commissioned by the same organization that had run his middle school in Shanghai, broke severely from the cubist grid patterns of his urban projects.\nThe challenge of coordinating those projects took an artistic toll on Pei. He found himself responsible for acquiring new building contracts and supervising the plans for them. As a result, he felt disconnected from the actual creative work. \"Design is something you have to put your hand to,\" he said. \"While my people had the luxury of doing one job at a time, I had to keep track of the whole enterprise.\" Pei's dissatisfaction reached its peak at a time when financial problems began plaguing Zeckendorf's firm. I.\u00a0M. Pei and Associates officially broke from Webb and Knapp in 1960, which benefited Pei creatively but pained him personally. He had developed a close friendship with Zeckendorf, and both men were sad to part ways.\nNCAR and related projects.\nPei was able to return to hands-on design when he was approached in 1961 by Walter Orr Roberts to design the new Mesa Laboratory for the National Center for Atmospheric Research outside Boulder, Colorado. The project differed from Pei's earlier urban work because it rested in an open area in the foothills of the Rocky Mountains. He drove around the region with his wife, visiting assorted buildings and surveying the natural environs. He was impressed by the United States Air Force Academy in Colorado Springs, but felt it was \"detached from nature\".\nThe conceptualization stages were important for Pei, presenting a need and an opportunity to break from the Bauhaus tradition. He later recalled the long periods of time he spent in the area: \"I recalled the places I had seen with my mother when I was a little boy\u2014the mountaintop Buddhist retreats. There in the Colorado mountains, I tried to listen to the silence again\u2014just as my mother had taught me. The investigation of the place became a kind of religious experience for me.\" Pei also drew inspiration from the Mesa Verde cliff dwellings of the Ancestral Puebloans; he wanted the buildings to exist in harmony with their natural surroundings. To this end, he called for a rock-treatment process that could color the buildings to match the nearby mountains. He also set the complex back on the mesa overlooking the city, and designed the approaching road to be long, winding, and indirect.\nRoberts disliked Pei's initial designs, referring to them as \"just a bunch of towers\". Roberts intended his comments as typical of scientific experimentation, rather than artistic critique, but Pei was frustrated. His second attempt, however, fitted Roberts' vision perfectly: a spaced-out series of clustered buildings, joined by lower structures and complemented by two underground levels. The complex used many elements of cubist design, and the walkways were arranged to increase the probability of casual encounters among colleagues.\nOnce the laboratory was built, several problems with its construction became apparent. Leaks in the roof caused difficulties for researchers, and the shifting of clay soil beneath the building caused cracks which were expensive to repair. Still, both architect and project manager were pleased with the final result. Pei referred to the NCAR complex as his \"breakout building\", and he remained a friend of Roberts until the scientist died in March 1990.\nThe success of NCAR brought renewed attention to Pei's design acumen. He was recruited to work on a variety of projects, including the S. I. Newhouse School of Public Communications at Syracuse University, the Everson Museum of Art in Syracuse, New York, the Sundrome terminal at John F. Kennedy International Airport in New York City, and dormitories at New College of Florida.\nKennedy Library.\nAfter President John F. Kennedy was assassinated in November 1963, his family and friends discussed constructing a library that would serve as a fitting memorial. A committee was formed to advise Kennedy's widow Jacqueline, who would make the final decision. The group deliberated for months and considered many famous architects. Eventually, Kennedy chose Pei to design the library, based on two considerations. First, she appreciated the variety of ideas he had used for earlier projects. \"He didn't seem to have just one way to solve a problem,\" she said. \"He seemed to approach each commission thinking only of it and then develop a way to make something beautiful.\" Ultimately, however, Kennedy made her choice based on her personal connection with Pei. Calling it \"really an emotional decision\", she explained: \"He was so full of promise, like Jack; they were born in the same year. I decided it would be fun to take a great leap with him.\"\nThe project was plagued with problems from the outset. President Kennedy had begun considering the structure of his library soon after taking office, and he wanted to include archives from his administration, a museum of personal items, and a political science institute. After the assassination, the list expanded to include a fitting memorial tribute to the slain president. The variety of necessary inclusions complicated the design process and caused significant delays.\nPei's first proposed design included a large glass pyramid that would fill the interior with sunlight, meant to represent the optimism and hope that Kennedy's administration had symbolized for so many in the United States. Mrs. Kennedy liked the design, but resistance began in Cambridge, the first proposed site for the building, as soon as the project was announced. Many community members worried that the library would become a tourist attraction, causing particular problems with traffic congestion. Others worried that the design would clash with the architectural feel of nearby Harvard Square. By the mid-1970s, Pei tried proposing a new design, but the library's opponents resisted every effort. These events pained Pei, who had sent all three of his sons to Harvard, and although he rarely discussed his frustration, it was evident to his wife. \"I could tell how tired he was by the way he opened the door at the end of the day,\" she said. \"His footsteps were dragging. It was very hard for I.\u00a0M. to see that so many people didn't want the building.\"\nFinally the project moved to Columbia Point, near the University of Massachusetts Boston. The new site was less than ideal; it was located on an old landfill, and just over a large sewage pipe. Pei's architectural team added more fill to cover the pipe and developed an elaborate ventilation system to conquer the odor. A new design was unveiled, combining a large square glass-enclosed atrium with a triangular tower and a circular walkway.\nThe John F. Kennedy Presidential Library and Museum was dedicated on October 20, 1979. Critics generally liked the finished building, but the architect himself was unsatisfied. The years of conflict and compromise had changed the nature of the design, and Pei felt that the final result lacked its original passion. \"I wanted to give something very special to the memory of President Kennedy,\" he said in 2000. \"It could and should have been a great project.\" Pei's work on the Kennedy project boosted his reputation as an architect of note.\n\"Pei Plan\" in Oklahoma City.\nThe Pei Plan was a failed urban redevelopment initiative designed for downtown Oklahoma City, Oklahoma, in 1964. The plan called for the demolition of hundreds of old downtown structures in favor of renewed parking, office building, and retail developments, in addition to public projects such as the Myriad Convention Center and the Myriad Botanical Gardens. It was the dominant template for downtown development in Oklahoma City from its inception through the 1970s. The plan generated mixed results and opinion, largely succeeding in re-developing office building and parking infrastructure but failing to attract its anticipated retail and residential development. Significant public resentment also developed as a result of the destruction of multiple historic structures. As a result, Oklahoma City's leadership avoided large-scale urban planning for downtown throughout the 1980s and early 1990s, until the passage of the Metropolitan Area Projects (MAPS) initiative in 1993.\nProvidence's Cathedral Square.\nAnother city which turned to Pei for urban renewal during this time was Providence, Rhode Island. In the late 1960s, Providence hired Pei to redesign Cathedral Square, a once-bustling civic center which had become neglected and empty, as part of an ambitious larger plan to redesign downtown. Pei's new plaza, modeled after the Greek Agora marketplace, opened in 1972. The city ran out of money before Pei's vision could be fully realized. Also, recent construction of a low-income housing complex and Interstate 95 had changed the neighborhood's character permanently. In 1974, The Providence Evening Bulletin called Pei's new plaza a \"conspicuous failure\". By 2016, media reports characterized the plaza as a neglected, little-visited \"hidden gem\".\nAugusta, Georgia.\nIn 1974, the city of Augusta, Georgia turned to Pei and his firm for downtown revitalization. The Chamber of Commerce building and Bicentennial Park were completed from his plan. In 1976, Pei designed a distinctive modern penthouse that was added to the roof of architect William Lee Stoddart's historic Lamar Building, designed in 1916. In 1980, Pei and his company designed the Augusta Civic Center, now known as the James Brown Arena.\nDallas City Hall.\nKennedy's assassination also led indirectly to another commission for Pei's firm. In 1964 the acting mayor of Dallas, Erik Jonsson, began working to change the community's image. Dallas was known and disliked as the city where the president had been killed, but Jonsson began a program designed to initiate a community renewal. One of the goals was a new city hall, which could be a \"symbol of the people\". Jonsson, a co-founder of Texas Instruments, learned about Pei from his associate Cecil Howard Green, who had recruited the architect for MIT's Earth Sciences building.\nPei's approach to the new Dallas City Hall mirrored those of other projects; he surveyed the surrounding area and worked to make the building fit. In the case of Dallas, he spent days meeting with residents of the city and was impressed by their civic pride. He also found that the skyscrapers of the downtown business district dominated the skyline, and sought to create a building that could face the tall buildings and represent the importance of the public sector. He spoke of creating \"a public-private dialogue with the commercial high-rises\".\nWorking with his associate Theodore Musho, Pei developed a design centered on a building with a top much wider than the bottom; the facade leans at an angle of 34 degrees, which shades the building from the Texas sun. A plaza stretches out before the building, and a series of support columns holds it up. It was influenced by Le Corbusier's High Court building in Chandigarh, India; Pei sought to use the significant overhang to unify the building and plaza. The project cost much more than initially expected, and took 11 years to complete. Revenue was secured in part by including a subterranean parking garage. The interior of the city hall is large and spacious; windows in the ceiling above the eighth floor fill the main space with light.\nThe city of Dallas received the building well, and a local television news crew found unanimous approval of the new city hall when it officially opened to the public in 1978. Pei himself considered the project a success, even as he worried about the arrangement of its elements. He said: \"It's perhaps stronger than I would have liked; it's got more strength than finesse.\" He felt that his relative lack of experience left him without the necessary design tools to refine his vision, but the community liked the city hall enough to invite him back. Over the years he went on to design five additional buildings in the Dallas area.\nIn October 2025, city leaders began discussing the future of the Dallas city hall building, including an estimated $100 million in estimated deferred maintenance and repairs needed, some of which are serious enough to threaten the building's structural integrity. Among the considerations is a plan to demolish the building and make way for a new arena for the Dallas Mavericks.\nHancock Tower, Boston.\nWhile Pei and Musho were coordinating the Dallas project, their associate Henry Cobb had taken the helm for a commission in Boston. John Hancock Insurance chairman Robert Slater hired I.\u00a0M. Pei &amp; Partners to design a building that could overshadow the Prudential Tower, erected by their rival.\nAfter the firm's first plan was discarded due to a need for more office space, Cobb developed a new plan around a towering parallelogram, slanted away from the Trinity Church and accented by a wedge cut into each narrow side. To minimize the visual impact, the building was covered in large reflective glass panels; Cobb said this would make the building a \"background and foil\" to the older structures around it. When the Hancock Tower was finished in 1976, it was the tallest building in New England.\nSerious issues of execution became evident in the tower almost immediately. Many glass panels fractured in a windstorm during construction in 1973. Some detached and fell to the ground, causing no injuries but sparking concern among Boston residents. The entire tower was reglazed with smaller panels, significantly increasing costs. Hancock sued the glass manufacturers, Libbey-Owens-Ford, as well as I.\u00a0M. Pei &amp; Partners, for submitting plans that were \"not good and workmanlike\". LOF countersued Hancock for defamation, accusing Pei's firm of poor use of their materials; I.\u00a0M. Pei &amp; Partners sued LOF in return. All three companies settled out of court in 1981.\nThe project became an albatross for Pei's firm. Pei himself refused to discuss it for many years. The pace of new commissions slowed and the firm's architects began looking overseas for opportunities. Cobb worked in Australia and Pei took on jobs in Singapore, Iran, and Kuwait. Although it was a difficult time for everyone involved, Pei later reflected with patience on the experience. \"Going through this trial toughened us,\" he said. \"It helped to cement us as partners; we did not give up on each other.\"\nNational Gallery East Building, Washington, D.C..\nIn the mid-1960s, directors of the National Gallery of Art in Washington, D.C., declared the need for a new building. Paul Mellon, a primary benefactor of the gallery and a member of its building committee, set to work with his assistant J. Carter Brown (who became gallery director in 1969) to find an architect. The new structure would be located to the east of the original building, and tasked with two functions: offer a large space for public appreciation of various popular collections; and house office space as well as archives for scholarship and research. They likened the scope of the new facility to the Library of Alexandria. After inspecting Pei's work at the Des Moines Art Center in Iowa and the Johnson Museum at Cornell University, they offered him the commission.\nPei took to the project with vigor, and set to work with two young architects he had recently recruited to the firm, William Pedersen and Yann Weymouth. Their first obstacle was the unusual shape of the building site, a trapezoid of land at the intersection of Constitution and Pennsylvania Avenues. Inspiration struck Pei in 1968, when he scrawled a rough diagram of two triangles on a scrap of paper. The larger building would be the public gallery; the smaller would house offices and archives. This triangular shape became a singular vision for the architect. As the date for groundbreaking approached, Pedersen suggested to his boss that a slightly different approach would make construction easier. Pei simply smiled and said: \"No compromises.\"\nThe growing popularity of art museums presented unique challenges to the architecture. Mellon and Pei both expected large crowds of people to visit the new building, and they planned accordingly. To this end, Pei designed a large lobby roofed with enormous skylights. Individual galleries are located along the periphery, allowing visitors to return after viewing each exhibit to the spacious main room. A large mobile sculpture by American artist Alexander Calder was later added to the lobby. Pei hoped the lobby would be exciting to the public in the same way as the central room of the Guggenheim Museum is in New York City. The modern museum, he said later, \"must pay greater attention to its educational responsibility, especially to the young\".\nMaterials for the building's exterior were chosen with careful precision. To match the look and texture of the original gallery's marble walls, builders re-opened the quarry in Knoxville, Tennessee, from which the first batch of stone had been harvested. The project even found and hired Malcolm Rice, a quarry supervisor who had overseen the original 1941 gallery project. The marble was cut into three-inch-thick blocks and arranged over the concrete foundation, with darker blocks at the bottom and lighter blocks on top.\nThe East Building was honored on May 30, 1978, two days before its public unveiling, with a black-tie party attended by celebrities, politicians, benefactors, and artists. When the building opened, popular opinion was enthusiastic. Large crowds visited the new museum, and critics generally voiced their approval. Ada Louise Huxtable wrote in \"The New York Times\" that Pei's building was \"a palatial statement of the creative accommodation of contemporary art and architecture\". The sharp angle of the smaller building has been a particular note of praise for the public; over the years it has become stained and worn from the hands of visitors.\nSome critics disliked the unusual design, however, and criticized the reliance on triangles throughout the building. Others took issue with the large main lobby, particularly its attempt to lure casual visitors. In his review for \"Artforum\", critic Richard Hennessy described a \"shocking fun-house atmosphere\" and \"aura of ancient Roman patronage\". One of the earliest and most vocal critics, however, came to appreciate the new gallery once he saw it in person. Allan Greenberg had scorned the design when it was first unveiled, but wrote later to J. Carter Brown: \"I am forced to admit that you are right and I was wrong! The building is a masterpiece.\"\nFragrant Hills, China.\nAfter U.S. President Richard Nixon made his famous 1972 visit to China, a wave of exchanges took place between the two countries. One of these was a delegation of the American Institute of Architects in 1974, which Pei joined. It was his first trip back to China since leaving in 1935. He was favorably received, returned the welcome with positive comments, and a series of lectures ensued. Pei noted in one lecture that since the 1950s Chinese architects had been content to imitate Western styles; he urged his audience in one lecture to search China's native traditions for inspiration.\nIn 1978, Pei was asked to initiate a project for his home country. After surveying a number of different locations, Pei fell in love with a valley that had once served as an imperial garden and hunting preserve known as Fragrant Hills. The site housed a decrepit hotel; Pei was invited to tear it down and build a new one. As usual, he approached the project by carefully considering the context and purpose. Likewise, he considered modernist styles inappropriate for the setting. Thus, he said, it was necessary to find \"a third way\".\nAfter visiting his ancestral home in Suzhou, Pei created a design based on some simple but nuanced techniques he admired in traditional residential Chinese buildings. Among these were abundant gardens, integration with nature, and consideration of the relationship between enclosure and opening. Pei's design included a large central atrium covered by glass panels that functioned much like the large central space in his East Building of the National Gallery. Openings of various shapes in walls invited guests to view the natural scenery beyond. Younger Chinese who had hoped the building would exhibit some of Cubist flavor for which Pei had become known were disappointed, but the new hotel found more favor with government officials and architects.\nThe hotel, with 325 guest rooms and a four-story central atrium, was designed to fit perfectly into its natural habitat. The trees in the area were of special concern, and particular care was taken to cut down as few as possible. He worked with an expert from Suzhou to preserve and renovate a water maze from the original hotel, one of only five in the country. Pei was also meticulous about the arrangement of items in the garden behind the hotel; he even insisted on transporting of rocks from a location in southwest China to suit the natural aesthetic. An associate of Pei's said later that he never saw the architect so involved in a project.\nDuring construction, a series of mistakes collided with the nation's lack of technology to strain relations between architects and builders. Whereas 200\u00a0or so workers might have been used for a similar building in the US, the Fragrant Hill project employed over 3,000\u00a0workers. This was mostly because the construction company lacked the sophisticated machines used elsewhere. The problems continued for months, until Pei had an uncharacteristically emotional moment during a meeting with Chinese officials. He later explained that his actions included \"shouting and pounding the table\" in frustration. The design staff noticed a difference in the manner of work among the crew after the meeting. As the opening neared, however, Pei found the hotel still needed work. He began scrubbing floors with his wife and ordered his children to make beds and vacuum floors. The project's difficulties took an emotional and physical strain on the Pei family.\nThe Fragrant Hill Hotel opened on October 17, 1982, but quickly fell into disrepair. A member of Pei's staff returned for a visit several years later and confirmed the dilapidated condition of the hotel. He and Pei attributed this to the country's general unfamiliarity with deluxe buildings. The Chinese architectural community at the time gave the structure little attention, as their interest at the time centered on the work of American postmodernists such as Michael Graves.\nJavits Center, New York.\nAs the Fragrant Hill project neared completion, Pei began work on the Javits Center in New York City, for which his associate James Freed served as lead designer. Hoping to create a vibrant community institution in what was then a run-down neighborhood on Manhattan's west side, Freed developed a glass-coated structure with an intricate space frame of interconnected metal rods and spheres.\nThe convention center was plagued from the start by budget problems and construction blunders. City regulations forbid a general contractor having final authority over the project, so architects and program manager Richard Kahan had to coordinate the wide array of builders, plumbers, electricians, and other workers. The forged steel globes to be used in the space frame came to the site with hairline cracks and other defects: 12,000 were rejected. These and other problems led to media comparisons with the disastrous Hancock Tower. One New York City official blamed Kahan for the difficulties, indicating that the building's architectural flourishes were responsible for delays and financial crises. The Javits Center opened on April 3, 1986, to a generally positive reception.\nGrand Louvre, Paris.\nWhen Fran\u00e7ois Mitterrand was elected President of France in 1981, he laid out an ambitious plan for a variety of construction projects. One of these was the renovation of the Louvre. Mitterrand appointed a civil servant named \u00c9mile Biasini to oversee it. After visiting museums in Europe and the United States, including the U.S. National Gallery, he asked Pei to join the team. The architect made three secretive trips to Paris, to determine the feasibility of the project; only one museum employee knew why he was there. Pei finally agreed that a new construction project was not only possible, but necessary for the future of the museum. He thus became the first foreign architect to work on the Louvre.\nThe heart of the new design included not only a renovation of the Cour Napol\u00e9on in the midst of the buildings, but also a transformation of the interiors. Pei proposed a central entrance, not unlike the lobby of the National Gallery East Building, which would link the three major wings around the central space. Below would be a complex of additional floors for research, storage, and maintenance purposes. At the center of the courtyard he designed a glass and steel pyramid, first proposed with the Kennedy Library, to serve as entrance and anteroom skylight. It was mirrored by an inverted pyramid to the west, to reflect sunlight into the complex. These designs were partly an homage to the fastidious geometry of the French landscape architect Andr\u00e9 Le N\u00f4tre. Pei also found the pyramid shape best suited for stable transparency, and considered it \"most compatible with the architecture of the Louvre, especially with the faceted planes of its roofs\".\nBiasini and Mitterrand liked the plans, but the scope of the renovation displeased Louvre administrator Andr\u00e9 Chabaud. He resigned from his post, complaining that the project was \"unfeasible\" and posed \"architectural risks\". Some sections of the French public also reacted harshly to the design, mostly because of the proposed pyramid. One critic called it a \"gigantic, ruinous gadget\"; another charged Mitterrand with \"despotism\" for inflicting Paris with the \"atrocity\". Pei estimated that 90\u00a0percent of Parisians opposed his design. \"I received many angry glances in the streets of Paris,\" he said. Some condemnations carried nationalistic overtones. One opponent wrote: \"I am surprised that one would go looking for a Chinese architect in America to deal with the historic heart of the capital of France.\"\nSoon, however, Pei and his team won the support of several key cultural icons, including the conductor Pierre Boulez and Claude Pompidou, widow of former French President Georges Pompidou, after whom the similarly controversial Centre Georges Pompidou was named. In an attempt to soothe public ire, Pei took a suggestion from then-mayor of Paris Jacques Chirac and placed a full-sized cable model of the pyramid in the courtyard. During the four days of its exhibition, an estimated 60,000\u00a0people visited the site. Some critics eased their opposition after witnessing the proposed scale of the pyramid.\nPei demanded a method of glass production that resulted in clear panes. The pyramid was constructed at the same time as the subterranean levels below, which caused difficulties during the building stages. As they worked, construction teams came upon an abandoned set of rooms containing 25,000\u00a0historical items; these were incorporated into the rest of the structure to add a new exhibition zone.\nThe new Cour Napol\u00e9on was opened to the public on October 14, 1988, and the Pyramid entrance was opened the following March. By this time, public opposition had softened; a poll found a 56 percent approval rating for the pyramid, with 23 percent still opposed. The newspaper \"Le Figaro\" had vehemently criticized Pei's design, but later celebrated the tenth anniversary of its magazine supplement at the pyramid. Prince Charles of Britain surveyed the new site with curiosity, and declared it \"marvelous, very exciting\". A writer in \"Le Quotidien de Paris\" wrote: \"The much-feared pyramid has become adorable.\"\nThe experience was exhausting for Pei, but also rewarding. \"After the Louvre,\" he said later, \"I thought no project would be too difficult.\" The pyramid achieved further widespread international recognition for its central role in the plot at the denouement of \"The Da Vinci Code\" by Dan Brown and its appearance in the final scene of the subsequent screen adaptation. The \"Louvre Pyramid\" became Pei's most famous structure.\nMeyerson Symphony Center, Dallas.\nThe opening of the Louvre Pyramid coincided with four other projects on which Pei had been working, prompting architecture critic Paul Goldberger to declare 1989 \"the year of Pei\" in \"The New York Times\". It was also the year in which Pei's firm changed its name to Pei Cobb Freed &amp; Partners, to reflect the increasing stature and prominence of his associates. At the age of 72, Pei had begun thinking about retirement, but continued working long hours to see his designs come to light.\nOne of the projects took Pei back to Dallas, Texas, to design the Morton H. Meyerson Symphony Center. The success of city's performing artists, particularly the Dallas Symphony Orchestra then led by conductor Eduardo Mata, led to interest by city leaders in creating a modern center for musical arts that could rival the best halls in Europe. The organizing committee contacted 45\u00a0architects, but at first Pei did not respond, thinking that his work on the Dallas City Hall had left a negative impression. One of his colleagues from that project, however, insisted that he meet with the committee. He did and, although it would be his first concert hall, the committee voted unanimously to offer him the commission. As one member put it: \"We were convinced that we would get the world's greatest architect putting his best foot forward.\"\nBecause its main purpose was the presentation of live music, the hall needed a design focused on acoustics first, then public access and exterior aesthetics. To this end, a professional sound technician was hired to design the interior. He proposed a shoebox auditorium, used in the acclaimed designs of top European symphony halls such as the Amsterdam Concertgebouw and Vienna Musikverein. Pei drew inspiration for his adjustments from the designs of the German architect Johann Balthasar Neumann, especially the Basilica of the Fourteen Holy Helpers. He also sought to incorporate some of the panache of the Paris Op\u00e9ra designed by Charles Garnier.\nPei's design placed the rigid shoebox at an angle to the surrounding street grid, connected at the north end to a long rectangular office building, and cut through the middle with an assortment of circles and cones. The design attempted to reproduce with modern features the acoustic and visual functions of traditional elements like filigree. The project was risky: its goals were ambitious and any unforeseen acoustic flaws would be virtually impossible to remedy after the hall's completion. Pei admitted that he did not completely know how everything would come together. \"I can imagine only 60\u00a0percent of the space in this building,\" he said during the early stages. \"The rest will be as surprising to me as to everyone else.\" As the project developed, costs rose steadily and some sponsors considered withdrawing their support. Billionaire tycoon Ross Perot made a donation of US$10\u00a0million, on the condition that it be named in honor of Morton H. Meyerson, the longtime patron of the arts in Dallas.\nThe building opened and immediately garnered widespread praise, especially for its acoustics. After attending a week of performances in the hall, a music critic for \"The New York Times\" wrote an enthusiastic account of the experience and congratulated the architects. One of Pei's associates told him during a party before the opening that the symphony hall was \"a very mature building\"; he smiled and replied: \"Ah, but did I have to wait this long?\"\nBank of China, Hong Kong.\nA new offer had arrived for Pei from the Chinese government in 1982. With an eye toward the handover of Hong Kong from the British in 1997, authorities in China sought Pei's aid on a new tower for the local branch of the Bank of China. The Chinese government was preparing for a new wave of engagement with the outside world and sought a tower to represent modernity and economic strength. Given the elder Pei's history with the bank before the Communist takeover, government officials visited the 89-year-old man in New York to gain approval for his son's involvement. Pei then spoke with his father at length about the proposal. Although the architect remained pained by his experience with Fragrant Hills, he agreed to accept the commission.\nThe proposed site in Hong Kong's Central District was less than ideal; a tangle of highways lined it on three sides. The area had also been home to a headquarters for Japanese military police during World War\u00a0II, and was notorious for prisoner torture. The small parcel of land made a tall tower necessary, and Pei had usually shied away from such projects; in Hong Kong especially, the skyscrapers lacked any real architectural character. Lacking inspiration and unsure of how to approach the building, Pei took a weekend vacation to the family home in Katonah, New York. There he found himself experimenting with a bundle of sticks until he happened upon a cascading sequence.\nPei felt that his design for the Bank of China Tower needed to reflect \"the aspirations of the Chinese people\". The design that he developed for the skyscraper was not only unique in appearance, but also sound enough to pass the city's rigorous standards for wind-resistance. The building is composed of four triangular shafts rising up from a square base, supported by a visible truss structure that distributes stress to the four corners of the base. Using the reflective glass that had become something of a trademark for him, Pei organized the facade around diagonal bracing in a union of structure and form that reiterates the triangle motif established in the plan. At the top, he designed the roofs at sloping angles to match the rising aesthetic of the building. Some influential advocates of \"feng shui\" in Hong Kong and China criticized the design, and Pei and government officials responded with token adjustments.\nAs the tower neared completion, Pei was shocked to witness the government's massacre of unarmed civilians at the Tiananmen Square protests of 1989. He wrote an opinion piece for \"The New York Times\" titled \"China Won't Ever Be the Same\", in which he said that the killings \"tore the heart out of a generation that carries the hope for the future of the country\". The massacre deeply disturbed his entire family, and he wrote that \"China is besmirched.\"\n1990\u20132019: museum projects.\nAs the 1990s began, Pei transitioned into a role of decreased involvement with his firm. The staff had begun to shrink, and Pei wanted to dedicate himself to smaller projects allowing for more creativity. Before he made this change, however, he set to work on his last major project as active partner: the Rock and Roll Hall of Fame in Cleveland, Ohio. Considering his work on such bastions of high culture as the Louvre and U.S. National Gallery, some critics were surprised by his association with what many considered a tribute to low culture. The sponsors of the hall, however, sought Pei for specifically this reason; they wanted the building to have an aura of respectability from the beginning. Pei accepted the commission in part because of the unique challenge it presented.\nUsing a glass wall for the entrance, similar in appearance to his Louvre pyramid, Pei coated the exterior of the main building in white metal, and placed a large cylinder on a narrow perch to serve as a performance space. The combination of off-centered wraparounds and angled walls was, Pei said, designed to provide \"a sense of tumultuous youthful energy, rebelling, flailing about\".\nThe building opened in 1995, and was received with moderate praise. \"The New York Times\" called it \"a fine building\", but Pei was among those who felt disappointed with the results. The museum's early beginnings in New York combined with an unclear mission created a fuzzy understanding among project leaders for precisely what was needed. Although the city of Cleveland benefited greatly from the new tourist attraction, Pei was unhappy with it.\nAt the same time, Pei designed a new museum for Luxembourg, the \"Mus\u00e9e d'art moderne Grand-Duc Jean\", commonly known as the Mudam. Drawing from the original shape of the Fort Th\u00fcngen walls where the museum was located, Pei planned to remove a portion of the original foundation. Public resistance to the historical loss forced a revision of his plan, however, and the project was nearly abandoned. The size of the building was halved, and it was set back from the original wall segments to preserve the foundation. Pei was disappointed with the alterations, but remained involved in the building process even during construction.\nIn 1995, Pei was hired to design an extension to the \"Deutsches Historisches Museum\", or German Historical Museum in Berlin. Returning to the challenge of the East Building of the U.S. National Gallery, Pei worked to combine a modernist approach with a classical main structure. He described the glass cylinder addition as a \"beacon\", and topped it with a glass roof to allow plentiful sunlight inside. Pei had difficulty working with German government officials on the project; their utilitarian approach clashed with his passion for aesthetics. \"They thought I was nothing but trouble\", he said.\nPei also worked at this time on two projects for a new Japanese religious movement called \"Shinji Shumeikai\". He was approached by the movement's spiritual leader, Kaishu Koyama, who impressed the architect with her sincerity and willingness to give him significant artistic freedom. One of the buildings was a bell tower, designed to resemble the \"bachi\" used when playing traditional instruments like the \"shamisen\". Pei was unfamiliar with the movement's beliefs, but explored them in order to represent something meaningful in the tower. As he said: \"It was a search for the sort of expression that is not at all technical.\"\nThe experience was rewarding for Pei, and he agreed immediately to work with the group again. The new project was the Miho Museum, to display Koyama's collection of tea ceremony artifacts. Pei visited the site in Shiga Prefecture, and during their conversations convinced Koyama to expand her collection. She conducted a global search and acquired more than 300\u00a0items showcasing the history of the Silk Road.\nOne major challenge was the approach to the museum. The Japanese team proposed a winding road up the mountain, not unlike the approach to the NCAR building in Colorado. Instead, Pei ordered a hole cut through a nearby mountain, connected to a major road via a bridge suspended from ninety-six steel cables and supported by a post set into the mountain. The museum itself was built into the mountain, with 80\u00a0percent of the building underground.\nWhen designing the exterior, Pei borrowed from the tradition of Japanese temples, particularly those found in nearby Kyoto. He created a concise spaceframe wrapped into French limestone and covered with a glass roof. Pei also oversaw specific decorative details, including a bench in the entrance lobby, carved from a 350-year-old \"keyaki\" tree. Because of Koyama's considerable wealth, money was rarely considered an obstacle; estimates at the time of completion put the cost of the project at US$350\u00a0million.\nDuring the first decade of the 2000s, Pei designed a variety of buildings, including the Suzhou Museum near his childhood home. He also designed the Museum of Islamic Art in Doha, Qatar, at the request of the Al-Thani Family. Although it was originally planned for the corniche road along Doha Bay, Pei convinced the project coordinators to build a new island to provide the needed space. He then spent six months touring the region and surveying mosques in Spain, Syria, and Tunisia. He was especially impressed with the elegant simplicity of the Mosque of Ibn Tulun in Cairo.\nOnce again, Pei sought to combine new design elements with the classical aesthetic most appropriate for the location of the building. The sand-colored rectangular boxes rotate evenly to create a subtle movement, with small arched windows at regular intervals into the limestone exterior. Inside, galleries are arranged around a massive atrium, lit from above. The museum's coordinators were pleased with the project; its official website describes its \"true splendour unveiled in the sunlight,\" and speaks of \"the shades of colour and the interplay of shadows paying tribute to the essence of Islamic architecture\".\nThe Macao Science Center in Macau was designed by Pei Partnership Architects in association with I. M. Pei. The project to build the science center was conceived in 2001 and construction started in 2006. The center was completed in 2009 and opened by the Chinese President Hu Jintao. The main part of the building is a distinctive conical shape with a spiral walkway and large atrium inside, similar to that of the Solomon R. Guggenheim Museum in New York City. Galleries lead off the walkway, mainly consisting of interactive exhibits aimed at science education. The building is in a prominent position by the sea and is now a Macau landmark.\nPei's career ended with his death in May 2019, at 102 years of age.\nStyle and method.\nPei's style was described as thoroughly modernist, with significant cubist themes. He was known for combining traditional architectural principles with progressive designs based on simple geometric patterns\u2014circles, squares, and triangles are common elements of his work in both plan and elevation. As one critic wrote: \"Pei has been aptly described as combining a classical sense of form with a contemporary mastery of method.\" In 2000, biographer Carter Wiseman called Pei \"the most distinguished member of his Late-Modernist generation still in practice\". At the same time, Pei himself rejected simple dichotomies of architectural trends. He once said: &lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The talk about modernism versus post-modernism is unimportant. It's a side issue. An individual building, the style in which it is going to be designed and built, is not that important. The important thing, really, is the community. How does it affect life?\nPei's work is celebrated throughout the world of architecture. His colleague John Portman once told him: \"Just once, I'd like to do something like the East Building.\" But this originality did not always bring large financial reward; as Pei replied to the successful architect: \"Just once, I'd like to make the kind of money you do.\" His concepts, moreover, were too individualized and dependent on context to have given rise to a particular school of design. Pei referred to his own \"analytical approach\" when explaining the lack of a \"Pei School\".\n\"For me,\" he said, \"the important distinction is between a stylistic approach to the design; and an analytical approach giving the process of due consideration to time, place, and purpose\u00a0... My analytical approach requires a full understanding of the three essential elements\u00a0... to arrive at an ideal balance among them.\"\nAwards and honors.\nIn the words of his biographer, Pei won \"every award of any consequence in his art\", including the Arnold Brunner Award from the National Institute of Arts and Letters (1963), the Gold Medal for Architecture from the American Academy of Arts and Letters (1979), the AIA Gold Medal (1979), the first \"Praemium Imperiale\" for Architecture from the Japan Art Association (1989), the Lifetime Achievement Award from the Cooper-Hewitt, National Design Museum, the 1998 Edward MacDowell Medal in the Arts, and the 2010 Royal Gold Medal from the Royal Institute of British Architects. In 1983 he was awarded the Pritzker Prize, sometimes referred to as the Nobel Prize of architecture. In its citation, the jury said: \"Ieoh Ming Pei has given this century some of its most beautiful interior spaces and exterior forms\u00a0... His versatility and skill in the use of materials approach the level of poetry.\" The prize was accompanied by a US$100,000\u00a0award, which Pei used to create a scholarship for Chinese students to study architecture in the U.S., on the condition that they return to China to work. In 1986, he was one of twelve recipients of the Medal of Liberty. When he was awarded the 2003 Henry C. Turner Prize by the National Building Museum, museum board chair Carolyn Brody praised his impact on construction innovation: \"His magnificent designs have challenged engineers to devise innovative structural solutions, and his exacting expectations for construction quality have encouraged contractors to achieve high standards.\" In December 1992, Pei was awarded the Presidential Medal of Freedom by President George H. W. Bush. In 1996, Pei became the first person to be elected a foreign member of the Chinese Academy of Engineering. Pei was also an elected member of the American Academy of Arts and Sciences and the American Philosophical Society.\nPersonal life.\nPei's wife, Eileen Loo, died on June 20, 2014. Together they had three sons, T'ing Chung (1945\u20132003), Chien Chung (1946\u20132023; known as Didi), and Li Chung (b. 1949; known as Sandi); and a daughter, Liane (b. 1960). T'ing Chung was an urban planner and alumnus of his father's alma mater MIT and Harvard. Chieng Chung and Li Chung, who are both Harvard Graduate School of Design alumni, founded and run Pei Partnership Architects. Liane is a lawyer.\nPei was considered an influential representative of Chinese Americans. At the recommendation of Henry Kissinger, he founded the Committee of 100, an organization of prominent Chinese Americans which advocates for closer relations between the United States and Greater China, in 1989.\nIn 2015, Pei's home health aide, Eter Nikolaishvili, grabbed Pei's right forearm and twisted it, resulting in bruising and bleeding and necessitating hospital treatment. Pei alleged that the assault occurred when Pei threatened to call the police about Nikolaishvili. Nikolaishvili agreed to plead guilty in 2016.\nPei celebrated his 100th birthday on April 26, 2017. He died at his Manhattan apartment on May 16, 2019, at the age of 102.\nReferences.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "15156", "revid": "1215648696", "url": "https://en.wikipedia.org/wiki?curid=15156", "title": "ICD (disambiguation)", "text": "ICD is the International Statistical Classification of Diseases and Related Health Problems, an international standard diagnostic tool.\nICD may also refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "15157", "revid": "8066546", "url": "https://en.wikipedia.org/wiki?curid=15157", "title": "ICD-CM", "text": ""}
{"id": "15158", "revid": "1277490915", "url": "https://en.wikipedia.org/wiki?curid=15158", "title": "Islamic Jihad", "text": "Islamic Jihad may refer to:\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "15161", "revid": "35498457", "url": "https://en.wikipedia.org/wiki?curid=15161", "title": "I486", "text": "Successor to the Intel 386\nThe Intel 486, officially named i486 and also known as 80486, is a microprocessor introduced in 1989. It is a higher-performance follow-up to the Intel 386. It represents the fourth generation of binary compatible CPUs following the 8086 of 1978, the Intel 80286 of 1982, and 1985's i386.\nIt was the first tightly-pipelined x86 design as well as the first x86 chip to include more than one million transistors. It offered a large on-chip cache and an integrated floating-point unit. When it was announced, the initial performance was originally published between 15 and 20 VAX MIPS, between 37,000 and 49,000 dhrystones per second, and between 6.1 and 8.2 double-precision megawhetstones per second for both 25 and 33\u00a0MHz version. A typical 50\u00a0MHz i486 executes 41\u00a0million instructions per second Dhrystone MIPS and SPEC integer rating of 27.9. It is approximately twice as fast as the i386 or i286 per clock cycle. The i486's improved performance is thanks to its five-stage pipeline with all stages bound to a single cycle. The enhanced FPU unit on the chip was significantly faster than the i387 FPU per cycle. The i387 FPU was a separate, optional math coprocessor installed in a motherboard socket alongside the i386.\nThe i486 was succeeded by the original Pentium. Orders were discontinued for the i486 on March 30, 2007 and the last shipments were on September 28, 2007.\nHistory.\nThe concept of this microprocessor generation was discussed with Pat Gelsinger and John Crawford shortly after the release of 386 processor in 1985. The team started the computer simulation in early 1987. They finalized the logic and microcode function during 1988. The team finalized the database in February 1989 until the tape out on March 1. They received the first silicon from the fabrication on March 20.\nThe i486 was announced at Spring Comdex on April 10, 1989. At the announcement, Intel stated that samples would be available in the third quarter and production quantities would ship in the fourth quarter. The first i486-based PCs were announced in late 1989.\nIn fall of 1991, Intel introduced the 50 MHz i486\u00a0DX using the three layer 800\u00a0nm process CHMOS-V technology. They were available for US$665 in 1,000-unit quantities.\nIn that season, Intel introduced low-power 25 MHz Intel486\u00a0DX microprocessor. This one was available for US$471. Also, there were low-power 16, 20, and 25\u00a0MHz Intel486\u00a0SX microprocessors. They were available at $235, $266, and $366 for these frequency range respectively. All pricing were in quantities of 1,000 pieces. These low-power microprocessors have power consumption reduced by 50\u201375% compared to similar regular versions of these CPUs.\nThe first major update to the i486 design came in March 1992 with the release of the clock-doubled 486DX2 series. It was the first time that the CPU core clock frequency was separated from the system bus clock frequency by using a dual clock multiplier, supporting 486DX2 chips at 40 and 50\u00a0MHz. The faster 66\u00a0MHz 486DX2-66 was released that August.\nThe fifth-generation Pentium processor launched in 1993, while Intel continued to produce i486 processors, including the triple-clock-rate 486DX4-100 with a 100\u00a0MHz clock speed and a L1 cache doubled to 16\u00a0KB.\nEarlier, Intel had decided not to share its 80386 and 80486 technologies with AMD. However, AMD believed that their technology sharing agreement extended to the 80386 as a derivative of the 80286. AMD reverse-engineered the 386 and produced the 40\u00a0MHz Am386DX-40 chip, which was cheaper and had lower power consumption than Intel's best 33\u00a0MHz version. Intel attempted to prevent AMD from selling the processor, but AMD won in court, which allowed it to establish itself as a competitor.\nAfter 386 competitors appeared, Intel in 1992 lowered the price of the 25-MHz 80486SX to less than that of the 33-MHz 80386. An industry analyst said that Intel wanted customers to move to the competition-free 486. The strategy was very successful; by 1993 Dell reported that 80486-based computers were 70% of sales. AMD continued to create clones, releasing the first-generation Am486 chip in April 1993 with clock frequencies of 25, 33 and 40\u00a0MHz. Second-generation Am486DX2 chips with 50, 66 and 80\u00a0MHz clock frequencies were released the following year. The Am486 series was completed with a 120\u00a0MHz DX4 chip in 1995.\nAMD's long-running 1987 arbitration lawsuit against Intel was settled in 1995, and AMD gained access to Intel's 80486 microcode. This led to the creation of two versions of AMD's 486 processor\u00a0\u2013 one reverse-engineered from Intel's microcode, while the other used AMD's microcode in a clean-room design process. However, the settlement also concluded that the 80486 would be AMD's last Intel clone.\nAnother 486 clone manufacturer was Cyrix, which was a fabless co-processor chip maker for 80286/386 systems. The first Cyrix 486 processors, the 486SLC and 486DLC, were released in 1992 and used the 80386 package. Both Texas Instruments-manufactured Cyrix processors were pin-compatible with 386SX/DX systems, which allowed them to become an upgrade option. However, these chips could not match the Intel 486 processors, having only 1\u00a0KB of cache memory and no built-in math coprocessor. In 1993, Cyrix released its own Cx486DX and DX2 processors, which were closer in performance to Intel's counterparts. Intel and Cyrix sued each other, with Intel filing for patent infringement, and Cyrix for antitrust claims. In 1994, Cyrix won the patent infringement case and dropped its antitrust claim.\nIn 1995, both Cyrix and AMD began looking at a ready market for users wanting to upgrade their processors. Cyrix released a derivative 486 processor called the 5x86, based on the Cyrix M1 core, which was clocked up to 120\u00a0MHz and was an option for 486 Socket\u00a03 motherboards. AMD released a 133\u00a0MHz Am5x86 upgrade chip, which was essentially an improved 80486 with double the cache and a quad multiplier that also worked with the original 486DX motherboards. Am5x86 was the first processor to use AMD's performance rating and was marketed as Am5x86-P75, with claims that it was equivalent to the Pentium\u00a075. Kingston Technology launched a \"TurboChip\" 486 system upgrade that used a 133\u00a0MHz Am5x86.\nIntel responded by making a Pentium OverDrive upgrade chip for 486 motherboards, which was a modified Pentium core that ran up to 83\u00a0MHz on boards with a 25 or 33\u00a0MHz front-side bus clock. OverDrive wasn't popular due to speed and price. New computers equipped with 486 processors in discount warehouses became scarce, and an IBM spokesperson called it a \"dinosaur\". Even after the Pentium series of processors gained a foothold in the market, however, Intel continued to produce 486 cores for industrial embedded applications. Intel discontinued production of i486 processors in late 2007.\nImprovements.\nThe instruction set of the i486 is very similar to the i386, with the addition of a few extra instructions, such as CMPXCHG, a compare-and-swap atomic operation, and XADD, a fetch-and-add atomic operation that returned the original value (unlike a standard ADD, which returns flags only). This generation CPU has brought up to 156 different instructions listing.\nThe i486's performance architecture is a vast improvement over the i386. It has an on-chip unified instruction and data cache, an on-chip floating-point unit (FPU) and an enhanced bus interface unit. Due to the tight pipelining, sequences of simple instructions (such as codice_1 and codice_2) could sustain single-clock-cycle throughput (one instruction completed every clock). In other words, it was running about 1.8 clocks per instruction. These improvements yielded a rough doubling in integer ALU performance over the i386 at the same clock rate. A 16\u00a0MHz i486 therefore had performance similar to a 33\u00a0MHz i386. The combination of both CPU and FPU housed on a single die results in bus utilization rates of 50% for the 25 MHz Intel486 version. In other words, with the combination of both CPU and MCP (math coprocessor) provides 40% more performance than with both Intel386 DX and Intel387 DX math coprocessor combined. The older design had to reach 50\u00a0MHz to be comparable with a 25\u00a0MHz i486 part.\nDifferences between i386 and i486.\nJust as in the i386, a flat 4\u00a0GB memory model could be implemented. All \"segment selector\" registers could be set to a neutral value in protected mode, or to zero in real mode, and using only the 32-bit \"offset registers\" (x86-terminology for general CPU registers used as address registers) as a linear 32-bit virtual address bypassing the segmentation logic. Virtual addresses were then normally mapped onto physical addresses by the paging system except when it was disabled (\"real\" mode had no \"virtual\" addresses). Just as with the i386, circumventing memory segmentation could substantially improve performance for some operating systems and applications.\nOn a typical PC motherboard, either four matched 30-pin (8-bit) SIMMs or one 72-pin (32-bit) SIMM per bank were required to fit the i486's 32-bit data bus. The address bus used 30-bits (A31..A2) complemented by four byte-select pins (instead of A0,A1) to allow for any 8/16/32-bit selection. This meant that the limit of directly addressable physical memory was 4\u00a0gigabytes as well (230 \"32-bit\" words = 232 \"8-bit\" words).\nModels.\nIntel offered several suffixes and variants (see table). Variants include:\nThe maximal internal clock frequency (on Intel's versions) ranged from 16 to 100\u00a0MHz. The 16\u00a0MHz i486SX model was used by Dell Computers.\nOne of the few i486 models specified for a 50\u00a0MHz bus (486DX-50) initially had overheating problems and was moved to the 0.8-micrometer fabrication process. However, problems continued when the 486DX-50 was installed in local-bus systems due to the high bus speed, making it unpopular with mainstream consumers. Local-bus video was considered a requirement at the time, though it remained popular with users of EISA systems. The 486DX-50 was soon eclipsed by the clock-doubled i486DX2, which although running the internal CPU logic at twice the external bus speed (50\u00a0MHz), was nevertheless slower because the external bus ran at only 25\u00a0MHz. The i486DX2 at 66\u00a0MHz (with 33\u00a0MHz external bus) was faster than the 486DX-50, overall.\nMore powerful i486 iterations such as the OverDrive and DX4 were less popular (the latter available as an OEM part only), as they came out after Intel had released the next-generation Pentium processor family. Certain steppings of the DX4 also officially supported 50\u00a0MHz bus operation, but it was a seldom-used feature.\nOther makers of 486-like CPUs.\nProcessors compatible with the i486 were produced by companies such as IBM, Texas Instruments, AMD, Cyrix, UMC, and STMicroelectronics (formerly SGS-Thomson). Some were clones (identical at the microarchitectural level), others were clean room implementations of the Intel instruction set. (IBM's multiple-source requirement was one of the reasons behind its x86 manufacturing since the 80286.) The i486 was, however, covered by many Intel patents, including from the prior i386. Intel and IBM had broad cross-licenses of these patents, and AMD was granted rights to the relevant patents in the 1995 settlement of a lawsuit between the companies.\nAMD produced several clones using a 40\u00a0MHz bus (486DX-40, 486DX/2-80, and 486DX/4-120) which had no Intel equivalent, as well as a part specified for 90\u00a0MHz, using a 30\u00a0MHz external clock, that was sold only to OEMs. The fastest running i486-compatible CPU, the Am5x86, ran at 133\u00a0MHz and was released by AMD in 1995. 150\u00a0MHz and 160\u00a0MHz parts were planned but never officially released.\nCyrix made a variety of i486-compatible processors, positioned at the cost-sensitive desktop and low-power (laptop) markets. Unlike AMD's 486 clones, the Cyrix processors were the result of clean-room reverse engineering. Cyrix's early offerings included the 486DLC and 486SLC, two hybrid chips that plugged into 386DX or SX sockets respectively, and offered 1\u00a0KB of cache (versus 8\u00a0KB for the then-current Intel/AMD parts). Cyrix also made \"real\" 486 processors, which plugged into the i486's socket and offered 2 or 8\u00a0KB of cache. Clock-for-clock, the Cyrix-made chips were generally slower than their Intel/AMD equivalents, though later products with 8\u00a0KB caches were more competitive, albeit late to market.\nThe Motorola 68040, while not i486 compatible, was often positioned as its equivalent in features and performance. Clock-for-clock basis the Motorola 68040 could significantly outperform the Intel chip. However, the i486 had the ability to be clocked significantly faster without overheating. Motorola 68040 performance lagged behind the later production i486 systems.\nMotherboards and buses.\nEarly i486-based computers were equipped with several ISA slots (using an emulated PC/AT-bus) and sometimes one or two 8-bit-only slots (compatible with the PC/XT-bus). Many motherboards enabled overclocking of these from the default 6 or 8\u00a0MHz to perhaps 16.7 or 20\u00a0MHz (half the i486 bus clock) in several steps, often from within the BIOS setup. Especially older peripheral cards normally worked well at such speeds as they often used standard MSI chips instead of slower (at the time) custom VLSI designs. This could give significant performance gains (such as for old video cards moved from a 386 or 286 computer, for example). However, operation beyond 8 or 10\u00a0MHz could sometimes lead to stability problems, at least in systems equipped with SCSI or sound cards.\nSome motherboards came equipped with a 32-bit EISA bus that was backward compatible with the ISA-standard. EISA offered attractive features such as increased bandwidth, extended addressing, IRQ sharing, and card configuration through software (rather than through jumpers, DIP switches, etc.) However, EISA cards were expensive and therefore mostly employed in servers and workstations. Consumer desktops often used the simpler, faster VESA Local Bus (VLB). Unfortunately prone to electrical and timing-based instability; typical consumer desktops had ISA slots combined with a single VLB slot for a video card. VLB was gradually replaced by PCI during the final years of the i486 period. Few Pentium class motherboards had VLB support as VLB was based directly on the i486 bus; much different from the P5 Pentium-bus. ISA persisted through the P5 Pentium generation and was not completely displaced by PCI until the Pentium III era, although ISA persisted well into the Pentium 4 era, especially among industrial PCs.\nLate i486 boards were normally equipped with both PCI and ISA slots, and sometimes a single VLB slot. In this configuration, VLB or PCI throughput suffered depending on how buses were bridged. Initially, the VLB slot in these systems was usually fully compatible only with video cards (fitting as \"VESA\" stands for \"Video Electronics Standards Association\"); VLB-IDE, multi I/O, or SCSI cards could have problems on motherboards with PCI slots. The VL-Bus operated at the same clock speed as the i486-bus (basically a local bus) while the PCI bus also usually depended on the i486 clock but sometimes had a divider setting available via the BIOS. This could be set to 1/1 or 1/2, sometimes even 2/3 (for 50\u00a0MHz CPU clocks). Some motherboards limited the PCI clock to the specified maximum of 33\u00a0MHz and certain network cards depended on this frequency for correct bit-rates. The ISA clock was typically generated by a divider of the CPU/VLB/PCI clock.\nThe earliest hardware product to use the i486 chip was IBM's 486/25 Power Platform, a CPU card that plugged into their PS/2 Model 70 386 in order to upgrade it to a 25-MHz i486. Introduced in October 1989, it was recalled a few weeks after its release after reports of bugs in initial batches of the i486 were confirmed by Intel. The first complete computer system to use the i486 chip was the Apricot VX FT, produced by British hardware manufacturer Apricot Computers and released in late 1989.\nLater i486 boards supported Plug-And-Play, a specification designed by Microsoft that began as a part of Windows 95 to make component installation easier for consumers.\nSome mid-end and high-end i486 motherboards can include L2 cache integrated in motherboard.\nObsolescence.\nThe AMD Am5x86 and Cyrix Cx5x86 were the last i486 processors often used in late-generation i486 motherboards. They came with PCI slots and 72-pin SIMMs that were designed to run Windows 95, and also used for 80486 motherboards upgrades. While the Cyrix Cx5x86 faded when the Cyrix 6x86 took over, the AMD Am5x86 remained important given AMD K5 delays.\nComputers based on the i486 remained popular through the late 1990s, serving as low-end processors for entry-level PCs. Production for traditional desktop and laptop systems ceased in 1998, when Intel introduced the Celeron brand, though it continued to be produced for embedded systems through the late 2000s.\nIn the general-purpose desktop computer role, i486-based machines remained in use into the early 2000s, especially as Windows 95 through 98 and Windows NT 4.0 were the last Microsoft operating systems to officially support i486-based systems. Windows 2000 could run on an i486-based machine, although with a less than optimal performance (the official \"minimum hardware requirement\" was a Pentium processor). As they were generally overtaken by newer operating systems, i486 systems fell out of use except for backward compatibility with older programs (most notably games), especially given problems running on newer operating systems. However, support was not removed from some open source operating systems until considerably later.\nThe i486 was eventually overtaken by the Pentium for personal computer applications, although Intel continued production for use in embedded systems. In May 2006, Intel announced that production of the i486 would stop at the end of September 2007.\nThe mainline Linux kernel considered dropping support for i486-class x86 processors in 2022 and 2025.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "15162", "revid": "20836525", "url": "https://en.wikipedia.org/wiki?curid=15162", "title": "Intel Pentium", "text": ""}
{"id": "15163", "revid": "11292982", "url": "https://en.wikipedia.org/wiki?curid=15163", "title": "Internet humour", "text": ""}
{"id": "15164", "revid": "18040497", "url": "https://en.wikipedia.org/wiki?curid=15164", "title": "I486SX", "text": "Type of microprocessor\nThe i486SX was a microprocessor originally released by Intel in 1991. It was a modified Intel i486DX microprocessor with its floating-point unit (FPU) disabled. It was intended as a lower-cost CPU for use in low-end systems\u2014selling for US$258\u2014adapting the \"SX\" suffix of the earlier i386SX in order to connote a lower-cost option. However, unlike the i386SX, which had a 16-bit external data bus and a 24-bit external address bus (compared to the fully 32-bit i386DX, its higher-cost counterpoint), the i486SX was entirely 32-bit. The Intel486 SX-20 CPU can perform up 20 MIPS at 25 MHz while this can also perform 70% faster than the 33 MHz Intel386 DX with external cache.\nOverview.\nIn the early 1990s, common applications, such as word processors and database applications, did not need or benefit from a floating-point unit, such as that included in the i486, introduced in 1989. Among the rare exceptions were CAD applications, which could often simulate floating point operations in software, but benefited from a hardware floating point unit immensely. AMD had begun manufacturing its i386DX clone, the Am386, which was faster than Intel's. To respond to this new situation, Intel wanted to provide a lower cost i486 CPU for system integrators, but without sacrificing the better profit margins of a full i486. Intel were able to accomplish this with the i486SX, the first revisions of which were practically identical to the i486 but with its floating-point unit internally wired to be disabled. The i486SX was introduced in mid-1991 at 20 MHz, one core with 8kb of cache in a pin grid array (PGA) package. There were low-power version of 16, 20, and 25 MHz Intel486 SX microprocessors. They were available USD $235, USD $266, and USD $366 for these frequency range respectfully. All pricing were in quantities of 1,000 pieces. Later versions of the i486SX, from 1992 onward, had the FPU entirely removed for cost-cutting reasons and comes in surface-mount packages as well.\nThe first computer system to ship with an i486SX on its motherboard from the factory was Advanced Logic Research's Business VEISA 486/20SX in April 1991. Initial reviews of the i486SX chip were generally poor among technology publications and the buying public, who deemed it an example of crippleware.\nMany systems allowed the user to upgrade the i486SX to a CPU with the FPU enabled. The upgrade was shipped as the i487, which was a full-blown i486DX chip with an extra pin. The extra pin has no electrical connection; its purpose is to physically prevent the chip from being installed incorrectly (\"keying\"). The choice of keeping an inactive i486SX is because i486SX was physically hard to remove, being typically installed in non-ZIF sockets or in a plastic package that was surface mounted on the motherboard. Later i486 OverDrive processors also plugged into the 169-pin socket (since named Socket 1) and offered performance enhancements as well.\nExplanatory notes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "15165", "revid": "31282773", "url": "https://en.wikipedia.org/wiki?curid=15165", "title": "Ivory", "text": "Material derived from the tusks and teeth of animals\nIvory is a hard, white material from the tusks (traditionally from elephants) and teeth of animals, that consists mainly of dentin, one of the physical structures of teeth and tusks. The chemical structure of the teeth and tusks of mammals is the same, regardless of the species of origin, but ivory contains structures of mineralised collagen. The trade in certain teeth and tusks other than elephant is well established and widespread; therefore, \"ivory\" can correctly be used to describe any mammalian teeth or tusks of commercial interest which are large enough to be carved or scrimshawed.\nBesides natural ivory, ivory can also be produced synthetically, hence (unlike natural ivory) not requiring the retrieval of the material from animals. Tagua nuts can also be carved like ivory.\nThe trade of finished goods of ivory products has its origins in the Indus Valley. Ivory is a main product that is seen in abundance and was used for trading in Harappan civilization. Finished ivory products that were seen in Harappan sites include kohl sticks, pins, awls, hooks, toggles, combs, game pieces, dice, inlay and other personal ornaments.\nIvory has been valued since ancient times in art or manufacturing for making a range of items from ivory carvings to false teeth, piano keys, fans, and dominoes. Elephant ivory is the most important source, but ivory from mammoth, walrus, hippopotamus, sperm whale, orca, narwhal and warthog is used as well. Elk also have two ivory teeth, which are believed to be the remnants of tusks from their ancestors.\nThe national and international trade in natural ivory of threatened species, such as African and Asian elephants, is illegal. The word \"ivory\" ultimately derives from the ancient Egyptian ('elephant'), through the Latin or .\nUses.\nBoth the Greek and Roman civilizations practiced ivory carving to make large quantities of high-value works of art, precious religious objects, and decorative boxes for costly objects. Ivory was often used to form the white of the eyes of statues.\nThere is some evidence of either whale or walrus ivory used by the ancient Irish. Solinus, a Roman writer in the 3rd century claimed that the Celtic peoples in Ireland would decorate their sword-hilts with the 'teeth of beasts that swim in the sea'. Adomnan of Iona wrote a story about St Columba giving a sword decorated with carved ivory as a gift that a penitent would bring to his master so he could redeem himself from slavery.\nThe Syrian and North African elephant populations were reduced to extinction, probably due to the demand for ivory in the Classical world.\nThe Chinese have long valued ivory for both art and utilitarian objects. Early reference to the Chinese export of ivory is recorded after the Chinese explorer Zhang Qian ventured to the west to form alliances to enable the eventual free movement of Chinese goods to the west; as early as the first century BC, ivory was moved along the Northern Silk Road for consumption by western nations. Southeast Asian kingdoms included tusks of the Indian elephant in their annual tribute caravans to China. Chinese craftsmen carved ivory to make everything from images of deities to the pipe stems and end pieces of opium pipes.\nIn Japan, ivory carvings became popular in the 17th century during the Edo period, and many \"netsuke\" and \"kiseru\", on which animals and legendary creatures were carved, and \"inro\", on which ivory was inlaid, were made. From the mid-1800s, the new Meiji government's policy of promoting and exporting arts and crafts led to the frequent display of elaborate ivory crafts at World's fair. Among them, the best works were admired because they were purchased by Western museums, wealthy people, and the Japanese Imperial Family.\nThe Buddhist cultures of Southeast Asia, including Myanmar, Thailand, Laos and Cambodia, traditionally harvested ivory from their domesticated elephants. Ivory was prized for containers due to its ability to keep an airtight seal. It was also commonly carved into elaborate seals utilized by officials to \"sign\" documents and decrees by stamping them with their unique official seal.\nIn Southeast Asian countries, where Muslim Malay peoples live, such as Malaysia, Indonesia and the Philippines, ivory was the material of choice for making the handles of kris daggers. \nIn the Philippines, ivory was also used to craft the faces and hands of Catholic icons and images of saints prevalent in the Santero culture.\nTooth and tusk ivory can be carved into a vast variety of shapes and objects. Examples of modern carved ivory objects are okimono, netsukes, jewelry, flatware handles, furniture inlays, and piano keys. Additionally, warthog tusks, and teeth from sperm whales, orcas and hippos can also be scrimshawed or superficially carved, thus retaining their morphologically recognizable shapes.\nAs trade with Africa expanded during the first part of the 1800s, ivory became readily available. Up to 90 percent of the ivory imported into the United States was processed, at one time, in Connecticut where Deep River and Ivoryton in 1860s became the centers of ivory milling, in particular, due to the demand for ivory piano keys.\nIvory usage in the last thirty years has moved towards mass production of souvenirs and jewelry. In Japan, the increase in wealth sparked consumption of solid ivory \"hanko\" \u2013 name seals \u2013 which before this time had been made of wood. These \"hanko\" can be carved out in a matter of seconds using machinery and were partly responsible for massive African elephant decline in the 1980s, when the African elephant population went from 1.3 million to around 600,000 in ten years.\nConsumption before plastics.\nBefore plastics were introduced, ivory had many ornamental and practical uses, mainly because of the white color it presents when processed. It was formerly used to make cutlery handles, billiard balls, piano keys, Scottish bagpipes, buttons and a wide range of ornamental items.\nSynthetic substitutes for ivory in the use of most of these items have been developed since 1800: the billiard industry challenged inventors to come up with an alternative material that could be manufactured; the piano industry abandoned ivory as a key-covering material in the 1970s.\nIvory can be taken from dead animals\u00a0\u2013 however, most ivory came from elephants that were killed for their tusks. For example, in 1930 to acquire 40 tons of ivory required the killing of approximately 700 elephants. Other animals which are now endangered were also preyed upon, for example, hippos, which have very hard white ivory prized for making artificial teeth. In the first half of the 20th century, Kenyan elephant herds were devastated because of demand for ivory, to be used for piano keys.\nDuring the Art Deco era from 1912 to 1940, dozens (if not hundreds) of European artists used ivory in the production of chryselephantine statues. Two of the most frequent users of ivory in their sculptured artworks were Ferdinand Preiss and Claire Colinet.\nMechanical characteristics.\nWhile many uses of ivory are purely ornamental in nature, it often must be carved and manipulated into different shapes to achieve the desired form. Other applications, such as ivory piano keys, introduce repeated wear and surface handling of the material. It is therefore essential to consider the mechanical properties of ivory when designing alternatives.\nElephant tusks are the animal's incisors, so the composition of ivory is unsurprisingly similar to that of teeth in several other mammals. It is composed of dentine, a biomineral composite constructed from collagen fibers mineralized with hydroxyapatite. This composite lends ivory the impressive mechanical properties\u2014high stiffness, strength, hardness, and toughness\u2014required for its use in the animal's day-to-day activities. Ivory has a measured hardness of 35 on the Vickers scale, exceeding that of bone. It also has a flexural modulus of 14 GPa, a flexural strength of 378 MPa a fracture toughness of 2.05 MPam1/2. These measured values indicate that ivory mechanically outperforms most of its most common alternatives, including celluloid plastic and polyethylene terephthalate.\nIvory's mechanical properties result from the microstructure of the dentine tissue. It is thought that the structural arrangement of mineralized collagen fibers could contribute to the checkerboard-like Schreger pattern observed in polished ivory samples. This is often used as an attribute in ivory identification. As well as being an optical feature, the Schreger pattern could point towards a micropattern well-designed to prevent crack propagation by dispersing stresses. Additionally, this intricate microstructure lends a strong anisotropy to ivory's mechanical characteristics. Separate hardness measurements on three orthogonal tusk directions indicated that circumferential planes of tusk had up to 25% greater hardness than radial planes of the same specimen. During hardness testing, inelastic and elastic recovery was observed on circumferential planes while the radial planes displayed plastic deformation. This implies that ivory has directional viscoelasticity. These anisotropic properties can be explained by the reinforcement of collagen fibers in the composite oriented along the circumference.\nAvailability.\nOwing to the rapid decline in the populations of the animals that produce it, the importation and sale of ivory in many countries is banned or severely restricted. In the ten years preceding a decision in 1989 by CITES to ban international trade in African elephant ivory, the population of African elephants declined from 1.3 million to around 600,000. It was found by investigators from the Environmental Investigation Agency (EIA) that CITES sales of stockpiles from Singapore and Burundi (270 tonnes and 89.5 tonnes respectively) had created a system that increased the value of ivory on the international market, thus rewarding international smugglers and giving them the ability to control the trade and continue smuggling new ivory.\nSince the ivory ban, some Southern African countries have claimed their elephant populations are stable or increasing, and argued that ivory sales would support their conservation efforts. Other African countries oppose this position, stating that renewed ivory trading puts their own elephant populations under greater threat from poachers reacting to demand. CITES allowed the sale of 49 tonnes of ivory from Zimbabwe, Namibia and Botswana in 1997 to Japan.\nIn 2007, under pressure from the International Fund for Animal Welfare, eBay banned all international sales of elephant-ivory products. The decision came after several mass slaughters of African elephants, most notably the 2006 Zakouma elephant slaughter in Chad. The IFAW found that up to 90% of the elephant-ivory transactions on eBay violated their own wildlife policies and could potentially be illegal. In October 2008, eBay expanded the ban, disallowing any sales of ivory on eBay.\nA more recent sale in 2008 of 108 tonnes from the three countries and South Africa took place to Japan and China. The inclusion of China as an \"approved\" importing country created enormous controversy, despite being supported by CITES, the World Wide Fund for Nature and Traffic. They argued that China had controls in place and the sale might depress prices. However, the price of ivory in China has skyrocketed. Some believe this may be due to deliberate price fixing by those who bought the stockpile, echoing the warnings from the Japan Wildlife Conservation Society on price-fixing after sales to Japan in 1997, and monopoly given to traders who bought stockpiles from Burundi and Singapore in the 1980s.\nA 2019 peer-reviewed study reported that the rate of African elephant poaching was in decline, with the annual poaching mortality rate peaking at over 10% in 2011 and falling to below 4% by 2017. The study found that the \"annual poaching rates in 53 sites strongly correlate with proxies of ivory demand in the main Chinese markets, whereas between-country and between-site variation is strongly associated with indicators of corruption and poverty.\" Based on these findings, the study authors recommended action to both reduce demand for ivory in China and other main markets and to decrease corruption and poverty in Africa.\nIn 2006, nineteen African countries signed the \"Accra Declaration\" calling for a total ivory trade ban, and twenty range states attended a meeting in Kenya calling for a 20-year moratorium in 2007.\nMethods of obtaining ivory can be divided into:\nControversy and conservation issues.\nThe use and trade of elephant ivory have become controversial because they have contributed to seriously declining elephant populations in many countries. It is estimated that consumption in Great Britain alone in 1831 amounted to the deaths of nearly 4,000 elephants. In 1975, the Asian elephant was placed on Appendix I of the Convention on International Trade in Endangered Species (CITES), which prevents international trade between member states of species that are threatened by trade. The African elephant was placed on Appendix I in January 1990. Since then, some southern African countries have had their populations of elephants \"downlisted\" to Appendix II, allowing the domestic trade of non-ivory items; there have also been two \"one off\" sales of ivory stockpiles.\nIn June 2015, more than a ton of confiscated ivory was crushed in New York City's Times Square by the Wildlife Conservation Society to send a message that the illegal trade will not be tolerated. The ivory, confiscated in New York and Philadelphia, was sent up a conveyor belt into a rock crusher. The Wildlife Conservation Society has pointed out that the global ivory trade leads to the slaughter of up to 35,000 elephants a year in Africa. In June 2018, Conservative MEPs' Deputy Leader Jacqueline Foster MEP urged the EU to follow the UK's lead and introduce a tougher ivory ban across Europe.\nChina was the biggest market for poached ivory but announced they would phase out the legal domestic manufacture and sale of ivory products in May 2015. In September of the same year, China and the U.S. announced they would \"enact a nearly complete ban on the import and export of ivory.\" The Chinese market has a high degree of influence on the elephant population.\nAlternatives.\nFossil mammoth tusks.\nTrade in the ivory from the tusks of dead woolly mammoths frozen in the tundra has occurred for 300 years and continues to be legal. Mammoth ivory is used today to make handcrafted knives and similar implements. Mammoth ivory is rare and costly because mammoths have been extinct for millennia, and scientists are hesitant to sell museum-worthy specimens in pieces. Some estimates suggest that 10 or more million mammoths are still buried in Siberia.\nFossil walrus ivory.\nFossil walrus ivory from animals that died before 1972 is legal to buy and sell in the United States, unlike many other types of ivory.\nElk ivory.\nThe ancestors of elk had teeth, also known as elk ivory, that protruded outwards, similar to animals that have tusks. These served as protection from predators, and for asserting dominance during the mating season. These elk once had much smaller antlers compared to the size of modern day species\u2019 antlers. Elk antlers evolved to become bigger and the use of their tusks diminished as antlers grew, thus evolving towards a smaller size over time, making them nothing more than teeth in their mouths.\nThese teeth have the same chemical compound as the ivory found in the highly used and poached elephant tusks, making it another good alternative when it comes to taking ivory as the teeth can be possibly removed without harming the elk themselves.\nAmong Native Americans and First Nations in elk range, primarily within the Great Plains, Rocky Mountains, and Pacific Northwest, elk teeth has major significance when it comes to jewelry. Among women, men wore them as well. Either through bracelets, earrings, and chokers, there was deeper meaning for both men and women within the tribes. For the women, it was believed that it would bring in good luck and good health. As for the men, it was seen that they were a good hunter.\nSynthetic ivory.\nIvory can also be produced synthetically.\nNuts.\nA species of hard nut is gaining popularity as a replacement for ivory, although its size limits its usability. It is sometimes called vegetable ivory, or tagua, and is the seed endosperm of the ivory nut palm commonly found in coastal rainforests of Ecuador, Peru and Colombia.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "15166", "revid": "50233935", "url": "https://en.wikipedia.org/wiki?curid=15166", "title": "Infantry fighting vehicle", "text": "Type of armored personnel carrier with direct-fire support\nAn infantry fighting vehicle (IFV), also known as a mechanized infantry combat vehicle (MICV), is a type of armoured fighting vehicle, light tank, and armoured personnel carrier used to carry infantry into battle and provide direct-fire support. The 1990 Treaty on Conventional Armed Forces in Europe defines an infantry fighting vehicle as \"an armoured combat vehicle which is designed and equipped primarily to transport a combat infantry squad, and which is armed with an integral or organic cannon of at least 20 millimeters calibre and sometimes an antitank missile launcher\". IFVs often serve both as the principal weapons system and as the mode of transport for a mechanized infantry unit.\nInfantry fighting vehicles are distinct from general armored personnel carriers (APCs), which are transport vehicles armed only for self-defense and not specifically engineered to fight on their own. IFVs are designed to be more mobile than tanks and are equipped with a rapid-firing autocannon or a large conventional gun; they may include side ports for infantrymen to fire their personal weapons while on board.\nThe IFV rapidly gained popularity with armies worldwide due to a demand for vehicles with higher firepower than APCs that were less expensive and easier to maintain than tanks. Nevertheless, it did not supersede the APC concept altogether, due to the latter's continued usefulness in specialized roles. Some armies continue to maintain fleets of both IFVs and APCs.\nHistory.\nEarly Cold War.\nThe infantry fighting vehicle (IFV) concept evolved directly out of that of the armored personnel carrier (APC). During the Cold War of 1947-1991 armies increasingly fitted heavier and heavier weapons systems on an APC chassis to deliver suppressive fire for infantry debussing from the vehicle's troop compartment. With the growing mechanization of infantry units worldwide, some armies also came to believe that the embarked personnel should fire their weapons from inside the protection of the APC and only fight on foot as a last resort. These two trends led to the IFV, with firing ports in the troop compartment and a crew-operated weapons system. The IFV established a new niche between those combat vehicles which functioned primarily as armored weapons-carriers or as APCs.\nDuring the 1950s, the Soviet, US, and most European armies had adopted tracked APCs. In 1957, however, France's adopted the AMX-VCI (VCI for \"V\u00e9hicule de Combat d'Infanterie,\" literally \"Infantry Fighting Vehicle\"), which resembled a small, conventional tracked APC but carried a turret-mounted 20\u00a0mm autocannon that enabled it to engage other armored vehicles. The AMX-VCI was the first purpose-built IFV, renamed from \"AMX-VTT\" in 1957, One year before German SPz-12-3, the second true IFV.\nThe 's doctrine called for mounted infantry to fight and maneuver alongside tank formations rather than the previously well-known heavy armor doctrine. AMX-VCI could carry ten troops in addition to a three-man crew.\nAs the AMX-VCI and SPz-12-3 were being inducted into service, the Austrian army adopted new APCs which possessed firing ports, allowing embarked infantry to observe and fire their weapons from inside the vehicle. These were known as the Saurer 4K. Austria subsequently introduced an IFV variant of the Saurer 4K which carried a 20\u00a0mm autocannon, making it the first vehicle of this class to possess both firing ports and a turreted weapons-system.\nIn the early to mid-1960s, the Swedish Army adopted two IFVs armed with 20\u00a0mm autocannon turrets and roof firing hatches: Pansarbandvagn 301 and Pansarbandvagn 302, having experimented with the IFV concept already during WWII in the Terr\u00e4ngbil m/42 KP wheeled machine gun armed proto-IFV. Following the trend towards converting preexisting APCs into IFVs, the Dutch, US, and Belgian armies experimented with a variety of modified M113s during the late 1960s; these were collectively identified as the AIFV (Armored Infantry Fighting Vehicle).\nThe first US M113-based IFV appeared in 1969; known as the XM765, it had a sharply angled hull, ten vision blocks, and a cupola-mounted 20\u00a0mm autocannon. The XM765 design, though rejected for service, later became the basis for the very similar Dutch YPR-765. The YPR-765 had five firing ports and a 25\u00a0mm autocannon with a co-axial machine gun.\nThe Soviet Army fielded its first tracked APC, the BTR-50, in 1957. Its first wheeled APC, the BTR-152, had been designed as early as the late 1940s. Early versions of both these lightly armored vehicles were open-topped and carried only general-purpose machine guns for armament. As Soviet strategists became more preoccupied with the possibility of a war involving weapons of mass destruction, they became convinced of the need to deliver mounted troops to a battlefield without exposing them to the radioactive fallout from an atomic weapon. The IFV concept was received favorably because it would enable a Soviet infantry squad to fight from inside their vehicles when operating in contaminated environments. Soviet design work on a new tracked IFV began in the late 1950s and the first prototype appeared as the \"Obyekt 765\" in 1961. After evaluating and rejecting a number of other wheeled and tracked prototypes, the Soviet Army accepted the \"Obyekt 765\" for service. It entered serial production as the BMP-1 in 1966.\nThe BMP-1 was heavily armed and armored, combining the qualities of a light tank with those of the traditional APC. In addition to being amphibious and superior in cross-country mobility to its predecessors, the BMP-1 carried a 73mm smoothbore cannon, a co-axial PKT machine gun, and a launcher for 9M14 Malyutka anti-tank missiles. Its hull had sufficiently heavy armor to resist .50 caliber armor-piercing ammunition along its frontal arc. Eight firing ports and vision blocks allowed the embarked infantry squad to observe and engage targets with rifles or machine guns. The BMP-1's use of a relatively large caliber main gun marked a departure from the Western trend of fitting IFVs with automatic cannon, which were more suitable for engaging low-flying aircraft, light armor, and dismounted personnel.\nThe Soviet Union produced about 20,000 BMP-1s from 1966 to 1983, at which time it was considered the most widely adopted IFV design in the world. In Soviet service, the BMP-1 was ultimately superseded by the more sophisticated BMP-2 (in service from 1980) and by the BMP-3 (in service from 1987). A similar vehicle known as the BMD-1 was designed to accompany Soviet airborne infantry and for a number of years was the world's only airborne IFV.\nIn 1971 the adopted the Marder, which became increasingly heavily armored through its successive marks and \u2013 like the BMP \u2013 was later fitted as standard with a launcher for anti-tank guided missiles. Between 1973 and 1975 the French and Yugoslav armies developed the AMX-10P and BVP M-80, respectively \u2013 the first amphibious IFVs to appear outside the Soviet Union. The Marder, AMX-10P, and M-80 were all armed with similar 20\u00a0mm autocannon and carried seven to eight passengers. They could also be armed with various anti-tank missile configurations.\nLate Cold War.\nWheeled IFVs did not begin appearing until 1976, when the Ratel was introduced in response to a South African Army specification for a wheeled combat vehicle suited to the demands of rapid offensives combining maximum firepower and strategic mobility. Unlike European IFVs, the Ratel was not designed to allow mounted infantrymen to fight in concert with tanks but rather to operate independently across vast distances. South African officials chose a very simple, economical design because it helped reduce the significant logistical commitment necessary to keep heavier combat vehicles operational in undeveloped areas. Excessive track wear was also an issue in the region's abrasive, sandy terrain, making the Ratel's wheeled configuration more attractive. The Ratel was typically armed with a 20\u00a0mm autocannon featuring what was then a unique twin-linked ammunition feed, allowing its gunner to rapidly switch between armor-piercing and high-explosive ammunition. Other variants were also fitted with mortars, a bank of anti-tank guided missiles, or a 90\u00a0mm cannon. Most notably, the Ratel was the first mine-protected IFV; it had a blastproof hull and was built to withstand the explosive force of anti-tank mines favored by local insurgents.\nLike the BMP-1, the Ratel proved to be a major watershed in IFV development, albeit for different reasons: until its debut wheeled IFV designs were evaluated unfavorably, since they lacked the weight-carrying capacity and off-road mobility of tracked vehicles, and their wheels were more vulnerable to hostile fire. However, improvements during the 1970s in power trains, suspension technology, and tires had increased their potential strategic mobility. Reduced production, operation, and maintenance costs also helped make wheeled IFVs attractive to several nations.\nDuring the late 1960s and early 1970s, the United States Army had gradually abandoned its attempts to utilize the M113 as an IFV and refocused on creating a dedicated IFV design able to match the BMP. Although considered reliable, the M113 chassis did not meet the necessary requirements for protection or stealth. The US also considered the M113 too heavy and slow to serve as an IFV capable of keeping pace with tanks. Its MICV-65 program produced a number of unique prototypes, none of which were accepted for service owing to concerns about speed, armor protection, and weight. US Army evaluation staff were sent to Europe to review the AMX-10P and the Marder, both of which were rejected due to high cost, insufficient armor, or lackluster amphibious capabilities.\nIn 1973, the FMC Corporation developed and tested the XM723, which was a 21-ton tracked chassis which could accommodate three crew members and eight passengers. It initially carried a single 20\u00a0mm autocannon in a one-man turret but in 1976 a two-man turret was introduced; this carried a 25\u00a0mm autocannon like M242 or Oerlikon KBA, a co-axial machine gun, and a TOW anti-tank missile launcher. The XM723 possessed amphibious capability, nine firing ports, and spaced laminate armor on its hull. It was accepted for service with the US Army in 1980 as the Bradley Fighting Vehicle. Successive variants have been retrofitted with improved missile systems, gas particulate filter systems, Kevlar spall liners, and increased stowage. The amount of space taken up by the hull and stowage modifications has reduced the number of passengers to six.\nBy 1982 30,000 IFVs had entered service worldwide, and the IFV concept appeared in the doctrines of 30 national armies. The popularity of the IFV was increased by the growing trend on the part of many nations to mechanize armies previously dominated by light infantry. However, contrary to expectation the IFV did not render APCs obsolete. The US, Russian, French, and German armies have all retained large fleets of IFVs and APCs, finding the APC more suitable for multi-purpose or auxiliary roles.\nThe British Army was one of the few Western armies which had neither recognized a niche for IFVs nor adopted a dedicated IFV design by the late 1970s. In 1980, it made the decision to adopt a new tracked armored vehicle, the FV510 Warrior. British doctrine is that a vehicle should carry troops under protection to the objective and then give firepower support when they have disembarked. While normally classified as an IFV, the Warrior fills the role of an APC in British service and infantrymen do not remain embarked during combat.\nDoctrine.\nThe role of the IFV is closely linked to mechanized infantry doctrine. While some IFVs are armed with a direct fire gun or anti-tank guided missiles for close infantry support, they are not intended to assault armored and mechanized forces with any type of infantry on their own, mounted or not. Rather, the IFV's role is to give an infantry unit battlefield, tactical, and operational mobility during combined arms operations.\nMost IFVs either complement tanks as part of an armored battalion, brigade, or division. Others perform traditional infantry missions supported by tanks. Early development of IFVs in a number of Western nations was promoted primarily by armor officers who wanted to integrate tanks with supporting infantry in armored divisions. There were a few exceptions to the rule: for example, the 's decision to adopt the SPz 12-3 was largely due to the experiences of Wehrmacht s who had been inappropriately ordered to undertake combat operations better suited for armor. Hence, the concluded that infantry should only fight while mounted in their own armored vehicles, ideally supported by tanks. This doctrinal trend was later subsumed into the armies of other Western nations, including the US, leading to the widespread conclusion that IFVs should be confined largely to assisting the forward momentum of tanks.\nThe Soviet Army granted more flexibility in this regard to its IFV doctrine, allowing for the mechanized infantry to occupy terrain that compromised an enemy defense, carry out flanking movements, or lure armor into ill-advised counterattacks. While they still performed an auxiliary role to tanks, the notion of using IFVs in these types of engagements dictated that they be heavily armed, which was reflected in the BMP-1 and its successors. Additionally, Soviet airborne doctrine made use of the BMD series of IFVs to operate in concert with paratroops rather than traditional mechanized or armored formations.\nIFVs assumed a new significance after the 1973 Arab-Israeli War. In addition to heralding the combat debut of the BMP-1, that conflict demonstrated the newfound significance of anti-tank guided missiles and the obsolescence of independent armored attacks. More emphasis was placed on combined arms offensives, and the importance of mechanized infantry to support tanks reemerged.\nAs a result of the 1973 Arab-Israeli War, the Soviet Union attached more infantry to its armored formations and the US accelerated its long-delayed IFV development program. An IFV capable of accompanying tanks for the purpose of suppressing anti-tank weapons and the hostile infantry which operated them was seen as necessary to avoid the devastation wreaked on purely armored Israeli formations.\nDesign.\nThe US Army defines all vehicles classed as IFVs as having three essential characteristics: they are armed with at least a medium-caliber cannon or automatic grenade launcher, at least sufficiently protected against small arms fire, and possess off-road mobility. It also identifies all IFVs as having some characteristics of an APC and a light tank.\nThe United Nations Register for Conventional Arms (UNROCA) simply defines an IFV as any armored vehicle \"designed to fight with soldiers on board\" and \"to accompany tanks\". UNROCA makes a clear distinction between IFVs and APCs, as the former's primary mission is combat rather than general transport.\nProtection.\nAll IFVs possess armored hulls protected against rifle and machine gun fire, and some are equipped with active protection systems. Most have lighter armor than main battle tanks to ensure mobility. Armies have generally accepted risk in reduced protection to recapitalize on an IFV's mobility, weight and speed. Their fully enclosed hulls offer protection from artillery fragments and residual environmental contaminants as well as limit exposure time to the mounted infantry during extended movements over open ground.\nMany IFVs also have sharply angled hulls that offer a relatively high degree of protection for their armor thickness. The BMP, Boragh, BVP M-80, and their respective variants all possess steel hulls with a distribution of armor and steep angling that protect them during frontal advances. The BMP-1 was vulnerable to heavy machine guns at close range on its flanks or rear, leading to a variety of more heavily armored marks appearing from 1979 onward.\nThe Bradley possessed a lightweight aluminum alloy hull, which in most successive marks has been bolstered by the addition of explosive reactive and slat armor, spaced laminate belts, and steel track skirts. Throughout its life cycle, an IFV is expected to gain 30% more weight from armor additions.\nAs asymmetric conflicts become more common, an increasing concern with regards to IFV protection has been adequate countermeasures against land mines and improvised explosive devices. During the Iraq War, inadequate mine protection in US Bradleys forced their crews to resort to makeshift strategies such as lining the hull floors with sandbags. A few IFVs, such as the Ratel, have been specifically engineered to resist mine explosions.\nArmament.\nIFVs may be equipped with: turrets carrying autocannons of various calibers, low or medium velocity tank guns, anti-tank guided missiles, or automatic grenade launchers.\nWith a few exceptions, such as the BMP-1 and the BMP-3, designs such as the Marder and the BMP-2 have set the trend of arming IFVs with an autocannon suitable for use against lightly armored vehicles, low-flying aircraft, and dismounted infantry. This reflected the growing inclination to view IFVs as auxiliaries of armored formations: a small or medium caliber autocannon was perceived as an ideal suppressive weapon to complement large caliber tank fire. IFVs armed with miniature tank guns did not prove popular because many of the roles they were expected to perform were better performed by accompanying tanks.\nThe BMP-1, which was the first IFV to carry a relatively large cannon, came under criticism during the 1973 Arab-Israeli War for its mediocre individual accuracy, due in part to the low velocities of its projectiles. During the Soviet\u2013Afghan War, BMP-1 crews also complained that their armament lacked the elevation necessary to engage insurgents in mountainous terrain. The effectiveness of large caliber, low-velocity guns like the 2A28 Grom on the BMP-1 and BMD-1 was also much reduced by the appearance of Chobham armor on Western tanks.\nThe Ratel, which included a variant armed with a 90mm low-velocity gun, was utilized in South African combat operations against Angolan and Cuban armored formations during the South African Border War, with mixed results. Although the Ratels succeeded in destroying a large number of Angolan tanks and APCs, they were hampered by many of the same problems as the BMP-1: mediocre standoff ranges, inferior fire control, and a lack of stabilized main gun. The Ratels' heavy armament also tempted South African commanders to utilize them as light tanks rather than in their intended role of infantry support.\nAnother design feature of the BMP-1 did prove more successful in establishing a precedent for future IFVs: its inclusion of an anti-tank missile system. This consisted of a rail-launcher firing 9M14 Malyutka missiles which had to be reloaded manually from outside the BMP's turret. Crew members had to expose themselves to enemy fire to reload the missiles, and they could not guide them effectively from inside the confines of the turret space.\nThe BMP-2 and later variants of the BMP-1 made use of semiautonomous guided missile systems. In 1978, the became the first Western army to embrace this trend when it retrofitted all its Marders with launchers for MILAN anti-tank missiles.\nThe US Army added a launcher for TOW anti-tank missiles to its fleet of Bradleys, despite the fact that this greatly reduced the interior space available for seating the embarked infantry. This was justified on the basis that the Bradley needed to not only engage and destroy other IFVs, but support tanks in the destruction of other tanks during combined arms operations.\nMobility.\nIFVs are designed to have the strategic and tactical mobility necessary to keep pace with tanks during rapid maneuvers. Some, like the BMD series, have airborne and amphibious capabilities. IFVs may be either wheeled or tracked; tracked IFVs are usually more heavily armored and possess greater carrying capacity. Wheeled IFVs are cheaper and simpler to produce, maintain, and operate. From a logistical perspective, they are also ideal for an army without widespread access to transporters or a developed rail network to deploy its armor.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nExplanatory notes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "15167", "revid": "27015025", "url": "https://en.wikipedia.org/wiki?curid=15167", "title": "ICQ", "text": "Cross-platform instant messaging system and VoIP client\nICQ was a cross-platform instant messaging (IM) and VoIP client founded in June 1996 by Yair Goldfinger, Sefi Vigiser, Amnon Amir, Arik Vardi, and Arik's father, Yossi Vardi. The name ICQ derives from the English phrase \"I Seek You\". Originally developed by the Israeli company Mirabilis in 1996, the client was bought by AOL in 1998, and then by Mail.Ru Group (now VK) in 2010.\nThe ICQ client application and service were initially released in November 1996, freely available to download. The business did not have traditional marketing and relied mostly on word-of-mouth advertising instead, with customers telling their friends about it, who then informed their friends, and so on. ICQ was among the first stand-alone instant messenger (IM) applications\u2014while real-time chat was not in itself new (Internet Relay Chat [IRC] being the most common platform at the time), the concept of a fully centralized service with individual user accounts focused on one-on-one conversations set the blueprint for later instant messaging services like AIM, and its influence is seen in modern social media applications. ICQ became the first widely adopted IM platform.\nAt its peak around 2001, ICQ had more than 100 million accounts registered. At the time of the Mail.Ru acquisition in 2010, there were around 42 million daily users. In 2022, ICQ had about 11 million monthly users.\nThe service was shut down on June 26, 2024, following an announcement on ICQ's website in May 2024.\nFeatures of ICQ New.\nThe last version of the service, launched in 2020 as \"ICQ New\", featured a number of different messaging functions:\nUIN.\nICQ users were identified and distinguished from one another by UIN, or User Identification Numbers, distributed in sequential order. The UIN was invented by Mirabilis, as the user name assigned to each user upon registration. Issued UINs started at '100,000' (6 digits) and every user received a UIN when first registering with ICQ. As of ICQ6 users were also able to log in using the specific e-mail address they associated with their UIN during the initial registration process.\nUnlike other instant messaging software or web applications, on ICQ the only permanent user info was the UIN, although it was possible to search for other users using their associated e-mail address or any other detail they made public by updating it in their account's public profile. In addition the user could change all of his or her personal information, including screen name and e-mail address, without having to re-register. Since 2000, ICQ and AIM users were able to add each other to their contact list without the need for any external clients. As a response to UIN theft or sale of attractive UINs, ICQ started to store email addresses previously associated with a UIN. As such UINs that are stolen could sometimes be reclaimed, if a valid primary email address was entered into the user profile.\nHistory.\nThe founding company of ICQ, Mirabilis, was established in June 1996 by five Israeli developers: Yair Goldfinger, Sefi Vigiser, Amnon Amir, Arik Vardi, and Arik's father Yossi Vardi. ICQ was one of the first text-based messengers to reach a wide range of users.\nThe technology Mirabilis developed for ICQ was distributed free of charge. The technology's success encouraged AOL to acquire Mirabilis on June 8, 1998, for $287 million up front and $120 million in additional payments over three years based on performance levels. In 2002 AOL successfully patented the technology.\nAfter the purchase, the product was initially managed by Ariel Yarnitsky and Avi Shechter. ICQ's management changed at the end of 2003. Under the leadership of the new CEO, Orey Gilliam, who also assumed the responsibility for all of AOL's messaging business in 2007, ICQ resumed its growth; it was not only a highly profitable company, but one of AOL's most successful businesses. Eliav Moshe replaced Gilliam in 2009 and became ICQ's managing director.\nIn April 2010, AOL sold ICQ to Digital Sky Technologies, headed by Alisher Usmanov, for $187.5 million. While ICQ was displaced by AOL Instant Messenger, Google Talk, and other competitors in the US and many other countries over the 2000s, it remained the most popular instant messaging network in Russian-speaking countries, and an important part of online culture. Popular UINs demanded over 11,000\u20bd in 2010.\nIn September of that year, Digital Sky Technologies changed its name to Mail.Ru Group. Since the acquisition, Mail.ru has invested in turning ICQ from a desktop client to a mobile messaging system. As of 2013, around half of ICQ's users were using its mobile apps, and in 2014, the number of users began growing for the first time since the purchase.\nIn March 2016, the source code of the client was released under the Apache license on GitHub.\nIn 2020, Mail.Ru Group decided to launch a new version, \"ICQ New\", based on the original ICQ. The updated software was presented to the general public on April 6, 2020. \nDuring the second week of January 2021, ICQ saw a renewed increase in popularity in Hong Kong, spurred on by the controversy over WhatsApp's privacy policy update. The number of downloads for the application increased 35-fold in the region.\nOn May 24, 2024, the main page of ICQ's website announced that the service would be shutting down on June 26, 2024. ICQ recommended that users migrate to VK Messenger and VK WorkSpace.\nCriticism.\nPolicy against unofficial clients.\nAOL (and later Mail.ru) pursued an aggressive policy regarding alternative (\"unauthorized\") ICQ clients.\n\"\u0421\u0438\u0441\u0442\u0435\u043c\u043d\u043e\u0435 \u0441\u043e\u043e\u0431\u0449\u0435\u043d\u0438\u0435\n ICQ \u043d\u0435 \u043f\u043e\u0434\u0434\u0435\u0440\u0436\u0438\u0432\u0430\u0435\u0442 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u043c\u0443\u044e \u0432\u0430\u043c\u0438 \u0432\u0435\u0440\u0441\u0438\u044e. \u0421\u043a\u0430\u0447\u0430\u0439\u0442\u0435 \u0431\u0435\u0441\u043f\u043b\u0430\u0442\u043d\u0443\u044e \u0430\u0432\u0442\u043e\u0440\u0438\u0437\u043e\u0432\u0430\u043d\u043d\u0443\u044e \u0432\u0435\u0440\u0441\u0438\u044e ICQ \u0441 \u043e\u0444\u0438\u0446\u0438\u0430\u043b\u044c\u043d\u043e\u0433\u043e web-\u0441\u0430\u0439\u0442\u0430 ICQ.\nSystem Message\n The version you are using is not supported by ICQ. Download a free authorized ICQ version from ICQ's official website.\"\nOn icq.com there was an \"important message\" for Russian-speaking ICQ users: \"ICQ \u043e\u0441\u0443\u0449\u0435\u0441\u0442\u0432\u043b\u044f\u0435\u0442 \u043f\u043e\u0434\u0434\u0435\u0440\u0436\u043a\u0443 \u0442\u043e\u043b\u044c\u043a\u043e \u0430\u0432\u0442\u043e\u0440\u0438\u0437\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u044b\u0445 \u0432\u0435\u0440\u0441\u0438\u0439 \u043f\u0440\u043e\u0433\u0440\u0430\u043c\u043c: ICQ Lite \u0438 ICQ 6.5.\" (\"ICQ supports only authorized versions of programs: ICQ Lite and ICQ 6.5.\")\nCooperation with Russian intelligence services.\nAccording to a \"Novaya Gazeta\" article published in May 2018, Russian intelligence agencies had access to online reading of ICQ users' correspondence during crime investigations. The article examined 34 sentences of Russian courts, during the investigation of which the evidence of the defendants' guilt was obtained by reading correspondence on a PC or mobile devices. In six of the fourteen cases in which ICQ was involved, the capturing of information occurred before the seizure of the device. Because the rival service Telegram blocks all access for the agencies, the Advisor of the Russian President, German Klimenko, recommended to use ICQ instead.\nChild pornography.\nIn 2023, an investigation by Brazilian news outlet \"N\u00facleo Jornalismo\" found that ICQ was used to freely share child pornography due to lax moderation policies.\nClients.\nAOL's OSCAR network protocol used by ICQ was proprietary and using a third party client was a violation of ICQ Terms of Service. Nevertheless, a number of third-party clients were created by using reverse-engineering and protocol descriptions. These clients included:\nAOL supported clients include:\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "15169", "revid": "998182", "url": "https://en.wikipedia.org/wiki?curid=15169", "title": "Impressionism", "text": "19th-century art movement\n \nImpressionism was a 19th-century art movement characterized by visible brush strokes, open composition, emphasis on accurate depiction of light in its changing qualities (often accentuating the effects of the passage of time), ordinary subject matter, unusual visual angles, and inclusion of movement as a crucial element of human perception and experience. Impressionism originated with a group of Paris-based artists whose independent exhibitions brought them to prominence during the 1870s and 1880s.\nThe Impressionists faced harsh opposition from the conventional art community in France. The name of the style derives from the title of a Claude Monet work, \"Impression, soleil levant\" (\"Impression, Sunrise\"), which provoked the critic Louis Leroy to coin the term in a satirical 1874 review of the First Impressionist Exhibition published in the Parisian newspaper \"Le Charivari\". The development of Impressionism in the visual arts was soon followed by analogous styles in other media that became known as Impressionist music and Impressionist literature.\nOverview.\nRadicals in their time, the early Impressionists violated the rules of academic painting. They constructed their pictures from freely brushed colours that took precedence over lines and contours, following the example of painters such as Eug\u00e8ne Delacroix and J. M. W. Turner. They also painted realistic scenes of everyday life in natural settings, often outdoors, attempting to capture a moment as experienced.\nPreviously, paintings were accomplished in studio, whether landscape art, still life or portrait, with an emphasis on verisimilitude. The Impressionists found that they could capture the momentary and transient effects of sunlight by painting outdoors or \"en plein air\". They portrayed overall visual effects instead of details, and used short \"broken\" brush strokes of mixed and pure unmixed colour\u2014not blended smoothly or shaded, as was customary\u2014to achieve an effect of intense colour vibration.\nImpressionism emerged in France at the same time that a number of other painters, including the Italian artists known as the Macchiaioli, and Winslow Homer in the United States, were also exploring \"plein-air\" painting. The Impressionists, however, developed new techniques specific to the style. Encompassing what its adherents argued was a different way of seeing, it is an art of immediacy and movement, of candid poses and compositions, of the play of light expressed in a bright and varied use of colour. In 1876, the poet and critic St\u00e9phane Mallarm\u00e9 said of the new style: \"The represented subject, being composed of a harmony of reflected and ever-changing lights, cannot be supposed always to look the same but palpitates with movement, light, and life\".\nThe public, at first hostile, gradually came to believe that the Impressionists had captured a fresh and original vision, even if the art critics and art establishment disapproved of the new style. By recreating the sensation in the eye that views the subject, rather than delineating the details of the subject, and by creating a welter of techniques and forms, Impressionism is a precursor of various painting styles, including Post-Impressionism, Fauvism, and Cubism.\nBeginnings.\nIn the middle of the 19th century\u2014a time of rapid industrialization and unsettling social change in France, as Emperor Napoleon III rebuilt Paris and waged war\u2014the dominated French art. The Acad\u00e9mie was the preserver of traditional French painting standards of content and style. Historical subjects, religious themes, and portraits were valued; landscape and still life were not. The Acad\u00e9mie preferred carefully finished images that looked realistic when examined closely. Paintings in this style were made up of precise brush strokes carefully blended to hide the artist's hand in the work. Colour was restrained and often toned down further by the application of a thick golden varnish.\nThe Acad\u00e9mie had an annual, juried art show, the Salon de Paris, and artists whose work was displayed in the show won prizes, garnered commissions, and enhanced their prestige. The standards of the juries represented the values of the Acad\u00e9mie, represented by the works of such artists as Jean-L\u00e9on G\u00e9r\u00f4me and Alexandre Cabanel. Using an eclectic mix of techniques and formulas established in Western painting since the Renaissance\u2014such as linear perspective and figure types derived from Classical Greek art\u2014these artists produced escapist visions of a reassuringly ordered world. By the 1850s, some artists, notably the Realist painter Gustave Courbet, had gained public attention and critical censure by depicting contemporary realities without the idealization demanded by the Acad\u00e9mie.\nIn the early 1860s, four young painters\u2014Claude Monet, Pierre-Auguste Renoir, Alfred Sisley, and Fr\u00e9d\u00e9ric Bazille\u2014met while studying under the academic artist Charles Gleyre. They discovered that they shared an interest in painting landscape and contemporary life rather than historical or mythological scenes. Following a practice\u2014pioneered by artists such as the Englishman John Constable\u2014 that had become increasingly popular by mid-century, they often ventured into the countryside together to paint in the open air. Their purpose was not to make sketches to be developed into carefully finished works in the studio, as was the usual custom, but to complete their paintings out-of-doors.\nBy painting in sunlight directly from nature, and making bold use of the vivid synthetic pigments that had become available since the beginning of the century, they began to develop a lighter and brighter manner of painting that extended further the Realism of Courbet and the Barbizon school. A favourite meeting place for the artists was the Caf\u00e9 Guerbois on Avenue de Clichy in Paris, where the discussions were often led by \u00c9douard Manet, whom the younger artists greatly admired. They were soon joined by Camille Pissarro, Paul C\u00e9zanne, and Armand Guillaumin.\nDuring the 1860s, the Salon jury routinely rejected about half of the works submitted by Monet and his friends in favour of works by artists faithful to the approved style. In 1863, the Salon jury rejected Manet's \"The Luncheon on the Grass\" () primarily because it depicted a nude woman with two clothed men at a picnic. While the Salon jury routinely accepted nudes in historical and allegorical paintings, they condemned Manet for placing a realistic nude in a contemporary setting. The jury's severely worded rejection of Manet's painting appalled his admirers, and the unusually large number of rejected works that year perturbed many French artists.\nAfter Emperor Napoleon III saw the rejected works of 1863, he decreed that the public be allowed to judge the work themselves, and the Salon des Refus\u00e9s (Salon of the Refused) was organized. While many viewers came only to laugh, the Salon des Refus\u00e9s drew attention to the existence of a new tendency in art and attracted more visitors than the regular Salon.\nArtists' petitions requesting a new Salon des Refus\u00e9s in 1867, and again in 1872, were denied. In December 1873, Monet, Renoir, Pissarro, Sisley, C\u00e9zanne, Berthe Morisot, Edgar Degas and several other artists founded the to exhibit their artworks independently. Members of the association were expected to forswear participation in the Salon. The organizers invited a number of other progressive artists to join them in their inaugural exhibition, including the older Eug\u00e8ne Boudin, whose example had first persuaded Monet to adopt \"plein air\" painting years before. Another painter who greatly influenced Monet and his friends, Johan Jongkind, declined to participate, as did \u00c9douard Manet. In total, thirty artists participated in their first exhibition, held in April 1874 at the studio of the photographer Nadar.\nThe critical response was mixed. Monet and C\u00e9zanne received the harshest attacks. Critic and humorist Louis Leroy wrote a scathing review in the newspaper \"Le Charivari\" in which, making wordplay with the title of Claude Monet's \"Impression, Sunrise\" \"(Impression, soleil levant)\", he gave the artists the name by which they became known. Derisively titling his article \"\", Leroy declared that Monet's painting was at most, a sketch, and could hardly be termed a finished work.\nHe wrote, in the form of a dialogue between viewers,\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\"Impression\u2014I was certain of it. I was just telling myself that, since I was impressed, there had to be some impression in it ... and what freedom, what ease of workmanship! Wallpaper in its embryonic state is more finished than that seascape.\"\nThe term \"Impressionist\" quickly gained favour with the public. It was also accepted by the artists themselves, even though they were a diverse group in style and temperament, unified primarily by their spirit of independence and rebellion. They exhibited together\u2014albeit with shifting membership\u2014eight times between 1874 and 1886. The Impressionists' style, with its loose, spontaneous brushstrokes, would soon become synonymous with modern life.\nMonet, Sisley, Morisot, and Pissarro may be considered the \"purest\" Impressionists, in their consistent pursuit of an art of spontaneity, sunlight, and colour. Degas rejected much of this, as he believed in the primacy of drawing over colour and belittled the practice of painting outdoors. Renoir turned away from Impressionism for a time during the 1880s, and never entirely regained his commitment to its ideas. \u00c9douard Manet, although regarded by the Impressionists as their leader, never abandoned his liberal use of black as a colour (while Impressionists avoided its use and preferred to obtain darker colours by mixing), and never participated in the Impressionist exhibitions. He continued to submit his works to the Salon, where his painting \"Spanish Singer\" had won a 2nd class medal in 1861, and he urged the others to do likewise, arguing that \"the Salon is the real field of battle\" where a reputation could be made.\nAmong the artists of the core group (minus Bazille, who had died in the Franco-Prussian War in 1870), defections occurred as C\u00e9zanne, followed later by Renoir, Sisley, and Monet, abstained from the group exhibitions so they could submit their works to the Salon. Disagreements arose from issues such as Guillaumin's membership in the group, championed by Pissarro and C\u00e9zanne against opposition from Monet and Degas, who thought him unworthy. Degas invited Mary Cassatt to display her work in the 1879 exhibition, but also insisted on the inclusion of Jean-Fran\u00e7ois Raffa\u00eblli, Ludovic Lepic, and other realists who did not represent Impressionist practices, causing Monet in 1880 to accuse the Impressionists of \"opening doors to first-come daubers\".\nIn this regard, the seventh Paris Impressionist exhibition in 1882 was the most selective of all including the works of only nine \"true\" impressionists, namely Gustave Caillebotte, Paul Gauguin, Armand Guillaumin, Claude Monet, Berthe Morisot, Camille Pissarro, Pierre-Auguste Renoir, Alfred Sisley, and Victor Vignon. The group then divided again over the invitations to Paul Signac and Georges Seurat to exhibit with them at the 8th Impressionist exhibition in 1886. Pissarro was the only artist to show at all eight Paris Impressionist exhibitions.\nThe individual artists achieved few financial rewards from the Impressionist exhibitions, but their art gradually won a degree of public acceptance and support. Their dealer, Durand-Ruel, played a major role in this as he kept their work before the public and arranged shows for them in London and New York. Although Sisley died in poverty in 1899, Renoir had a great Salon success in 1879. Monet became secure financially during the early 1880s and so did Pissarro by the early 1890s. By this time the methods of Impressionist painting, in a diluted form, had become commonplace in Salon art.\nImpressionist techniques.\nFrench painters who prepared the way for Impressionism include the Romantic colourist Eug\u00e8ne Delacroix; the leader of the realists, Gustave Courbet; and painters of the Barbizon school such as Th\u00e9odore Rousseau. The Impressionists learned much from the work of Johan Barthold Jongkind, Jean-Baptiste-Camille Corot and Eug\u00e8ne Boudin, who painted from nature in a direct and spontaneous style that prefigured Impressionism, and who befriended and advised the younger artists.\nA number of identifiable techniques and working habits contributed to the innovative style of the Impressionists. Although these methods had been used by previous artists\u2014and are often conspicuous in the work of artists such as Frans Hals, Diego Vel\u00e1zquez, Peter Paul Rubens, John Constable, and J.\u00a0M.\u00a0W.\u00a0Turner\u2014the Impressionists were the first to use them all together, and with such consistency. These techniques include:\nNew technology played a role in the development of the style. Impressionists took advantage of the mid-century introduction of premixed paints in tin tubes (resembling modern toothpaste tubes), which allowed artists to work more spontaneously, both outdoors and indoors. Previously, painters made their own paints individually, by grinding and mixing dry pigment powders with linseed oil, which were then stored in animal bladders.\nMany vivid synthetic pigments became commercially available to artists for the first time during the 19th century. These included cobalt blue, viridian, cadmium yellow, and synthetic ultramarine blue, all of which were in use by the 1840s, before Impressionism. The Impressionists' manner of painting made bold use of these pigments, and of even newer colours such as cerulean blue, which became commercially available to artists in the 1860s.\nThe Impressionists' progress toward a brighter style of painting was gradual. During the 1860s, Monet and Renoir sometimes painted on canvases prepared with the traditional red-brown or grey ground. By the 1870s, Monet, Renoir, and Pissarro usually chose to paint on grounds of a lighter grey or beige colour, which functioned as a middle tone in the finished painting. By the 1880s, some of the Impressionists had come to prefer white or slightly off-white grounds, and no longer allowed the ground colour a significant role in the finished painting.\nContent and composition.\nThe Impressionists reacted to modernity by exploring \"a wide range of non-academic subjects in art\" such as middle-class leisure activities and \"urban themes, including train stations, caf\u00e9s, brothels, the theater, and dance.\" They found inspiration in the newly widened avenues of Paris, bounded by new tall buildings that offered opportunities to depict bustling crowds, popular entertainments, and nocturnal lighting in artificially closed-off spaces.\nA painting such as Caillebotte's \"Paris Street; Rainy Day\" (1877) strikes a modern note by emphasizing the isolation of individuals amid the outsized buildings and spaces of the urban environment. When painting landscapes, the Impressionists did not hesitate to include the factories that were proliferating in the countryside. Earlier painters of landscapes had conventionally avoided smokestacks and other signs of industrialization, regarding them as blights on nature's order and unworthy of art.\nPrior to the Impressionists, other painters, notably such 17th-century Dutch painters as Jan Steen, had emphasized common subjects, but their methods of composition were traditional. They arranged their compositions so that the main subject commanded the viewer's attention. J. M. W. Turner, while an artist of the Romantic era, anticipated the style of impressionism with his artwork. The Impressionists relaxed the boundary between subject and background so that the effect of an Impressionist painting often resembles a snapshot, a part of a larger reality captured as if by chance. Photography was gaining popularity, and as cameras became more portable, photographs became more candid. Photography inspired Impressionists to represent momentary action, not only in the fleeting lights of a landscape, but in the day-to-day lives of people.\nThe development of Impressionism can be considered partly as a reaction by artists to the challenge presented by photography, which seemed to devalue the artist's skill in reproducing reality. Both portrait and landscape paintings were deemed somewhat deficient and lacking in truth as photography \"produced lifelike images much more efficiently and reliably\".\nIn spite of this, photography actually inspired artists to pursue other means of creative expression, and rather than compete with photography to emulate reality, artists focused \"on the one thing they could inevitably do better than the photograph\u2014by further developing into an art form its very subjectivity in the conception of the image, the very subjectivity that photography eliminated\". The Impressionists sought to express their perceptions of nature, rather than create exact representations. This allowed artists to depict subjectively what they saw with their \"tacit imperatives of taste and conscience\". Photography encouraged painters to exploit aspects of the painting medium, like colour, which photography then lacked: \"The Impressionists were the first to consciously offer a subjective alternative to the photograph\".\nAnother major influence was Japanese ukiyo-e art prints (Japonism). The art of these prints contributed significantly to the \"snapshot\" angles and unconventional compositions that became characteristic of Impressionism. An example is Monet's \"Jardin \u00e0 Sainte-Adresse\", 1867, with its bold blocks of colour and composition on a strong diagonal slant showing the influence of Japanese prints.\nEdgar Degas was both an avid photographer and a collector of Japanese prints. His \"The Dance Class\" \"(La classe de danse)\" of 1874 shows both influences in its asymmetrical composition. The dancers are seemingly caught off guard in various awkward poses, leaving an expanse of empty floor space in the lower right quadrant. He also captured his dancers in sculpture, such as the \"Little Dancer of Fourteen Years\".\nFemale Impressionists.\nImpressionists, in varying degrees, were looking for ways to depict visual experience and contemporary subjects. Female Impressionists were interested in these same ideals but had many social and career limitations compared to male Impressionists. They were particularly excluded from the imagery of the bourgeois social sphere of the boulevard, cafe, and dance hall.\nAs well as imagery, women were excluded from the formative discussions that resulted in meetings in those places. That was where male Impressionists were able to form and share ideas about Impressionism. In the academic realm, women were believed to be incapable of handling complex subjects, which led teachers to restrict what they taught female students. It was also considered unladylike to excel in art, since women's true talents were then believed to center on homemaking and mothering.\nYet several women were able to find success during their lifetime, even though their careers were affected by personal circumstances \u2013 Bracquemond, for example, had a husband who was resentful of her work which caused her to give up painting. The four most well known, namely, Mary Cassatt, Eva Gonzal\u00e8s, Marie Bracquemond, and Berthe Morisot, are, and were, often referred to as the 'Women Impressionists'. Their participation in the series of eight Impressionist exhibitions that took place in Paris from 1874 to 1886 varied: Morisot participated in seven, Cassatt in four, Bracquemond in three, and Gonzal\u00e8s did not participate.\nThe critics of the time lumped these four together without regard to their personal styles, techniques, or subject matter. Critics viewing their works at the exhibitions often attempted to acknowledge the women artists' talents but circumscribed them within a limited notion of femininity. Arguing for the suitability of Impressionist technique to women's manner of perception, Parisian critic S.C. de Soissons wrote:One can understand that women have no originality of thought, and that literature and music have no feminine character; but surely women know how to observe, and what they see is quite different from that which men see, and the art which they put in their gestures, in their toilet, in the decoration of their environment is sufficient to give is the idea of an instinctive, of a peculiar genius which resides in each one of them.\nWhile Impressionism legitimized the domestic social life as subject matter, of which women had intimate knowledge, it also tended to limit them to that subject matter. Portrayals of often-identifiable sitters in domestic settings, which could offer commissions, were dominant in the exhibitions. The subjects of the paintings were often women interacting with their environment by either their gaze or movement. Cassatt, in particular, was aware of her placement of subjects: she kept her predominantly female figures from objectification and cliche; when they are not reading, they converse, sew, drink tea, and when they are inactive, they seem lost in thought.\nThe women Impressionists, like their male counterparts, were striving for \"truth\", for new ways of seeing and new painting techniques; each artist had an individual painting style. Women Impressionists, particularly Morisot and Cassatt, were conscious of the balance of power between women and objects in their paintings \u2013 the bourgeois women depicted are not defined by decorative objects, but instead, interact with and dominate the things with which they live. There are many similarities in their depictions of women who seem both at ease and subtly confined. Gonzal\u00e8s' \"Box at the Italian Opera\" depicts a woman staring into the distance, at ease in a social sphere but confined by the box and the man standing next to her. Cassatt's painting \"Young Girl at a Window\" is brighter in color but remains constrained by the canvas edge as she looks out the window.\nDespite their success in their ability to have a career and Impressionism's demise attributed to its allegedly feminine characteristics\u2014its sensuality, dependence on sensation, physicality, and fluidity\u2014the four women artists, and other, lesser-known women Impressionists, were largely omitted from art historical textbooks covering Impressionist artists until Tamar Garb's \"Women Impressionists\" published in 1986. For example, \"Impressionism\" by Jean Leymarie, published in 1955 included no information on any women Impressionists.\nPainter Androniqi Zengo Antoniu is co-credited with the introduction of impressionism to Albania.\nProminent Impressionists.\nThe central figures in the development of Impressionism in France, listed alphabetically, were:\nTimeline: lives of the Impressionists.\nstyle=\"text-align:left\"|\nAssociates and influenced artists.\nAmong the close associates of the Impressionists, Victor Vignon is the only artist outside the group of prominent names who participated to the most exclusive Seventh Paris Impressionist Exhibition in 1882, which was indeed a rejection to the previous less restricted exhibitions chiefly organized by Degas. Originally from the school of Corot, Vignon was a friend of Camille Pissarro, whose influence is evident in his impressionist style after the late 1870s, and a friend of post-impressionist Vincent van Gogh.\nThere were several other close associates of the Impressionists who adopted their methods to some degree. These include Jean-Louis Forain, who participated in Impressionist exhibitions in 1879, 1880, 1881 and 1886, and Giuseppe De Nittis, an Italian artist living in Paris who participated in the first Impressionist exhibit at the invitation of Degas, although the other Impressionists disparaged his work. Federico Zandomeneghi was another Italian friend of Degas who showed with the Impressionists. Eva Gonzal\u00e8s was a follower of Manet who did not exhibit with the group.\nJames Abbott McNeill Whistler was an American-born painter who played a part in Impressionism although he did not join the group and preferred grayed colours. Walter Sickert, an English artist, was initially a follower of Whistler, and later an important disciple of Degas. He did not exhibit with the Impressionists. In 1904, the artist and writer Wynford Dewhurst wrote the first important study of the French painters published in English, \"Impressionist Painting: its genesis and development\", which did much to popularize Impressionism in Great Britain.\nBy the early 1880s, Impressionist methods were affecting, at least superficially, the art of the Salon. Fashionable painters such as Jean B\u00e9raud and Henri Gervex found critical and financial success by brightening their palettes while retaining the smooth finish expected of Salon art. Works by these artists are sometimes casually referred to as Impressionism, despite their remoteness from Impressionist practice.\nThe influence of the French Impressionists lasted long after most of them had died. Artists like J.D. Kirszenbaum were borrowing Impressionist techniques throughout the twentieth century.\nBeyond France.\nAs the influence of Impressionism spread beyond France, artists, too numerous to list, became identified as practitioners of the new style. Some of the more important examples are:\nImpressionism in other media.\nSculpture.\nWhile Edgar Degas was primarily known as a painter in his lifetime, he began to pursue the medium of sculpture later in his artistic career in the 1880s. He created as many as 150 sculptures during his lifetime. Degas preferred the medium of wax for his sculptures because it allowed him to make changes, start over, and further explore the modelling process. Only one of Degas's sculptures, \"Little Dancer of Fourteen Years\", was exhibited in his lifetime, which was exhibited at the Sixth Impressionist Exhibition in 1881. \"Little Dancer\" proved to be controversial with critics. Some considered Degas to have overthrown sculptural traditions in the same way that Impressionism had overthrown the traditions of painting. Others found it to be ugly. Following the Degas's death in 1917, his heirs authorized bronze castings from 73 of the artist's sculptures.\nThe sculptor Auguste Rodin is sometimes called an Impressionist for the way he used roughly modeled surfaces to suggest transient light effects. The sculptor Medardo Rosso has also been called an Impressionist.\nSome Russian artists created Impressionistic sculptures of animals in order to break away from old world concepts. Their works have been described as endowing birds and beasts with new spiritual characteristics.\nPhotography and film.\nWhile his photographs are less known than his paintings or his sculptures, Edgar Degas also pursued photography later in his life. His photographs were never exhibited during his lifetime, and not much attention was given to them following his death. It was not until the late 20th century that scholars started to take interest in Degas's photographs.\nPictorialist photographers, whose work is characterized by soft focus and atmospheric effects, have also been called Impressionists. These Impressionist photographers used various techniques such as photographing subjects out of focus, using soft focus lenses or pinhole lenses, and manipulating the gum bichromate process to create images that resembled Impressionist paintings.\nFrench Impressionist Cinema is a term applied to a loosely defined group of films and filmmakers in France from 1919 to 1929, although these years are debatable. French Impressionist filmmakers include Abel Gance, Jean Epstein, Germaine Dulac, Marcel L'Herbier, Louis Delluc, and Dmitry Kirsanoff.\nMusic.\nMusical Impressionism is the name given to a movement in European classical music that arose in the late 19th century and continued into the middle of the 20th century. Originating in France, musical Impressionism is characterized by suggestion and atmosphere, and eschews the emotional excesses of the Romantic era. Impressionist composers favoured short forms such as the nocturne, arabesque, and prelude, and often explored uncommon scales such as the whole tone scale. Perhaps the most notable innovations of Impressionist composers were the introduction of major 7th chords and the extension of chord structures in 3rds to five- and six-part harmonies.\nThe influence of visual Impressionism on its musical counterpart is debatable. Claude Debussy and Maurice Ravel are generally considered the greatest Impressionist composers, but Debussy disavowed the term, calling it the invention of critics. Erik Satie was also considered in this category, though his approach was regarded as less serious, more musical novelty in nature.\nPaul Dukas is another French composer sometimes considered an Impressionist, but his style is perhaps more closely aligned to the late Romanticists, Lili Boulanger, however, has clear Debussian sounds and has been considered as an Impressionist also. Musical Impressionism beyond France includes the work of such composers as Ottorino Respighi (Italy), Ralph Vaughan Williams, Cyril Scott, and John Ireland (England), Alexander Scriabin (Russia), Manuel De Falla and Isaac Albeniz (Spain), and Charles Griffes (America).\nAmerican Impressionist music differs from European Impressionist music, and these differences are mainly reflected in Charles Tomlinson Griffes's Poem for flute and orchestra. He is also the most prolific Impressionist composer in the United States.\nLiterature.\nThe term Impressionism has also been used to describe works of literature in which a few select details suffice to convey the sensory impressions of an incident or scene. Impressionist literature is closely related to Symbolism, with its major exemplars being Baudelaire, Mallarm\u00e9, Rimbaud, and Verlaine. Authors such as Virginia Woolf, D.H. Lawrence, Henry James, and Joseph Conrad have written works that are Impressionistic in the way that they describe, rather than interpret, the impressions, sensations and emotions that constitute a character's mental life. Some literary scholars, such as John G. Peters, believe literary Impressionism is better defined by its philosophical stance than by any supposed relationship with Impressionist painting.\nPost-Impressionism.\nDuring the 1880s several artists began to develop different precepts for the use of colour, pattern, form, and line, derived from the Impressionist example: Vincent van Gogh, Paul Gauguin, Georges Seurat, and Henri de Toulouse-Lautrec. These artists were slightly younger than the Impressionists, and their work is known as post-Impressionism. Post-Impressionist artists reacted against the Impressionists' concern with realistically reproducing the optical sensations of light and colour; they turned instead toward symbolic content and the expression of emotion.\nPost-Impressionism prefigured the characteristics of Futurism and Cubism, reflecting the change of attitude towards art in European society. Some of the original Impressionist artists also ventured into this new territory; Camille Pissarro briefly painted in a pointillist manner, and even Monet abandoned strict \"plein air\" painting. Paul C\u00e9zanne, who participated in the first and third Impressionist exhibitions, developed a highly individual vision emphasising pictorial structure, and he is more often called a post-Impressionist. Although these cases illustrate the difficulty of assigning labels, the work of the original Impressionist painters may, by definition, be categorised as Impressionism.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nWorks cited.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "15172", "revid": "50497608", "url": "https://en.wikipedia.org/wiki?curid=15172", "title": "Internet slang", "text": "Slang languages used by different people on the Internet\nInternet slang (also called Internet shorthand, cyber-slang, netspeak, digispeak or chatspeak) is a non-standard or unofficial form of language used by people on the Internet to communicate to one another. A popular example of Internet slang is \"lol\", meaning \"laugh out loud\". Since Internet slang is constantly changing, it is difficult to provide a standardized definition. However, it can be understood to be any type of slang that Internet users have popularized, and in many cases, have coined. Such terms often originate with the purpose of saving keystrokes or to compensate for character limit restrictions. Many people use the same abbreviations in texting, instant messaging, and social networking websites. Acronyms, keyboard symbols, and abbreviations are common types of Internet slang. New dialects of slang, such as leet or Lolspeak, develop as ingroup Internet memes rather than time savers. Many people also use Internet slang in face-to-face, real life communication.\nCreation and evolution.\nOrigins.\nInternet slang originated in the early days of the Internet with some terms predating the Internet. The earliest forms of Internet slang assumed people's knowledge of programming and commands in a specific language. Internet slang is used in chat rooms, social networking services, online games, video games and in the online community. Since 1979, users of communications networks like Usenet created their own shorthand. Internet slang originated as a way to save keystrokes for users, alongside getting around auto-moderated platforms. If a platform banned users for typing a specific word, they would create new ones that had a communal understanding of the definition, allowing them to avoid the ban filter.\nMotivations.\nThe primary motivation for using a slang unique to the Internet is to ease communication. However, while Internet slang shortcuts save time for the writer, they take two times as long for the reader to understand, according to a study by the University of Tasmania. On the other hand, similar to the use of slang in traditional face-to-face speech or written language, slang on the Internet is often a way of indicating group membership.\nInternet slang provides a channel which facilitates and constrains the ability to communicate in ways that are fundamentally different from those found in other semiotic situations. Many of the expectations and practices which we associate with spoken and written language are no longer applicable. The Internet itself is ideal for new slang to emerge because of the richness of the medium and the availability of information. Slang is also thus motivated for the \"creation and sustenance of online communities\". These communities, in turn, play a role in solidarity or identification or an exclusive or common cause.\nDavid Crystal distinguishes among five areas of the Internet where slang is used \u2014 The Web itself, email, asynchronous chat (for example, mailing lists), synchronous chat (for example, Internet Relay Chat), and virtual worlds. The electronic character of the channel has a fundamental influence on the language of the medium. Options for communication are constrained by the nature of the hardware needed in order to gain Internet access. Thus, productive linguistic capacity (the type of information that can be sent) is determined by the preassigned characters on a keyboard, and receptive linguistic capacity (the type of information that can be seen) is determined by the size and configuration of the screen. Additionally, both sender and receiver are constrained linguistically by the properties of the internet software, computer hardware, and networking hardware linking them. Electronic discourse refers to writing that is \"very often reads as if it were being spoken \u2013 that is, as if the sender were writing talking\".\nTypes of slang.\nInternet slang does not constitute a homogeneous language variety; rather, it differs according to the user and type of Internet situation. Audience design occurs in online platforms, and therefore online communities can develop their own sociolects, or shared linguistic norms.\nWithin the language of Internet slang, there is still an element of prescriptivism, as seen in style guides, for example \"Wired Style\", which are specifically aimed at usage on the Internet. Even so, few users consciously heed these prescriptive recommendations on CMC (Computer-mediated communication), but rather adapt their styles based on what they encounter online. Although it is difficult to produce a clear definition of Internet slang, the following types of slang may be observed. This list is not exhaustive.\nViews.\nMany debates about how the use of slang on the Internet influences language outside of the digital sphere go on. Even though the direct causal relationship between the Internet and language has yet to be proven by any scientific research, Internet slang has invited split views on its influence on the standard of language use in non-computer-mediated communications.\nPrescriptivists tend to have the widespread belief that the Internet has a negative influence on the future of language, and that it could lead to a degradation of standard. Some would even attribute any decline of standard formal English to the increase in usage of electronic communication. It has also been suggested that the linguistic differences between Standard English and CMC can have implications for literacy education. This is illustrated by the widely reported example of a school essay submitted by a Scottish teenager, which contained many abbreviations and acronyms likened to SMS language. There was great condemnation of this style by the mass media as well as educationists, who expressed that this showed diminishing literacy or linguistic abilities.\nOn the other hand, descriptivists have counter-argued that the Internet allows better expressions of a language. Rather than established linguistic conventions, linguistic choices sometimes reflect personal taste. It has also been suggested that as opposed to intentionally flouting language conventions, Internet slang is a result of a lack of motivation to monitor speech online. Hale and Scanlon describe language in emails as being derived from \"writing the way people talk\", and that there is no need to insist on 'Standard' English. English users, in particular, have an extensive tradition of etiquette guides, instead of traditional prescriptive treatises, that offer pointers on linguistic appropriateness. Using and spreading Internet slang also adds onto the cultural currency of a language. It is important to the speakers of the language due to the foundation it provides for identifying within a group, and also for defining a person's individual linguistic and communicative competence. The result is a specialized subculture based on its use of slang.\nIn the workspace, internet slang and abbreviation is becoming more acceptable. People are resonating with each other when they see a quickly jotted down message with lots of contractions and slang added in. As long as 'Sent from my iPhone' appears at the bottom of an email, most people are willing to look the other way when it comes to formal grammar.\nIn American schools, internet slang has started to become more common in a real-life setting. The current '6-7' trend has spread to most middle schools in America, now being spoken in person. '6-7,' slang initially derived from the internet, has now made its way into the classroom, and people have conflicting views on it. The slang itself does not have much meaning, leaving some teachers confused and angry, while others are just happy that their students are smiling and having fun. Taylor Jones, a linguist and social scientist, attempted to explain what people thought of its lack of meaning: \u201cI think that\u2019s part of what upsets people about it, and I think that\u2019s part of what people like about it.\u201d\nInternet slang has borrowed heavily from African-American Vernacular English (AAVE), which is often seen as an example of cultural appropriation.\nIn scholarly research, attention has been drawn to the effect of the use of Internet slang in ethnography, and more importantly to how conversational relationships online change structurally because slang is used.\nIn German, there is already considerable controversy regarding the use of anglicisms outside of CMC. This situation is even more problematic within CMC, since the jargon of the medium is dominated by English terms. An extreme example of an anti-anglicisms perspective can be observed from the chatroom rules of a Christian site, which bans all anglicisms (\"\" [Using anglicisms is strictly prohibited!]), and also translates even fundamental terms into German equivalents.\nJournalism.\nIn April 2014, \"Gawker\"'s editor-in-chief Max Read instituted new writing style guidelines banning internet slang for his writing staff. Internet slang has gained attraction, however in other publications ranging from BuzzFeed to The Washington Post, gaining attention from younger viewers. Clickbait headlines have particularly sparked attention, originating from the rise of BuzzFeed in the journalistic sphere which ultimately lead to an online landscape populated with social media references and a shift in language use.\nBeyond the clickbait, internet slang is now used in modern news articles. After Faker, a professional League of Legends player, won the 2025 League of Legends world championship and his sixth championship total, The New York Times' Athletic wrote about him. In the title they reference Faker as the 'GOAT' of League, a commonly used term in internet slang.\nThe scene of journalism as a whole has become increasingly interested in internet slang over the past few years. The New York Times has published many articles covering internet slang, or as they refer to much of it, 'Gen Alpha' slang. Journalists are interested in explaining the lexicon of the youth, helping older generations better understand what their children are talking about. One Times article alone covers over 10 different words of internet slang, ranging from terms like 'gyat' to what a 'rizzler' is. Two years later, the Time published yet another article, explaining more of the Gen Z and Gen Alpha vernacular. This article spent less time explaining multiple terms and instead focused in on a specific one: 'chopped.' As internet slang becomes more ubiquitous in the modern era, journalists are looking to keep people informed on the changing ways that people are communicating.\nUse beyond computer-mediated communication.\nInternet slang has crossed from being mediated by the computer into other non-physical domains. Here, these domains are taken to refer to any domain of interaction where interlocutors need not be geographically proximate to one another, and where the Internet is not primarily used. Internet slang is now prevalent in telephony, mainly through short messages (SMS) communication. Abbreviations and interjections, especially, have been popularized in this medium, perhaps due to the limited character space for writing messages on mobile phones. Another possible reason for this spread is the convenience of transferring the existing mappings between expression and meaning into a similar space of interaction.\nAt the same time, Internet slang has also taken a place as part of everyday offline language, among those with digital access. The nature and content of online conversation is brought forward to direct offline communication through the telephone and direct talking, as well as through written language, such as in writing notes or letters. In the case of interjections, such as numerically based and abbreviated Internet slang, are not pronounced as they are written physically or replaced by any actual action. Rather, they become lexicalized and spoken like non-slang words in a \"stage direction\" like fashion, where the actual action is not carried out but substituted with a verbal signal. The notions of flaming and trolling have also extended outside the computer, and are used in the same circumstances of deliberate or unintentional implicatures.\nThe expansion of Internet slang has been furthered through codification and the promotion of digital literacy. The subsequently existing and growing popularity of such references among those online as well as offline has thus advanced Internet slang literacy and globalized it. Awareness and proficiency in manipulating Internet slang in both online and offline communication indicates digital literacy and teaching materials have even been developed to further this knowledge. A South Korean publisher, for example, has published a textbook that details the meaning and context of use for common Internet slang instances and is targeted at young children who will soon be using the Internet. Similarly, Internet slang has been recommended as language teaching material in second language classrooms in order to raise communicative competence by imparting some of the cultural value attached to a language that is available only in slang.\nMeanwhile, well-known dictionaries such as the ODE and Merriam-Webster have been updated with a significant and growing body of slang jargon. Besides common examples, lesser known slang and slang with a non-English etymology have also found a place in standardized linguistic references. Along with these instances, literature in user-contributed dictionaries such as Urban Dictionary has also been added to. Codification seems to be qualified through frequency of use, and novel creations are often not accepted by other users of slang. In the past few years, internet slang has been seeing a massive rise in acceptance from dictionaries on the web. Dictionary.com's word of the year for 2025 was the term '67,' a piece of internet slang largely used by Gen Alpha on TikTok, and now, real life.\nPolitics.\nIn recent years, politicians have begun using internet slang in their campaigns. In the 2025 New York City Mayoral race, Curtis Sliwa, the republican nominee, used the term 'glazing' in a debate with Zohran Mamdani and Andrew Cuomo. Sliwa ended up receiving 7% of the overall vote. On the other hand, Mamdani used a largely online platform, featuring many Instagram Reels to convey information to his target audience. He catered to Gen Z and Millennials by taking to the internet and proving he was one of them by using his own variants of Internet Slang.\nA study showed that online, most people are interacting with political news utilizing slang. In comment sections of news article, sub dialects of internet slang are being created, solely based around politics and current movements. The study also found that depending on the news site being commented on, slang differences would heavily vary. Internet slang used on The New York Times site would be incredibly different than that seen on Breitbart.\nPresent.\nAlthough Internet slang began as a means of \"opposition\" to mainstream language, its popularity with today's globalized digitally literate population has shifted it into a part of everyday language, where it also leaves a profound impact. 6\u20137, a meme that grew to fame in 2025 is a perfect example. It is a term that does not have a true meaning to it, but was developed and catalysed on the internet as slang. The term grew so big that dictionary.com labeled it as their 'Word of the Year' for 2025. They stated that its large usage by generation alpha in a real world context earned it the number one spot. Its influence reached beyond that of the computer screen, changing how kids interact with their parents, teachers, and friends. Other terms like 'rizz' have seen massive uses in modern-day life, all while they originated from online figures such as Kai Cenat.\nFrequently used slang also have become conventionalised into memetic \"unit[s] of cultural information\". These memes in turn are further spread through their use on the Internet, prominently through websites. The Internet as an \"information superhighway\" is also catalysed through slang. The evolution of slang has also created a 'slang union' as part of a unique, specialised subculture. Such impacts are, however, limited and requires further discussion especially from the non-English world. This is because Internet slang is prevalent in languages more actively used on the Internet, like English, which is the Internet's lingua franca.\nAround the world.\nAside from the more frequent abbreviations, acronyms, and emoticons, Internet slang also uses archaic words or the lesser-known meanings of mainstream terms. Regular words can also be altered into something with a similar pronunciation but altogether different meaning, or attributed new meanings altogether. Phonetic transcriptions are the transformation of words to how it sounds in a certain language, and are used as internet slang. In places where logographic languages are used, such as China, a visual Internet slang exists, giving characters dual meanings, one direct and one implied.\nThe Internet has helped people from all over the world to become connected to one another, enabling \"global\" relationships to be formed. As such, it is important for the various types of slang used online to be recognizable for everyone. It is also important to do so because of how other languages are quickly catching up with English on the Internet, following the increase in Internet usage in predominantly non-English speaking countries. In fact, as of January 2020, only approximately 25.9% of the online population is made up of English speakers.\nDifferent cultures tend to have different motivations behind their choice of slang, on top of the difference in language used. For example, in China, because of the tough Internet regulations imposed, users tend to use certain slang to talk about issues deemed as sensitive to the government. These include using symbols to separate the characters of a word to avoid detection from manual or automated text pattern scanning and consequential censorship. An outstanding example is the use of the term river crab to denote censorship. River crab (hexie) is pronounced the same as \"harmony\"\u2014the official term used to justify political discipline and censorship. As such Chinese netizens reappropriate the official terms in a sarcastic way.\nAbbreviations are popular across different cultures, including countries like Japan, China, France, Portugal, etc., and are used according to the particular language the Internet users speak. Significantly, this same style of slang creation is also found in non-alphabetical languages as, for example, a form of \"e gao\" or alternative political discourse.\nThe difference in language often results in miscommunication, as seen in an onomatopoeic example, \"555\", which sounds like \"crying\" in Chinese, and \"laughing\" in Thai. A similar example is between the English \"haha\" and the Spanish \"jaja\", where both are onomatopoeic expressions of laughter, but the difference in language also meant a different consonant for the same sound to be produced. For more examples of how other languages express \"laughing out loud\", see also: LOL\nIn terms of culture, in Chinese, the numerically based onomatopoeia \"770880\" (), which means to 'kiss and hug you', is used. This is comparable to \"XOXO\", which many Internet users use. In French, \"pk\" or \"pq\" is used in the place of pourquoi, which means 'why'. This is an example of a combination of onomatopoeia and shortening of the original word for convenience when writing online.\nIn conclusion, every different country has their own language background and cultural differences and hence, they tend to have their own rules and motivations for their own Internet slang. However, at present, there is still a lack of studies done by researchers on some differences between the countries.\nOn the whole, the popular use of Internet slang has resulted in a unique online and offline community as well as a couple sub-categories of \"special internet slang which is different from other slang spread on the whole internet... similar to jargon... usually decided by the sharing community\". It has also led to virtual communities marked by the specific slang they use and led to a more homogenized yet diverse online culture.\nInternet slang in advertisements.\nInternet slang can make advertisements more effective. Through two empirical studies, it was proven that Internet slang could help promote or capture the crowd's attention through advertisement, but did not increase the sales of the product. However, using Internet slang in advertisement may attract a certain demographic, and might not be the best to use depending on the product or goods. Furthermore, an overuse of Internet slang also negatively effects the brand due to quality of the advertisement, but using an appropriate amount would be sufficient in providing more attention to the ad. According to the experiment, Internet slang helped capture the attention of the consumers of necessity items. However, the demographic of luxury goods differ, and using Internet slang would potentially have the brand lose credibility due to the appropriateness of Internet slang.\nAnother study found that what type of slang used altered how customers perceived a brand. Brands that used amiable slang were more likely to be perceived by consumers as sincere, whereas harsher slang would make consumers feel the brand is more competent. It is important to note that the experiment was conducted entirely in China, sampling only that portion of the world's internet userbase.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "15173", "revid": "49117425", "url": "https://en.wikipedia.org/wiki?curid=15173", "title": "Islamic", "text": ""}
{"id": "15174", "revid": "49255800", "url": "https://en.wikipedia.org/wiki?curid=15174", "title": "Impi", "text": "Zulu armed body of men or regiment\n is a Nguni word meaning war or combat and by association any body of men gathered for war, for example is a term denoting an army. were formed from regiments () from large militarised homesteads (). In English is often used to refer to a Zulu regiment, which is called an in Zulu, or the army of the Zulu Kingdom.\nIts beginnings lie far back in historic local warfare customs, when groups of armed men called battled. They were systematised radically by the Zulu king Shaka, who was then only the exiled illegitimate son of king Senzangakhona kaJama, but already showing much prowess as a general in the army () of Mthethwa king Dingiswayo in the Ndwandwe\u2013Zulu War of 1817\u20131819.\nGenesis.\nThe Zulu impi is popularly identified with the ascent of Shaka, ruler of the relatively small Zulu tribe before its explosion across the landscape of southern Africa, but its earliest shape as an instrument of statecraft lies in the innovations of the Mthethwa chieftain Dingiswayo, according to some historians (Morris 1965). These innovations in turn drew upon existing tribal customs, such as the \"iNtanga\". This was an age grade tradition common among many of the Bantu peoples of the continent's southern region. Young men were organised into age groups, with each cohort responsible for certain duties and tribal ceremonies. Periodically, the older age grades were summoned to the kraals of sub-chieftains, or \"inDunas\", for consultations, assignments, and an induction ceremony that marked their transition from boys to full-fledged adults and warriors, the \"ukuButwa\". Kraal or settlement elders generally handled local disputes and issues. Above them were the inDunas, and above the inDunas stood the chief of a particular clan lineage or tribe. The inDunas handled administrative matters for their chiefs \u2013 ranging from settlement of disputes to the collection of taxes. In times of war, the inDunas supervised the fighting men in their areas, forming leadership of the military forces deployed for combat. The age grade \"iNtangas\", under the guidance of the inDunas, formed the basis for the systematic regimental organisation that would become known worldwide as the impi.\nLimited nature of early tribal warfare.\nWarfare was of low intensity among the KwaZulu Natal tribes prior to the rise of Shaka, though it occurred frequently. Objectives were typically limited to such matters as cattle raiding, avenging some personal insult, or resolving disputes over segments of grazing land. Generally a loose mob, called an \"impi\" participated in these melees. There were no campaigns of extermination against the defeated. They simply moved on to other open spaces on the veldt, and equilibrium was restored. \nThe bow and arrow were known but seldom used. Warfare, like the hunt, depended on skilled spearmen and trackers. The primary weapon was a thin throwing spear, the \"assegai\"; several were carried into combat. Defensive equipment included a small cowhide shield, which was later improved by King Shaka. Many battles were prearranged, with the clan warriors meeting at an agreed place and time while women and children of the clan watched from some distance away. Ritualized taunts, single combats and tentative charges were the typical pattern. If the affair did not dissipate before, one side might find enough courage to mount a sustained attack and drive their enemies. Casualties were usually light. The defeated clan might pay in lands or cattle and have captives to be ransomed but extermination and mass casualties were rare. Tactics were rudimentary. \nOutside the ritual battles, the quick raid was the most frequent combat action, marked by burning kraals, seizure of captives, and the driving off of cattle. Pastoral herders and light agriculturalists, the Bantu did not usually build permanent fortifications to fend off enemies. A clan under threat simply packed their meagre material possessions, rounded up their cattle and fled until the marauders were gone. If the marauders did not stay to permanently dispossess them of grazing areas, the fleeing clan might return to rebuild in a day or two. The genesis of the Zulu impi thus lies in tribal structures existing long before the coming of Europeans or the Shaka era.\nRise of Dingiswayo.\nIn the early 19th century, a combination of factors began to change the customary pattern. These included rising populations, the growth of white settlement and slaving that dispossessed native peoples both at the Cape and in Portuguese Mozambique, and the rise of ambitious \"new men.\" One such man, a warrior called Dingiswayo (\"the Troubled One\") of the Mthethwa rose to prominence. Historians such as Donald Morris hold that his political genius laid the basis for a relatively light hegemony. This was established through a combination of diplomacy and conquest, using not extermination or slavery, but strategic reconciliation and judicious force of arms. This hegemony reduced the frequent feuding and fighting among the small clans in the Mthethwa's orbit, transferring their energies to more centralised forces. Under Dingiswayo the age grades came to be regarded as military drafts, deployed more frequently to maintain the new order. It was from these small clans, including among them the eLangeni and the Zulu, that Shaka sprung.\nAscent and innovations of Shaka.\nShaka proved himself to be one of Dingiswayo's most able warriors after the military call up of his age grade to serve in the Mthethwa forces. He fought with his iziCwe regiment wherever he was assigned during this early period, but from the beginning, Shaka's approach to battle did not fit the traditional mould. He began to implement his own individual methods and style, designing the famous short stabbing spear the \"iKlwa\", a larger, stronger shield, and discarding the oxhide sandals that he felt slowed him down. These methods proved effective on a small scale, but Shaka himself was restrained by his overlord. His conception of warfare was far more extreme than the reconciliatory methods of Dingiswayo. He sought to bring combat to a swift and bloody decision, as opposed to duels of individual champions, scattered raids, or limited skirmishes where casualties were comparatively light. While his mentor and overlord Dingiswayo lived, Shaka's methods were reined in, but the removal of this check gave the Zulu chieftain a much broader scope. It was under his rule that a much more rigorous mode of tribal warfare came into being. This newer, brutal focus demanded changes in weapons, organisation and tactics.\nWeapons and shields.\nShaka is credited with introducing a new variant of the traditional weapon, demoting the long, spindly throwing spear in favour of a heavy-bladed, short-shafted stabbing spear. He is also said to have introduced a larger, heavier cowhide shield (\"isihlangu\"), and trained his forces to engage the enemy in more effective hand-to-hand combat. The throwing spear was not discarded, but standardised like the stabbing implement and carried as a missile weapon, typically discharged at the foe, before close contact. These weapons changes integrated with and facilitated an aggressive mobility and tactical organisation.\nAs weapons, the Zulu warrior carried the \"iklwa\" stabbing spear (losing one could result in execution) and a club or cudgel fashioned from dense hardwood known in Zulu as the \"iwisa\", usually called the knobkerrie or knobkerry in English and knopkierie in Afrikaans, for beating an enemy in the manner of a mace. Zulu officers often carried the half-moon-shaped Zulu ax (\"isizenze\"), but this weapon was more of a symbol to show their rank. The iklwa \u2013 so named because of the sucking sound it made when withdrawn from a human body \u2013 with its long and broad blade was an invention of Shaka that superseded the older thrown \"ipapa\" (so named because of the \"pa-pa\" sound it made as it flew through the air). The \"iklwa\" could theoretically be used both in melee and as a thrown weapon, but warriors were forbidden in Shaka's day from throwing it, which would disarm them and give their opponents something to throw back. Moreover, Shaka felt it discouraged warriors from closing into hand-to-hand combat.\nShaka's brother and successor, Dingane kaSenzangakhona reintroduced greater use of the throwing spear, perhaps as a counter to Boer firearms.\nAs early as Shaka's reign small numbers of firearms, often obsolete muskets and rifles, were obtained by the Zulus from Europeans by trade. In the aftermath of the defeat of the British at the Battle of Isandlwana in 1879, many Martini\u2013Henry rifles were captured by the Zulus together with considerable amounts of ammunition. The advantage of this capture is debatable due to the alleged tendency of Zulu warriors to close their eyes when firing such weapons. The possession of firearms did little to change Zulu tactics, which continued to rely on a swift approach to the enemy to bring him into close combat.\nAll warriors carried a shield made of oxhide, which retained the hair, with a central stiffening shaft of wood, the \"mgobo\". Shields were the property of the king; they were stored in specialised structures raised off the ground for protection from vermin when not issued to the relevant regiment. The large \"isihlangu\" shield of Shaka's day was about five feet in length and was later partially replaced by the smaller \"umbumbuluzo\", a shield of identical manufacture but around three and a half feet in length. Close combat relied on co-ordinated use of the \"iklwa\" and shield. The warrior sought to get the edge of his shield behind the edge of his enemy's, so that he could pull the enemy's shield to the side, thus opening him to a thrust with the \"iklwa\" deep into the abdomen or chest.\nLogistics.\nThe fast-moving host, like all military formations, needed supplies. These were provided by young boys, who were attached to a force and carried rations, cooking pots, sleeping mats, extra weapons and other material. Cattle were sometimes driven on the hoof as a movable larder. Again, such arrangements in the local context were probably nothing unusual. What was different was the systematisation and organisation, a pattern yielding major benefits when the Zulu were dispatched on raiding missions.\nAge-grade regimental system.\nAge-grade groupings of various sorts were common in the Bantu tribal culture of the day, and indeed are still important in much of Africa. Age grades were responsible for a variety of activities, from guarding the camp, to cattle herding, to certain rituals and ceremonies. It was customary in Zulu culture for young men to provide limited service to their local chiefs until they were married and recognised as official householders. Shaka manipulated this system, transferring the customary service period from the regional clan leaders to himself, strengthening his personal hegemony. Such groupings on the basis of age, did not constitute a permanent, paid military in the modern Western sense, nevertheless they did provide a stable basis for sustained armed mobilisation, much more so than ad hoc tribal levies or war parties.\nShaka organised the various age grades into regiments, and quartered them in special military kraals, with each regiment having its own distinctive names and insignia. Some historians argue that the large military establishment was a drain on the Zulu economy and necessitated continual raiding and expansion. This may be true since large numbers of the society's men were isolated from normal occupations, but whatever the resource impact, the regimental system was clearly built on existing tribal cultural elements that could be adapted and shaped to fit an expansionist agenda.\nAfter their 20th birthdays, young men would be sorted into formal \"ibutho\" (plural \"amabutho\") or regiments. They would build their \"i=handa\" (often referred to as a 'homestead', as it was basically a stockade group of huts surrounding a corral for cattle), their gathering place when summoned for active service. Active service continued until a man married, a privilege only the king bestowed. The amabutho were recruited on the basis of age rather than regional or tribal origin. The reason for this was to enhance the centralised power of the Zulu king at the expense of clan and tribal leaders. They swore loyalty to the king of the Zulu nation.\nMobility, training and insignia.\nShaka discarded sandals to enable his warriors to run faster. Initially the move was unpopular, but those who objected were simply killed, a practice that quickly concentrated the minds of remaining personnel. Zulu tradition indicates that Shaka hardened the feet of his troops by having them stamp thorny tree and bush branches flat. Shaka drilled his troops frequently, implementing forced marches covering more than fifty miles a day. He also drilled the troops to carry out encirclement tactics (see below). Such mobility gave the Zulu a significant impact in their local region and beyond. Upkeep of the regimental system and training seems to have continued after Shaka's death, although Zulu defeats by the Boers, and growing encroachment by British colonists, sharply curtailed raiding operations prior to the War of 1879. Morris (1965, 1982) records one such mission under King Mpande to give green warriors of the uThulwana regiment experience: a raid into Swaziland, dubbed \"Fund' uThulwana\" by the Zulu, or \"Teach the uThulwana\".\nImpi warriors were trained as early as age six, joining the army as \"udibi\" porters at first, being enrolled into same-age groups (\"intanga\"). Until they were \"buta\"'d, Zulu boys accompanied their fathers and brothers on campaign as servants. Eventually, they would go to the nearest \"ikhanda\" to \"kleza\" (literally, \"to drink directly from the udder\"), at which time the boys would become \"inkwebane\", cadets. They would spend their time training until they were formally enlisted by the king. They would challenge each other to stick fights, which had to be accepted on pain of dishonor.\nIn Shaka's day, warriors often wore elaborate plumes and cow tail regalia in battle, but by the Anglo-Zulu War of 1879, many warriors wore only a loin cloth and a minimal form of headdress. The later period Zulu soldier went into battle relatively simply dressed, painting his upper body and face with chalk and red ochre, despite the popular conception of elaborately panoplied warriors. Each \"ibutho\" had a singular arrangement of headdress and other adornments, so that the Zulu army could be said to have had regimental uniforms; latterly the 'full-dress' was only worn on festive occasions. The men of senior regiments would wear, in addition to their other headdress, the head-ring (\"isicoco\") denoting their married state. A gradation of shield colour was found, junior regiments having largely dark shields the more senior ones having shields with more light colouring; Shaka's personal regiment \"Fasimba\" (The Haze) having white shields with only a small patch of darker colour. This shield uniformity was facilitated by the custom of separating the king's cattle into herds based on their coat colours.\nCertain adornments were awarded to individual warriors for conspicuous courage in action; these included a type of heavy brass arm-ring (\"ingxotha\") and an intricate necklace composed of interlocking wooden pegs (\"iziqu\").\nTactics.\nThe Zulu typically took the offensive, deploying in the well known \"buffalo horns\" formation. The attack layout was composed of four elements, each of which represented a grouping of Zulu regiments:\nEncirclement tactics were not unique in the region and attempts to surround an enemy were not unknown even in the ritualised battles. The use of separate manoeuvre elements to support a stronger central group was also known in pre-mechanised tribal warfare, as is the use of reserve echelons farther back. What was unique about the Zulu was the degree of organisation, consistency with which they used these tactics, and the speed at which they executed them. Developments and refinements may have taken place after Shaka's death, as witnessed by the use of larger groupings of regiments by the Zulu against the British in 1879. Missions, available manpower and enemies varied, but whether facing native spear, or European bullet, the impis generally fought in and adhered to the classical buffalo horns pattern.\nOrganisation of the Zulu forces.\nOrganization. The Zulu forces were generally grouped into 3 levels: regiments, corps of several regiments, and \"armies\" or bigger formations, although the Zulu did not use these terms in the modern sense. Size distinctions were taken account of, any grouping of men on a mission could collectively be called an impi, whether a raiding party of 100 or horde of 10,000. Numbers were not uniform, but dependent on a variety of factors including assignments by the king, or the manpower mustered by various clan chiefs or localities. A regiment might be 400 or 4000 men. These were grouped into Corps that took their name from the military kraals where they were mustered, or sometimes the dominant regiment of that locality. While the modest Zulu population could not turn out the hundreds of thousand available to major world or continental powers like France, Britain, or Russia, the Zulu \"nation in arms\" approach could mobilize substantial forces in local context for short campaigns, and maneuver them in the Western equivalent of divisional strength. The victory won by Zulu king Cetshwayo at Ndondakusuka, for example, two decades before the Anglo-Zulu War of 1879, involved a battlefield deployment of 30,000 troops.\nHigher command and unit leadership. An inDuna guided each regiment, and he in turn answered to senior izinduna who controlled the corps grouping. Overall guidance of the host was furnished by elder izinduna usually with many years of experience. One or more of these elder chiefs might accompany a big force on an important mission. Coordination of tactical movements was supplied by the indunas who used hand signals and messengers. Generally before deploying for battle, the regiments were made to squat in a semicircle while these commanders made final assignments and adjustments. Lower level regimental izinduna, like the NCOs of today's armies, and yesterday's Roman centurions, were extremely important to morale and discipline. Prior to the clash at Isandhlwana for example, they imposed order on the frenzied rush of warriors eager to get at the British, and steadied those faltering under withering enemy fire during the battle. The widely spaced maneuvers of an impi sometimes could make control problematic once an attack was unleashed. Indeed, the Zulu attacks on the British strongpoints at Rorke's Drift and at Kambula, (both bloody defeats) seemed to have been carried out by over-enthusiastic leaders and warriors despite contrary orders of the Zulu King, Cetshwayo. Such over-confidence or disobedience by thrusting leaders or forces is not unusual in warfare. At the Battle of Trebia for example, the over-confident Roman commander Sempronius was provoked into a hasty attack, that resulted in a defeat for Roman arms. Likewise, General George Custer disobeyed the orders of his superior, General Terry, and rashly launched a disastrous charge against Indian forces at the Battle of the Little Bighorn, resulting in the total destruction of his command. Popular film re-enactments display a grizzled \"izinduna\" directing the Zulu host from a promontory with elegant sweeps of the hand, and the reserves still lay within top commanders' overall control. Coordination after an army was set in motion however relied more on the initial pre-positioning and assignments of the regiments before the advance, and the deep understanding by Zulu officers of the general attack plan. These sub-commanders could thus slow down or speed up their approach runs to maintain the general \"buffalo horns\" alignment to match terrain and situation.\nSummary of the Shaka reforms.\nAs noted above, Shaka was neither the originator of the impi, or the age grade structure, nor the concept of a bigger grouping than the small clan system. His major innovations were to blend these traditional elements in a new way, to systematise the approach to battle, and to standardise organization, methods and weapons, particularly in his adoption of the \"ilkwa\" \u2013 the Zulu thrusting spear, unique long-term regimental units, and the \"buffalo horns\" formation. Dingswayo's approach was of a loose federation of allies under his hegemony, combining to fight, each with their own contingents, under their own leaders. Shaka dispensed with this, insisting instead on a standardised organisation and weapons package that swept away and replaced old clan allegiances with loyalty to himself. This uniform approach also encouraged the loyalty and identification of warriors with their own distinctive military regiments. In time, these warriors, from many conquered tribes and clans came to regard themselves as one nation- the Zulu. The so-called Marian reforms of Rome in the military sphere are referenced by some writers as similar. While other ancient powers such as the Carthaginians maintained a patchwork of force types, and the legions retained such phalanx-style holdovers like the \"triarii\", later writers would attribute to Marius the implementation of one consistent standardised approach for all the infantry that likely actually took place gradually across many years. This enabled more disciplined formations and efficient execution of tactics over time against a variety of enemies. As one military historian notes: \n\"Combined with Shaka's \"buffalo horns\" attack formation for surrounding and annihilating enemy forces, the Zulu combination of iklwa and shield\u2014similar to the Roman legionaries' use of gladius and scutum\u2014was devastating. By the time of Shaka's assassination in 1828, it had made the Zulu kingdom the greatest power in southern Africa and a force to be reckoned with, even against Britain's modern army in 1879.\"\nIn battle.\nTo understand the full scope of the impi's performance in battle, military historians of the Zulu typically look to its early operations against internal African enemies, not merely the British interlude. In terms of numbers, the operations of the impi would change\u2014from the Western equivalent of small company and battalion size forces, to manoeuvres in multi-divisional strength of between 10,000 and 40,000 men. The victory won by Zulu king Cetswayo at Ndondakusuka, for example, two decades before the Anglo-Zulu War, involved a deployment of 30,000 troops. These were sizeable formations in regional context but represented the bulk of prime Zulu fighting strength. Few impi-style formations were to routinely achieve this level of mobilisation for a single battle. By comparison, at Cannae, the Romans deployed 80,000 men, and generally could put tens of thousands more into smaller combat actions. The popular notion of countless attacking black spearmen is a distorted one. Manpower supplies on the continent were often limited. In the words of one historian: \"The savage hordes of popular lore seldom materialized on African battlefields.\" This limited resource base would hurt the Zulu when they confronted technologically advanced world powers such as Britain. The advent of new weapons like firearms would also have a profound impact on the African battlefield, but as will be seen, the impi-style forces largely eschewed firearms, or used them in a minor way. Whether facing native spear or European bullet, impis largely fought as they had since the days of Shaka, from Zululand to Zimbabwe, and from Mozambique to Tanzania.\nThe Zulu had greater numbers than their opponents, but greater numbers massed together in compact arrays simply presented easy targets in the age of modern firearms and artillery. African tribes that fought in smaller guerrilla detachments typically held out against European invaders for a much longer time, as witnessed by the 7-year resistance of the Lobi against the French in West Africa, or the operations of the Berbers in Algeria against the French.\nWhen the Zulu did acquire firearms, most notably captured stocks after the great victory at Isandhlwana, they lacked training and used them ineffectively, consistently firing high to give the bullets \"strength.\" Southern Africa, including the areas near Natal, was teeming with bands like the Griquas who had learned to use guns. Indeed, one such group not only mastered the way of the gun, but became proficient horsemen as well, skills that helped build the Basotho tribe, in what is now the nation of Lesotho. In addition, numerous European renegades or adventurers (both Boer and non-Boer) skilled in firearms were known to the Zulu. Some had even led detachments for the Zulu kings on military missions.\nThroughout the 19th century they persisted in \"human wave\" attacks against well defended European positions where massed firepower devastated their ranks. The ministrations of an \"isAngoma\" (plural: \"izAngoma\") Zulu diviner or \"witch doctor\", and the bravery of individual regiments were ultimately of little use against the volleys of modern rifles, Gatling guns and artillery at the Ineyzane River, Rorke's Drift, Kambula, Gingingdlovu and finally Ulindi.\nIn popular culture.\nThe term \"impi\" has become synonymous with the Zulu nation in international popular culture; it appears in various video games such as \"Civilization III\", ', ', \"\", and \"Civilization VI\", where the Impi is the unique unit for the Zulu faction with Shaka as their leader. 'Impi' is also the title of a very famous South African song by Johnny Clegg and his band Juluka, which has become something of an unofficial national anthem, especially at major international sports events and especially when the opponent is England.\nLyrics:\n\"Impi! O nans'impi iyeza (Impi! Oh here comes impi)\"\n\"Uban'obengathint'amabhubesi? (Who would have touched the lions?)\"\nBefore stage seven of the 2013 Tour de France, the Orica\u2013GreenEDGE cycling team played 'Impi' on their team bus in honor of teammate Daryl Impey, the first South African Tour de France leader.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "15175", "revid": "7903804", "url": "https://en.wikipedia.org/wiki?curid=15175", "title": "Irish mythology", "text": "Irish mythology is the body of myths indigenous to the island of Ireland. It was originally passed down orally in the prehistoric era. In the early medieval era, myths were written down by Christian scribes, who Christianized them to some extent. Irish mythology is the best-preserved branch of Celtic mythology.\nThe myths are conventionally grouped into 'cycles'. The Mythological Cycle consists of tales and poems about the god-like Tuatha D\u00e9 Danann, who are based on Ireland's pagan deities, and other mythical races like the Fomorians. Important works in the cycle are the \"Lebor Gab\u00e1la \u00c9renn\" (\"Book of Invasions\"), a legendary history of Ireland, the \"Cath Maige Tuired\" (\"Battle of Moytura\"), and the \"Aided Chlainne Lir\" (\"Children of Lir\"). The Ulster Cycle consists of heroic legends relating to the Ulaid, the most important of which is the epic \"T\u00e1in B\u00f3 C\u00faailnge\" (\"Cattle Raid of Cooley\"). The Fenian Cycle focuses on the exploits of the mythical hero Finn and his warrior band the Fianna, including the lengthy \"Acallam na Sen\u00f3rach\" (\"Tales of the Elders\"). The Cycles of the Kings comprises legends about historical and semi-historical kings of Ireland (such as \"Buile Shuibhne\", \"The Madness of King Sweeny\"), and tales about the origins of dynasties and peoples.\nThere are also mythological texts that do not fit into any of the cycles; these include the \"echtrai\" tales of journeys to the Otherworld (such as \"The Voyage of Bran\"), and the \"Dindsenchas\" (\"lore of places\"). Some written materials have not survived, and many more myths were likely never written down.\nFigures.\nTuatha D\u00e9 Danann.\nThe main supernatural beings in Irish mythology are the Tuatha D\u00e9 Danann (\"the folk of the goddess Danu\"), also known by the earlier name Tuath D\u00e9 (\"god folk\" or \"tribe of the gods\"). Early medieval Irish writers also called them the \"fir d\u00e9\" (god-men) and \"cen\u00e9la d\u00e9\" (god-kindreds), possibly to avoid calling them simply 'gods'. They are often depicted as kings, queens, bards, warriors, heroes, healers and craftsmen who have supernatural powers and are immortal. Prominent members include The Dagda (\"the great god\"); The Morr\u00edgan (\"the great queen\" or \"phantom queen\"); Lugh; Nuada; Aengus; Brigid; Manann\u00e1n; Dian C\u00e9cht the healer; and Goibniu the smith. They are also said to control the fertility of the land; the tale \"De Gab\u00e1il in t-S\u00edda\" says the first Gaels had to establish friendship with the Tuath D\u00e9 before they could raise crops and herds.\nThey dwell in the Otherworld but interact with humans and the human world. Many are associated with specific places in the landscape, especially the \"s\u00eddhe\": prominent ancient burial mounds such as Br\u00fa na B\u00f3inne, which are entrances to Otherworld realms. The Tuath D\u00e9 can hide themselves with a \"f\u00e9th f\u00edada\" ('magic mist'). They are said to have travelled from the north of the world, but then were forced to live underground in the \"s\u00eddhe\" after the coming of the Irish.\nIn some tales, such as \"Baile in Sc\u00e1il\", kings receive affirmation of their legitimacy from one of the Tuath D\u00e9, or a king's right to rule is affirmed by an encounter with an otherworldly woman (see sovereignty goddess). The Tuath D\u00e9 can also bring doom to unrightful kings.\nThe medieval writers who wrote about the Tuath D\u00e9 were Christians. Sometimes they explained the Tuath D\u00e9 as fallen angels; neutral angels who sided neither with God nor Lucifer and were punished by being forced to dwell on the Earth; or ancient humans who had become highly skilled in magic. However, several writers acknowledged that at least some of them had been gods.\nThere is strong evidence that many of the Tuath D\u00e9 represent the gods of Irish paganism. The name itself means \"tribe of gods\", and the ninth-century \"Sc\u00e9l Tuain meic Cairill\" (Tale of Tuan mac Cairill) speaks of the \"Tuath D\u00e9 ocus And\u00e9\", \"tribe of gods and un-gods\". Goibniu, Credne and Luchta are called the \"tr\u00ed d\u00e9 d\u00e1no\", \"three gods of craft\". In \"Sanas Cormaic\" (Cormac's Glossary), Anu is called \"mother of the Irish gods\", N\u00e9t a \"god of war\", and Brigid a \"goddess of poets\". Writing in the seventh century, T\u00edrech\u00e1n explained the \"s\u00eddh\" folk as \"earthly gods\" (Latin \"dei terreni\"), while \"Fiacc's Hymn\" says the Irish adored the \"s\u00eddh\" before the coming of Saint Patrick. Several of the Tuath D\u00e9 are cognate with ancient Celtic deities: Lugh with Lugus, Brigid with Brigantia, Nuada with Nodons, and Ogma with Ogmios.\nNevertheless, John Carey notes that it is not wholly accurate to describe all of them as gods in the medieval literature itself. He argues that the literary Tuath D\u00e9 are \"sui generis\", and suggests \"immortals\" might be a more neutral term.\nMany of the Tuath D\u00e9 are not defined by singular qualities, but are more of the nature of well-rounded humans, who have areas of special interests or skills like the druidic arts they learned before traveling to Ireland. In this way, they do not correspond directly to other pantheons such as those of the Greeks or Romans.\nIrish goddesses or Otherworldly women are usually connected to the land, the waters, and sovereignty, and are often seen as the oldest ancestors of the people in the region or nation. They are maternal figures caring for the earth itself as well as their descendants, but also fierce defenders, teachers and warriors. The goddess Brigid is linked with poetry, healing, and smithing. Another is the Cailleach, said to have lived many lives that begin and end with her in stone formation. She is still celebrated at Ballycrovane Ogham Stone with offerings and the retelling of her life's stories. The tales of the Cailleach connect her to both land and sea. Several Otherworldly women are associated with sacred sites where seasonal festivals are held. They include Macha of Eamhain Mhacha, Carman, and Tailtiu, among others.\nWarrior goddesses are often depicted as a triad and connected with sovereignty and sacred animals. They guard the battlefield and those who do battle, and according to the stories in the \"T\u00e1in B\u00f3 C\u00faailnge\", some of them may instigate and direct war themselves. The main goddesses of battle are The Morr\u00edgan, Macha, and Badb. Other warrior women are seen in the role of training warriors in the Fianna bands, such as Liath Luachra, one of the women who trained the hero Fionn mac Cumhaill. Zoomorphism is an important feature. Badb Catha, for instance, is \"the Raven of Battle\", and in the \"T\u00e1in B\u00f3 C\u00faailnge\", The Morr\u00edgan shapeshifts into an eel, a wolf, and a cow.\nIrish gods are divided into four main groups. Group one encompasses the older gods of Gaul and Britain. The second group is the main focus of much of the mythology and surrounds the native Irish gods with their homes in burial mounds. The third group are the gods that dwell in the sea and the fourth group includes stories of the Otherworld. The gods that appear most often are the Dagda and Lugh. Some scholars have argued that the stories of these gods align with Greek stories and gods.\nFomorians.\nThe Fomorians or Fomori () are a supernatural race, who are often portrayed as hostile and monstrous beings. Originally, they were said to come from under the sea or the earth. Later, they were portrayed as sea raiders, which was probably influenced by the Viking raids on Ireland around that time. Later still they were portrayed as giants. They are enemies of Ireland's first settlers and opponents of the Tuatha D\u00e9 Danann, although some members of the two races have offspring. The Fomorians were viewed as the alter-egos to the Tuath D\u00e9 The Tuath D\u00e9 defeat the Fomorians in the \"Battle of Mag Tuired\". This has been likened to other Indo-European myths of a war between gods, such as the \u00c6sir and Vanir in Norse mythology and the Olympians and Titans in Greek mythology.\nHeroes.\nHeroes in Irish mythology can be found in two distinct groups. There is the lawful hero who exists within the boundaries of the community, protecting their people from outsiders. Within the kin-group or \"tuath\", heroes are human and gods are not.\nThe Fianna warrior bands are seen as outsiders, connected with the wilderness, youth, and liminal states. Their leader was called Fionn mac Cumhaill, and the first stories of him are told in fourth century. They are considered aristocrats and outsiders who protect the community from other outsiders; though they may winter with a settled community, they spend the summers living wild, training adolescents and providing a space for war-damaged veterans. The time of vagrancy for these youths is designated as a transition in life post puberty but pre-manhood. Manhood being identified as owning or inheriting property. They live under the authority of their own leaders, or may be somewhat anarchic, and may follow other deities or spirits than the settled communities.\nThe church refused to recognize this group as an institution and referred to them as \"sons of death\".\nLegendary creatures.\nThe Oilliph\u00e9ist is a sea-serpent-like monster in Irish mythology and folklore. These monsters were believed to inhabit many lakes and rivers in Ireland and there are legends of saints, especially St. Patrick, and heroes fighting them.\nSources.\nThe three main manuscript sources for Irish mythology are the late 11th/early 12th\u00a0century (Book of the Dun Cow), which is in the library of the Royal Irish Academy, and is the oldest surviving manuscript written entirely in the Irish language; the early 12th-century \"Book of Leinster\", which is in the Library of Trinity College Dublin; and Bodleian Library, MS Rawlinson B 502 (\"Rawl.\"), which is in the Bodleian Library at the University of Oxford. Despite the dates of these sources, most of the material they contain predates their composition.\nOther important sources include a group of manuscripts that originated in the West of Ireland in the late 14th\u00a0century or the early 15th century: \"The Yellow Book of Lecan\", \"The Great Book of Lecan\" and \"The Book of Ballymote\". The first of these is in the Library of Trinity College and the others are in the Royal Irish Academy. The Yellow Book of Lecan is composed of sixteen parts and includes the legends of Fionn Mac Cumhail, selections of legends of Irish Saints, and the earliest known version of the \"T\u00e1in B\u00f3 C\u00faailnge\" (\"The Cattle Raid of Cooley\"). This is one of Europe's oldest epics written in a vernacular language. Other 15th-century manuscripts, such as \"The Book of Fermoy\", also contain interesting materials, as do such later syncretic works such as Geoffrey Keating's \"Foras Feasa ar \u00c9irinn\" (\"The History of Ireland\") (c.\u20091640). These later compilers and writers may well have had access to manuscript sources that have since disappeared.\nMost of these manuscripts were created by Christian monks, who may well have been torn between a desire to record their native culture and hostility to pagan beliefs, resulting in some of the gods being euhemerised. Many of the later sources may also have formed parts of a propaganda effort designed to create a history for the people of Ireland that could bear comparison with the mythological descent of their British invaders from the founders of Rome, as promulgated by Geoffrey of Monmouth and others. There was also a tendency to rework Irish genealogies to fit them into the schemas of Greek or biblical genealogy.\nWhether medieval Irish literature provides reliable evidence of oral tradition remains a matter for debate. Kenneth Jackson described the Ulster Cycle as a \"window on the Iron Age\", and Garret Olmsted has attempted to draw parallels between \"T\u00e1in B\u00f3 Cuailnge\", the Ulster Cycle epic and the iconography of the Gundestrup Cauldron. However, these \"nativist\" claims have been challenged by \"revisionist\" scholars who believe that much of the literature was created, rather than merely recorded, in Christian times, more or less in imitation of the epics of classical literature that came with Latin learning. The revisionists point to passages apparently influenced by the Iliad in \"T\u00e1in B\u00f3 Cuailnge\", and to the \"Togail Tro\u00ed\", an Irish adaptation of Dares Phrygius' \"De excidio Troiae historia\", found in the Book of Leinster. They also argue that the material culture depicted in the stories is generally closer to that of the time of their composition than to that of the distant past.\nMythological Cycle.\nThe Mythological Cycle, comprising stories of the former gods and origins of the Irish, is the least well preserved of the four cycles. It is about the principal people who invaded and inhabited the island. The people include Cessair and her followers, the Formorians, the Partholinians, the Nemedians, the Firbolgs, the Tuatha D\u00e9 Danann, and the Milesians. The most important sources are the \"Metrical Dindshenchas\" or \"Lore of Places\" and the \"Lebor Gab\u00e1la \u00c9renn\" or \"Book of Invasions\". Other manuscripts preserve such mythological tales as \"The Dream of Aengus\", \"the Wooing of \u00c9tain\" and \"Cath Maige Tuireadh\", \"the (second) Battle of Magh Tuireadh\". One of the best known of all Irish stories, \"Oidheadh Clainne Lir\", or \"The Tragedy of the Children of Lir\", is also part of this cycle.\n\"Lebor Gab\u00e1la \u00c9renn\" is a pseudo-history of Ireland, tracing the ancestry of the Irish back to before Noah. It tells of a series of invasions or \"takings\" of Ireland by a succession of peoples, the fifth of whom was the people known as the Tuatha D\u00e9 Danann (\"Peoples of the Goddess Danu\"), who were believed to have inhabited the island before the arrival of the Gaels, or Milesians. They faced opposition from their enemies, the Fomorians, led by Balor of the Evil Eye. Balor was eventually slain by Lugh L\u00e1mfada (Lugh of the Long Arm) at the second battle of Magh Tuireadh. With the arrival of the Gaels, the Tuatha D\u00e9 Danann retired underground to become the fairy people of later myth and legend.\nThe \"Metrical Dindshenchas\" is the great onomastics work of early Ireland, giving the naming legends of significant places in a sequence of poems. It includes a lot of important information on Mythological Cycle figures and stories, including the Battle of Tailtiu, in which the Tuatha D\u00e9 Danann were defeated by the Milesians.\nBy the Middle Ages, the Tuatha D\u00e9 Danann were not viewed so much as gods as the shape-shifting magician population of an earlier Golden Age Ireland. Texts such as \"Lebor Gab\u00e1la \u00c9renn\" and \"Cath Maige Tuireadh\" present them as kings and heroes of the distant past, complete with death-tales. However, there is considerable evidence, both in the texts and from the wider Celtic world, that they were once considered deities.\nEven after they are displaced as the rulers of Ireland, characters such as Lugh, the M\u00f3rr\u00edgan, Aengus and Manann\u00e1n Mac Lir appear in stories set centuries later, betraying their immortality. A poem in the Book of Leinster lists many of the Tuatha D\u00e9, but ends \"Although [the author] enumerates them, he does not worship them\". Goibniu, Creidhne and Luchta are referred to as \"Tr\u00ed D\u00e9 D\u00e1na\" (\"three gods of craftsmanship\"), and the Dagda's name is interpreted in medieval texts as \"the good god\". Nuada is cognate with the British god Nodens; Lugh is a reflex of the pan-Celtic deity Lugus, the name of whom may indicate \"Light\"; Tuireann may be related to the Gaulish Taranis; Ogma to Ogmios; the Badb to Catubodua.\nUlster Cycle.\nThe Ulster Cycle is traditionally set around the first century AD, and most of the action takes place in the provinces of Ulster and Connacht. It consists of a group of heroic tales dealing with the lives of Conchobar mac Nessa, king of Ulster, the great hero C\u00fa Chulainn, who was the son of Lug (Lugh), and of their friends, lovers, and enemies. These are the Ulaid, or people of the North-Eastern corner of Ireland and the action of the stories centres round the royal court at Emain Macha (known in English as Navan Fort), close to the modern town of Armagh. The Ulaid had close links with the Irish colony in Scotland, and part of C\u00fa Chulainn's training takes place in that colony.\nThe cycle consists of stories of the births, early lives and training, wooing, battles, feastings, and deaths of the heroes. It also reflects a warrior society in which warfare consists mainly of single combats and wealth is measured mainly in cattle. These stories are written mainly in prose. The centerpiece of the Ulster Cycle is the \"T\u00e1in B\u00f3 C\u00faailnge\". Other important Ulster Cycle tales include \"The Tragic Death of Aife's only Son\", \"Bricriu's Feast\", and \"The Destruction of Da Derga's Hostel\". \"The Exile of the Sons of Usnach\", better known as the tragedy of Deirdre and the source of plays by John Millington Synge, William Butler Yeats, and Vincent Woods, is also part of this cycle.\nThis cycle is, in some respects, close to the mythological cycle. Some of the characters from the latter reappear, and the same sort of shape-shifting magic is much in evidence, side by side with a grim, almost callous realism. While we may suspect a few characters, such as Medb or C\u00fa Ro\u00ed, of once being deities, and C\u00fa Chulainn in particular displays superhuman prowess, the characters are mortal and associated with a specific time and place. If the Mythological Cycle represents a Golden Age, the Ulster Cycle is Ireland's Heroic Age.\nFianna Cycle.\nLike the Ulster Cycle, the Fianna Cycle or Fenian Cycle, also referred to as the Ossianic Cycle, is concerned with the deeds of Irish heroes. The stories of the Cycle appear to be set around the 3rd century and mainly in the provinces of Leinster and Munster. They differ from the other cycles in the strength of their links with the Gaelic-speaking community in Scotland and there are many extant texts from that country. They also differ from the Ulster Cycle in that the stories are told mainly in verse and that in tone they are nearer to the tradition of romance than the tradition of epic. The stories concern the doings of Fionn mac Cumhaill and his band of soldiers, the Fianna.\nThe single most important source for the Fianna Cycle is the \"Acallam na Sen\u00f3rach\" (\"Colloquy of the Old Men\"), which is found in two 15th\u00a0century manuscripts, the \"Book of Lismore\" and Laud\u00a0610, as well as a 17th\u00a0century manuscript from Killiney, County Dublin. The text is dated from linguistic evidence to the 12th\u00a0century. The text records conversations between Ca\u00edlte mac R\u00f3n\u00e1in and Ois\u00edn, the last surviving members of the Fianna, and Saint Patrick, and consists of about 8,000\u00a0lines. The late dates of the manuscripts may reflect a longer oral tradition for the Fenian stories.\nThe Fianna of the story are divided into the Clann Baiscne, led by Fionn mac Cumhaill (often rendered as \"Finn MacCool\", Finn Son of Cumhall), and the Clann Morna, led by his enemy, Goll mac Morna. Goll killed Fionn's father, Cumhal, in battle and the boy Fionn was brought up in secrecy. As a youth, while being trained in the art of poetry, he accidentally burned his thumb while cooking the Salmon of Knowledge, which allowed him to suck or bite his thumb to receive bursts of stupendous wisdom. He took his place as the leader of his band and numerous tales are told of their adventures. Two of the greatest of the Irish tales, \"T\u00f3raigheacht Dhiarmada agus Ghr\u00e1inne\" (\"The Pursuit of Diarmuid and Gr\u00e1inne)\" and \"Ois\u00edn in T\u00edr na n\u00d3g\" form part of the cycle. The Diarmuid and Grainne story, which is one of the cycle's few prose tales, is a probable source of \"Tristan and Iseult\".\nThe world of the Fianna Cycle is one in which professional warriors spend their time hunting, fighting, and engaging in adventures in the spirit world. New entrants into the band are expected to be knowledgeable in poetry as well as undergo a number of physical tests or ordeals. Most of the poems are attributed to being composed by Ois\u00edn\".\" This cycle creates a bridge between pre-Christian and Christian times.\nKings' Cycle.\nIt was part of the duty of the medieval Irish bards, or court poets, to record the history of the family and the genealogy of the king they served. This they did in poems that blended the mythological and the historical to a greater or lesser degree. The resulting stories from what has come to be known as the Cycle of the Kings, or more correctly Cycles, as there are a number of independent groupings. This term is a more recent addition to the cycles, with it being coined in 1946 by Irish literary critic Myles Dillon.\nThe kings that are included range from the almost entirely mythological Labraid Loingsech, who allegedly became High King of Ireland around 431\u00a0BC, to the entirely historical Brian Boru. However, the greatest glory of the Kings' Cycle is the \"Buile Shuibhne\" (\"The Frenzy of Sweeney\"), a 12th\u00a0century tale told in verse and prose. Suibhne, king of D\u00e1l nAraidi, was cursed by St. Ronan and became a kind of half-man, half bird, condemned to live out his life in the woods, fleeing from his human companions. The story has captured the imaginations of contemporary Irish poets and has been translated by Trevor Joyce and Seamus Heaney.\nOther tales.\n\"Eachtra\u00ed\".\nThe adventures, or \"echtrae\", are a group of stories of visits to the Irish Other World (which may be westward across the sea, underground, or simply invisible to mortals). The most famous, \"Oisin in Tir na n\u00d3g\" belongs to the Fenian Cycle, but several free-standing adventures survive, including \"The Adventure of Conle\", \"The Voyage of Bran mac Ferbail\", and \"The Adventure of L\u00f3egaire\".\n\"Immrama\".\nThe voyages, or \"immrama\", are tales of sea journeys and the wonders seen on them that may have resulted from the combination of the experiences of fishermen combined and the Other World elements that inform the adventures. Of the seven \"immrama\" mentioned in the manuscripts, only three have survived: \"The Voyage of M\u00e1el D\u00fain\", the \"Voyage of the U\u00ed Chorra\", and the \"Voyage of Snedgus and Mac Riagla\". \"The Voyage of Mael Duin\" is the forerunner of the later \"Voyage of St. Brendan\". While not as ancient, later 8th century AD works, that influenced European literature, include \"The Vision of Adamn\u00e1n\".\nFolk tales.\nAlthough there are no written sources of Irish mythology, many stories are passed down orally through traditional storytelling. Some of these stories have been lost, but some Celtic regions continue to tell folktales to the modern-day. Folktales and stories were primarily preserved by monastic scribes from the bards of nobility. Once the noble houses started to decline, this tradition was put to an abrupt end. The bards passed the stories to their families, and the families would take on the oral tradition of storytelling.\nDuring the first few years of the 20th century, Herminie Templeton Kavanagh wrote down many Irish folk tales, which she published in magazines and in two books. Twenty-six years after her death, the tales from her two books, \"Darby O'Gill and the Good People\" and \"Ashes of Old Wishes,\" were made into the film \"Darby O'Gill and the Little People\". Noted Irish playwright Lady Gregory also collected folk stories to preserve Irish history. The Irish Folklore Commission gathered folk tales from the general Irish populace from 1935 onward.\nReferences.\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nSources.\nPrimary sources in English translation\n Primary sources in Medieval Irish\nSecondary sources"}
{"id": "15176", "revid": "11096", "url": "https://en.wikipedia.org/wiki?curid=15176", "title": "Insurance", "text": "Equitable transfer of the risk of a loss, from one entity to another, in exchange for payment\nInsurance is a means of protection from financial loss in which, in exchange for a fee, a party agrees to compensate another party in the event of a certain loss, damage, or injury. It is a form of risk management, primarily used to protect against the risk of a contingent or uncertain loss.\nAn entity which provides insurance is known as an insurer, insurance company, insurance carrier, or underwriter. A person or entity who buys insurance is known as a policyholder, while a person or entity covered under the policy is called an insured. The insurance transaction involves the policyholder assuming a guaranteed, known, and relatively small loss in the form of a payment to the insurer (a premium) in exchange for the insurer's promise to compensate the insured in the event of a covered loss. The loss may or may not be financial, but it must always be reducible to financial terms. Furthermore, it usually involves something in which the insured has an insurable interest established by ownership, possession, or pre-existing relationship.\nThe insured receives a contract, called the insurance policy, which details the conditions and circumstances under which the insurer will compensate the insured, or their designated beneficiary or assignee. The amount of money charged by the insurer to the policyholder for the coverage set forth in the insurance policy is called the premium. If the insured experiences a loss which is potentially covered by the insurance policy, the insured submits a claim to the insurer for processing by a claims adjuster. A mandatory out-of-pocket expense required by an insurance policy before an insurer will pay a claim is called a deductible or excess (or if required by a health insurance policy, a copayment). The insurer may mitigate its own risk by taking out reinsurance, whereby another insurance company agrees to carry some of the risks, especially if the primary insurer deems the risk too large for it to carry.\nHistory.\nEarly methods.\nMethods for transferring or distributing risk were practiced by Chinese and Indian traders as long ago as the 3rd and 2nd millennia BC, respectively. Chinese merchants travelling treacherous river rapids would redistribute their wares across many vessels to limit the loss due to any single vessel capsizing.\n\"Codex Hammurabi\" Law 238 (c. 1755\u20131750 BC) stipulated that a sea captain, ship-manager, or ship charterer who saved a ship from total loss was only required to pay one-half the value of the ship to the ship-owner. In the \"Digesta seu Pandectae\" (533), the second volume of the codification of laws ordered by Justinian I (527\u2013565), a legal opinion written by the Roman jurist Paulus in 235 AD was included about the \"Lex Rhodia\" (\"Rhodian law\"). It articulates the general average principle of marine insurance established on the island of Rhodes in approximately 1000 to 800 BC, plausibly by the Phoenicians during the proposed Dorian invasion and emergence of the purported Sea Peoples during the Greek Dark Ages (c. 1100\u2013c. 750).\nThe law of general average is the fundamental principle that underlies all insurance. In 1816, an archeological excavation in Minya, Egypt produced a Nerva\u2013Antonine dynasty-era tablet from the ruins of the Temple of Antinous in Antino\u00f6polis, Aegyptus. The tablet prescribed the rules and membership dues of a burial society collegium established in Lanuvium, Italia in approximately 133 AD during the reign of Hadrian (117\u2013138) of the Roman Empire. In 1851 AD, future U.S. Supreme Court Associate Justice Joseph P. Bradley (1870\u20131892 AD), once employed as an actuary for the Mutual Benefit Life Insurance Company, submitted an article to the \"Journal of the Institute of Actuaries\". His article detailed an historical account of a Severan dynasty-era life table compiled by the Roman jurist Ulpian in approximately 220 AD that was also included in the \"Digesta\".\nConcepts of insurance has been also found in 3rd century BC Hindu scriptures such as Dharmasastra, Arthashastra and Manusmriti. The ancient Greeks had marine loans. Money was advanced on a ship or cargo, to be repaid with large interest if the voyage prospers. However, the money would not be repaid at all if the ship were lost, thus making the rate of interest high enough to pay for not only for the use of the capital but also for the risk of losing it (fully described by Demosthenes). Loans of this character have ever since been common in maritime lands under the name of bottomry and respondentia bonds.\nThe direct insurance of sea-risks for a premium paid independently of loans began in Belgium about 1300 AD.\nSeparate insurance contracts (i.e., insurance policies not bundled with loans or other kinds of contracts) were invented in Genoa in the 14th century, as were insurance pools backed by pledges of landed estates. The first known insurance contract dates from Genoa in 1347. In the next century, maritime insurance developed widely, and premiums were varied with risks. These new insurance contracts allowed insurance to be separated from investment, a separation of roles that first proved useful in marine insurance.\nThe earliest known policy of life insurance was made in the Royal Exchange, London, on 18 June 1583, for \u00a3383, 6s. 8d. for twelve months on the life of William Gibbons.\nModern methods.\nInsurance became far more sophisticated in Enlightenment-era Europe, where specialized varieties developed.\nProperty insurance as we know it today can be traced to the Great Fire of London, which in 1666 devoured more than 13,000 houses. The devastating effects of the fire converted the development of insurance \"from a matter of convenience into one of urgency, a change of opinion reflected in Sir Christopher Wren's inclusion of a site for \"the Insurance Office\" in his new plan for London in 1667.\" A number of attempted fire insurance schemes came to nothing, but in 1681, economist Nicholas Barbon and eleven associates established the first fire insurance company, the \"Insurance Office for Houses\", at the back of the Royal Exchange to insure brick and frame homes. Initially, 5,000 homes were insured by his Insurance Office.\nAt the same time, the first insurance schemes for the underwriting of business ventures became available. By the end of the seventeenth century, London's growth as a centre for trade was increasing due to the demand for marine insurance. In the late 1680s, Edward Lloyd opened a coffee house, which became the meeting place for parties in the shipping industry wishing to insure cargoes and ships, including those willing to underwrite such ventures. These informal beginnings led to the establishment of the insurance market Lloyd's of London and several related shipping and insurance businesses.\nLife insurance policies were taken out in the early 18th century. The first company to offer life insurance was the Amicable Society for a Perpetual Assurance Office, founded in London in 1706 by William Talbot and Sir Thomas Allen. Upon the same principle, Edward Rowe Mores established the Society for Equitable Assurances on Lives and Survivorship in 1762.\nIt was the world's first mutual insurer and it pioneered age based premiums based on mortality rate laying \"the framework for scientific insurance practice and development\" and \"the basis of modern life assurance upon which all life assurance schemes were subsequently based.\"\nIn the late 19th century \"accident insurance\" began to become available. The first company to offer accident insurance was the Railway Passengers Assurance Company, formed in 1848 in England to insure against the rising number of fatalities on the nascent railway system. \nThe first international insurance rule was the York Antwerp Rules (YAR) for the distribution of costs between ship and cargo in the event of general average. In 1873 the \"Association for the Reform and Codification of the Law of Nations\", the forerunner of the International Law Association (ILA), was founded in Brussels. It published the first YAR in 1890, before switching to the present title of the \"International Law Association\" in 1895.\nBy the late 19th century governments began to initiate national insurance programs against sickness and old age. Germany built on a tradition of welfare programs in Prussia and Saxony that began as early as in the 1840s. In the 1880s Chancellor Otto von Bismarck introduced old age pensions, accident insurance and medical care that formed the basis for Germany's welfare state. In Britain more extensive legislation was introduced by the Liberal government in the National Insurance Act 1911. This gave the British working classes the first contributory system of insurance against illness and unemployment. This system was greatly expanded after the Second World War under the influence of the Beveridge Report, to form the first modern welfare state.\nIn 2008, the International Network of Insurance Associations (INIA), then an informal network, became active and it has been succeeded by the Global Federation of Insurance Associations (GFIA), which was formally founded in 2012 to aim to increase insurance industry effectiveness in providing input to international regulatory bodies and to contribute more effectively to the international dialogue on issues of common interest. It consists of its 40 member associations and 1 observer association in 67 countries, which companies account for around 89% of total insurance premiums worldwide.\nPrinciples.\nInsurance involves pooling funds from many insured entities to pay for the losses that some may incur, a process known as Risk pool. The insured entities are therefore protected from risk for a fee, with the fee being dependent upon the frequency and severity of the event occurring. In order to be an insurable risk, the risk insured against must meet certain characteristics. Insurance as a financial intermediary is a commercial enterprise and a major part of the financial services industry, but individual entities can also self-insure through saving money for possible future losses.\nInsurability.\nRisk which can be insured by private companies typically share seven common characteristics:\nLegal.\nWhen a company insures an individual entity, there are basic legal requirements and regulations. Several commonly cited legal principles of insurance include:\nIndemnification.\nTo \"indemnify\" means to make whole again, or to be reinstated to the position that one was in, to the extent possible, prior to the happening of a specified event or peril. Accordingly, life insurance is generally not considered to be indemnity insurance, but rather \"contingent\" insurance (i.e., a claim arises on the occurrence of a specified event). There are generally three types of insurance contracts that seek to indemnify an insured:\nFrom an insured's standpoint, the result is usually the same: the insurer pays the loss and claims expenses.\nIf the Insured has a \"reimbursement\" policy, the insured can be required to pay for a loss and then be \"reimbursed\" by the insurance carrier for the loss and out of pocket costs including, with the permission of the insurer, claim expenses.\nUnder a \"pay on behalf\" policy, the insurance carrier would defend and pay a claim on behalf of the insured who would not be out of pocket for anything. Most modern liability insurance is written on the basis of \"pay on behalf\" language, which enables the insurance carrier to manage and control the claim.\nUnder an \"indemnification\" policy, the insurance carrier can generally either \"reimburse\" or \"pay on behalf of\", whichever is more beneficial to it and the insured in the claim handling process.\nAn entity seeking to transfer risk (an individual, corporation, or association of any type, etc.) becomes the \"insured\" party once risk is assumed by an \"insurer\", the insuring party, by means of a contract, called an insurance policy. Generally, an insurance contract includes, at a minimum, the following elements: identification of participating parties (the insurer, the insured, the beneficiaries), the premium, the period of coverage, the particular loss event covered, the amount of coverage (i.e., the amount to be paid to the insured or beneficiary in the event of a loss), and exclusions (events not covered). An insured is thus said to be \"indemnified\" against the loss covered in the policy.\nWhen insured parties experience a loss for a specified peril, the coverage entitles the policyholder to make a claim against the insurer for the covered amount of loss as specified by the policy. The fee paid by the insured to the insurer for assuming the risk is called the premium. Insurance premiums from many insureds are used to fund accounts reserved for later payment of claims \u2013 in theory for a relatively few claimants \u2013 and for overhead costs. So long as an insurer maintains adequate funds set aside for anticipated losses (called reserves), the remaining margin is an insurer's profit.\nExclusions.\nPolicies typically include a number of exclusions, for example:\nInsurers may prohibit certain activities which are considered dangerous and therefore excluded from coverage. One system for classifying activities according to whether they are authorised by insurers refers to \"green light\" approved activities and events, \"yellow light\" activities and events which require insurer consultation and/or waivers of liability, and \"red light\" activities and events which are prohibited and outside the scope of insurance cover.\nSocial effects.\nInsurance can have various effects on society through the way that it changes who bears the cost of losses and damage. On one hand it can increase fraud; on the other it can help societies and individuals prepare for catastrophes and mitigate the effects of catastrophes on both households and societies.\nInsurance can influence the probability of losses through moral hazard, insurance fraud, and preventive steps by the insurance company. Insurance scholars have typically used moral hazard to refer to the increased loss due to unintentional carelessness and insurance fraud to refer to increased risk due to intentional carelessness or indifference. Insurers attempt to address carelessness through inspections, policy provisions requiring certain types of maintenance, and possible discounts for loss mitigation efforts. While in theory insurers could encourage investment in loss reduction, some commentators have argued that in practice insurers had historically not aggressively pursued loss control measures\u2014particularly to prevent disaster losses such as hurricanes\u2014because of concerns over rate reductions and legal battles. However, since about 1996 insurers have begun to take a more active role in loss mitigation, such as through building codes.\nMethods of insurance.\nAccording to the study books of The Chartered Insurance Institute, there are variant methods of insurance as follows:\nInsurers' business model.\nInsurers may use the subscription business model, collecting premium payments periodically in return for on-going and/or compounding benefits offered to policyholders.\nInsurance premium.\nInsurers' business model aims to collect more in insurance premiums than is paid out in losses, and to also offer a competitive price which consumers will accept. Insurance premiums can be simplified as:\ninsurance premium = expected value of claims + underwriting expenses + operating expense + profit - return on investment.\nAt the most basic level, insurance premium estimation involves looking at the frequency of claims, and the expected value of the payout for these claims. The most complicated aspect of insuring is the actuarial science of ratemaking (price-setting) of policies, which uses statistics and probability to approximate the rate of future claims based on a given risk. After producing rates, the insurer will use discretion to reject or accept risks through the underwriting process. The insurance company will collect historical loss-data, bring the loss data to present value, and compare these prior losses to the premium collected in order to assess rate adequacy. Loss ratios and expense loads are also used. Rating for different risk characteristics involves\u2014at the most basic level\u2014comparing the losses with \"loss relativities\"\u2014a policy with twice as many losses would, therefore, be charged twice as much. More complex multivariate analyses are sometimes used when multiple characteristics are involved and a univariate analysis could produce confounded results. Other statistical methods may be used in assessing the probability of future losses.\nUpon termination of a given policy, the amount of premium collected minus the amount paid out in claims is the insurer's underwriting profit on that policy. Underwriting performance is measured by something called the \"combined ratio\", which is the ratio of expenses/losses to premiums. A combined ratio of less than 100% indicates an underwriting profit, while anything over 100 indicates an underwriting loss. \nInsurers make money in two ways:\nA company with a combined ratio over 100% may nevertheless remain profitable due to investment earnings.\nInsurance companies earn investment profits on \"float\". Float, or available reserve, is the amount of money on hand at any given moment that an insurer has collected in insurance premiums but has not paid out in claims. Insurers start investing insurance premiums as soon as they are collected and continue to earn interest or other income on them until claims are paid out. The Association of British Insurers (grouping together 400 insurance companies and 94% of UK insurance services) has almost 20% of the investments in the London Stock Exchange. In 2007, U.S. industry profits from float totaled $58 billion. In a 2009 letter to investors, Warren Buffett wrote, \"we were \"paid\" $2.8 billion to hold our float in 2008\".\nIn the United States, the underwriting loss of property and casualty insurance companies was $142.3 billion in the five years ending 2003. But overall profit for the same period was $68.4 billion, as the result of float. Some insurance-industry insiders, most notably Hank Greenberg, do not believe that it is possible to sustain a profit from float forever without an underwriting profit as well, but this opinion is not universally held. Reliance on float for profit has led some industry experts to call insurance companies \"investment companies that raise the money for their investments by selling insurance\".\nNaturally, the float method is difficult to carry out in an economically depressed period generally causing insurers to shift away from investments and to toughen up their underwriting standards, so a poor economy generally means high insurance-premiums. This tendency to swing between profitable and unprofitable periods over time is commonly known as the underwriting, or insurance, cycle.\nClaims.\nClaims and loss handling is the materialized utility of insurance; it is the actual \"product\" paid for. Claims may be filed by insureds directly with the insurer or through brokers or agents. The insurer may require that the claim be filed on its own proprietary forms, or may accept claims on a standard industry form, such as those produced by ACORD.\nInsurance company claims departments employ a large number of claims adjusters, supported by a staff of records management and data entry clerks. Incoming claims are classified based on severity and are assigned to adjusters, whose settlement authority varies with their knowledge and experience. An adjuster undertakes an investigation of each claim, usually in close cooperation with the insured, determines if coverage is available under the terms of the insurance contract (and if so, the reasonable monetary value of the claim), and authorizes payment.\nPolicyholders may hire their own public adjusters to negotiate settlements with the insurance company on their behalf. For policies that are complicated, where claims may be complex, the insured may take out a separate insurance policy add-on, called loss recovery insurance, which covers the cost of a public adjuster in the case of a claim.\nAdjusting liability insurance claims is particularly difficult because they involve a third party, the plaintiff, who is under no contractual obligation to cooperate with the insurer and may in fact regard the insurer as a deep pocket. The adjuster must obtain legal counsel for the insured\u2014either inside (\"house\") counsel or outside (\"panel\") counsel, monitor litigation that may take years to complete, and appear in person or over the telephone with settlement authority at a mandatory settlement conference when requested by a judge.\nIf a claims adjuster suspects underinsurance, the condition of average may come into play to limit the insurance company's exposure.\nIn managing the claims-handling function, insurers seek to balance the elements of customer satisfaction, administrative handling expenses, and claims overpayment leakages. In addition to this balancing act, fraudulent insurance practices are a major business risk that insurers must manage and overcome. Disputes between insurers and insureds over the validity of claims or claims-handling practices occasionally escalate into litigation (see insurance bad faith).\nMarketing.\nInsurers will often use insurance agents to initially market or underwrite their customers. Agents can be captive, meaning they write only for one company, or independent, meaning that they can issue policies from several companies. The existence and success of companies using insurance agents is likely due to the availability of improved and personalised services. Companies also use Broking firms, Banks and other corporate entities (like Self Help Groups, Microfinance Institutions, NGOs, etc.) to market their products.\nTypes.\nAny risk that can be quantified can potentially be insured. Specific kinds of risk that may give rise to claims are known as perils. An insurance policy will set out in detail which perils are covered by the policy and which are not. Below are non-exhaustive lists of the many different types of insurance that exist. A single policy may cover risks in one or more of the categories set out below. For example, vehicle insurance would typically cover both the property risk (theft or damage to the vehicle) and the liability risk (legal claims arising from an accident). A home insurance policy in the United States typically includes coverage for damage to the home and the owner's belongings, certain legal claims against the owner, and even a small amount of coverage for medical expenses of guests who are injured on the owner's property.\nBusiness insurance can take a number of different forms, such as the various kinds of professional liability insurance, also called professional indemnity (PI), which are discussed below under that name; and the business owner's policy (BOP), which packages into one policy many of the kinds of coverage that a business owner needs, in a way analogous to how homeowners' insurance packages the coverages that a homeowner needs.\nVehicle insurance.\nVehicle insurance protects the policyholder against financial loss in the event of an incident involving a vehicle they own, such as in a traffic collision.\nCoverage typically includes:\nGap insurance.\nGAP (Guaranteed Asset Protection) insurance covers the excess amount on an auto loan in an instance where the policyholder's insurance company does not cover the entire loan. Depending on the company's specific policies it might or might not cover the deductible as well. This coverage is marketed for those who put low down payments, have high interest rates on their loans, and those with 60-month or longer terms. Gap insurance is typically offered by a finance company when the vehicle owner purchases their vehicle, but many auto insurance companies offer this coverage to consumers as well.\nHealth insurance.\nHealth insurance policies cover the cost of medical treatments. Dental insurance, like medical insurance, protects policyholders for dental costs. In most developed countries, all citizens receive some health coverage from their governments, paid through taxation. In most countries, health insurance is often part of an employer's benefits.\nCasualty insurance.\nCasualty insurance insures against accidents, not necessarily tied to any specific property. It is a broad spectrum of insurance that a number of other types of insurance could be classified, such as auto, workers compensation, and some liability insurances.\nLife insurance.\nLife insurance provides a monetary benefit to a decedent's family or other designated beneficiary, and may specifically provide for income to an insured person's family, burial, funeral and other final expenses. Life insurance policies often allow the option of having the proceeds paid to the beneficiary either in a lump sum cash payment or an annuity. In most states, a person cannot purchase a policy on another person without their knowledge.\nAnnuities provide a stream of payments and are generally classified as insurance because they are issued by insurance companies, are regulated as insurance, and require the same kinds of actuarial and investment management expertise that life insurance requires. Annuities and pensions that pay a benefit for life are sometimes regarded as insurance against the possibility that a retiree will outlive his or her financial resources. In that sense, they are the complement of life insurance and, from an underwriting perspective, are the mirror image of life insurance.\nCertain life insurance contracts accumulate cash values, which may be taken by the insured if the policy is surrendered or which may be borrowed against. Some policies, such as annuities and endowment policies, are financial instruments to accumulate or liquidate wealth when it is needed.\nIn many countries, such as the United States and the UK, the tax law provides that the interest on this cash value is not taxable under certain circumstances. This leads to widespread use of life insurance as a tax-efficient method of saving as well as protection in the event of early death.\nIn the United States, the tax on interest income on life insurance policies and annuities is generally deferred. However, in some cases the benefit derived from tax deferral may be offset by a low return. This depends upon the insuring company, the type of policy and other variables (mortality, market return, etc.). Moreover, other income tax saving vehicles (e.g., IRAs, 401(k) plans, Roth IRAs) may be better alternatives for value accumulation.\nBurial insurance.\nBurial insurance is an old type of life insurance which is paid out upon death to cover final expenses, such as the cost of a funeral. The Greeks and Romans introduced burial insurance c.\u00a0600 CE when they organized collegia (guilds) called benevolent societies, which cared for the surviving families and paid funeral expenses of members upon death. Guilds in the Middle Ages served a similar purpose, as did friendly societies during Victorian times.\nProperty.\nProperty insurance provides protection against risks to property, such as fire, theft or weather damage. This may include specialized forms of insurance such as fire insurance, flood insurance, earthquake insurance, home insurance, inland marine insurance or boiler insurance.\nThe term \"property insurance\" may, like casualty insurance, be used as a broad category of various subtypes of insurance, some of which are listed below:\nLiability.\nLiability insurance is a broad superset that covers legal claims against the insured. Many types of insurance include an aspect of liability coverage. For example, a homeowner's insurance policy will normally include liability coverage which protects the insured in the event of a claim brought by someone who slips and falls on the property; automobile insurance also includes an aspect of liability insurance that indemnifies against the harm that a crashing car can cause to others' lives, health, or property. The protection offered by a liability insurance policy is twofold: a legal defense in the event of a lawsuit commenced against the policyholder and indemnification (payment on behalf of the insured) with respect to a settlement or court verdict. Liability policies typically cover only the negligence of the insured, and will not apply to results of wilful or intentional acts by the insured.\nOften a commercial insured's liability insurance program consists of several layers. The first layer of insurance generally consists of primary insurance, which provides first dollar indemnity for judgments and settlements up to the limits of liability of the primary policy. Generally, primary insurance is subject to a deductible and obligates the insurer to defend the insured against lawsuits, which is normally accomplished by assigning counsel to defend the insured. In many instances, a commercial insured may elect to self-insure. Above the primary insurance or self-insured retention, the insured may have one or more layers of excess insurance to provide coverage additional limits of indemnity protection. There are a variety of types of excess insurance, including \"stand-alone\" excess policies (policies that contain their own terms, conditions, and exclusions), \"follow form\" excess insurance (policies that follow the terms of the underlying policy except as specifically provided), and \"umbrella\" insurance policies (excess insurance that in some circumstances could provide coverage that is broader than the underlying insurance).\nCredit.\nCredit insurance repays some or all of a loan when the borrower is insolvent.\nCyber attack insurance.\nCyber-insurance is a business lines insurance product intended to provide coverage to corporations from Internet-based risks, and more generally from risks relating to information technology infrastructure, information privacy, information governance liability, and activities related thereto.\nClosed community and governmental self-insurance.\nSome communities prefer to create virtual insurance among themselves by other means than contractual risk transfer, which assigns explicit numerical values to risk. A number of religious groups, including the Amish and some Muslim groups, depend on support provided by their communities when disasters strike. The risk presented by any given person is assumed collectively by the community who all bear the cost of rebuilding lost property and supporting people whose needs are suddenly greater after a loss of some kind. In supportive communities where others can be trusted to follow community leaders, this tacit form of insurance can work. In this manner the community can even out the extreme differences in insurability that exist among its members. Some further justification is also provided by invoking the moral hazard of explicit insurance contracts.\nIn the United Kingdom, The Crown (which, for practical purposes, meant the civil service) did not insure property such as government buildings. If a government building was damaged, the cost of repair would be met from public funds because, in the long run, this was cheaper than paying insurance premiums. Since many UK government buildings have been sold to property companies and rented back, this arrangement is now less common.\nIn the United States, the most prevalent form of self-insurance is governmental risk management pools. They are self-funded cooperatives, operating as carriers of coverage for the majority of governmental entities today, such as county governments, municipalities, and school districts. Rather than these entities independently self-insure and risk bankruptcy from a large judgment or catastrophic loss, such governmental entities form a risk pool. Such pools begin their operations by capitalization through member deposits or bond issuance. Coverage (such as general liability, auto liability, professional liability, workers compensation, and property) is offered by the pool to its members, similar to coverage offered by insurance companies. However, self-insured pools offer members lower rates (due to not needing insurance brokers), increased benefits (such as loss prevention services) and subject matter expertise. Of approximately 91,000 distinct governmental entities operating in the United States, 75,000 are members of self-insured pools in various lines of coverage, forming approximately 500 pools. Although a relatively small corner of the insurance market, the annual contributions (self-insured premiums) to such pools have been estimated up to 17 billion dollars annually.\nInsurance companies.\nInsurance companies may provide any combination of insurance types, but are often classified into three groups:\nGeneral insurance companies can be further divided into these sub categories.\nIn most countries, life and non-life insurers are subject to different regulatory regimes and different tax and accounting rules. The main reason for the distinction between the two types of company is that life, annuity, and pension business is long-term in nature \u2013 coverage for life assurance or a pension can cover risks over many decades. By contrast, non-life insurance cover usually covers a shorter period, such as one year.\nMutual versus proprietary.\nInsurance companies are commonly classified as either mutual or proprietary companies. Mutual companies are owned by the policyholders, while shareholders (who may or may not own policies) own proprietary insurance companies.\nDemutualization of mutual insurers to form stock companies, as well as the formation of a hybrid known as a mutual holding company, became common in some countries, such as the United States, in the late 20th century. However, not all states permit mutual holding companies.\nReinsurance companies.\nReinsurance companies are insurance companies that provide policies to other insurance companies, allowing them to reduce their risks and protect themselves from substantial losses. The reinsurance market is dominated by a few large companies with huge reserves. A reinsurer may also be a direct writer of insurance risks as well.\nCaptive insurance companies.\nCaptive insurance companies can be defined as limited-purpose insurance companies established with the specific objective of financing risks emanating from their parent group or groups. This definition can sometimes be extended to include some of the risks of the parent company's customers. In short, it is an in-house self-insurance vehicle. Captives may take the form of a \"pure\" entity, which is a 100% subsidiary of the self-insured parent company; of a \"mutual\" captive, which insures the collective risks of members of an industry; and of an \"association\" captive, which self-insures individual risks of the members of a professional, commercial or industrial association. Captives represent commercial, economic and tax advantages to their sponsors because of the reductions in costs they help create and for the ease of insurance risk management and the flexibility for cash flows they generate. Additionally, they may provide coverage of risks which is neither available nor offered in the traditional insurance market at reasonable prices.\nThe types of risk that a captive can underwrite for their parents include property damage, public and product liability, professional indemnity, employee benefits, employers' liability, motor and medical aid expenses. The captive's exposure to such risks may be limited by the use of reinsurance.\nCaptives are becoming an increasingly important component of the risk management and risk financing strategy of their parent. This can be understood against the following background:\nOther forms.\nOther possible forms for an insurance company include reciprocals, in which policyholders reciprocate in sharing risks, and Lloyd's organizations.\nAdmitted versus non-admitted.\nAdmitted insurance companies are those in the United States that have been admitted or licensed by the state licensing agency. The insurance they provide is called admitted insurance. Non-admitted companies have not been approved by the state licensing agency, but are allowed to provide insurance under special circumstances when they meet an insurance need that admitted companies cannot or will not meet.\nInsurance consultants.\nThere are also companies known as \"insurance consultants\". Like a mortgage broker, these companies are paid a fee by the customer to shop around for the best insurance policy among many companies. Similar to an insurance consultant, an \"insurance broker\" also shops around for the best insurance policy among many companies. However, with insurance brokers, the fee is usually paid in the form of commission from the insurer that is selected rather than directly from the client.\nNeither insurance consultants nor insurance brokers are insurance companies and no risks are transferred to them in insurance transactions. Third party administrators are companies that perform underwriting and sometimes claims handling services for insurance companies. These companies often have special expertise that the insurance companies do not have.\nFinancial stability and rating.\nThe financial stability and strength of an insurance company is a consideration when buying an insurance contract. An insurance premium paid currently provides coverage for losses that might arise many years in the future. For that reason, a more financially stable insurance carrier reduces the risk of the insurance company becoming insolvent, leaving their policyholders with no coverage (or coverage only from a government-backed insurance pool or other arrangements with less attractive payouts for losses). A number of independent rating agencies provide information and rate the financial viability of insurance companies.\nInsurance companies are rated by various agencies such as AM Best. The ratings include the company's financial strength, which measures its ability to pay claims. It also rates financial instruments issued by the insurance company, such as bonds, notes, and securitization products.\nAcross the world.\nAdvanced economies account for the bulk of the global insurance industry. According to Swiss Re, the global insurance market wrote $7.186 trillion in direct premiums in 2023. (\"Direct premiums\" means premiums written directly by insurers before accounting for ceding of risk to reinsurers.) The United States was the country with the largest insurance market with $3.226 trillion (44.9%) of direct premiums written, with the People's Republic of China coming in second at only $723 billion (10.1%), the United Kingdom coming in third at $374 billion (5.2%), and Japan coming in fourth at $362 billion (5.0%). However, the European Union's single market is the actual second largest market, with 16 percent market share.\nRegulatory differences.\nIn the United States, insurance is regulated by the states under the McCarran\u2013Ferguson Act, with \"periodic proposals for federal intervention\", and a nonprofit coalition of state insurance agencies called the National Association of Insurance Commissioners works to harmonize the country's different laws and regulations. The National Conference of Insurance Legislators (NCOIL) also works to harmonize the different state laws. 1988 California Proposition 103 is claimed to reduce home insurance rates, while it is blamed by some for reduced availability of home insurance in wildfire-distressed neighborhoods.\nIn the European Union, the Third Non-Life Directive and the Third Life Directive, both passed in 1992 and effective 1994, created a single insurance market in Europe and allowed insurance companies to offer insurance anywhere in the EU (subject to permission from authority in the head office) and allowed insurance consumers to purchase insurance from any insurer in the EU. As far as insurance in the United Kingdom, the Financial Services Authority took over insurance regulation from the General Insurance Standards Council in 2005; laws passed include the Insurance Companies Act 1973 and another in 1982, and reforms to warranty and other aspects under discussion as of 2012[ [update]].\nThe insurance industry in China was nationalized in 1949 and thereafter offered by only a single state-owned company, the People's Insurance Company of China, which was eventually suspended as demand declined in a communist environment. In 1978, market reforms led to an increase in the market and by 1995 a comprehensive Insurance Law of the People's Republic of China was passed, followed in 1998 by the formation of China Insurance Regulatory Commission (CIRC), which has broad regulatory authority over the insurance market of China.\nIn India IRDA is insurance regulatory authority. As per the section 4 of IRDA Act 1999, Insurance Regulatory and Development Authority (IRDA), which was constituted by an act of parliament. National Insurance Academy, Pune is apex insurance capacity builder institute promoted with support from Ministry of Finance and by LIC, Life &amp; General Insurance companies.\nIn 2017, within the framework of the joint project of the Bank of Russia and Yandex, a special check mark (a green circle with a tick and '\u0420\u0435\u0435\u0441\u0442\u0440 \u0426\u0411 \u0420\u0424' (Unified state register of insurance entities) text box) appeared in the search for Yandex system, informing the consumer that the company's financial services are offered on the marked website, which has the status of an insurance company, a broker or a mutual insurance association.\nInsurance practices and controversies.\nDoes not reduce the risk.\nInsurance is just a risk transfer mechanism wherein the financial burden which may arise due to some fortuitous event is transferred to a bigger entity (i.e., an insurance company) by way of paying premiums. This only reduces the financial burden and not the actual chances of happening of an event. Insurance is a risk for both the insurance company and the insured. The insurance company understands the risk involved and will perform a risk assessment when writing the policy. \nAs a result, the premiums may go up if they determine that the policyholder will file a claim. However, premiums might reduce if the policyholder commits to a risk management program as recommended by the insurer. It is therefore important that insurers view risk management as a joint initiative between policyholder and insurer since a robust risk management plan minimizes the possibility of a large claim for the insurer while stabilizing or reducing premiums for the policyholder. University of Tennessee research published in 2014 found that all company staff in the businesses they surveyed recognised the importance of insurance but largely they were too distant within their organization from the provision or cost of insurance to be able to relate to company insurance needs.\nIf a person is financially stable and plans for life's unexpected events, they may be able to go without insurance. However, they must have enough to cover a total and complete loss of employment and of their possessions. Some states will accept a surety bond, a government bond, or even making a cash deposit with the state.\nMoral hazard.\nAn insurance company may inadvertently find that its insureds may not be as risk-averse as they might otherwise be (since, by definition, the insured has transferred the risk to the insurer), a concept known as moral hazard. This 'insulates' many from the true costs of living with risk, negating measures that can mitigate or adapt to risk and leading some to describe insurance schemes as potentially maladaptive.\nComplexity of insurance policy contracts.\nInsurance policies can be complex and some policyholders may not understand all the fees and coverages included in a policy. As a result, people may buy policies on unfavorable terms. In response to these issues, many countries have enacted detailed statutory and regulatory regimes governing every aspect of the insurance business, including minimum standards for policies and the ways in which they may be advertised and sold.\nFor example, most insurance policies in the English language today have been carefully drafted in plain English; the industry learned the hard way that many courts will not enforce policies against insureds when the judges themselves cannot understand what the policies are saying. Typically, courts construe ambiguities in insurance policies against the insurance company and in favor of coverage under the policy.\nMany institutional insurance purchasers buy insurance through an insurance broker. While on the surface it appears the broker represents the buyer (not the insurance company), and typically counsels the buyer on appropriate coverage and policy limitations, in the vast majority of cases a broker's compensation comes in the form of a commission as a percentage of the insurance premium, creating a conflict of interest in that the broker's financial interest is tilted toward encouraging an insured to purchase more insurance than might be necessary at a higher price. A broker generally holds contracts with many insurers, thereby allowing the broker to \"shop\" the market for the best rates and coverage possible.\nInsurance may also be purchased through an agent. A tied agent, working exclusively with one insurer, represents the insurance company from whom the policyholder buys (while a free agent sells policies of various insurance companies). Just as there is a potential conflict of interest with a broker, an agent has a different type of conflict. Because agents work directly for the insurance company, if there is a claim the agent may advise the client to the benefit of the insurance company. Agents generally cannot offer as broad a range of selection compared to an insurance broker.\nAn independent insurance consultant advises insureds on a fee-for-service retainer, similar to an attorney, and thus offers completely independent advice, free of the financial conflict of interest of brokers or agents. However, such a consultant must still work through brokers or agents in order to secure coverage for their clients.\nLimited consumer benefits.\nIn the United States, economists and consumer advocates generally consider insurance to be worthwhile for low-probability, catastrophic losses, but not for high-probability, small losses. Because of this, consumers are advised to select high deductibles and to not insure losses which would not cause a disruption in their life. However, consumers have shown a tendency to prefer low deductibles and to prefer to insure relatively high-probability, small losses over low-probability, perhaps due to not understanding or ignoring the low-probability risk. This is associated with reduced purchasing of insurance against low-probability losses, and may result in increased inefficiencies from moral hazard.\nRedlining.\nRedlining is the practice of denying insurance coverage in specific geographic areas, supposedly because of a high likelihood of loss, while the alleged motivation is unlawful discrimination. Racial profiling or redlining has a long history in the property insurance industry in the United States. From a review of industry underwriting and marketing materials, court documents, and research by government agencies, industry and community groups, and academics, it is clear that race has long affected and continues to affect the policies and practices of the insurance industry.\nIn July 2007, the US Federal Trade Commission (FTC) released a report presenting the results of a study concerning credit-based insurance scores in automobile insurance. The study found that these scores are effective predictors of risk. It also showed that African-Americans and Hispanics are substantially overrepresented in the lowest credit scores, and substantially underrepresented in the highest, while Caucasians and Asians are more evenly spread across the scores. The credit scores were also found to predict risk within each of the ethnic groups, leading the FTC to conclude that the scoring models are not solely proxies for redlining. The FTC indicated little data was available to evaluate benefit of insurance scores to consumers. The report was disputed by representatives of the Consumer Federation of America, the National Fair Housing Alliance, the National Consumer Law Center, and the Center for Economic Justice, for relying on data provided by the insurance industry.\nAll states have provisions in their rate regulation laws or in their fair trade practice acts that prohibit unfair discrimination, often called redlining, in setting rates and making insurance available.\nIn determining premiums and premium rate structures, insurers consider quantifiable factors, including location, credit scores, gender, occupation, marital status, and education level. However, the use of such factors is often considered to be unfair or unlawfully discriminatory, and the reaction against this practice has in some instances led to political disputes about the ways in which insurers determine premiums and regulatory intervention to limit the factors used.\nAn insurance underwriter's job is to evaluate a given risk as to the likelihood that a loss will occur. Any factor that causes a greater likelihood of loss should theoretically be charged a higher rate. This basic principle of insurance must be followed if insurance companies are to remain solvent. Thus, \"discrimination\" against (i.e., negative differential treatment of) potential insureds in the risk evaluation and premium-setting process is a necessary by-product of the fundamentals of insurance underwriting. For instance, insurers charge older people significantly higher premiums than they charge younger people for term life insurance. Older people are thus treated differently from younger people (i.e., a distinction is made, discrimination occurs). The rationale for the differential treatment goes to the heart of the risk a life insurer takes: older people are likely to die sooner than young people, so the risk of loss (the insured's death) is greater in any given period of time and therefore the risk premium must be higher to cover the greater risk. However, treating insureds differently when there is no actuarially sound reason for doing so is unlawful discrimination.\nInsurance patents.\nNew assurance products can now be protected from copying with a business method patent in the United States.\nA recent example of a new insurance product that is patented is Usage Based auto insurance. Early versions were independently invented and patented by a major US auto insurance company, Progressive Auto Insurance (https://) and a Spanish independent inventor, Salvador Minguijon Perez.\nMany independent inventors are in favor of patenting new insurance products since it gives them protection from big companies when they bring their new insurance products to market. Independent inventors account for 70% of the new U.S. patent applications in this area.\nPatenting new insurance products can be risky, as it is practically impossible for insurance companies to determine if their product will infringe on a pre-existing patent. For example, in 2004, The Hartford insurance company had to pay $80 million to an independent inventor, Bancorp Services, in order to settle a patent infringement and theft of trade secret lawsuit for a type of corporate owned life insurance product invented and patented by Bancorp.\nThere are currently about 150 new patent applications on insurance inventions filed per year in the United States. The rate at which patents have been issued has steadily risen from 15 in 2002 to 44 in 2006.\nThe first US insurance patent was granted in 2005, which concerned coverage of data transferred over the internet. Another example of an application posted was posted in 2009. This patent application describes a method for increasing the ease of changing insurance companies.\nInsurance on demand.\nInsurance on demand (also IoD) is an insurance service that provides clients with coverage for a specific occasion or event when needed; i.e. only episodic rather than on a 24/7 basis as is typically provided by traditional policies. For example, air travelers can purchase a policy for one single plane flight, rather than a longer-lasting travel insurance plan.\nInsurance industry and rent-seeking.\nCertain insurance products and practices have been described as rent-seeking by critics. That is, some insurance products or practices are useful primarily because of legal benefits, such as reducing taxes, as opposed to providing protection against risks of adverse events.\nReligious concerns.\nMuslim scholars have varying opinions about life insurance. Life insurance policies that earn interest (or guaranteed bonus/NAV) are generally considered to be a form of \"riba\" (usury) and some consider even policies that do not earn interest to be a form of \"gharar\" (speculation). Some argue that \"gharar\" is not present due to the actuarial science behind the underwriting. Jewish rabbinical scholars also have expressed reservations regarding insurance as an avoidance of God's will but most find it acceptable in moderation.\nSome Christians believe insurance represents a lack of faith. There is a long history of resistance to commercial insurance in Anabaptist communities (Mennonites, Amish, Hutterites, Brethren in Christ), but many participate in community-based self-insurance programs that spread risk within their communities.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nCountry-specific articles:\n* Insurance in Australia\n* Insurance industry in China\n* Insurance in India\n* Insurance in the United Kingdom\n* Insurance in the United States\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nSources.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "15177", "revid": "194203", "url": "https://en.wikipedia.org/wiki?curid=15177", "title": "International Convention for the Prevention of Pollution from Ships", "text": ""}
{"id": "15178", "revid": "194203", "url": "https://en.wikipedia.org/wiki?curid=15178", "title": "International environmental law", "text": ""}
{"id": "15179", "revid": "45366078", "url": "https://en.wikipedia.org/wiki?curid=15179", "title": "Indira Gandhi", "text": "Prime Minister of India (1966\u20131977; 1980\u20131984)\nIndira Priyadarshini Gandhi (n\u00e9e\u00a0Nehru; 19 November 1917 \u2013 31 October 1984) was an Indian politician and stateswoman who served as the prime minister of India from 1966 to 1977 and again from 1980 until her assassination in 1984. She was India's first and only female prime minister as of 2025, and a central figure in Indian politics as the leader of the Indian National Congress (INC). She was the daughter of Jawaharlal Nehru, the first prime minister of India, and the mother of Rajiv Gandhi, who succeeded her as prime minister. Her cumulative tenure of 15 years and 350 days makes her the second-longest-serving Indian prime minister after her father.\nDuring her father Jawaharlal Nehru's premiership from 1947 to 1964, Gandhi was his hostess and accompanied him on his numerous foreign trips. In 1959, she played a part in the dissolution of the communist-led Kerala state government as then-president of the Indian National Congress, otherwise a ceremonial position to which she was elected earlier that year. Lal Bahadur Shastri, who had succeeded Nehru as prime minister upon his death in 1964, appointed her minister of information and broadcasting in his government; the same year she was elected to the Rajya Sabha, the upper house of the Indian Parliament. After Shastri's sudden death in January 1966, Gandhi defeated her rival, Morarji Desai, in the INC's parliamentary leadership election to become leader and also succeeded Shastri as prime minister. She was the world's second female prime minister after Sirimavo Bandaranaike when she became prime minister of India. She led the Congress to victory in two subsequent elections, starting with the 1967 general election, in which she was first elected to the lower house\u00a0of the Indian parliament, the Lok Sabha. In 1971, her party secured its first landslide victory since her father's sweep in 1962, focusing on issues such as poverty. But following the nationwide state of emergency she implemented, she faced massive anti-incumbency sentiment causing the INC to lose the 1977 election, which was the first time this happened in the history of India. She even lost her own parliamentary constituency. However, due to her portrayal as a strong leader and the weak governance of the Janata Party, her party won the next election by a landslide and she returned to the premiership.\nAs prime minister, Gandhi was known for her uncompromising political stances and centralisation of power within the executive branch. In 1967, she headed a military conflict with China in which India repelled Chinese incursions into the Himalayas. In 1971, she went to war with Pakistan in support of the independence movement and war of independence in East Pakistan, which resulted in an Indian victory and the independence of Bangladesh, as well as increasing India's influence to the point where it became the sole regional power in South Asia. Another military operation against Pakistan, codenamed Operation Meghdoot, occurred during her tenure in 1984, which led to India expanding the territory it effectively controlled in the disputed Kashmir region.\nGandhi also played a crucial role in initiating India's first successful nuclear weapon test in 1974. Her rule saw India grow closer to the Soviet Union by signing a friendship treaty in 1971 to ward off perceived geopolitical threat as a result of the U.S. warming up to China. India received military, financial, and diplomatic support from the Soviet Union during its conflict with Pakistan in the same year. Though India was at the forefront of the Non-Aligned Movement, Gandhi made it one of the Soviet Union's closest allies in Asia, each often supporting the other in proxy wars and at the United Nations. \nResponding to separatist tendencies and a call for revolution, she instituted a state of emergency from 1975 to 1977, during which she ruled by decree and basic civil liberties were suspended. More than 100,000 political opponents, journalists and dissenters were imprisoned. She faced the growing Sikh separatism movement throughout her fourth premiership; in response, she ordered Operation Blue Star, which involved military action in the Golden Temple and killed hundreds of Sikhs. On 31 October 1984, she was assassinated by two of her bodyguards, both of whom were Sikh nationalists seeking retribution for the events at the temple.\nGandhi is remembered as one of the most powerful woman in the world. Her supporters cite her leadership during victories over geopolitical rivals China and Pakistan, the Green Revolution, a growing economy in the early 1980s, and her anti-poverty campaign that led her to be known as \"Mother Indira\" (a pun on \"Mother India\") among the country's poor and rural classes. Henry Kissinger described her as an \"Iron Lady\", a nickname that became associated with her tough personality. Critics note her cult of personality and authoritarian rule of India during the Emergency. In 1999, she was named \"Woman of the Millennium\" in an online poll organised by the BBC. In 2020, she was named by \"Time\" magazine among the 100 women who defined the past century as counterparts to the magazine's previous choices for Man of the Year.\nEarly life and career.\nIndira Gandhi was born in British ruled India as Indira Nehru, into a Kashmiri Pandit family on 19 November 1917 in Allahabad (present-day Prayagraj) in Uttar Pradesh. Her father, Jawaharlal Nehru, was a leading figure in the Indian movement for independence from British rule, and became the first Prime Minister of the Dominion (and later Republic) of India. Indira was her parents' only surviving child (she had a younger brother who died while young); she grew up with her mother, Kamala Nehru, at the Anand Bhavan, a large family estate in Allahabad. In 1930, the Nehru family donated the mansion to the Indian National Congress and renamed it Swaraj Bhavan (meaning abode of freedom). A new mansion was built nearby to serve as the family residence and given the name of the old Anand Bhavan. Indira had a lonely and unhappy childhood. Her father was often away, directing political activities or incarcerated, while her mother was frequently bedridden with illness and later suffered an early death from tuberculosis. Indira had limited contact with her father, mostly through letters.\nIndira Nehru was taught mostly at home by tutors and attended school intermittently until matriculation in 1934. She was a student at the Modern School in Delhi, St. Cecilia's and St. Mary's Convent schools in Allahabad, the International School of Geneva in Geneva, the Ecole Nouvelle in Bex in Vaud, Switzerland, and the Pupils' Own School in Poona in Maharashtra and in Bombay, which is affiliated with the University of Mumbai. She and her mother moved to the Belur Math headquarters of the Ramakrishna Mission where Swami Ranganathananda was her guardian. Indira then studied at the Vishwa Bharati in Santiniketan, which became Visva-Bharati University in 1951. During an interview with Rabindranath Tagore, he named Indira \"Priyadarshini\", which means \"looking at everything with kindness\" in Sanskrit and she became known as Indira Priyadarshini Nehru. A year later, however, she had to leave university to attend to her ailing mother in Lausanne, Switzerland. There it was decided that Indira would continue her education at the University of Oxford. After her mother died, Indira attended the Badminton School in Bristol, England for a short time period and then enrolled at Somerville College in Oxford in 1937 to study history. She had to take the entrance examination twice, having failed at her first attempt with a poor performance in Latin. At Oxford, she excelled in history, political science, and economics but her grades in Latin\u2014a compulsory subject\u2014remained poor. However she was active socially at the university and was a member of the Oxford Majlis Asian Society.\nDuring her time in Europe, Indira Nehru was plagued with ill health and was constantly attended to by doctors. She had to make repeated trips to Switzerland to recover, disrupting her studies. She was there in 1940, when Germany rapidly conquered Europe. Nehru tried to return to England through Portugal but was left stranded for nearly two months. She managed to enter England in early 1941, and from there returned to India without completing her studies at Oxford. The university later awarded her an honorary degree. In 2010, Oxford honoured her further by selecting her as one of the ten Oxasians, illustrious Asian graduates from the University of Oxford. During her stay in Britain, Nehru frequently met her future husband Feroze Gandhi (no relation to Mahatma Gandhi). They were married in Allahabad according to Adi Dharm rituals, although Feroze belonged to a Zoroastrian Parsi family of Gujarat. The couple had two sons, Rajiv Gandhi (born 1944) and Sanjay Gandhi (born 1946).\nIn September 1942, Indira Gandhi was arrested over her role in the Quit India Movement. She was released from jail in April 1943. \"Mud entered our souls in the drabness of prison,\" she later recalled her time in the jail. She added, \"When I came out, it was such a shock to see colors again I thought I would go out of my mind.\"\nIn the 1950s, Indira, now Indira Gandhi after her marriage, unofficially served her father as a personal assistant during his tenure as the first prime minister of India. Near the end of the 1950s, Gandhi served as the president of the Congress. In that capacity, she was instrumental in having the communist-led Kerala state government dismissed in 1959. That government was India's first elected communist government. After her father's death in 1964 she was appointed a member of the Rajya Sabha (upper house) and served in Prime Minister Lal Bahadur Shastri's cabinet as Minister of Information and Broadcasting. In January 1966, after Shastri's death, the Congress legislative party elected her over Morarji Desai as their leader. Congress party veteran K. Kamaraj was instrumental in Gandhi achieving victory. Because she was a woman, other political leaders in India saw Gandhi as weak and hoped to use her as a puppet once elected: Congress President Kamaraj orchestrated Mrs. Gandhi's selection as prime minister because he perceived her to be weak enough that he and the other regional party bosses could control her, and yet strong enough to beat Desai [her political opponent] in a party election because of the high regard for her father... a woman would be an ideal tool for the Syndicate.\nPrime minister (1966\u20131977).\nGandhi's first eleven years serving as prime minister saw her evolve from the perception of Congress party leaders as their puppet, to a strong leader with the iron resolve to split the party over her policy positions, or to go to war with Pakistan to assist Bangladesh in the 1971 liberation war. At the end of 1977, she was such a dominating figure in Indian politics that Congress party president D. K. Barooah had coined the phrase \"India is Indira and Indira is India.\"\nFirst year.\nGandhi formed her government with Morarji Desai as deputy prime minister and finance minister. At the beginning of her first term as prime minister, she was widely criticised by the media and the opposition as a \"Goongi goodiya\" (Hindi for a \"dumb doll\") of the Congress party bosses who had orchestrated her election and then tried to constrain her.\nIndira was a reluctant successor to her famed father, although she had accompanied him on several official foreign visits and played an anchor role in bringing down the first democratically elected communist government in Kerala. According to certain sources it was the socialist leader Ram Manohar Lohia that first derided her personality as the \"Goongi Goodiya\" that later was echoed by other Congress politicians who were wary of her rise in the party.\nOne of her first major actions was to crush the separatist Mizo National Front uprising in Mizoram in 1966.\n1967\u20131971.\nThe first electoral test for Gandhi was the 1967 general elections for the Lok Sabha and state assemblies. The Congress Party won a reduced majority in the Lok Sabha after these elections owing to widespread disenchantment over the rising prices of commodities, unemployment, economic stagnation and a food crisis. Gandhi was elected to the Lok Sabha from the Raebareli constituency. She had a rocky start after agreeing to devalue the rupee which created hardship for Indian businesses and consumers. The importation of wheat from the United States fell through due to political disputes.\nFor the first time, the party also lost power or lost its majority in a number of states across the country. After the 1967 elections, Gandhi gradually began to move towards socialist policies. In 1969, she fell out with senior Congress party leaders over several issues. Chief among them was her decision to support V. V. Giri, the independent candidate rather than the official Congress party candidate Neelam Sanjiva Reddy for the vacant position of president of India. The other was the announcement by the prime minister of Bank nationalisation without consulting the finance minister, Morarji Desai. These steps culminated in party president S. Nijalingappa expelling her from the party for indiscipline. Gandhi, in turn, floated her own faction of the Congress party and managed to retain most of the Congress MPs on her side with only 65 on the side of the Congress (O) faction. The Gandhi faction, called Congress (R), lost its majority in the parliament but remained in power with the support of regional parties such as DMK. The policies of the Congress under Gandhi, before the 1971 elections, also included proposals for the abolition of the Privy Purse to former rulers of the princely states and the 1969 nationalisation of the fourteen largest banks in India.\nMilitary conflict with China.\nIn 1967, a military conflict alongside the border of the Himalayan Kingdom of Sikkim, then an Indian protectorate, broke out between India and China. India won by repelling Chinese attacks and forced the subsequent withdrawal of Chinese forces from the region. Throughout the conflict, the Indian losses were 88 killed and 163 wounded while Chinese casualties stood at 340 killed and 450 wounded, according to the Indian Defense Ministry. Chinese sources made no declarations of casualties but alleged India to be the aggressor.\nIn December 1967, Indira Gandhi remarked these developments that \"China continues to maintain an attitude of hostility towards us and spares no opportunity to malign us and to carry on anti-Indian propaganda not only against the Indian Government but the whole way of our democratic functioning.\" In 1975, Gandhi incorporated Sikkim into India, after a referendum in which a majority of Sikkimese voted to join India. The move was condemned as being a \"despicable act of the Indian Government\" by China. Chinese government mouthpiece \"China Daily\" wrote that \"the Nehrus, father and daughter, had always acted in this way, and Indira Gandhi had gone further\".\n1971\u20131977.\nGaribi Hatao (Remove Poverty) was the resonant theme for Gandhi's 1971 political bid. The slogan was developed in response to the combined opposition alliance's use of the two-word manifesto\u2014\"Indira Hatao\" (Remove Indira). The Garibi Hatao slogan and the proposed anti-poverty programs that came with it were designed to give Gandhi independent national support, based on the rural and urban poor. This would allow her to bypass the dominant rural castes both in and of state and local governments as well as the urban commercial class. For their part, the previously voiceless poor would at last gain both political worth and political weight. The programs created through Garibi Hatao, though carried out locally, were funded and developed by the Central Government in New Delhi. The program was supervised and staffed by the Indian National Congress party. \"These programs also provided the central political leadership with new and vast patronage resources to be disbursed\u00a0... throughout the country.\"\nThe Congress government faced numerous problems during this term. Some of these were due to high inflation which in turn was caused by wartime expenses, drought in some parts of the country and, more importantly, the 1973 oil crisis. Opposition to her in the 1973\u201375 period, after the Gandhi wave had receded, was strongest in the states of Bihar and Gujarat. In Bihar, Jayaprakash Narayan, the veteran leader came out of retirement to lead the protest movement there.\nWar with Pakistan.\nGandhi's biggest achievement following the 1971 election came in December 1971 with India's decisive victory over Pakistan in the Indo-Pakistani War. That victory occurred in the last two weeks of the Bangladesh Liberation War, which led to the formation of independent Bangladesh. An insurgency in East Pakistan (now Bangladesh) formed in early 1971, with Bengali's and East Pakistanis revolting against authoritarian rule from the central West Pakistan Government. In response, Pakistani security forces launched the infamous Operation Searchlight, in which Pakistan committed genocide among Bengali Hindus, nationalists and intelligentsia. Gandhi's India was initially restrained from intervening in the insurgency but quickly started to support Bengali rebels through the provision of military supplies. Indian forces clashed multiple times with Pakistani forces in the Eastern border. At one point, Indian forces along with Mukti Bahini rebels allied together and attacked Pakistani forces at Dhalai. The attack, supported and later successfully executed by India, was done to stop Pakistani cross-border shelling. The battle occurred more than a month before India's official intervention in December. Gandhi quickly dispatched more troops to the Eastern border with East Pakistan, hoping to support Mukti Bahini rebels and cease any Pakistani infiltration. Indian forces then clashed again with Pakistani forces after Indian forces crossed the border and secured Garibpur after a one-day battle lasting from 20 November 1971 to the 21st. The next day, on 22 November, Indian and Pakistani aircraft engaged in a dogfight over the Boyra Salient, in which thousands of people watched as 4 Indian Folland Gnats shot down 2 Pakistani Canadair Sabres and damaged another. Both Pakistani pilots that were shot down were captured as prisoners of war. The Battle of Boyra instantly made the 4 Indian pilots celebrities and created large-scale nationalism as the Bangladesh Liberation War saw more and more Indian intervention and escalation. Other clashes also happened on the same day but did not receive as much media attention as did the battle of Boyra and Garibpur. On 3 December 1971, the Pakistan Air Force launched Operation Chengiz Khan, which saw Pakistani aircraft attacking Indian airbases and military installations across the Western border in a pre-emptive strike. The initial night-time attack by Pakistani forces was foiled, failing to inflict any major damage on Indian airbases, allowing Indian aircraft to counterattack into West Pakistan. Gandhi quickly declared a state of emergency and addressed the nation on radio shortly after midnight, stating: \"We must be prepared for a long period of hardship and sacrifice.\"\nBoth countries mobilised for war and Gandhi ordered full-out war, ordering an invasion into East Pakistan. Pakistan's Navy had not improved since the 1965 war, while the Pakistani airforce could not launch attacks on the same scale as the Indian airforce. The Pakistan Army quickly attempted major land operations on the Western border, but most of these attacks besides some in Kashmir stalled, and allowed Indian counterattacks to gain land. The Pakistan Army lacked wide-scale organisation which contributed to miscommunication and high casualties in the Western front.\nIn the Eastern Front of the war, Indian generals opted for a high speed lightning war, using mechanised and airborne units to quickly bypass Pakistani opposition and make quick strides towards the capital of East Pakistan, Dhaka. Jagjit Singh Aurora (who later became a critic of Gandhi in 1984) led Indian Army's Eastern Command. The Indian Air Force quickly overcame the small contingent of Pakistani aircraft in East Pakistan, allowing for air superiority over the region. Indian forces liberated Jessore and several other towns during the Battle of Sylhet between 7 December and 15 December 1971, which saw India conduct its first heliborne operation. India then conducted another airdrop on 9 December, with Indian forces led by Major General Sagat Singh capturing just under 5,000 Pakistani POWs and also crossing the Meghna River towards Dhaka. Two days later, Indian forces conducted the largest airborne operation since World War II. 750 men of the Army's Parachute Regiment landed in Tangail and defeated the Pakistani forces in the area, securing a direct route to Dhaka. Little Pakistani forces escaped the battle with only 900 out of 7000 soldiers retreating back to Dhaka alive. By 12 December, Indian forces had reached the outskirts of Dhaka and had prepared to besiege the capital. Indian heavy artillery arrived by the 14th, and shelled the city.\nAs surrender became apparent by 14 December 1971, Pakistani paramilitaries and militia roamed the streets of Dhaka during the night, kidnapping, torturing and then executing any educated Bengali who was viewed as someone who could lead Bangladesh once Pakistan surrendered. Over 200 of these people were killed on the 14th. By 16 December, Pakistani morale had reached a low point, with the Indian Army finally encircling Dhaka and besieging the city. On the 16th, Indian forces issued a 30-minute ultimatum for the city to surrender. Seeing that the city's defences paled in comparison to the Mukti Bahini and Indian forces outside the city, Lt-Gen. A.A.K. Niazi (Cdr. of Eastern Command) and his deputy, V-Adm. M.S. Khan surrendered the city without resistance. BBC News captured the moment of surrender as Indian soldiers from the Parachute Regiment streamed into the city. As Indian forces and Mukti Bahini rounded up the remaining Pakistani forces, Lieutenant General Jagjit Singh Aurora of India and A.A.K. Niazi of Pakistan signed the Pakistani Instrument of Surrender at 16:31Hrs IST on 16 December 1971. The surrender signified the collapse of the East Pakistan Government along with the end of the war. 93,000 soldiers of the Pakistani security forces surrendered, the largest surrender since World War II. The entire four-tiered military surrendered to India along with its officers and generals. Large crowds flooded the scenes as anti-Pakistani slogans emerged and Pakistani POWs were beaten by the locals. Eventually, Indian officers formed a human-chain to protect Pakistani POWs and Niazi from being lynched by the belligerent locals. Most of the 93,000 captured were Pakistan Army officers or paramilitary officers, along with 12,000 supporters (razakars). Hostilities officially ended on 17 December 1971. 8,000 Pakistani soldiers were killed along with 25,000 wounded; Indian forces suffered only 3,000 dead and 12,000 wounded. India claimed to have captured 3.6k square kilometres of Pakistani land on the Western Front while losing 126 square kilometres of land to Pakistan.\nGandhi was hailed as Goddess Durga by the people as well as the opposition leaders at the time when India defeated Pakistan in the war. In the elections held for State assemblies across India in March 1972, the Congress (R) swept to power in most states riding on the post-war \"Indira wave\".\nVerdict on electoral malpractice.\nOn 12 June 1975, the Allahabad High Court declared Indira Gandhi's election to the Lok Sabha in 1971 void on the grounds of electoral malpractice. In an election petition filed by her 1971 opponent, Raj Narain (who later defeated her in the 1977 parliamentary election running in the Raebareli constituency), alleged several major as well as minor instances of the use of government resources for campaigning. Gandhi had asked one of her colleagues in government, Ashoke Kumar Sen, to defend her in court. She gave evidence in her defence during the trial. After almost four years, the court found her guilty of dishonest election practices, excessive election expenditure, and of using government machinery and officials for party purposes. The judge, however, rejected the more serious charges of bribery, laid against her in the case.\nThe court ordered her stripped of her parliamentary seat and banned her from running for any office for six years. As the constitution requires that the Prime Minister must be a member of either the Lok Sabha or the Rajya Sabha, the two houses of the Parliament of India, she was effectively removed from office. However, Gandhi rejected calls to resign. She announced plans to appeal to the Supreme Court and insisted that the conviction did not undermine her position. She said, \"There is a lot of talk about our government not being clean, but from our experience the situation was very much worse when [opposition] parties were forming governments.\" She dismissed criticism of the way her Congress Party raised election campaign money, saying all parties used the same methods. The prime minister retained the support of her party, which issued a statement backing her.\nAfter news of the verdict spread, hundreds of supporters demonstrated outside her house, pledging their loyalty. Indian High Commissioner to the United Kingdom Braj Kumar Nehru said Gandhi's conviction would not harm her political career. \"Mrs Gandhi has still today overwhelming support in the country,\" he said. \"I believe the prime minister of India will continue in office until the electorate of India decides otherwise\".\nState of Emergency (1975\u20131977).\nGandhi moved to restore order by ordering the arrest of most of the opposition participating in the unrest. Her Cabinet and government recommended that then President Fakhruddin Ali Ahmed declare a state of emergency because of the disorder and lawlessness following the Allahabad High Court decision. Accordingly, Ahmed declared a State of Emergency caused by internal disorder, based on the provisions of Article 352(1) of the Constitution, on 25 June 1975. At the time of emergency, there was a widespread rumour that Gandhi had ordered her search guards to eliminate firebrand trade unionist and socialist party leader George Fernandes, while he was on a run. Few International organisations and Government officials issued request letters to Indira Gandhi pleading her to relinquish such decrees. Fernandes had called a nationwide railway strike in 1974, that shut the railways for three weeks and became the largest industrial action in Asia. Gandhi had turned furious over him and the strike was massively cracked down.\nRule by decree.\nWithin a few months, President's rule was imposed on the two opposition party ruled states of Gujarat and Tamil Nadu thereby bringing the entire country under direct Central rule or by governments led by the ruling Congress party. Police were granted powers to impose curfews and detain citizens indefinitely; all publications were subjected to substantial censorship by the Ministry of Information and Broadcasting. Finally, the impending legislative assembly elections were postponed indefinitely, with all opposition-controlled state governments being removed by virtue of the constitutional provision allowing for a dismissal of a state government on the recommendation of the state's governor.\nIndira Gandhi used the emergency provisions to change conflicting party members:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nUnlike her father Jawaharlal Nehru, who preferred to deal with strong chief ministers in control of their legislative parties and state party organizations, Mrs. Gandhi set out to remove every Congress chief minister who had an independent base and to replace each of them with ministers personally loyal to her...Even so, stability could not be maintained in the states...\nPresident Ahmed issued ordinances that did not require debate in the Parliament, allowing Gandhi to rule by decree.\nRise of Sanjay Gandhi.\nDuring the emergency Gandhi's younger son, Sanjay Gandhi, entered into Indian politics. He wielded tremendous power during the emergency without holding any government office. According to Mark Tully, \"His inexperience did not stop him from using the Draconian powers his mother, Indira Gandhi, had taken to terrorise the administration, setting up what was in effect a police state.\" It was said that during the emergency Sanjay virtually ran India along with his friends, especially Bansi Lal. It was also quipped that Sanjay had total control over his mother and that the government was run by the PMH (Prime Minister House) rather than the PMO (Prime Minister Office).\nOpposition leader (1977\u20131980).\nIn 1977, after extending the state of emergency twice, Indira Gandhi called elections to give the electorate a chance to vindicate her rule. She may have grossly misjudged her popularity by reading what the heavily censored press wrote about her. She was opposed by the Janata alliance of Opposition parties. The alliance was made up of Bharatiya Jana Sangh, Congress (O), The Socialist parties, and Charan Singh's Bharatiya Kranti Dal representing northern peasants and farmers. The Janata alliance, with Jai Prakash Narayan as its spiritual guide, claimed the elections were the last chance for India to choose between \"democracy and dictatorship\". The Congress Party split during the election campaign of 1977; veteran Gandhi supporters like Jagjivan Ram, Hemvati Nandan Bahuguna, and Nandini Satpathy were compelled to part ways and form a new political entity, the CFD (Congress for Democracy) due primarily to intra-party politicking and the circumstances created by Sanjay Gandhi. The prevailing rumour was that he intended to dislodge Indira Gandhi, and the trio stood to prevent that. The Gandhi's Congress party was soundly crushed in the elections. The Janata Party's democracy or dictatorship claim seemed to resonate with the public. Indira Gandhi and Sanjay Gandhi lost their seats, and Congress was reduced to 153 seats (compared with 350 in the previous Lok Sabha), 92 of which were in the South. The Janata alliance, under the leadership of Morarji Desai, came to power after the State of Emergency was lifted. The alliance parties later merged to form the Janata Party under the guidance of Gandhian leader, Jayaprakash Narayan. The other leaders of the Janata Party were Charan Singh, Raj Narain, George Fernandes, and Atal Bihari Vajpayee.\nAfter the humiliating defeat in the election, the king of Nepal, through an intermediatory offered to move her and her family to Nepal. She refused to shift herself, but was open to move her two sons Sanjay Gandhi and Rajiv Gandhi. However, after consulting with Kao, she declined the offer altogether keeping in view of her future political career.\nIn opposition and return to power.\nSince Indira Gandhi had lost her seat in the election, the defeated Congress party appointed Yashwantrao Chavan as their parliamentary party leader. Soon afterwards, the Congress party split again with Gandhi floating her own Congress faction called Congress(I) where I stood for Indira. She won a by-election in the Chikmagalur Constituency and took a seat in the Lok Sabha in November 1978 after the Janata Party's attempts to have Kannada matinee idol Rajkumar run against her failed when he refused to contest the election saying he wanted to remain apolitical. However, the Janata government's home minister, Charan Singh, ordered her arrest along with Sanjay Gandhi on several charges, none of which would be easy to prove in an Indian court. The arrest meant that Gandhi was automatically expelled from Parliament. The allegations included that she \"had planned or thought of killing all opposition leaders in jail during the Emergency\". However, the strategy backfired disastrously. In response to her arrest, Gandhi's supporters hijacked an Indian Airlines jet and demanded her immediate release. Her arrest and long-running trial gained her sympathy from many people. The Janata coalition was only united by its hatred of Gandhi (or \"that woman\" as some called her). The party included right wing Hindu Nationalists, Socialists, and former Congress party members. With so little in common, the Morarji Desai government was bogged down by infighting. In 1979, the government began to unravel over the issue of the dual loyalties of some members to Janata and the Rashtriya Swayamsevak Sangh (RSS)\u2014the Hindu nationalist, paramilitary organisation. The ambitious Union finance minister, Charan Singh, who as the Union home minister during the previous year had ordered the Gandhi's' arrests, took advantage of this and started courting Indira and Sanjay. After a significant exodus from the party to Singh's faction, Desai resigned in July 1979. Singh was appointed prime minister, by President Reddy, after Indira Gandhi and Sanjay Gandhi promised Singh that Congress (I) would support his government from outside on certain conditions. The conditions included dropping all charges against Indira and Sanjay. Since Singh refused to drop them, Congress (I) withdrew its support and President Reddy dissolved Parliament in August 1979.\nBefore the 1980 elections Indira Gandhi approached the Shahi Imam of Jama Masjid at the time, Syed Abdullah Bukhari and entered into an agreement with him on the basis of 10-point programme to secure the support of the Muslim votes. In the elections held in January, Congress (I) under Gandhi's leadership returned to power with a landslide majority.\nPrime minister (1980\u20131984).\nThe Congress Party under Gandhi swept back into power in January 1980. In this election, Gandhi was elected by the voters of the Medak constituency. On 23\u00a0June, Sanjay Gandhi was killed in a plane crash while performing an aerobatic manoeuvre in New Delhi. In 1980, as a tribute to her son's dream of launching an indigenously manufactured car, Indira Gandhi nationalised Sanjay's debt-ridden company, Maruti Udyog, for Rs. 43,000,000 (4.34 crore) and invited joint venture bids from automobile companies around the world. Suzuki of Japan was selected as the partner. The company launched its first Indian-manufactured car in 1984.\nBy the time of Sanjay's death, Indira Gandhi trusted only family members, and therefore persuaded her reluctant son, Rajiv, to enter politics. Her PMO office staff included H. Y. Sharada Prasad as her information adviser and speechwriter.\nOperation Blue Star.\nAfter the 1977 elections, a coalition led by the Sikh-majority Akali Dal came to power in the northern Indian state of Punjab. In an effort to split the Akali Dal and gain popular support among the Sikhs, Gandhi's Congress Party helped to bring the orthodox religious leader Jarnail Singh Bhindranwale to prominence in Punjab politics. Later, Bhindranwale's organisation, Damdami Taksal, became embroiled in violence with another religious sect called the Sant Nirankari Mission and he was accused of instigating the murder of Jagat Narain, the owner of the \"Punjab Kesari\" newspaper. After being arrested, Bhindranwale disassociated himself from the Congress Party and joined Akali Dal. In July 1982, he led the campaign for the implementation of the Anandpur Resolution, which demanded greater autonomy for the Sikh-majority state. Meanwhile, a small group of Sikhs, including some of Bhindranwale's followers, turned to militancy after being targeted by government officials and police for supporting the Anandpur Resolution. In 1982, Bhindranwale and approximately 200 armed followers moved into a guest house called the Guru Nanak Niwas near the Golden Temple.\nBy 1983, the Temple complex had become a fort for many militants. \"The Statesman\" later reported that light machine guns and semi-automatic rifles were known to have been brought into the compound. On 23\u00a0April 1983, the Punjab Police Deputy Inspector General A. S. Atwal was shot dead as he left the Temple compound. The next day, Harchand Singh Longowal (then president of Akali Dal) confirmed the involvement of Bhindranwale in the murder. After several futile negotiations, in June 1984, Gandhi ordered the Indian army to enter the Golden Temple to remove Bhindranwale and his supporters from the complex. The army used heavy artillery, including tanks, in the action code-named Operation Blue Star. The operation badly damaged or destroyed parts of the Temple complex, including the Akal Takht shrine and the Sikh library. It led to the deaths of many Sikh fighters and innocent pilgrims. The number of casualties remains disputed, with estimates ranging from many hundreds to many thousands.\nGandhi was accused of using the attack for political ends. Harjinder Singh Dilgeer stated that she attacked the temple complex to present herself as a great hero in order to win the general elections planned towards the end of 1984. There was fierce criticism of the action by Sikhs in India and overseas. There were also incidents of mutiny by Sikh soldiers in the aftermath of the attack.\nAssassination.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\n\"I am alive today, I may not be there tomorrow\u00a0... I shall continue to serve until my last breath and when I die, I can say, that every drop of my blood will invigorate India and strengthen it \u00a0... Even if I died in the service of the nation, I would be proud of it. Every drop of my blood\u00a0... will contribute to the growth of this nation and to make it strong and dynamic.\"\n\u2014Gandhi's remarks on her last speech a day before her death (30 October 1984) at the then Parade Ground, Odisha.\nOn 31\u00a0October 1984, two of Gandhi's Sikh bodyguards, Satwant Singh and Beant Singh, shot her with their service weapons in the garden of the prime minister's residence at 1\u00a0Safdarjung Road, New Delhi, allegedly in revenge for Operation Blue Star. The shooting occurred as she was walking past a wicket gate guarded by the two men. She was to be interviewed by the British filmmaker Peter Ustinov, who was filming a documentary for Irish television. Beant shot her three times using his side-arm; Satwant fired 30 rounds. The men dropped their weapons and surrendered. Afterwards, they were taken away by other guards into a closed room where Beant was shot dead. Kehar Singh was later arrested for being part of the conspiracy in the attack. Satwant and Kehar were sentenced to death and hanged in Delhi's Tihar Jail.\nGandhi was taken to the All India Institutes of Medical Sciences at 9:30\u00a0AM where doctors operated on her. She was declared dead at 2:20\u00a0PM. The post-mortem examination was conducted by a team of doctors headed by Tirath Das Dogra. Dogra said that Gandhi had sustained as many as 30 bullet wounds from two sources: a Sten submachine gun and a .38 Special revolver. The assailants had fired 31 bullets at her, of which 30 hit her; 23 had passed through her body while seven remained inside her. Dogra extracted bullets to establish the make of the weapons used and to match each weapon with the bullets recovered by ballistic examination. The bullets were matched with their respective weapons at the Central Forensic Science Laboratory (CFSL) Delhi. Subsequently, Dogra appeared in Shri Mahesh Chandra's court as an expert witness (PW-5); he gave his testimony in several sessions. The cross examination was conducted by Shri Pran Nath Lekhi, the defence counsel. Salma Sultan provided the first news of her assassination on Doordarshan's evening news on 31\u00a0October 1984, more than 10\u00a0hours after she was shot.\nGandhi was cremated in accordance with Hindu tradition on 3\u00a0November near Raj Ghat. The site where she was cremated is known today as Shakti Sthal. Paying homage, Gandhi's body lay in state at Teen Murti House. Thousands of followers strained for a glimpse of the cremation. Her funeral was televised live on domestic and international stations, including the BBC. After her death, the Parade Ground was converted to the Indira Gandhi Park which was inaugurated by her son, Rajiv Gandhi.\nGandhi's assassination dramatically changed the political landscape. Rajiv succeeded his mother as prime minister within hours of her murder and anti-Sikh riots erupted, lasting for several days and killing more than 3,000 Sikhs in New Delhi and an estimated 8,000 across India. Many Congress leaders were believed to be behind the anti-Sikh massacre.\nInternational reaction.\nGandhi's death was mourned worldwide. World leaders condemned the assassination and said her death would leave a 'big emptiness' in international affairs. In Moscow, Soviet President Konstantin Chernenko sent condolences, \"The Soviet people learned with pain and sorrow about the untimely death in a villainous assassination of the glorious daughter of the great Indian people, a fiery fighter for peace and security of peoples and a great friend of the Soviet Union\". President Ronald Reagan, along with Secretary of State George Shultz, visited the Indian Embassy to sign a book of condolences and expressed his 'shock, revulsion, and grief' over the assassination. 42nd vice president of the United States Walter Mondale called Gandhi 'a great leader of a great democracy' and deplored 'this shocking act of violence'. Asian, African, and European leaders mourned Gandhi as a great champion of democracy and leader of the Non-Aligned Movement expressed its 'deepest grief' and called the killing a 'terrorist' act. South Korean President Chun Doo-hwan, said Gandhi's death meant the 'loss of a great leader to the whole world.' Yugoslav President Veselin \u0110uranovi\u0107, Pakistani President Mohammad Zia ul-Haq, Italian President Sandro Pertini, Pope John Paul II at the Vatican, and French President Fran\u00e7ois Mitterrand condemned the killing. At the United Nations, the General Assembly paused during its work as shocked delegates mourned the death. Assembly President Paul Lusaka of Zambia postponed a scheduled debate and hastily organised a memorial meeting.\nForeign policy.\nGandhi is remembered for her ability to effectively promote Indian foreign policy measures.\nSouth Asia.\nIn early 1971, disputed elections in Pakistan led then East Pakistan to declare independence as Bangladesh. Repression and violence by the Pakistani army led to 10 million refugees crossing the border into India over the following months. Finally, in December 1971, Gandhi intervened directly in the conflict to liberate Bangladesh. India emerged victorious following the war with Pakistan to become the dominant power of South Asia. India had signed a treaty with the Soviet Union promising mutual assistance in the case of war, while Pakistan received active support from the United States during the conflict. U.S. President Richard Nixon disliked Gandhi personally, referring to her as a \"bitch\" and a \"clever fox\" in his private communication with Secretary of State Henry Kissinger. Nixon later wrote of the war: \"[Gandhi] suckered [America]. Suckered us\u00a0... this woman suckered us.\" Relations with the U.S. became distant as Gandhi developed closer ties with the Soviet Union after the war. The latter grew to become India's largest trading partner and its biggest arms supplier for much of Gandhi's premiership. India's new hegemonic position, as articulated under the \"Indira Doctrine\", led to attempts to bring the Himalayan states under India's sphere of influence. Nepal and Bhutan remained aligned with India, while in 1975, after years of campaigning, Sikkim voted to join India in a referendum.\nIndia maintained close ties with neighbouring Bangladesh (formerly East Pakistan) following the Liberation War. Prime Minister Sheikh Mujibur Rahman recognised Gandhi's contributions to the independence of Bangladesh. However, Mujibur Rahman's pro-India policies antagonised many in Bangladeshi politics and the military, which feared that Bangladesh had become a client state of India. The Assassination of Mujibur Rahman in 1975 led to the establishment of Islamist military regimes that sought to distance the country from India. Gandhi's relationship with the military regimes was strained because of her alleged support of anti-Islamist leftist guerrilla forces in Bangladesh. Generally, however, there was a rapprochement between Gandhi and the Bangladeshi regimes, although issues such as border disputes and the Farakka Dam remained an irritant to bilateral ties. In 2011, the Government of Bangladesh conferred its highest state award for non-nationals, the Bangladesh Freedom Honour posthumously on Gandhi for her \"outstanding contribution\" to the country's independence.\nGandhi's approach to dealing with Sri Lanka's ethnic problems was initially accommodating. She enjoyed cordial relations with Prime Minister Sirimavo Bandaranaike. In 1974, India ceded the tiny islet of Katchatheevu to Sri Lanka to save Bandaranaike's socialist government from a political disaster. However, relations soured over Sri Lanka's movement away from socialism under J. R. Jayewardene, whom Gandhi despised as a \"western puppet\". India under Gandhi was alleged to have supported the Liberation Tigers of Tamil Eelam (LTTE) militants in the 1980s to put pressure on Jayewardene to abide by Indian interests. Nevertheless, Gandhi rejected demands to invade Sri Lanka in the aftermath of Black July 1983, an anti-Tamil pogrom carried out by Sinhalese mobs. Gandhi made a statement emphasising that she stood for the territorial integrity of Sri Lanka, although she also stated that India cannot \"remain a silent spectator to any injustice done to the Tamil community.\"\nIndia's relationship with Pakistan remained strained after the Shimla Accord in 1972. Gandhi's authorisation of the detonation of a nuclear device at Pokhran in 1974 was viewed by Pakistani leader Zulfikar Ali Bhutto as an attempt to intimidate Pakistan into accepting India's hegemony in the subcontinent. However, in May 1976, she and Bhutto both agreed to reopen diplomatic establishments and normalise relations. After General Muhammad Zia-ul-Haq rose to power in Pakistan in 1978, India's relations with its neighbour reached a nadir. Gandhi accused General Zia of supporting Khalistani militants in Punjab. Military hostilities recommenced in 1984 following Gandhi's authorisation of Operation Meghdoot. India was victorious in the resulting Siachen conflict against Pakistan.\nIn order to keep the Soviet Union and the United States out of South Asia, Gandhi was instrumental in establishing the South Asian Association for Regional Cooperation (SAARC) in 1983\nMiddle East.\nGandhi remained a staunch supporter of the Palestinians in the Arab\u2013Israeli conflict and was critical of the Middle East diplomacy sponsored by the United States. Israel was viewed as a religious state, and thus an analogue to India's archrival Pakistan. Indian diplomats hoped to win Arab support in countering Pakistan in Kashmir. Nevertheless, Gandhi authorised the development of a secret channel of contact and security assistance with Israel in the late 1960s. Her lieutenant, P. V. Narasimha Rao, later became prime minister and approved full diplomatic ties with Israel in 1992.\nIndia's pro-Arab policy had mixed success. Establishment of close ties with the socialist and secular Baathist regimes to some extent neutralised Pakistani propaganda against India. However, the Indo-Pakistani War of 1971 presented a dilemma for the Arab and Muslim states of the Middle East as the war was fought by two states both friendly to the Arabs. The progressive Arab regimes in Egypt, Syria, and Algeria chose to remain neutral, while the conservative pro-American Arab monarchies in Jordan, Saudi Arabia, Kuwait, and United Arab Emirates openly supported Pakistan. Egypt's stance was met with dismay by the Indians, who had come to expect close co-operation with the Baathist regimes. But, the death of Nasser in 1970 and Sadat's growing friendship with Riyadh, and his mounting differences with Moscow, constrained Egypt to a policy of neutrality. Gandhi's overtures to Muammar Gaddafi were rebuffed. Libya agreed with the Arab monarchies in believing that Gandhi's intervention in East Pakistan was an attack against Islam.\nThe 1971 war became a temporary stumbling block in growing Indo-Iranian ties. Although Iran had earlier characterised the Indo-Pakistani war in 1965 as Indian aggression, the Shah had launched an effort at rapprochement with India in 1969 as part of his effort to secure support for a larger Iranian role in the Persian Gulf. Gandhi's tilt towards Moscow and her dismemberment of Pakistan was perceived by the Shah as part of a larger anti-Iran conspiracy involving India, Iraq, and the Soviet Union. Nevertheless, Iran had resisted Pakistani pressure to activate the Baghdad Pact and draw the Central Treaty Organisation (CENTO) into the conflict. Gradually, Indian and Iranian disillusionment with their respective regional allies led to a renewed partnership between the nations. She was unhappy with the lack of support from India's Arab allies during the war with Pakistan, while the Shah was apprehensive at the growing friendship between Pakistan and Arab states of the Persian Gulf, especially Saudi Arabia, and the growing influence of Islam in Pakistani society. There was an increase in Indian economic and military co-operation with Iran during the 1970s. The 1974 India-Iranian agreement led to Iran supplying nearly 75 percent of India's crude oil demands. Gandhi appreciated the Shah's disregard of Pan-Islamism in diplomacy.\nAsia-Pacific.\nOne of the major developments in Southeast Asia during Gandhi's premiership was the formation of the Association of Southeast Asian Nations (ASEAN) in 1967. Relations between ASEAN and India were mutually antagonistic. India perceived ASEAN to be linked to the Southeast Asia Treaty Organization (SEATO) and, therefore, it was seen as a pro-American organisation. On their part, the ASEAN nations were unhappy with Gandhi's sympathy for the Viet Cong and India's strong links with the USSR. Furthermore, they were also apprehensions in the region about Gandhi's plans, particularly after India played a big role in breaking up Pakistan and facilitating the emergence of Bangladesh as a sovereign country in 1971. India's entry into the nuclear weapons club in 1974 also contributed to tensions in Southeast Asia. Relations only began to improve following Gandhi's endorsement of the ZOPFAN declaration and the disintegration of the SEATO alliance in the aftermath of Pakistani and American defeats in the region. Nevertheless, Gandhi's close relations with reunified Vietnam and her decision to recognise the Vietnam-installed Government of Cambodia in 1980 meant that India and ASEAN were unable to develop a viable partnership.\nOn 26\u00a0September 1981, Gandhi was conferred with the honorary degree of Doctor at the Laucala Graduation at the University of the South Pacific in Fiji.\nAfrica.\nAlthough independent India was initially viewed as a champion of various African independence movements, its cordial relationship with the Commonwealth of Nations and its liberal views of British policies in East Africa had harmed its image as a staunch supporter of various independence movements in the third world. Indian condemnation of militant struggles in Kenya and Algeria was in sharp contrast to China, who had supported armed struggle to win African independence. After reaching a high diplomatic point in the aftermath of Nehru's role in the Suez Crisis, India's isolation from Africa was almost complete when only four nations\u2014Ethiopia, Kenya, Nigeria, and Libya\u2014supported her during the Sino-Indian War in 1962. After Gandhi became prime minister, diplomatic and economic relations with the states which had sided with India during the Sino-Indian War were expanded. Gandhi began negotiations with the Kenyan government to establish the Africa-India Development Cooperation. The Indian government also started considering the possibility of bringing Indians settled in Africa within the framework of its policy goals to help recover its declining geo-strategic influence. Gandhi declared the people of Indian origin settled in Africa as \"Ambassadors of India\". Efforts to rope in the Asian community to join Indian diplomacy, however, came to naught, in part because of the unwillingness of Indians to remain in politically insecure surroundings, and because of the exodus of African Indians to Britain with the passing of the Commonwealth Immigrants Act in 1968. In Uganda, the African Indian community suffered persecution and eventually expulsion under the government of Idi Amin.\nForeign and domestic policy successes in the 1970s enabled Gandhi to rebuild India's image in the eyes of African states. Victory over Pakistan and India's possession of nuclear weapons showed the degree of India's progress. Furthermore, the conclusion of the Indo-Soviet treaty in 1971, and threatening gestures by the United States, to send its nuclear-armed Task Force 74 into the Bay of Bengal at the height of the East Pakistan crisis had enabled India to regain its anti-imperialist image. Gandhi firmly tied Indian anti-imperialist interests in Africa to those of the Soviet Union. Unlike Nehru, she openly and enthusiastically supported liberation struggles in Africa. At the same time, Chinese influence in Africa had declined owing to its incessant quarrels with the Soviet Union. These developments permanently halted India's decline in Africa and helped to reestablish its geo-strategic presence.\nThe Commonwealth.\nThe Commonwealth is a voluntary association of mainly former British colonies. India maintained cordial relations with most of the members during Gandhi's time in power. In the 1980s, she was regarded alongside Canadian prime minister Pierre Trudeau, Zambian president Kenneth Kaunda, Australian prime minister Malcolm Fraser and Singaporean prime minister Lee Kuan Yew as being one of the pillars of the Commonwealth. India under Gandhi also hosted the 1983 Commonwealth Heads of Government summit in New Delhi. Gandhi used the meetings as a forum to put pressure on member countries to cut economic, sports, and cultural ties with apartheid South Africa.\nThe Non-Aligned Movement.\nIn the early 1980s under Gandhi, India attempted to reassert its prominent role in the Non-Aligned Movement by focusing on the relationship between disarmament and economic development. By appealing to the economic grievances of developing countries, Gandhi and her successors exercised a moderating influence on the Non-Aligned Movement, diverting it from some of the Cold War issues that marred the controversial 1979 Havana meeting where Cuban leader Fidel Castro attempted to steer the movement towards the Soviet Union. Although hosting the 1983 summit at Delhi boosted Indian prestige within the movement, its close relations with the Soviet Union and its pro-Soviet positions on Afghanistan and Cambodia limited its influence.\nWestern Europe.\nGandhi spent a number of years in Europe during her youth and had formed many friendships there. During her premiership she formed friendships with many leaders including West German chancellor, Willy Brandt and Austrian chancellor Bruno Kreisky. She enjoyed a close working relationship with many British leaders including conservative premiers, Edward Heath and Margaret Thatcher.\nSoviet Union and Eastern Bloc countries.\nThe relationship between India and the Soviet Union deepened during Gandhi's rule. The main reason was the perceived bias of the United States and China, rivals of the USSR, towards Pakistan. The support of the Soviets with arms supplies and the casting of a veto at the United Nations helped in winning and consolidating the victory over Pakistan in the 1971 Bangladesh liberation war. Before the war, Gandhi signed a treaty of friendship with the Soviets. They were unhappy with the 1974 nuclear test conducted by India but did not support further action because of the ensuing Cold War with the United States. Gandhi was unhappy with the Soviet invasion of Afghanistan, but once again calculations involving relations with Pakistan and China kept her from criticising the Soviet Union harshly. The Soviets became the main arms supplier during the Gandhi years by offering cheap credit and transactions in rupees rather than in dollars. The easy trade deals also applied to non-military goods. Under Gandhi, by the early 1980s, the Soviets had become India's largest trading partner.\nSoviet intelligence in India.\nSoviet intelligence was involved in India during Indira Gandhi's administration, sometimes at Gandhi's expense. In the prelude to Operation Blue Star, by 1981, the Soviets had launched \"Operation Kontakt\", which was based on a forged document purporting to contain details of the weapons and money provided by the ISI to Sikh militants who wanted to create an independent country. In November 1982, Yuri Andropov, the General Secretary of the Communist Party and leader of the Soviet Union, approved a proposal to fabricate Pakistani intelligence documents detailing ISI plans to foment religious disturbances in Punjab and promote the creation of Khalistan as an independent Sikh state. Indira Gandhi's decision to move troops into the Punjab was based on her taking seriously the information provided by the Soviets regarding secret CIA support for the Sikhs.\nAccording to the Mitrokhin Archive, the Soviets used a new recruit in the New Delhi residency named \"Agent S\" who was close to Indira Gandhi as a major channel for providing her disinformation. Agent S provided Indira Gandhi with false documents purporting to show Pakistani involvement in the Khalistan conspiracy. The KGB became confident that it could continue to deceive Indira Gandhi indefinitely with fabricated reports of CIA and Pakistani conspiracies against her. The Soviets persuaded Rajiv Gandhi during a visit to Moscow in 1983 that the CIA was engaged in subversion in the Punjab. When Rajiv Gandhi returned to India, he declared this to be true. The KGB was responsible for Indira Gandhi exaggerating the threats posed by both the CIA and Pakistan. This KGB role in facilitating Operation Bluestar was acknowledged by Subramanian Swamy who stated in 1992 \"The 1984 Operation Bluestar became necessary because of the vast disinformation against Sant Bhindranwale by the KGB, and repeated inside Parliament by the Congress Party of India.\"\nA report following the Mitrokhin archive also caused some historiographical controversy about Indira Gandhi. In India, a senior leader of the Bharatiya Janata Party, L. K. Advani, requested of the Government a white paper on the role of foreign intelligence agencies and a judicial enquiry on the allegations. The spokesperson of the Indian Congress party referred to the book as \"pure sensationalism not even remotely based on facts or records\" and pointed out that the book is not based on official records from the Soviet Union. L.K Advani raised his voice because the book refers to ex-prime minister Indira Gandhi's (Codenamed VANO) relations with the KGB. The KGB was alleged to be directly link to Prime Minister of India, Indira Gandhi (code-named Vano). \"Suitcases full of banknotes were said to be routinely taken to the Prime Minister's house. Former Syndicate member S. K. Patil is reported to have said that Mrs. Gandhi did not even return the suitcases\". An extensive footprint in the Indian media was also described- \"According to KGB files, by 1973 it had ten Indian newspapers on its payroll (which cannot be identified for legal reasons) as well as a press agency under its control. During 1972 the KGB claimed to have planted 3,789 articles in Indian newspapers\u2013probably more than in any other country in the non-Communist world.\" According to its files, the number fell to 2,760 in 1973 but rose to 4,486 in 1974 and 5,510 in 1975. Mitrokhin estimated that in some major NATO countries, \"despite active-measures campaigns, the KGB was able to plant a little more than 1 per cent of the articles which it placed in the Indian press.\"\nUnited States.\nWhen Gandhi came to power in 1966, Lyndon Johnson was the US president. At the time, India was reliant on the US for food aid. Gandhi resented the US policy of food aid being used as a tool to force India to adopt policies favoured by the US. She also resolutely refused to sign the Treaty on the Non-Proliferation of Nuclear Weapons (NPT). Relations with the US were strained badly under President Richard Nixon and his favouring of Pakistan during the Bangladesh liberation war. Nixon despised Gandhi politically and personally. In 1981, Gandhi met President Ronald Reagan for the first time at the North\u2013South Summit held to discuss global poverty. She had been described to him as an 'Ogre', but he found her charming and easy to work with and they formed a close working relationship during her premiership in the 1980s.\nEconomic policy.\nGandhi presided over three Five-Year Plans as prime minister, two of which succeeded in meeting their targeted growth.\nThere is considerable debate whether Gandhi was a socialist on principle or out of political expediency. Sunanda K. Datta-Ray described her as \"a master of rhetoric\u00a0... often more posture than policy\", while \"The Times\" journalist, Peter Hazelhurst, famously quipped that Gandhi's socialism was \"slightly left of self-interest.\" Critics have focused on the contradictions in the evolution of her stance towards communism. Gandhi was known for her anti-communist stance in the 1950s, with Meghnad Desai even describing her as \"the scourge of [India's] Communist Party.\" Yet, she later forged close relations with Indian communists even while using the army to break the Naxalites. In this context, Gandhi was accused of formulating populist policies to suit her political needs. She was seemingly against the rich and big business while preserving the status quo to manipulate the support of the left in times of political insecurity, such as the late 1960s. Although in time Gandhi came to be viewed as the scourge of the right-wing and reactionary political elements of India, leftist opposition to her policies emerged. As early as 1969, critics had begun accusing her of insincerity and Machiavellianism. \"The Indian Libertarian\" wrote, \"it would be difficult to find a more machiavellian leftist than Mrs Indira Gandhi... for here is Machiavelli at its best in the person of a suave, charming and astute politician.\" J. Barkley Rosser Jr. wrote that \"some have even seen the declaration of emergency rule in 1975 as a move to suppress [leftist] dissent against Gandhi's policy shift to the right.\" In the 1980s, Gandhi was accused of \"betraying socialism\" after the beginning of \"Operation Forward\", an attempt at economic reform. Nevertheless, others were more convinced of Gandhi's sincerity and devotion to socialism. Pankaj Vohra noted that \"even the late prime minister's critics would concede that the maximum number of legislations of social significance was brought about during her tenure... [and that] she lives in the hearts of millions of Indians who shared her concern for the poor and weaker sections and who supported her politics.\"\nIn summarising the biographical works on Gandhi, Blema S. Steinberg concludes she was decidedly non-ideological. Only 7.4% (24) of the total 330 biographical extractions posit ideology as a reason for her policy choices. Steinberg notes Gandhi's association with socialism was superficial. She had only a general and traditional commitment to the ideology by way of her political and family ties. Gandhi personally had a fuzzy concept of socialism. In one of the early interviews she gave as prime minister, Gandhi ruminated, \"I suppose you could call me a socialist, but you have understand what we mean by that term\u00a0... we used the word [socialism] because it came closest to what we wanted to do here\u2013which is to eradicate poverty. You can call it socialism; but if by using that word we arouse controversy, I don't see why we should use it. I don't believe in words at all.\" Regardless of the debate over her ideology or lack thereof, Gandhi remains a left-wing icon. She has been described by \"Hindustan Times\" columnist, Pankaj Vohra, as \"arguably the greatest mass leader of the last century.\" Her campaign slogan, Garibi Hatao ('Remove Poverty'), has become an often used motto of the Indian National Congress Party. To the rural and urban poor, untouchables, minorities and women in India, Gandhi was \"Indira Amma or Mother Indira.\"\nGreen Revolution and the Fourth Five-Year Plan.\nGandhi inherited a weak and troubled economy. Fiscal problems associated with the war with Pakistan in 1965, along with a drought-induced food crisis that spawned famines, had plunged India into the sharpest recession since independence. The government responded by taking steps to liberalise the economy and agreeing to the devaluation of the currency in return for the restoration of foreign aid. The economy managed to recover in 1966 and ended up growing at 4.1% over 1966\u20131969. Much of that growth however, was offset by the fact that the external aid promised by the United States government and the International Bank for Reconstruction and Development (IBRD), meant to ease the short-run costs of adjustment to a liberalised economy, never materialised. American policy makers had complained of continued restrictions imposed on the economy. At the same time, Indo-US relations were strained because of Gandhi's criticism of the American bombing campaign in Vietnam. While it was thought at the time, and for decades after, that President Johnson's policy of withholding food grain shipments was to coerce Indian support for the war, in fact, it was to offer India rainmaking technology that he wanted to use as a counterweight to China's possession of the atomic bomb. In light of the circumstances, liberalisation became politically suspect and was soon abandoned. Grain diplomacy and currency devaluation became matters of intense national pride in India. After the bitter experience with Johnson, Gandhi decided not to request food aid in the future. Moreover, her government resolved never again to become \"so vulnerably dependent\" on aid, and painstakingly began building up substantial foreign exchange reserves. When food stocks slumped after poor harvests in 1972, the government made it a point to use foreign exchange to buy US wheat commercially rather than seek resumption of food aid.\nThe period of 1967\u201375 was characterised by socialist ascendency in India, which culminated in 1976 with the official declaration of state socialism. Gandhi not only abandoned the short-lived liberalisation programme but also aggressively expanded the public sector with new licensing requirements and other restrictions for industry. She began a new course by launching the Fourth Five-Year Plan in 1969. The government targeted growth at 5.7% while stating as its goals, \"growth with stability and progressive achievement of self-reliance.\" The rationale behind the overall plan was Gandhi's \"Ten-Point Programme\" of 1967. This had been her first economic policy formulation, six months after coming to office. The programme emphasised greater state control of the economy with the understanding that government control assured greater welfare than private control. Related to this point were a set of policies that were meant to regulate the private sector. By the end of the 1960s, the reversal of the liberalisation process was complete, and India's policies were characterised as \"protectionist as ever.\"\nTo deal with India's food problems, Gandhi expanded the emphasis on production of inputs to agriculture that had already been initiated by her father, Jawaharlal Nehru. The Green Revolution in India subsequently culminated under her government in the 1970s. It transformed the country from a nation heavily reliant on imported grains, and prone to famine, to one largely able to feed itself, and becoming successful in achieving its goal of food security. Gandhi had a personal motive in pursuing agricultural self-sufficiency, having found India's dependency on the U.S. for shipments of grains humiliating.\nThe economic period of 1967\u20131975 became significant for its major wave of nationalisation amidst increased regulation of the private sector. Some other objectives of the economic plan for that period were providing for the minimum needs of the community through a rural works program and the removal of the privy purses of the nobility. Those and many other goals of the 1967 programme were accomplished by 1974\u20131975. Nevertheless, the success of the overall economic plan was tempered by the fact that annual growth at 3.3\u20133.4% over 1969\u20131974 fell short of the targeted figure.\nThe Fifth Five-Year Plan.\nThe Fifth Five-Year Plan (1974\u20131979) was enacted with the backdrop of the state of emergency and the \"Twenty Point Program\" of 1975. It was the economic rationale of the emergency, a political act which has often been justified on economic grounds. In contrast to the reception of Gandhi's earlier economic plan, this one was criticised for being a \"hastily thrown together wish list.\" She promised to reduce poverty by targeting the consumption levels of the poor and enact wide-ranging social and economic reforms. In addition, the government targeted an annual growth rate of 4.4% over the period of the plan.\nThe measures of the emergency regime was able to halt the economic trouble of the early to mid-1970s, which had been marred by harvest failures, fiscal contraction, and the breakdown of the Bretton Woods system of fixed exchanged rates. The resulting turbulence in the foreign exchange markets was accentuated further by the oil shock of 1973. The government was able to exceed the targeted growth figure with an annual growth rate of 5.0\u20135.2% over the five-year period of the plan (1974\u201379). The economy grew at the rate of 9% in 1975\u201376 alone, and the Fifth Plan, became the first plan during which the per capita income of the economy grew by over 5%.\nOperation Forward and the Sixth Five-Year Plan.\nGandhi inherited a weak economy when she became prime minister again in 1980. The preceding year\u20141979\u201380\u2014under the Janata Party government saw the strongest recession (\u22125.2%) in the history of modern India with inflation rampant at 18.2%. Gandhi proceeded to abrogate the Janata Party government's Five-Year Plan in 1980 and launched the Sixth Five-Year Plan (1980\u201385). Her government targeted an average growth rate of 5.2% over the period of the plan. Measures to check inflation were also taken; by the early 1980s it was under control at an annual rate of about 5%.\nAlthough Gandhi continued professing socialist beliefs, the Sixth Five-Year Plan was markedly different from the years of Garibi Hatao. Populist programmes and policies were replaced by pragmatism. There was an emphasis on tightening public expenditures, greater efficiency of the state-owned enterprises (SOE), which Gandhi qualified as a \"sad thing\", and on stimulating the private sector through deregulation and liberation of the capital market. The government subsequently launched \"Operation Forward\" in 1982, the first cautious attempt at reform. The Sixth Plan went on to become the most successful of the Five-Year Plans yet; showing an average growth rate of 5.7% over 1980\u201385.\nInflation and unemployment.\nDuring Lal Bahadur Shastri's last full year in office (1965), inflation averaged 7.7%, compared to 5.2% at the end of Gandhi's first term in office (1977). On average, inflation in India had remained below 7% through the 1950s and 1960s. It then accelerated sharply in the 1970s, from 5.5% in 1970\u201371 to over 20% by 1973\u201374, due to the international oil crisis. Gandhi declared inflation the gravest of problems in 1974 (at 25.2%) and devised a severe anti-inflation program. The government was successful in bringing down inflation during the emergency; achieving negative figures of \u22121.1% by the end of 1975\u201376.\nGandhi inherited a tattered economy in her second term; harvest failures and a second oil shock in the late 1970s had caused inflation to rise again. During Charan Singh's short time in office in the second half of 1979, inflation averaged 18.2%, compared to 6.5% during Gandhi's last year in office (1984). General economic recovery under Gandhi led to an average inflation rate of 6.5% from 1981\u201382 to 1985\u201386\u2014the lowest since the beginning of India's inflation problems in the 1960s.\nThe unemployment rate remained constant at 9% over a nine-year period (1971\u201380) before declining to 8.3% in 1983.\nDomestic policy.\nNationalisation.\nDespite the provisions, control and regulations of the Reserve Bank of India, most banks in India had continued to be owned and operated by private persons. Businessmen who owned the banks were often accused of channeling the deposits into their own companies and ignoring priority sector lending. Furthermore, there was a great resentment against \"class\" banking in India, which had left the poor (the majority of the population) unbanked. After becoming prime minister, Gandhi expressed her intention of nationalising the banks to alleviate poverty in a paper titled, \"Stray thoughts on Bank Nationalisation\". The paper received overwhelming public support. In 1969, Gandhi moved to nationalise fourteen major commercial banks. After this, public sector bank branch deposits increased by approximately 800 percent; advances took a huge jump by 11,000 percent. Nationalisation also resulted in significant growth in the geographic coverage of banks. Jayaprakash Narayan, who became famous for leading the opposition to Gandhi in the 1970s, solidly praised her nationalisation of banks.\nHaving been re-elected in 1971 on a nationalisation platform, Gandhi proceeded to nationalise the coal, steel, copper, refining, cotton textiles, and insurance industries. Most of this was done to protect employment and the interests of organised labour. The remaining private sector industries were placed under strict regulatory control. During the Indo-Pakistani war of 1971, foreign-owned private oil companies had refused to supply fuel to the Indian Navy and the Indian Air Force. In response, Gandhi nationalised some oil companies in 1973. However, major nationalisations occurred in 1974 and 1976, forming the oil majors. After nationalisation, the oil majors including the Indian Oil Corporation (IOC), the Hindustan Petroleum Corporation (HPCL), and the Bharat Petroleum Corporation (BPCL) had to keep a minimum stock level of oil to be supplied to the military when needed.\nAdministration.\nIn 1966, Gandhi accepted the demands of the Akalis to reorganise Punjab on linguistic lines. The Hindi-speaking southern half of Punjab became a separate state, Haryana, while the Pahari speaking hilly areas in the northeast were joined to Himachal Pradesh. By this action she had hoped to ward off the growing political conflict between Hindu and Sikh groups in the region. However, a contentious issue that was considered unresolved by the Akalis was the status of Chandigarh, a prosperous city on the Punjab-Haryana border, which Gandhi declared a union territory to be shared as a capital by both the states.\nVictory over Pakistan in 1971 consolidated Indian power in Kashmir. Gandhi indicated that she would make no major concessions on Kashmir. The most prominent of the Kashmiri separatists, Sheikh Abdullah, had to recognise India's control over Kashmir in light of the new order in South Asia. The situation was normalised in the years following the war after Abdullah agreed to an accord with Gandhi, by giving up the demand for a plebiscite in return for a special autonomous status for Kashmir. In 1975, Gandhi declared the state of Jammu and Kashmir as a constituent unit of India. The Kashmir conflict remained largely peaceful if frozen under Gandhi's premiership.\nIn 1972, Gandhi granted statehood to Meghalaya, Manipur, and Tripura while the North-East Frontier Agency was declared a union territory and renamed Arunachal Pradesh. The transition to statehood for the territories was successfully overseen by her administration and it was followed by the annexation of Sikkim in 1975.\nSocial reform.\nThe principle of equal pay for equal work for both men and women was enshrined in the Indian Constitution under the Gandhi administration.\nGandhi questioned the continued existence of a privy purse for former rulers of princely states. She argued the case for abolition based on equal rights for all citizens and the need to reduce the government's revenue deficit. The nobility responded by rallying around the Jana Sangh and other right-wing parties that stood in opposition to Gandhi's attempts to abolish royal privileges. The motion to abolish privy purses, and the official recognition of the titles, was originally brought before the Parliament in 1970. It was passed in the Lok Sabha but fell short of the two-thirds majority in the Rajya Sabha by a single vote. Gandhi responded by having a Presidential proclamation issued; de-recognising the princes; with this withdrawal of recognition, their claims to privy purses were also legally lost. However, the proclamation was struck down by the Supreme Court of India. In 1971, she again motioned to abolish the privy purse and it was passed successfully as the 26th Amendment to the Constitution of India.\nGandhi claimed that only \"clear vision, iron will and the strictest discipline\" can remove poverty. She justified the imposition of the state of emergency in 1975 in the name of the socialist mission of the Congress. Armed with the power to rule by decree and without constitutional constraints, she embarked on a massive redistribution program. The provisions included rapid enforcement of land ceilings, housing for landless labourers, the abolition of bonded labour and a moratorium on the debts of the poor. North India was at the centre of the reforms. Millions of hectares of land were acquired and redistributed. The government was also successful in procuring houses for landless labourers; According to Francine Frankel, three-fourths of the targeted four million houses was achieved in 1975 alone. Nevertheless, others have disputed the success of the program and criticised Gandhi for not doing enough to reform land ownership. The political economist, Jyotindra Das Gupta, cryptically questioned \"whether or not the real supporters of land-holders were in jail or in power?\" Critics also accused Gandhi of choosing to \"talk left and act right\", referring to her concurrent pro-business decisions and endeavours. J. Barkley Rosser Jr. wrote that \"some have even seen the declaration of emergency rule in 1975 as a move to suppress dissent against Gandhi's policy shift to the right.\" Regardless of the controversy over the nature of the reforms, the long-term effects of the social changes gave rise to the prominence of middle-ranking farmers from intermediate and lower castes in North India. The rise of the newly empowered social classes challenged the political establishment of the Hindi Belt in the years to come.\nLanguage policy.\nUnder the 1950 Constitution of India, Hindi was to be the official national language by 1965. That was unacceptable to many non-Hindi-speaking states which wanted the continued use of English in government. In 1967, Gandhi introduced a constitutional amendment that guaranteed the de facto use of both Hindi and English as official languages. It established the official government policy of bilingualism in India and satisfied the non-Hindi-speaking Indian states. She thus put herself forward as a leader with a pan-Indian vision. Nevertheless, critics alleged that her stance was actually meant to weaken the position of rival Congress leaders from the northern states such as Uttar Pradesh, where there had been strong, sometimes violent, pro-Hindi agitations. Gandhi came out of the language conflicts with the strong support of the south Indian populace.\nNational security.\nIn the late 1960s and 1970s, Gandhi had the Indian army crush militant Communist uprisings in the Indian state of West Bengal. The communist insurgency in India was completely suppressed during the state of emergency.\nGandhi considered the north-eastern region important, because of its strategic situation. In 1966, the Mizo uprising took place against the government of India and overran almost the whole of the Mizoram region. She ordered the Indian Army to launch massive retaliatory strikes in response. The rebellion was suppressed with the Indian Air Force carrying out airstrikes in Aizawl; it remains the only instance of India carrying out airstrikes in its own territory. The defeat of Pakistan in 1971 and the secession of East Pakistan as pro-India Bangladesh led to the collapse of the Mizo separatist movement. In 1972, after the less extremist Mizo leaders came to the negotiating table, Gandhi upgraded Mizoram to the status of a union territory. A small-scale insurgency by some militants continued into the late 1970s, but it was successfully dealt with by the government. The Mizo conflict was definitively resolved during the administration of Gandhi's son Rajiv. Today, Mizoram is considered one of the most peaceful states in the north-east.\nResponding to the insurgency in Nagaland, Indira Gandhi \"unleashed a powerful military offensive\" in the 1970s. Finally, a massive crackdown on the insurgents took place during the state of emergency ordered by Gandhi. The insurgents soon agreed to surrender and signed the Shillong Accord in 1975. While the agreement was considered a victory for the Indian government and ended large-scale conflicts, there have since been spurts of violence by rebel holdouts and ethnic conflict amongst the tribes.\nIndia's nuclear programme.\nGandhi contributed to and carried out further, the vision of Jawaharlal Nehru, the former premier of India, to develop its nuclear program. Gandhi authorised the development of nuclear weapons in 1967, in response to \"Test No. 6\" by the People's Republic of China. Gandhi saw the test as Chinese nuclear intimidation and promoted Nehru's views to establish India's stability and security interests independent from those of the nuclear superpowers.\nThe programme became fully mature in 1974, when Raja Ramanna reported to Gandhi that India had the ability to test its first nuclear weapon. Gandhi gave verbal authorisation for the test, and preparations were made in the Indian Army's Pokhran Test Range.&lt;ref name=\"http://nuclearweaponarchive.org\"&gt;&lt;/ref&gt; In 1974, India successfully conducted an underground nuclear test, unofficially code named \"Smiling Buddha\", near the desert village of Pokhran in Rajasthan. As the world was quiet about this test, a vehement protest came from Pakistan as its prime minister, Zulfikar Ali Bhutto, described the test as \"Indian hegemony\" to intimidate Pakistan. In response to this, Bhutto launched a massive campaign to make Pakistan a nuclear power. Bhutto asked the nation to unite and slogans such as \"hum ghaas aur pattay kha lay gay magar nuclear power ban k rhe gay\" (\"We will eat grass or leaves or even go hungry, but we will get nuclear power\") were employed. Gandhi directed a letter to Bhutto, and later to the world, claiming the test was for peaceful purposes and part of India's commitment to develop its programme for industrial and scientific use.\nIn spite of intense international criticism and steady decline in foreign investment and trade, the nuclear test was popular domestically. The test caused an immediate revival of Gandhi's popularity, which had flagged considerably from its heights after the 1971 war. The overall popularity and image of the Congress Party was enhanced and the Congress Party was well received in the Indian Parliament.\nPersonal life.\nShe married Feroze Gandhi at the age of 25, in 1942. Their marriage lasted 18 years until he died of a heart attack in 1960. They had two sons\u2014Rajiv and Sanjay. Initially, her younger son Sanjay had been her chosen heir, but after his death in a flying accident in June 1980, Indira Gandhi persuaded her reluctant elder son Rajiv to quit his job as a pilot and enter politics in February 1981. Rajiv took office as prime minister following his mother's assassination in 1984; he served until December 1989. Rajiv Gandhi was assassinated by a suicide bomber working on behalf of LTTE on 21\u00a0May 1991.\nViews on women.\nIn 1952 in a letter to her American friend Dorothy Norman, Gandhi wrote: \"I am in no sense a feminist, but I believe in women being able to do everything... Given the opportunity to develop, capable Indian women have come to the top at once.\" While this statement appears paradoxical, it reflects Gandhi's complex feelings toward her gender and feminism. Her egalitarian upbringing with her cousins helped contribute to her sense of natural equality. \"Flying kites, climbing trees, playing marbles with her boy cousins, Indira said she hardly knew the difference between a boy and a girl until the age of twelve.\"\nGandhi did not often discuss her gender but she involved herself in women's issues before becoming the prime minister. Before her election as prime minister, she became active in the organisational wing of the Congress party, working in part in the Women's Department. In 1956, she had an active role in setting up the Congress Party's Women's Section. Unsurprisingly, a lot of her involvement stemmed from her father. As an only child, Gandhi naturally stepped into the political light. And, as a woman, she naturally helped head the Women's section of the Congress Party. She often tried to organise women to involve themselves in politics. Although rhetorically Gandhi may have attempted to separate her political success from her gender, she did involve herself in women's organisations. The political parties in India paid substantial attention to Gandhi's gender before she became prime minister, hoping to use her for political gain.\nEven though men surrounded her during her upbringing, she still had a female role model as a child. Several books on Gandhi reference her interest in Joan of Arc. In Gandhi's own accounts through her letters, she wrote to her friend Dorothy Norman, in 1952 she wrote: \"At about eight or nine I was taken to France; Jeanne d'Arc became a great heroine of mine. She was one of the first people I read about with enthusiasm.\" Another historian recounts Indira's comparison of herself to Joan of Arc: \"Indira developed a fascination for Joan of Arc, telling her aunt, 'Someday I am going to lead my people to freedom just as Joan of Arc did'!\" Gandhi's linking of herself to Joan of Arc presents a model for historians to assess Gandhi. As one writer said: \"The Indian people were her children; members of her family were the only people capable of leading them.\"\nGandhi had been swept up in the call for Indian independence since she was born in 1917. Thus by 1947, she was already well immersed in politics, and by 1966, when she first assumed the position of prime minister, she had held several cabinet positions in her father's office. Her advocacy for women's rights began with her help in establishing the Congress Party's Women's Section. In 1956, she wrote in a letter: \"It is because of this that I am taking a much more active part in politics. I have to do a great deal of touring in order to set up the Congress Party Women's Section, and am on numerous important committees.\" Gandhi spent a great deal of time throughout the 1950s helping to organise women. She wrote to Norman in 1959, irritable that women had organised around the communist cause but had not mobilised for the Indian cause: \"The women, whom I have been trying to organise for years, had always refused to come into politics. Now they are out in the field.\" Once appointed president in 1959, she \"travelled relentlessly, visiting remote parts of the country that had never before received a VIP... she talked to women, asked about child health and welfare, inquired after the crafts of the region\" Her actions throughout her ascent to power clearly reflect a desire to mobilise women. Gandhi did not see the purpose of feminism. She saw her own success as a woman, and also noted that: \"Given the opportunity to develop, capable Indian women have come to the top at once.\"\nGandhi felt guilty about her inability to fully devote her time to her children. She noted that her main problem in office was how to balance her political duties with tending to her children, and \"stressed that motherhood was the most important part of her life.\" At another point, she went into more detail: \"To a woman, motherhood is the highest fulfilment\u00a0... To bring a new being into this world, to see its perfection and to dream of its future greatness is the most moving of all experiences and fills one with wonder and exaltation.\" Her domestic initiatives did not necessarily reflect favourably on Indian women. Gandhi did not make a special effort to appoint women to cabinet positions. She did not appoint any women to full cabinet rank during her terms in office. Yet despite this, many women saw Gandhi as a symbol for feminism and an image of women's power.\nLegacy.\nAmerican veteran politician Henry A. Kissinger had described Indira Gandhi as being an \"Iron lady\", a nickname that became associated with her tough personality. After leading India to victory against Pakistan in the Bangladesh Liberation War in 1971, President V. V. Giri awarded Gandhi with India's highest civilian honour, the Bharat Ratna. In 2011, the Bangladesh Freedom Honour, Bangladesh's highest civilian award for foreign nationals, was posthumously conferred on Gandhi for her \"outstanding contributions\" to Bangladesh's Liberation War.\nGandhi's main legacy was standing firm in the face of American pressure to defeat Pakistan and turn East Pakistan into independent Bangladesh. She was responsible for India joining the group of countries with nuclear weapons. Although India being officially part of the Non-Aligned Movement, she gave Indian foreign policy a tilt towards the Soviet bloc. In 1999, Gandhi was named \"Woman of the Millennium\" in an online poll organised by the BBC. In 2012, she was ranked number seven on \"Outlook India's\" poll of the Greatest Indian.\nBeing at the forefront of Indian politics for decades, Gandhi left a powerful legacy on Indian politics. Similarly, some of her actions have also caused controversies. One of the criticisms concerns her rule to have damaged internal party democracy in the Congress party. Her detractors accuse her of weakening State chief ministers and thereby weakening the federal structure, weakening the independence of the judiciary, and weakening her cabinet by vesting power in her secretariat and her sons. Gandhi is also associated with fostering a culture of nepotism in Indian politics and in India's institutions. She is also almost singularly associated with the period of emergency rule, described by some as a \"dark period\" in Indian democracy. The Forty-second Amendment of the Constitution of India which was adopted during the emergency can also be regarded as part of her legacy. Although judicial challenges and non-Congress governments tried to water down the amendment, the amendment still stands.\nShe was the only woman to occupy the office of the prime minister of India and in 2020, Gandhi was named by \"Time\" magazine among the world's 100 powerful women who defined the last century. Shakti Sthal means a \"place of strength\" and is a monument to her.\nIn popular culture.\nWhile portrayals of Indira Gandhi by actors in Indian cinema have generally been avoided, with filmmakers using back-shots, silhouettes and voiceovers to give impressions of her character, several films surrounding her tenure, policies or assassination have been made.\nThese include \"Aandhi\" (1975) by Gulzar, \"Kissa Kursi Ka\" (1975) by Amrit Nahata\", Nasbandi\" (1978) by I. S. Johar, \"Maachis\" (1996) by Gulzar, \"Hazaaron Khwaishein Aisi\" (2003) by Sudhir Mishra, \"Hawayein\" (2003) by Ammtoje Mann, \"Des Hoyaa Pardes\" (2004) by Manoj Punj, \"Kaya Taran\" (2004) by Sashi Kumar, \"Amu\" (2005) by Shonali Bose, \"Kaum De Heere\" (2014) by Ravinder Ravi, \"47 to 84\" (2014) by Rajiv Sharma, \"Punjab 1984\" (2014) by Anurag Singh, \"The Fourth Direction\" (2015) by Gurvinder Singh, \"Dharam Yudh Morcha\" (2016) by Naresh S. Garg, \"31 October\" (2016) by Shivaji Lotan Patil, \"Baadshaho\" (2017) by Milan Luthria, \"Toofan Singh\" (2017) by Baghal Singh, \"Sonchiriya\" (2019) by Abhishek Chaubey, \"Shukranu\" (2020) by Bishnu Dev Halder. \"Aandhi\", \"Kissa Kursi Ka\" and \"Nasbandi\" are notable for having been released during Gandhi's lifetime and were subject to censorship on exhibition during the Emergency.\n\"Indus Valley to Indira Gandhi\" is a 1970 Indian two-part documentary film by S. Krishnaswamy which traces the history of India from the earliest times of the Indus Valley Civilisation to the prime ministership of Indira Gandhi. The Films Division of India produced \"Our Indira\", a 1973 short documentary film directed by S.N.S. Sastry showing the beginning of her first tenure as PM and her speeches from the Stockholm Conference.\n\"Pradhanmantri\" (lit.\u2009'Prime Minister'), a 2013 Indian documentary television series which aired on ABP News and covers the various policies and political tenures of Indian PMs, includes the tenureship of Gandhi in the episodes \"Indira Gandhi Becomes PM\", \"Split in Congress Party\", \"Story before Indo-Pakistani War of 1971\", \"Indo-Pakistani War of 1971 and Birth of Bangladesh\", \"1975\u201377 State of Emergency in India\", and \"Indira Gandhi back as PM and Operation Blue Star\" with Navni Parihar portraying the role of Gandhi. Parihar also portrays Gandhi in the 2021 Indian film \"\" which is based on the 1971 Indo-Pakistani War.\nThe taboo surrounding the depiction of Indira Gandhi in Indian cinema has begun to dissipate in recent years with actors portraying her in films. Notable portrayals include: Sarita Choudhury in \"Midnight's Children\" (2012); Mandeep Kohli in \"Jai Jawaan Jai Kisaan\" (2015); Supriya Vinod in \"Indu Sarkar\" (2017), '/' (2019) and \"Yashwantrao Chavan \u2013 Bakhar Eka Vaadalaachi\" (2014); Flora Jacob in \"Raid\" (2018), \"Thalaivi\" (2021) and \"Radhe Shyam\" (2022), Kishori Shahane in \"PM Narendra Modi\" (2019), Avantika Akerkar in \"Thackeray\" (2019) and \"83\" (2021), Supriya Karnik in \"Main Mulayam Singh Yadav\" (2021), Lara Dutta in \"Bell Bottom\" (2021), Fatima Sana Shaikh in \"Sam Bahadur\" (2023) and Kangana Ranaut in \"Emergency\" (2025).\nThe phrase \"indiragandi\" is used in Turkish slang as a way to convey the action of getting money through corruption or otherwise unethical means. This is largely due to the word \"indirmek\" (English: take down) being used similarly in slang, although the corruption scandal that Indira Gandhi presided over is also a factor.\nBibliography.\n\"Book written by Indira Gandhi\"\n\"Books on Indira Gandhi\"\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nSources.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nBibliography.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nExternal links.\nrole=\"presentation\" class=\"wikitable succession-box noprint\" style=\"margin:0.5em auto; font-size:small;clear:both;\""}
{"id": "15180", "revid": "7903804", "url": "https://en.wikipedia.org/wiki?curid=15180", "title": "Intergovernmentalism", "text": "Concept in international relations\nIn international relations, intergovernmentalism treats states (and national governments in particular) as the primary actors in the integration process. Intergovernmentalist approaches claim to be able to explain both periods of radical change in the European Union because of converging governmental preferences and periods of inertia because of diverging national interests. \nIntergovernmentalism is distinguishable from realism and neorealism because it recognized the significance of institutionalisation in international politics and the impact of domestic politics upon governmental preferences.\nRegional integration.\nEuropean integration.\nThe best-known example of regional integration is the European Union (EU), an economic and political intergovernmental organisation of 27 member states, all in Europe. The EU operates through a system of supranational independent institutions and intergovernmental negotiated decisions by the member states. Institutions of the EU include the European Commission, the Council of the European Union, the European Council, the Court of Justice of the European Union, the European Central Bank, the Court of Auditors, and the European Parliament. The European Parliament is elected every five years by EU citizens.\nThe EU has developed a single market through a standardised system of laws that apply in all member states. Within the Schengen Area (which includes 25 EU and 4 non-EU European states) passport controls have been abolished. EU policies favour the free movement of people, goods, services, and capital within its boundaries, enact legislation in justice and home affairs, and maintain common policies on trade, agriculture, fisheries and regional development.\nA monetary union, the eurozone, was established in 1999 and is composed of 17 member states. Through the Common Foreign and Security Policy the EU has developed a role in external relations and defence. Permanent diplomatic missions have been established around the world. The EU is represented at the United Nations, the World Trade Organization, the G8 and the G-20.\nIntergovernmentalism represents a way for limiting the conferral of powers upon supranational institutions, halting the emergence of common policies. In the current institutional system of the EU, the European Council and the Council play the role of the institutions which have the last word about decisions and policies of the EU, institutionalizing a de facto intergovernmental control over the EU as a whole, with the possibility to give more power to a small group of states. This extreme consequence can create the condition of supremacy of someone over someone else violating the principle of a \"Union of Equals\". However, from a neo-functionalist viewpoint, some scholars argue that despite the appearance of intergovernmental dominance, the EU's supranational institutions have progressively expanded their influence through spillover effects, which gradually limit member states' control and enhance deeper integration.\nAfrican integration.\nThe African Union (AU, or, in its other official languages, UA) is a continental intergovernmental union, similar but less integrated to the EU, consisting of 54\u00a0African states. The AU was presented on 26 May 2001 in Addis Ababa, Ethiopia and officially founded on 9 July 2002 in Durban, South Africa to replace the Organisation of African Unity (OAU). The most important decisions of the AU are made by the Assembly of the African Union, a semi-annual meeting of the heads of state and government of its member states. The AU's secretariat, the African Union Commission, is based in Addis Ababa, Ethiopia.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "15181", "revid": "24618756", "url": "https://en.wikipedia.org/wiki?curid=15181", "title": "Individualism", "text": "Concept regarding the moral worth of the individual\nIndividualism is the moral stance, political philosophy, ideology, and social outlook that emphasizes the worth or central role of the individual. Individualists promote realizing one's goals and desires, valuing independence and self-reliance, and advocating that the interests of the individual should gain precedence over the state or a social group, while opposing external interference upon one's own interests by society or institutions such as the government. Individualism makes the individual its focus, and so starts \"with the fundamental premise that the human individual is of primary importance in the struggle for liberation\". \nIndividualism represents one kind of sociocultural perspective and is often defined in contrast to other perspectives, such as communitarianism, collectivism and corporatism.\nIndividualism is also associated with artistic and bohemian interests and lifestyles, where there is a tendency towards self-creation and experimentation as opposed to tradition or popular mass opinions and behaviors, and it is associated with humanist philosophical positions and ethics. \"Individualism\" has also been used as a term denoting \"[t]he quality of being an individual; individuality\", related to possessing \"[a]n individual characteristic; a quirk\".\nEtymology.\nIn the English language, the word \"individualism\" was first introduced as a pejorative by utopian socialists such as the Owenites in the late 1830s, although it is unclear if they were influenced by Saint-Simonianism or came up with it independently. A more positive use of the term in Britain came to be used with the writings of James Elishama Smith, a millenarian-turned-socialist and Christian Israelite. Although an early follower of Robert Owen, he eventually rejected Owen's collective idea of property and found in individualism a \"universalism\" that allowed for the development of the \"original genius\". Without individualism, Smith argued that individuals cannot amass property to increase one's happiness. William Maccall, another Unitarian preacher and probably an acquaintance of Smith, came somewhat later, although influenced by John Stuart Mill, Thomas Carlyle and German Romanticism, to the same positive conclusions in his 1847 work \"Elements of Individualism\".\nIndividual.\nAn individual is a person or any specific object in a collection. In the 15th century and earlier, and also today within the fields of statistics and metaphysics, individual means \"indivisible\", typically describing any numerically singular thing, but sometimes meaning \"a person\" as in \"the problem of proper names\". From the 17th century on, individual indicates separateness, as in individualism. Individuality is the state or quality of being an individuated being; a person separated from everything with unique character by possessing their own needs, goals, and desires in comparison to other people.\nIndividuation principle.\nThe principle of individuation, or \"\", describes the manner in which a thing is identified as distinguished from other things. For Carl Jung, individuation is a process of transformation, whereby the personal and collective unconscious is brought into consciousness (by means of dreams, active imagination or free association to take examples) to be assimilated into the whole personality. It is a completely natural process necessary for the integration of the psyche to take place. Jung considered individuation to be the central process of human development. In \"L'individuation psychique et collective\", Gilbert Simondon developed a theory of individual and collective individuation in which the individual subject is considered as an effect of individuation rather than a cause. Thus, the individual atom is replaced by a never-ending ontological process of individuation. Individuation is an always incomplete process, always leaving a \"pre-individual\" left-over, itself making possible future individuations. The philosophy of Bernard Stiegler draws upon and modifies the work of Gilbert Simondon on individuation and also upon similar ideas in Friedrich Nietzsche and Sigmund Freud. For Stiegler, \"the \"I\", as a psychic individual, can only be thought in relationship to \"we\", which is a collective individual. The \"I\" is constituted in adopting a collective tradition, which it inherits and in which a plurality of \"I\"'s acknowledge each other's existence.\"\nIndividualism and society.\nIndividualism holds that a person taking part in society attempts to learn and discover what their own interests are on a personal basis, without a presumed following of the interests of a societal structure (an individualist need not be an egoist). The individualist does not necessarily follow one particular philosophy. They may create an amalgamation of elements of many philosophies, based on personal interests in particular aspects that they find of use. On a societal level, the individualist participates on a personally structured political and moral ground. Independent thinking and opinion is a necessary trait of an individualist. Jean-Jacques Rousseau, claims that his concept of general will in \"The Social Contract\" is not the simple collection of individual wills and that it furthers the interests of the individual (the constraint of law itself would be beneficial for the individual, as the lack of respect for the law necessarily entails, in Rousseau's eyes, a form of ignorance and submission to one's passions instead of the preferred autonomy of reason).\nIndividualism versus collectivism is a common dichotomy in cross-cultural research. Global comparative studies have found that the world's cultures vary in the degree to which they emphasize individual autonomy, freedom and initiative (individualistic traits), respectively conformity to group norms, maintaining traditions and obedience to in-group authority (collectivistic traits). Cultural differences between individualism and collectivism are differences in degrees, not in kind. Cultural individualism is strongly correlated with GDP per capita and venture capital investments. The cultures of economically developed regions such as Australia, New Zealand, Japan, South Korea, North America and Western Europe are the most individualistic in the world. Middle income regions such as Eastern Europe, South America and mainland East Asia have cultures which are neither very individualistic nor very collectivistic. The most collectivistic cultures in the world are from economically developing regions such as the Middle East and Northern Africa, Sub-Saharan Africa, South and South-East Asia, Central Asia and Central America. Against this background, a number of prominent authors from various disciplines (e.g., Louis Dumont, Geert Hofstede, Anthony Giddens, Zygmunt Bauman, Ronald Inglehart) have supported the influential thesis that the modernization of a society goes hand in hand with an increasing degree of individualization. However, this thesis has also found its critics, who point out, among other things, that the cultural-historical development of individualism from antiquity to the present has not proceeded in a straight line, that some societies with a more collectivist orientation are nevertheless highly modernized and that the concepts of individualism, collectivism and modernity lack conceptual clarity so that an appropriately differentiated analysis of the alleged connection is still lacking. \u00a0 \nAn earlier analysis by Ruth Benedict in her book The Chrysanthemum and the Sword states that societies and groups can differ in the extent to which they are based upon predominantly \"self-regarding\" (individualistic, and/or self-interested) behaviors, rather than \"other-regarding\" (group-oriented, and group, or society-minded) behaviors. Ruth Benedict made a distinction, relevant in this context, between guilt societies (e.g. medieval Europe) with an \"internal reference standard\" and shame societies (e.g. Japan, \"bringing shame upon one's ancestors\") with an \"external reference standard\", where people look to their peers for feedback on whether an action is acceptable or not.\nIndividualism is often contrasted either with totalitarianism or with collectivism, but there is a spectrum of behaviors at the societal level ranging from highly individualistic societies through mixed societies to collectivist.\nA 2022 study published by the Journal of Economic Behavior and Organization indicates that the individualistic societies have higher levels of charitable giving, providing a response to critics of individualism and capitalism. The authors propose that individualism increases charity through direct mechanisms (self-interested giving) and indirect mechanisms (reinforcing economic freedom). The findings support classical liberal arguments that individualism has virtues, aligning with the views of thinkers like Adam Smith and David Hume.\nCompetitive individualism.\nAccording to an Oxford Dictionary, \"competitive individualism\" in sociology is \"the view that achievement and non-achievement should depend on merit. Effort and ability are regarded as prerequisites of success. Competition is seen as an acceptable means of distributing limited resources and rewards.\nMethodological individualism.\nMethodological individualism is the view that phenomena can only be understood by examining how they result from the motivations and actions of individual agents. In economics, people's behavior is explained in terms of rational choices, as constrained by prices and incomes. The economist accepts individuals' preferences as givens. Becker and Stigler provide a forceful statement of this view:\nOn the traditional view, an explanation of economic phenomena that reaches a difference in tastes between people or times is the terminus of the argument: the problem is abandoned at this point to whoever studies and explains tastes (psychologists? anthropologists? phrenologists? sociobiologists?). On our preferred interpretation, one never reaches this impasse: the economist continues to search for differences in prices or incomes to explain any differences or changes in behavior.\nPolitical individualism.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\n\"With the abolition of private property, then, we shall have true, beautiful, healthy Individualism. Nobody will waste his life in accumulating things, and the symbols for things. One will live. To live is the rarest thing in the world. Most people exist, that is all.\"\n\u2014Oscar Wilde, \"The Soul of Man under Socialism\", 1891\nIndividualists are chiefly concerned with protecting individual autonomy against obligations imposed by social institutions (such as the state or religious morality). For L. Susan Brown, \"Liberalism and anarchism are two political philosophies that are fundamentally concerned with individual freedom yet differ from one another in very distinct ways. Anarchism shares with liberalism a radical commitment to individual freedom while rejecting liberalism's competitive property relations.\"\nCivil libertarianism is a strain of political thought that supports civil liberties, or which emphasizes the supremacy of individual rights and personal freedoms over and against any kind of authority (such as a state, a corporation and social norms imposed through peer pressure, among others). Civil libertarianism is not a complete ideology; rather, it is a collection of views on the specific issues of civil liberties and civil rights. Because of this, a civil libertarian outlook is compatible with many other political philosophies, and civil libertarianism is found on both the right and left in modern politics. For scholar Ellen Meiksins Wood, \"there are doctrines of individualism that are opposed to Lockean individualism [...] and non-Lockean individualism may encompass socialism\".\nBritish historians such as Emily Robinson, Camilla Schofield, Florence Sutcliffe-Braithwaite and Natalie Thomlinson have argued that Britons were keen about defining and claiming their individual rights, identities and perspectives by the 1970s, demanding greater personal autonomy and self-determination and less outside control, angrily complaining that the establishment was withholding it. Historians argue that this shift in concerns helped cause Thatcherism and was incorporated into Thatcherism's appeal.\nAnarchism.\nWithin anarchism, individualist anarchism represents several traditions of thought within the anarchist movement that emphasize the individual and their will over any kinds of external determinants such as groups, society, traditions and ideological systems. Individualist anarchism is not a single philosophy but refers to a group of individualistic philosophies that sometimes are in conflict.\nIn 1793, William Godwin, who has often been cited as the first anarchist, wrote \"Political Justice\", which some consider to be the first expression of anarchism. Godwin, a philosophical anarchist, from a rationalist and utilitarian basis opposed revolutionary action and saw a minimal state as a present \"necessary evil\" that would become increasingly irrelevant and powerless by the gradual spread of knowledge. Godwin advocated individualism, proposing that all cooperation in labour be eliminated on the premise that this would be most conducive with the general good.\nAn influential form of individualist anarchism called egoism, or egoist anarchism, was expounded by one of the earliest and best-known proponents of individualist anarchism, the German Max Stirner. Stirner's \"The Ego and Its Own\", published in 1844, is a founding text of the philosophy. According to Stirner, the only limitation on the rights of the individual is their power to obtain what they desire, without regard for God, state, or morality. To Stirner, rights were \"spooks\" in the mind, and he held that society does not exist but \"the individuals are its reality\". Stirner advocated self-assertion and foresaw unions of egoists, non-systematic associations continually renewed by all parties' support through an act of will, which Stirner proposed as a form of organization in place of the state. Egoist anarchists claim that egoism will foster genuine and spontaneous union between individuals. Egoist anarchism has inspired many interpretations of Stirner's philosophy. It was re-discovered and promoted by German philosophical anarchist and LGBT activist John Henry Mackay.\nJosiah Warren is widely regarded as the first American anarchist and \"The Peaceful Revolutionist\", the four-page weekly paper he edited during 1833, was the first anarchist periodical published. For American anarchist historian Eunice Minette Schuster, \"[i]t is apparent [...] that Proudhonian Anarchism was to be found in the United States at least as early as 1848 and that it was not conscious of its affinity to the Individualist Anarchism of Josiah Warren and Stephen Pearl Andrews. [...] William B. Greene presented this Proudhonian Mutualism in its purest and most systematic form\". Henry David Thoreau was an important early influence in individualist anarchist thought in the United States and Europe. Thoreau was an American author, poet, naturalist, tax resister, development critic, surveyor, historian, philosopher and leading transcendentalist, who is best known for his book \"Walden\", a reflection upon simple living in natural surroundings, and his essay \"Civil Disobedience\", an argument for individual resistance to civil government in moral opposition to an unjust state. Later, Benjamin Tucker fused Stirner's egoism with the economics of Warren and Proudhon in his eclectic influential publication \"Liberty\".\nFrom these early influences, anarchism and especially individualist anarchism was related to the issues of love and sex. In different countries, this attracted a small but diverse following of bohemian artists and intellectuals, free love and birth control advocates, individualist naturists nudists as in anarcho-naturism, freethought and anti-clerical activists as well as young anarchist outlaws in what came to be known as illegalism and individual reclamation, especially within European individualist anarchism and individualist anarchism in France. These authors and activists included Oscar Wilde, \u00c9mile Armand, Han Ryner, Henri Zisly, Renzo Novatore, Miguel Gim\u00e9nez Igualada, Adolf Brand and Lev Chernyi among others. In his important essay \"The Soul of Man Under Socialism\" from 1891, Wilde defended socialism as the way to guarantee individualism and so he saw that \"[w]ith the abolition of private property, then, we shall have true, beautiful, healthy Individualism. Nobody will waste his life in accumulating things, and the symbols for things. One will live. To live is the rarest thing in the world. Most people exist, that is all\". For anarchist historian George Woodcock, \"Wilde's aim in \"The Soul of Man Under Socialism\" is to seek the society most favorable to the artist.\u00a0[...] for Wilde art is the supreme end, containing within itself enlightenment and regeneration, to which all else in society must be subordinated.\u00a0[...] Wilde represents the anarchist as aesthete\". Woodcock finds that \"[t]he most ambitious contribution to literary anarchism during the 1890s was undoubtedly Oscar Wilde \"The Soul of Man Under Socialism\"\" and finds that it is influenced mainly by the thought of William Godwin.\nAutarchism.\nAutarchism promotes the principles of individualism, the moral ideology of individual liberty and self-reliance whilst rejecting compulsory government and supporting the elimination of government in favor of ruling oneself to the exclusion of rule by others. Robert LeFevre, recognized as an autarchist by anarcho-capitalist Murray Rothbard, distinguished autarchism from anarchy, whose economics he felt entailed interventions contrary to freedom in contrast to his own \"laissez-faire\" economics of the Austrian School.\nLiberalism.\nLiberalism is the belief in the importance of individual freedom. This belief is widely accepted in the United States, Europe, Australia and other Western nations, and was recognized as an important value by many Western philosophers throughout history, in particular since the Enlightenment. It is often rejected by collectivist ideas such as in Abrahamic or Confucian societies, although Taoists were and are known to be individualists. The Roman Emperor Marcus Aurelius wrote praising \"the idea of a polity administered with regard to equal rights and equal freedom of speech, and the idea of a kingly government which respects most of all the freedom of the governed\".\nLiberalism has its roots in the Age of Enlightenment and rejects many foundational assumptions that dominated most earlier theories of government, such as the Divine Right of Kings, hereditary status, and established religion. John Locke and Montesquieu are often credited with the philosophical foundations of classical liberalism, a political ideology inspired by the broader liberal movement. Locke wrote that \"no one ought to harm another in his life, health, liberty, or possessions.\"\nIn the 17th century, liberal ideas began to influence European governments in nations such as the Netherlands, Switzerland, England and Poland, but they were strongly opposed, often by armed might, by those who favored absolute monarchy and established religion. In the 18th century, the first modern liberal state was founded without a monarch or a hereditary aristocracy in the United States of America. The US Declaration of Independence includes the words which echo Locke that \"all men are created equal; that they are endowed by their Creator with certain unalienable rights; that among these are life, liberty, and the pursuit of happiness; that to insure these rights, governments are instituted among men, deriving their just powers from the consent of the governed.\"\nLiberalism comes in many forms. According to John N. Gray, the essence of liberalism is toleration of different beliefs and of different ideas as to what constitutes a good life.\nPhilosophical individualism.\nEgoist anarchism.\nEgoist anarchism is a school of anarchist thought that originated in the philosophy of Max Stirner, a 19th-century Hegelian philosopher whose \"name appears with familiar regularity in historically orientated surveys of anarchist thought as one of the earliest and best-known exponents of individualist anarchism.\" According to Stirner, the only limitation on the rights of the individual is their power to obtain what they desire, without regard for God, state, or morality. Stirner advocated self-assertion and foresaw unions of egoists, non-systematic associations continually renewed by all parties' support through an act of will which Stirner proposed as a form of organisation in place of the state.\nEgoist anarchists argue that egoism will foster genuine and spontaneous union between individuals. Egoism has inspired many interpretations of Stirner's philosophy, but it has also gone beyond Stirner within anarchism. It was re-discovered and promoted by German philosophical anarchist and LGBT activist John Henry Mackay. John Beverley Robinson wrote an essay called \"Egoism\" in which he states that \"Modern egoism, as propounded by Stirner and Nietzsche, and expounded by Ibsen, Shaw and others, is all these; but it is more. It is the realization by the individual that they are an individual; that, as far as they are concerned, they are the only individual.\" Stirner and Nietzsche, who exerted influence on anarchism despite its opposition, were frequently compared by French \"literary anarchists\" and anarchist interpretations of Nietzschean ideas appear to have also been influential in the United States.\nEthical egoism.\nEthical egoism, also called simply egoism, is the normative ethical position that moral agents ought to do what is in their own self-interest. It differs from psychological egoism, which claims that people \"do\" only act in their self-interest. Ethical egoism also differs from rational egoism which holds merely that it is rational to act in one's self-interest. However, these doctrines may occasionally be combined with ethical egoism.\nEthical egoism contrasts with ethical altruism, which holds that moral agents have an obligation to help and serve others. Egoism and altruism both contrast with ethical utilitarianism, which holds that a moral agent should treat one's self (also known as the subject) with no higher regard than one has for others (as egoism does, by elevating self-interests and \"the self\" to a status not granted to others), but that one also should not (as altruism does) sacrifice one's own interests to help others' interests, so long as one's own interests (i.e. one's own desires or well-being) are substantially-equivalent to the others' interests and well-being. Egoism, utilitarianism, and altruism are all forms of consequentialism, but egoism and altruism contrast with utilitarianism, in that egoism and altruism are both agent-focused forms of consequentialism (i.e. subject-focused or subjective), but utilitarianism is called agent-neutral (i.e. objective and impartial) as it does not treat the subject's (i.e. the self's, i.e. the moral \"agent's\") own interests as being more or less important than if the same interests, desires, or well-being were anyone else's.\nEthical egoism does not require moral agents to harm the interests and well-being of others when making moral deliberation, e.g. what is in an agent's self-interest may be incidentally detrimental, beneficial, or neutral in its effect on others. Individualism allows for others' interest and well-being to be disregarded or not as long as what is chosen is efficacious in satisfying the self-interest of the agent. Nor does ethical egoism necessarily entail that in pursuing self-interest one ought always to do what one wants to do, e.g. in the long term the fulfilment of short-term desires may prove detrimental to the self. Fleeting pleasance then takes a back seat to protracted eudaemonia. In the words of James Rachels, \"[e]thical egoism [...] endorses selfishness, but it doesn't endorse foolishness.\"\nEthical egoism is sometimes the philosophical basis for support of libertarianism or individualist anarchism as in Max Stirner, although these can also be based on altruistic motivations. These are political positions based partly on a belief that individuals should not coercively prevent others from exercising freedom of action.\nExistentialism.\nExistentialism is a term applied to the work of a number of 19th- and 20th-century philosophers who generally held, despite profound doctrinal differences, that the focus of philosophical thought should be to deal with the conditions of existence of the individual person and their emotions, actions, responsibilities, and thoughts. The early 19th century philosopher S\u00f8ren Kierkegaard, posthumously regarded as the father of existentialism, maintained that the individual solely has the responsibilities of giving one's own life meaning and living that life passionately and sincerely, in spite of many existential obstacles and distractions including despair, angst, absurdity, alienation and boredom.\nSubsequent existential philosophers retain the emphasis on the individual, but differ in varying degrees on how one achieves and what constitutes a fulfilling life, what obstacles must be overcome, and what external and internal factors are involved, including the potential consequences of the existence or non-existence of God. Many existentialists have also regarded traditional systematic or academic philosophy in both style and content as too abstract and remote from concrete human experience. Existentialism became fashionable after World War II as a way to reassert the importance of human individuality and freedom.\nNietzsche's concept of the superman is closely related to the idea of individualism and the pursuit of one's own unique path and potential.\nFreethought.\nFreethought holds that individuals should not accept ideas proposed as truth without recourse to knowledge and reason. Thus, freethinkers strive to build their opinions on the basis of facts, scientific inquiry and logical principles, independent of any logical fallacies or intellectually limiting effects of authority, confirmation bias, cognitive bias, conventional wisdom, popular culture, prejudice, sectarianism, tradition, urban legend and all other dogmas. Regarding religion, freethinkers hold that there is insufficient evidence to scientifically validate the existence of supernatural phenomena.\nHumanism.\nHumanism is a perspective common to a wide range of ethical stances that attaches importance to human dignity, concerns, and capabilities, particularly rationality. Although the word has many senses, its meaning comes into focus when contrasted to the supernatural or to appeals to authority. Since the 19th century, humanism has been associated with an anti-clericalism inherited from the 18th-century Enlightenment \"philosophes\". 21st century Humanism tends to strongly endorse human rights, including reproductive rights, gender equality, social justice, and the separation of church and state. The term covers organized non-theistic religions, secular humanism, and a humanistic life stance.\nHedonism.\nPhilosophical hedonism is a meta-ethical theory of value which argues that pleasure is the only intrinsic good and pain is the only intrinsic bad. The basic idea behind hedonistic thought is that pleasure (an umbrella term for all inherently likable emotions) is the only thing that is good in and of itself or by its very nature. This implies evaluating the moral worth of character or behavior according to the extent that the pleasure it produces exceeds the pain it entails.\nLibertinism.\nA libertine is one devoid of most moral restraints, which are seen as unnecessary or undesirable, especially one who ignores or even spurns accepted morals and forms of behaviour sanctified by the larger society. Libertines place value on physical pleasures, meaning those experienced through the senses. As a philosophy, libertinism gained new-found adherents in the 17th, 18th, and 19th centuries, particularly in France and Great Britain. Notable among these were John Wilmot, 2nd Earl of Rochester and the Marquis de Sade. During the Baroque era in France, there existed a freethinking circle of philosophers and intellectuals who were collectively known as \"libertinage \u00e9rudit\" and which included Gabriel Naud\u00e9, \u00c9lie Diodati and Fran\u00e7ois de La Mothe Le Vayer. The critic Vivian de Sola Pinto linked John Wilmot, 2nd Earl of Rochester's libertinism to Hobbesian materialism.\nObjectivism.\nObjectivism is a system of philosophy created by philosopher and novelist Ayn Rand which holds that reality exists independent of consciousness; human beings gain knowledge rationally from perception through the process of concept formation and inductive and deductive logic; the moral purpose of one's life is the pursuit of one's own happiness or rational self-interest. Rand thinks the only social system consistent with this morality is full respect for individual rights, embodied in pure \"laissez-faire\" capitalism; and the role of art in human life is to transform man's widest metaphysical ideas, by selective reproduction of reality, into a physical form\u00a0\u2013 a work of art\u00a0\u2013 that he can comprehend and to which he can respond emotionally. Objectivism celebrates man as his own hero, \"with his own happiness as the moral purpose of his life, with productive achievement as his noblest activity, and reason as his only absolute.\"\nPhilosophical anarchism.\nPhilosophical anarchism is an anarchist school of thought which contends that the state lacks moral legitimacy. In contrast to revolutionary anarchism, philosophical anarchism does not advocate violent revolution to eliminate it but advocates peaceful evolution to superate it. Although philosophical anarchism does not necessarily imply any action or desire for the elimination of the state, philosophical anarchists do not believe that they have an obligation or duty to obey the state, or conversely that the state has a right to command.\nPhilosophical anarchism is a component especially of individualist anarchism. Philosophical anarchists of historical note include Mohandas Gandhi, William Godwin, Pierre-Joseph Proudhon, Max Stirner, Benjamin Tucker and Henry David Thoreau. Contemporary philosophical anarchists include A. John Simmons and Robert Paul Wolff.\nSubjectivism.\nSubjectivism is a philosophical tenet that accords primacy to subjective experience as fundamental of all measure and law. In extreme forms such as solipsism, it may hold that the nature and existence of every object depends solely on someone's subjective awareness of it. In the proposition 5.632 of the \"Tractatus Logico-Philosophicus\", Ludwig Wittgenstein wrote: \"The subject doesn't belong to the world, but it is a limit of the world\". Metaphysical subjectivism is the theory that reality is what we perceive to be real, and that there is no underlying true reality that exists independently of perception. One can also hold that it is consciousness rather than perception that is reality (subjective idealism). In probability, a subjectivism stands for the belief that probabilities are simply degrees-of-belief by rational agents in a certain proposition and which have no objective reality in and of themselves.\nEthical subjectivism stands in opposition to moral realism, which claims that moral propositions refer to objective facts, independent of human opinion; to error theory, which denies that any moral propositions are true in any sense; and to non-cognitivism, which denies that moral sentences express propositions at all. The most common forms of ethical subjectivism are also forms of moral relativism, with moral standards held to be relative to each culture or society, i.e. cultural relativism, or even to every individual. The latter view, as put forward by Protagoras, holds that there are as many distinct scales of good and evil as there are subjects in the world. Moral subjectivism is that species of moral relativism that relativizes moral value to the individual subject.\nHorst Matthai Quelle was a Spanish-language German anarchist philosopher influenced by Max Stirner. Quelle argued that since the individual gives form to the world, he is those objects, the others and the whole universe. One of his main views was a \"theory of infinite worlds\" which for him was developed by pre-socratic philosophers.\nSolipsism.\nSolipsism is the philosophical idea that only one's own mind is sure to exist. The term comes from Latin \"solus\" (\"alone\") and \"ipse\" (\"self\"). Solipsism as an epistemological position holds that knowledge of anything outside one's own mind is unsure. The external world and other minds cannot be known, and might not exist outside the mind. As a metaphysical position, solipsism goes further to the conclusion that the world and other minds do not exist. Solipsism is the only epistemological position that, by its own postulate, is both irrefutable and yet indefensible in the same manner. Although the number of individuals sincerely espousing solipsism has been small, it is not uncommon for one philosopher to accuse another's arguments of entailing solipsism as an unwanted consequence, in a kind of reductio ad absurdum. In the history of philosophy, solipsism has served as a skeptical hypothesis.\nEconomic individualism.\nThe doctrine of economic individualism holds that each individual should be allowed autonomy in making their own economic decisions as opposed to those decisions being made by the community, the corporation or the state for him or her.\nClassical liberalism.\nLiberalism is a political ideology that developed in the 19th century in the Americas, England, France and Western Europe. It followed earlier forms of liberalism in its commitment to personal freedom and popular government, but differed from earlier forms of liberalism in its commitment to classical economics and free markets.\nNotable liberals in the 19th century include Jean-Baptiste Say, Thomas Malthus and David Ricardo. Classical liberalism, sometimes also used as a label to refer to all forms of liberalism before the 20th century, was revived in the 20th century by Ludwig von Mises and Friedrich Hayek and further developed by Milton Friedman, Robert Nozick, Loren Lomasky and Jan Narveson.\nLibertarianism.\nLibertarianism upholds liberty as a core principle. Libertarians seek to maximize autonomy and political freedom, emphasizing free association, freedom of choice, individualism and voluntary association. Libertarianism shares a skepticism of authority and state power, but libertarians diverge on the scope of their opposition to existing economic and political systems. Various schools of libertarian thought offer a range of views regarding the legitimate functions of state and private power, often calling for the restriction or dissolution of coercive social institutions. Different categorizations have been used to distinguish various forms of libertarianism. This is done to distinguish libertarian views on the nature of property and capital, usually along left\u2013right or socialist\u2013capitalist lines.\nLeft-libertarianism.\nLeft-libertarianism represents several related yet distinct approaches to politics, society, culture and political and social theory which stress both individual and political freedom alongside social justice. Unlike right-libertarians, left-libertarians believe that neither claiming nor mixing one's labor with natural resources is enough to generate full private property rights, and maintain that natural resources (land, oil, gold, trees) ought to be held in some egalitarian manner, either unowned or owned collectively. Those left-libertarians who support property do so under different property norms and theories, or under the condition that recompense is offered to the local or global community.\nRelated terms include \"egalitarian libertarianism\", \"left-wing libertarianism\", \"libertarianism\", \"libertarian socialism\", \"social libertarianism\" and \"socialist libertarianism\". Left-libertarianism can refer generally to these related and overlapping schools of thought:\nLibertarian socialism, sometimes dubbed left-libertarianism and socialist libertarianism, is an anti-authoritarian, anti-statist and libertarian tradition within the socialist movement that rejects the state socialist conception of socialism as a statist form where the state retains centralized control of the economy. Libertarian socialists criticize wage slavery relationships within the workplace, emphasizing workers' self-management of the workplace and decentralized structures of political organization.\nLibertarian socialism asserts that a society based on freedom and justice can be achieved through abolishing authoritarian institutions that control certain means of production and subordinate the majority to an owning class or political and economic elite. Libertarian socialists advocate for decentralized structures based on direct democracy and federal or confederal associations such as libertarian municipalism, citizens' assemblies, trade unions and workers' councils.\nAll of this is generally done within a general call for liberty and free association through the identification, criticism and practical dismantling of illegitimate authority in all aspects of human life. Within the larger socialist movement, libertarian socialism seeks to distinguish itself from Leninism and social democracy.\nPast and present currents and movements commonly described as libertarian socialist include anarchism (especially anarchist schools of thought such as anarcho-communism, anarcho-syndicalism, collectivist anarchism, green anarchism, individualist anarchism, mutualism, and social anarchism) as well as communalism, some forms of democratic socialism, guild socialism, libertarian Marxism (autonomism, council communism, left communism, and Luxemburgism, among others), participism, revolutionary syndicalism and some versions of utopian socialism.\nRight-libertarianism.\nRight-libertarianism represents either non-collectivist forms of libertarianism or a variety of different libertarian views that scholars label to the right of libertarianism such as libertarian conservatism. Related terms include \"conservative libertarianism\", \"libertarian capitalism\" and \"right-wing libertarianism\". In the mid-20th century, right-libertarian ideologies such as anarcho-capitalism and minarchism co-opted the term \"libertarian\" to advocate \"laissez-faire\" capitalism and strong private property rights such as in land, infrastructure and natural resources. The latter is the dominant form of libertarianism in the United States, where it advocates civil liberties, natural law, free-market capitalism and a major reversal of the modern welfare state.\nMutualism.\nWith regard to economic questions within individualist socialist schools such as individualist anarchism, there are adherents to mutualism (Pierre-Joseph Proudhon, \u00c9mile Armand and early Benjamin Tucker); natural rights positions (early Benjamin Tucker, Lysander Spooner and Josiah Warren); and egoistic disrespect for \"ghosts\" such as private property and markets (Max Stirner, John Henry Mackay, Lev Chernyi, later Benjamin Tucker, Renzo Novatore and illegalism). Contemporary individualist anarchist Kevin Carson characterizes American individualist anarchism saying that \"[u]nlike the rest of the socialist movement, the individualist anarchists believed that the natural wage of labor in a free market was its product, and that economic exploitation could only take place when capitalists and landlords harnessed the power of the state in their interests. Thus, individualist anarchism was an alternative both to the increasing statism of the mainstream socialist movement, and to a classical liberal movement that was moving toward a mere apologetic for the power of big business.\"\nMutualism is an anarchist school of thought which can be traced to the writings of Pierre-Joseph Proudhon, who envisioned a socialist society where each person possess a means of production, either individually or collectively, with trade representing equivalent amounts of labor in the free market. Integral to the scheme was the establishment of a mutual-credit bank which would lend to producers at a minimal interest rate only high enough to cover the costs of administration. Mutualism is based on a labor theory of value which holds that when labor or its product is sold, it ought to receive goods or services in exchange embodying \"the amount of labor necessary to produce an article of exactly similar and equal utility\" and that receiving anything less would be considered exploitation, theft of labor, or usury.\nCriticisms.\nThe Greek philosopher Plato emphasized that individuals must adhere to laws and perform duties while declining to grant individuals rights to limit or reject state interference in their lives.\nGerman philosopher Georg Wilhelm Friedrich Hegel criticized individualism by claiming that human self-consciousness relies on recognition from others, therefore embracing a holistic view and rejecting the idea of the world as a collection of atomized individuals.\nFascists believe that the liberal emphasis on individual freedom produces national divisiveness.\nPope Francis criticised a \"me\"-centred form of individualism in his 2015 encyclical letter \"Laudato si\"':&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Men and women of our postmodern world run the risk of rampant individualism, and many problems of society are connected with today's self-centred culture of instant gratification.As an example he comments on parents who \"can be prone to impulsive and wasteful consumption, which then affects their children who find it increasingly difficult to acquire a home of their own and build a family.\"\nOther views.\nAs creative independent lifestyle.\nThe anarchist writer and bohemian Oscar Wilde wrote in his famous essay \"The Soul of Man under Socialism\" that \"Art is individualism, and individualism is a disturbing and disintegrating force. There lies its immense value. For what it seeks is to disturb monotony of type, slavery of custom, tyranny of habit, and the reduction of man to the level of a machine.\" For anarchist historian George Woodcock, \"Wilde's aim in \"The Soul of Man under Socialism\" is to seek the society most favorable to the artist, [...] for Wilde art is the supreme end, containing within itself enlightenment and regeneration, to which all else in society must be subordinated. [...] Wilde represents the anarchist as aesthete.\" In this way, \"individualism\" has been used to denote a personality with a strong tendency towards self-creation and experimentation as opposed to tradition or popular mass opinions and behaviors.\nAnarchist writer Murray Bookchin describes a lot of individualist anarchists as people who \"expressed their opposition in uniquely personal forms, especially in fiery tracts, outrageous behavior, and aberrant lifestyles in the cultural ghettos of fin de si\u00e8cle New York, Paris, and London. As a credo, individualist anarchism remained largely a bohemian lifestyle, most conspicuous in its demands for sexual freedom ('free love') and enamored of innovations in art, behavior, and clothing.\"\nIn relation to this view of individuality, French individualist anarchist \u00c9mile Armand advocated egoistical denial of social conventions and dogmas to live in accord to one's own ways and desires in daily life since he emphasized anarchism as a way of life and practice. In this way, he opined that \"the anarchist individualist tends to reproduce himself, to perpetuate his spirit in other individuals who will share his views and who will make it possible for a state of affairs to be established from which authoritarianism has been banished. It is this desire, this will, not only to live, but also to reproduce oneself, which we shall call 'activity.'\"\nIn the book \"Imperfect Garden: The Legacy of Humanism\", humanist philosopher Tzvetan Todorov identifies individualism as an important current of socio-political thought within modernity and as examples of it he mentions Michel de Montaigne, Fran\u00e7ois de La Rochefoucauld, Marquis de Sade, and Charles Baudelaire. In La Rochefoucauld, he identifies a tendency similar to stoicism in which \"the honest person works his being in the manner of a sculptor who searches the liberation of the forms which are inside a block of marble, to extract the truth of that matter.\" In Baudelaire, he finds the dandy trait in which one searches to cultivate \"the idea of beauty within oneself, of satisfying one's passions of feeling and thinking.\"\nThe Russian-American poet Joseph Brodsky once wrote that \"[t]he surest defense against Evil is extreme individualism, originality of thinking, whimsicality, even\u00a0\u2013 if you will\u00a0\u2013 eccentricity. That is, something that can't be feigned, faked, imitated; something even a seasoned imposter couldn't be happy with.\" Ralph Waldo Emerson famously declared that \"[w]hoso would be a man must be a nonconformist\"\u00a0\u2013 a point of view developed at length in both the life and work of Henry David Thoreau. Equally memorable and influential on Walt Whitman is Emerson's idea that \"a foolish consistency is the hobgoblin of small minds, adored by little statesmen and philosophers and divines\". Emerson opposed on principle the reliance on civil and religious social structures precisely because through them the individual approaches the divine second-hand, mediated by the once original experience of a genius from another age. According to Emerson, \"[an institution is the lengthened shadow of one man.\" To achieve this original relation, Emerson stated that one must \"[i]nsist on one's self; never imitate\", for if the relationship is secondary the connection is lost.\nReligion.\nPeople in Western countries tend to be more individualistic than communitarian. The authors of one study proposed that this difference is due in part to the influence of the Catholic Church in the Middle Ages. They pointed specifically to its bans on incest, cousin marriage, adoption, and remarriage, and its promotion of the nuclear family over the extended family.\nThe Catholic Church teaches \"if we pray the Our Father sincerely, we leave individualism behind, because the love that we receive frees us ... our divisions and oppositions have to be overcome\". Many Catholics have believed Martin Luther and the Protestant Reformation were sources of individualism.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "15187", "revid": "20483999", "url": "https://en.wikipedia.org/wiki?curid=15187", "title": "In vivo", "text": "Process of testing biological interventions on whole, living organisms\nStudies that are in vivo (Latin for \"within the living\"; often not italicized in English) are those in which the effects of various biological entities are tested on whole, living organisms or cells, usually animals, including humans, and plants, as opposed to a tissue extract or dead organism.\nExamples of investigations \"in vivo\" include: the pathogenesis of disease by comparing the effects of bacterial infection with the effects of purified bacterial toxins; the development of non-antibiotics, antiviral drugs, and new drugs generally; and new surgical procedures. Consequently, animal testing and clinical trials are major elements of \"in vivo\" research. \"In vivo\" testing is often employed over \"in vitro\" because it is better suited for observing the overall effects of an experiment on a living subject. In drug discovery, for example, verification of efficacy \"in vivo\" is crucial, because \"in vitro\" assays can sometimes yield misleading results with drug candidate molecules that are irrelevant \"in vivo\" (e.g., because such molecules cannot reach their site of \"in vivo\" action, for example as a result of rapid catabolism in the liver).\nThe English microbiologist Professor Harry Smith and his colleagues in the mid-1950s found that sterile filtrates of serum from animals infected with \"Bacillus anthracis\" were lethal for other animals, whereas extracts of culture fluid from the same organism grown \"in vitro\" were not. This discovery of anthrax toxin through the use of \"in vivo\" experiments had a major impact on studies of the pathogenesis of infectious disease.\nThe maxim \"in vivo veritas\" (\"in a living thing [there is] truth\") is a play on \"in vino veritas\", (\"in wine [there is] truth\"), a well-known proverb.\nLevels of closeness to the natural state.\nLatin phrases used to describe the closeness of a wet lab experiment setup to the natural state include:\nDifferent subfields of biology have a tendency to use each word differently. Notable variations from the above include:\nMethods of use.\nAccording to Christopher Lipinski and Andrew Hopkins, \"Whether the aim is to discover drugs or to gain knowledge of biological systems, the nature and properties of a chemical tool cannot be considered independently of the system it is to be tested in. Compounds that bind to isolated recombinant proteins are one thing; chemical tools that can perturb cell function another; and pharmacological agents that can be tolerated by a live organism and perturb its systems are yet another. If it were simple to ascertain the properties required to develop a lead discovered \"in vitro\" to one that is active \"in vivo\", drug discovery would be as reliable as drug manufacturing.\" Studies on \"In vivo\" behavior, determined the formulations of set specific drugs and their habits in a Biorelevant (or Biological relevance) medium.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "15188", "revid": "51020302", "url": "https://en.wikipedia.org/wiki?curid=15188", "title": "In vitro", "text": "Latin term meaning outside a natural biological environment\nIn vitro (meaning \"in glass\", or \"in the glass\") studies are performed with cells or biological molecules outside their normal biological context. Colloquially called \"test-tube experiments\", these studies in biology and its subdisciplines are traditionally done in labware such as test tubes, flasks, Petri dishes, and microtiter plates. Studies conducted using components of an organism that have been isolated from their usual biological surroundings permit a more detailed or more convenient analysis than can be done with whole organisms; however, results obtained from \"in vitro\" experiments may not fully or accurately predict the effects on a whole organism. In contrast to \"in vitro\" experiments, \"in vivo\" studies are those conducted in living organisms, including humans, known as clinical trials, and whole plants.\nDefinition.\n\"In vitro\" (Latin for \"in glass\"; often not italicized in English usage) studies are conducted using components of an organism that have been isolated from their usual biological surroundings. As the name suggests, \"in vitro\" experiments, colloquially \"test-tube experiments\", are traditionally done in glass labware, using test tubes, flasks, Petri dishes, etc.\nThe exact scope of \"in vitro\" depends on what is considered to be \"in vitro\" (experiments done on whole living beings), and in turn what is considered to be a \"whole\" living being:\nExamples.\nAs described before, \"in vitro\" can encompass work on living and non-living systems of a wide range of complexities.\nAdvantages.\n\"In vitro\" studies permit a species-specific, simpler, more convenient, and more detailed analysis than can be done with the whole organism. Just as studies in whole animals more and more replace human trials, so are \"in vitro\" studies replacing studies in whole animals.\nSimplicity.\nLiving organisms are extremely complex functional systems that are made up of, at a minimum, many tens of thousands of genes, protein molecules, RNA molecules, small organic compounds, inorganic ions, and complexes in an environment that is spatially organized by membranes, and in the case of multicellular organisms, organ systems. These myriad components interact with each other and with their environment in a way that processes food, removes waste, moves components to the correct location, and is responsive to signalling molecules, other organisms, light, sound, heat, taste, touch, and balance.\nThis complexity makes it difficult to identify the interactions between individual components and to explore their basic biological functions. \"In vitro\" work simplifies the system under study, so the investigator can focus on a small number of components.\nFor example, the identity of proteins of the immune system (e.g. antibodies), and the mechanism by which they recognize and bind to foreign antigens would remain very obscure if not for the extensive use of \"in vitro\" work to isolate the proteins, identify the cells and genes that produce them, study the physical properties of their interaction with antigens, and identify how those interactions lead to cellular signals that activate other components of the immune system.\nSpecies specificity.\nAnother advantage of \"in vitro\" methods is that human cells can be studied without \"extrapolation\" from an experimental animal's cellular response.\nConvenience, automation.\n\"In vitro\" methods can be miniaturized and automated, yielding high-throughput screening methods for testing molecules in pharmacology or toxicology.\nDisadvantages.\nThe primary disadvantage of \"in vitro\" experimental studies is that it may be challenging to extrapolate from the results of \"in vitro\" work back to the biology of the intact organism. Investigators doing \"in vitro\" work must be careful to avoid over-interpretation of their results, which can lead to erroneous conclusions about organismal and systems biology.\nFor example, scientists developing a new viral drug to treat an infection with a pathogenic virus (e.g., HIV-1) may find that a candidate drug functions to prevent viral replication in an \"in vitro\" setting (typically cell culture). However, before this drug is used in the clinic, it must progress through a series of \"in vivo\" trials to determine if it is safe and effective in intact organisms (typically small animals, primates, and humans in succession). Typically, most candidate drugs that are effective \"in vitro\" prove to be ineffective \"in vivo\" because of issues associated with delivery of the drug to the affected tissues, toxicity towards essential parts of the organism that were not represented in the initial \"in vitro\" studies, or other issues.\n\"In vitro\" test batteries.\nA method which could help decrease animal testing is the use of \"in vitro\" batteries, where several \"in vitro\" assays are compiled to cover multiple endpoints. Within developmental neurotoxicity and reproductive toxicity there are hopes for test batteries to become easy screening methods for prioritization for which chemicals to be risk assessed and in which order. Within ecotoxicology \"in vitro\" test batteries are already in use for regulatory purpose and for toxicological evaluation of chemicals. \"In vitro\" tests can also be combined with \"in vivo\" testing to make a \"in vitro in vivo\" test battery, for example for pharmaceutical testing.\n\"In vitro\" to \"in vivo\" extrapolation.\nResults obtained from \"in vitro\" experiments cannot usually be transposed, as is, to predict the reaction of an entire organism \"in vivo\". Building a consistent and reliable extrapolation procedure from \"in vitro\" results to \"in vivo\" is therefore extremely important. Solutions include:\nThese two approaches are not incompatible; better \"in vitro\" systems provide better data to mathematical models. However, increasingly sophisticated \"in vitro\" experiments collect increasingly numerous, complex, and challenging data to integrate. Mathematical models, such as systems biology models, are much needed here.\nExtrapolating in pharmacology.\nIn pharmacology, IVIVE can be used to approximate pharmacokinetics (PK) or pharmacodynamics (PD). Since the timing and intensity of effects on a given target depend on the concentration time course of candidate drug (parent molecule or metabolites) at that target site, \"in vivo\" tissue and organ sensitivities can be completely different or even inverse of those observed on cells cultured and exposed \"in vitro\". That indicates that extrapolating effects observed \"in vitro\" needs a quantitative model of \"in vivo\" PK. Physiologically based PK (PBPK) models are generally accepted to be central to the extrapolations.\nIn the case of early effects or those without intercellular communications, the same cellular exposure concentration is assumed to cause the same effects, both qualitatively and quantitatively, \"in vitro\" and \"in vivo\". In these conditions, developing a simple PD model of the dose\u2013response relationship observed \"in vitro\", and transposing it without changes to predict \"in vivo\" effects is not enough.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "15189", "revid": "27015025", "url": "https://en.wikipedia.org/wiki?curid=15189", "title": "IEEE 754-1985", "text": "First edition of the IEEE 754 floating-point standard\nIEEE 754-1985 is a historic industry standard for representing floating-point numbers in computers, officially adopted in 1985 and superseded in 2008 by IEEE 754-2008, and then again in 2019 by minor revision IEEE 754-2019. During its 23 years, it was the most widely used format for floating-point computation. It was implemented in software, in the form of floating-point libraries, and in hardware, in the instructions of many CPUs and FPUs. The first integrated circuit to implement the draft of what was to become IEEE\u00a0754-1985 was the Intel 8087.\nIEEE 754-1985 represents numbers in binary, providing definitions for four levels of precision, of which the two most commonly used are: \nThe standard also defines representations for positive and negative infinity, a \"negative zero\", five exceptions to handle invalid results like division by zero, special values called NaNs for representing those exceptions, denormal numbers to represent numbers smaller than shown above, and four rounding modes.\nRepresentation of numbers.\nFloating-point numbers in IEEE\u00a0754 format consist of three fields: a sign bit, a biased exponent, and a fraction. The following example illustrates the meaning of each.\nThe decimal number 0.1562510 represented in binary is 0.001012 (that is, 1/8 + 1/32). (Subscripts indicate the number base.) Analogous to scientific notation, where numbers are written to have a single non-zero digit to the left of the decimal point, we rewrite this number so it has a single 1 bit to the left of the \"binary point\". We simply multiply by the appropriate power of 2 to compensate for shifting the bits left by three positions:\n formula_1\nNow we can read off the fraction and the exponent: the fraction is .012 and the exponent is \u22123.\nAs illustrated in the pictures, the three fields in the IEEE\u00a0754 representation of this number are:\n \"sign\" = 0, because the number is positive. (1 indicates negative.)\n \"biased exponent\" = \u22123 + the \"bias\". In single precision, the bias is 127, so in this example the biased exponent is 124; in double precision, the bias is 1023, so the biased exponent in this example is 1020.\n \"fraction\" = .01000\u20262.\nIEEE\u00a0754 adds a bias to the exponent so that numbers can in many cases be compared conveniently by the same hardware that compares signed 2's-complement integers. Using a biased exponent, the lesser of two positive floating-point numbers will come out \"less than\" the greater following the same ordering as for sign and magnitude integers. If two floating-point numbers have different signs, the sign-and-magnitude comparison also works with biased exponents. However, if both biased-exponent floating-point numbers are negative, then the ordering must be reversed. If the exponent were represented as, say, a 2's-complement number, comparison to see which of two numbers is greater would not be as convenient.\nThe leading 1 bit is omitted since all numbers except zero start with a leading 1; the leading 1 is implicit and doesn't actually need to be stored which gives an extra bit of precision for \"free.\"\nZero.\nThe number zero is represented specially:\n \"sign\" = 0 for positive zero, 1 for negative zero.\n \"biased exponent\" = 0.\n \"fraction\" = 0.\nDenormalized numbers.\nThe number representations described above are called \"normalized,\" meaning that the implicit leading binary digit is a 1. To reduce the loss of precision when an underflow occurs, IEEE\u00a0754 includes the ability to represent fractions smaller than are possible in the normalized representation, by making the implicit leading digit a 0. Such numbers are called denormal. They don't include as many significant digits as a normalized number, but they enable a gradual loss of precision when the result of an operation is not exactly zero but is too close to zero to be represented by a normalized number.\nA denormal number is represented with a biased exponent of all 0 bits, which represents an exponent of \u2212126 in single precision (not \u2212127), or \u22121022 in double precision (not \u22121023). In contrast, the smallest biased exponent representing a normal number is 1 (see examples below).\nRepresentation of non-numbers.\nThe biased-exponent field is filled with all 1 bits to indicate either infinity or an invalid result of a computation.\nPositive and negative infinity.\nPositive and negative infinity are represented thus:\n \"sign\" = 0 for positive infinity, 1 for negative infinity.\n \"biased exponent\" = all 1 bits.\n \"fraction\" = all 0 bits.\nNaN.\nSome operations of floating-point arithmetic are invalid, such as taking the square root of a negative number. The act of reaching an invalid result is called a floating-point \"exception.\" An exceptional result is represented by a special code called a NaN, for \"Not a Number\". All NaNs in IEEE\u00a0754-1985 have this format:\n \"sign\" = either 0 or 1.\n \"biased exponent\" = all 1 bits.\n \"fraction\" = anything except all 0 bits (since all 0 bits represents infinity).\nRange and precision.\nPrecision is defined as the minimum difference between two successive mantissa representations; thus it is a function only in the mantissa; while the gap is defined as the difference between two successive numbers.\nSingle precision.\nSingle-precision numbers occupy 32 bits. In single precision:\nSome example range and gap values for given exponents in single precision:\nAs an example, 16,777,217 cannot be encoded as a 32-bit float as it will be rounded to 16,777,216. However, all integers within the representable range that are a power of 2 can be stored in a 32-bit float without rounding.\nDouble precision.\nDouble-precision numbers occupy 64 bits. In double precision:\nSome example range and gap values for given exponents in double precision:\nExtended formats.\nThe standard also recommends extended format(s) to be used to perform internal computations at a higher precision than that required for the final result, to minimise round-off errors: the standard only specifies minimum precision and exponent requirements for such formats. The x87 80-bit extended format is the most commonly implemented extended format that meets these requirements.\nExamples.\nHere are some examples of single-precision IEEE 754 representations:\nComparing floating-point numbers.\nEvery possible bit combination is either a NaN or a number with a unique value in the affinely extended real number system with its associated order, except for the two combinations of bits for negative zero and positive zero, which sometimes require special attention (see below). The binary representation has the special property that, excluding NaNs, any two numbers can be compared as sign and magnitude integers (endianness issues apply). When comparing as 2's-complement integers: If the sign bits differ, the negative number precedes the positive number, so 2's complement gives the correct result (except that negative zero and positive zero should be considered equal). If both values are positive, the 2's complement comparison again gives the correct result. Otherwise (two negative numbers), the correct FP ordering is the opposite of the 2's complement ordering.\nRounding errors inherent to floating point calculations may limit the use of comparisons for checking the exact equality of results. Choosing an acceptable range is a complex topic. A common technique is to use a comparison epsilon value to perform approximate comparisons. Depending on how lenient the comparisons are, common values include codice_1 or codice_2 for single-precision, and codice_3 for double-precision. Another common technique is ULP, which checks what the difference is in the last place digits, effectively checking how many steps away the two values are.\nAlthough negative zero and positive zero are generally considered equal for comparison purposes, some programming language relational operators and similar constructs treat them as distinct. According to the Java Language Specification, comparison and equality operators treat them as equal, but codice_4 and codice_5 distinguish them (officially starting with Java version 1.1 but actually with 1.1.1), as do the comparison methods codice_6, codice_7 and even codice_8 of classes codice_9 and codice_10.\nRounding floating-point numbers.\nThe IEEE standard has four different rounding modes; the first is the default; the others are called \"directed roundings\".\nExtending the real numbers.\nThe IEEE standard employs (and extends) the affinely extended real number system, with separate positive and negative infinities. During drafting, there was a proposal for the standard to incorporate the projectively extended real number system, with a single unsigned infinity, by providing programmers with a mode selection option. In the interest of reducing the complexity of the final standard, the projective mode was dropped, however. The Intel 8087 and Intel 80287 floating point co-processors both support this projective mode.\nFunctions and predicates.\nStandard operations.\nThe following functions must be provided:\nHistory.\nIn 1976, Intel was starting the development of a floating-point coprocessor. Intel hoped to be able to sell a chip containing good implementations of all the operations found in the widely varying maths software libraries.\nJohn Palmer, who managed the project, believed the effort should be backed by a standard unifying floating point operations across disparate processors. He contacted William Kahan of the University of California, who had helped improve the accuracy of Hewlett-Packard's calculators. Kahan suggested that Intel use the floating point of Digital Equipment Corporation's (DEC) VAX. The first VAX, the VAX-11/780 had just come out in late 1977, and its floating point was highly regarded. However, seeking to market their chip to the broadest possible market, Intel wanted the best floating point possible, and Kahan went on to draw up specifications. Kahan initially recommended that the floating point base be decimal but the hardware design of the coprocessor was too far along to make that change.\nThe work within Intel worried other vendors, who set up a standardization effort to ensure a \"level playing field\". Kahan attended the second IEEE 754 standards working group meeting, held in November 1977. He subsequently received permission from Intel to put forward a draft proposal based on his work for their coprocessor; he was allowed to explain details of the format and its rationale, but not anything related to Intel's implementation architecture. The draft was co-written with Jerome Coonen and Harold Stone, and was initially known as the \"Kahan-Coonen-Stone proposal\" or \"K-C-S format\".\nAs an 8-bit exponent was not wide enough for some operations desired for double-precision numbers, e.g. to store the product of two 32-bit numbers, both Kahan's proposal and a counter-proposal by DEC therefore used 11 bits, like the time-tested 60-bit floating-point format of the CDC 6600 from 1965. Kahan's proposal also provided for infinities, which are useful when dealing with division-by-zero conditions; not-a-number values, which are useful when dealing with invalid operations; denormal numbers, which help mitigate problems caused by underflow; and a better balanced exponent bias, which can help avoid overflow and underflow when taking the reciprocal of a number.\nEven before it was approved, the draft standard had been implemented by a number of manufacturers. The Intel 8087, which was announced in 1980, was the first chip to implement the draft standard.\nIn 1980, the Intel 8087 chip was already released, but DEC remained opposed, to denormal numbers in particular, because of performance concerns and since it would give DEC a competitive advantage to standardise on DEC's format.\nThe arguments over gradual underflow lasted until 1981 when an expert hired by DEC to assess it sided against the dissenters. DEC had the study done in order to demonstrate that gradual underflow was a bad idea, but the study concluded the opposite, and DEC gave in. In 1985, the standard was ratified, but it had already become the de facto standard a year earlier, implemented by many manufacturers.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "15190", "revid": "910180", "url": "https://en.wikipedia.org/wiki?curid=15190", "title": "Intel 80186", "text": "16-bit microcontroller\nThe Intel 80186, also known as the iAPX 186, or just 186, is a microprocessor and microcontroller introduced in 1982. It is based on the Intel 8086 and, like it, has a 16-bit external data bus multiplexed with a 20-bit address bus. The 80188 is a variant with an 8-bit external data bus.\nDescription.\nThe 80186 series was designed to reduce the number of integrated circuits required. It included features such as clock generator, interrupt controller, timers, wait state generator, DMA channels, and external chip select lines. It was used in numerous embedded systems, as microcontrollers with external memory.\nThe initial clock rate of the 80186 was 6\u00a0MHz, but due to more hardware available for the microcode to use, especially for address calculation, many individual instructions completed in fewer clock cycles than on an 8086 at the same clock frequency. For instance, the common \"register+immediate\" addressing mode was significantly faster than on the 8086, especially when a memory location was both (one of) the operand(s) and the destination. Multiply and divide also showed great improvement, being several times as fast as on the original 8086, and multi-bit shifts were done almost four times as quickly as in the 8086.\nA few new instructions were introduced with the 80186 (referred to as the 8086-2 instruction set in some datasheets): \"enter\"/\"leave\" (replacing several instructions when handling stack frames), \"pusha\"/\"popa\" (push/pop all general registers), \"bound\" (check array index against bounds), and \"ins\"/\"outs\" (input/output of string). A useful \"immediate\" mode was added for the \"push\", \"imul\", and multi-bit shift instructions. These instructions were also included in the contemporary 80286 and in successor chips.\nVariants.\nThe (redesigned) CMOS version, 80C186, introduced DRAM refresh, a power-save mode, and a direct interface to the 80C187 floating-point numeric coprocessor. Intel second-sourced this microprocessor to Fujitsu Limited around 1985. Both packages for Intel 80186 version were available in 68-pin PLCC and PGA in sampling at third quarter of 1985. The 12.5\u00a0MHz Intel 80186-12 version using the 1.5\u00a0\u03bcm HMOS-III process for US$36 in quantities of 100. The 12.5\u00a0MHz Intel 80C186 version using the CHMOS III-E technology using approximately 90\u00a0mA under normal load and only 32\u00a0mA under power-save mode. It was available in 68-pin PLCC, CPGA, or CLCC package.\nThe M80C186 military version was available in 10 and 12\u00a0MHz versions. They met MIL-STD-883 Rev.\u00a0C and MIL-STD-1553 bus application standards. The 12\u00a0MHz CHMOS version consumes approximately 100\u00a0mA. The available packages were 68-pin CPGA and CQFP. The 10\u00a0MHz M80C186 PGA version was available for US$378 in 100-unit quantities.\nThe 80C186EB was a fully static design for the application-specific standard product using the 1\u00a0\u03bcm CHMOS IV technology. They were available in 3- and 5-volt versions with 84-lead PLCC and 80-lead EIAJ QFP packaging. It was also available for US$16.95 in 1,000-unit quantities.\nThe Intel 80C186EC contains 4 DMA channels, 2 interrupt controllers, 22 I/O which control two serial channels, and 4 timers. This version was available for US$17.70 in quantites of 1,000 units. This microcontroller only available in 5-volt version. Both Intel 80C186EC and 80C186EA contains three different power-management modes, which has idle, powerdown and powersave. The 80C186EA has both 5- and 3-volt versions.\nThe 80C186XL version was available up to 20\u00a0MHz, which is compatible with existing CMOS version of 80C186 that has 25% higher performance and 50% lower power consumption. This version used 1\u00a0\u03bcm CHMOS process technology. Both 80C186EA and 80C186XL were available for US$11.80 in quantities of 1,000 units.\n80188 series.\nThe 80188 variant, with an 8-bit external data bus was also available; this made it less expensive to connect to peripherals. The 16-bit registers and the one megabyte address range were unchanged, however. It had a throughput of 1\u00a0million instructions per second. Intel second sourced this microprocessor to Fujitsu Limited around 1985. Both packages of Intel 80188 version were available in 68-pin PLCC and PGA in sampling at third quarter of 1985. The available 80C188EB in fully static design for the application-specific standard product using the 1-micron CHMOS IV technology. They were available in 3- and 5-Volts version with 84-lead PLCC and 80-lead EIAJ QFP version. It was also available for US$15.15 in 1,000 unit quantities.\nThe 80188 series was generally intended for embedded systems, as microcontrollers with external memory. Therefore, to reduce the number of chips required, it included features such as clock generator, interrupt controller, timers, wait state generator, DMA channels, and external chip select lines.\nWhile the N80188 was compatible with the 8087 numeric co-processor, the 80C188 was not. It did not have the ESC control codes integrated.\nUses.\nIn personal computers.\nBecause the integrated hardware included in the 80186 was incompatible with the support chips chosen by IBM for the 8088-based IBM\u00a0PC released a few months earlier, the chip did not see wide success in the PC market. IBM chose the 80286 for its successor, the IBM\u00a0PC/AT, released in August 1984. Most other PC-compatible manufactures followed.\nRegardless, several notable personal computers used the 80186:\nIn addition to the above examples of stand-alone implementations of the 80186 for personal computers, there were at least two examples of \"add-in\" accelerator card implementations: the BBC Master 512, Acorn's plug-in for the BBC Master range of computers containing an 80186\u201310 with 512\u00a0KB of RAM, and the Orchid Technology PC Turbo 186, released in 1985. It was intended for use with the original Intel 8088-based IBM\u00a0PC (Model\u00a05150).\nOther devices.\nThe Intel 80186 and 80188 are often embedded in electronic devices that are not primarily computers. For example:\nEnd of life.\nOn March 30, 2006, Intel announced that production of the 80186 and 80188, along with the production of other processor models such as the 80386 and 80486, would cease at the end of September 2007. Pin- and instruction-compatible replacements might still be manufactured by various third-party sources, and FPGA versions are publicly available.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "15191", "revid": "19571773", "url": "https://en.wikipedia.org/wiki?curid=15191", "title": "Inquisition", "text": "System of tribunals enforcing Catholic orthodoxy\nAn inquisition was a Catholic judicial procedure in which ecclesiastical judges could initiate, investigate and try cases in their jurisdiction. Popularly the Inquisition became the name for various medieval and reformation-era state-organized tribunals whose aim was to combat heresy, apostasy, blasphemy, witchcraft, and customs considered to be deviant, using this judicial procedure. Violence, isolation, certain torture or the threat of its application, have been used by inquisitions to extract confessions and denunciations. \nInquisitions with the aim of combatting religious sedition (e.g. apostasy or heresy) had their start in the 12th-century Kingdom of France, particularly among the Cathars and the Waldensians. The inquisitorial courts from this time until the mid-15th century are together known as the Medieval Inquisition. Other banned groups investigated by medieval inquisitions, which primarily took place in France and Italy, include the Spiritual Franciscans, the Hussites, and the Beguines. Beginning in the 1250s, inquisitors were generally chosen from members of the Dominican Order, replacing the earlier practice of using local clergy as judges.\nInquisitions also expanded to other European countries, resulting in the Spanish Inquisition and the Portuguese Inquisition. The Spanish and Portuguese inquisitions often focused on the New Christians or \"Conversos\" (former Jews who converted to Christianity to avoid antisemitic regulations and persecution), the \"Marranos\" (people who were forced to abandon Judaism against their will by violence and threats of expulsion), and on the \"Moriscos\" (Muslims who had been forced to convert to Catholicism), as a result of suspicions that they had secretly maintained or reverted to their previous religions, as well as the fear of possible rebellions, as had occurred in previous times (such as the First and Second Morisco Rebellions). Spain and Portugal also operated inquisitorial courts not only in Europe, but also throughout their empires: the Goa Inquisition, the Peruvian Inquisition, and the Mexican Inquisition, among others. Inquisitions conducted in the Papal States were known as the Roman Inquisition.\nThe scope of the inquisitions grew significantly in response to the Protestant Reformation and the Catholic Counter-Reformation. In 1542, a putative governing institution, the Supreme Sacred Congregation of the Roman and Universal Inquisition was created. With the exception of the Papal States, ecclessiastical inquisition courts were abolished in the early 19th century, after the Napoleonic Wars in Europe and the Spanish American wars of independence in the Americas. The papal institution survived as part of the Roman Curia, although it underwent a series of name and focus changes, now part of the Dicastery for the Doctrine of the Faith.\nLegal Background.\nIn the high medieval period, various forms of \"ad hoc\" or non-evidence-based trials occurred: trial by ordeal (trial by combat, trial by fire, trial by water, etc.), and compurgation (character witnesses), especially in teutonic cultures. In tenth and eleventh centuries, attempts were made to re-establish safer aspects of Roman and Hebrew law following the discovery of major ancient Roman legal texts. By the late tenth century, the new University of Bologna was training lawyers in Roman legal jurisprudence, and other universities followed. \nAn inquisitorial procedure was adopted for capital crimes, first in ecclesiastical courts run by clergy as mandated by the Fourth Council of the Lateran (1215), and then progressively also in secular courts as well. (Many countries still retain an inquisitorial legal system, as distinct from e.g., an adversarial or arbitrated one.)\nIn the revived legal system, for capital crimes, circumstantial evidence was not enough to convict: the testimony of two or more witnesses was now necessary, which increased the necessity of obtaining a confession. This in turn promoted the uptake of threats and application of torture, akin to the \"enhanced interrogation techniques\" or the illegal \"third degree\" police techniques, to collaborate information for investigations for both secular and ecclesiastical courts.\nSecular and ecclesiastical legal theorists of the Late Middle Ages developed a variety of rules concerning when torture was used, how much, what it was unsafe for, who was allowed to do it, what medical supervision was necessary, etc. Because it belonged to the investigation phase, it was frequently not documented outside the Inquisition.\nHistorian Henry A. Kelly concludes that inquisition was \"a brilliant and much-needed innovation in trial procedure, instituted by the greatest lawyer-pope of the Middle Ages\" and that later \"abusive practices\" should be identified as a perversion of the original inquisitorial process.\nTerminology.\nInquisition.\nThe term \"inquisition\" comes from the Medieval Latin word , which described a court process based on Roman law, which came back into use during the Late Middle Ages. It was a new, less arbitrary form of trial that replaced the and process which required a denouncer or used an adversarial process, the most unjust being trial by ordeal and the secular Germanic trial by combat. \nToday, the English term \"Inquisition\" is popularly applied to any one of the regional tribunals or later national institutions that worked against heretics or other offenders against the canon law of the Catholic Church. Although the term \"Inquisition\" is usually applied to ecclesiastical courts of the Catholic Church, in the Middle Ages it properly referred to an organized judicial process.\nInquisitor.\nInquisitors 'were called such because they applied a judicial technique known as \"inquisitio\", which could be translated as \"inquiry\" or \"inquest\". \n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\"In this process, which was already widely used by secular rulers (Henry II used it extensively in England in the 12th century), an official inquirer called for information on a specific subject from anyone who felt he or she had something to offer.\"\u2014\u200a\n\"The Inquisition\" usually refers to specific regional tribunals authorized to concern themselves with the heretical behaviour of Catholic adherents or converts (including forced converts). \nAs with sedition inquisitions, heresy inquisitions were supposed to use the standard inquisition procedures: these included that the defendant must be informed of the charges, has a right to a lawyer, and a right of appeal (to the Pope). The inquisitor could only start a heresy proceeding if there was some broad public opinion of the \"infamy\" of the defendant (rather than a formal denunciation or accusation) to prevent fishing, or charging for private opinions. However, such inquisitions could proceed with minimal distraction by lawyers, the identities of witnesses were protected, tainted witnesses were allowed, and once found guilty of heresy there was no right to a lawyer. Inquisitors did not all follow these rules scrupulously, notably from the late 1300s: many inquisitors had theological, not legal, training.\nScope.\nTheoretically, inquisitions, as a church court, had no jurisdiction over Muslims and Jews as such. Despite several exceptions, like the infamous example of the Holy Child of La Guardia, the Inquisition was concerned mainly with the heretical behaviour of Catholic adherents or converts (including forced converts).\nControversy and revisionism.\nThe opening of Spanish and Roman archives over the last 50 years has caused some historians to revise their understanding of the Inquisition, some to the extent of viewing previous views as \"a body of legends and myths\". It has also been suggested that some instruments of torture, like \"the pear of anguish,\" were not invented until the 16th century or later. Some of these revisions from scholars may be due to their own subjective religion, the historic erasure of crimes committed by the church, or erasure of minority lives and voices. Many of the sources that discredit or undermine the torture are written by practicing Catholics. One example is Reverend Brian Van Hove, S.J., who suggests that the inquisition is overblown in popular imagination. Van Hove writes\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\"...secular historians now tend to speak of how fair the system actually was. They observe how many people were released because of technicalities in the law which withstood whim and abuse. They note how many opportunities the accused persons had to avoid further prosecution.\"\nHowever, this perspective fails to address that the majority of inquisitions led to torture, mass excommunications, and burnings which incited fear and submission in the general population, creating lasting effects on Europe. The majority of historical scholars continue to see the inquisition as an example of extremist religious leaders enforcing order and rooting out paganism through false accusations and inordinate violence.\nSentences.\nWhen a suspect was convicted of \"wilful, unrepentant\" heresy, canon law required the inquisitorial tribunal to hand the person over to secular authorities for final sentencing. A secular magistrate, the \"secular arm\", would then determine the penalty based on local law. Those local laws included proscriptions against certain religious crimes, and the punishments included death by burning in regions where the secular law equated persistent heresy with sedition. Thus the inquisitors generally knew the expected fate of anyone so remanded. The \"secular arm\" didn't have access to the trial record of the defendants, only declared and executed the sentences and was obliged to do so on pain of heresy and excommunication. \nWhile the notational purpose of the trial itself was for the salvation of the individual soul, allegedly by persuasion, according to the 1578 edition of the Directorium Inquisitorum (a standard manual for inquisitions) the penalties themselves were preventative not retributive, thought to spread an example by terror: \" \"... quoniam punitio non refertur primo &amp; per se in correctionem &amp; bonum eius qui punitur, sed in bonum publicum ut alij terreantur, &amp; a malis committendis avocentur\" (translation: \"... for punishment does not take place primarily and \"per se\" for the correction and good of the person punished, but for the public good in order that others may become terrified and weaned away from the evils they would commit\").\nStatistics.\nBeginning in the 19th century, historians have gradually compiled statistics drawn from the surviving court records, from which estimates have been calculated by adjusting the recorded number of convictions by the average rate of document loss for each time period. Gustav Henningsen and Jaime Contreras studied the records of the Spanish Inquisition, which list 44,674 cases of which 826 resulted in executions in person and 778 in effigy (i.e. a straw dummy was burned in place of the person). William Monter estimated there were 1000 executions in Spain between 1530\u20131630 and 250 between 1630 and 1730. Jean-Pierre Dedieu studied the records of Toledo's tribunal, which put 12,000 people on trial. For the period prior to 1530, Henry Kamen estimated there were about 2,000 executions in all of Spain's tribunals.\nOrigin.\nBefore the 12th century, the Catholic Church suppressed what they believed to be heresy, usually through a system of ecclesiastical proscription or imprisonment, but without using torture, and seldom resorting to executions. Such punishments were opposed by a number of clergymen and theologians, although some countries punished heresy with the death penalty. Pope Siricius, Ambrose of Milan, and Martin of Tours protested against the execution of Priscillian, largely as an undue interference in ecclesiastical discipline by a civil tribunal. Though widely viewed as a heretic, Priscillian was executed as a sorcerer. Ambrose refused to give any recognition to Ithacius of Ossonuba, \"not wishing to have anything to do with bishops who had sent heretics to their death\".\nIn the 12th century, to counter the spread of Catharism and other heresies, prosecution of heretics became more frequent. The Church charged councils composed of bishops and archbishops with establishing inquisitions (the Episcopal Inquisition). Pope Lucius III issued the bull \"Ad Abolendam\" (1184), which condemned heresy as contumacy toward ecclesiastical authority. The bull \"Vergentis in Senium\" in 1199 stipulated that heresy would be considered, in terms of punishment, equal to treason (\"L\u00e8se-majest\u00e9)\", and the punishment would be imposed also on the descendants of the condemned.\nThe first Inquisition was temporarily established in Languedoc (south of France) in 1184. The murder of Pope Innocent III's papal legate Pierre de Castelnau by Cathars in 1208 sparked the Albigensian Crusade (1209\u20131229). The Inquisition was permanently established in 1229 (Council of Toulouse), run largely by the Dominicans in Rome and later at Carcassonne in Languedoc.\nIn 1252, the Papal Bull \"Ad extirpanda\", following another assassination by Cathars, charged the head of state with funding and selecting inquisitors from monastic orders; this caused friction by establishing a competitive court to the Bishop's courts.\nMedieval Inquisitions.\nHistorians use the term \"Medieval Inquisition\" to describe the various inquisitions that started around 1184, including the Episcopal Inquisitions (1184\u20131230s) and later the Papal Inquisitions (1230s). These inquisitions responded to large popular movements throughout Europe considered apostate or heretical to Christianity, in particular the Cathars in southern France and the Waldensians in both southern France and northern Italy. Other inquisitions followed after these first inquisition movements. The legal basis for some inquisitorial activity came from Pope Innocent IV's papal bull \"Ad extirpanda\" of 1252, which authorized the use of tortures in certain circumstances by inquisitors for eliciting confessions and denunciations from heretics. By 1256 Alexander IV's rescripts \"Ut negotium\" allowed certain anti-Cathar inquisitors to absolve each other if the torture (accidentally) resulted in shedding of blood, forbidden to priests.\nIn the 13th century, Pope Gregory IX (reigned 1227\u20131241) assigned the duty of carrying out inquisitions to the Dominican Order and Franciscan Order. By the end of the Middle Ages, England and Castile were the only large western nations without a papal inquisition. Most inquisitors were friars who taught theology and/or law in the universities. They used inquisitorial procedures, a common legal practice adapted from the earlier Ancient Roman court procedures. They judged heresy along with bishops and groups of \"assessors\" (clergy serving in a role that was roughly analogous to a jury or legal advisers), using the local authorities to establish a tribunal and to prosecute heretics. After 1200, a Grand Inquisitor headed but did not control each regional Inquisition. Grand Inquisitions persisted until the mid 19th century.\nInquisitions in Medieval Italy.\nOnly fragmentary data is available for the period before the Roman Inquisition of 1542. In 1276, some 170 Cathars were captured in Sirmione, who were then imprisoned in Verona, and there, after a two-year trial, on 13 February from 1278, more than a hundred of them were burned. In Orvieto, at the end of 1268/1269, 85 heretics were sentenced, none of whom were executed, but in 18 cases the sentence concerned people who had already died. In Tuscany, the inquisitor Ruggiero burned at least 11 people in about a year (1244/1245). Excluding the executions of the heretics at Sirmione in 1278, 36 Inquisition executions are documented in the March of Treviso between 1260 and 1308. Ten people were executed in Bologna between 1291 and 1310. In Piedmont, 22 heretics (mainly Waldensians) were burned in the years 1312\u20131395 out of 213 convicted. 22 Waldensians were burned in Cuneo around 1440 and another five in the Marquisate of Saluzzo in 1510.\nThere are also fragmentary records of a good number of executions of people suspected of witchcraft in northern Italy in the 15th and early 16th centuries. Wolfgang Behringer estimates that there could have been as many as two thousand executions. This large number of witches executed was probably because some inquisitors took the view that the crime of witchcraft was exceptional, which meant that the usual rules for heresy trials did not apply to its perpetrators. Many alleged witches were executed even though they were first tried and pleaded guilty, which under normal rules would have meant only canonical sanctions, not death sentences. The episcopal inquisition was also active in suppressing alleged witches: in 1518, judges delegated by the Bishop of Brescia, Paolo Zane, sent some 70 witches from Val Camonica to the stake.\nInquisitions in Medieval France.\nThe Albigensian Crusade (1209\u20131229) a crusade proclaimed by the Catholic Church against heresy, mainly Catharism, with many thousands of victims (men, women and children, some of them Catholics), had already paved the way for the later Inquisition.\nFrance has the best preserved archives of medieval inquisitions (13th\u201314th centuries), although they are still very incomplete. The activity of the inquisition in this country was very diverse, both in terms of time and territory. In the first period (1233 to c. 1330), the courts of Languedoc (Toulouse, Carcassonne) are the most active. After 1330 the center of the persecution of heretics shifted to the Alpine regions, while in Languedoc they ceased almost entirely. In northern France, the activity of the inquisitors was irregular throughout this period and, except for the first few years, it was not very intense.\nFrance's first Dominican inquisitor, Robert le Bougre, working in the years 1233\u20131244, earned a particularly grim reputation. In 1236, Robert burned about 50 people in the area of Champagne and Flanders, and on 13 May 1239, in Montwimer, he burned 183 Cathars. Following Robert's removal from office, Inquisition activity in northern France remained very low. One of the largest trials in the area took place in 1459\u20131460 at Arras; 34 people were then accused of witchcraft and Satanism, 12 of them were burned at the stake.\nThe main center of the medieval inquisition was undoubtedly the Languedoc. The first inquisitors were appointed there in 1233, but due to strong resistance from local communities in the early years, most sentences concerned dead heretics, whose bodies were exhumed and burned. Actual executions occurred sporadically and, until the fall of the fortress of Montsegur (1244), probably accounted for no more than 1% of all sentences. In addition to the cremation of the remains of the dead, a large percentage were also sentences in absentia and penances imposed on heretics who voluntarily confessed their faults (for example, in the years 1241\u20131242 the inquisitor Pierre Ceila reconciled 724 heretics with the Church). Inquisitor Ferrier of Catalonia, investigating Montauban between 1242 and 1244, questioned about 800 people, of whom he sentenced 6 to death and 20 to prison. Between 1243 and 1245, Bernard de Caux handed down 25 sentences of imprisonment and confiscation of property in Agen and Cahors. After the fall of Montsegur and the seizure of power in Toulouse by Count Alfonso de Poitiers, the percentage of death sentences increased to around 7% and remained at this level until the end of the Languedoc Inquisition around from 1330.\nBetween 1245 and 1246, the inquisitor Bernard de Caux carried out a large-scale investigation in the area of Lauragais and Lavaur. He covered 39 villages, and probably all the adult inhabitants (5,471 people) were questioned, of whom 207 were found guilty of heresy. Of these 207, no one was sentenced to death, 23 were sentenced to prison and 184 to penance. Between 1246 and 1248, the inquisitors Bernard de Caux and Jean de Saint-Pierre handed down 192 sentences in Toulouse, of which 43 were sentences in absentia and 149 were prison sentences.\nIn Pamiers in 1246/1247 there were 7 prison sentences [201] and in Limoux in the county of Foix 156 people were sentenced to carry crosses. Between 1249 and 1257, in Toulouse, the inquisitors handed down 306 sentences, without counting the penitential sentences imposed during \"times of grace\". 21 people were sentenced to death, 239 to prison, in addition, 30 people were sentenced in absentia and 11 posthumously; In another five cases the type of sanction is unknown, but since they all involve repeat offenders, only prison or burning at stake. Between 1237 and 1279, at least 507 convictions were passed in Toulouse (most in absentia or posthumously) resulting in the confiscation of property; in Albi between 1240 and 1252 there were 60 sentences of this type.\nThe activities of Bernard Gui, inquisitor of Toulouse from 1307 to 1323, are better documented, as a complete record of his trials has been preserved. During the entire period of his inquisitorial activity, he handed down 633 sentences against 602 people (31 repeat offenders), including:\nIn addition, Bernard Gui issued 274 more sentences involving the mitigation of sentences already served to convicted heretics; in 139 cases he exchanged prison for carrying crosses, and in 135 cases, carrying crosses for pilgrimage. To the full statistics, there are 22 orders to demolish houses used by heretics as meeting places and one condemnation and burning of Jewish writings (including commentaries on the Torah).\nThe episcopal inquisition was also active in Languedoc. In the years 1232\u20131234, the Bishop of Toulouse, Raymond, sentenced several dozen Cathars to death. In turn, Bishop Jacques Fournier of Pamiers (he was later Pope Benedict XII) in the years 1318\u20131325 conducted an investigation against 89 people, of whom 64 were found guilty and 5 were sentenced to death.\nAfter 1330, the center of activity of the French inquisitions moved east, to the Alpine regions, where there were numerous Waldensian communities. The repression against them was not continuous and was very ineffective. Data on sentences issued by inquisitors are fragmentary. In 1348, 12 Waldensians were burned in Embrun, and in 1353/1354 as many as 168 received penances. In general, however, few Waldensians fell into the hands of the inquisitors, for they took refuge in hard-to-reach mountainous regions, where they formed close-knit communities. Inquisitors operating in this region, in order to be able to conduct trials, often had to resort to the armed assistance of local secular authorities (e.g. military expeditions in 1338\u20131339 and 1366). In the years 1375\u20131393 (with some breaks), the Dauphin\u00e9 was the scene of the activities of the inquisitor Francois Borel, who gained an extremely gloomy reputation among the locals. It is known that on 1 July 1380, he pronounced death sentences in absentia against 169 people, including 108 from the Valpute valley, 32 from Argentiere and 29 from Freyssiniere. It is not known how many of them were actually carried out, only six people captured in 1382 are confirmed to be executed.\nIn the 15th and 16th centuries, major trials took place only sporadically, e.g. against the Waldensians in Delphinate in 1430\u20131432 (no numerical data) and 1532\u20131533 (7 executed out of about 150 tried) or the aforementioned trial in Arras 1459\u20131460 . In the 16th century, the jurisdiction of the inquisitors in the kingdom of France was effectively limited to clergymen, while local parliaments took over the jurisdiction of the laity. Between 1500 and 1560, 62 people were burned for heresy in the Languedoc, all of whom were convicted by the Parliament of Toulouse.\nInquisitions in Medieval Germany.\nThe Rhineland and Thuringia in the years 1231\u20131233 were the field of activity of the notorious inquisitor Konrad of Marburg. Unfortunately, the documentation of his trials has not been preserved, making it impossible to determine the number of his victims. The chronicles only mention \"many\" heretics that he burned. The only concrete information is about the burning of four people in Erfurt in May 1232.\nAfter the murder of Konrad of Marburg, burning at the stake in Germany was virtually unknown for the next 80 years. It was not until the early fourteenth century that stronger measures were taken against heretics, largely at the initiative of bishops. In the years 1311\u20131315, numerous trials were held against the Waldensians in Austria, resulting in the burning of at least 39 people, according to incomplete records. In 1336, in Angerm\u00fcnde, in the diocese of Brandenburg, another 14 heretics were burned.\nThe number of those convicted by the papal inquisitors was smaller. Walter Kerlinger burned 10 begards in Erfurt and Nordhausen in 1368\u20131369. In turn, Eylard Sch\u00f6neveld burned a total of four people in various Baltic cities in 1402\u20131403.\nIn the last decade of the 14th century, episcopal inquisitors carried out large-scale operations against heretics in eastern Germany, Pomerania, Austria, and Hungary. In Pomerania, of 443 sentenced in the years 1392\u20131394 by the inquisitor Peter Zwicker, the provincial of the Celestinians, none went to the stake, because they all submitted to the Church. Bloodier were the trials of the Waldensians in Austria in 1397, where more than a hundred Waldensians were burned at the stake. However, it seems that in these trials the death sentences represented only a small percentage of all the sentences, because according to the account of one of the inquisitors involved in these repressions, the number of heretics reconciled with the Church from Thuringia to Hungary amounted to about 2,000.\nIn 1414, the inquisitor Heinrich von Sch\u00f6neveld arrested 84 flagellants in Sangerhausen, of whom he burned 3 leaders, and imposed penitential sentences on the rest. However, since this sect was associated with the peasant revolts in Thuringia from 1412, after the departure of the inquisitor, the local authorities organized a mass hunt for flagellants and, regardless of their previous verdicts, sent at least 168 to the stake (possibly up to 300) people. Inquisitor Friedrich M\u00fcller (d. 1460) sentenced to death 12 of the 13 heretics he had tried in 1446 at Nordhausen. In 1453 the same inquisitor burned 2 heretics in G\u00f6ttingen.\nInquisitor Heinrich Kramer, author of the Malleus Maleficarum, in his own words, sentenced 48 people to the stake in five years (1481\u20131486). Jacob Hoogstraten, inquisitor of Cologne from 1508 to 1527, sentenced four people to be burned at the stake.\nA notable former inquisitor, Jesuit Friedrich Spee, published a book \"Cautio Criminalis\" (1631) which helped end witch-hunting and the reliance on torture, highly regarded in Catholic and Protestant circles.\nInquisition in Hungary and the Balkans.\nVery little is known about the activities of inquisitors in Hungary and the countries under its influence (Bosnia, Croatia), as there are few sources about this activity. Numerous conversions and executions of Bosnian Cathars are known to have taken place around 1239/40, and in 1268 the Dominican inquisitor Andrew reconciled many heretics with the Church in the town of Skradin, but precise figures are unknown. The border areas with Bohemia and Austria were under major inquisitorial action against the Waldensians in the early 15th century. In addition, in the years 1436\u20131440 in the Kingdom of Hungary, the Franciscan Jacobo de la Marcha acted as an inquisitor... his mission was mixed, preaching and inquisitorial. The correspondence preserved between James, his collaborators, the Hungarian bishops and Pope Eugene IV shows that he reconciled up to 25,000 people with the Church. This correspondence also shows that he punished recalcitrant heretics with death, and in 1437 numerous executions were carried out in the diocese of Sirmium, although the number of those executed is also unknown.\nInquisitions in the Czech lands and Poland.\nIn Bohemia and Poland, the inquisition was established permanently in 1318, although anti-heretical repressions were carried out as early as 1315 in the episcopal inquisition, when more than 50 Waldensians were burned in various Silesian cities. The fragmentary surviving protocols of the investigations carried out by the Prague inquisitor Gallus de Neuhaus in the years 1335 to around 1353 mention 14 heretics burned out of almost 300 interrogated, but it is estimated that the actual number executed could have been even more than 200, and the entire process was covered to varying degrees by some 4,400 people.\nIn the lands belonging to the Kingdom of Poland little is known of the activities of the Inquisition until the appearance of the Hussite heresy in the 15th century. Polish courts of the inquisition in the fight against this heresy issued at least 8 death sentences for some 200 trials carried out.\nThere are 558 court cases finished with conviction researched in Poland from the 15th to 18th centuries.\nInquisition in Medieval Spain.\nPortugal and Spain in the late Middle Ages consisted largely of multicultural territories of Muslim and Jewish influence, reconquered from Islamic control, and the new Christian authorities could not assume that all their subjects would suddenly become and remain orthodox Catholics. So the Inquisition in Iberia, in the lands of the Reconquista counties and kingdoms like Le\u00f3n, Castile, and Aragon, had a special socio-political basis as well as more fundamental religious motives.\nIn some parts of Spain towards the end of the 14th century, there was a wave of violent anti-Judaism, encouraged by the preaching of Ferrand Mart\u00ednez, Archdeacon of \u00c9cija. In the pogroms of June 1391 in Seville, hundreds of Jews were killed, and the synagogue was completely destroyed. The number of people killed was also high in other cities, such as C\u00f3rdoba, Valencia, and Barcelona.\nOne of the consequences of these pogroms was the mass conversion of thousands of surviving Jews. Forced baptism was contrary to the law of the Catholic Church, and theoretically anybody who had been forcibly baptized could legally return to Judaism. However, this was very narrowly interpreted. Legal definitions of the time theoretically acknowledged that a forced baptism was not a valid sacrament, but confined this to cases where it was literally administered by physical force. A person who had consented to baptism under threat of death or serious injury was still regarded as a voluntary convert, and accordingly forbidden to revert to Judaism. After the public violence, many of the converted \"felt it safer to remain in their new religion\". Thus, after 1391, a new social group appeared and were referred to as \"conversos\" or \"New Christians\".\nEarly modern European history.\nWith the sharpening of debate and of conflict between the Protestant Reformation and the Catholic Counter-Reformation, Protestant societies came to see/use the Inquisition as a terrifying \"other\", while staunch Catholics regarded the Holy Office as a necessary bulwark against the spread of reprehensible heresies. Since the beginning of the most serious heretic groups, like the Cathars or the Waldensians, they were soon accused of the most fantastic behavior, like having wild sexual orgies, eating babies, copulating with demons, worshipping the Devil.\nSpanish Inquisition.\nKing Ferdinand II of Aragon and Queen Isabella I of Castile established the Spanish Inquisition in 1478 to be overseen by 14 local Tribunals. In contrast to the previous inquisitions, it operated completely under royal Christian authority, though staffed by clergy and orders, and independently of the Holy See. It operated first in Spain, then in Portugal, and eventually in most Spanish colonies and territories, which included the Canary Islands, the Kingdom of Sicily, and all Spanish possessions in North, Central, and South America. It primarily focused upon forced converts from Islam (Moriscos, \"conversos\", and \"secret Moors\") and from Judaism (\"conversos\", Crypto-Jews, and Marranos)\u2014both groups which continued to reside in Spain and who came under suspicion of either continuing to adhere to their old religion or of having fallen back into it.\nUnder the Alhambra Decree of 1492, all Jews who had not converted were expelled from Spain in 1492. Tom\u00e1s de Torquemada was chosen to be the first Grand Inquisitor, to oversee the Inquisition; and it is estimated that up to 2,000 Jews were burned at the stake during the reign of Queen Isabella.(See https://).\nAll Muslims were ordered to convert in different stages starting in 1507 and culminating in 1614, when Muslims who had previously converted were now expelled . Those who converted or simply remained after the relevant edict became nominally and legally Catholics, and thus subject to the Inquisition.\nInquisition in the Spanish overseas empire.\nIn 1569, King Philip II of Spain set up three tribunals in the Americas (each formally titled \"Tribunal del Santo Oficio de la Inquisici\u00f3n\"): one in Mexico, one in Cartagena de Indias (in modern-day Colombia), and one in Peru. The Mexican office administered Mexico (central and southeastern Mexico), Nueva Galicia (northern and western Mexico), the Audiencias of Guatemala (Guatemala, Chiapas, El Salvador, Honduras, Nicaragua, Costa Rica), and the Spanish East Indies. The Peruvian Inquisition, based in Lima, administered all the Spanish territories in South America and Panama.\nThe Spanish Inquisition was formerly ended by proclamation on https://, by Maria Cristina de Bourbon, then queen regent of Spain, also known as Maria Cristina of Naples and Sicily.\nPortuguese Inquisition.\nThe Portuguese Inquisition formally started in Portugal in 1536 at the request of King Jo\u00e3o III. Manuel I had asked Pope Leo X for the installation of the Inquisition in 1515, but only after his death in 1521 did Pope Paul III acquiesce. At its head stood a \"Grande Inquisidor\", or General Inquisitor, named by the Pope but selected by the Crown, and always from within the royal family. Jews who fled Spain and the Spanish Inquisition now found themselves subject to the Inquisition in Portugal. The Portuguese Inquisition principally focused upon the Jews from Spain, the Sephardi Jews, who had fled or whom the state had forced to convert to Christianity.\nThe Portuguese Inquisition held its first \"auto-da-f\u00e9\" in 1540. The Portuguese inquisitors mostly focused upon the Jewish New Christians (i.e. \"conversos\" or \"marranos\"). The Portuguese Inquisition expanded its scope of operations from Portugal to its colonial possessions, including Brazil, Cape Verde, and Goa. In the colonies, it continued as a religious court, investigating and trying cases of breaches of the tenets of orthodox Catholicism until 1821. King Jo\u00e3o III (reigned 1521\u201357) extended the activity of the courts to cover censorship, divination, witchcraft, and bigamy. Originally oriented for a religious action, the Inquisition exerted an influence over almost every aspect of Portuguese society: political, cultural, and social.\nAccording to Henry Charles Lea, between 1540 and 1794, tribunals in Lisbon, Porto, Coimbra, and \u00c9vora resulted in the burning of 1,175 persons, the burning of another 633 in effigy, and the penancing of 29,590. But documentation of 15 out of 689 autos-da-f\u00e9 has disappeared, so these numbers may slightly understate the activity.\nInquisition in the Portuguese overseas empire.\nGoa Inquisition.\nThe Goa Inquisition began in 1560 at the order of John III of Portugal. It had originally been requested in a letter in the 1540s by Jesuit priest Francis Xavier, because of the New Christians who had arrived in Goa and then reverted to Judaism. The Goa Inquisition also focused upon Catholic converts from Hinduism or Islam who were thought to have returned to their original ways. In addition, this inquisition prosecuted non-converts who broke prohibitions against the public observance of Hindu or Muslim rites or interfered with Portuguese attempts to convert non-Christians to Catholicism. Aleixo Dias Falc\u00e3o and Francisco Marques set it up in the palace of the Sabaio Adil Khan.\nBrazilian Inquisition.\nThe inquisition was active in colonial Brazil. The religious mystic and formerly enslaved prostitute, Rosa Egipc\u00edaca was arrested, interrogated and imprisoned, both in the colony and in Lisbon. Egipc\u00edaca was the first black woman in Brazil to write a book \u2013 this work detailed her visions and was entitled \"Sagrada Teologia do Amor Divino das Almas Peregrinas.\"\nRoman Inquisition.\nWith the Protestant Reformation, Catholic authorities became much more ready to suspect heresy in any new ideas, including those of Renaissance humanism, previously strongly supported by many at the top of the Church hierarchy. The extirpation of heretics became a much broader and more complex enterprise, complicated by the politics of territorial Protestant powers, especially in northern Europe. The Catholic Church could no longer exercise direct influence in the politics and justice-systems of lands that officially adopted Protestantism. Thus war (the French Wars of Religion, the Thirty Years' War), massacre (the St. Bartholomew's Day massacre) and the missional and propaganda work (by the \"Sacra congregatio de propaganda fide\") of the catholic Counter-Reformation came to play larger roles in these circumstances, and the Roman law type of a \"judicial\" approach to heresy represented by the Inquisition became less important overall. In 1542 Pope Paul III established the Congregation of the Holy Office of the Inquisition as a permanent congregation staffed with cardinals and other officials. It had the tasks of maintaining and defending the integrity of the faith and of examining and proscribing errors and false doctrines; it thus became the supervisory body of local Inquisitions. A famous case tried by the Roman Inquisition was that of Galileo Galilei in 1633.\nThe penances and sentences for those who confessed or were found guilty were pronounced together in a public ceremony at the end of all the processes. This was the \"sermo generalis\" or \"auto-da-f\u00e9\". Penances (not matters for the civil authorities) might consist of pilgrimages, a public scourging, a fine, or the wearing of a cross. The wearing of two tongues of red or other brightly colored cloth, sewn onto an outer garment in an \"X\" pattern, marked those who were under investigation. The penalties in serious cases were confiscation of property by the Inquisition or imprisonment. This led to the possibility of false charges to enable confiscation being made against those over a certain income, particularly rich \"marranos\". Following the French invasion of 1798, the new authorities sent 3,000 chests containing over 100,000 Inquisition documents to France from Rome.\nIn France.\nBetween 1657 and 1659, twenty-two alleged witches were burned on the orders of the inquisitor Pierre Symard in the province of Franche-Comt\u00e9, then part of the Empire.\nThe inquisitorial tribunal in papally-ruled Avignon, established in 1541, passed 855 death sentences, almost all of them (818) in the years 1566\u20131574, but the vast majority of them were pronounced in absentia.\nWitch-hunts.\nThe fierce denunciation and persecution of supposed sorceresses that characterized the cruel witchhunts of a later age were not generally found in the first thirteen hundred years of the Christian era. While belief in witchcraft, and persecutions directed at or excused by it, were widespread in pre-Christian Europe, and reflected in old Germanic law, the growing influence of the Church in the early medieval era in pagan areas resulted in the revocation of these laws in many places, bringing an end to the traditional witch hunts. Throughout the medieval era, mainstream Christian teaching had disputed the existence of witches and denied any power to witchcraft, condemning it as pagan superstition.\nBlack magic practitioners were generally dealt with through confession, repentance, and charitable work assigned as penance. In 1258, Pope Alexander IV ruled that inquisitors should limit their involvement to those cases in which there was some clear presumption of heretical belief but slowly this vision changed.\nThe prosecution of witchcraft generally became more prominent in the late medieval and Renaissance era, perhaps driven partly by the upheavals of the era \u2013 the Black Death, the Hundred Years War, and a gradual cooling of the climate that modern scientists call the Little Ice Age (between about the 15th and 19th centuries). Witches were sometimes blamed. Since the years of most intense witch-hunting largely coincide with the age of the Protestant Reformation and Counter-Reformation, some historians point to the influence of the Reformation on the European witch-hunt. However, witch-hunting began almost one hundred years before Luther's ninety-five theses.\nManuals for Inquisitors.\nOver the centuries that it lasted, several procedure manuals for inquisitors were produced for dealing with different types of heresy. The primordial text was Pope Innocent IV's bull, \"Ad Extirpanda\", from 1252, which in its thirty-eight laws details in detail what must be done and authorizes the limited use of non-bloody, non-maining torture to corroborate certain evidence. Of the various manuals produced later, some stand out: by Nicholas Eymerich, \"Directorium Inquisitorum,\" written in 1376; by Bernardo Gui, \"Practica inquisitionis heretice pravitatis,\" written between 1319 and 1323. Witches were not forgotten: the controversial book \"Malleus Maleficarum (\"the witches' hammer\"),\" written in 1486, by ex-inquisitor Heinrich Kramer, deals with the subject.\nIn Portugal, several \"Regimentos\" (four) were written for the use of the inquisitors, the first in 1552 at the behest of the inquisitor Cardinal D. Henrique and the last in 1774, this sponsored by the Marquis of Pombal, himself a \"familiar\" of the inquisition. The Portuguese 1640 Regiment determined that each court of the Holy Office should have a Bible, a compendium of canon and civil law, Eymerich's \"Directorium Inquisitorum,\" and Diego de Simancas' \"Catholicis institutionibus\".\nIn 1484, Spanish inquisitor Torquemada, based in Nicholas Eymerich's \"Directorium Inquisitorum\", wrote his twenty eight articles code, \"Compilaci\u00f3n de las instrucciones del oficio de la Santa Inquisici\u00f3n\" (i.e. Compilation of the instructions of the office of the Holy Inquisitio\"n).\" Later additions would be made, based on experience, many by the canonist Francisco Pe\u00f1a.\nMalleus Maleficarum.\nDominican priest Heinrich Kramer was assistant to the Archbishop of Salzburg, a sensational preacher, and an appointed local inquisitor. Historian Malcolm Gaskill calls Kramer a \"superstitious psychopath\".\nIn 1484 Kramer requested that Pope Innocent VIII clarify his authority to conduct inquisitions into witchcraft throughout Germany, where he had been refused assistance by the local ecclesiastical authorities. They maintained that Kramer could not legally function in their areas. Despite some support from Pope Innocent VIII, he was expelled from the city of Innsbruck by the local bishop, George Golzer, who ordered Kramer to stop making false accusations.\nGolzer described Kramer as senile in letters written shortly after the incident. This rebuke led Kramer to write a justification of his views on witchcraft in his 1486 book \"Malleus Maleficarum\" (\"Hammer against witches\"). The book distinguishes itself from other demonologies by its obsessive hate of women and sex, seemingly reflecting the twisted psyche of the author. Historian Brian Levack calls it \"scholastic pornography\".\nDespite Kramer's claim that the book gained acceptance from the clergy at the University of Cologne, it was in fact condemned by the clergy at Cologne for advocating views that violated Catholic doctrine and standard inquisitorial procedure. In 1538 the Spanish Inquisition cautioned its members not to believe everything the \"Malleus\" said. Despite this, Heinrich Kramer was never excommunicated and even enjoyed considerable prestige till his death.\nInquisition Proceedings.\nDenunciations.\nThe usual procedure began with the visitation by the inquisitors in a chosen location. The so-called heretics were then asked to be present and denounce themselves and others; it was not enough to denounce himself as a heretic.\nMany confessed alleged heresies for fear that a friend or neighbor might do so later. The terror of the Inquisition provoked chain reactions and denunciations even of spouses, children and friends.\nIf they confessed within a \"grace period\" \u2014 usually 30 days \u2014 they could be accepted back into the church without punishment. In general, the benefits proposed by the \"edicts of grace\" to those who presented themselves spontaneously were the forgiveness of the death penalty or life imprisonment and the forgiveness of the penalty of confiscation of property.\nAnyone suspected of knowing about another's heresy and who did not make the obligatory denunciation would be excommunicated and then subject to prosecution as a \"promoter of heresy.\" If the denouncer named other potential heretics, they would also be summoned. All types of complaints were accepted by the Inquisition, regardless of the reputation or position of the complainant. Rumors, mere suppositions, and even anonymous letters were accepted as denunciations, \"if the case were of such a nature that such action seemed appropriate to the service of God and the good of the Faith\". It was foreseen that prison guards themselves could report and be witnesses against the accused.\nThis strategy transformed everyone into an Inquisition agent, reminding them that a simple word or deed could bring them before the tribunal. Denunciation was elevated to the status of a superior religious duty, filling the nation with spies and making every individual suspicious of his neighbor, family members, and any strangers he might met.\nThere were various rules, not always followed, on evidence: an enemy could not be a witness against the accused, more than one witness was required, torture \u2014of the accused, denouncer, or witnesses\u2014 (which had widespread \"ad hoc\" use in secular proceedings) could only be used to corroborate suspect testimony, etc.\nMethods of torture used.\nThe primary method of torture was psychological: solitary confinement and indefinite incarceration.\nThe real prevalence or extent of torture is disputed. Some defend that victims were interrogated under physical torture only in extreme cases. However, that there was a wide range of views and practices in different times and locations can be seen from the regulations and manuals for inquisitions. \nThe view of historian Ron E. Hassner is that 'inquisitors knew that information obtained through torture often was not reliable. [So] They built their cases patiently, gathering information from a variety of sources, using a variety of methods. With any given subject, they used torture only intermittently, in sessions sometimes months apart. Their main goal was not to compel a confession or a profession of faith, but to extract factual information that would confirm or corroborate information already in hand.'\nThe summary of the \"Directorium Inquisitorum\", by Nicol\u00e1s Aymerich, made by Marchena, notes a comment by the Aragonese inquisitor: \"Quaestiones sunt fallaces et inefficaces\" (\"The interrogations are misleading and useless\"). In spite of this, Eymerich strongly recommends the use of torture and describes in detail the rules to be followed in order to recommend its use, which he considers very praiseworthy.\nDefendants were punished if found guilty, with their property being confiscated to cover legal and prison costs and to maintain the heavy machinery of persecution. The victims could also repent of their accusation and receive reconciliation with the Church. The execution of the tortures was attended by the inquisitor, the doctor, the secretary and the torturer, applying them on the nearly naked prisoner. In the year 1252, the bull \"Ad extirpanda\" allowed torture, but always with a doctor involved to avoid endangering life, and limited its use to non-bloody methods that did not break bones:\nAccording to Catholic apologists, the method of torture (which was socially accepted in the context of the time) was adopted only in exceptional cases, and the inquisitorial procedure was meticulously regulated in interrogation practices.\nIt is clear that after the proceedings the tortured were left in a sorry state. Some perished as a result.Despite the loss of thousands of documents over the years, many of the meticulous records of torture sessions have survived.\nFake instruments of torture.\nDespite what is popularly believed, the cases in which torture was used during the inquisitorial processes were rare, since it was considered (according to some authors) to be ineffective in obtaining evidence. Before torture, some inquisitors may have displayed the instruments mainly on the purpose of intimidation of the accused, so he could understand what to expect. If he wished to avoid punishment, he should only confess his faults.\nIn the words of historian Helen Mary Carrel: \"the common view of the medieval justice system as cruel and based on torture and execution is often unfair and inaccurate.\" As the historian Nigel Townson wrote: \"The sinister torture chambers equipped with cogwheels, bone crushing contraptions, shackles, and other terrifying mechanisms only existed in the imagination of their detractors.\"\nIn fact, it seems likely that the inquisitors favoured simpler and \"cleaner\" methods, which left few apparent marks. Aymerich points out that canon law does not prescribe either this or that particular torture, so judges can use whatever they see fit, as long as it's not an unusual torture. Many types of torments have been chosen, but Eymerich think they seem more like the inventions of executioners than the works of theologians. \"It is true that it is a very praiseworthy practice to subject the accused to torture, but no less reprehensible are those bloodthirsty judges who base their vain glory on the invention of crude and exquisite torments\" \u2013 he adds. Also, Rafael Sabatini notes that the available records do not show these uncommon inventions. It seems that the inquisitors must have been satisfied with the devices already in use, or a limited number of the most efficient.\nMany torture instruments were designed by late 18th and early 19th century pranksters, entertainers, and con artists who wanted to profit from people's morbid interest in the Dark Age myth by charging them to witness such instruments in Victorian-era circuses.\nHowever, several torture instruments are accurately described in \"Foxe's Book of Martyrs\", including but not limited to the dry pan.\nSome of the instruments that \"the Inquisition\" never used, but that are erroneously registered in various inquisition museums:\nTrials.\nThe Inquisition's trials were secret and there was no possibility of appealing the decisions. The defendant was pressured to confess to the \"crimes\" assigned to him. The Inquisitors kept the accusations made and evidence they possessed hidden, to achieve a confession without announcing the accusation. The main goal was to make the defendant confess. When a lawyer was assigned to him, he was an employee of the Inquisition and worked for it, not in the defense of the accused. Each court had its own staff (lawyers, prosecutors, notaries, etc.) and prison. The guards who served the inquisition spied the accused in their cells; if they refused to eat for example, this could be considered a fast, a Jewish custom.\nIn many cases, it was common for false accusations to be made against New Christians and it was difficult to prove their innocence. It was therefore more convenient for many to make a false confession to the inquisitors, including a list of imaginary accomplices, in the hope that they would not receive extreme penalties, such as the death penalty, but only the confiscation of property or lesser penalties.\nThere was no trial in the modern sense of the term, but an interrogation; the prisoner was usually not told about the reasons for his arrest \u2014 often for months or years. There was no precise accusation and therefore little chance of a plausible defence. The prisoner was advised \"to search his conscience, confess the truth, and trust to the mercy of the tribunal'\". Eventually, the prisoner was informed of the charges against him \u2014 but omitting the names of the witnesses. After the interrogations, hearings and waiting periods came to an end, the sentence could be pronounced.\nWalter Ullmann, a historian, summarises his evaluation of the trials: \"There is hardly one item in the whole Inquisitorial procedure that could be squared with the demands of justice; on the contrary, every one of its items is the denial of justice or a hideous caricature of it [...] its principles are the very denial of the demands made by the most primitive concepts of natural justice [...] This kind of proceeding has no longer any semblance to a judicial trial but is rather its systematic and methodical perversion.\" Portuguese author A. Jos\u00e9 Saraiva points out the analogy of the trials with the absurdity of the Kafka's novel The Trial or the show trials of Stalin's era.\nPunishments.\nThe Inquisition's sentences could be simple penances, for example private devotions, or heavy punishments. One of the Inquisition's punishments was the forced wearing of distinctive clothing or signs such as the sambenito, sometimes for an entire life.\nOther punishments were exile, compulsory pilgrimages, fines, the galleys, life imprisonment (in fact prison for some years) and in addition the confiscation of goods and property. The bull Ad Extirpanda determined that the houses of heretics should be completely razed to the ground. Furthermore, the impact of the Inquisition's activity on the fabric of society was not limited to these penances or punishments. As under the terror of the Inquisition entire families denounced each other, they were soon reduced to misery, completed by the confiscation of property, public humiliation and ostracism.\nEven dead people could be accused, and sentenced up to forty years after the death. When inquisitors considered proven that the deceased were heretics in their lifetime, their corpses were exhumed and burned, their property confiscated and the heirs disinherited.\nLegitimation by the texts.\nThe Inquisition always referred to biblical passages, as well as to church fathers, like Augustine of Hippo, to legitimise his actuation.\nThe New Testament contains some sentences that the church could interpret for dealing with heretics. The excommunication of a deviant from the faith was equivalent to handing him over to the Devil: \"When you have gathered together, and my spirit with you, in the power of our Lord Jesus, hand this man over to Satan for destruction of the flesh, so that his spirit may be saved on the day of the Lord.\" (The Pauline letters: 1 Corinthians, B. Incest in Corinth, 5:4 and 5:5)\nThe sentence of Paul could also be understood in this way: he handed over to the Devil those \"who have suffered shipwreck in the faith [...] so that they may be taught not to be blasphemous.\" (The Pastoral epistles: 1 Timothy \u2013 The first letter from Paul to Timothy\u2014Timothy's responsibility: 1:19 and 1:20)\nPaul's view reflects less the idea of punishment than the idea of isolation when he says: \" After a first and second warning have nothing to do with a disputatious person, since you may be sure that such a person is warped and is self-condemned as a sinner.\" (The Pastoral epistles : Titus \u2013 The letter from Paul to Titus\u20143:10 and 3:11)\nIn the Gospel of John, Jesus tells the apostates in a parable: \"I am the vine, you are the branches. Whoever remains in me, and I in that person, bears fruit in plenty; for apart from me you can do nothing. Anyone who does not remain in me is thrown away like a branch and withers. These branches are collected, thrown on the fire and burnt.\" This parable can be interpreted as the burning of stubborn heretics at the stake. (The Gospel according to John: The true vine\u201415:5 and 15:6)\nThe celebrated theologian Thomas Aquinas (1225\u20131274) supplied the theoretical foundation for the medieval Inquisition in his \"Summa theologica\" II 2. 11. A heretic who repents, the first time, should be allowed penance and their life safeguarded by the church from the punishment of the secular authorities (who treated pernicious and public heresy as a kind of sedition.) A subsequent lapse into heresy would show insincerity that called for excommunication, leaving them to the secular authorities who could impose the death penalty on unprotected heretics: \"Accipere fidem est voluntatis, sed tenere fidem iam acceptam est necessitatis\" (i.e. \"The acceptance of faith is voluntary, maintaining the accepted faith is necessary. So heretics should be compelled to keep the faith.\")\nLuis de P\u00e1ramo, theologian and Inquisitor of then Spanish-ruled Sicily from 1584 to 1605, asserted that Jesus Christ was \"the first Inquisitor under the Evangelical law\" and that John the Baptist and the apostles were also inquisitors.\nHowever, another traditional stream of Catholic thought, for example championed by Erasmus, was that the Parable of the wheat and tares forbade any premature culling of heretics.\nSaint Augustine (354\u2013430) led a debate in Africa with the Donatist community, which had split from the Roman Church. In his works, he called for moderate severity or measures by secular power, including the death penalty, against heretics, however he did not consider it desirable: \"Corrigi eos volumus, non necari, nec disciplinam circa eos negligi volumus, nec suppliciis quibus digni sunt exerci\", meaning \"We would like them to be improved, not killed; we desire the triumph of church discipline, not the death they deserve.\"\nOpposition and resistance.\nIn many regions and times, there was opposition to the Inquisition.\nAssassinations.\nIn some cases, heretics and other targets did not hesitate to attempt to murder the inquisitors, or destroy its voluminous archives, because they had much to lose in the face of an inquisitorial investigation: their freedom, their property,\u00a0their lives. \nThe much hated Inquisitor Konrad von Marburg, who also initiated inquisition trials against nobles, was murdered in 1233 by six mounted men on an open country road on the way to Marburg.\nIn 1242, a Cathar group armed with axes entered the castle of the town of Avignonet (southern France) and murdered the inquisitors Guillaume Arnaud and \u00c9tienne de Saint-Thib\u00e9ry.\nIn 1252, the inquisitor Peter of Verona was killed by Cathars. Eleven months after his assassination, he was made a Catholic saint, the quickest canonization in history. As Christine Caldwell Ames writes, \"Inquisition changed what it meant to be a martyr, to be holy, and to be an imitator of Christ.\"\nIn 1395 near Steyr, where the inquisitor Petrus Zwicker was quartered with associates, an assassination attempt on him failed: someone had tried to set fire to the place and burn him alive.\nClergy opposition.\nOpposition to Inquisition power and abuses sometimes came from within the clergy: including friars, priests and bishops.\nDuring French Inquisition, a Franciscan friar, Bernard D\u00e9licieux, opposed the actions of the Inquisition in Languedoc. The infamous Bernard Gui presented him as the commander-in-chief of the \"iniquitous army\" against the Dominicans and the Inquisition. D\u00e9licieux alleged the Inquisitiors were pursuing innocent Catholics for heresy, trying to destroy their towns. He stated that the methods of the inquisition would have condemned even Peter and Paul as heretics if they appeared before the inquisitors. D\u00e9licieux later became one more victim of the Inquisition for his criticism. In 1317, Pope John XXII called him and other Franciscan Spirituals to Avignon, and he was arrested, questioned, and tortured by the Inquisition. In 1319, he was found guilty and sentenced to life in prison. Fragile and old, he died shortly thereafter.\nIn Spain, several bishops contended with inquisitorial tribunals. In 1532, the Archbishop of Toledo Alonso III Fonseca had to ransom \"converso\" Juan de Vergara (Cisneros' Latin secretary) from Spanish inquisitors. Fonseca had previously rescued Ignatius of Loyola from them. Far from being a monolithic institution, sometimes the tribunals threatened individuals protected by the Inquisitor-General, such as with the Inquisitor General Alonso Manrique de Lara and Erasmus.\nIn Portugal, Father Ant\u00f3nio Vieira (1608\u20131697), himself a Jesuit, philosopher, writer and orator, was one of the most important opponents of the Inquisition. Arrested by the Inquisition for \"heretical, reckless, ill-sounding and scandalous propositions\" in October 1665, was imprisoned until December 1667. Under the Inquisitorial sentence, he was forbidden to teach, write or preach. Only perhaps Vieira's prestige, his intelligence and his support among members of the royal family saved him from greater consequences. Father Vieira led an anti-inquisition movement in Rome, where he spent six years. In addition to his humanitarian objections, he also had others: he realised that a mercantile middle class was being attacked that would be sorely missed in the country's economic development. He is believed to have been the author of the anonymous writing \"Not\u00edcias Rec\u00f4nditas do Modo de Proceder a Inquisi\u00e7\u00e3o de Portugal com os seus Presos\", which reveals a great deal about the inner workings of the Inquisitorial mechanism and which he delivered to Pope Clement X in favour of the cause of the persecuted of the Inquisition. The Inquisition was suspended by Clement X between 1674 and 1681.\nEnding of the Inquisition in the 19th and 20th centuries.\nBy decree of Napoleon's government in 1797, the Inquisition in Venice was abolished in 1806.\nIn Portugal, in the wake of the Liberal Revolution of 1820, the \"General Extraordinary and Constituent Courts of the Portuguese Nation\" abolished the Portuguese Inquisition in 1821.\nThe wars of independence of the former Spanish colonies in the Americas concluded with the abolition of the Inquisition in every quarter of Hispanic America between 1813 and 1825.\nThe last execution of the Inquisition was in Spain in 1826. This was the execution by garroting of the Catalan school teacher Gaiet\u00e0 Ripoll for purportedly teaching Deism in his school. In Spain the practices of the Inquisition were finally outlawed in 1834.\nIn Italy, the restoration of the Pope as the ruler of the Papal States in 1814 brought the Inquisition back to the Papal States. It remained active there until the late-19th century, notably in the well-publicised Mortara affair (1858\u20131870).\nA putative governing institution, the Supreme Sacred Congregation of the Roman and Universal Inquisition was created in 1542 in the Vatican. This office survives to this day as part of the Roman Curia, although it underwent a series of name changes. In 1908, it was renamed the Supreme Sacred Congregation of the Holy Office. In 1965, it became the Congregation for the Doctrine of the Faith. In 2022, this office was renamed the Dicastery for the Doctrine of the Faith, as retained to the present day.\nCurrent position of the Catholic Church.\nReflection on the inquisitorial activity of the Catholic Church began to be seriously undertaken in the period of preparation for the Great Jubilee of 2000, on the initiative of John Paul II, who called for repentance for \"examples of thought and action that are in fact a source of anti-witness and scandal\". On 12 March 2000, during the celebration of the Jubilee, the Pope, on behalf of the entire Catholic Church and all Christians, apologized for these acts and in general for many others. The Pope asked for forgiveness for seven categories of sins: general sins; sins \"in the service of truth\"; sins against Christian unity; sins against the Jews; against respect for love, peace and cultures; sins against the dignity of women and minorities; and against human rights. Some theologians were of the opinion that this unprecedented apology would undermine the authority of the Church. Cardinal Joseph Ratzinger gave an apology on behalf of his office, the successor to the Roman Inquisition: \"Even men of the church, in the name of faith and morals, have sometimes used methods not in keeping with the Gospel.\"\nJohn Paul II's apology was considered imperfect by several critics, including Jewish figures, who among other points raised the issue of the beatification, at the same time, of Pope Pius IX, known for his anti-Judaism and his approval of the abduction of Edgardo Mortara as the then six-year-old child had been forcibly taken from his Jewish family by Papal States police, under orders of the Inquisitor of Bologna, and was eventually raised in the papal household.\nSeveral inquisitors are considered saints by the Catholic Church, such as Peter of Verona, Pedro de Arbu\u00e9s, or John of Capistrano; some were even Popes, such as Michele Ghislieri, who would later become Pope Pius V, and Jacques Fournier\u2014later Pope Benedict XII. Raymond of Penyafort, author of one of the first manuals for use by inquisitors\u2014the \"Directorium inquisitoriale\" (1242) -- is also a Catholic saint.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "15192", "revid": "49629546", "url": "https://en.wikipedia.org/wiki?curid=15192", "title": "Isaac", "text": "Biblical patriarch, son of Abraham and Sarah\nIsaac is one of the three patriarchs of the Israelites and an important figure in the Abrahamic religions, including Judaism, Samaritanism, Christianity, Islam, the Bah\u00e1\u02bc\u00ed Faith, and Rastafari. Isaac first appears in the Torah, in which he is the son of Abraham and Sarah, the father of Jacob and Esau, and the grandfather of the twelve tribes of Israel. \nIsaac's name means \"he will laugh\", reflecting the laughter, in disbelief, of Abraham and Sarah, when told by God that they would have a child. He is the only patriarch whose name was not changed, and the only one who did not move out of Canaan. According to the narrative, he died aged 180, the longest-lived of the three patriarchs.\nRecent scholarship has discussed the possibility that Isaac could have originally been an ancestor from the Beersheba region who was venerated at a sanctuary.\nEtymology.\nThe anglicized name \"Isaac\" is a transliteration of the , which literally means \"He laughs/will laugh\". Ugaritic texts dating from the 13th century BCE refer to the benevolent smile of the Canaanite deity El. \" Genesis\" ascribes the laughter to Isaac's parents, Abraham and Sarah, instead. According to the biblical narrative, Abraham fell on his face and laughed when God (Hebrew, ) imparted the news of their son's eventual birth. He laughed because Sarah was past the age of childbearing; both she and Abraham were advanced in age. Later, when Sarah overheard three messengers of the Lord renew the promise, she laughed inwardly for the same reason. Sarah denied laughing when God questioned Abraham about it.\nGenesis narrative.\nBirth.\nAfter God changes Abram and Sarai's names to \"Abraham\" and \"Sarah\", he tells Abraham that he will bear a second son by Sarah named Isaac, with whom a new covenant would be established. In response, Abraham began to laugh, as both he and Sarah were well beyond natural child-bearing age. Some time later, three men who Abraham identifies as messengers of God visit him and Sarah, and Abraham treats them to food and niceties. They repeat the prophecy that Sarah would bear a child, promising Isaac's birth within a year's time, at which point Sarah laughs in disbelief. God questions why the pair laughed in disbelief at his words, and if it is because they believe such things were not within his power. Now afraid, they futilely deny ever having laughed at God's words.\nTime passes as Isaac is born. Isaac was Abraham's second son and firstborn of Sarah who was then Sarai. Sarai had been barren for a long time and sought a way to fulfill God's promise that Abram would be father of many nations, especially since they had grown old, so she offered Hagar to Abram to be his concubine.\nOn the eighth day from his birth, Isaac was circumcised, as was necessary for all males of Abraham's household, in order to be in compliance with the Jewish covenant.\nAfter Isaac had been weaned, Sarah saw Ishmael playing with or mocking him (the Hebrew term is ambiguous), and urged her husband to cast out Hagar the bondservant and her son, so that Isaac would be Abraham's sole heir. Abraham was hesitant, but at God's order he listened to his wife's request.\nBinding.\nAt some point in Isaac's youth, his father Abraham took him to Mount Moriah. At God's command as the last of ten trials to test his faith, Abraham was to build a sacrificial altar and sacrifice his son Isaac upon it. After he had bound his son to the altar and drawn his knife to kill him, at the last moment an angel of God prevented Abraham from proceeding. Instead, he was directed to sacrifice a nearby ram that was stuck in thickets.\nFamily life.\nBefore Isaac was 40 (Genesis 25:20), Abraham sent Eliezer, his steward, into Mesopotamia to find a wife for Isaac, from his nephew Bethuel's family. Eliezer chose the Aramean Rebekah for Isaac. After many years of marriage to Isaac, Rebekah had still not given birth to a child and was believed to be barren. Isaac prayed for her and she conceived. Rebekah gave birth to twin boys, Esau and Jacob. Isaac was 60 years old when his two sons were born. Isaac favored Esau, and Rebekah favored Jacob.\nThe narratives about Isaac do not mention his having concubines.\nMigration.\nIsaac moved to \"Beer-lahai-roi\" after his father died. When the land experienced famine, he moved to the Philistine land of Gerar where his father once lived. This land was still under the control of King Abimelech as it was in the days of Abraham. Like his father, Isaac also pretended that Rebekah was his sister due to fear that Abimelech would kill him in order to take her. He had gone back to all of the wells that his father dug and saw that they were all stopped up with earth. The Philistines did this after Abraham died. So, Isaac unearthed them and began to dig for more wells all the way to Beersheba, where he made a pact with Abimelech, just like in the day of his father.\nBirthright.\nIsaac grew old and became blind. He called his son Esau and directed him to procure some venison for him, in order to receive Isaac's blessing. While Esau was hunting, Jacob, after listening to his mother's advice, deceived his blind father by misrepresenting himself as Esau and thereby obtained his father's blessing, such that Jacob became Isaac's primary heir and Esau was left in an inferior position. According to Genesis 25:29\u201334, Esau had previously sold his birthright to Jacob for \"bread and stew of lentils\". Thereafter, Isaac sent Jacob into Mesopotamia to take a wife of his mother's brother's house. After 20 years working for his uncle Laban, Jacob returned home. He reconciled with his twin brother Esau, then he and Esau buried their father, Isaac, in Hebron after he died at the age of 180.\nBurial site.\nAccording to local tradition, the graves of Isaac and Rebekah, along with the graves of Abraham and Sarah and Jacob and Leah, are in the Cave of the Patriarchs.\nJewish views.\nWhile the Book of Genesis does not tell the age of Isaac at the time of binding, some Talmudic sages take it to be thirty seven, likely based on the next biblical story, which is of Sarah's death at 127 years, being 90 when Isaac was born, attributing this to her hearing the news of his intended sacrifice. The sacrifice of Isaac is cited in appeals for the mercy of God in later Jewish traditions. The post-biblical Jewish interpretations often elaborate the role of Isaac beyond the biblical description and primarily focus on Abraham's intended sacrifice of Isaac, called the (\"binding\"). According to a version of these interpretations, Isaac died in the sacrifice and was revived. According to many accounts of Aggadah, unlike the Bible, it is Satan who is testing Isaac as an agent of God. Isaac's willingness to follow God's command at the cost of his death has been a model for many Jews who preferred martyrdom to violation of the Jewish law.\nAccording to the Jewish tradition, Isaac instituted the afternoon prayer. This tradition is based on Genesis chapter 24, verse 63 (\"Isaac went out to meditate in the field at the eventide\").\nIsaac was the only patriarch who stayed in Canaan during his whole life and though once he tried to leave, God told him not to do so. Rabbinic tradition gave the explanation that Isaac was almost sacrificed and anything dedicated as a sacrifice may not leave the Land of Israel. Isaac was the oldest of the biblical patriarchs at the time of his death, and the only patriarch whose name was not changed.\nRabbinic literature also linked Isaac's blindness in old age, as stated in the Bible, to the sacrificial binding: Isaac's eyes went blind because the tears of angels present at the time of his sacrifice fell on Isaac's eyes.\nChristian views.\nThe early Christian church continued and developed the New Testament theme of Isaac as a type of Christ and the Church being both \"the son of the promise\" and the \"father of the faithful\". Tertullian draws a parallel between Isaac's bearing the wood for the sacrificial fire with Christ's carrying his cross. and there was a general agreement that, while all the sacrifices of the Old Law were anticipations of that on Calvary, the sacrifice of Isaac was so \"in a pre-eminent way\".\nThe Eastern Orthodox Church and the Roman Catholic Church consider Isaac as a saint along with other biblical patriarchs. Along with those of other patriarchs and the Old Testament Righteous, his feast day is celebrated in the Eastern Orthodox Church and the Byzantine rite of the Catholic Church on the Second Sunday before Christmas (December 11\u201317), under the title \"the Sunday of the Forefathers\".\nIsaac is commemorated in the Catholic Church on 25 March or on 17 December.\nNew Testament.\nThe New Testament states Isaac was \"offered up\" by his father Abraham, and that Isaac blessed his sons. Paul contrasted Isaac, symbolizing Christian liberty, with the rejected older son Ishmael, symbolizing slavery; Hagar is associated with the Sinai covenant, while Sarah is associated with the covenant of grace, into which her son Isaac enters. The Epistle of James chapter 2, verses 21\u201324, states that the sacrifice of Isaac shows that justification (in the Johannine sense) requires both faith and works.\nIn the Epistle to the Hebrews, Abraham's willingness to follow God's command to sacrifice Isaac is used as an example of faith as is Isaac's action in blessing Jacob and Esau with reference to the future promised by God to Abraham. In verse 19, the author views the release of Isaac from sacrifice as analogous to the resurrection of Jesus, the idea of the sacrifice of Isaac being a prefigurement of the sacrifice of Jesus on the cross.\nIslamic views.\nIslam considers Isaac () a prophet, and describes him as the father of the Israelites and a righteous servant of God.\nIsaac, along with Ishmael, is highly important for Muslims for continuing to preach the message of monotheism after his father Abraham. Among Isaac's children was the follow-up Israelite patriarch Jacob, who is also venerated as an Islamic prophet.\nIsaac is mentioned seventeen times by name in the Quran, often with his father and his son, Jacob. The Quran states that Abraham received \"good tidings of Isaac, a prophet, of the righteous\", and that God blessed them both ( https://). In a fuller description, when angels came to Abraham to tell him of the future punishment to be imposed on Sodom and Gomorrah, his wife, Sarah, \"laughed, and We gave her good tidings of Isaac, and after Isaac of (a grandson) Jacob\" ( https://); and it is further explained that this event will take place despite Abraham and Sarah's old age. Several verses speak of Isaac as a \"gift\" to Abraham (6:84; 14:49\u201350), and 24:26\u201327 adds that God made \"prophethood and the Book to be among his offspring\", which has been interpreted to refer to Abraham's two prophetic sons, his prophetic grandson Jacob, and his prophetic great-grandson Joseph. In the Quran, it later narrates that Abraham also praised God for giving him Ishmael and Isaac in his old age ( https://).\nElsewhere in the Quran, Isaac is mentioned in lists: Joseph follows the religion of his forefathers Abraham, Isaac and Jacob ( https://) and speaks of God's favor to them ( https://); Jacob's sons all testify their faith and promise to worship the God that their forefathers, \"Abraham, Ishmael and Isaac\", worshiped ( https://); and the Quran commands Muslims to believe in the revelations that were given to \"Abraham, Ishmael, Isaac, Jacob and the Patriarchs\" ( https://; https://). In the Quran's narrative of Abraham's near-sacrifice of his son ( https://), the name of the son is not mentioned and debate has continued over the son's identity, though many feel that the identity is the least important element in a story which is given to show the courage that one develops through faith.\nQuran.\nThe Quran mentions Isaac as a prophet and a righteous man of God. Isaac and Jacob are mentioned as being bestowed upon Abraham as gifts of God, who then worshipped God only and were righteous leaders in the way of God:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;And We bestowed on him Isaac and, as an additional gift, (a grandson), Jacob, and We made righteous men of every one (of them).\nAnd We made them leaders, guiding (men) by Our Command, and We sent them inspiration to do good deeds, to establish regular prayers, and to practise regular charity; and they constantly served Us (and Us only).\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;And WE gave him the glad tidings of Isaac, a Prophet, and one of the righteous.\nAcademic views.\nSome scholars have described Isaac as \"a legendary figure\" or \"as a figure representing tribal history,\u201d or \"as a seminomadic leader\". \nThe biblical historian A. Jopsen believes in the connection between the Isaac traditions and the north, and in support of this theory adduces Amos 7:9 (\"the high places of Isaac\").\nIsrael Finkelstein and Thomas R\u00f6mer have proposed that Isaac might be the ancestor worshipped in Beersheba and the oldest tradition about him might be an ancestor myth dating back to at least 8th century BCE as shown in Amos 7:9, while proposing that the story about him conflicting with Abimelech, king of Gerar, and Philistines, which is the story that has possibility that Abraham cycle could have vampirized or vice versa, could have been originated and have background in 7th century BCE, and could be made to aim at justifying and legitimizing the claim of Judah over the Judahite territories that are transferred to the Philistine cities by Sennacherib because of several reasons: it was time when Gerar (Tel Haror) had the special importance and fortified Assyrian administration center; there was king of Ashdod, Ahimilki, whose name is similar to that of Abimelech; the Kingdom of Judah could have gotten back parts of Judahite territories while Judah was a compliant vassal of Assyria under Manasseh. In addition, Finkelstein and R\u00f6mer proposed that Abraham might be the ancestor worshipped in Hebron, and Jacob might be the ancestor worshipped in Israel, but the earliest tradition of Jacob, the tradition about him and his uncle Laban the Aramean establishing the border between them, might be originated in Gilead.\nIn art.\nThe earliest Christian portrayal of Isaac is found in the Roman catacomb frescoes. Excluding the fragments, Alison Moore Smith classifies these artistic works in three categories:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "15193", "revid": "15881234", "url": "https://en.wikipedia.org/wiki?curid=15193", "title": "Italian Football League", "text": "Italian American football league\nItalian Football League (IFL; the name is in English) is the top level American football league in Italy first established in 1978. The first recognized league champion was crowned in 1980.\nThe annual final playoff game to determine the league champion is called the Italian Bowl, that awards, for American football, the title of \"champion of Italy\" and the \"scudetto\".\nBackground.\nIn Italy, the first American football game took place in Genoa on 27 November 1913 when the teams of the USS Connecticut and USS Kansas faced each other, two of the 14 ships of the American Great White Fleet temporarily docked in the Ligurian port during an exercise cruise in the Mediterranean Sea. USS Connecticut won 17\u20136.\nAfter this sporadic appearance, American football returned to Italy with the Allied troops during World War II. American football followed the advance of the US units from the south to the north of the Italian peninsula. On 23 November 1944, a touch football match was played at the Stadio della Vittoria in Bari, between the Playboys and the Technical School. The trophy, called the \"Bambino Bowl\", was won by the Technical School 13\u20130 in front of an audience of 5,000.\nA little over a month later, the Spaghetti Bowl was held in Florence in front of 25,000 people on New Year's Day 1945 between the Bridgebusters (representatives of the Twelfth Air Force) and the Mudders (United States Army North); the Mudders won 20\u20130. Although probably other matches were played in those years of which no documentation remains, the first in peacetime, took place in Trieste, the last territory liberated from the Nazi-Fascists, in January 1948. The match was organized by the Trieste United States Troops and saw the SP'S prevail over D Company by \"three touchdowns\" (then 21\u20130).\nHistory.\nIn the 1970s teams formed and played in Italy. The first American football championship organized in Italy, which was never recognized by the federation, took place in 1977 and was won by the Tori Torino. \nAmong the games played in the 1970s there was the first official match played between Italian American football teams in preparation for the first championship officially recognized by the federation; played on 24 June 1978 at the Stadio Carlo Speroni in Busto Arsizio, it was won 36\u20130 by the Rhinos Milano over the Gallarate Frogs.\nIn 1980 the first official American football league in Italy was established and crowned a champion. This championship did not include a final and was won by Lupi Roma. However, the title of first champions of Italy was recognized to the Lupi only in 2016.\nThe Italian league (Series A) in the late 1970s and early 1980s, was one of the first leagues in Europe to sign professional import players and coaches from the USA. The league had good popularity in the early years especially the late 1980s and early 1990s with reported attendance of nearly 20,000 fans for a Series A league final championship game in that time period. American Football in Italy has had ups and downs since that time but has always had a competitive league with different lower levels playing below the Italian Football League (IFL). \nThe new IFL was founded in 2007, taking over previous league's significance called (National Football League Italy). The league was born as a result of the escape of several of the best clubs of the old championship organized by the Italian federation, such as Milano Rhinos, Parma Panthers, Bologna Doves and Bolzano Giants. However some of the historic Italian clubs have not joined the new league and continue to participate in different tournaments organized by other federations. \nIn the following years a lot of teams moved to the Federazione Italiana di American Football (the federation the IFL belongs to) and most of the biggest teams are now again part of the IFL that is the First Division or in the other two divisions. \nThe Bergamo Lions have won the most Italian Super Bowl league championships winning 12 finals.\nOn Saturday, July 1, 2023, Italian Bowl XLII was played at the Glass Bowl Stadium on the campus of The University of Toledo, Toledo, Ohio, USA. This marked the first Italian Football League Championship held outside of Europe. The Parma Panthers won the game played in front of nearly 10,000 fans, and was televised in the United States.\nIFL teams.\n\u2020 defunct\n\u2666 due to league expansion the Napoli team can play the 2015 IFL season and is not relegated to the second division\n\u2021 Roma Grizzlies won the second division championship and earned the right to play the 2015 IFL season\nItalian Bowl.\nItalian Bowl is the annual final play-off game of the Italian Football League (IFL) to determine the league champion. It is the game that awards, for American football, the title of \"champion of Italy\" and the \"scudetto\". Until 2014 the championship game was called \"Italian Super Bowl\".\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "15195", "revid": "27335766", "url": "https://en.wikipedia.org/wiki?curid=15195", "title": "Iduna", "text": "Iduna may refer to:\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "15196", "revid": "212624", "url": "https://en.wikipedia.org/wiki?curid=15196", "title": "Infra-red radiation", "text": ""}
{"id": "15197", "revid": "38179619", "url": "https://en.wikipedia.org/wiki?curid=15197", "title": "Infra-red", "text": ""}
{"id": "15198", "revid": "48343365", "url": "https://en.wikipedia.org/wiki?curid=15198", "title": "Indic", "text": "Indic may refer to:\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "15199", "revid": "36679905", "url": "https://en.wikipedia.org/wiki?curid=15199", "title": "Papua (province)", "text": "Province in Western New Guinea, Indonesia\nPapua, formerly known as West Irian and Irian Jaya, is a province of Indonesia, comprising the northern coast of Western New Guinea together with island groups in Cenderawasih Bay to the west. It roughly follows the borders of the Papuan customary region of Mamta \u2013 Tabi Saireri and is divided into eight regencies () and one city (\"kota\"), the latter being the provincial capital of Jayapura.\nIt is bordered by the nation of Papua New Guinea to the east, the Pacific Ocean to the north, Cenderawasih Bay to the west, and the provinces of Central Papua and Highland Papua to the south. The province also shares maritime boundaries with Palau in the Pacific. Papua, along with the five other Papuan provinces, has a higher degree of autonomy compared to other Indonesian provinces.\nBefore 2003, the province (known as Irian Barat from 1963 to 1973 and Irian Jaya from 1973 to 2002) covered the entirety of Western New Guinea, a region also known as \"Papua\". In 2002, Papua adopted its current name and was granted a special autonomous status under Indonesian legislation. In 2001, the western end of the province was split off into a new province of West Papua, and in July 2022 the provinces of Central Papua, Highland Papua, and South Papua were also split off, leaving the current province covering a much smaller northern area around Jayapura, the northern part of the former province, and the islands in the Cenderawasih Bay.\nThe official estimate of the population in mid-2024 of the province under its current borders was 1,060,550 (comprising 554,800 males and 505,800 females).\nPolitics.\nGovernment.\nThe province of Papua is governed by a directly elected governor and a regional legislature,the People's Representative Council of Papua (\"Dewan Perwakilan Rakyat Papua\", abbreviated as DPRP or DPR Papua). A unique government organization in the province is the Papuan People's Assembly (\"Majelis Rakyat Papua\"), which was formed by the Indonesian government in 2005, as mandated by the Papua Special Autonomy Law, as a coalition of Papuan tribal chiefs, Papuan religious leaders, and Papuan women representatives, tasked with arbitration and speaking on behalf of Papuan tribal customs.\nSince 2014, the DPRP had 55 members who are elected through General elections every five years and 14 people who are appointed through special autonomy, bringing the total number of DPRP members to 69 people. The DPRP leadership consists of 1 Chairperson and 3 Deputy Chairmen who come from political parties that have the most seats and votes. The current DPRP members are the results of the 2019 General Election which was sworn in on 31 October 2019 by the Chairperson of the Jayapura High Court at the Papua DPR Building. The composition of DPRP members for the 2019\u20132024 period consists of 13 political parties where the NasDem Party is the political party with the most seats, with 8 seats, followed by the Democratic Party which also won 8 seats and the Indonesian Democratic Party of Struggle which won 7 seats.\nThe province of Papua is one of seven provinces to have obtained special autonomy status, the others being Aceh, West Papua, Southwest Papua, Central Papua, Highland Papua and South Papua (the Special Regions of Jakarta and Yogyakarta have similar province-level special status). According to Law 21/2001 on Special Autonomy Status \"(UU Nomor 21 Tahun 2001 tentang Otonomi khusus Papua),\" the provincial government of Papua is provided with authority within all sectors of administration, except for the five strategic areas of foreign affairs, security and defense, monetary and fiscal affairs, religion and justice. The provincial government is authorized to issue local regulations to further stipulate the implementation of the special autonomy, including regulating the authority of districts and municipalities within the province. Due to its special autonomy status, Papua province is provided with a significant amount of special autonomy funds, which can be used to benefit its indigenous peoples. However, the province has low fiscal capacity and it is highly dependent on unconditional transfers and the above-mentioned special autonomy fund, which accounted for about 55% of total revenues in 2008.\nAfter obtaining its special autonomy status, to allow the local population access to timber production benefits, the Papuan provincial government issued several decrees, enabling:\nAdministrative divisions.\nAs of 2022 (following the separation of Central Papua, Highland Papua, and South Papua province), the residual Papua Province consisted of 8 regencies () and one city (\"kota\"); on the map below, these regencies comprise the northern belt from Waropen Regency to Keerom Regency, plus the island groups to their northwest. Initially, the area now forming the present Papua Province contained three regencies \u2013 Jayapura, Yapen Waropen and Biak Numfor. The City of Jayapura was separated on 2 August 1993 from Jayapura Regency and formed into a province-level administration. On 11 December 2002, three new regencies were created \u2013 Keerom and Sarmi from parts of Jayapura Regency, and Waropen from part of Yapen Waropen Regency (the rest of this regency was renamed as Yapen Islands). On 18 December 2003 a further regency \u2013 Supiori \u2013 was created from part of Biak Numfor Regency, and on 15 March 2007 a further regency \u2013 Mamberamo Raya \u2013 was created from the western part of Sarmi Regency. These regencies and the city are together subdivided into districts (\"distrik\"), and thence into \"villages\" (\"kelurahan\" and \"desa\"). With the release of Act Number 21 of 2001 concerning the Special Autonomous Region of Papua Province, the term \"distrik\" was used instead of \"kecamatan\" in the entire Western New Guinea. The difference between the two is merely the terminology, with \"kepala distrik\" being the district head.\nThe regencies () and the city (\"kota\") are listed below with their areas and their populations at the 2020 census and subsequent official estimates for mid-2024, together with the 2020 Human Development Index of each administrative division.\nThe province now forms one of Indonesia's 84 national electoral districts to elect members to the People's Representative Council. The Papua Electoral District consists of all of the 8 regencies in the province, together with the city of Jayapura, and elects 3 members to the People's Representative Council.\nGeography.\nThe province of Papua is located between 2 \u00b0 25' \u2013 9 \u00b0 S and 130 \u00b0 \u2013 141 \u00b0 East. The total area of Papua is now . Until its division in 2022 into four provinces, Papua province was the province that had the largest area in Indonesia, with a total area of 312,816.35\u00a0km2, or 19.33% of the total area of the Indonesian archipelago. The boundaries of Papua are: the Pacific Ocean (north), Highland Papua (south), Central Papua (Southwest), and Papua New Guinea (east).\nDemographics.\n&lt;templatestyles src=\"Module:Historical populations/styles.css\"/&gt;\nWhile the Papuan branch of the Central Agency on Statistics had earlier projected the 2020 population of the province (as constituted at that time) to be 3,435,430 people the actual census in 2020 revealed a total population of 4,303,707, of which the majority were Christian. The official estimate for mid-2022 was 4,418,581 before the division of the province into four separate provinces. , spread throughout 28 regencies and one administrative city. Following the division of the province into 4 separate provinces, the city of Jayapura is the most populated administrative division in the province, with a total of 420,580 people in mid-2024, while Supiori Regency, which comprises mainly the island of Supiori, one of the Schouten Islands within Cenderawasih Bay off the north coast of Papua, is the least populated administrative division in the province, with just 24,530 people. Most of the population in the province is concentrated in coastal regions, especially around the city of Jayapura and its suburbs.\nReligion.\n&lt;templatestyles src=\"Pie chart/styles.css\"/&gt;\nAccording to Indonesian Citizenship and Civil Registry in 2022, 70.15% of the Papuans identified themselves as Christians, with 64.68% being Protestants and 5.47% being Catholics. 29.56% of the population are Muslims and less than 1% are Buddhists or Hindus.\nCulture.\nThe native Papuan people have a distinct culture and traditions that cannot be found in other parts of Indonesia. Coastal Papuans are usually more willing to accept modern influence into their daily lives, which in turn diminishes their original culture and traditions. Meanwhile, most inland Papuans still preserve their original culture and traditions, although their way of life over the past century is tied to the encroachment of modernity and globalization. Each Papuan tribe usually practices its tradition and culture, which may differ greatly from one tribe to another.\nThe \"Ararem\" tradition is the tradition of delivering the dowry of a future husband to the family of the prospective wife in the Biak custom. In the Biak language, the word \"Ararem\" means dowry. In this procession, the bride and groom will be escorted on foot in a procession, accompanied by songs and dances accompanied by music. The amount of the dowry is determined by the woman's family as agreed by her relatives. The date of submission of the dowry must be agreed upon by the family of the woman or the family of the prospective wife and the family of the man or the family of the prospective husband. In the tradition of the Biak people, the payment of the dowry is a tradition that must be obeyed because it involves the consequences of a marriage.\nArts and performance.\nThere are many traditional dances native to Papua, and each Papuan tribe usually has their own unique traditional dances.\nThe \"Yospan\" dance () is a type of traditional and social association dance originating from the coastal regions of Papua, namely Biak, Yapen, and Waropen; it is often performed by young people as a form of friendship. Initially, the \"Yospan\" dance originated from two dances called \"Yosim\" and \"Pancar\", which were eventually combined into one\u2014hence, \"Yospan\" is an acronym of the words \"Yosim\" and \"Pancar\". When performing the \"Yosim\" dance, originally from Yapen and Waropen, the dancers often invited other residents to listen. The instruments usually consist of ukulele and guitar, neither of which are native to Papua, as well as a form of bass with three strings made from rolled pandanus fibers leaf found in coastal forest. A musical instrument called \"kalabasa\" is also played during the dance, made of dried calabash, and then filled with beads or small stones that are shaken to produce sound. Female dancers wear woven sarongs to cover their chests, and decorative heads with flowers and bird feathers. Meanwhile, the male dancers would usually wear shorts, open chests, and with heads also decorated with bird feathers. The \"Pancar\" dance originating from Biak is only accompanied by a \"tifa\", the traditional musical instrument of the coastal tribes in Papua.\nThe dance is performed on boats by the inhabitants who live around Lake Sentani in Jayapura Regency, and is danced to symbolize the harmony between different tribes in Papua. Boat dancing is a tradition of various Papuan peoples, especially among the Sentani people, where the dance is performed in various villages. The word consists of two words in the Sentani language: , meaning to rejoice and dance with joy, and (or ), meaning a group of people from all ages who dance; thus means a group of people who dance with joy. The dance of the Sentani is usually performed by (traditional leaders) and the village community to present a gift to other . Valuable items are offered, such as large wild boar, garden products, girls to be married, and other traditional gifts. However, besides being a form of respect for the , the dance is nowadays more of a Sentani performative dance, and a popular attraction at the annual Sentani Lake Festival.\nEach Papuan tribe usually has its own war dance, one of the oldest forms of Papuan dance. In Papuan culture, these dances are a symbol of Papuan strength and bravery; allegedly, this dance was once a part of traditional ceremonies when fighting other tribes.\nAnother traditional dance common to most Papuan tribes is the \"musyoh\" dance, the emergence of which is based on an old myth. In ancient times, when a tribal member died due to an accident or something unexpected, the Papuan people believed that the evil spirit () of the person who died was still roaming and unsettled. To overcome this, the Papuan tribesmen created an exorcism ritual in the form of the \"musyoh\" dance, and it is thus often referred to as an exorcism dance. Besides exorcism, the \"musyoh\" dance is also used for other purposes, such as welcoming guests, and can be a symbol of respect and gratitude, and an expression of happiness. If being done for exorcism, the \"musyoh\" dance is performed by men, but in the case of welcoming guests, it is performed by both men and women. The dancers wear simple costumes, consisting of head coverings, tops, and bottoms, made from processed tree bark and plant roots. These are then adorned with bracelets, necklaces, and body paint on the dancers' bodies.\nArchitecture.\nThe \"kariwari\" is one of the traditional Papuan houses, more precisely the traditional house of the Tobati-Enggros people who live around Yotefa Bay and Lake Sentani near Jayapura. Unlike other forms of Papuan traditional houses, such as the round \"honai,\" the \"kariwari\" is usually constructed in the shape of an octagonal pyramid. \"Kariwari\" is usually made of, bamboo, ironwood and forest sago leaves. The Kariwari house consists of two floors and three rooms or three rooms, each with different functions. The \"kariwari\" is not like a \"honai\" that can be lived in by anyone, it cannot even be the residence of a tribal chief \u2013 unlike the \"honai\" which has political and legal functions. The \"kariwari\" is specifically a place of education and worship, therefore the position of the \"Kariwari\" in the community of the Tobati-Enggros people is considered a sacred and holy place. Like traditional houses in general, the \"kariwari\" also has a design that is full of decorative details that make it unique, of course, the decorations are related to Papuan culture especially from the Tobati-Enggros. The decorations found in the \"kariwari\" are usually in the form of works of art, among others; paintings, carvings and also sculptures. Apart from being decorated with works of art, the \"kariwari\" is also decorated with various weapons, such as; a bow and arrow. There are also some skeletons of prey animals, usually in the form of wild boar fangs, kangaroo skeletons, turtle or turtle shells, birds-of-paradise, and so on.\n\"Rumsram\" is the traditional house of the Biak Numfor people on the northern coast of Papua. This house was originally intended for men, while women were prohibited from entering or approaching it. Its function is similar to the \"kariwari\", namely as a place for activities in teaching and educating men who are starting to be teenagers, in seeking life experiences. The building is square with a roof in the shape of an upside-down boat because of the background of the Biak Numfor tribe who work as sailors. The materials used are bark for floors, split and chopped water bamboo for walls, while the roof is made of dried sago leaves. The walls are made of sago leaves. The original \"rumsram\" wall only had a few windows and its position was at the front and back. A \"rumsram\" usually has a height of approximately 6\u20138 m and is divided into two parts, differentiated by floor levels. The first floor is open and without walls. Only the building columns were visible. In this place, men are educated to learn sculpting, shielding, boat building, and war techniques. In a traditional ceremony called \"Wor Kapanaknik\", which in the Biak language means \"to shave a child's hair\", a traditional ritual is usually carried out when boys are 6\u20138 years old. The age when a child is considered to be able to think and the child has started to get an education in the search for life experiences, as well as how to become a strong and responsible man as the head of the family later. The children would then enter a \"rumsram\", hence the rite of passage is also called \"rumsram,\" because the ritual is carried out in the \"rumsram\".\nTraditional weapons.\nThe cuscus bone skewer is a traditional Papuan weapon used by one of the indigenous Papuan tribes, namely the Bauzi people. The Bauzi people still maintain their tradition of hunting and gathering. The weapon they use to hunt animals while waiting for the harvest to arrive is a piercing tool made of cuscus bones. The use of cuscus bones as a traditional weapon is very environmentally friendly. This happens because, in its manufacture, it does not require the help of industrial equipment that pollutes the environment. This traditional weapon is made from cleaned cuscus bone (before the meat is eaten and separated from the bone), sharpened by rubbing it with a whetstone, and repeated so that the desired sharpness is formed.\nPapuan knife blades are usually used for slashing or cutting when hunting animals in the forest. Even though the animals they face are large mammals and crocodiles, the Papuan people still adhere to prevailing customs. The custom is that it is not permissible to use any kind of firearm when hunting. Papuan daggers are knives made of unique materials and are difficult to obtain in other areas, namely the bones of an endemic animal to Papua, the cassowary. Cassowary bones are used by local culture to become a tool that has beneficial values for life. Apart from that, the feathers attached to the blade's handle are also the feathers of the cassowary.\nThe spear is referred to by the local community of Sentani as . The spear was a weapon that could be used for both fighting and hunting. In addition, Papuan culture often uses the spear as a property in dances. The weapons mentioned above are made from basic materials that are easily found in nature. Wood to make the handle, and a river stone that was sharpened as a spearhead. For that reason, the spear can survive as a weapon that must be present in hunting and fighting activities. What makes this traditional Papuan weapon feel special is that there is a rule not to use a spear other than for hunting and fighting purposes. For example, it is forbidden to cut young tree shoots with a spear or to use a spear to carry garden produce. If this rule was broken, the person who wielded this spear would have bad luck. Meanwhile, in the manufacturing process, this spear frame takes a long time. Starting from the wood taken from the tree \"kayu swang\" with a diameter of 25\u00a0cm. After drying it in the sun, the wood is split into four and shaped so it has a rounded cross-section, then the tip is shaped until it formed a two-sided and leaf shaped spear-tip.\nThe bow and arrow is a traditional Papuan weapon locally in Sentani called that has uses for hunting wild boar and other animals. The arrowheads are made from the bark of a sago tree, the bow is made from a type of wild betel nut tree which can also be made the arrowheads, the shaft is made from a type of grass, small-sized bamboo which do not have cavity and rattan as the bowstring. Depending on the phase of for battle there are variety of arrow type, is a plain sharp arrow with no decoration to lure the enemy; is a sharp arrow which have one serrated sided tip and the other plain, used to shoot seen enemy that is getting closer; is an arrow with both sides serrated, used for enemy that is getting closer still; is an arrow with three sided serrated tip, used for a really close enemy; is an arrow with four-sided serrated arrowhead, used only after depleted; is an arrow with two-sided arrowhead, with three large teeth, and hole in the middle, only used to kill enemy chieftain. In addition, for hunting three kinds of arrows are used, which have similar characteristic as war other than different shape; is an arrow with two-pronged tip; and is an arrow with three-pronged tip.\nThe Papuan parang called in Sentani is made from old \"swang\" wood, take 2\u20133 days to make and can be made before or after drying the wood. It can be used for household purposes, namely cooking, cutting meat, cutting vegetables and cutting down sago. In addition, Papuan machetes are also used in the agricultural industry and be used as a collection. Usually it will have carving symbolizing prosperity for humans or prosperity for animals.\nSentani oars are traditional tools called for males and for females. They are made from \"swang\" wood and the bark of sago trees. The wood was split to create flat surface and then shaped like an oar, with the tip made thinner and sharper. It primarily functioned as an oar to propel canoes forward, but under attack from enemies from the seas it can be used as spear because of its sharp tip. Usually oars have ornamental engravings shaped like a finger called to symbolize unity of strength of ten fingers to power the oars.\nStone axes from Sentani are called usually made from river stones secured to the handle with rattan. Usually it was made from \"batu pualan\" (marble) which was then shaped with another stone by chipping slowly. According local tradition the making of the stone have to be done secretly from the family, and can take up to 2 months. For the handle it was constructed using \"swang\" wood or ironwood. One part was to secure the axe head and another for the handle, with all parts tied together using rattan. the axe are usually made for cutting down trees and canoes building, however currently used more often as collections.\nMusic and handicrafts.\nTifa is a traditional Papuan musical instrument that is played by beating. Unlike those from Maluku, this musical instrument from Papua is usually longer and has a handle on one part of the instrument. Meanwhile, the tifa from Maluku has a wide size and there is no handle on the side. The material used also comes from the strongest wood, usually the type of Lenggua wood (\"Pterocarpus indicus)\" with animal skin as the upper membrane. The animal's skin is tied with rattan in a circle so that it is tight and can produce a beautiful sound. In addition, on the body part of the musical instrument there is a typical Papuan carving. Tifa is usually used to accompany guest welcoming events, traditional parties, dances, etc. The size of the sound that comes out of the drum depends on the size of the instrument. Apart from being a means of accompanying the dance, the tifa also has a social meaning based on the function and shape of the carved ornaments on the body of the tifa. In the culture of the Marind-Anim people in Merauke, each clan has its own shape and motif as well as a name for each tifa. The same goes for the Biak and Waropen people.\nThe triton is a traditional Papuan musical instrument that is played by blowing it. This musical instrument is found throughout the coast, especially in the Biak, Yapen, Waropen and Nabire. Initially, this tool was only used as a means of communication or as a means of calling and signaling. Currently this instrument is also used as a means of entertainment and traditional musical instruments.\nCuisine.\nThe native Papuan food usually consists of roasted boar with Tubers such as sweet potato. The staple food of Papua and eastern Indonesia in general is sago, as the counterpart of central and western Indonesian cuisines that favour rice as their staple food. Sago is either processed as a pancake or sago congee called \"papeda\", usually eaten with yellow soup made from tuna, red snapper or other fishes spiced with turmeric, lime, and other spices. On some coasts and lowlands on Papua, sago is the main ingredient to all the foods.\nIn the coastal regions, seafood is the main food for the local people. One of the famous sea foods from Papua is fish wrap (Indonesian: \"Ikan Bungkus\"). Wrapped fish in other areas is called \"Pepes ikan.\" Wrapped fish from Papua is known to be very fragrant. This is because there are additional bay leaves so that the mixture of spices is more fragrant and soaks into the fish meat. The basic ingredient of Papuan wrapped fish is sea fish, the most commonly used fish is milkfish. Milkfish is suitable for \"wrap\" because it has meat that does not crumble after processing. The spices are sliced or cut into pieces, namely, red and bird's eye chilies, bay leaves, tomatoes, galangal, and lemongrass stalks. While other spices are turmeric, garlic and red, red chilies, coriander, and hazelnut. The spices are first crushed and then mixed or smeared on the fish. The wrapping is in banana leaves.\nCommon Papuan snacks are usually made out of sago. Kue bagea (also called sago cake) is a cake originating from Ternate in North Maluku, although it can also be found in Papua. It has a round shape and creamy color. Bagea has a hard consistency that can be softened in tea or water, to make it easier to chew. It is prepared using sago, a plant-based starch derived from the sago palm or sago cycad. \"Sagu Lempeng\" is a typical Papuan snacks that is made in the form of processed sago in the form of plates. \"Sagu Lempeng\" are also a favorite for travelers. But it is very difficult to find in places to eat because this bread is a family consumption and is usually eaten immediately after cooking. Making sago plates is as easy as making other breads. Sago is processed by baking it by printing rectangles or rectangles with iron which is ripe like white bread. Initially tasteless, but recently it has begun to vary with sugar to get a sweet taste. It has a tough texture and can be enjoyed by mixing it or dipping it in water to make it softer. Sago porridge is a type of porridge that are found in Papua. This porridge is usually eaten with yellow soup made of mackerel or tuna then seasoned with turmeric and lime. Sago porridge is sometimes also consumed with boiled tubers, such as those from cassava or sweet potato. Vegetable papaya flowers and saut\u00e9ed kale are often served as side dishes to accompany the sago porridge. In the coastal regions, Sago worms are usually served as a type of snack dish. Sago worms come from sago trunks which are cut and left to rot. The rotting stems cause the worms to come out. The shape of the sago worms varies, ranging from the smallest to the largest size of an adult's thumb. These sago caterpillars are usually eaten alive or cooked beforehand, such as stir-frying, cooking, frying and then skewered. But over time, the people of Papua used to process these sago caterpillars into sago caterpillar satay. To make satay from this sago caterpillar, the method is no different from making satay in general, namely on skewers with a skewer and grilled over hot coals.\nCoat of arms.\nThe coat of arms of Papua is shaped like a five-sided shield, symbolizing vigilance and resilience. The five sides represent the principles of Pancasila, the philosophical foundation of Indonesia.\nInside the shield, there are three monuments standing on a pile of stones arranged in groups of 6 and 9, symbolizing the struggle of Trikora and the \"Penentuan Pendapat Rakyat\" held in 1969.\nOn both sides are rice and cotton, with 7 grains of rice and 8 cotton buds, tied together with a ribbon folded 4 times with 5 tassels. Altogether, these elements represent the Proclamation of Indonesian Independence on 17 August 1945.\nAt the top, three snow-capped mountains of equal height are depicted, representing the natural features and identity of Papua Province.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "15200", "revid": "13286072", "url": "https://en.wikipedia.org/wiki?curid=15200", "title": "IMF (disambiguation)", "text": "The IMF is the International Monetary Fund, an international organization.\nIMF may also refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nOther uses.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "15201", "revid": "199747", "url": "https://en.wikipedia.org/wiki?curid=15201", "title": "Interdisciplinarity", "text": "Combination of two or more academic disciplines into one activity\n \nInterdisciplinarity or interdisciplinary studies involves the combination of multiple academic disciplines into one activity (e.g., a research project). It draws knowledge from several fields such as sociology, anthropology, psychology, economics, etc. It is related to an \"interdiscipline\" or an \"interdisciplinary field,\" which is an organizational unit that crosses traditional boundaries between academic disciplines or schools of thought, as new needs and professions emerge. Large engineering teams are usually interdisciplinary, as a power station or mobile phone or other project requires the melding of several specialties. However, the term \"interdisciplinary\" is sometimes confined to academic settings.\nThe term \"interdisciplinary\" is applied within education and training pedagogies to describe studies that use methods and insights of several established disciplines or traditional fields of study. Interdisciplinarity involves researchers, students, and teachers in the goals of connecting and integrating several academic schools of thought, professions, or technologies\u2014along with their specific perspectives\u2014in the pursuit of a common task. The epidemiology of HIV/AIDS or global warming requires understanding of diverse disciplines to solve complex problems. \"Interdisciplinary\" may be applied where the subject is felt to have been neglected or even misrepresented in the traditional disciplinary structure of research institutions, for example, women's studies or ethnic area studies. Interdisciplinarity can likewise be applied to complex subjects that can only be understood by combining the perspectives of two or more fields. \nThe adjective \"interdisciplinary\" is most often used in educational circles when researchers from two or more disciplines pool their approaches and modify them so that they are better suited to the problem at hand, including the case of the team-taught course where students are required to understand a given subject in terms of multiple traditional disciplines. Interdisciplinary education fosters cognitive flexibility and prepares students to tackle complex, real-world problems by integrating knowledge from multiple fields. This approach emphasizes active learning, critical thinking, and problem-solving skills, equipping students with the adaptability needed in an increasingly interconnected world. For example, the subject of land use may appear differently when examined by different disciplines, for instance, biology, chemistry, economics, geography, and politics.\nDevelopment.\nAlthough \"interdisciplinary\" and \"interdisciplinarity\" are frequently viewed as twentieth century terms, the concept has historical antecedents, most notably Greek philosophy. Julie Thompson Klein attests that \"the roots of the concepts lie in a number of ideas that resonate through modern discourse\u2014the ideas of a unified science, general knowledge, synthesis and the integration of knowledge\", while Giles Gunn says that Greek historians and dramatists took elements from other realms of knowledge (such as medicine or philosophy) to further understand their own material. The building of Roman roads required men who understood surveying, material science, logistics and several other disciplines. Any broadminded humanist project involves interdisciplinarity, and history shows a crowd of cases, as seventeenth-century Leibniz's task to create a system of universal justice, which required linguistics, economics, management, ethics, law philosophy, politics, and even sinology.\nInterdisciplinary programs sometimes arise from a shared conviction that the traditional disciplines are unable or unwilling to address an important problem. For example, social science disciplines such as anthropology and sociology paid little attention to the social analysis of technology throughout most of the twentieth century. As a result, many social scientists with interests in technology have joined science, technology and society programs, which are typically staffed by scholars drawn from numerous disciplines. They may also arise from new research developments, such as nanotechnology, which cannot be addressed without combining the approaches of two or more disciplines. Examples include quantum information processing, an amalgamation of quantum physics and computer science, and bioinformatics, combining molecular biology with computer science. Sustainable development as a research area deals with problems requiring analysis and synthesis across economic, social and environmental spheres; often an integration of multiple social and natural science disciplines. Interdisciplinary research is also key to the study of health sciences, for example in studying optimal solutions to diseases. Some institutions of higher education offer accredited degree programs in Interdisciplinary Studies.\nAt another level, interdisciplinarity is seen as a remedy to the harmful effects of excessive specialization and isolation in information silos. On some views, however, interdisciplinarity is entirely indebted to those who specialize in one field of study\u2014that is, without specialists, interdisciplinarians would have no information and no leading experts to consult. Others place the focus of interdisciplinarity on the need to transcend disciplines, viewing excessive specialization as problematic both epistemologically and politically. When interdisciplinary collaboration or research results in new solutions to problems, much information is given back to the various disciplines involved. Therefore, both disciplinarians and interdisciplinarians may be seen in complementary relation to one another.\nBarriers.\nBecause most participants in interdisciplinary ventures were trained in traditional disciplines, they must learn to appreciate differences of perspectives and methods. For example, a discipline that places more emphasis on quantitative rigor may produce practitioners who are more scientific in their training than others; in turn, colleagues in \"softer\" disciplines who may associate quantitative approaches with difficulty grasp the broader dimensions of a problem and lower rigor in theoretical and qualitative argumentation. An interdisciplinary program may not succeed if its members remain stuck in their disciplines (and in disciplinary attitudes). Those who lack experience in interdisciplinary collaborations may also not fully appreciate the intellectual contribution of colleagues from those disciplines. From the disciplinary perspective, however, much interdisciplinary work may be seen as \"soft\", lacking in rigor, or ideologically motivated; these beliefs place barriers in the career paths of those who choose interdisciplinary work. For example, interdisciplinary grant applications are often refereed by peer reviewers drawn from established disciplines; interdisciplinary researchers may experience difficulty getting funding for their research. In addition, untenured researchers know that, when they seek promotion and tenure, it is likely that some of the evaluators will lack commitment to interdisciplinarity. They may fear that making a commitment to interdisciplinary research will increase the risk of being denied tenure.\nInterdisciplinary programs may also fail if they are not given sufficient autonomy. For example, interdisciplinary faculty are usually recruited to a joint appointment, with responsibilities in both an interdisciplinary program (such as women's studies) and a traditional discipline (such as history). If the traditional discipline makes the tenure decisions, new interdisciplinary faculty will be hesitant to commit themselves fully to interdisciplinary work. Other barriers include the generally disciplinary orientation of most scholarly journals, leading to the perception, if not the fact, that interdisciplinary research is hard to publish. In addition, since traditional budgetary practices at most universities channel resources through the disciplines, it becomes difficult to account for a given scholar or teacher's salary and time. During periods of budgetary contraction, the natural tendency to serve the primary constituency (i.e., students majoring in the traditional discipline) makes resources scarce for teaching and research comparatively far from the center of the discipline as traditionally understood. For these same reasons, the introduction of new interdisciplinary programs is often resisted because it is perceived as a competition for diminishing funds.\nDue to these and other barriers, interdisciplinary research areas are strongly motivated to become disciplines themselves. If they succeed, they can establish their own research funding programs and make their own tenure and promotion decisions. In so doing, they lower the risk of entry. Examples of former interdisciplinary research areas that have become disciplines, many of them named for their parent disciplines, include neuroscience, cybernetics, biochemistry and biomedical engineering. These new fields are occasionally referred to as \"interdisciplines\". On the other hand, even though interdisciplinary activities are now a focus of attention for institutions promoting learning and teaching, as well as organizational and social entities concerned with education, they are practically facing complex barriers, serious challenges and criticism. The most important obstacles and challenges faced by interdisciplinary activities in the past two decades can be divided into \"professional\", \"organizational\", and \"cultural\" obstacles.\nInterdisciplinary studies and studies of interdisciplinarity.\nAn initial distinction should be made between interdisciplinary studies, which can be found spread across the academy today, and the study of interdisciplinarity, which involves a much smaller group of researchers. The former is instantiated in thousands of research centers across the US and the world. The latter has one US organization, the Association for Interdisciplinary Studies (founded in 1979), two international organizations, the International Network of Inter- and Transdisciplinarity (founded in 2010) and the Philosophy of/as Interdisciplinarity Network (founded in 2009). The US's research institute devoted to the theory and practice of interdisciplinarity, the Center for the Study of Interdisciplinarity at the University of North Texas, was founded in 2008 but is closed as of 1 September 2014, the result of administrative decisions at the University of North Texas.\nAn interdisciplinary study is an academic program or process seeking to synthesize broad perspectives, knowledge, skills, interconnections, and epistemology in an educational setting. Interdisciplinary programs may be founded in order to facilitate the study of subjects which have some coherence, but which cannot be adequately understood from a single disciplinary perspective (for example, women's studies or medieval studies). More rarely, and at a more advanced level, interdisciplinarity may itself become the focus of study, in a critique of institutionalized disciplines' ways of segmenting knowledge.\nIn contrast, studies of interdisciplinarity raise to self-consciousness questions about how interdisciplinarity works, the nature and history of disciplinarity, and the future of knowledge in post-industrial society. Researchers at the Center for the Study of Interdisciplinarity have made the distinction between philosophy 'of' and 'as' interdisciplinarity, the former identifying a new, discrete area within philosophy that raises epistemological and metaphysical questions about the status of interdisciplinary thinking, with the latter pointing toward a philosophical practice that is sometimes called 'field philosophy'.\nPerhaps the most common complaint regarding interdisciplinary programs, by supporters and detractors alike, is the lack of synthesis\u2014that is, students are provided with multiple disciplinary perspectives but are not given effective guidance in resolving the conflicts and achieving a coherent view of the subject. Others have argued that the very idea of synthesis or integration of disciplines presupposes questionable politico-epistemic commitments. Critics of interdisciplinary programs feel that the ambition is simply unrealistic, given the knowledge and intellectual maturity of all but the exceptional undergraduate; some defenders concede the difficulty, but insist that cultivating interdisciplinarity as a habit of mind, even at that level, is both possible and essential to the education of informed and engaged citizens and leaders capable of analyzing, evaluating, and synthesizing information from multiple sources in order to render reasoned decisions.\nWhile much has been written on the philosophy and promise of interdisciplinarity in academic programs and professional practice, social scientists are increasingly interrogating academic discourses on interdisciplinarity, as well as how interdisciplinarity actually works\u2014and does not\u2014in practice. Some have shown, for example, that some interdisciplinary enterprises that aim to serve society can produce deleterious outcomes for which no one can be held to account.\nPolitics of interdisciplinary studies.\nSince 1998, there has been an ascendancy in the value of interdisciplinary research and teaching and a growth in the number of bachelor's degrees awarded at U.S. universities classified as multi- or interdisciplinary studies. The number of interdisciplinary bachelor's degrees awarded annually rose from 7,000 in 1973 to 30,000 a year by 2005 according to data from the National Center of Educational Statistics (NECS). In addition, educational leaders from the Boyer Commission to Carnegie's President Vartan Gregorian to Alan I. Leshner, CEO of the American Association for the Advancement of Science have advocated for interdisciplinary rather than disciplinary approaches to problem-solving in the 21st century. This has been echoed by federal funding agencies, particularly the National Institutes of Health under the direction of Elias Zerhouni, who has advocated that grant proposals be framed more as interdisciplinary collaborative projects than single-researcher, single-discipline ones.\nAt the same time, many thriving longstanding bachelor's in interdisciplinary studies programs in existence for 30 or more years, have been closed down, in spite of healthy enrollment. Examples include Arizona International (formerly part of the University of Arizona), the School of Interdisciplinary Studies at Miami University, and the Department of Interdisciplinary Studies at Wayne State University; others such as the Department of Interdisciplinary Studies at Appalachian State University, and George Mason University's New Century College, have been cut back. Stuart Henry has seen this trend as part of the hegemony of the disciplines in their attempt to recolonize the experimental knowledge production of otherwise marginalized fields of inquiry. This is due to threat perceptions seemingly based on the ascendancy of interdisciplinary studies against traditional academia.\nHistorical examples.\nThere are many examples of when a particular idea, almost in the same period, arises in different disciplines. One case is the shift from the approach of focusing on \"specialized segments of attention\" (adopting one particular perspective), to the idea of \"instant sensory awareness of the whole\", an attention to the \"total field\", a \"sense of the whole pattern, of form and function as a unity\", an \"integral idea of structure and configuration\". This has happened in painting (with cubism), physics, poetry, communication and educational theory. According to Marshall McLuhan, this paradigm shift was due to the passage from an era shaped by mechanization, which brought sequentiality, to the era shaped by the instant speed of electricity, which brought simultaneity.\nEfforts to simplify and defend the concept.\nAn article in the \"Social Science Journal\" attempts to provide a simple, common-sense, definition of interdisciplinarity, bypassing the difficulties of defining that concept and obviating the need for such related concepts as transdisciplinarity, pluridisciplinarity, and multidisciplinary:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;To begin with, a discipline can be conveniently defined as any comparatively self-contained and isolated domain of human experience which possesses its own community of experts. Interdisciplinarity is best seen as bringing together distinctive components of two or more disciplines. In academic discourse, interdisciplinarity typically applies to four realms: knowledge, research, education, and theory. Interdisciplinary knowledge involves familiarity with components of two or more disciplines. Interdisciplinary research combines components of two or more disciplines in the search or creation of new knowledge, operations, or artistic expressions. Interdisciplinary education merges components of two or more disciplines in a single program of instruction. Interdisciplinary theory takes interdisciplinary knowledge, research, or education as its main objects of study.\nIn turn, interdisciplinary \"richness\" of any two instances of knowledge, research, or education can be ranked by weighing four variables: number of disciplines involved, the \"distance\" between them, the novelty of any particular combination, and their extent of integration.\nInterdisciplinary knowledge and research are important because:\nQuotations.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\"The modern mind divides, specializes, thinks in categories: the Greek instinct was the opposite, to take the widest view, to see things as an organic whole [...]. The Olympic games were designed to test the arete of the whole man, not a merely specialized skill [...]. The great event was the pentathlon, if you won this, you were a man. Needless to say, the Marathon race was never heard of until modern times: the Greeks would have regarded it as a monstrosity.\"\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\"Previously, men could be divided simply into the learned and the ignorant, those more or less the one, and those more or less the other. But your specialist cannot be brought in under either of these two categories. He is not learned, for he is formally ignorant of all that does not enter into his specialty; but neither is he ignorant, because he is 'a scientist,' and 'knows' very well his own tiny portion of the universe. We shall have to say that he is a learned ignoramus, which is a very serious matter, as it implies that he is a person who is ignorant, not in the fashion of the ignorant man, but with all the petulance of one who is learned in his own special line.\"\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\"It is the custom among those who are called 'practical' men to condemn any man capable of a wide survey as a visionary: no man is thought worthy of a voice in politics unless he ignores or does not know nine-tenths of the most important relevant facts.\"\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "15202", "revid": "15912693", "url": "https://en.wikipedia.org/wiki?curid=15202", "title": "Immediate subordinate", "text": ""}
{"id": "15203", "revid": "15912694", "url": "https://en.wikipedia.org/wiki?curid=15203", "title": "Immediate superior", "text": ""}
{"id": "15205", "revid": "50214485", "url": "https://en.wikipedia.org/wiki?curid=15205", "title": "Insertion sort", "text": "Sorting algorithm\nInsertion sort is a simple sorting algorithm that builds the final sorted array (or list) one item at a time by comparisons. It is much less efficient on large lists than more advanced algorithms such as quicksort, heapsort, or merge sort. However, insertion sort provides several advantages:\nWhen people manually sort cards in a bridge hand, most use a method that is similar to insertion sort.\nAlgorithm.\nInsertion sort iterates, consuming one input element each repetition, and grows a sorted output list. At each iteration, insertion sort removes one element from the input data, finds the correct location within the sorted list, and inserts it there. It repeats until no input elements remain.\nSorting is typically done in-place, by iterating up the array, growing the sorted list behind it. At each array-position, it checks the value there against the largest value in the sorted list (which happens to be next to it, in the previous array-position checked). If larger, it leaves the element in place and moves to the next. If smaller, it finds the correct position within the sorted list, shifts all the larger values up to make a space, and inserts into that correct position.\nThe resulting array after \"k\" iterations has the property where the first \"k\" + 1 entries are sorted (\"+1\" because the first entry is skipped). In each iteration the first remaining entry of the input is removed, and inserted into the result at the correct position, thus extending the result:\nbecomes\nwith each element greater than \"x\" copied to the right as it is compared against \"x\".\nThe most common variant of insertion sort, which operates on arrays, can be described as follows:\nPseudocode of the complete algorithm follows, where the arrays are zero-based:\n i \u2190 1\n while i &lt; length(A)\n j \u2190 i\n while j &gt; 0 and A[j-1] &gt; A[j]\n swap A[j] and A[j-1]\n j \u2190 j - 1\n end while\n i \u2190 i + 1\n end while\nThe outer loop runs over all the elements except the first one, because the single-element prefix codice_1 is trivially sorted, so the invariant that the first codice_2 entries are sorted is true from the start. The inner loop moves element codice_3 to its correct place so that after the loop, the first codice_4 elements are sorted. Note that the codice_5-operator in the test must use short-circuit evaluation, otherwise the test might result in an array bounds error, when codice_6 and it tries to evaluate codice_7 (i.e. accessing codice_8 fails).\nAfter expanding the codice_9 operation in-place as codice_10 (where codice_11 is a temporary variable), a slightly faster version can be produced that moves codice_3 to its position in one go and only performs one assignment in the inner loop body:\n i \u2190 1\n while i &lt; length(A)\n x \u2190 A[i]\n j \u2190 i\n while j &gt; 0 and A[j-1] &gt; x\n A[j] \u2190 A[j-1]\n j \u2190 j - 1\n end while\n A[j] \u2190 x\n i \u2190 i + 1\n end while\nThe new inner loop shifts elements to the right to clear a spot for codice_13.\nThe algorithm can also be implemented in a recursive way. The recursion just replaces the outer loop, calling itself and storing successively smaller values of \"n\" on the stack until \"n\" equals 0, where the function then returns up the call chain to execute the code after each recursive call starting with \"n\" equal to 1, with \"n\" increasing by 1 as each instance of the function returns to the prior instance. The initial call would be \"codice_14\".\n function insertionSortR(array A, int n)\n if n &gt; 0\n insertionSortR(A, n-1)\n x \u2190 A[n]\n j \u2190 n-1\n while j &gt;= 0 and A[j] &gt; x\n A[j+1] \u2190 A[j]\n j \u2190 j-1\n end while\n A[j+1] \u2190 x\n end if\n end function\nIt does not make the code any shorter, it also does not reduce the execution time, but it increases the additional memory consumption from O(1) to O(N) (at the deepest level of recursion the stack contains N references to the array, each with accompanying value of variable from N down to 1).\nBest, worst, and average cases.\nThe best case input is an array that is already sorted. In this case insertion sort has a linear running time (i.e., O(\"n\")). During each iteration, the first remaining element of the input is only compared with the right-most element of the sorted subsection of the array.\nThe simplest worst case input is an array sorted in reverse order. The set of all worst case inputs consists of all arrays where each element is the smallest or second-smallest of the elements before it. In these cases every iteration of the inner loop will scan and shift the entire sorted subsection of the array before inserting the next element. This gives insertion sort a quadratic running time (i.e., O(\"n\"2)).\nThe average case is also quadratic, which makes insertion sort impractical for sorting large arrays. However, insertion sort is one of the fastest algorithms for sorting very small arrays, even faster than quicksort; indeed, good quicksort implementations use insertion sort for arrays smaller than a certain threshold, also when arising as subproblems; the exact threshold must be determined experimentally and depends on the machine, but is commonly around ten.\nExample: The following table shows the steps for sorting the sequence {3, 7, 4, 9, 5, 2, 6, 1}. In each step, the key under consideration is underlined. The key that was moved (or left in place because it was the biggest yet considered) in the previous step is marked with an asterisk.\n 3 7 4 9 5 2 6 1\n 3* 7 4 9 5 2 6 1\n 3 7* 4 9 5 2 6 1\n 3 4* 7 9 5 2 6 1\n 3 4 7 9* 5 2 6 1\n 3 4 5* 7 9 2 6 1\n 2* 3 4 5 7 9 6 1\n 2 3 4 5 6* 7 9 1\n 1* 2 3 4 5 6 7 9\nRelation to other sorting algorithms.\nInsertion sort is very similar to selection sort. As in selection sort, after \"k\" passes through the array, the first \"k\" elements are in sorted order. However, the fundamental difference between the two algorithms is that insertion sort scans backwards from the current key, while selection sort scans forwards. This results in selection sort making the first k elements the \"k\" smallest elements of the unsorted input, while in insertion sort they are simply the first \"k\" elements of the input.\nThe primary advantage of insertion sort over selection sort is that selection sort must always scan all remaining elements to find the absolute smallest element in the unsorted portion of the list, while insertion sort requires only a single comparison when the (\"k\" + 1)-st element is greater than the \"k\"-th element; when this is frequently true (such as if the input array is already sorted or partly sorted), insertion sort is distinctly more efficient compared to selection sort. On average (assuming the rank of the (\"k\" + 1)-st element rank is random), insertion sort will require comparing and shifting half of the previous \"k\" elements, meaning that insertion sort will perform about half as many comparisons as selection sort on average.\nIn the worst case for insertion sort (when the input array is reverse-sorted), insertion sort performs just as many comparisons as selection sort. However, a disadvantage of insertion sort over selection sort is that it requires more writes due to the fact that, on each iteration, inserting the (\"k\" + 1)-st element into the sorted portion of the array requires many element swaps to shift all of the following elements, while only a single swap is required for each iteration of selection sort. In general, insertion sort will write to the array O(\"n\"2) times, whereas selection sort will write only O(n) times. For this reason selection sort may be preferable in cases where writing to memory is significantly more expensive than reading, such as with EEPROM or flash memory.\nWhile some divide-and-conquer algorithms such as quicksort and mergesort outperform insertion sort for larger arrays, non-recursive sorting algorithms such as insertion sort or selection sort are generally faster for very small arrays (the exact size varies by environment and implementation, but is typically between 7 and 50 elements). Therefore, a useful optimization in the implementation of those algorithms is a hybrid approach, using the simpler algorithm when the array has been divided to a small size.\nVariants.\nD.L. Shell made substantial improvements to the algorithm; the modified version is called Shell sort. The sorting algorithm compares elements separated by a distance that decreases on each pass. Shell sort has distinctly improved running times in practical work, with two simple variants requiring O(\"n\"3/2) and O(\"n\"4/3) running time.\nIf the cost of comparisons exceeds the cost of swaps, as is the case for example with string keys stored by reference or with human interaction (such as choosing one of a pair displayed side-by-side), then using \"binary insertion sort\" may yield better performance. Binary insertion sort employs a binary search to determine the correct location to insert new elements, and therefore performs \u2308log2 \"n\"\u2309 comparisons in the worst case. When each element in the array is searched for and inserted this is O(\"n\" log \"n\"). The algorithm as a whole still has a running time of O(\"n\"2) on average because of the series of swaps required for each insertion.\nThe number of swaps can be reduced by calculating the position of multiple elements before moving them. For example, if the target position of two elements is calculated before they are moved into the proper position, the number of swaps can be reduced by about 25% for random data. In the extreme case, this variant works similar to merge sort.\nA variant named \"binary merge sort\" uses a \"binary insertion sort\" to sort groups of 32 elements, followed by a final sort using merge sort. It combines the speed of insertion sort on small data sets with the speed of merge sort on large data sets.\nTo avoid having to make a series of swaps for each insertion, the input could be stored in a linked list, which allows elements to be spliced into or out of the list in constant time when the position in the list is known. However, searching a linked list requires sequentially following the links from each element to the next (or previous) element: a linked list does not have random access, so it cannot use a faster method such as binary search to find the insertion point for an unsorted element. Therefore, the running time required for searching is O(\"n\"), and the time for sorting is O(\"n\"2). If a more sophisticated data structure (e.g., heap or binary tree) is used, the time required for searching and insertion can be reduced significantly; this is the essence of heap sort and binary tree sort.\nIn 2006 Bender, Martin Farach-Colton, and Mosteiro published a new variant of insertion sort called \"library sort\" or \"gapped insertion sort\" that leaves a small number of unused spaces (i.e., \"gaps\") spread throughout the array. The benefit is that insertions need only shift elements over until a gap is reached. The authors show that this sorting algorithm runs with high probability in O(\"n\" log \"n\") time.\nIf a skip list is used, the insertion time is brought down to O(log \"n\"), and swaps are not needed because the skip list is implemented on a linked list structure. The final running time for insertion would be O(\"n\" log \"n\").\nList insertion sort code in C.\nIf the items are stored in a linked list, then the list can be sorted with O(1) additional space. The algorithm starts with an initially empty (and therefore trivially sorted) list. The input items are taken off the list one at a time, and then inserted in the proper place in the sorted list. When the input list is empty, the sorted list has the desired result.\nstruct LIST * SortList1(struct LIST * pList) \n // zero or one element in list\n if (pList == NULL || pList-&gt;pNext == NULL)\n return pList;\n // head is the first element of resulting sorted list\n struct LIST * head = NULL;\n while (pList != NULL) {\n struct LIST * current = pList;\n pList = pList-&gt;pNext;\n if (head == NULL || current-&gt;iValue &lt; head-&gt;iValue) {\n // insert into the head of the sorted list\n // or as the first element into an empty sorted list\n current-&gt;pNext = head;\n head = current;\n } else {\n // insert current element into proper position in non-empty sorted list\n struct LIST * p = head;\n while (p != NULL) {\n if (p-&gt;pNext == NULL || // last element of the sorted list\n current-&gt;iValue &lt; p-&gt;pNext-&gt;iValue) // middle of the list\n // insert into middle of the sorted list or as the last element\n current-&gt;pNext = p-&gt;pNext;\n p-&gt;pNext = current;\n break; // done\n p = p-&gt;pNext;\n return head;\nThe algorithm below uses a trailing pointer for the insertion into the sorted list. A simpler recursive method rebuilds the list each time (rather than splicing) and can use O(\"n\") stack space.\nstruct LIST\n struct LIST * pNext;\n int iValue;\nstruct LIST * SortList(struct LIST * pList)\n // zero or one element in list\n if (!pList || !pList-&gt;pNext)\n return pList;\n /* build up the sorted array from the empty list */\n struct LIST * pSorted = NULL;\n /* take items off the input list one by one until empty */\n while (pList != NULL) {\n /* remember the head */\n struct LIST * pHead = pList;\n /* trailing pointer for efficient splice */\n struct LIST ** ppTrail = &amp;pSorted;\n /* pop head off list */\n pList = pList-&gt;pNext;\n /* splice head into sorted list at proper place */\n while (!(*ppTrail == NULL || pHead-&gt;iValue &lt; (*ppTrail)-&gt;iValue)) { /* does head belong here? */\n /* no - continue down the list */\n ppTrail = &amp;(*ppTrail)-&gt;pNext;\n pHead-&gt;pNext = *ppTrail;\n *ppTrail = pHead;\n return pSorted;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "15207", "revid": "2308716", "url": "https://en.wikipedia.org/wiki?curid=15207", "title": "Ig Nobel Prize", "text": "Annually awarded parody of the Nobel Prize\nThe Ig Nobel Prize () is a satirical prize awarded annually since 1991 to promote public engagement with scientific research. Its aim is to \"honor achievements that first make people laugh, and then make them think.\" The name of the award is a pun on the Nobel Prize, which it parodies, and on the word \"https://\".\nOrganized by the scientific humor magazine \"Annals of Improbable Research\" (AIR), the Ig Nobel Prizes are presented by Nobel laureates in a ceremony at the Massachusetts Institute of Technology. The winners also deliver public lectures. The Ig Nobel Prize monetary award is given in a solitary banknote for the amount of 10 trillion Zimbabwean dollars (US$0.40, but the banknote is worth more as a collector's item).\nHistory.\nThe Ig Nobels were created in 1991 by Marc Abrahams, then editor-in-chief of the \"Journal of Irreproducible Results\" and later co-founder of the \"Annals of Improbable Research\", who has been the master of ceremonies at all awards ceremonies. Awards were presented at that time for discoveries \"that cannot, or should not, be reproduced\". Ten prizes are awarded each year in many categories, including the Nobel Prize categories of physics, chemistry, physiology/medicine, literature, economics, and peace, but also other categories such as public health, engineering, biology, and interdisciplinary research. The Ig Nobel Prizes recognize genuine achievements, with the exception of three prizes awarded in the first year to fictitious scientists Josiah S. Carberry, Paul DeFanti, and Thomas Kyle.\nThe awards are sometimes criticism via satire, as in the two awards given for homeopathy research, prizes in \"science education\" to the Kansas State Department of Education and Colorado State Board of Education for their stance regarding the teaching of evolution, and the prize awarded to \"Social Text\" after the Sokal affair. Most often, however, they draw attention to scientific articles that have some humorous or unexpected aspect. Examples range from the discovery that the presence of humans tends to sexually arouse ostriches, to the statement that black holes fulfill all the technical requirements for being the location of Hell, to research on the \"five-second rule\", a tongue-in-cheek belief that food dropped on the floor will not become contaminated if it is picked up within five seconds.\nSir Andre Geim, who had been awarded an Ig Nobel Prize in 2000 for levitating a frog by magnetism, was awarded a Nobel Prize in physics in 2010 for his work with the electromagnetic properties of graphene. He is the only individual, as of 2025, to have received both a Nobel and an Ig Nobel.\nTwo books have been published with write-ups on some winners: \"The Ig Nobel Prize\" and \"The Ig Nobel Prize 2\", the latter of which was later retitled \"The Man Who Tried to Clone Himself\". An Ig Nobel Tour has been an annual part of National Science week in the United Kingdom since 2003.\nCeremony.\nThe prizes are mostly presented by Nobel laureates, originally at a ceremony in a lecture hall at MIT but moved in 1994 to the Sanders Theater at Harvard University for many years. Due to the COVID-19 pandemic, the event was held fully online in the years of 2020 through 2023. The ceremony returned to MIT in September 2024.\nThe event contains a number of running jokes, including Miss Sweetie Poo, a little girl who repeatedly cries out, \"Please stop: I'm bored\", in a high-pitched voice if speakers go on too long. The awards ceremony is traditionally closed with the words: \"If you didn't win a prize\u2014and especially if you did\u2014better luck next year!\"\nThe ceremony is co-sponsored by the Harvard Computer Society, the Harvard\u2013Radcliffe Science Fiction Association and the Harvard\u2013Radcliffe Society of Physics Students.\nThrowing paper planes onto the stage is a long-standing tradition. For many years Professor Roy J. Glauber swept the stage clean of the airplanes as the official \"Keeper of the Broom\". Glauber could not attend the 2005 awards because he was traveling to Stockholm to claim a genuine Nobel Prize in Physics.\nThe \"Parade of Ignitaries\" into the hall includes supporting groups. At the 1997 ceremonies, a team of \"cryogenic sex researchers\" distributed a pamphlet titled \"Safe Sex at Four Kelvin.\" Delegates from the Museum of Bad Art are often on hand to display some pieces from their collection.\nLegacy.\nA September 2009 article in \"The National\" titled \"A noble side to Ig Nobels\" says that, although the Ig Nobel Awards are veiled criticism of trivial research, history shows that trivial research sometimes leads to important breakthroughs. For instance, in 2006, a study showing that one of the mosquitoes that can carry malaria (\"Anopheles gambiae\") is attracted equally to the smell of Limburger cheese and the smell of human feet earned the Ig Nobel Prize in the area of biology. As a direct result of these findings, traps baited with this cheese have been placed in strategic locations to combat the epidemic of malaria in Africa. Andre Geim, before sharing the 2010 Nobel Prize in Physics for his research on graphene, shared the Physics Ig Nobel in 2000 with Michael Berry for the magnetic levitation of a frog, which by 2022 was reportedly part of the inspiration for China's lunar gravity research facility.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "15208", "revid": "7611264", "url": "https://en.wikipedia.org/wiki?curid=15208", "title": "Isaac Alb\u00e9niz", "text": "Spanish composer (1860\u20131909)\nIsaac Manuel Francisco Alb\u00e9niz y Pascual (; 29 May 1860 \u2013 18 May 1909) was a Spanish virtuoso pianist, composer, and conductor. He is one of the foremost composers of the post-romantic era who also had a significant influence on his contemporaries and younger composers. He is best known for his piano works that incorporate Spanish folk music idioms and elements. His compositions, particularly those in his suite \"Iberia\" (1905\u20131908), are considered masterpieces and have influenced both classical music and Spanish nationalism in music. Isaac Alb\u00e9niz was close to the Generation of '98.\nTranscriptions of many of his pieces, such as \"Asturias (Leyenda)\", \"Granada\", \"Sevilla\", \"Cadiz\", \"C\u00f3rdoba\", \"Catalu\u00f1a\", \"Mallorca\", and Tango in D, are important pieces for classical guitar, though he never composed for the guitar. \nSome of Alb\u00e9niz's personal papers are held in the Library of Catalonia.\nBiography.\n&lt;templatestyles src=\"Stack/styles.css\"/&gt;\nIn 1860, Alb\u00e9niz was born in Camprodon, province of Girona, to \u00c1ngel Alb\u00e9niz (a customs official) and his wife, Maria de los Dolores Pascual. He was a child prodigy, first performing at the age of 4.\nIn 1867, at age 7, after apparently taking lessons from Antoine Fran\u00e7ois Marmontel, Alb\u00e9niz passed the entrance examination for piano at the Conservatoire de Paris, but he was refused admission because he was believed to be too young.\nAs of 1872, by the time he had reached 12, Alb\u00e9niz had made many attempts to run away from home.\nAlb\u00e9niz's concert career began at the age of nine when his father toured both Isaac and his sister, Clementina, throughout northern Spain. A popular myth is that at the age of 12, in 1872, Alb\u00e9niz stowed away in a ship bound for Buenos Aires. He then found himself in Cuba, then in the United States, giving concerts in New York and San Francisco and then travelled to Liverpool, London and Leipzig.\nBy age 15, in 1875, Alb\u00e9niz had already given concerts worldwide. This story is not entirely false, Alb\u00e9niz did travel the world as a performer; however, he was accompanied by his father, who as a customs agent was required to travel frequently. This can be attested by comparing Isaac's concert dates with his father's travel itinerary.\nIn 1876, after a short stay at the Leipzig Conservatory, Alb\u00e9niz went to study at the Royal Conservatory of Brussels after King Alfonso's personal secretary, Guillermo Morphy, obtained him a royal grant. Count Morphy thought highly of Alb\u00e9niz, who would later dedicate \"Sevilla\" to Morphy's wife when it premiered in Paris in January 1886.\nIn 1880, Alb\u00e9niz went to Budapest, Hungary, to study with Franz Liszt, only to find out that Liszt was in Weimar, Germany.\nIn 1883, Alb\u00e9niz met the teacher and composer Felip Pedrell, who inspired him to write Spanish music such as the \"Chants d'Espagne\". The first movement (Prelude) of that suite, later retitled after the composer's death as \"Asturias (Leyenda)\", is now part of the classical guitar repertoire, even though it was originally composed for piano. Many of Alb\u00e9niz's other compositions were also transcribed for guitar by Francisco T\u00e1rrega. At the 1888 Barcelona Universal Exposition, the piano manufacturer \u00c9rard sponsored a series of 20 concerts featuring Alb\u00e9niz's music.\nAlso in 1883, the composer married Rosina Jordana Lagarriga, daughter of the former mayor of the Gr\u00e0cia district and a former student of Isaac. They had two children who lived into adulthood: Alfonso (1885\u20131941), who played for FC Barcelona in the early 1900s before embarking on a career as a diplomat, and Laura (1890\u20131944), who went on to become a renowned illustrator in the arts of drawing and painting. Another child, Enriqueta, died in infancy in 1886. His great-granddaughter is C\u00e9cilia Attias, former wife of Nicolas Sarkozy.\nThe apex of Alb\u00e9niz's concert career is considered to be 1889 to 1892 when he had concert tours throughout Europe. During the 1890s Alb\u00e9niz lived in London and Paris. For London he wrote some musical comedies which brought him to the attention of the wealthy Francis Money-Coutts, 5th\u00a0Baron Latymer. Money-Coutts commissioned and provided him with librettos for the opera \"Henry Clifford\" and for a projected trilogy of Arthurian operas. The first of these, \"Merlin\" (1898\u20131902), was thought to have been lost but has recently been reconstructed and performed. Alb\u00e9niz never completed \"Lancelot\" (only the first act is finished, as a vocal and piano score), and he never began \"Guinevere\", the final part.\nIn 1900, Alb\u00e9niz started to suffer from Bright's disease and returned to writing piano music.\nBetween 1905 and 1908, Alb\u00e9niz composed his final masterpiece, \"Iberia\" (1908), a suite of twelve piano \"impressions\".\nOn 18\u00a0 1909 ()\u00a0(1909--), at age 48, Alb\u00e9niz died from his kidney disease in Cambo-les-Bains, in Labourd, south-western France. Only a few weeks before his death, the French Government had bestowed upon Alb\u00e9niz the Legion of Honour, its highest honour. He is buried at the Montju\u00efc Cemetery, Barcelona.\nMusic.\nEarly works.\nAlb\u00e9niz's early works were mostly \"salon style\" music. His first published composition, \"Marcha Militar\", appeared in 1868. A number of works written before this are now lost. He continued composing in traditional styles ranging from Jean-Philippe Rameau, Johann Sebastian Bach, Ludwig van Beethoven, Fr\u00e9d\u00e9ric Chopin and Franz Liszt until the mid-1880s. He also wrote at least five zarzuelas, of which all but two are now lost.\nPerhaps the best source on the works is Alb\u00e9niz himself. He is quoted as commenting on his earlier period works as:There are among them a few things that are not completely worthless. The music is a bit infantile, plain, spirited; but in the end, the people, our Spanish people, are something of all that. I believe that the people are right when they continue to be moved by \"C\u00f3rdoba\", \"Mallorca\", by the copla of the \"Sevillanas\", by the \"Serenata\", and \"Granada\". In all of them I now note that there is less musical science, less of the grand idea, but more colour, sunlight, flavour of olives. That music of youth, with its little sins and absurdities that almost point out the sentimental affectation ... appears to me like the carvings in the Alhambra, those peculiar arabesques that say nothing with their turns and shapes, but which are like the air, like the sun, like the blackbirds or like the nightingales of its gardens. They are more valuable than all else of Moorish Spain, which though we may not like it, is the true Spain.\nMiddle period.\nDuring the late 1880s, the strong influence of Spanish style is evident in Alb\u00e9niz's music. In 1883 Alb\u00e9niz met the teacher and composer Felipe Pedrell. Pedrell was a leading figure in the development of nationalist Spanish music. In his book \"The Music of Spain\", Gilbert Chase describes Pedrell's influence on Alb\u00e9niz: \"What Alb\u00e9niz derived from Pedrell was above all a spiritual orientation, the realization of the wonderful values inherent in Spanish music.\" Felipe Pedrell inspired Alb\u00e9niz to write Spanish music such as the \"Suite espa\u00f1ola\", Op. 47, noted for its delicate, intricate melody and abrupt dynamic changes.\nIn addition to the Spanish spirit infused in Alb\u00e9niz's music, he incorporated other qualities as well. In her biography of Alb\u00e9niz, Pola Baytelman discerns four characteristics of the music from the middle period as follows:\n1. The dance rhythms of Spain, of which there are a wide variety. 2. The use of cante jondo, which means deep or profound singing. It is the most serious and moving variety of flamenco or Spanish gypsy song, often dealing with themes of death, anguish, or religion. 3. The use of exotic scales also associated with flamenco music. The Phrygian mode is the most prominent in Alb\u00e9niz's music, although he also used the Aeolian and Mixolydian modes as well as the whole-tone scale. 4. The transfer of guitar idioms into piano writing.\nFollowing his marriage, Alb\u00e9niz settled in Madrid, Spain, and produced a substantial quantity of music in a relatively short period. By 1886 he had written over 50 piano pieces. Alb\u00e9niz biographer Walter A. Clark says that pieces from this period received enthusiastic reception in the composer's many concerts. Chase describes music from this period,\nTaking the guitar as his instrumental model, and drawing his inspiration largely from the peculiar traits of Andalusian folk music\u2014but without using actual folk themes\u2014Alb\u00e9niz achieves a stylization of Spanish traditional idioms that while thoroughly artistic, gives a captivating impression of spontaneous improvisation... \"C\u00f3rdoba\" is the piece that best represents the style of Alb\u00e9niz in this period, with its hauntingly beautiful melody, set against the acrid dissonances of the plucked accompaniment imitating the notes of the Moorish guzlas. Here is the heady scent of jasmines amid the swaying palm trees, the dream fantasy of an Andalusian \"Arabian Nights\" in which Alb\u00e9niz loved to let his imagination dwell.\nLater period.\nWhile Alb\u00e9niz's crowning achievement, \"Iberia\", was written in the last years of his life in France, many of its preceding works are well-known and of great interest. The five pieces in \"Chants d'Espagne\" (\"Songs of Spain\", published in 1892) are a solid example of the compositional ideas he was exploring in the \"middle period\" of his life. The suite shows what Alb\u00e9niz biographer Walter Aaron Clark describes as the \"first flowering of his unique creative genius\", and the beginnings of compositional exploration that became the hallmark of his later works. This period also includes his operatic works\u2014\"Merlin, Henry Clifford\", and \"Pepita Jim\u00e9nez\". His orchestral works of this period include \"Spanish Rhapsody\" (1887) and \"Catalonia\" (1899), dedicated to Ramon Casas, who had painted his full-length portrait in 1894.\nImpact and legacy.\nAs one of the leading composers of his era, Alb\u00e9niz's influences on both contemporary composers and on the future of Spanish music are profound. As a result of his extended stay in France and the friendship he formed with numerous composers there, his composition technique and harmonic language influenced aspiring younger composers such as Claude Debussy and Maurice Ravel. His activities as conductor, performer and composer significantly raised the profile of Spanish music abroad and encouraged Spanish music and musicians in his own country.\nAlb\u00e9niz's works have become an important part of the repertoire of the classical guitar, many of which have been transcribed by Francisco T\u00e1rrega, Miguel Llobet and others. \"Asturias (Leyenda)\" in particular is heard most often on the guitar, as are \"Granada\", \"Sevilla\", \"Cadiz\", \"Catalu\u00f1a\", \"C\u00f3rdoba\", \"Mallorca\", and \"Tango in D\". Gordon Crosskey and Cuban-born guitarist Manuel Barrueco have both made solo guitar arrangements of all the eight movements in \"Suite espa\u00f1ola\". Selections from \"Iberia\" have rarely been attempted on solo guitar but have been very effectively performed by guitar ensembles, such as the performance by John Williams and Julian Bream of \"Iberia's \" opening \"Evocation\". The Doors incorporated \"Asturias\" into their song \"Spanish Caravan\"; also, Iron Maiden's \"To Tame a Land\" uses the introduction of the piece for the song bridge. More recently, a guitar version of \"Granada\" functions as something of a love theme in Woody Allen's 2008 film \"Vicky Cristina Barcelona\".\nA film about his life, \"Alb\u00e9niz,\" was made in 1947. It was produced in Argentina.\nThe theme from \"Asturias\" was incorporated or adapted in several soundtracks including the 2008 horror film \"Mirrors\", composed by Javier Navarrete, and the Netflix TV show \"Godless\", composed by Carlos Rafael Rivera.\nIn 1997 the \"Fundaci\u00f3n Isaac Alb\u00e9niz\" was founded to promote Spanish music and musicians and to act as a research centre for Alb\u00e9niz and Spanish music in general.\nReferences and sources.\nReferences\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nSources\nFurther reading.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;"}
{"id": "15210", "revid": "24902", "url": "https://en.wikipedia.org/wiki?curid=15210", "title": "ITU-R", "text": "One of the three sectors of the ITU\nThe ITU Radiocommunication Sector (ITU-R) is one of the three sectors (divisions or units) of the International Telecommunication Union (ITU) and is responsible for radio communications. \nIts role is to manage the international radio-frequency spectrum and satellite orbit resources and to develop standards for radiocommunication systems with the objective of ensuring the effective use of the spectrum.\nITU is required, according to its constitution, to allocate spectrum and register frequency allocation, orbital positions and other parameters of satellites, \"in order to avoid harmful interference between radio stations of different countries\". The international spectrum management system is therefore based on regulatory procedures for frequency coordination, notification and registration.\nITU-R has a permanent secretariat, the Radiocommunication Bureau, based at the ITU HQ in Geneva, Switzerland. The elected Director of the Bureau is Mario Maniewicz; he was first elected by the ITU membership to the directorship in 2018.\nHistory.\nThe CCIR\u2014Comit\u00e9 consultatif international pour la radio, Consultative Committee on International Radio or International Radio Consultative Committee\u2014was founded in 1927.\nIn 1932 the CCIR and several other organizations (including the original ITU, which had been founded as the International Telegraph Union in 1865), merged to form what would in 1934 become known as the International Telecommunication Union. In 1992, the CCIR became the ITU-R.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "15214", "revid": "8144267", "url": "https://en.wikipedia.org/wiki?curid=15214", "title": "Irish Civil War", "text": "1922\u20131923 conflict between factions of the IRA\nThe Irish Civil War (; 28 June 1922 \u2013 24 May 1923) was a conflict that followed the Irish War of Independence and accompanied the establishment of the Irish Free State, an entity independent from the United Kingdom but within the British Empire.\nThe civil war was waged between the Provisional Government of Ireland and the Anti-Treaty IRA over the Anglo-Irish Treaty. The Provisional Government (which became the Free State in December 1922) supported the terms of the treaty, while the anti-Treaty opposition saw it as a betrayal of the Irish Republic proclaimed during the Easter Rising of 1916. Many of the combatants had fought together against the British in the Irish Republican Army during the War of Independence and had divided after that conflict ended and the treaty negotiations began.\nThe Civil War was won by the pro-treaty National Army, who first secured Dublin by early July, then went on the offensive against the anti-Treaty strongholds of the south and west, especially the 'Munster Republic'. All urban centres had been captured by the National Army by late August. The guerrilla phase of the Irish Civil War lasted another 10 months, before the IRA leadership issued a \"dump arms\" order to all units, effectively ending the conflict. The National Army benefited from substantial quantities of weapons provided by the British government, particularly artillery and armoured cars.\nThe conflict left Irish society divided and embittered for generations. Today, the three largest political parties in Ireland are direct descendants of the opposing sides in the war: Fine Gael, from the supporters of the pro-Treaty side; Fianna F\u00e1il, the party formed from the bulk of the anti-Treaty republicans by \u00c9amon de Valera; and Sinn F\u00e9in, comprising the minority of anti-Treaty republicans who refused to join any partitionist party.\nBackground.\nThe treaty and its consequences.\nThe Anglo-Irish Treaty was agreed upon to end the 1919\u20131921 Irish War of Independence between the Irish Republic and the United Kingdom of Great Britain and Ireland. The treaty provided for a self-governing Irish state, having its own army and police. The treaty also allowed Northern Ireland (the six north-eastern counties\u00a0\u2013 Fermanagh, Antrim, Tyrone, Londonderry, Armagh and Down\u00a0\u2013 where collectively the majority population was of the Protestant religion) to opt out of the new state and return to the United Kingdom\u00a0\u2013 which it did immediately. With the Partition of Ireland a two-year period of communal conflict took place within the newly formed Northern Ireland. Rather than creating the independent republic for which nationalists had fought, the Irish Free State would be a dominion of the British Empire with the British monarch as head of state, in the same manner as Canada and Australia. The British suggested dominion status in secret correspondence even before treaty negotiations began, but Sinn F\u00e9in leader \u00c9amon de Valera rejected the dominion. The treaty also stipulated that members of the new Irish Oireachtas (parliament) would have to take the following \"Oath of Allegiance\":\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nThis oath was highly objectionable to many Irish Republicans. Furthermore, the partition of Ireland, which had already been decided by the Westminster parliament in the Government of Ireland Act 1920, was effectively confirmed in the Anglo-Irish treaty. The most contentious areas of the Treaty for the IRA were the disestablishment of the Irish Republic declared in 1919, the abandonment of the First D\u00e1il, the status of the Irish Free State as a dominion in the British Commonwealth and the British retention of the strategic Treaty Ports on Ireland's south western and north western coasts which were to remain occupied by the Royal Navy. All these issues were the cause of a split in the IRA and ultimately civil war.\nMichael Collins, the Irish finance minister and Irish Republican Brotherhood (IRB) president, argued in the D\u00e1il \u00c9ireann that the treaty gave \"not the ultimate freedom that all nations aspire and develop, but the freedom to achieve freedom\". However, those against the treaty believed that it would never deliver full Irish independence.\nSplit in the Nationalist movement.\nThe split over the Treaty was deeply personal. Many on both sides had been close friends and comrades during the War of Independence. This made their disagreement all the more bitter. On 6 January 1922, at the Mansion House, Dublin, Austin Stack, Home Affairs minister, showed president de Valera the evening news announcing the signing of the Treaty: de Valera merely glanced at it; when Eamonn Duggan, part of the returning Irish delegation, handed him an envelope confirming it, he pushed it aside. De Valera had held secret discussions with UK Prime Minister David Lloyd George from 14 to 21 July in London. Collins, also part of the delegation, supposed (with others) that these discussions confirmed the earlier correspondence, i.e. no British acceptance of a Republic. De Valera, Stack and Defence minister Cathal Brugha had then all refused to join the delegation to London. Collins wrote that his inclusion as a plenipotentiary was \"a trap\" of de Valera's which he was forewarned of, argued against, but walked into anyway, \"as a soldier obeying his commanding officer.\" Arthur Griffith, the delegation chairman, had made a similar comment about obeying orders to de Valera himself. Mutual suspicion and confusion pertained; the delegation was unclear about the cabinet's instructions and individually became burdened to the point of breakdown. Collins expected the blame for the compromise within the Treaty and wrote: \"Early this morning I signed my death warrant.\" Notwithstanding this, he was frustrated and at times emotional when de Valera and others refused to support the Treaty and friendships died.\nD\u00e1il \u00c9ireann (the parliament of the Irish Republic) narrowly passed the Anglo-Irish Treaty by 64 votes to 57 on 7 January 1922. Following the Treaty's ratification, in accordance with article 17 of the Treaty, the British-recognised Provisional Government of the Irish Free State was established. Its authority under the Treaty was to provide a \"provisional arrangement for the administration of Southern Ireland during the interval\" before the establishment of the Irish Free State. In accordance with the Treaty, the British Government transferred \"the powers and machinery requisite for the discharge of its duties\". Before the British Government transferred such powers, the members of the Provisional Government each \"signified in writing [their] acceptance of [the Treaty]\".\nUpon the Treaty's ratification, de Valera resigned as President of the Republic and failed to be re-elected by an even closer vote of 60\u201358. He challenged the right of the D\u00e1il to approve the treaty, saying that its members were breaking their oath to the Irish Republic. Meanwhile, he continued to promote a compromise whereby the new Irish Free State would be in \"external association\" with the British Commonwealth rather than be a member of it (the inclusion of republics within the Commonwealth of Nations was not formally implemented until 1949).\nIn early March, de Valera formed the Cumann na Poblachta ('Republican Association') party while remaining a member of Sinn F\u00e9in, and commenced a speaking tour of the more republican province of Munster on 17 March 1922. During the tour he made controversial speeches at Carrick on Suir, Lismore, Dungarvan and Waterford, saying at one point, \"If the Treaty were accepted, the fight for freedom would still go on, and the Irish people, instead of fighting foreign soldiers, will have to fight the Irish soldiers of an Irish government set up by Irishmen.\" At Thurles several days later he repeated this imagery, and added that the IRA \"would have to wade through the blood of the soldiers of the Irish Government, and perhaps through that of some members of the Irish Government to get their freedom.\"\nIn a letter to the \"Irish Independent\" on 23 March, de Valera accepted the accuracy of their report of his comment about \"wading\" through blood, but deplored that the newspaper had published it.\nMore seriously, many Irish Republican Army (IRA) officers were also against the treaty, and in March 1922 an ad hoc Army Convention repudiated the authority of the D\u00e1il to accept the treaty. In contrast, the Minister of Defence, Richard Mulcahy, stated in the D\u00e1il on 28 April that conditions in Dublin had prevented a Convention from being held, but that delegates had been selected and voted by ballot to accept the Oath. The anti-Treaty IRA formed their own \"Army Executive\", which they declared to be the real government of the country, despite the result of the 1921 general election. On 26 April Mulcahy summarised alleged illegal activities by many IRA men over the previous three months, whom he described as 'seceding volunteers', including hundreds of robberies. Yet this fragmenting army was the only police force on the ground following the disintegration of the Irish Republican Police and the disbanding of the Royal Irish Constabulary (RIC).\nBy putting ten questions to Mulcahy on 28 April, Se\u00e1n MacEntee argued that the Army Executive had acted continuously on its own to create a republic since 1917, had an unaltered constitution, had never fallen under the control of the D\u00e1il, and that \"the only body competent to dissolve the Volunteer Executive was a duly convened convention of the Irish Republican Army\" \u2013 not the D\u00e1il. By accepting the treaty in January and abandoning the republic, the D\u00e1il majority had effectively deserted the Army Executive. In his reply, Mulcahy rejected this interpretation. Then, in a debate on defence, MacEntee suggested that supporting the Army Executive \"even if it meant the scrapping of the Treaty and terrible and immediate war with England, would be better than the civil war which we are beginning at present apparently\". MacEntee's supporters added that the many robberies complained of by Mulcahy on 26 April were caused by the lack of payment and provision by the D\u00e1il to the volunteers.\nOccupation of the Four Courts.\nOn 14 April 1922, 200 Anti-Treaty IRA militants, with Rory O'Connor as their spokesman, occupied the Four Courts and several other buildings in central Dublin, resulting in a tense stand-off. These anti-treaty Republicans wanted to spark a new armed confrontation with the British, which they hoped would unite the two factions of the IRA against their common enemy. However, for those who were determined to make the Free State into a viable, self-governing Irish state, this was an act of rebellion that would have to be put down by them rather than the British.\nArthur Griffith was in favour of using force against these men immediately, but Michael Collins, who wanted at all costs to avoid civil war, left the Four Courts garrison alone until late June 1922. By this point, the Pro-Treaty Sinn F\u00e9in party had secured a large majority in the general election, along with other parties that supported the Treaty. Collins was also coming under continuing pressure from London to assert his government's authority in Dublin.\nDelay until the June election.\nCollins established an \"army re-unification committee\" to re-unite the IRA and organised an election pact with de Valera's anti-treaty political followers to campaign jointly in the Free State's first election in 1922 and form a coalition government afterwards. He also tried to reach a compromise with anti-treaty IRA leaders by agreeing to a republican-type constitution (with no mention of the British monarchy) for the new state. IRA leaders such as Liam Lynch were prepared to accept this compromise. However, the proposal for a republican constitution was vetoed by the British as being contrary to the terms of the treaty and they threatened military intervention in the Free State unless the treaty were fully implemented. Collins reluctantly agreed. This completely undermined the electoral pact between the pro- and anti-treaty factions, who went into the Irish general election on 16 June 1922 as hostile parties in some constituencies, both calling themselves Sinn F\u00e9in.\nThe Pro-Treaty Sinn F\u00e9in party claimed the election with 239,193 votes to 133,864 for Anti-Treaty Sinn F\u00e9in. A further 247,226 people voted for other parties, most of whom supported the Treaty. Labour's 132,570 votes were ambiguous with regard to the Treaty. According to Hopkinson, \"Irish labour and union leaders, while generally pro-Treaty, made little attempt to lead opinion during the Treaty conflict, casting themselves rather as attempted peacemakers.\" The election showed that a majority of the Irish electorate accepted the treaty and the foundation of the Irish Free State, but de Valera, his political followers and most of the IRA continued to oppose the treaty. De Valera is quoted as saying, \"the majority have no right to do wrong\". From the anti-treaty perspective the election was held under the British threat of a war of reconquest and therefore was not a free contest. In this view, the pro-treaty position expressed as republican leader Liam Mellows put it 'not the will of the people, but the fear of the people'.\nMeanwhile, under the leadership of Michael Collins and Arthur Griffith, the pro-treaty Provisional Government set about establishing the Irish Free State, and organised the National Army \u2013 to replace the IRA \u2013 and a new police force. However, since it was envisaged that the new army would be built around the IRA, Anti-Treaty IRA units were allowed to take over British barracks and take their arms. In practice, this meant that by the summer of 1922, the Provisional Government of Southern Ireland controlled only Dublin and some other areas like County Longford where the IRA units supported the treaty. Fighting ultimately broke out when the Provisional Government tried to assert its authority over well-armed and intransigent Anti-Treaty IRA units around the country \u2013 particularly a hardliner group in Dublin.\nAssassination of Field Marshal Wilson.\nField Marshal Henry Hughes Wilson, a prominent security adviser to the Prime Minister of Northern Ireland James Craig, was shot dead by IRA men on his own doorstep in London on 22 June 1922, with no responsibility for the act being publicly claimed by any IRA authority. Winston Churchill assumed that the Anti-Treaty IRA were responsible for the shooting and warned Collins that he would use British troops to attack the Four Courts unless the Provisional Government took action. In fact, the British cabinet actually resolved to attack the Four Courts themselves on 25 June, in an operation that would have involved tanks, howitzers and aeroplanes. However, on the advice of General Nevil Macready, who commanded the British garrison in Dublin, the plan was cancelled at the last minute. Macready's argument was that British involvement would have united Irish Nationalist opinion against the treaty, and instead Collins was given a last chance to clear the Four Courts himself.\nCourse of the war.\nFighting in Dublin.\nOn 26 June anti-treaty forces occupying the Four Courts kidnapped JJ \"Ginger\" O'Connell, a general in the National Army, in retaliation for the arrest of Leo Henderson. Collins, after giving the Four Courts garrison a final (and according to Ernie O'Malley, only) ultimatum to leave the building on 27 June, decided to end the stand-off by bombarding the Four Courts garrison into surrender. The government then appointed Collins as Commander-in-Chief of the National Army. This attack was not the opening shot of the war, as skirmishes had taken place between pro- and anti-treaty IRA factions throughout the country when the British were handing over the barracks. However, this represented the 'point of no return', when all-out war was effectively declared and the Civil War officially began.\nCollins ordered Mulcahy to accept a British offer of two 18-pounder field artillery for use by the new army of the Free State, though General Macready gave just 200 shells of the 10,000 he had in store at Richmond barracks in Inchicore. The anti-treaty forces in the Four Courts, who possessed only small arms, surrendered after three days of bombardment and the storming of the building by Provisional Government troops (28\u201330 June 1922). Shortly before the surrender, a massive explosion destroyed the western wing of the complex, including the Irish Public Record Office (PRO), injuring many advancing Free State soldiers and destroying the records. Government supporters alleged that the building had been deliberately mined. Historians dispute whether the PRO was intentionally destroyed by mines laid by the Republicans on their evacuation, or whether the explosions occurred when their ammunition store was accidentally ignited by the bombardment. Coogan, however, asserts that two lorry-loads of gelignite was exploded in the PRO, leaving priceless manuscripts floating over the city for several hours afterward.\nPitched battles continued in Dublin until 5 July. IRA units from the Dublin Brigade, led by Oscar Traynor, occupied O'Connell Street \u2013 provoking a week's more street fighting and costing another 65 killed and 280 wounded. Among the dead was Republican leader Cathal Brugha, who made his last stand after exiting the Granville Hotel. In addition, the Free State took over 500 Republican prisoners. The civilian casualties are estimated to have numbered well over 250. When the fighting in Dublin died down, the Free State government was left firmly in control of the Irish capital and the anti-treaty forces dispersed around the country, mainly to the south and west.\nThe opposing forces.\nThe outbreak of the Civil War forced pro- and anti-treaty supporters to choose sides. Supporters of the treaty came to be known as \"pro-treaty\" or later Free State Army, legally after 1923 the National Army, and were often called \"Staters\" by their opponents. The latter called themselves Republicans and were also known as \"anti-treaty\" forces or \"Irregulars\", a term preferred by the Free State side. This nomenclature, however, may be confusing. The civil war was fought by republicans on both sides who disagreed on how best to achieve the republic. For example, Collins and many of his closest comrades started the war committed to the goals of the Irish Republican Brotherhood. \nThe Anti-Treaty IRA claimed that it was defending the Irish Republic declared in 1916 during the Easter Rising, confirmed by the First D\u00e1il and invalidly set aside by those who accepted the compromise of the Free State. \u00c9amon de Valera stated that he would serve as an ordinary IRA volunteer and left the leadership of the anti-treaty Republicans to Liam Lynch, the IRA Chief of Staff. De Valera, though the Republican President as of October 1922, had little control over military operations. The campaign was directed by Liam Lynch until he was killed on 10 April 1923, and then by Frank Aiken from 20 April 1923.\nThe Civil War split the IRA. When the Civil War broke out, the Anti-Treaty IRA (concentrated in the south and west) outnumbered pro-Free State forces by roughly 12,000 men to 8,000. Moreover, the anti-treaty ranks included many of the IRA's most experienced guerrilla fighters. The paper strength of the IRA in early 1922 was over 72,000 men, but most of them were recruited during the truce with the British and fought in neither the War of Independence nor the Civil War. According to Richard Mulcahy's estimate, the Anti-Treaty IRA at the beginning of the war had 6,780 rifles and 12,900 men.\nHowever, the IRA lacked an effective command structure, a clear strategy and sufficient arms. As well as rifles they had a handful of machine guns and many of their fighters were armed only with shotguns or handguns. They also took a small number of armoured cars from British troops as they were evacuating the country. Finally, they had no artillery of any kind. As a result, they were forced to adopt a defensive stance throughout the war.\nBy contrast, the Free State army funded by the British managed to expand its forces dramatically after the start of the war. Collins and his commanders were able to build up an army that could overwhelm their opponents in the field. British supplies of artillery, aircraft, armoured cars, machine guns, small arms and ammunition were of much help to pro-Treaty forces. The British delivered for instance, over 27,000 rifles, 250 machine guns and eight 18-pounder artillery pieces to the pro-treaty forces between the outbreak of the Civil War and September 1922. The National Army amounted to 14,000 men by August 1922, was 38,000 strong by the end of 1922, and by the end of the war had grown to 55,000 men and 3,500 officers, far in excess of what the Irish state would need to maintain in peacetime. The Free State army was able to absorb experienced soldiers from the recently disbanded Irish regiments in the British army. These soldiers provided invaluable specialist skills for the new army.Like the Anti-Treaty IRA, the Free State's National Army was initially rooted in the IRA that fought against the British. Collins' most ruthless officers and men were recruited from the Dublin Active Service Unit (the elite unit of the IRA's Dublin Brigade) and from Collins' Intelligence Department and assassination unit, The Squad. In the new National Army, they were known as the Dublin Guard. Towards the end of the war, they were implicated in some notorious atrocities against anti-treaty guerrillas in County Kerry. Up to the outbreak of Civil War, it had been agreed that only men with service in the IRA could be recruited into the National Army. However, once the war began, all such restrictions were lifted. A 'National Call to Arms' issued on 7 July for recruitment on a six-month basis brought in thousands of new recruits. Many of the new army's recruits were veterans of the British Army in World War I, where they had served in disbanded Irish regiments of the British Army. Many others were raw recruits without any military experience. The fact that at least 50% of the other ranks had no military experience in turn led to ill-discipline becoming a major problem.\nA major problem for the National Army was a shortage of experienced officers. At least 20% of its officers had previously served as officers in the British Army, while 50% of the rank-and-file of the National Army had served in the British Army in World War I. Former British Army officers were also recruited for their technical expertise. A number of the senior Free State commanders, such as Emmet Dalton, John T. Prout and W. R. E. Murphy, had seen service as officers in World War I, Dalton and Murphy in the British Army and Prout in the US Army. The Republicans made much use of this fact in their propaganda \u2013 claiming that the Free State was only a proxy force for Britain itself. However, the majority of Free State soldiers were raw recruits without military experience, either in World War I or the Irish War of Independence. There were also a significant number of former members of the British Armed Forces on the Republican side, including such senior figures as Tom Barry, David Robinson and Erskine Childers.\nFree State takes major towns.\nWith Dublin in pro-treaty hands, conflict spread throughout the country. The war started with the anti-treaty forces holding Cork, Limerick and Waterford as part of a self-styled Munster Republic. However, since the anti-treaty side were not equipped to wage conventional war, Lynch was unable to take advantage of the Republicans' initial advantage in numbers and territory held. He hoped simply to hold the Munster Republic long enough to force Britain to renegotiate the treaty.\nThe large towns in Ireland were all relatively easily taken by the Free State in August 1922. Collins, Richard Mulcahy and Eoin O'Duffy planned a nationwide Free State offensive, dispatching columns overland to take Limerick in the west and Waterford in the south-east and seaborne forces to take counties Cork and Kerry in the south and Mayo in the west. In the south, landings occurred at Union Hall in Cork and Fenit, the port of Tralee, in Kerry. Limerick fell on 20 July, Waterford on the same day and Cork city on 10 August after a Free State force landed by sea at Passage West. Another seaborne expedition to Mayo in the west secured government control over that part of the country. While in some places the Republicans had put up determined resistance, nowhere were they able to defeat regular forces armed with artillery and armour. The only real conventional battle during the Free State offensive, the Battle of Killmallock, was fought when Free State troops advanced south from Limerick.\nGuerrilla war.\nGovernment victories in the major towns inaugurated a period of guerrilla warfare. After the fall of Cork, Lynch ordered IRA units to disperse and form flying columns as they had when fighting the British. They held out in areas such as the western part of counties Cork and Kerry in the south, county Wexford in the east and counties Sligo and Mayo in the west. Sporadic fighting also took place around Dundalk, where Frank Aiken and the Fourth Northern Division of the Irish Republican Army were based, and Dublin, where small-scale but regular attacks were mounted on Free State troops.\nAugust and September 1922 saw widespread attacks on Free State forces in the territories that they had occupied in the July\u2013August offensive, inflicting heavy casualties on them. Collins was killed in an ambush by anti-treaty Republicans at B\u00e9al na Bl\u00e1th, near his home in County Cork, in August 1922. Collins' death increased the bitterness of the Free State leadership towards the Republicans and probably contributed to the subsequent descent of the conflict into a cycle of atrocities and reprisals. Arthur Griffith, the Free State president, had also died of a brain haemorrhage ten days before, leaving the government in the hands of W.T. Cosgrave and the Free State army under the command of General Richard Mulcahy. For a brief period, with rising casualties among its troops and its two principal leaders dead, it looked as if the Free State might collapse. However, as winter set in, the Republicans found it increasingly difficult to sustain their campaign, and casualty rates among National Army troops dropped rapidly. For instance, in County Sligo, 54 people died in the conflict, of whom all but eight had been killed by the end of September.\nIn the autumn and winter of 1922, Free State forces broke up many of the larger Republican guerrilla units \u2013 in Sligo, Meath and Connemara in the west, for example, and in much of Dublin city. Elsewhere, anti-treaty units were forced by lack of supplies and safe-houses to disperse into smaller groups, typically of nine to ten men. Despite these successes for the National Army, it took eight more months of intermittent warfare before the war was brought to an end.\nBy late 1922 and early 1923, the anti-treaty guerrilla campaign had been reduced largely to acts of sabotage and destruction of public infrastructure such as roads and railways. It was also in this period that the Anti-Treaty IRA began burning the homes of Free State Senators and of many of the Anglo-Irish landed class.\nIn October 1922, de Valera and the anti-treaty Teachta\u00ed D\u00e1la (TDs) set up their own \"Republican government\" in opposition to the Free State. However, by then the anti-treaty side held no significant territory and de Valera's government had no authority over the population.\nAtrocities and executions.\nOn 27 September 1922, three months after the outbreak of war, the Free State's Provisional Government put before the D\u00e1il an Army (Emergency Powers) Resolution endorsing the establishment of military courts and tribunals by the Army Council. Sometimes incorrectly referred to as the \"Public Safety Bill\" or \"Emergency Powers Act\", the Army Resolution was not law, it was a resolution passed by parliament endorsing the measures the pro-treaty army was implementing in the war under martial law since July. Consequently, \"Public Safety Act\" or \"Emergency Powers Act\" is not recorded on the Irish Statute book. These pieces of \"legislation\" are alone the invention of Irish historians. The fictitious \"Acts\" nevertheless play an important role in the Irish state's foundation myth, dividing civil war violence into bogus legal and illegal categories. \nThe Army Resolution recognised the military courts and tribunals established in the army to impose life imprisonment, as well as the death penalty, for 'aiding or abetting attacks' on state forces, possession of arms and ammunition or explosive 'without the proper authority' and 'looting destruction or arson'.\nThe final phase of the Civil War degenerated into a series of atrocities that left a lasting legacy of bitterness in Irish politics. The Free State began executing Republican prisoners on 17 November 1922, when five IRA men were shot by firing squad. They were followed on 24 November by the execution of acclaimed author and treaty negotiator Erskine Childers. In all, out of around 12,000 Republican prisoners taken in the conflict, 81 were officially executed by the Free State.\nThe Anti-Treaty IRA in reprisal assassinated TD Se\u00e1n Hales on 7 December 1922. The next day four prominent Republicans held since the first week of the war \u2014 Rory O'Connor, Liam Mellows, Richard Barrett and Joe McKelvey \u2014 were executed in revenge for the killing of Hales. In addition, Free State troops, particularly in County Kerry, where the guerrilla campaign was most bitter, began the summary execution of captured anti-treaty fighters. The most notorious example of this occurred at Ballyseedy, where nine Republican prisoners were tied to a landmine, which was detonated, killing eight and only leaving one, Stephen Fuller, who was blown clear by the blast, to escape.\nThe number of \"unauthorised\" executions of Republican prisoners during the war has been put as high as 153. Among the Republican reprisals were the assassination of Kevin O'Higgins's father and W. T. Cosgrave's uncle in February 1923.\nThe IRA were unable to maintain an effective guerrilla campaign, given the gradual loss of support. The Catholic Church also supported the Free State, deeming it the lawful government of the country, denouncing the IRA and refusing to administer the Sacraments to anti-treaty fighters. On 10 October 1922, the Catholic Bishops of Ireland issued a formal statement, describing the anti-treaty campaign as:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;[A] system of murder and assassination of the National forces without any legitimate authority... the guerrilla warfare now being carried on [by] the Irregulars is without moral sanction and therefore the killing of National soldiers is murder before God, the seizing of public and private property is robbery, the breaking of roads, bridges and railways is criminal. All who in contravention of this teaching, participate in such crimes are guilty of grievous sins and may not be absolved in Confession nor admitted to the Holy Communion if they persist in such evil courses.\nThe Church's support for the Free State aroused bitter hostility among some republicans. Although the Catholic Church in independent Ireland has often been seen as a triumphalist Church, a recent study has found that it felt deeply insecure after these events.\nEnd of the war.\nBy early 1923, the offensive capability of the IRA had been seriously eroded and when, in February 1923, the Republican leader Liam Deasy was captured by Free State forces, he called on the republicans to end their campaign and reach an accommodation with the Free State. The State's executions of anti-treaty prisoners, 34 of whom were shot in January 1923, also took its toll on the Republicans' morale.\nIn addition, the National Army's operations in the field were slowly but steadily breaking up the remaining Republican concentrations.\nMarch and April 1923 saw this progressive dismemberment of the Republican forces continue with the capture and sometimes killing of guerrilla columns. A National Army report of 11 April stated, \"Events of the last few days point to the beginning of the end as a far as the irregular campaign is concerned\".\nAs the conflict petered out into a \"de facto\" victory for the pro-treaty side. The Anti-Treaty IRA executive (senior commanders) met on 24 March 1923 in County Waterford to discuss the war's future. Tom Barry proposed a motion to end the war, but it was defeated by 6 votes to 5. \u00c9amon de Valera was allowed to attend, after some debate, but was given no voting rights.\nLynch, the Republican leader, was killed in a skirmish in the Knockmealdown Mountains in County Tipperary on 10 April. On 11 April six more Volunteers were executed in Tuam, County Galway. The National Army had extracted information from Republican prisoners in Dublin that the IRA Executive was in the area and as well as killing Lynch, they also captured senior anti-treaty IRA officers Dan Breen, Todd Andrews, Se\u00e1n Gaynor and Frank Barrett in the operation. \nIt is often suggested by historians including Professor Michael Laffan of University College Dublin, that the death of Lynch allowed the more pragmatic Frank Aiken, who took over as IRA Chief of Staff, to call a halt to what seemed a futile struggle. Aiken's accession to IRA leadership was followed on 30 April by the declaration of a suspension of military activities; on 24 May 1923, he issued a ceasefire order to IRA volunteers. They were to dump arms rather than surrender them or continue a fight that they were incapable of winning.\nAftermath of the ceasefire.\n\u00c9amon de Valera supported the order, issuing a statement to Anti-Treaty fighters on 24 May:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Soldiers of the Republic. Legion of the Rearguard: The Republic can no longer be defended successfully by your arms. Further sacrifice of life would now be in vain and the continuance of the struggle in arms unwise in the national interest and prejudicial to the future of our cause. Military victory must be allowed to rest for the moment with those who have destroyed the Republic.\nThe Free State government had started peace negotiations in early May, which broke down. The High Court of Justice in Ireland ruled on 31 July 1923 that a state of war no longer existed, and consequently the internment of Republicans, permitted under common law only in wartime, was now illegal. Without a formal peace, holding 13,000 prisoners and worried that fighting could break out again at any time, the government enacted two Public Safety (Emergency Powers) Acts on 1 and 3 August 1923, to permit continued internment and other measures. Thousands of Anti-Treaty IRA members (including de Valera on 15 August) were arrested by the Free State forces in the weeks and months after the end of the war, when they had dumped their arms and returned home.\nA general election was held on 27 August 1923, which Cumann na nGaedheal, the pro-Free State party, won with about 40% of the first-preference vote. The Republicans, represented by Sinn F\u00e9in, won about 27% of the vote. Many of their candidates and supporters were still imprisoned before, during and after the election.\nIn October 1923, around 8,000 of the 12,000 Republican prisoners in Free State gaols went on a hunger strike which lasted for 41 days. Among those who died were Denny Barry, Joseph Whitty and Andy O'Sullivan) However, most of the women prisoners were released shortly thereafter and the hunger strike helped concentrate the Republican movement on the prisoners and their associated organisations. In July, de Valera had recognised the Republican political interests lay with the prisoners and went so far as to say:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The whole future of our cause and of the nation depends in my opinion upon the spirit of the prisoners in the camps and in the jails. You are the repositories of the NATIONAL FAITH AND WILL.\nAttacks on former Unionists.\nAlthough the cause of the Civil War was the Treaty, as the war developed the anti-treaty forces sought to identify their actions with the traditional Republican cause of the \"men of no property\" and the result was that large Anglo-Irish landowners and some less well-off Southern Unionists were attacked. A total of 192 \"stately homes\" of the old landed class and of Free State politicians were destroyed by anti-treaty forces during the war.\nThe stated reason for such attacks was that some landowners had become Free State senators. In October 1922, a deputation of Southern Unionists met W. T. Cosgrave to offer their support to the Free State and some of them had received positions in the State's Upper house or Senate. Among the prominent senators whose homes were attacked were: Palmerstown House near Naas, which belonged to the Earl of Mayo, Moore Hall in Mayo, Horace Plunkett (who had helped to establish the rural co-operative schemes), and Senator Henry Guinness (which was unsuccessful). Also burned was Marlfield House in Clonmel, the home of Senator John Philip Bagwell, with its extensive library of historical documents. Bagwell was kidnapped and held in the Dublin Mountains, but later released when reprisals were threatened.\nHowever, in addition to their allegiance to the Free State, there were also other factors behind Republican animosity towards the old landed class. Many, but not all of these people, had supported the Crown forces during the War of Independence. This support was often largely moral, but sometimes it took the form of actively assisting the British in the conflict. Such attacks should have ended with the Truce of 11 July 1921, but they continued after the truce and escalated during the Civil War. In July 1922, Con Moloney, the IRA Adjutant General, ordered that unionist property should be seized to accommodate their men. The \"worst spell\" of attacks on former unionist property came in the early months of 1923, 37 \"big houses\" being burnt in January and February alone.\nThough the Land Purchase (Ireland) Act 1903 allowed tenants to buy land from their landlords, some small farmers, particularly in Mayo and Galway, simply occupied land belonging to political opponents during this period when the RIC had ceased to function. In 1919, senior Sinn F\u00e9in officials were sufficiently concerned at this unilateral action that they instituted Arbitration Courts to adjudicate disputes. Sometimes these attacks had sectarian overtones, although most IRA men made no distinction between Catholic and Protestant supporters of the Irish government.\nThe IRA burnt an orphanage housing Protestant boys near Clifden, County Galway in June 1922, on the ground that it was \"pro-British\". The 60 orphans were taken to Devonport on board a Royal Navy destroyer.\nControversy continues to this day about the extent of intimidation of Protestants at this time. Many left Ireland during and after the Civil War. Dr Andy Bielenberg of UCC considers that about 41,000 who were not linked to the former British administration left Southern Ireland (which became the Irish Free State) between 1919 and 1923. He has found that a \"high-water mark\" of this 41,000 left between 1921 and 1923. In all, from 1911 to 1926, the Protestant population of the 26 counties fell from some 10.4% of the total population to 7.4%.\nForeign support.\nThe Civil War attracted international attention which led to various groups expressing support and opposition to the anti-treaty side. The Communist Party of Great Britain in its journal \"The Communist\" wrote \"The proletarians of the IRA have the future of Ireland in their hands. If the Irish Labour Party would only dare! A mass movement of the Irish workers in alliance with the IRA could establish a Workers' Republic now\". They were also supported by the Communist International (Comintern) which on 3 January 1923 passed a resolution stating it \"sends fraternal greetings to the struggling Irish national revolutionaries and feels assured that they will soon tread the only path that leads to real freedom \u2013 the path of Communism. The CI will assist all efforts to organise the struggle to combat this terror and to help the Irish workers and peasants to victory.\"\nThe majority of Irish-Americans supported the treaty, including those in Clann na Gael and Friends of Irish Freedom. However anti-treaty republicans had control of what was left of Clann na Gael and the American Association for the Recognition of the Irish Republic so they supported the anti-treaty side during the war.\nConsequences.\nCasualties.\nThe Civil War, though short, was bloody. It cost the lives of many public figures, including Michael Collins, Cathal Brugha, Arthur Griffith and Liam Lynch. Both sides carried out brutal acts\u2014the anti-treaty forces killed a TD and several other pro-Treaty politicians and burned many homes of senators and Free State supporters; while the government executed anti-treaty prisoners, officially and unofficially.\nThe 2023 Irish Civil War Fatalities Project, a University College Cork research project funded by the Department of Tourism, Culture, Arts, Gaeltacht, Sport and Media, has calculated that the pro-treaty forces suffered 637 fatalities from all causes. Both the project and the Republican roll of honour, compiled in the 1920s, calculate that 426 anti-Treaty IRA Volunteers were killed between January 1922 and April 1924. It has, however, been suggested that the anti-treaty forces' true death toll was higher. For total combatant and civilian deaths, figures of 1,426 in the Free State and 1,485 for the island of Ireland have been calculated by the 2023 project. A 2012 county-by-county study suggested a death toll of just under 2,000. In the decades following the Civil War, casualty figures as high as 4,000 were suggested, though these numbers are generally accepted to be too high.\nThe Garda S\u00edoch\u00e1na (new police force) was not involved in the war, which meant that it was well placed to develop into an unarmed and politically neutral police service after the war. It had been disarmed by the Government in order to win public confidence in June\u2013September 1922 and in December 1922, the IRA issued a General Order not to fire on the Civil Guard. The Criminal Investigation Department, or CID, a 350-strong, armed, plain-clothed Police Corps that had been established during the conflict for the purposes of counter-insurgency, was disbanded in October 1923, shortly after the conflict's end.\nEconomic costs.\nThe economic costs of the war were also high. As their forces abandoned their fixed positions in July\u2013August 1922, the Republicans burned many of the administrative buildings and businesses that they had been occupying. In addition, their subsequent guerrilla campaign caused much destruction, and the economy of the Free State suffered a hard blow in the earliest days of its existence, as a result. The material damage caused by the war to property in the Free State has been estimated to be in the region of \u00a350 million in 1922. This is equivalent to about \u00a32.2 billion, or \u20ac2.6 billion worth of damage in 2024 values.\nParticularly damaging to the Free State's economy was the systematic destruction of railway infrastructure and roads by the Republicans. In addition, the cost to the Free State of waging the war came to another \u00a317 million (\u00a3718m or \u20ac883m in 2022 values). By September 1923, Deputy Hogan estimated the cost at \u00a350 million. The new State ended 1923 with a budget deficit of over \u00a34 million (\u00a3168m or \u20ac196m in 2022 values). This weakened financial situation meant that the new state could not pay its share of Imperial debt under the treaty. This adversely affected the boundary negotiations in 1924\u201325, in which the Free State government acquiesced that border with Northern Ireland would remain unchanged in exchange for forgiveness of the Imperial debt. Further, the state undertook to pay for damage caused to property between the truce of July 1921 and the end of the Civil War; W. T. Cosgrave told the D\u00e1il:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Every Deputy in this House is aware of the complaint which has been made that the measure of compensation for post-Truce damage compares unfavourably with the awards for damage suffered pre-Truce.\nPolitical results.\nThe fact that the Irish Civil War was fought between Irish Nationalist factions meant that the sporadic conflict in Northern Ireland ended. Collins and Sir James Craig signed an agreement to end it on 30 March 1922, but, despite this, Collins covertly supplied arms to the Northern IRA until a week before his death in August 1922. Because of the Irish Civil War, Northern Ireland was able to consolidate its existence and the partition of Ireland was confirmed for the foreseeable future. The continuing war also confirmed the northern Unionists' existing stance against the ethos of all shades of nationalism. This might have led to open hostilities between North and South had the Irish Civil War not broken out. Indeed, the Ulster Special Constabulary (the \"B-Specials\") that had been established in 1920 (on the foundation of Northern Ireland) was expanded in 1922 rather than being demobilised.\nIn the event, it was only well after their defeat in the Civil War that anti-treaty Irish Republicans seriously considered whether to take armed action against British rule in Northern Ireland (the first serious suggestion to do this came in the late 1930s). The northern units of the IRA largely supported the Free State side in the Civil War because of Collins's policies, and over 500 of them joined the new Free State's National Army.\nThe cost of the war and the budget deficit it caused was a difficulty for the new Free State and affected the Boundary Commission negotiations of 1925, which were to determine the border with Northern Ireland. The Free State agreed to waive its claim to predominantly Nationalist areas in Northern Ireland and in return its agreed share of the Imperial debt under the 1921 Treaty was not paid.\nIn 1926, having failed to persuade the majority of the Anti-Treaty IRA or the anti-treaty party of Sinn F\u00e9in to accept the new status quo as a basis for an evolving Republic, a large faction led by de Valera and Aiken left to resume constitutional politics and to found the Fianna F\u00e1il party. Whereas Fianna F\u00e1il was to become the dominant party in Irish politics, Sinn F\u00e9in became a small, isolated political party. The IRA, then much more numerous and influential than Sinn F\u00e9in, remained associated with Fianna F\u00e1il (though not directly) until banned by de Valera in 1935.\nIn 1927, Fianna F\u00e1il members took the Oath of Allegiance and entered the D\u00e1il, effectively recognising the legitimacy of the Free State. The Free State was already moving towards independence by this point. Under the Statute of Westminster 1931, the British Parliament gave up its right to legislate for members of the British Commonwealth. When elected to power in 1932, Fianna F\u00e1il under de Valera set about dismantling what they considered to be objectionable features of the treaty, abolishing the Oath of Allegiance, removing the power of the Office of Governor General (British representative in Ireland) and abolishing the Senate, which was dominated by former Unionists and pro-treaty Nationalists. In 1937, they passed a new constitution, which made a President the head of state, did not mention any allegiance to the British monarch, and which included a territorial claim to Northern Ireland. The following year, Britain returned without conditions the seaports that it had kept under the terms of the treaty. When the Second World War broke out in 1939, the state was able to demonstrate its independence by remaining neutral throughout the war, although Dublin did to some extent tacitly support the Allies. Finally, in 1948, a coalition government, containing elements of both sides in the Civil War (pro-treaty Fine Gael and anti-treaty Clann na Poblachta) left the British Commonwealth and described the state as a republic in The Republic of Ireland Act 1948. By the 1950s, the issues over which the Civil War had been fought were largely settled.\nLegacy and memory.\nAs with most civil wars, the internecine conflict left a bitter legacy, which continues to influence Irish politics to this day. The two largest political parties in the republic through most of its history (except for the 2011 and 2020 general elections) were Fianna F\u00e1il and Fine Gael, the descendants respectively of the anti-treaty and pro-treaty forces of 1922. Until the 1970s, almost all of Ireland's prominent politicians were veterans of the Civil War, a fact which poisoned the relationship between Ireland's two biggest parties. Civil War veterans include Republicans \u00c9amon de Valera, Frank Aiken, Todd Andrews and Se\u00e1n Lemass; and Free State supporters W. T. Cosgrave, Richard Mulcahy and Kevin O'Higgins.\nMoreover, many of these men's sons and daughters also became politicians, meaning that the personal wounds of the civil war were felt over three generations. In the 1930s, after Fianna F\u00e1il took power for the first time, it looked possible for a while that the Civil War might break out again between the IRA and the pro-Free State Blueshirts. This crisis was averted, and by the 1950s violence was no longer prominent in politics in the Republic of Ireland. However, the breakaway IRA continued (and continues in various forms) to exist. It was not until 1948 that the IRA renounced military attacks on the forces of the southern Irish state when it became the Republic of Ireland. After this point, the organisation dedicated itself primarily to the end of British rule in Northern Ireland. Nonetheless, the IRA Army Council continued to make claim to be the legitimate Provisional Government of the Irish Republic declared in 1916 and annulled by the Anglo-Irish Treaty of 1921.\nFictional accounts.\nAccording to Edward Quinn, the play \"Juno and the Paycock\" by Se\u00e1n O'Casey is a tragicomedy that criticises the civil war and the foolishness that led to it. Irish writer James Stephens says the play's theme is an \"orchestrated hymn against all poverty and hate.\"\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFootnotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "15215", "revid": "50667879", "url": "https://en.wikipedia.org/wiki?curid=15215", "title": "Internet Explorer", "text": "Web browser series by Microsoft\nInternet Explorer (formerly Microsoft Internet Explorer and Windows Internet Explorer, commonly abbreviated as IE or MSIE) is a retired series of graphical web browsers developed by Microsoft that were used in the Windows line of operating systems. While IE has been discontinued on most Windows editions, it remains supported on certain editions of Windows, such as Windows 10 LTSB/LTSC. Starting in 1995, it was first released as part of the add-on package Plus! for Windows 95 that year. Later versions were available as free downloads or in-service packs and included in the original equipment manufacturer (OEM) service releases of Windows 95 and later versions of Windows. Microsoft spent over US$ per year on Internet Explorer in the late 1990s, with over 1,000 people involved in the project by 1999. In 2016, Microsoft Edge was released to succeed Internet Explorer 11 as Microsoft's primary web browser. New feature development for Internet Explorer was discontinued that same year, and support for the browser officially ended on June 15, 2022, for Windows 10 Semi-Annual Channel (SAC) editions.\nInternet Explorer was once the most widely used web browser, attaining a peak of 95% usage share by 2003. It has since fallen out of general use after retirement. This came after Microsoft used bundling to win the first browser war against Netscape, which was the dominant browser in the 1990s. Its usage share has since declined with the launches of Firefox (2004) and Google Chrome (2008) and with the growing popularity of mobile operating systems such as Android and iOS that do not support Internet Explorer. Microsoft Edge, IE's successor, first overtook Internet Explorer in terms of market share in November 2019. Versions of Internet Explorer for other operating systems have also been produced, including an Xbox 360 version called Internet Explorer for Xbox and for platforms Microsoft no longer supports: Internet Explorer for Mac and Internet Explorer for UNIX (Solaris and HP-UX), and an embedded OEM version called Pocket Internet Explorer, later rebranded Internet Explorer Mobile, made for Windows CE, Windows Phone, and, previously, based on Internet Explorer 7, for Windows Phone 7.\nThe browser has been scrutinized throughout its development for its use of third-party technology (such as the source code of Spyglass Mosaic, used without royalty in early versions) and security and privacy vulnerabilities, and the United States and the European Union have determined that the integration of Internet Explorer with Windows has been to the detriment of fair browser competition.\nThe core of Internet Explorer 11 will continue being shipped and supported until at least 2029 as \"IE Mode\", a feature of Microsoft Edge, enabling Edge to display web pages using Internet Explorer 11's Trident layout engine and other components. Through IE Mode, the underlying technology of Internet Explorer 11 partially exists on versions of Windows that do not support IE11 as a proper application, including newer versions of Windows 10, as well as Windows 11 21H2-25H2, Windows Server 2022 and Windows Server 2025. \nHistory.\nInternet Explorer 1.\nThe Internet Explorer project was started in the summer of 1994 by Thomas Reardon, who, according to former project lead Ben Slivka, used source code from Spyglass, Inc. Mosaic, which was an early commercial web browser with formal ties to the pioneering National Center for Supercomputing Applications (NCSA) Mosaic browser. In late 1994, Microsoft licensed Spyglass Mosaic for a quarterly fee plus a percentage of Microsoft's non-Windows revenues for the software. Although bearing a name similar to NCSA Mosaic, Spyglass Mosaic had used the NCSA Mosaic source code sparingly.\nThe first version, dubbed Microsoft Internet Explorer, was installed as part of the \"Internet Jumpstart Kit\" in the Microsoft Plus! pack for Windows 95. The Internet Explorer team began with about six people in early development. Internet Explorer 1.5 was released several months later for Windows NT and added support for basic table rendering. By including it free of charge with their operating system, they did not have to pay royalties to Spyglass Inc, resulting in a lawsuit and a US$8\u00a0million settlement on January 22, 1997.\nMicrosoft was sued by SyNet Inc. in 1996, for trademark infringement, claiming it owned the rights to the name \"Internet Explorer\". It ended with Microsoft paying $5 million to settle the lawsuit.\nInternet Explorer 2.\nInternet Explorer 2 is the second major version of Internet Explorer, released on November 28, 1995, for Windows 95 and Windows NT, and on April 23, 1996, for Apple Macintosh and Windows 3.1.\nInternet Explorer 3.\nInternet Explorer 3 is the third major version of Internet Explorer, released on August 13, 1996, for Microsoft Windows and on January 8, 1997, for Apple Mac OS.\nInternet Explorer 4.\nInternet Explorer 4 is the fourth major version of Internet Explorer, released in September 1997 for Microsoft Windows, Mac OS, Solaris, and HP-UX. It was the first version of Internet Explorer to use the Trident web engine.\nInternet Explorer 5.\nInternet Explorer 5 is the fifth major version of Internet Explorer, released on March 18, 1999, for Windows 3.1, Windows NT 3, Windows 95, Windows NT 4.0 SP3, Windows 98, Mac OS X (up to v5.2.3), Classic Mac OS (up to v5.1.7), Solaris and HP-UX (up to 5.01 SP1).\nInternet Explorer 6.\nInternet Explorer 6 is the sixth major version of Internet Explorer, released on August 24, 2001, for Windows NT 4.0 SP6a, Windows 98, Windows 2000, Windows ME and as the default web browser for Windows XP and Windows Server 2003.\nInternet Explorer 7.\nInternet Explorer 7 is the seventh major version of Internet Explorer, released on October 18, 2006, for Windows XP SP2, Windows Server 2003 SP1 and as the default web browser for Windows Vista, Windows Server 2008 and Windows Embedded POSReady 2009. IE7 introduces tabbed browsing.\nInternet Explorer 8.\nInternet Explorer 8 is the eighth major version of Internet Explorer, released on March 19, 2009, for Windows XP, Windows Server 2003, Windows Vista, Windows Server 2008 and as the default web browser for Windows 7 (later default was Internet Explorer 11) and Windows Server 2008 R2.\nInternet Explorer 9.\nInternet Explorer 9 is the ninth major version of Internet Explorer, released on March 14, 2011, for Windows 7, Windows Server 2008 R2, Windows Vista Service Pack 2 and Windows Server 2008 SP2 with the Platform Update.\nInternet Explorer 10.\nInternet Explorer 10 is the tenth major version of Internet Explorer, released on October 26, 2012, and is the default web browser for Windows 8 and Windows Server 2012. It became available for Windows 7 SP1 and Windows Server 2008 R2 SP1 in February 2013.\nInternet Explorer 11.\nInternet Explorer 11 is featured in Windows 8.1, Windows Server 2012 R2 and Windows RT 8.1, which was released on October 17, 2013. It includes an incomplete mechanism for syncing tabs. It is a major update to its developer tools, enhanced scaling for high DPI screens, HTML5 prerender and prefetch, hardware-accelerated JPEG decoding, closed captioning, HTML5 full screen, and is the first Internet Explorer to support WebGL and Google's protocol SPDY (starting at v3). This version of IE has features dedicated to Windows 8.1, including cryptography (WebCrypto), adaptive bitrate streaming (Media Source Extensions) and Encrypted Media Extensions.\nInternet Explorer 11 was made available for Windows 7 users to download on November 7, 2013, with Automatic Updates in the following weeks.\nInternet Explorer 11's user agent string now identifies the agent as \"Trident\" (the underlying browser engine) instead of \"MSIE\". It also announces compatibility with Gecko (the browser engine of Firefox).\nMicrosoft claimed that Internet Explorer 11, running the WebKit SunSpider JavaScript Benchmark, was the fastest browser as of October 15, 2013.\nInternet Explorer 11 was made available for Windows Server 2012 and Windows Embedded 8 Standard in April 2019.\nEnd of life.\nMicrosoft Edge [Legacy] was officially unveiled on January 21, 2015, as \"Project Spartan\". On April 29, 2015, Microsoft announced that Microsoft Edge would replace Internet Explorer as the default browser in Windows 10. However, Internet Explorer remained the default web browser on the Windows 10 Long Term Servicing Channel (LTSC) and on Windows Server until 2021, primarily for enterprise purposes.\nInternet Explorer is still installed in Windows 10 to maintain compatibility with older websites and intranet sites that require ActiveX and other legacy web technologies. The browser's MSHTML rendering engine also remains for compatibility reasons.\nAdditionally, Microsoft Edge (Chromium) shipped with the \"Internet Explorer mode\" feature, which enables support for legacy internet applications. This is possible through use of the Trident MSHTML engine, the rendering code of Internet Explorer. Microsoft has committed to supporting Internet Explorer mode at least through 2029, with a one-year notice before it is discontinued. \nWith the release of Microsoft Edge [Legacy], the development of new features for Internet Explorer ceased. Internet Explorer 11 was the final release, and Microsoft began the process of deprecating Internet Explorer. During this process, it will still be maintained as part of Microsoft's support policies.\nSince January 12, 2016, only the latest version of Internet Explorer available for each version of Windows has been supported. At the time, nearly half of Internet Explorer users were using an unsupported version.\nIn February 2019, Microsoft Chief of Security Chris Jackson recommended that users stop using Internet Explorer as their default browser.\nVarious websites have dropped support for Internet Explorer. On June 1, 2020, the Internet Archive removed Internet Explorer from its list of supported browsers, due to the browser's dated nature. Since November 30, 2020, the web version of Microsoft Teams can no longer be accessed using Internet Explorer 11, followed by the remaining Microsoft 365 applications since August 17, 2021. WordPress also dropped support for the browser in July 2021.\nMicrosoft disabled the normal means of launching Internet Explorer in Windows 11 and later versions of Windows 10, but it is still possible for users to launch the browser from the Control Panel's browser toolbar settings or via PowerShell.\nOn June 15, 2022, Internet Explorer 11 support ended for the Windows 10 Semi-Annual Channel (SAC). Users on these versions of Windows 10 were redirected to Microsoft Edge starting on February 14, 2023, and visual references to the browser (such as icons on the taskbar) would have been removed on June 13, 2023. However, on May 19, 2023, various organizations disapproved, leading Microsoft to withdraw the change.\nOther versions of Windows that were still supported at the time were unaffected. Specifically, Windows 7 ESU, Windows 8.x, Windows RT; Windows Server 2008/R2 ESU, Windows Server 2012/R2 and later; and Windows 10 LTSB/LTSC continued to receive updates until their respective end of life dates. \nOn other versions of Windows, Internet Explorer will still be supported until their own end of support dates. IE7 was supported until October 10, 2023, alongside the end of support for Windows Embedded Compact 2013, while IE9 is supported until January 13, 2026, alongside the end of [paid and grandfathered] Premium Assurance support for customers on Windows Server 2008. Barring additional changes to the support policy, Internet Explorer 11 will be supported until January 13, 2032, concurrent with the end of support for Windows 10 IoT Enterprise LTSC 2021.\nFeatures.\nInternet Explorer has been designed to view a broad range of web pages and provide certain features within the operating system, including Microsoft Update. During the height of the browser wars, Internet Explorer superseded Netscape only when it caught up technologically to support the progressive features of the time.\nStandards support.\nInternet Explorer, using the MSHTML (Trident) browser engine:\nInternet Explorer uses DOCTYPE sniffing to choose between standards mode and a \"quirks mode\" in which it deliberately mimics nonstandard behaviors of old versions of MSIE for HTML and CSS rendering on screen (Internet Explorer always uses standards mode for printing). It also provides its own dialect of ECMAScript called JScript.\nInternet Explorer was criticized by Tim Berners-Lee for its limited support for SVG, which is promoted by W3C.\nNon-standard extensions.\nInternet Explorer has introduced an array of proprietary extensions to many of the standards, including HTML, CSS, and the DOM. This has resulted in several web pages that appear broken in standards-compliant web browsers and has introduced the need for a \"quirks mode\" to allow for rendering improper elements meant for Internet Explorer in these other browsers.\nInternet Explorer has introduced several extensions to the DOM that have been adopted by other browsers.\nThese include the inner HTML property, which provides access to the HTML string within an element, which was part of IE 5 and was standardized as part of HTML 5 roughly 15 years later after all other browsers implemented it for compatibility, the XMLHttpRequest object, which allows the sending of HTTP request and receiving of HTTP response, and may be used to perform AJAX, and the designMode attribute of the content Document object, which enables rich text editing of HTML documents. Some of these functionalities were not possible until the introduction of the W3C DOM methods. Its Ruby character extension to HTML is also accepted as a module in W3C XHTML 1.1, though it is not found in all versions of W3C HTML.\nMicrosoft submitted several other features of IE for consideration by the W3C for standardization. These include the 'behavior' CSS property, which connects the HTML elements with JScript behaviors (known as HTML Components, HTC), HTML+TIME profile, which adds timing and media synchronization support to HTML documents (similar to the W3C XHTML+SMIL), and the VML vector graphics file format. However, all were rejected, at least in their original forms; VML was subsequently combined with PGML (proposed by Adobe and Sun), resulting in the W3C-approved SVG format, one of the few vector image formats being used on the web, which IE did not support until version 9.\nOther non-standard behaviors include: support for vertical text, but in a syntax different from W3C CSS3 candidate recommendation, support for a variety of image effects and page transitions, which are not found in W3C CSS, support for obfuscated script code, in particular JScript.Encode, as well as support for embedding EOT fonts in web pages.\nFavicon.\nSupport for favicons was first added in Internet Explorer 5. Internet Explorer supports favicons in PNG, static GIF and native Windows icon formats. In Windows Vista and later, Internet Explorer can display native Windows icons that have embedded PNG files.\nUsability and accessibility.\nInternet Explorer makes use of the accessibility framework provided in Windows. Internet Explorer is also a user interface for FTP, with operations similar to Windows Explorer. Internet Explorer 5 and 6 had a side bar for web searches, enabling jumps through pages from results listed in the side bar. Pop-up blocking and tabbed browsing were added respectively in Internet Explorer 6 and Internet Explorer 7. Tabbed browsing can also be added to older versions by installing MSN Search Toolbar or Yahoo Toolbar.\nCache.\nInternet Explorer caches visited content in the Temporary Internet Files folder to allow quicker access (or offline access) to previously visited pages. The content is indexed in a database file, known as Index.dat. Multiple Index.dat files exist which index different content\u2014visited content, web feeds, visited URLs, cookies, etc.\nPrior to IE7, clearing the cache used to clear the index but the files themselves were not reliably removed, posing a potential security and privacy risk. In IE7 and later, when the cache is cleared, the cache files are more reliably removed, and the index.dat file is overwritten with null bytes.\nCaching has been improved in IE9.\nGroup Policy.\nInternet Explorer is fully configurable using Group Policy. Administrators of Windows Server domains (for domain-joined computers) or the local computer can apply and enforce a variety of settings on computers that affect the user interface (such as disabling menu items and individual configuration options), as well as underlying security features such as downloading of files, zone configuration, per-site settings, ActiveX control behavior and others. Policy settings can be configured for each user and for each machine. Internet Explorer also supports Integrated Windows Authentication.\nArchitecture.\nInternet Explorer uses a componentized architecture built on the Component Object Model (COM) technology. It consists of several major components, each of which is contained in a separate dynamic-link library (DLL) and exposes a set of COM programming interfaces hosted by the Internet Explorer main executable, &lt;samp style=\"padding-left:0.4em; padding-right:0.4em; color:var( --color-subtle, #666666); \" &gt;iexplore.exe&lt;/samp&gt;:\nInternet Explorer does not include any native scripting functionality. Rather, &lt;samp style=\"padding-left:0.4em; padding-right:0.4em; color:var( --color-subtle, #666666); \" &gt;MSHTML.dll&lt;/samp&gt; exposes an API that permits a programmer to develop a scripting environment to be plugged-in and to access the DOM tree. Internet Explorer 8 includes the bindings for the Active Scripting engine, which is a part of Microsoft Windows and allows any language implemented as an Active Scripting module to be used for client-side scripting. By default, only the JScript and VBScript modules are provided; third party implementations like ScreamingMonkey (for ECMAScript 4 support) can also be used. Microsoft also makes available the Microsoft Silverlight runtime that allows CLI languages, including DLR-based dynamic languages like IronPython and IronRuby, to be used for client-side scripting.\nInternet Explorer 8 introduced some major architectural changes, called \"loosely coupled IE\" (LCIE). LCIE separates the main window process (frame process) from the processes hosting the different web applications in different tabs (tab processes). A frame process can create multiple tab processes, each of which can be of a different integrity level, each tab process can host multiple web sites. The processes use asynchronous inter-process communication to synchronize themselves. Generally, there will be a single frame process for all web sites. In Windows Vista with protected mode turned on, however, opening privileged content (such as local HTML pages) will create a new tab process as it will not be constrained by protected mode.\nExtensibility.\nInternet Explorer exposes a set of Component Object Model (COM) interfaces that allows add-ons to extend the functionality of the browser. Extensibility is divided into two types: Browser extensibility and content extensibility. Browser extensibility involves adding context menu entries, toolbars, menu items or Browser Helper Objects (BHO). BHOs are used to extend the feature set of the browser, whereas the other extensibility options are used to expose that feature in the user interface. Content extensibility adds support for non-native content formats. It allows Internet Explorer to handle new file formats and new protocols, e.g. WebM or SPDY. In addition, web pages can integrate widgets known as ActiveX controls which run on Windows only but have vast potentials to extend the content capabilities; Adobe Flash Player and Microsoft Silverlight are examples. Add-ons can be installed either locally, or directly by a web site.\nSince malicious add-ons can compromise the security of a system, Internet Explorer implements several safeguards. Internet Explorer 6 with Service Pack 2 and later feature an Add-on Manager for enabling or disabling individual add-ons, complemented by a \"No Add-Ons\" mode. Starting with Windows Vista, Internet Explorer and its BHOs run with restricted privileges and are isolated from the rest of the system. Internet Explorer 9 introduced a new component\u00a0\u2013 Add-on Performance Advisor. Add-on Performance Advisor shows a notification when one or more of installed add-ons exceed a pre-set performance threshold. The notification appears in the Notification Bar when the user launches the browser. Windows 8 and Windows RT introduce a Metro-style version of Internet Explorer that is entirely sandboxed and does not run add-ons at all. In addition, Windows RT cannot download or install ActiveX controls at all; although existing ones bundled with Windows RT still run in the traditional version of Internet Explorer.\nInternet Explorer itself can be hosted by other applications via a set of COM interfaces. This can be used to embed the browser functionality inside a computer program or create Internet Explorer shells.\nSecurity.\nInternet Explorer uses a zone-based security framework that groups sites based on certain conditions, including whether it is an Internet- or intranet-based site as well as a user-editable whitelist. Security restrictions are applied per zone; all the sites in a zone are subject to the restrictions.\nInternet Explorer 6 SP2 onwards uses the \"Attachment Execution Service\" of Microsoft Windows to mark executable files downloaded from the Internet as being potentially unsafe. Accessing files marked as such will prompt the user to make an explicit trust decision to execute the file, as executables originating from the Internet can be potentially unsafe. This helps in preventing the accidental installation of malware.\nInternet Explorer 7 introduced the phishing filter, which restricts access to phishing sites unless the user overrides the decision. With version 8, it also blocks access to sites known to host malware. Downloads are also checked to see if they are known to be malware-infected.\nIn Windows Vista, Internet Explorer by default runs in what is called \"Protected Mode\", where the privileges of the browser itself are severely restricted\u2014it cannot make any system-wide changes. One can optionally turn this mode off, but this is not recommended. This also effectively restricts the privileges of any add-ons. As a result, even if the browser or any add-on is compromised, the damage the security breach can cause is limited.\nPatches and updates to the browser are released periodically and made available through the Windows Update service, as well as through Automatic Updates. Although security patches continue to be released for a range of platforms, most feature additions and security infrastructure improvements are only made available on operating systems that are in Microsoft's mainstream support phase.\nOn December 16, 2008, Trend Micro recommended users switch to rival browsers until an emergency patch was released to fix a potential security risk which \"could allow outside users to take control of a person's computer and steal their passwords.\" Microsoft representatives countered this recommendation, claiming that \"0.02% of internet sites\" were affected by the flaw. A fix for the issue was released the following day with the Security Update for Internet Explorer KB960714, on Microsoft Windows Update.\nIn 2010, Germany's Federal Office for Information Security, known by its German initials, BSI, advised \"temporary use of alternative browsers\" because of a \"critical security hole\" in Microsoft's software that could allow hackers to remotely plant and run malicious code on Windows PCs.\nIn 2011, a report by Accuvant, funded by Google, rated the security (based on sandboxing) of Internet Explorer worse than Google Chrome but better than Mozilla Firefox.\nA 2017 browser security white paper comparing Google Chrome, Microsoft Edge [Legacy], and Internet Explorer 11 by X41 D-Sec in 2017 came to similar conclusions, also based on sandboxing and support of legacy web technologies.\nSecurity vulnerabilities.\nInternet Explorer has been subjected to many security vulnerabilities and concerns such that the volume of criticism for IE is unusually high. Much of the spyware, adware, and computer viruses across the Internet are made possible by exploitable bugs and flaws in the security architecture of Internet Explorer, sometimes requiring nothing more than viewing of a malicious web page to install themselves. This is known as a \"drive-by install\". There are also attempts to trick the user into installing malicious software by misrepresenting the software's true purpose in the description section of an ActiveX security alert.\nA number of security flaws affecting IE originated not in the browser itself, but in ActiveX-based add-ons used by it. Because the add-ons have the same privilege as IE, the flaws can be as critical as browser flaws. This has led to the ActiveX-based architecture being criticized for being fault-prone. By 2005, some experts maintained that the dangers of ActiveX had been overstated and there were safeguards in place. In 2006, new techniques using automated testing found more than a hundred vulnerabilities in standard Microsoft ActiveX components. Security features introduced in Internet Explorer 7 mitigated some of these vulnerabilities.\nIn 2008, Internet Explorer had a number of published security vulnerabilities. According to research done by security research firm Secunia, Microsoft did not respond as quickly as its competitors in fixing security holes and making patches available. The firm also reported 366 vulnerabilities in ActiveX controls, an increase from the previous year.\nAccording to an October 2010 report in \"The Register\", researcher Chris Evans had detected a known security vulnerability which, then dating back to 2008, had not been fixed for at least six hundred days. Microsoft says that it had known about this vulnerability, but it was of exceptionally low severity as the victim web site must be configured in a peculiar way for this attack to be feasible at all.\nIn December 2010, researchers were able to bypass the \"Protected Mode\" feature in Internet Explorer.\nVulnerability exploited in attacks on U.S. firms.\nIn an advisory on January 14, 2010, Microsoft said that attackers targeting Google and other U.S. companies used software that exploits a security hole, which had already been patched, in Internet Explorer. The vulnerability affected Internet Explorer 6 on Windows XP and Server 2003, IE6 SP1 on Windows 2000 SP4, IE7 on Windows Vista, XP, Server 2008, and Server 2003, IE8 on Windows 7, Vista, XP, Server 2003, and Server 2008 (R2).\nThe German government warned users against using Internet Explorer and recommended switching to an alternative web browser, due to the major security hole described above that was exploited in Internet Explorer. The Australian and French governments also issued a similar warning a few days later.\nMajor vulnerability across versions.\nOn April 26, 2014, Microsoft issued a security advisory relating to CVE- (use-after-free vulnerability in Microsoft Internet Explorer 6 through 11), a vulnerability that could allow \"remote code execution\" in Internet Explorer versions 6 to 11. On April 28, 2014, the United States Department of Homeland Security's United States Computer Emergency Readiness Team (US-CERT) released an advisory stating that the vulnerability could result in \"the complete compromise\" of an affected system. US-CERT recommended reviewing Microsoft's suggestions to mitigate an attack or using an alternate browser until the bug is fixed. The UK National Computer Emergency Response Team (CERT-UK) published an advisory announcing similar concerns and for users to take the additional step of ensuring their antivirus software is up to date. Symantec, a cyber security firm, confirmed that \"the vulnerability crashes Internet Explorer on Windows XP.\" The vulnerability was resolved on May 1, 2014, with a security update.\nMarket adoption and usage share.\nThe adoption rate of Internet Explorer seems to be closely related to that of Microsoft Windows, as it is the default web browser that comes with Windows. Since the integration of Internet Explorer 2.0 with Windows 95 OSR 1 in 1996, and especially after version 4.0's release in 1997, the adoption was greatly accelerated: from below 20% in 1996, to about 40% in 1998, and over 80% in 2000. This made Microsoft the winner in the infamous 'first browser war' against Netscape. Netscape Navigator was the dominant browser during 1995 and until 1997, but rapidly lost share to IE starting in 1998, and eventually slipped behind in 1999. The integration of IE with Windows led to a lawsuit by AOL, Netscape's owner, accusing Microsoft of unfair competition. The infamous case was eventually won by AOL but by then it was too late, as Internet Explorer had already become the dominant browser.\nInternet Explorer peaked during 2002 and 2003, with about 95% share. Its first notable competitor after beating Netscape was Firefox from Mozilla, which itself was an offshoot from Netscape.\nApproximate usage over time based on various usage share counters averaged for the year overall, or for the fourth quarter, or for the last month in the year depending on availability of reference.\nInternet Explorer's market share fell below 50% in September 2010. In May 2012, Google Chrome overtook Internet Explorer as the most used browser worldwide, according to StatCounter.\nIndustry adoption.\nBrowser Helper Objects are also used by many search engines companies and third parties for creating add-ons that access their services, such as search engine toolbars. Because of the use of COM, it is possible to embed web-browsing functionality in third-party applications. Hence, there are several Internet Explorer shells, and several content-centric applications like RealPlayer also use Internet Explorer's web browsing module for viewing web pages within the applications.\nRemoval.\nWhile a major upgrade of Internet Explorer can be uninstalled in a traditional way if the user has saved the original application files for installation, the matter of uninstalling the version of the browser that has shipped with an operating system remains a controversial one.\nThe idea of removing a stock install of Internet Explorer from a Windows system was proposed during the \"United States v. Microsoft Corp.\" case. One of Microsoft's arguments during the trial was that removing Internet Explorer from Windows may result in system instability. Indeed, programs that depend on libraries installed by IE, including Windows help and support system, fail to function without IE. Before Windows Vista, it was not possible to run Windows Update without IE because the service used ActiveX technology, which no other web browser supports.\nImpersonation by malware.\nThe popularity of Internet Explorer led to the appearance of malware abusing its name. On January 28, 2011, a fake Internet Explorer browser calling itself \"Internet Explorer \u2013 Emergency Mode\" appeared. It closely resembled the real Internet Explorer but had fewer buttons, no tabs and no search bar. If a user attempted to launch any other browser such as Google Chrome, Mozilla Firefox, Opera, Safari, or the real Internet Explorer, this browser would be loaded instead. It also displayed a fake error message, claiming that the computer was infected with malware and Internet Explorer had entered \"Emergency Mode\". It blocked access to legitimate sites such as Google if the user tried to access them.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "15217", "revid": "212624", "url": "https://en.wikipedia.org/wiki?curid=15217", "title": "Ideolect", "text": ""}
{"id": "15219", "revid": "38179619", "url": "https://en.wikipedia.org/wiki?curid=15219", "title": "Insterburg", "text": ""}
{"id": "15220", "revid": "7903804", "url": "https://en.wikipedia.org/wiki?curid=15220", "title": "Imprecise language", "text": "Language in which several interpretations are plausible\nImprecise language, informal spoken language, or everyday language is less precise than any more formal or academic languages.\nLanguage might be said to be imprecise because it exhibits one or more of the following features:\nWhile imprecise language is not desirable in various scientific fields, it may be helpful, illustrative or discussion-stimulative in other contexts. Imprecision in a discourse may or may not be the intention of the author(s) or speaker(s). The role of imprecision may depend on audience, end goal, extended context and subject matter. Relevant players and real stakes will also bear on truth-grounds of statements.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "15221", "revid": "42342156", "url": "https://en.wikipedia.org/wiki?curid=15221", "title": "Intel 80188", "text": ""}
{"id": "15222", "revid": "50477309", "url": "https://en.wikipedia.org/wiki?curid=15222", "title": "IEEE 802.2", "text": "IEEE standard\nIEEE 802.2 is the original name of the ISO/IEC 8802-2 standard which defines logical link control (LLC) as the upper portion of the data link layer of the OSI Model. The original standard developed by the Institute of Electrical and Electronics Engineers (IEEE) in collaboration with the American National Standards Institute (ANSI) was adopted by the International Organization for Standardization (ISO) in 1998, but it remains an integral part of the family of IEEE 802 standards for local and metropolitan networks.\nLLC is a software component that provides a uniform interface to the user of the data link service, usually the network layer. LLC may offer three types of services:\nThe LLC uses the services of the media access control (MAC), which is dependent on the specific transmission medium (Ethernet, Token Ring, FDDI, 802.11, etc.). Using LLC is compulsory for all IEEE 802 networks with the exception of Ethernet. It is also used in Fiber Distributed Data Interface (FDDI) which is not part of the IEEE 802 family.\nThe IEEE 802.2 sublayer adds some control information to the message created by the upper layer and passed to the LLC for transmission to another node on the same data link. The resulting packet is generally referred to as \"LLC protocol data unit (PDU)\" and the additional information added by the LLC sublayer is the \"LLC HEADER\". The LLC Header consist of \"DSAP\" (\"Destination Service Access Point\"), \"SSAP\" (\"Source Service Access Point\") and the \"Control\" field.\nThe two 8-bit fields DSAP and SSAP allow multiplexing of various upper layer protocols above LLC. However, many protocols use the Subnetwork Access Protocol (SNAP) extension which allows using EtherType values to specify the protocol being transported atop IEEE 802.2. It also allows vendors to define their own protocol value spaces.\nThe 8 or 16 bit HDLC-style Control field serves to distinguish communication mode, to specify a specific operation and to facilitate connection control and flow control (in connection mode) or acknowledgements (in acknowledged connectionless mode).\nOperational modes.\nIEEE 802.2 provides two connectionless and one connection-oriented operational modes:\nThe use of multicasts and broadcasts reduces network traffic when the same information needs to be propagated to all stations of the network. However the Type 1 service provides no guarantees regarding the order of the received frames compared to the order in which they have been sent; the sender does not even get an acknowledgment that the frames have been received.\nEach device conforming to the IEEE 802.2 standard must support service type 1. Each network node is assigned an LLC Class according to which service types it supports:\nLLC header.\nAny 802.2 LLC PDU has the following format:\nWhen Subnetwork Access Protocol (SNAP) extension is used, it is located at the start of the Information field:\nThe 802.2 header includes two eight-bit address fields, called service access points (SAP) or collectively LSAP in the OSI terminology:\nLSAP values.\nAlthough the LSAP fields are 8 bits long, the low-order bit is reserved for special purposes, leaving only 128 values available for most purposes.\nThe low-order bit of the DSAP indicates whether it contains an individual or a group address:\nThe low-order bit of the SSAP indicates whether the packet is a command or response packet:\nThe remaining 7 bits of the SSAP specify the LSAP (always an individual address) from which the packet was transmitted.\nLSAP numbers are globally assigned by the IEEE to uniquely identify well established international standards.\nThe protocols or families of protocols which have assigned one or more SAPs may operate directly on top of 802.2 LLC. Other protocols may use the Subnetwork Access Protocol (SNAP) with IEEE 802.2 which is indicated by the hexadecimal value 0xAA (or 0xAB, if the source of a response) in SSAP and DSAP. The SNAP extension allows using EtherType values or private protocol ID spaces in all IEEE 802 networks. It can be used both in datagram and in connection-oriented network services.\nEthernet (IEEE 802.3) networks are an exception; the IEEE 802.3x-1997 standard explicitly allowed using of the Ethernet II framing, where the 16-bit field after the MAC addresses does not carry the length of the frame followed by the IEEE 802.2 LLC header, but the EtherType value followed by the upper layer data. With this framing only datagram services are supported on the data link layer.\nIPv4, IPX, and 802.2 LLC.\nAlthough IPv4 has been assigned an LSAP value of 6 (0x06) and ARP has been assigned an LSAP value of 152 (0x98), IPv4 is almost never directly encapsulated in 802.2 LLC frames without SNAP headers. Instead, the Internet standard RFC 1042 is usually used for encapsulating IPv4 traffic in 802.2 LLC frames with SNAP headers on FDDI and on IEEE 802 networks other than Ethernet. Ethernet networks typically use Ethernet II framing with EtherType 0x800 for IP and 0x806 for ARP.\nThe IPX protocol used by Novell NetWare networks supports an additional Ethernet frame type, 802.3 raw, ultimately supporting four frame types on Ethernet (802.3 raw, 802.2 LLC, 802.2 SNAP, and Ethernet II) and two frame types on FDDI and other (non-Ethernet) IEEE 802 networks (802.2 LLC and 802.2 SNAP).\nIt is possible to use diverse framings on a single network. It is possible to do it even for the same upper layer protocol, but in such a case the nodes using unlike framings cannot directly communicate with each other.\nControl Field.\nFollowing the destination and source SAP fields is a control field. IEEE 802.2 was conceptually derived from HDLC, and has the same three types of PDUs:\nTo carry data in the most-often used unacknowledged connectionless mode the U-format is used. It is identified by the value '11' in lower two bits of the single-byte control field.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "15223", "revid": "50337121", "url": "https://en.wikipedia.org/wiki?curid=15223", "title": "Invertebrate", "text": "Animals without a vertebral column\nInvertebrates are animals that neither develop nor retain a vertebral column (commonly known as a \"spine\" or \"backbone\"), which evolved from the notochord. It is a paraphyletic grouping including all animals excluding the chordate subphylum Vertebrata, i.e. vertebrates. Well-known phyla of invertebrates include arthropods, molluscs, annelids, echinoderms, flatworms, cnidarians, and sponges.\nThe majority of animal species are invertebrates; one estimate puts the figure at 97%. Many invertebrate taxa have a greater number and diversity of species than the entire subphylum of Vertebrata. Invertebrates vary widely in size, from 10\u00a0\u03bcm (0.0004\u00a0in) myxozoans to the 9\u201310 m (30\u201333\u00a0ft) colossal squid.\nSome so-called invertebrates, such as the Tunicata and Cephalochordata, are actually sister chordate subphyla to Vertebrata, being more closely related to vertebrates than to other invertebrates. This makes the \"invertebrates\" paraphyletic, so the term has no significance in taxonomy.\nEtymology.\nThe word \"invertebrate\" comes from the Latin word , which means a joint in general, and sometimes specifically a joint from the spinal column of a vertebrate. The jointed aspect of \"vertebra\" is derived from the concept of turning, expressed in the root \"verto\" or \"vorto\", to turn. The prefix \"in-\" means \"not\" or \"without\".\nTaxonomic significance.\nThe term \"invertebrates\" does not describe a taxon in the same way that Arthropoda, Vertebrata or Manidae do. Each of those terms describes a valid taxon, phylum, subphylum or family. \"Invertebrata\" is a term of convenience, not a taxon; it has very little circumscriptional significance except within the Chordata. The Vertebrata as a subphylum comprises such a small proportion of the Metazoa that to speak of the kingdom Animalia in terms of \"Vertebrata\" and \"Invertebrata\" has limited practicality. In the more formal taxonomy of Animalia other attributes that logically should precede the presence or absence of the vertebral column in constructing a cladogram, for example, the presence of a notochord. That would at least circumscribe the Chordata. However, even the notochord would be a less fundamental criterion than aspects of embryological development and symmetry or perhaps Bauplan.\nDespite this, the concept of \"invertebrates\" as a taxon of animals has persisted for over a century among the laity, and within the zoological community and in its literature it remains in use as a term of convenience for animals that are not members of the Vertebrata. The following text reflects earlier scientific understanding of the term and of those animals which have constituted it. According to this understanding, invertebrates do not possess a skeleton of bone, either internal or external. They include hugely varied body plans. Many have fluid-filled, hydrostatic skeletons, like jellyfish or worms. Others have hard exoskeletons, outer shells like those of insects and crustaceans. The most familiar invertebrates include the Protozoa, Porifera, Coelenterata, Platyhelminthes, Nematoda, Annelida, Echinodermata, Mollusca and Arthropoda. Arthropoda include insects, crustaceans and arachnids.\nNumber of extant species.\nBy far the largest number of described invertebrate species are insects. The following table lists the number of described extant species for major invertebrate groups as estimated in the IUCN Red List of Threatened Species, 2014.3.\nThe IUCN estimates that 66,178 extant vertebrate species have been described, which means that over 95% of the described animal species in the world are invertebrates.\nCharacteristics.\nThe trait that is common to all invertebrates is the absence of a vertebral column (backbone): this creates a distinction between invertebrates and vertebrates. The distinction is one of convenience only; it is not based on any clear biologically homologous trait, any more than the common trait of having wings functionally unites insects, bats, and birds, or than not having wings unites tortoises, snails and sponges. Being animals, invertebrates are heterotrophs, and require sustenance in the form of the consumption of other organisms. With a few exceptions, such as the Porifera, invertebrates generally have bodies composed of differentiated tissues. There is also typically a digestive chamber with one or two openings to the exterior.\nMorphology and symmetry.\nThe body plans of most multicellular organisms exhibit some form of symmetry, whether radial, bilateral, or spherical. A minority, however, exhibit no symmetry. One example of asymmetric invertebrates includes all gastropod species. This is easily seen in snails and sea snails, which have helical shells. Slugs appear externally symmetrical, but their pneumostome (breathing hole) is located on the right side. Other gastropods develop external asymmetry, such as \"Glaucus atlanticus\" that develops asymmetrical cerata as they mature. The origin of gastropod asymmetry is a subject of scientific debate.\nOther examples of asymmetry are found in fiddler crabs and hermit crabs. They often have one claw much larger than the other. If a male fiddler loses its large claw, it will grow another on the opposite side after moulting. Sessile animals such as sponges are asymmetrical alongside coral colonies (with the exception of the individual polyps that exhibit radial symmetry); Alpheidae claws that lack pincers; and some copepods, polyopisthocotyleans, and monogeneans which parasitize by attachment or residency within the gill chamber of their fish hosts).\nNervous system.\nNeurons differ in invertebrates from mammalian cells. Invertebrates cells fire in response to similar stimuli as mammals, such as tissue trauma, high temperature, or changes in pH. The first invertebrate in which a neuron cell was identified was the medicinal leech, \"Hirudo medicinalis\".\nLearning and memory using nociceptors have been described in the sea hare, \"Aplysia\". Mollusk neurons are able to detect increasing pressures and tissue trauma.\nNeurons have been identified in a wide range of invertebrate species, including annelids, molluscs, nematodes and arthropods.\nRespiratory system.\nOne type of invertebrate respiratory system is the open respiratory system composed of spiracles, tracheae, and tracheoles that terrestrial arthropods have to transport metabolic gases to and from tissues. The distribution of spiracles can vary greatly among the many orders of insects, but in general each segment of the body can have only one pair of spiracles, each of which connects to an atrium and has a relatively large tracheal tube behind it. The tracheae are invaginations of the cuticular exoskeleton that branch (anastomose) throughout the body with diameters from only a few micrometres up to 0.8\u00a0mm. The smallest tubes, tracheoles, penetrate cells and serve as sites of diffusion for water, oxygen, and carbon dioxide. Gas may be conducted through the respiratory system by means of active ventilation or passive diffusion. Unlike vertebrates, insects do not generally carry oxygen in their haemolymph.\nA tracheal tube may contain ridge-like circumferential rings of taenidia in various geometries such as loops or helices. In the head, thorax, or abdomen, tracheae may also be connected to air sacs. Many insects, such as grasshoppers and bees, which actively pump the air sacs in their abdomen, are able to control the flow of air through their body. In some aquatic insects, the tracheae exchange gas through the body wall directly, in the form of a gill, or function essentially as normal, via a plastron. Despite being internal, the tracheae of arthropods are shed during moulting (ecdysis).\nReproduction.\nLike vertebrates, most invertebrates reproduce at least partly through sexual reproduction. They produce specialized reproductive cells that undergo meiosis to produce smaller, motile spermatozoa or larger, non-motile ova. These fuse to form zygotes, which develop into new individuals. Others are capable of asexual reproduction, or sometimes, both methods of reproduction.\nExtensive research with model invertebrate species such as \"Drosophila melanogaster\" and \"Caenorhabditis elegans\" has contributed much to our understanding of meiosis and reproduction. However, beyond the few model systems, the modes of reproduction found in invertebrates show incredible diversity. In one extreme example, it is estimated that 10% of orbatid mite species have persisted without sexual reproduction and have reproduced asexually for more than 400 million years.\nSocial interaction.\nSocial behavior is widespread in invertebrates, including cockroaches, termites, aphids, thrips, ants, bees, Passalidae, Acari, spiders, and more. Social interaction is particularly salient in eusocial species but applies to other invertebrates as well.\nInsects recognize information transmitted by other insects.\nPhyla.\nThe term invertebrates covers several phyla. One of these are the sponges (Porifera). They were long thought to have diverged from other animals early. They lack the complex organization found in most other phyla. Their cells are differentiated, but in most cases not organized into distinct tissues. Sponges typically feed by drawing in water through pores. Some speculate that sponges are not so primitive, but may instead be secondarily simplified. The Ctenophora and the Cnidaria, which includes sea anemones, corals, and jellyfish, are radially symmetric and have digestive chambers with a single opening, which serves as both the mouth and the anus. Both have distinct tissues, but they are not organized into organs. There are only two main germ layers, the ectoderm and endoderm, with only scattered cells between them. As such, they are sometimes called diploblastic.\nThe Echinodermata are radially symmetric and exclusively marine, including starfish (Asteroidea), sea urchins, (Echinoidea), brittle stars (Ophiuroidea), sea cucumbers (Holothuroidea) and feather stars (Crinoidea).\nThe largest animal phylum is also included within invertebrates: the Arthropoda, including insects, spiders, crabs, and their kin. All these organisms have a body divided into repeating segments, typically with paired appendages. In addition, they possess a hardened exoskeleton that is periodically shed during growth. Two smaller phyla, the Onychophora and Tardigrada, are close relatives of the arthropods and share some traits with them, excluding the hardened exoskeleton. The Nematoda, or roundworms, are perhaps the second largest animal phylum, and are also invertebrates. Roundworms are typically microscopic, and occur in nearly every environment where there is water. A number are important parasites. Smaller phyla related to them are the Kinorhyncha, Priapulida, and Loricifera. These groups have a reduced coelom, called a pseudocoelom. Other invertebrates include the Nemertea, or ribbon worms, and the Sipuncula.\nAnother phylum is Platyhelminthes, the flatworms. These were originally considered primitive, but it now appears they developed from more complex ancestors. Flatworms are acoelomates, lacking a body cavity, as are their closest relatives, the microscopic Gastrotricha. The Rotifera, or rotifers, are common in aqueous environments. Invertebrates also include the Acanthocephala, or spiny-headed worms, the Gnathostomulida, Micrognathozoa, and the Cycliophora.\nAlso included are two of the most successful animal phyla, the Mollusca and Annelida. The former, which is the second-largest animal phylum by number of described species, includes animals such as snails, clams, and squids, and the latter comprises the segmented worms, such as earthworms and leeches. These two groups have long been considered close relatives because of the common presence of trochophore larvae, but the annelids were considered closer to the arthropods because they are both segmented. Now, this is generally considered convergent evolution, owing to many morphological and genetic differences between the two phyla.\nAmong lesser phyla of invertebrates are the Hemichordata, or acorn worms, and the Chaetognatha, or arrow worms. Other phyla include Acoelomorpha, Brachiopoda, Bryozoa, Entoprocta, Phoronida, and Xenoturbellida.\nClassification.\nInvertebrates can be classified into several main categories, some of which are taxonomically obsolescent or debatable, but still used as terms of convenience. Each however appears in its own article at the following links.\nHistory.\nThe earliest animal fossils are of invertebrates. 665-million-year-old fossils in the Trezona Formation at Trezona Bore, West Central Flinders, South Australia have been interpreted as being early sponges. Some paleontologists suggest that animals appeared much earlier, possibly as early as 1\u00a0billion years ago though they probably became multicellular in the Tonian. Trace fossils such as tracks and burrows found in the late Neoproterozoic Era indicate the presence of triploblastic worms, roughly as large (about 5\u00a0mm wide) and complex as earthworms.\nAround 453 MYA, animals began diversifying, and many of the important groups of invertebrates diverged from one another. Fossils of invertebrates are found in various types of sediment from the Phanerozoic. Fossils of invertebrates are commonly used in stratigraphy.\nClassification.\nCarl Linnaeus divided these animals into only two groups, the Insecta and the now-obsolete Vermes (worms). Jean-Baptiste Lamarck, who was appointed to the position of \"Curator of Insecta and Vermes\" at the Mus\u00e9um National d'Histoire Naturelle in 1793, both coined the term \"invertebrate\" to describe such animals and divided the original two groups into ten, by splitting Arachnida and Crustacea from the Linnean Insecta, and Mollusca, Annelida, Cirripedia, Radiata, Coelenterata and Infusoria from the Linnean Vermes. They are now classified into over 30 phyla, from simple organisms such as sea sponges and flatworms to complex animals such as arthropods and molluscs.\nSignificance.\nInvertebrates are animals without a vertebral column. This has led to the conclusion that \"in\"vertebrates are a group that deviates from the normal, vertebrates. This has been said to be because researchers in the past, such as Lamarck, viewed vertebrates as a \"standard\": in Lamarck's theory of evolution, he believed that characteristics acquired through the evolutionary process involved not only survival, but also progression toward a \"higher form\", to which humans and vertebrates were closer than invertebrates were. Although goal-directed evolution has been abandoned, the distinction of invertebrates and vertebrates persists to this day, even though the grouping has been noted to be \"hardly natural or even very sharp.\" Another reason cited for this continued distinction is that Lamarck created a precedent through his classifications which is now difficult to escape from. It is also possible that some humans believe that, they themselves being vertebrates, the group deserves more attention than invertebrates. In any event, in the 1968 edition of \"Invertebrate Zoology\", it is noted that \"division of the Animal Kingdom into vertebrates and invertebrates is artificial and reflects human bias in favor of man's own relatives.\" The book also points out that the group lumps a vast number of species together, so that no one characteristic describes all invertebrates. In addition, some species included are only remotely related to one another, with some more related to vertebrates than other invertebrates (see Paraphyly).\nIn research.\nFor many centuries, invertebrates were neglected by biologists, in favor of big vertebrates and \"useful\" or charismatic species. Invertebrate biology was not a major field of study until the work of Linnaeus and Lamarck in the 18th century. During the 20th century, invertebrate zoology became one of the major fields of natural sciences, with prominent discoveries in the fields of medicine, genetics, palaeontology, and ecology. The study of invertebrates has also benefited law enforcement, as arthropods, and especially insects, were discovered to be a source of information for forensic investigators.\nTwo of the most commonly studied model organisms nowadays are invertebrates: the fruit fly \"Drosophila melanogaster\" and the nematode \"Caenorhabditis elegans\". They have long been the most intensively studied model organisms, and were among the first life-forms to be genetically sequenced. This was facilitated by the severely reduced state of their genomes, but many genes, introns, and linkages have been lost. Analysis of the starlet sea anemone genome has emphasised the importance of sponges, placozoans, and choanoflagellates, also being sequenced, in explaining the arrival of 1,500 ancestral genes unique to animals. Invertebrates are also used by scientists in the field of aquatic biomonitoring to evaluate the effects of water pollution and climate change.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "15225", "revid": "13286072", "url": "https://en.wikipedia.org/wiki?curid=15225", "title": "Ivar Aasen", "text": "Norwegian philologist and lexicographer (1813\u20131896)\nIvar Andreas Aasen (; 5 August 1813 \u2013 23 September 1896) was a Norwegian philologist, lexicographer, playwright, and poet. He is best known for having assembled one of the two official written versions of the Norwegian language, Nynorsk, from various dialects.\nBackground.\nIver Andreas Aasen was born in 1813 in \u00c5sen, in the parish of \u00d8rsten (now \u00d8rsta Municipality), in the district of Sunnm\u00f8re, on the west coast of Norway. His father Ivar Jonsson, a peasant with a small farm, died in 1826. Young Iver was brought up doing farmwork, but he assiduously cultivated all his leisure in reading. An early interest of his was botany. When he was eighteen, he opened an elementary school in his native parish. In 1833, he entered the household of Hans Conrad Thoresen, the husband of the eminent writer Magdalene Thoresen, in the parish of Her\u00f8 (now Her\u00f8y Municipality), where he picked up the elements of Latin. Aasen gradually mastered several languages, and began the scientific study of their structure. Ivar single-handedly created a new language for Norway, which later became its \"literary\" language.\nCareer.\nWhen Aasen travelled to Bergen in 1841, he met bishop Jacob Neumann, who was very impressed with his work, and had excerpts of it published in \"Bergens Stiftstidende\" (\"Bergen Diocese Newspaper\"). His contacts with Bishop Neumann became Aasen's entrance ticket to the Royal Norwegian Society of Sciences and Letters in Trondheim, and generous financial support (an annual grant of 120-200 speciedaler), which made the extensive travel possible to study the Norwegian vernacular. It is said to have been the rector of Trondheim, Fredrik M. Bugge, who came across Neumann's articles while travelling in Bergen and persuaded the scientific society to grant the funding to Aasen.\nTherefore, quite early in his career, in 1842, Aasen had begun to receive a grant to enable him to give his entire attention to his philological investigations; he had ceased doing any farmwork by 1846. Aasen's first monograph in 1843 was a small collection of folk songs in the dialect of his native district, Sunnm\u00f8re, which attracted general attention. His \"Grammar of the Norwegian Dialects\" (, 1848) was the result of long studies, and of journeys taken to every part of the country. Aasen's well-known \"Dictionary of the Norwegian Dialects\" () appeared in its original form in 1850, which became the basis of his construction of a popular language or definite \"folke-maal\" (lit.\u2009'people's language') for Norway.\nBy 1853, he had created the norm for utilizing his new language, which he called Landsmaal, meaning \"country language\". With certain modifications, the most important of which were introduced later by Aasen himself, but also through a latter policy aiming to merge this Norwegian language with Dano-Norwegian, this language has become \"Nynorsk\" (lit.\u2009'New Norwegian') (see Legacy \u00a7 Nynorsk).\nAasen composed poems and plays in the composite dialect to show how it should be used. One of these dramas, \"The Heir\" (1855), was frequently acted, and may be considered as the pioneer of dialectal literature of the second half of the 19th century, from Vinje to Garborg. In 1856, he published \"Norske Ordsprog\", a treatise on Norwegian proverbs. Aasen continuously enlarged and improved his grammars and his dictionary. He lived very quietly in lodgings in Oslo (then Christiania), surrounded by his books and shrinking from publicity, but his name grew into wide political favour as his ideas about the language of the peasants became more and more the watch-word of the popular party. In 1864, he published his definitive grammar of Nynorsk and in 1873 he published the definitive dictionary.\nThe Storting (the Norwegian parliament), conscious of the national importance of his work, treated Aasen in this respect with more and more financial generosity as he advanced in years. He continued his investigations to the last, but it may be said that, after the 1873 edition of his \"Dictionary\" (with a new title: ), he added but little to his stores.\nHe died in Christiania on 23 September 1896, and was buried with public honours.\nLegacy.\nNynorsk.\nThe language constructed by Aasen as \"Landsmaal\" would later become known as Nynorsk (lit.\u2009'New Norwegian'), and emerge as the second of Norway's two official languages (the other being \"Bokm\u00e5l\", the Dano-Norwegian descendant of the Danish language used in Norway in Aasen's time). An unofficial variety of Norwegian closer to Aasen's language is still found in H\u00f8gnorsk (lit.\u2009'High Norwegian'). As of the early 2000s, some scholars considered Nynorsk on equal footing with Bokm\u00e5l, as Bokm\u00e5l tended to be used more in radio and television and most newspapers, whereas Nynorsk was used equally in government work, as well as approximately 17% of schools. Although it was not as common as its brother language, some scholars argued it needed to be looked upon as a viable language, as a large minority of Norwegians used it as their primary language, including many scholars and authors. Nynorsk is both a written and spoken language.\nThe Ivar Aasen Centre.\nIvar Aasen-tunet, an institution devoted to the Nynorsk language, opened in June 2000. The building in \u00d8rsta was designed by Norwegian architect Sverre Fehn. Their web page includes most of Aasens' texts, numerous other examples of Nynorsk literature (in Nettbiblioteket, the Internet Library), and some articles, including some in English, about language history in Norway.\n2013 Language year.\n\"Spr\u00e5k\u00e5ret 2013\" (The Language Year 2013) celebrated Ivar Aasen's 200 year anniversary, as well as the 100 year anniversary of Det Norske Teateret. The year's main focus was to celebrate linguistic diversity in Norway. In a poll released in connection with the celebration, 56% of Norwegians said they held positive views of Aasen, while 7% held negative views. On Aasen's 200 anniversary, 5 August 2013, \"Bergens Tidende\", which is normally published mainly in Bokm\u00e5l, published an edition fully in Nynorsk in memory of Aasen.\nBibliography.\nAasen published a wide range of material, some of it released posthumously.\nFootnotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
