{"id": "14717", "revid": "8087765", "url": "https://en.wikipedia.org/wiki?curid=14717", "title": "MIRC", "text": "Internet Relay Chat (IRC) client for Microsoft Windows\nmIRC is an Internet Relay Chat (IRC) client for Windows with an integrated scripting language allowing the creation of extensions. The software was first released in 1995 and has since been described as \"one of the most popular IRC clients available for Windows.\" mIRC is shareware and requires payment for registration after the 30-day evaluation period.\nHistory.\nmIRC was created by Khaled Mardam-Bey, a British programmer born in Jordan to a Syrian father and a Palestinian mother. He began developing the software in late 1994, and released its first version on 28 February 1995.\nMardam-Bey states that he decided to create mIRC because he felt the first IRC clients for Windows lacked some basic IRC features. He then continued developing it due to the challenge and the fact that people appreciated his work. The author states that its subsequent popularity allowed him to make a living out of mIRC. He also jokingly states that the \"m\" in mIRC stands for \"moo\" or \"MU\" (meaning 'nothing' in Japanese and Korean).\nmIRC 5.91 is the final version to support 16-bit Windows; 6.35 is the last to support Windows 95, NT 4.0, 98, and ME. The current version supports Windows XP and later.\nThe application makes an appearance in the 2006 music video for \"Boten Anna\" by Swedish singer Basshunter.\nMain features.\nmIRC has a number of distinguishing features. One is its scripting language which is further developed with each version. The scripting language can be used to make minor changes to the program like custom commands (aliases), but can also used to completely alter the behavior and appearance of mIRC. Another claimed feature is mIRC's file sharing abilities, via the DCC protocol, featuring a built-in file server.\nStarting with mIRC 7.1, released on 30 July 2010, Unicode and IPv6 are supported.\nmIRC scripting.\nmIRC's abilities and behaviors can be altered and extended using the embedded mIRC scripting language. mIRC includes its own GUI scripting editor, with help that has been described as \"extremely detailed\".\nDue to the level of access the language has to a user's computer \u2014 for example, being able to rename and delete files \u2014 a number of abusive scripts have been made. One example of abuse was that executed with the $decode identifier which decodes a given encoded string. The issue was reported in August 2001; even five months later, users were still being reported as having fallen prey, tricked into executing commands on their systems which result in \"handing control of [their] mIRC over to somebody else\". This led to changes being made in mIRC version 6.17: according to the author, $decode is now disabled by default, and various other features which can be considered dangerous are now lockable.\nReception.\nmIRC has been downloaded over 40 million times from CNET's Download.com service. In 2003, Nielsen/NetRatings ranked mIRC among the top ten most popular Internet applications.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "14718", "revid": "50806320", "url": "https://en.wikipedia.org/wiki?curid=14718", "title": "HexChat", "text": "IRC client\nHexChat is a discontinued Internet Relay Chat client and is a fork of XChat. It has a choice of a tabbed document interface or tree interface, support for multiple servers, and numerous configuration options. Both command-line and graphical versions are available.\nThe client runs on Microsoft Windows and Unix-like operating systems, and many Linux distributions include packages in their repositories.\nHistory.\nThe XChat-WDK (XChat Windows Driver Kit) project started in 2010 and was originally Windows-only. The project's original goal was to merge itself with XChat, but evolved from just fixing Windows bugs to adding new features. It started to make sense to support more platforms than Windows. On July 6, 2012, XChat-WDK officially changed its name to HexChat.\nThe project was discontinued in early 2024, citing lack of maintainer availability.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "14720", "revid": "35936988", "url": "https://en.wikipedia.org/wiki?curid=14720", "title": "IRC takeover", "text": "An IRC channel takeover is an acquisition of IRC channel operator status by someone other than the channel's owner. It has largely been eliminated due to the increased use of services on IRC networks.\nRiding the split.\nThe most common variety of channel takeover uses disconnections caused by a netsplit; this is called riding the split. After such mass disconnections, a channel may be left without users, allowing the first rejoining user to recreate the channel and gain operator status. When the servers merge, any pre-existing operators retain their status, allowing the new user to kick out the original operators and take over the channel.\nA simple prevention mechanism involves \"timestamping\" (abbreviated to \"TS\"), or checking the creation dates of the channels being merged. This was first implemented by Undernet (ircu) in November 2000 and is now common in many IRC servers. If both channels were created at the same time, all user statuses are retained when the two are combined; if one is newer than the other, special statuses are removed from those in the newer channel.\nAdditionally, a newer protection involving timestamping is used when a server splits away from the main network (when it no longer detects that IRC services are available), it disallows anyone creating a channel to be given operator privileges.\nNick collision.\nAnother popular form of channel takeover abuses nickname collision protection, which keeps two users from having the same nickname at once. A user on one side of a netsplit takes the nickname of a target on the other side of the split; when the servers reconnect, the nicks collide and both users are kicked from the server. The attacker then reconnects or switches nicks in a second client while the target reconnects, and proceeds to jupe (or block) the target's nickname for a period of time.\nUser timestamping is often used to detect these kinds of attacks in a fashion similar to channel timestamping, with the user who selected that nickname later being kicked from the server. Another protection method, called \"nickhold\", disallows the use of recently split nicknames. This causes fewer kicks, but causes more inconvenience to users. For this reason, timestamping is generally more common. Some servers, such as ircd-ratbox, do both. IRC services and bots can also protect against such attacks by requiring that a password be supplied to use a certain nick. Users who do not provide a password are killed after a certain amount of time.\nOther methods.\nOther methods can be used to take over a channel, though they are unrelated to flaws in IRC itself; for example, cracking the computers of channel operators, compromising channel bot shell accounts, or obtaining services passwords through social engineering.\nSmurfing.\nSmurf attacks have been used to take over IRC servers. These exploit ICMP ping responses from broadcast addresses at multiple hosts sharing an Internet address, and forge the ping packet's return address to match a target machine's address. A single malformed packet sent to the \"smurf amplifier\" will be echoed to the target machine.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "14722", "revid": "40330219", "url": "https://en.wikipedia.org/wiki?curid=14722", "title": "Irssi", "text": "Text-mode IRC client\nIrssi ( (https://)) is an Internet Relay Chat (IRC) client program for Linux, FreeBSD, macOS and Microsoft Windows. It was originally written by Timo Sirainen, and released under the terms of the GNU GPL-2.0-or-later in January 1999.\nThe program has a text-based user interface was written from scratch using C. It may be customized by editing its config files or by installing plugins and Perl scripts. Though initially developed for Unix-like operating systems, it has been successfully ported to both Windows and macOS.\nFeatures.\nIrssi is written in the C programming language and in normal operation uses a text-mode user interface.\nAccording to the developers, Irssi was written from scratch, not based on ircII (like BitchX and epic). This freed the developers from having to deal with the constraints of an existing codebase, allowing them to maintain tighter control over issues such as security and customization. Numerous Perl scripts have been made available for Irssi to customise how it looks and operates. Plugins are available which add encryption and protocols such as ICQ and XMPP.\nIrssi may be configured by using its user interface or by manually editing its configuration files, which use a syntax resembling Perl data structures.\nDistributions.\nIrssi was written primarily to run on Unix-like operating systems, and binaries and packages are available for Gentoo Linux, Debian, Slackware, SUSE (openSUSE), Frugalware, Fedora, FreeBSD, OpenBSD, NetBSD, DragonFly BSD, Solaris, Arch Linux, Ubuntu, NixOS, and others.\nIrssi builds and runs on Microsoft Windows under Cygwin, and in 2006, an official Windows standalone build was released.\nFor the Unix-based macOS, text mode ports are available from the Homebrew, MacPorts, and Fink package managers, and two graphical clients have been written based on Irssi, IrssiX, and MacIrssi. The Cocoa client Colloquy was previously based on Irssi, but it now uses its own IRC core implementation.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "14723", "revid": "1306352", "url": "https://en.wikipedia.org/wiki?curid=14723", "title": "Infinitesimal calculus", "text": ""}
{"id": "14724", "revid": "20343605", "url": "https://en.wikipedia.org/wiki?curid=14724", "title": "Intellectual property", "text": "Ownership of creative expressions and processes\nIntellectual property (IP) is a category of property that includes intangible creations of the human intellect. There are many types of intellectual property, and some countries recognize more than others. The best-known types are patents, copyrights, trademarks, and trade secrets. The modern concept of intellectual property developed in England in the 17th and 18th centuries. The term \"intellectual property\" began to be used in the 19th century, though it was not until the late 20th century that intellectual property became commonplace in most of the world's legal systems.\nSupporters of intellectual property laws often describe their main purpose as encouraging the creation of a wide variety of intellectual goods. To achieve this, the law gives people and businesses property rights to certain information and intellectual goods they create, usually for a limited period of time. Supporters argue that because IP laws allow people to protect their original ideas and prevent unauthorized copying, creators derive greater individual economic benefit from the information and intellectual goods they create, and thus have more economic incentives to create them in the first place. Advocates of IP believe that these economic incentives and legal protections stimulate innovation and contribute to technological progress of certain kinds.\nThe intangible nature of intellectual property presents difficulties when compared with traditional property like land or goods. Unlike traditional property, intellectual property is \"indivisible\", since an unlimited number of people can in theory \"consume\" an intellectual good without its being depleted. Additionally, investments in intellectual goods suffer from appropriation problems: Landowners can surround their land with a robust fence and hire armed guards to protect it, but producers of information or literature can usually do little to stop their first buyer from replicating it and selling it at a lower price. Balancing rights so that they are strong enough to encourage the creation of intellectual goods but not so strong that they prevent the goods' wide use is the primary focus of modern intellectual property law.\nHistory.\nThe Venetian Patent Statute of 19\u00a0March 1474, established by the Republic of Venice, is usually considered to be the earliest codified patent system in the world. It states that patents might be granted for \"any new and ingenious device, not previously made\", provided it was useful. By and large, these principles still remain the basic principles of current patent laws. The Statute of Monopolies (1624) and the British Statute of Anne (1710) are seen as the origins of the current patent law and copyright respectively, firmly establishing the concept of intellectual property.\n\"Literary property\" was the term predominantly used in the British legal debates of the 1760s and 1770s over the extent to which authors and publishers of works also had rights deriving from the common law of property (\"Millar v Taylor\" (1769), \"Hinton v Donaldson\" (1773), \"Donaldson v Becket\" (1774)). The first known use of the term \"intellectual property\" dates to this time, when a piece published in the \"Monthly Review\" in 1769 used the phrase. The first clear example of modern usage goes back as early as 1808, when it was used as a heading title in a collection of essays.\nThe German equivalent was used with the founding of the North German Confederation whose constitution granted legislative power over the protection of intellectual property (\"Schutz des geistigen Eigentums\") to the confederation. When the administrative secretariats established by the Paris Convention (1883) and the Berne Convention (1886) merged in 1893, they located in Berne, and also adopted the term intellectual property in their new combined title, the United International Bureaux for the Protection of Intellectual Property.\nThe organization subsequently relocated to Geneva in 1960 and was succeeded in 1967 with the establishment of the World Intellectual Property Organization (WIPO) by treaty as an agency of the United Nations. According to legal scholar Mark Lemley, it was only at this point that the term really began to be used in the United States (which had not been a party to the Berne Convention), and it did not enter popular usage there until passage of the Bayh\u2013Dole Act in 1980.\nThe history of patents does not begin with inventions, but rather with royal grants by Queen Elizabeth I (1558\u20131603) for monopoly privileges. Approximately 200 years after the end of Elizabeth's reign, however, a patent represents a legal right obtained by an inventor providing for exclusive control over the production and sale of his mechanical or scientific invention. demonstrating the evolution of patents from royal prerogative to common-law doctrine.\nThe term can be found used in an October 1845 Massachusetts Circuit Court ruling in the patent case \"Davoll et al. v. Brown\", in which Justice Charles L. Woodbury wrote that \"only in this way can we protect intellectual property, the labors of the mind, productions and interests are as much a man's own ... as the wheat he cultivates, or the flocks he rears.\" The statement that \"discoveries are ... property\" goes back earlier. Section 1 of the French law of 1791 stated, \"All new discoveries are the property of the author; to assure the inventor the property and temporary enjoyment of his discovery, there shall be delivered to him a patent for five, ten or fifteen years.\" In Europe, French author A. Nion mentioned \"propri\u00e9t\u00e9 intellectuelle\" in his \"Droits civils des auteurs, artistes et inventeurs\", published in 1846.\nUntil the 2000s, the purpose of intellectual property law was to give as little protection as possible in order to encourage innovation. Historically, legal protection was therefore granted only when necessary to encourage invention, and it was limited in time and scope. This is mainly as a result of knowledge being traditionally viewed as a public good, in order to allow its extensive dissemination and improvement.\nThe concept's origin can potentially be traced back further. Jewish law includes several considerations whose effects are similar to those of modern intellectual property laws, though the notion of intellectual creations as property does not seem to exist\u2014notably the principle of Hasagat Ge'vul (unfair encroachment) was used to justify limited-term publisher (but not author) copyright in the 16th century. In 500\u00a0BCE, the government of the Greek state of Sybaris offered one year's patent \"to all who should discover any new refinement in luxury\".\nAccording to Jean-Fr\u00e9d\u00e9ric Morin, \"the global intellectual property regime is currently in the midst of a paradigm shift\". Up until the early 2000s, the global IP regime used to be dominated by high standards of protection characteristic of IP laws from Europe or the United States, with a vision that uniform application of these standards over every country and to several fields with little consideration over social, cultural or environmental values or of the national level of economic development. Morin argues that \"the emerging discourse of the global IP regime advocates for greater policy flexibility and greater access to knowledge, especially for developing countries\". With the Development Agenda adopted by WIPO in 2007, a set of 45 recommendations to adjust WIPO's activities to the specific needs of developing countries and aim to reduce distortions especially on issues such as patients' access to medicines, Internet users' access to information, farmers' access to seeds, programmers' access to source codes or students' access to scientific articles. However, this paradigm shift has not yet manifested itself in concrete legal reforms at the international level.\nSimilarly, it is based on these background that the Trade-Related Aspects of Intellectual Property Rights (TRIPS) agreement requires members of the WTO to set minimum standards of legal protection, but its objective to have a \"one-fits-all\" protection law on Intellectual Property has been viewed with controversies regarding differences in the development level of countries. Despite the controversy, the agreement has extensively incorporated intellectual property rights into the global trading system for the first time in 1995, and has prevailed as the most comprehensive agreement reached by the world.\nRights.\nIntellectual property rights include patents, copyright, industrial design rights, trademarks, plant variety rights, trade dress, geographical indications, and in some jurisdictions trade secrets. There are also more specialized or derived varieties of \"sui generis\" exclusive rights, such as circuit design rights (called mask work rights in the US), supplementary protection certificates for pharmaceutical products (after expiry of a patent protecting them), and database rights (in European law). The term \"industrial property\" is sometimes used to refer to a large subset of intellectual property rights including patents, trademarks, industrial designs, utility models, service marks, trade names, and geographical indications.\nPatents.\nA patent is a form of right granted by the government to an inventor or their successor-in-title, giving the owner the right to exclude others from making, using, selling, offering to sell, and importing an invention for a limited period of time, in exchange for the public disclosure of the invention. An invention is a solution to a specific technological problem, which may be a product or a process, and generally has to fulfill three main requirements: it has to be new, not obvious and there needs to be an industrial applicability. To enrich the body of knowledge and to stimulate innovation, it is an obligation for patent owners to disclose valuable information about their inventions to the public.\nCopyright.\nA copyright gives the creator of an original work exclusive rights to it, usually for a limited time. Copyright may apply to a wide range of creative, intellectual, or artistic forms, or \"works\". Copyright does not cover ideas and information themselves, only the form or manner in which they are expressed.\nIndustrial design rights.\nAn industrial design right (sometimes called \"design right\" or \"design patent\") protects the visual design of objects that are not purely utilitarian. An industrial design consists of the creation of a shape, configuration or composition of pattern or color, or combination of pattern and color in three-dimensional form containing aesthetic value. An industrial design can be a two- or three-dimensional pattern used to produce a product, industrial commodity or handicraft. Generally speaking, it is what makes a product look appealing, and as such, it increases the commercial value of goods.\nPlant varieties.\nPlant breeders' rights or plant variety rights are the rights to commercially use a new variety of a plant. The variety must, amongst others, be novel and distinct and for registration the evaluation of propagating material of the variety is considered.\nTrademarks.\nA trademark is a recognizable sign, design or expression that distinguishes a particular trader's products or services from similar products or services of other traders.\nTrade dress.\nTrade dress is a legal term of art that generally refers to characteristics of the visual and aesthetic appearance of a product or its packaging (or even the design of a building) that signify the source of the product to consumers.\nTrade secrets.\nA trade secret is a formula, practice, process, design, instrument, pattern, or compilation of information which is not generally known or reasonably ascertainable, by which a business can obtain an economic advantage over competitors and customers.\nTrade secrets are protected by a combination of state and federal laws, which prescribe a combination of civil and criminal penalties for trade secret \"misappropriation\"\u2014the improper acquisition, disclosure, or use of a trade secret.\nExamples of trade secrets include Coca-Cola's formulas for its soft drinks and the WD-40 Company's formula for its lubricant WD-40.\nMotivation and justification.\nIntellectual property law is mainly intended to encourage the creation of various intellectual goods for consumers by giving people and businesses property rights to the information and intellectual goods they create, usually for a limited period of time. Because they can then profit from them, this creates economic incentives for their creation. The intangible nature of intellectual property presents difficulties when compared with traditional property like land or goods. Unlike traditional property, intellectual property is indivisible\u2014an unlimited number of people can \"consume\" an intellectual good without it being depleted. Additionally, investments in intellectual goods suffer from problems of appropriation\u2014while a landowner can surround their land with a robust fence and hire armed guards to protect it, a producer of information or an intellectual good can usually do very little to stop their first buyer from replicating it and selling it at a lower price. Balancing rights so that they are strong enough to encourage the creation of information and intellectual goods, but not so strong that they prevent their wide use, is the primary focus of modern intellectual property law.\nBy exchanging limited exclusive rights for disclosure of inventions and creative works, society and rightsholders mutually benefit, and an incentive is created for inventors and authors to create and disclose their works. Some commentators have noted that the objective of intellectual property legislators and supporters of intellectual property laws appears to be \"objective protection\". \"If some intellectual property is desirable because it encourages innovation, they reason, more is better. The thinking is that creators will not have sufficient incentive to invent unless they are legally entitled to capture the full social value of their inventions\". This absolute protection or full-value view treats intellectual property as another type of \"real\" property, typically adopting its law and rhetoric. Other recent developments in intellectual property law, such as the America Invents Act, stress international harmonization. Recently, there has also been much debate over the desirability of using intellectual property rights to protect cultural heritage, including intangible ones, as well as over risks of commodification derived from this possibility. The issue still remains open in legal scholarship.\nFinancial incentive.\nThese exclusive rights allow intellectual property owners to benefit from the property they have created, providing a financial incentive for the creation of an investment in intellectual property, and, in the case of patents, pay associated research and development costs. In the United States Article\u00a0I Section\u00a08 Clause\u00a08 of the Constitution, commonly called the Patent and Copyright Clause, reads; \"The Congress shall have power 'To promote the progress of science and useful arts, by securing for limited times to authors and inventors the exclusive right to their respective writings and discoveries.'\" \"Some commentators, such as David Levine and Michele Boldrin, dispute this justification.\nIn 2013, the United States Patent and Trademark Office approximated that the worth of intellectual property to the U.S. economy is more than US$5\u00a0trillion and creates employment for an estimated 18\u00a0million American people. The value of intellectual property is considered similarly high in other developed nations, such as those in the European Union. In the UK, IP has become a recognised asset class for use in pension-led funding and other types of business finance. However, in 2013, the UK Intellectual Property Office stated: \"There are millions of intangible business assets whose value is either not being leveraged at all, or only being leveraged inadvertently\".\nAn October 2023 study released by Americans for the Arts (AFTA) found that \"nonprofit arts and culture organizations and their audiences generated $151.7\u00a0billion in economic activity\u2014$73.3\u00a0billion in spending by the organizations, which leveraged an additional $78.4\u00a0billion in event-related spending by their audiences.\" This spending supported 2.6\u00a0million jobs and generated $29.1\u00a0billion in local, state and federal tax revenue.\" 224,000\u00a0audience members and over 16,000\u00a0organizations in all 50\u00a0states and Puerto Rico were surveyed over an 18-month period to collect the data.\nEconomic growth.\nThe WIPO treaty and several related international agreements underline that the protection of intellectual property rights is essential to maintaining economic growth. The \"WIPO Intellectual Property Handbook\" gives two reasons for intellectual property laws: \"One is to give statutory expression to the moral and economic rights of creators in their creations and the rights of the public in access to those creations. The second is to promote, as a deliberate act of Government policy, creativity and the dissemination and application of its results and to encourage fair trading which would contribute to economic and social development.\"\nThe Anti-Counterfeiting Trade Agreement (ACTA) states that \"effective enforcement of intellectual property rights is critical to sustaining economic growth across all industries and globally\". Economists estimate that two-thirds of the value of large businesses in the United States can be traced to intangible assets. A joint research project of the WIPO and the United Nations University measuring the impact of IP systems on six Asian countries found \"a positive correlation between the strengthening of the IP system and subsequent economic growth.\"\nMorality.\nAccording to Article\u00a027 of the Universal Declaration of Human Rights, \"everyone has the right to the protection of the moral and material interests resulting from any scientific, literary or artistic production of which he is the author\". Although the relationship between intellectual property and human rights is complex, there are moral arguments for intellectual property. The arguments that justify intellectual property fall into three major categories. Personality theorists believe intellectual property is an extension of an individual. Utilitarians believe that intellectual property stimulates social progress and pushes people to further innovation. Lockeans argue that intellectual property is justified based on deservedness and hard work. Various moral justifications for private property can be used to argue in favor of the morality of intellectual property, such as:\nLysander Spooner (1855) argues that &lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;[A] man has a natural and absolute right\u2014and if a natural and absolute, then necessarily a perpetual, right\u2014of property, in the ideas, of which he is the discoverer or creator; that his right of property, in ideas, is intrinsically the same as, and stands on identically the same grounds with, his right of property in material things; that no distinction, of principle, exists between the two cases. Writer Ayn Rand argued in her book \"\" that the protection of intellectual property is essentially a moral issue. The belief is that the human mind itself is the source of wealth and survival and that all property at its base is intellectual property. Intellectual property rights violations therefore do not differ morally from violations of other property rights which compromise the very processes of survival and therefore constitute immoral acts.\nInfringement, misappropriation, and enforcement.\nViolation of intellectual property rights, called \"infringement\" with respect to patents, copyright, and trademarks, and \"misappropriation\" with respect to trade secrets, may be a breach of civil law or criminal law, depending on the type of intellectual property involved, jurisdiction, and the nature of the action. As of 2011, trade in counterfeit copyrighted and trademarked works was a $600\u00a0billion industry worldwide and accounted for 5\u200d\u2013\u200d7% of global trade. During the Russian invasion of Ukraine, IP has been a consideration in punishment of the aggressor through trade sanctions, has been proposed as a method to prevent future wars of aggression involving nuclear weapons, and has caused concern about stifling innovation by keeping patent information secret.\nPatent infringement.\nPatent infringement typically is caused by using or selling a patented invention without permission from the patent holder, i.e. from the patent owner. The scope of the patented invention or the extent of protection is defined in the claims of the granted patent. There is safe harbor in many jurisdictions to use a patented invention for research. This safe harbor does not exist in the US unless the research is done for purely philosophical purposes, or to gather data to prepare an application for regulatory approval of a drug. In general, patent infringement cases are handled under civil law (e.g., in the United States) but several jurisdictions incorporate infringement in criminal law also (for example, Argentina, China, France, Japan, Russia, South Korea).\nCopyright infringement.\nCopyright infringement is reproducing, distributing, displaying or performing a work, or to make derivative works, without permission from the copyright holder, which is typically a publisher or other business representing or assigned by the work's creator. It is often called \"piracy\". In the United States, while copyright is created the instant a work is fixed, generally the copyright holder can only get money damages if the owner registers the copyright. Enforcement of copyright is generally the responsibility of the copyright holder. The ACTA trade agreement, signed in May 2011 by the United States, Japan, Switzerland, and the EU, and which has not entered into force, requires that its parties add criminal penalties, including incarceration and fines, for copyright and trademark infringement, and obligated the parties to actively police for infringement. There are limitations and exceptions to copyright, allowing limited use of copyrighted works, which does not constitute infringement. Examples of such doctrines are the fair use and fair dealing doctrine.\nTrademark infringement.\nTrademark infringement occurs when one party uses a trademark that is identical or confusingly similar to a trademark owned by another party, in relation to products or services which are identical or similar to the products or services of the other party. In many countries, a trademark receives protection without registration, but registering a trademark provides legal advantages for enforcement. Infringement can be addressed by civil litigation and, in several jurisdictions, under criminal law.\nTrade secret misappropriation.\nTrade secret misappropriation is different from violations of other intellectual property laws, since by definition trade secrets are secret, while patents and registered copyrights and trademarks are publicly available. In the United States, trade secrets are protected under state law, and states have nearly universally adopted the Uniform Trade Secrets Act. The United States also has federal law in the form of the Economic Espionage Act of 1996 (\u00a0https://\u2013https://), which makes the theft or misappropriation of a trade secret a federal crime. This law contains two provisions criminalizing two sorts of activity. The first, \u00a0https://, criminalizes the theft of trade secrets to benefit foreign powers. The second, \u00a0https://, criminalizes their theft for commercial or economic purposes. The statutory penalties are different for the two offenses. In Commonwealth common law jurisdictions, confidentiality and trade secrets are regarded as an equitable right rather than a property right but penalties for theft are roughly the same as in the United States.\nInternational framework.\nThe international governance of IP involves multiple overlapping institutions and forums.25 There is no overall rule-making body.25 One of the most important aspects of global IP governance is the Agreement on Trade Related Aspects of Intellectual Property Rights (TRIPS).7 The TRIPS Agreement sets minimum international standards for IP which every member of the World Trade Organization (WTO) must comply with.7 A member's non-compliance with the TRIPS Agreement may be grounds for suit under the WTO's Dispute Settlement Mechanism.7 Bilateral and multi-lateral agreements often establish IP requirements above the requirements of the TRIPS Agreement.7\nCriticisms.\nThe term \"intellectual property\".\nCriticism of the term \"intellectual property\" ranges from discussing its vagueness and abstract overreach to direct contention to the semantic validity of using words like \"property\" and \"rights\" in fashions that contradict practice and law. Critics argue that this term specially serves the doctrinal agenda of parties opposing reform in the public interest or otherwise abusing related legislations, and that it disallows intelligent discussion about specific and often unrelated aspects of copyright, patents, trademarks, etc.\nFree Software Foundation founder Richard Stallman argues that, although the term \"intellectual property\" is in wide use, it should be rejected altogether, because it \"systematically distorts and confuses these issues, and its use was and is promoted by those who gain from this confusion\". He claims that the term \"operates as a catch-all to lump together disparate laws [which] originated separately, evolved differently, cover different activities, have different rules, and raise different public policy issues\" and that it creates a bias by confusing these monopolies with ownership of limited physical things, likening them to property rights. Stallman advocates referring to copyrights, patents and trademarks in the singular and warns against abstracting disparate laws into a collective term. He argues that, \"to avoid spreading unnecessary bias and confusion, it is best to adopt a firm policy not to speak or even think in terms of 'intellectual property'.\"\nSimilarly, economists Boldrin and Levine prefer to use the term \"intellectual monopoly\" as a more appropriate and clear definition of the concept, which, they argue, is very dissimilar from property rights. They further argued that \"stronger patents do little or nothing to encourage innovation\", mainly explained by its tendency to create market monopolies, thereby restricting further innovations and technology transfer.\nOn the assumption that intellectual property rights are actual rights, Stallman says that this claim does not live to the historical intentions behind these laws, which in the case of copyright served as a censorship system, and later on, a regulatory model for the printing press that may have benefited authors incidentally, but never interfered with the freedom of average readers. Still referring to copyright, he cites legal literature such as the United States Constitution and case law to demonstrate that the law is meant to be an optional and experimental bargain to temporarily trade property rights and free speech for public, not private, benefits in the form of increased artistic production and knowledge. He mentions that \"if copyright were a natural right nothing could justify terminating this right after a certain period of time\".\nLaw professor, writer and political activist Lawrence Lessig, along with many other copyleft and free software activists, has criticized the implied analogy with physical property (like land or an automobile). They argue such an analogy fails because physical property is generally rivalrous while intellectual works are non-rivalrous (that is, if one makes a copy of a work, the enjoyment of the copy does not prevent enjoyment of the original). A related argument is that unlike the situation with tangible property, there is no natural scarcity of a particular idea or information: once it exists at all, it can be re-used and duplicated indefinitely without such re-use diminishing the original. Stephan Kinsella has objected to \"intellectual property\" on the grounds that the word \"property\" implies scarcity, which is not applicable to ideas.\nEntrepreneur and politician Rick Falkvinge and hacker Alexandre Oliva have independently compared George Orwell's fictional dialect Newspeak to the terminology used by intellectual property supporters as a linguistic weapon to shape public opinion regarding copyright debate and digital rights management (DRM).\nAlternative terms.\nIn civil law jurisdictions, intellectual property has often been referred to as intellectual rights, traditionally a somewhat broader concept that has included moral rights and other personal protections that cannot be bought or sold. Use of the term \"intellectual rights\" has declined since the early 1980s, as use of the term \"intellectual property\" has increased. Alternative terms \"monopolies on information\" and \"intellectual monopoly\" have emerged among those who argue against the \"property\" or \"intellect\" or \"rights\" assumptions, notably Richard Stallman. The backronyms \"intellectual protectionism\" and \"intellectual poverty\", whose initials are also \"IP\", have also found supporters, especially among those who have used the backronym \"digital restrictions management\". The argument that an intellectual property right should (in the interests of better balancing of relevant private and public interests) be termed an \"intellectual monopoly privilege\" (IMP) has been advanced by several academics including Birgitte Andersen and Thomas Faunce.\nObjections to overly broad intellectual property laws.\nSome critics of intellectual property, such as those in the free-culture movement, point at intellectual monopolies as harming health (in the case of pharmaceutical patents), preventing progress, and benefiting concentrated interests to the detriment of the masses, and argue that ever-expansive monopolies in the form of copyright extensions, software patents, and business method patents harm the public interest. More recently, scientists and engineers are expressing concern that patent thickets are undermining technological development even in high-tech fields like nanotechnology. Petra Moser has asserted that historical analysis suggests that intellectual property laws may harm innovation:Overall, the weight of the existing historical evidence suggests that patent policies, which grant strong intellectual property rights to early generations of inventors, may discourage innovation. On the contrary, policies that encourage the diffusion of ideas and modify patent laws to facilitate entry and encourage competition may be an effective mechanism to encourage innovation.\nIn support of that argument, J\u00f6rg Baten, Nicola Bianchi and Petra Moser find historical evidence that especially compulsory licensing\u2014which allows governments to license patents without the consent of patent-owners\u2014encouraged invention in Germany in the early 20th century by increasing the threat of competition in fields with low pre-existing levels of competition. Peter Drahos notes, \"Property rights confer authority over resources. When authority is granted to the few over resources on which the many depend, the few gain power over the goals of the many. This has consequences for both political and economic freedom within a society.\"\nThe World Intellectual Property Organization (WIPO) recognizes that conflicts may exist between respecting and implementing current intellectual property systems and other human rights. In 2001 the UN Committee on Economic, Social and Cultural Rights issued a document called \"Human rights and intellectual property\" that argued that intellectual property tends to be governed by economic goals when it should be viewed primarily as a social product; in order to serve human well-being, intellectual property systems must respect and conform to human rights laws. According to the Committee, when systems fail to do so, they risk infringing upon the human right to food and health, and to cultural participation and scientific benefits. In 2004, the General Assembly of WIPO adopted \"The Geneva Declaration on the Future of the World Intellectual Property Organization\" which argues that WIPO should \"focus more on the needs of developing countries, and to view IP as one of many tools for development\u2014not as an end in itself\".\nEthical problems are most pertinent when socially valuable goods like life-saving medicines are given IP protection. While the application of IP rights can allow companies to charge higher than the marginal cost of production in order to recoup the costs of research and development, the price may exclude from the market anyone who cannot afford the cost of the product, in this case a life-saving drug. \"An IPR driven regime is therefore not a regime that is conductive to the investment of R&amp;D of products that are socially valuable to predominately poor populations\". Libertarians have differing views on intellectual property. Stephan Kinsella, an anarcho-capitalist on the right-wing of libertarianism, argues against intellectual property because allowing property rights in ideas and information creates artificial scarcity and infringes on the right to own tangible property. Kinsella uses the following scenario to argue this point:[I]magine the time when men lived in caves. One bright guy\u2014let's call him Galt-Magnon\u2014decides to build a log cabin on an open field, near his crops. To be sure, this is a good idea, and others notice it. They naturally imitate Galt-Magnon, and they start building their own cabins. But the first man to invent a house, according to IP advocates, would have a right to prevent others from building houses on their own land, with their own logs, or to charge them a fee if they do build houses. It is plain that the innovator in these examples becomes a partial owner of the tangible property (e.g., land and logs) of others, due not to first occupation and use of that property (for it is already owned), but due to his coming up with an idea. Clearly, this rule flies in the face of the first-user homesteading rule, arbitrarily and groundlessly overriding the very homesteading rule that is at the foundation of all property rights.\nThomas Jefferson once said in a letter to Isaac McPherson on 13 August 1813:\nIf nature has made any one thing less susceptible than all others of exclusive property, it is the action of the thinking power called an idea, which an individual may exclusively possess as long as he keeps it to himself; but the moment it is divulged, it forces itself into the possession of every one, and the receiver cannot dispossess himself of it. Its peculiar character, too, is that no one possesses the less, because every other possesses the whole of it. He who receives an idea from me, receives instruction himself without lessening mine; as he who lights his taper at mine, receives light without darkening me.\nIn 2005, the Royal Society of Arts launched the Adelphi Charter, aimed at creating an international policy statement to frame how governments should make balanced intellectual property law. Another aspect of current U.S. Intellectual Property legislation is its focus on individual and joint works; thus, copyright protection can only be obtained in 'original' works of authorship. Critics like Philip Bennet argue that this does not provide adequate protection against cultural appropriation of indigenous knowledge, for which a collective IP regime is needed. Intellectual property law has been criticized as not recognizing new forms of art such as the remix culture, whose participants often commit what technically constitutes violations of such laws, creation works such as anime music videos and others, or are otherwise subject to unnecessary burdens and limitations which prevent them from fully expressing themselves.\nObjections to the expansion in nature and scope of intellectual property laws.\nOther criticism of intellectual property law concerns the expansion of intellectual property, both in duration and in scope. As scientific knowledge has expanded and allowed new industries to arise in fields such as biotechnology and nanotechnology, originators of technology have sought IP protection for the new technologies. Patents have been granted for living organisms, and in the United States, certain living organisms have been patentable for over a century.\nThe increase in terms of protection is particularly seen in relation to copyright, which has recently been the subject of serial extensions in the United States and in Europe. With no need for registration or copyright notices, this is thought to have led to an increase in orphan works (copyrighted works for which the copyright owner cannot be contacted), a problem that has been noticed and addressed by governmental bodies around the world.\nAlso with respect to copyright, the American film industry helped to change the social construct of intellectual property via its trade organization, the Motion Picture Association (MPA). In amicus briefs in important cases, in lobbying before Congress, and in its statements to the public, the MPAA has advocated strong protection of intellectual property rights. In framing its presentations, the association has claimed that people are entitled to the property that is produced by their labor. Additionally Congress's awareness of the position of the United States as the world's largest producer of films has made it convenient to expand the conception of intellectual property. These doctrinal reforms have further strengthened the industry, lending the MPAA even more power and authority.\nThe growth of the Internet, and particularly distributed search engines like Kazaa and Gnutella, have represented a challenge for copyright policy. The Recording Industry Association of America, in particular, has been on the front lines of the fight against copyright infringement, which the industry calls \"piracy\". The industry has had victories against some services, including a highly publicized case against the file-sharing company Napster, and some people have been prosecuted for sharing files in violation of copyright. The electronic age has seen an increase in the attempt to use software-based DRM tools to restrict the copying and use of digitally based works. Laws such as the Digital Millennium Copyright Act have been enacted that use criminal law to prevent any circumvention of software used to enforce DRM systems. Equivalent provisions, to prevent circumvention of copyright protection have existed in EU for some time, and are being expanded in, for example, Article\u00a06 and 7 the Copyright Directive. Other examples are Article\u00a07 of the Software Directive of 1991 (91/250/EEC), and the Conditional Access Directive of 1998 (98/84/EEC). This can hinder legal uses, affecting public domain works, limitations and exceptions to copyright, or uses allowed by the copyright holder. Some copyleft licenses, like the GNU GPL 3, are designed to counter this. Laws may permit circumvention under specific conditions, such as when it is necessary to achieve interoperability with the circumventor's program, or for accessibility reasons; however, distribution of circumvention tools or instructions may be illegal.\nIn the context of trademarks, this expansion has been driven by international efforts to harmonise the definition of \"trademark\", as exemplified by the Agreement on Trade-Related Aspects of Intellectual Property Rights ratified in 1994, which formalized regulations for IP rights that had been handled by common law, or not at all, in member states. Pursuant to TRIPS, any sign which is \"capable of distinguishing\" the products or services of one business from the products or services of another business is capable of constituting a trademark.\nUse in corporate tax avoidance.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\nMake no mistake: the headline [tax] rate is not what triggers tax evasion and aggressive tax planning. That comes from schemes that facilitate profit shifting.\nPierre MoscoviciEuropean Commissioner for Tax\"Financial Times\", 11 March 2018\nIntellectual property has become a core tool in corporate tax planning and tax avoidance. IP is a key component of the leading multinational tax avoidance base erosion and profit shifting (BEPS) tools, which the OECD estimates costs $100\u200d\u2013\u200d240\u00a0billion in lost annual tax revenues. In 2017\u20132018, both the U.S. and the EU Commission simultaneously decided to depart from the OECD BEPS Project timetable, which was set up in 2013 to combat IP BEPS tax tools like the above, and launch their own anti-IP BEPS tax regimes:\nThe departure of the U.S. and EU Commission from the OECD BEPS Project process, is attributed to frustrations with the rise in IP as a key BEPS tax tool, creating intangible assets, which are then turned into royalty payment BEPS schemes (double Irish), and/or capital allowance BEPS schemes (capital allowances for intangibles). In contrast, the OECD has spent years developing and advocating intellectual property as a legal and a GAAP accounting concept.\nGender gap in intellectual property.\nWomen have historically been underrepresented in the creation and ownership of intellectual property covered by intellectual property rights. According to the World Intellectual Property Organization, women composed only 16.5% of patent holders even as recently as 2020. This disparity is the result of several factors including systemic bias, sexism and discrimination within the intellectual property space, underrepresentation within STEM, and barriers to access of necessary finance and knowledge in order to obtain intellectual property rights, among other reasons.\nGlobal IP ratchet and developing countries.\nThe global increase in intellectual property protection is sometimes referred to as a global IP ratchet in which a spiral of bilateral and multilateral agreements result in growing obligations where new agreements never recede from existing standards and very often further heighten them.7 The global IP ratchet has limited the freedom of developing countries to set their own IP standards.7 Developing countries' lack of bargaining power relative to the developed countries driving the global IP ratchet means that developing countries' ability to regulate intellectual property to advance domestic interests is eroding.\nReferences.\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nSources.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "14726", "revid": "2387872", "url": "https://en.wikipedia.org/wiki?curid=14726", "title": "Great Famine (Ireland)", "text": "Famine in Ireland from 1845 to 1852\nThe Great Famine, also known as the Great Hunger ( ), the Famine and the Irish Potato Famine, was a period of mass starvation and disease in Ireland lasting from 1845 to 1852 that constituted a historical social crisis and had a major impact on Irish society and history as a whole. The most severely affected areas were in the western and southern parts of Ireland\u2014where the Irish language was dominant\u2014hence the period was contemporaneously known in Irish as , which literally translates to \"the bad life\" and loosely translates to \"the hard times\". \nThe worst year of the famine was 1847, which became known as \"Black '47\". The population of Ireland on the eve of the famine was about 8.5 million; by 1901, it was just 4.4 million. During the Great Hunger, roughly one million people died and over one million more fled the country, causing the country's population to fall by 20\u201325% between 1841 and 1871, with some towns' populations falling by as much as 67%. Between 1845 and 1855, at least 2.1 million people left Ireland, primarily on packet ships but also on steamboats and barques\u2014one of the greatest exoduses from a single island in history.\nThe proximate cause of the famine was the infection of potato crops by blight (\"Phytophthora infestans)\" throughout Europe during the 1840s. Impact on food supply by blight infection caused 100,000 deaths outside Ireland, and influenced much of the unrest that culminated in European Revolutions of 1848. Longer-term reasons for the massive impact of this particular famine included the system of absentee landlordism and single-crop dependence. Initial limited but constructive government actions to alleviate famine distress were ended by a new Whig administration in London, which pursued a laissez-faire economic doctrine, but also because some assumed that the famine was divine judgement or that the Irish lacked moral character, with aid only resuming to some degree later. Large amounts of food were exported from Ireland during the famine and the refusal of London to bar such exports, as had been done on previous occasions, was an immediate and continuing source of controversy, contributing to anti-British sentiment and the campaign for independence. Additionally, the famine indirectly resulted in tens of thousands of households being evicted, exacerbated by a provision forbidding access to workhouse aid while in possession of more than one-quarter acre of land.\nThe famine was a defining moment in the history of Ireland, which was part of the United Kingdom of Great Britain and Ireland from 1801 to 1922. The famine and its effects permanently changed the island's demographic, political, and cultural landscape, producing an estimated 2 million refugees and spurring a century-long population decline. For both the native Irish and those in the resulting diaspora, the famine entered folk memory. The strained relations between many Irish people and the then ruling British government worsened further because of the famine, heightening ethnic and sectarian tensions and boosting nationalism and republicanism both in Ireland and among Irish emigrants around the world. English documentary maker John Percival said that the famine \"became part of the long story of betrayal and exploitation which led to the growing movement in Ireland for independence.\" Scholar Kirby Miller makes the same point. Debate exists regarding nomenclature for the event, whether to use the term \"Famine\", \"Potato Famine\" or \"Great Hunger\".\nThe potato blight returned to Europe in 1879 but, by this time, the Land War (one of the largest agrarian movements to take place in 19th-century Europe) had begun in Ireland. The movement, organized by the Irish National Land League, continued the political campaign for the Three Fs which was issued in 1850 by the Tenant Right League during the Great Famine. When the potato blight returned to Ireland in the 1879 famine, the League boycotted \"notorious landlords\" and its members physically blocked the evictions of farmers; the consequent reduction in homelessness and house demolition resulted in a drastic reduction in the number of deaths.\nCauses and contributing factors.\nIreland was brought into the United Kingdom in January 1801 following the passage of the Acts of Union. Executive power lay in the hands of the Lord Lieutenant of Ireland and Chief Secretary for Ireland, who were appointed by the British government. Ireland sent 105 members of parliament to the House of Commons of the United Kingdom, and Irish representative peers elected 28 of their own number to sit for life in the House of Lords. Between 1832 and 1859, 70% of Irish representatives were landowners or the sons of landowners.\nIn the 40 years that followed the union, successive British governments grappled with the problems of governing a country which had, as Benjamin Disraeli stated in 1844, \"a starving population, an absentee aristocracy, an alien established Protestant church, and in addition, the weakest executive in the world\". One historian calculated that, between 1801 and 1845, there had been 114 commissions and 61 special committees inquiring into the state of Ireland, and that \"without exception their findings prophesied disaster; Ireland was on the verge of starvation, her population rapidly increasing, three-quarters of her labourers unemployed, housing conditions appalling and the standard of living unbelievably low\".\nLectures printed in 1847 by John Hughes, Bishop of New York, are a contemporary exploration into the antecedent causes, particularly the political climate, in which the Irish famine occurred.\nLandlords and tenants.\nThe \"middleman system\" for managing landed property was introduced in the 18th century. Rent collection was left in the hands of the landlords' agents, or middlemen. This assured the landlord of a regular income and relieved them of direct responsibility while leaving tenants open to exploitation by the middlemen. The ability of middlemen was measured by the rent income they could contrive to extract from tenants. Middlemen leased large tracts of land from the landlords on long leases with fixed rents and sublet to tenants, keeping any money raised in excess to the rent paid to the landlord. This system, coupled with minimal oversight of the middlemen, incentivised harsh exploitation of tenants. Middlemen would split a holding into smaller and smaller parcels so as to increase the amount of rent they could obtain. Tenants could be evicted for reasons such as non-payment of rents (which were high), or a landlord's decision to raise sheep instead of grain crops. Cottiers paid their rent by working for the landlord while the spalpeens (itinerant labourers) paid for short-term leases through temporary day work.\nA majority of Catholics, who constituted 80% of the Irish population, lived in conditions of poverty and insecurity. At the top of the social hierarchy was the Ascendancy class, composed of English and Anglo-Irish families who owned most of the land and held more or less unchecked power over their tenants. Some of their estates were vast; for example, the Earl of Lucan owned more than . Many of these landowners lived in England and functioned as absentee landlords. The rent revenue was mostly sent to England.\nIn 1800, the 1st Earl of Clare observed of landlords that \"confiscation is their common title\". According to the historian Cecil Woodham-Smith, landlords regarded the land as a source of income, from which as much as possible was to be extracted. With the peasantry \"brooding over their discontent in sullen indignation\" (in the words of the Earl of Clare), the landlords largely viewed the countryside as a hostile place in which to live. Some landlords visited their property only once or twice in a lifetime, if ever. The rents from Ireland were generally spent elsewhere; an estimated \u00a36,000,000 was remitted out of Ireland in 1842.\nIn 1843, the British Government recognized that the land management system in Ireland was the foundational cause of disaffection in the country. The Prime Minister established a Royal Commission, chaired by the Earl of Devon (Devon Commission), to enquire into the laws regarding the occupation of land. Irish politician Daniel O'Connell described this commission as \"perfectly one-sided\", being composed of landlords with no tenant representation.\nIn February 1845, Devon reported:\nIt would be impossible adequately to describe the privations which they [the Irish labourer and his family] habitually and silently endure\u00a0... in many districts their only food is the potato, their only beverage water\u00a0... their cabins are seldom a protection against the weather\u00a0... a bed or a blanket is a rare luxury\u00a0... and nearly in all their pig and a manure heap constitute their only property.\nThe Commissioners concluded they could not \"forbear expressing our strong sense of the patient endurance which the labouring classes have exhibited under sufferings greater, we believe, than the people of any other country in Europe have to sustain\". The Commission stated that bad relations between landlord and tenant were principally responsible for this suffering. Landlords were described in evidence before the commission as \"land sharks\", \"bloodsuckers\", and \"the most oppressive species of tyrant that ever lent assistance to the destruction of a country\".\nAs any improvement made on a holding by a tenant became the property of the landlord when the lease expired or was terminated, the incentive to make improvements was limited. Most tenants had no security of tenure on the land; as tenants \"at will\", they could be turned out whenever the landlord chose. The only exception to this arrangement was in Ulster where, under a practice known as \"tenant right\", a tenant was compensated for any improvement they made to their holding. According to Woodham-Smith, the commission stated that \"the superior prosperity and tranquillity of Ulster, compared with the rest of Ireland, were due to tenant right\".\nLandlords in Ireland often used their powers without compunction, and tenants lived in dread of them. Woodham-Smith writes that, in these circumstances, \"industry and enterprise were extinguished and a peasantry created which was one of the most destitute in Europe\".\nTenants and subdivisions.\nImmense population growth, from about 2 million in 1700 to 8 million by the time of the Great Famine, led to increased division of holdings and a consequent reduction in their average size. By 1845, 24% of all Irish tenant farms were of in size, while 40% were of . Holdings were so small that no crop other than potatoes would suffice to feed a family. Shortly before the famine, the British government reported that poverty was so widespread that one-third of all Irish small holdings could not support the tenant families after rent was paid; the families survived only by earnings as seasonal migrant labour in England and Scotland. Following the famine, reforms were implemented making it illegal to further divide land holdings.\nThe 1841 census showed a population of just over eight million. Two-thirds of people depended on agriculture for their survival but rarely received a working wage. They had to work for their landlords in return for a small patch of land to farm. This forced Ireland's peasantry to practice continuous monoculture, as the potato was the only crop that could meet nutritional needs.\nPotato dependency.\nThe potato was first introduced in Ireland as a garden crop of the gentry. By the late 17th century, it had become widespread as a supplementary food, but the main Irish diet, at that time, was still based on butter, milk, and grain products.\nThe Irish economy grew between 1760 and 1815 due to infrastructure expansion and the Napoleonic Wars (1805\u20131815), which had increased the demand for food in Britain. Tillage increased to such an extent that there was only a small amount of land available to small farmers to feed themselves. The potato was adopted as a primary food source because of its quick growth in a comparatively small space. By 1800, the potato had become a staple food for one in three Irish people, especially in winter. It eventually became a staple year-round for farmers. A disproportionate share of the potatoes grown in Ireland were the Irish Lumper, creating a lack of genetic variability among potato plants, which increased vulnerability to disease.\nPotatoes were essential to the expansion of the cottier system; they supported an extremely cheap workforce, but at the cost of lower living standards. For the labourer, \"a potato wage\" shaped the expanding agrarian economy. The potato was also used extensively as a fodder crop for livestock immediately prior to the famine. Approximately 33% of production, amounting to , was typically used in this way.\nBlight in Ireland.\nPrior to the arrival of \"Phytophthora infestans\", commonly known as \"blight\", only two main potato plant diseases had been discovered. One was called \"dry rot\" or \"taint\", and the other was a virus known popularly as \"curl\". \"Phytophthora infestans\" is an oomycete (a variety of parasitic, non-photosynthetic organisms closely related to brown algae, and not a fungus).\nIn 1851, the Census of Ireland Commissioners recorded 24 failures of the potato crop going back to 1728, of varying severity. General crop failures, through disease or frost, were recorded in 1739, 1740, 1770, 1800, and 1807. In 1821 and 1822, the potato crop failed in Munster and Connaught. In 1830 and 1831, counties Mayo, Donegal, and Galway suffered likewise. In 1832, 1833, 1834, and 1836, dry rot and curl caused serious losses, and in 1835 the potato failed in Ulster. Widespread failures throughout Ireland occurred in 1836, 1837, 1839, 1841, and 1844. According to Woodham-Smith, \"the unreliability of the potato was an accepted fact in Ireland\".\nExperts are still unsure of how and when blight arrived in Europe; it almost certainly was not present prior to 1842, and probably arrived in 1844. The origin of the pathogen has been traced to the Toluca Valley in Mexico, whence it spread within North America and then to Europe. The 1845\u20131846 blight was caused by the HERB-1 strain of the blight.\nIn 1844, Irish newspapers carried reports concerning a disease that had attacked the potato crops in America for two years. In 1843 and 1844, blight largely destroyed the potato crops in the Eastern United States. Ships from Baltimore, Philadelphia, or New York City could have carried diseased potatoes from these areas to European ports. American plant pathologist William C. Paddock posited that the blight was transported via potatoes being carried to feed passengers on clipper ships sailing from America to Ireland. Once introduced in Ireland and Europe, blight spread rapidly. By mid-August 1845, it had reached much of northern and central Europe; Belgium, The Netherlands, northern France, and southern England had all already been affected.\nOn 16 August 1845, \"The Gardeners' Chronicle and Horticultural Gazette\" reported \"a blight of unusual character\" on the Isle of Wight. A week later, on 23 August, it reported that \"A fearful malady has broken out among the potato crop\u00a0... In Belgium the fields are said to be completely desolated. There is hardly a sound sample in Covent Garden market\u00a0... As for cure for this distemper, there is none.\" These reports were extensively covered in Irish newspapers. On 11 September, the \"Freeman's Journal\" reported on \"the appearance of what is called 'cholera' in potatoes in Ireland, especially in the north\". On 13 September, \"The Gardeners' Chronicle\" announced: \"We stop the Press with very great regret to announce that the potato Murrain has unequivocally declared itself in Ireland.\"\nNevertheless, the British government remained optimistic over the next few weeks, as it received conflicting reports. Only when the crop was harvested in October did the scale of destruction become apparent. Prime Minister Sir Robert Peel wrote to Sir James Graham in mid-October that he found the reports \"very alarming\", but allayed his fears by claiming that there was \"always a tendency to exaggeration in Irish news\".\nCrop loss in 1845 has been estimated at anywhere from one-third to one-half of cultivated acreage. The Mansion House Committee in Dublin, to which hundreds of letters were directed from all over Ireland, claimed on 19 November 1845 to have ascertained beyond the shadow of a doubt that \"considerably more than one-third of the entire of the potato crop ... has been already destroyed\".\nIn 1846, three-quarters of the harvest was lost to blight. According to Cormac \u00d3 Gr\u00e1da, the first attack of potato blight caused considerable hardship in rural Ireland from the autumn of 1846, when the first deaths from starvation were recorded. Seed potatoes were scarce in 1847. Few had been sown, so, despite average yields, hunger continued. 1848 yields were only two-thirds of normal. Since over three million Irish people were totally dependent on potatoes for food, hunger and famine were widespread.\nReaction in Ireland.\nIn early November 1845, a deputation from the citizens of Dublin, including the Duke of Leinster, Lord Cloncurry, Daniel O'Connell and the Lord Mayor, went to the Lord Lieutenant of Ireland, Lord Heytesbury to discuss the issue. They offered suggestions such as opening the ports to foreign corn, stopping distillation from grain, prohibiting the export of foodstuffs, and providing employment through public works. Lord Heytesbury urged them not to be alarmed, that they \"were premature\", that scientists were enquiring into all those matters.\nJohn Mitchel, one of the leading Irish nationalists, later wrote one of the first widely circulated tracts on the famine, \"The Last Conquest of Ireland (Perhaps)\", published in 1861. It proposed that British actions during the famine and their treatment of the Irish were a deliberate effort at genocide. It contained a sentence that has since become famous: \"The Almighty, indeed, sent the potato blight, but the English created the Famine.\" Mitchel was charged with sedition because of his writings, but this charge was dropped. He was convicted by a packed jury under the newly enacted Treason Felony Act and sentenced to 14 years transportation to Bermuda.\nAccording to Charles Gavan Duffy, \"The Nation\" insisted that the proper remedy, retaining in the country the food raised by her people until the people were fed, was one which the rest of Europe had adopted, and one which even the parliaments of the Pale (i.e., before the union with Great Britain in 1801) had adopted in periods of distress.\nContemporaneously, as found in letters from the period and in particular later oral memory, the name for the event is in , though with the earlier spelling standard of the era, which was Gaelic script, it is found written as in Dro\u010b-\u1e60ao\u0121al. In the modern era, this name, while loosely translated as \"the hard-time\", is always denoted with a capital letter to express its specific historic meaning.\nThe period of the potato blight in Ireland from 1845 to 1851 was full of political confrontation. A more radical Young Ireland group seceded from the Repeal movement in July 1846, and attempted an armed rebellion in 1848. It was unsuccessful.\nIn 1847, William Smith O'Brien, leader of the Young Ireland party, became one of the founding members of the Irish Confederation. The following year, he helped organise the short-lived Young Irelander Rebellion of 1848 in County Tipperary.\nGovernment response.\nGovernment responses to previous food shortages.\nWhen Ireland experienced food shortages in 1782\u20131783, ports were closed to exporting food, with the intention of keeping locally grown food in Ireland to feed the hungry. Irish food prices promptly dropped. Some merchants lobbied against the export ban, but the government in the 1780s overrode their protests.\nTory government.\nHistorian F. S. L. Lyons characterised the initial response of the British government to the early, less severe phase of the famine as \"prompt and relatively successful\". Confronted by widespread crop failure in November 1845, the Prime Minister, Sir Robert Peel, purchased \u00a3100,000 worth of maize and cornmeal secretly from America with Baring Brothers initially acting as his agents. The government hoped that they would not \"stifle private enterprise\" and that their actions would not act as a disincentive to local relief efforts. Due to poor weather conditions, the first shipment did not arrive in Ireland until the beginning of February 1846. The initial shipments were of unground dried kernels, but the few Irish mills in operation were not equipped for milling maize and a long and complicated milling process had to be adopted before the meal could be distributed. In addition, before the cornmeal could be consumed, it had to be \"very much\" cooked again, or eating it could result in severe bowel complaints. Due to its yellow colour, and initial unpopularity, it became known as \"Peel's brimstone\".\nIn October 1845, Peel moved to repeal the Corn Laws\u2014tariffs on grain which kept the price of bread high\u2014but the issue split his party and he had insufficient support from his own colleagues to push the measure through. He resigned the premiership in December, but the opposition was unable to form a government and he was re-appointed. In March, Peel set up a programme of public works in Ireland, to include road improvement and the building of piers and fishing harbours, but the famine situation worsened during 1846, and the repeal of the Corn Laws in that year did little to help the starving Irish; the measure split the Conservative Party, leading to the fall of Peel's ministry. On 25 June, the second reading of the government's Irish Coercion Bill was defeated by 73 votes in the House of Commons by a combination of Whigs, Radicals, Irish Repealers, and protectionist Conservatives. Peel was forced to resign as prime minister on 29 June, and the Whig leader, Lord John Russell, became prime minister.\nWhig government.\nThe measures undertaken by Peel's successor, Russell, proved inadequate as the crisis deepened. The new Whig administration, influenced by the doctrine of laissez-faire, assumed that the market would provide the food needed. They refused to interfere with the movement of food to England, and then halted the previous government's food and relief works, leaving many hundreds of thousands of people without access to work, money, or food. Russell's ministry introduced a new programme of public works that by December 1846 employed a third or half a million people but proved impossible to administer effectively.\nCharles Trevelyan, who was in charge of the administration of government relief, limited the Government's food aid programme, claiming that food would be readily imported into Ireland once people had more money to spend after wages were being paid on new public-works projects.\nIn a private correspondence, Trevelyan explained how the famine could bring benefit to the English; As he wrote to Edward Twisleton:\"We must not complain of what we really want to obtain. If small farmers go, and their landlords are reduced to sell portions of their estates to persons who will invest capital we shall at last arrive at something like a satisfactory settlement of the country\".In January 1847, the government abandoned its policy of noninterference, realising that it had failed, and turned to a mixture of \"indoor\" and \"outdoor\" direct relief; the former administered in workhouses through the Irish Poor Laws, the latter through soup kitchens. The costs of the Poor Law fell primarily on the local landlords, some of whom in turn attempted to reduce their liability by evicting their tenants or providing some relief through the conversionist practice of Souperism.\nOn 1 March 1847, the Bank of England announced plans to raise a loan of \u00a314 million to relieve the Irish crisis, and also for unfunded tax cuts. This led to the Panic of 1847, in which gold was withdrawn from circulation, so reducing the amount of bank notes that the Bank could legally circulate. By 17 April 1847 the bullion reserve of the Bank of England had diminished from \u00a315 million in January to some \u00a39 million, and it was announced that the cost of famine relief would be transferred to local taxes in Ireland. The financial crisis temporarily improved, but the intended relief for Ireland did not materialise.\nIn June 1847, the Poor Relief (Ireland) Act 1847 (10 &amp; 11 Vict. c. 31) was passed which embodied the principle, popular in Britain, that Irish property must support Irish poverty. The landed proprietors in Ireland were held in Britain to have created the conditions that led to the famine. However, it was asserted that, since the Acts of Union 1800, the British Parliament was partly to blame. This point was raised in \"The Illustrated London News\" on 13 February 1847: \"There was no law it would not pass at their request, and no abuse it would not defend for them.\" On 24 March, \"The Times\" reported that Britain had permitted in Ireland \"a mass of poverty, disaffection, and degradation without a parallel in the world. It allowed proprietors to suck the very life-blood of that wretched race\".\nThe \"Gregory clause\" of the Poor Law, named after William H. Gregory, MP, prohibited anyone who held at least from receiving relief. In practice, this meant that the many farmers who had to sell all their produce to pay rent and taxes, would have to deliver up all their land to the landlord to qualify for public outdoor relief. These factors combined to drive thousands of people off the land: 90,000 in 1849, and 104,000 in 1850.\nThe Incumbered Estates (Ireland) Act 1849 (12 &amp; 13 Vict. c. 77) allowed landlord estates to be auctioned off upon the petition of creditors. Estates with debts were then auctioned off at low prices. Wealthy British speculators purchased the lands and \"took a harsh view\" of the tenant farmers who continued renting. The rents were raised, and tenants evicted to create large cattle grazing pastures. Between 1849 and 1854, some 50,000 families were evicted.\nMilitary response.\nThe Royal Navy squadron stationed in Cork under the command of Rear-Admiral Hugh Pigot undertook significant relief operations from 1846 to 1847, transporting government relief into the port of Cork and other ports along the Irish coast, being ordered on 2 January 1846 to assist distressed regions. On 27 December 1846, Trevelyan ordered every available steamship to Ireland to assist in relief, and on 14 January 1847, Pigot received orders to also distribute supplies from the British Relief Association and treat them identically to government aid. In addition, some naval officers under Pigot oversaw the logistics of relief operations further inland from Cork. In February 1847, Trevelyan ordered Royal Navy surgeons dispatched to provide medical care for those suffering from illnesses that accompanied starvation, distribute medicines that were in short supply, and assist in proper, sanitary burials for the deceased. These efforts, although significant, were insufficient at preventing mass mortality from famine and disease.\nFood exports.\nThe historian Cecil Woodham-Smith wrote in \"\" that no issue has provoked so much anger and embittered relations between England and Ireland \"as the indisputable fact that huge quantities of food were exported from Ireland to England throughout the period when the people of Ireland were dying of starvation\". While in addition to the maize imports, four times as much wheat was imported into Ireland at the height of the famine as exported. Woodham-Smith added that provision via the Poor law union workhouses by the Poor Relief (Ireland) Act 1838 (1 &amp; 2 Vict. c. 56) had to be paid by rates levied on the local property owners, and in areas where the famine was worst, the tenants could not pay their rents to enable landlords to fund the rates and therefore the workhouses. Only by selling food, some of which would inevitably be exported, could a \"virtuous circle\" be created whereby the rents and rates would be paid, and the workhouses funded. Relief through the workhouse system was simply overwhelmed by the enormous scale and duration of the famine. Nicolas McEvoy, parish priest of Kells, wrote in October 1845:\nOn my most minute personal inspection of the potato crop in this most fertile potato-growing locale is founded my inexpressibly painful conviction that one family in twenty of the people will not have a single potato left on Christmas day next. Many are the fields I have examined and testimony the most solemn can I tender, that in the great bulk of those fields all the potatoes sizable enough to be sent to table are irreparably damaged, while for the remaining comparatively sounder fields very little hopes are entertained in consequence of the daily rapid development of the deplorable disease.\nWith starvation at our doors, grimly staring us, vessels laden with our sole hopes of existence, our provisions, are hourly wafted from our every port. From one milling establishment I have last night seen not less than fifty dray loads of meal moving on to Drogheda, thence to go to feed the foreigner, leaving starvation and death the sure and certain fate of the toil and sweat that raised this food.\nFor their respective inhabitants England, Holland, Scotland, Germany, are taking early the necessary precautions\u2014getting provisions from every possible part of the globe; and I ask are Irishmen alone unworthy the sympathies of a paternal gentry or a paternal Government?\nLet Irishmen themselves take heed before the provisions are gone. Let those, too, who have sheep, and oxen, and haggards. Self-preservation is the first law of nature. The right of the starving to try and sustain existence is a right far and away paramount to every right that property confers.\nInfinitely more precious in the eyes of reason in the adorable eye of the Omnipotent Creator, is the life of the last and least of human beings than the whole united property of the entire universe. The appalling character of the crisis renders delicacy but criminal and imperatively calls for the timely and explicit notice of principles that will not fail to prove terrible arms in the hands of a neglected, abandoned starving people.\nIn the 5 May 2020, issue of the \"Dublin Review of Books\", Editor Maurice Earls wrote:\nDr. McEvoy, in his grim forebodings and apocalyptic fear, was closer to the truth than the sanguine rationalists quoted in the newspapers, but McEvoy, like many others, overestimated the likelihood of mass rebellion, and even this great clerical friend of the poor could hardly have contemplated the depth of social, economic and cultural destruction which would persist and deepen over the following century and beyond.\nIt was politics that turned a disease of potatoes and tomatoes into famine, and it was politics which ensured its disastrous aftereffects would disfigure numerous future generations.\nAccording to historian James Donnelly, \"the picture of Irish people starving as food was exported was the most powerful image in the nationalist construct of the Famine\". Grain imports increased after the spring of 1847 and much of the debate \"has been conducted within narrow parameters,\" focusing \"almost exclusively on national estimates with little attempt to disaggregate the data by region or by product.\"\nCharity.\nTotal charitable donations for famine relief might have been about \u00a31.5 million of which \u00a3856,500 came from outside Ireland. Donations within Ireland are harder to trace; \u00a3380,000 of donations were officially registered but once some allowance is made for less formal donations the Irish total probably exceeds that of Britain (\u00a3525,000). People of Irish descent also contributed to funds raised outside of Ireland and those donations would be included in the region where the donation was made. English Protestants donated more to Irish famine relief than any other source outside of Ireland.\nLarge sums of money were donated by charities; the first foreign campaign in December 1845 included the Boston Repeal Association and the Catholic Church. Calcutta is credited with making the first larger donations in 1846, summing up to around \u00a314,000. The money raised included contributions by Irish soldiers serving there and Irish people employed by the East India Company. Russian Tsar Alexander II sent funds and Queen Victoria donated \u00a32,000. According to legend, Sultan Abd\u00fclmecid I of the Ottoman Empire originally offered to send \u00a310,000 but was asked either by British diplomats or his own ministers to reduce it to \u00a31,000 to avoid donating more than the Queen. U.S. President James K. Polk donated $50 and in 1847 Congressman Abraham Lincoln donated $10, or \u00a35.\nInternational fundraising activities received donations from locations as diverse as Venezuela, Australia, South Africa, Mexico, Russia and Italy. In New Brunswick, which was at the time a British colony, the House of Assembly voted to donate 1,500 to the British Relief Association.\nPope Pius IX also made a personal contribution of 1,000 Scudi (approximately \u00a3213) for famine relief in Ireland and authorized collections in Rome. Most significantly, on 25 March 1847, Pius IX issued the encyclical Praedecessores nostros, which called the whole Catholic world to contribute moneywise and spiritually to Irish relief. Major figures behind international Catholic fundraising for Ireland were the rector of the Pontifical Irish College, Paul Cullen, and the President of the Society of Saint Vincent de Paul, Jules Gossin.\nIn addition to the religious, non-religious organisations came to the assistance of famine victims. The British Relief Association was the largest of these groups. Founded on 1 January 1847 by Lionel de Rothschild, Abel Smith, and other prominent bankers and aristocrats, the Association raised money throughout England, America, and Australia; their funding drive was benefited by a \"Queen's Letter\", a letter from Queen Victoria appealing for money to relieve the distress in Ireland. With this initial letter, the Association raised \u00a3171,533. A second, somewhat less successful \"Queen's Letter\" was issued in late 1847. In total, the Association raised approximately \u00a3390,000 for Irish relief.\nPrivate initiatives such as the Central Relief Committee of the Society of Friends (Quakers) attempted to fill the gap caused by the end of government relief, and eventually, the government reinstated the relief works, although bureaucracy slowed the release of food supplies. Thousands of dollars were raised in the United States, including $170 ($5,218 in 2019 value) collected from a group of Native American Choctaws in 1847. Judy Allen, editor of the Choctaw Nation of Oklahoma's newspaper \"Biskinik\", wrote that \"It had been just 16 years since the Choctaw people had experienced the Trail of Tears, and they had faced starvation\u00a0... It was an amazing gesture.\" To mark the 150th anniversary, eight Irish people retraced the Trail of Tears.\nContributions by the United States during the famine were highlighted by Senator Henry Clay who said; \"No imagination can conceive\u2014no tongue express\u2014no brush paint\u2014the horrors of the scenes which are daily exhibited in Ireland.\" He called upon Americans to remind them that the practice of charity was the greatest act of humanity they could do. In total, 118 vessels sailed from the US to Ireland with relief goods valued at $545,145. Specific states which provided aid include South Carolina and Philadelphia, Pennsylvania. Pennsylvania was the second most important state for famine relief in the US and the second-largest shipping port for aid to Ireland. The state hosted the Philadelphia Irish Famine Relief Committee. Catholics, Methodists, Quakers, Presbyterians, Episcopalians, Lutherans, Moravian and Jewish groups put aside their differences in the name of humanity to help the Irish. South Carolina rallied around the efforts to help those experiencing the famine. They raised donations of money, food and clothing to help the victims of the famine\u2014Irish immigrants made up 39% of the white population in the southern cities. Historian Harvey Strum claims that \"The states ignored all their racial, religious, and political differences to support the cause for relief.\"\nEviction.\nLandlords were responsible for paying the rates of every tenant whose yearly rent was \u00a34 or less. Landlords whose land was crowded with poorer tenants were now faced with large bills. Many began clearing the poor tenants from their small plots and letting the land in larger plots for over \u00a34 which then reduced their debts. In 1846, there had been some clearances, but the great mass of evictions came in 1847. According to James S. Donnelly Jr., it is impossible to be sure how many people were evicted during the years of the famine and its immediate aftermath. It was only in 1849 that the police began to keep a count, and they recorded a total of almost 250,000 persons as officially evicted between 1849 and 1854.\nDonnelly considered this to be an underestimate, and if the figures were to include the number pressured into \"voluntary\" surrenders during the whole period (1846\u20131854), the figure would almost certainly exceed half a million persons. While Helen Litton says there were also thousands of \"voluntary\" surrenders, she notes also that there was \"precious little voluntary about them\". In some cases, tenants were persuaded to accept a small sum of money to leave their homes, \"cheated\" into thinking that they would be taken into the workhouses.\nWest Clare was one of the worst areas for evictions, where landlords turned thousands of families out and demolished their derisory cabins. Captain Kennedy in April 1848 estimated that 1,000 houses, with an average of six people to each, had been levelled since November. The Mahon family of Strokestown House evicted 3,000 people in 1847 and were still able to dine on lobster soup.\nAfter Clare, the worst area for evictions was County Mayo, accounting for 10% of all evictions between 1849 and 1854. George Bingham, 3rd Earl of Lucan, who owned over , was among the worst evicting landlords. He was quoted as saying that \"he would not breed paupers to pay priests\". Having turned out in the parish of Ballinrobe over 2,000 tenants alone, he then used the cleared land as grazing farms. In 1848, the Marquis of Sligo owed \u00a31,650 to Westport Union; he was also an evicting landlord, though he claimed to be selective, saying that he was only getting rid of the idle and dishonest. Altogether, he cleared about 25% of his tenants.\nIn 1846 the future Prime Minister of the United Kingdom John Russell, 1st Earl Russell reported that in one year more than 50,000 Irish families had been \"turned out of their wretched dwellings without pity and without refuge...we have made it the most degraded and most miserable country in the world...all the world is crying shame upon us.\"\nIn 1847, Bishop of Meath, Thomas Nulty, described his personal recollection of the evictions in a pastoral letter to his clergy:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Seven hundred human beings were driven from their homes in one day and set adrift on the world, to gratify the caprice of one who, before God and man, probably deserved less consideration than the last and least of them ... The horrid scenes I then witnessed, I must remember all my life long. The wailing of women\u2014the screams, the terror, the consternation of children\u2014the speechless agony of honest industrious men\u2014wrung tears of grief from all who saw them. I saw officers and men of a large police force, who were obliged to attend on the occasion, cry like children at beholding the cruel sufferings of the very people whom they would be obliged to butcher had they offered the least resistance. The landed proprietors in a circle all around\u2014and for many miles in every direction\u2014warned their tenantry, with threats of their direct vengeance, against the humanity of extending to any of them the hospitality of a single night's shelter ... and in little more than three years, nearly a fourth of them lay quietly in their graves.\nThe population in Drumbaragh, a townland in County Meath, plummeted 67 per cent between 1841 and 1851; in neighbouring Springville, it fell 54 per cent. There were fifty houses in Springville in 1841 and only eleven left in 1871.\nAccording to Litton, evictions might have taken place earlier but for fear of the secret societies. However, they were now greatly weakened by the Famine. Revenge still occasionally took place, with seven landlords being shot, six fatally, during the autumn and winter of 1847. Ten other occupiers of land, though without tenants, were also murdered, she says.\nOne such landlord reprisal occurred in West Roscommon. The \"notorious\" Major Denis Mahon enforced thousands of his tenants into eviction before the end of 1847, with an estimated 60 per cent decline in population in some parishes. He was shot dead in that year. In East Roscommon, \"where conditions were more benign\", the estimated decline in population was under 10 percent.\nLord Clarendon, alarmed at the number of landlords being shot and that this might mean rebellion, asked for special powers. Lord John Russell was not sympathetic to this appeal. Lord Clarendon believed that the landlords themselves were mostly responsible for the tragedy in the first place, saying that \"It is quite true that landlords in England would not like to be shot like hares and partridges ... but neither does any landlord in England turn out fifty persons at once and burn their houses over their heads, giving them no provision for the future.\" The Crime and Outrage Act was passed in December 1847 as a compromise, and additional troops were sent to Ireland.\nThe \"Gregory clause\", described by Donnelly as a \"vicious amendment to the Irish poor law\", had been a successful Tory amendment to the Whig poor-relief bill which became law in early June 1847, where its potential as an estate-clearing device was widely recognised in parliament, although not in advance. At first, the poor law commissioners and inspectors viewed the clause as a valuable instrument for a more cost-effective administration of public relief, but the drawbacks soon became apparent, even from an administrative perspective. They would soon view them as little more than murderous from a humanitarian perspective. According to Donnelly, it became obvious that the quarter-acre clause was \"indirectly a death-dealing instrument\".\nEmigration.\nAt least a million people are thought to have emigrated as a result of the famine. There were about 1\u00a0million long-distance emigrants between 1846 and 1851, mainly to North America. The total given in the 1851 census is 967,952. Short-distance emigrants, mainly to Britain, may have numbered 200,000 or more.\nWhile the famine was responsible for a significant increase in emigration from Ireland, of anywhere from 45% to nearly 85% depending on the year and the county, it was not the sole cause. The beginning of mass emigration from Ireland can be traced to the mid-18th century, when some 250,000 people left Ireland over a period of 50 years to settle in the New World. Irish economist Cormac \u00d3 Gr\u00e1da estimates that between 1\u00a0million and 1.5\u00a0million people emigrated during the 30 years between 1815 (when Napoleon was defeated in Waterloo) and 1845 (when the Great Famine began). However, during the worst of the famine, emigration reached somewhere around 250,000 in one year alone, with western Ireland seeing the most emigrants.\nFamilies did not migrate \"en masse\", but younger members of families did, so much so that emigration almost became a rite of passage, as evidenced by the data that show that, unlike similar emigrations throughout world history, women emigrated just as often, just as early, and in the same numbers as men. The emigrants would send remittances (reaching a total of \u00a31,404,000 by 1851) back to family in Ireland, which, in turn, allowed another member of their family to leave.\nEmigration during the famine years of 1845\u20131850 was primarily to England, Scotland, South Wales, North America, and Australia. Many of those fleeing to the Americas used the McCorkell Line. One city that experienced a particularly strong influx of Irish immigrants was Liverpool, with at least one-quarter of the city's population being Irish-born by 1851. This would heavily influence the city's identity and culture in the coming years, earning it the nickname of \"Ireland's second capital\". Liverpool became the only place outside of Ireland to elect an Irish nationalist to parliament when it elected T. P. O'Connor in 1885, and continuously re-elected him unopposed until his death in 1929. As of 2020, it is estimated that three quarters of people from the city have Irish ancestry.\nOf the more than 100,000 Irish that sailed to Canada in 1847, an estimated one out of five died from disease and malnutrition, including over 5,000 at Grosse Isle, Quebec, an island in the Saint Lawrence River used to quarantine ships near Quebec City. Overcrowded, poorly maintained, and badly provisioned vessels known as coffin ships sailed from small, unregulated harbours in the West of Ireland in contravention of British safety requirements, and mortality rates were high. The 1851 census reported that more than half the inhabitants of Toronto were Irish, and, in 1847 alone, 38,000 Irish flooded a city with fewer than 20,000 citizens. Other Canadian cities such as Quebec City, Montreal, Ottawa, Kingston, Hamilton, and Saint John also received large numbers. By 1871, 55% of Saint John residents were Irish natives or children of Irish-born parents. Unlike the United States, Canada could not close its ports to Irish ships because it was part of the British Empire, so emigrants could obtain cheap passage in returning empty lumber holds.\nIn America, most Irish became city-dwellers; with little money, many had to settle in the cities that the ships they came on landed in. By 1850, the Irish made up a quarter of the population in Boston, New York City, Philadelphia, and Baltimore.\nThe famine marked the beginning of the depopulation of Ireland in the 19th century. The population had increased by 13\u201314% in the first three decades of the 19th century; between 1831 and 1841, the population grew by 5%. Application of Thomas Malthus's idea of population expanding geometrically while resources increase arithmetically was popular during the famines of 1817 and 1822. By the 1830s, they were seen as overly simplistic, and Ireland's problems were seen \"less as an excess of population than as a lack of capital investment\". The population of Ireland was increasing no faster than that of England, which suffered no equivalent catastrophe. By 1854, between 1.5 and 2\u00a0million Irish left their country due to evictions, starvation, and harsh living conditions.\nDeath toll.\nIt is not known exactly how many people died during the period of the famine, although it is believed that more died from disease than from starvation. State registration of births, marriages, or deaths had not yet begun, and records kept by the Catholic Church are incomplete. One possible estimate has been reached by comparing the expected population with the eventual numbers in the 1850s. A census taken in 1841 recorded a population of 8,175,124. A census immediately after the famine in 1851 counted 6,552,385, a drop of over 1.5\u00a0million in 10 years. The census commissioners estimated that, at the normal rate of population increase, the population in 1851 should have grown to just over 9\u00a0million if the famine had not occurred.\nOn the in-development \"Great Irish Famine Online\" resource, produced by the Geography department of University College Cork, the population of Ireland section states, that together with the census figures being called low, before the famine it reads that \"it is now generally believed\" that over 8.75\u00a0million people populated the island of Ireland prior to it striking.\nIn 1851, the census commissioners collected information on the number who died in each family since 1841, and the cause, season, and year of death. They recorded 21,770 total deaths from starvation in the previous decade and 400,720 deaths from diseases. Listed diseases were fever, diphtheria, dysentery, cholera, smallpox, and influenza, with the first two being the main killers (222,021 and 93,232). The commissioners acknowledged that their figures were incomplete and that the true number of deaths was probably higher:\nThe greater the amount of destitution of mortality\u00a0... the less will be the amount of recorded deaths derived through any household form;\u2014for not only were whole families swept away by disease\u00a0... but whole villages were effaced from off the land.\nLater historians agree that the 1851 death tables \"were flawed and probably under-estimated the level of mortality\". The combination of institutional and figures provided by individuals gives \"an incomplete and biased count\" of fatalities during the famine. Cormac \u00d3 Gr\u00e1da, referencing the work of W. A. MacArthur, writes that specialists have long known that the Irish death tables were inaccurate, and undercounted the number of deaths.\nS. H. Cousens's estimate of 800,000 deaths relied heavily on retrospective information contained in the 1851 census and elsewhere, and is now regarded as too low. Modern historian J. J. Lee says \"at least 800,000\", and R. F. Foster estimates that \"at least 775,000 died, mostly through disease, including cholera in the latter stages of the holocaust\". He further notes that \"a recent sophisticated computation estimates excess deaths from 1846 to 1851 as between 1,000,000 and 1,500,000\u00a0... after a careful critique of this, other statisticians arrive at a figure of 1,000,000\".\nJoel Mokyr's estimates at an aggregated county level range from 1.1\u00a0million to 1.5\u00a0million deaths between 1846 and 1851. Mokyr produced two sets of data which contained an upper-bound and lower-bound estimate, which showed not much difference in regional patterns. The true figure is likely to lie between the two extremes of half and one and a half million, and the most widely accepted estimate is one million.\n&lt;templatestyles src=\"Crossreference/styles.css\" /&gt;\nAnother area of uncertainty lies in the descriptions of disease given by tenants as to the cause of their relatives' deaths. Though the 1851 census has been rightly criticised as underestimating the true extent of mortality, it does provide a framework for the medical history of the Great Famine. The diseases that badly affected the population fell into two categories: famine-induced diseases and diseases of nutritional deficiency. Of the nutritional deficiency diseases, the most commonly experienced were starvation and marasmus, as well as a condition at the time called dropsy. Dropsy (oedema) was a popular name given for the symptoms of several diseases, one of which, kwashiorkor, is associated with starvation.\nHowever, the greatest mortality was not from nutritional deficiency diseases, but from famine-induced ailments. The malnourished are very vulnerable to infections; therefore, these were more severe when they occurred. Measles, diphtheria, diarrhoea, tuberculosis, most respiratory infections, whooping cough, many intestinal parasites, and cholera were all strongly conditioned by nutritional status. Potentially lethal diseases, such as smallpox and influenza, were so virulent that their spread was independent of nutrition. The best example of this phenomenon was fever, which exacted the greatest death toll. In the popular mind, as well as medical opinion, fever and famine were closely related. Social dislocation\u2014the congregation of the hungry at soup kitchens, food depots, and overcrowded workhouses\u2014created conditions that were ideal for spreading infectious diseases such as typhus, typhoid, and relapsing fever.\nDiarrhoeal diseases were the result of poor hygiene, bad sanitation, and dietary changes. The concluding attack on a population incapacitated by famine was delivered by Asiatic cholera, which had visited Ireland briefly in the 1830s. In the following decade, it spread uncontrollably across Asia, through Europe, and into Britain, finally reaching Ireland in 1849. Some scholars estimate that the population of Ireland was reduced by 20\u201325%.\nAfter the famine.\nIreland's mean age of marriage in 1830 was 23.8 for women and 27.5 for men, where they had once been 21 for women and 25 for men, and those who never married numbered about 10% of the population; in 1840, they had respectively risen to 24.4 and 27.7. In the decades after the Famine, the age of marriage had risen to 28\u201329 for women and 33 for men, and as many as a third of Irishmen and a quarter of Irishwomen never married, due to low wages and chronic economic problems that discouraged early and universal marriage.\nOne consequence of the increase in the number of orphaned children was that some young women turned to prostitution to provide for themselves. Some of the women who became Wrens of the Curragh were famine orphans.\nThe potato blight would return to Ireland in 1879, though by then the rural cottier tenant farmers and labourers of Ireland had begun the \"Land War\", described as one of the largest agrarian movements to take place in nineteenth-century Europe.\nBy the time the potato blight returned in 1879, The Land League, which was led by Michael Davitt, who was born during the Great Famine and whose family had been evicted when Davitt was only 4 years old, encouraged the mass boycott of \"notorious landlords\" with some members also physically blocking evictions. The policy, however, would soon be suppressed. Close to 1000 people were interned under the 1881 Coercion Act for suspected membership. With the reduction in the rate of homelessness and the increased physical and political networks eroding the landlordism system, the severity of the following shorter famine would be limited.\nAccording to the linguist Erick Falc'her-Poyroux, surprisingly, for a country renowned for its rich musical heritage, only a small number of folk songs can be traced back to the demographic and cultural catastrophe brought about by the Great Famine, and he infers from this that the subject was generally avoided for decades among poorer people as it brought back too many sorrowful memories. Also, large areas of the country became uninhabited and the folk song collectors of the eighteenth and nineteenth centuries did not collect the songs they heard in the Irish language, as the language of the peasantry was often regarded as dead, or \"not delicate enough for educated ears\". Of the songs that have survived probably the best known is Skibbereen. Emigration has been an important source of inspiration for songs of the Irish during the 20th century.\nAnalysis of the government's role.\nContemporary analysis.\nContemporary opinion was sharply critical of the Russell government's response to and management of the crisis. From the start, there were accusations that the government failed to grasp the magnitude of the disaster. Sir James Graham, who had served as Home Secretary in Sir Robert Peel's late government, wrote to Peel that, in his opinion, \"the real extent and magnitude of the Irish difficulty are underestimated by the Government, and cannot be met by measures within the strict rule of economical science\".\nThis criticism was not confined to outside critics. The Lord-Lieutenant of Ireland, Lord Clarendon, wrote a letter to Russell on 26 April 1849, urging that the government propose additional relief measures: \"I don't think there is another legislature in Europe that would disregard such suffering as now exists in the west of Ireland, or coldly persist in a policy of extermination.\" Also in 1849, the Chief Poor Law Commissioner, Edward Twisleton, resigned in protest over the Rate-in-Aid Act, which provided additional funds for the Poor Law through a 6d in the pound levy on all rateable properties in Ireland. Twisleton testified that \"comparatively trifling sums were required for Britain to spare itself the deep disgrace of permitting its miserable fellow-subjects to die of starvation\". According to Peter Gray in his book \"The Irish Famine\", the government spent \u00a37\u00a0million for relief in Ireland between 1845 and 1850, \"representing less than half of one per cent of the British gross national product over five years. Contemporaries noted the sharp contrast with the \u00a320 million compensation given to West Indian slave-owners in the 1830s.\"\nOther critics maintained that, even after the government recognised the scope of the crisis, it failed to take sufficient steps to address it. John Mitchel, one of the leaders of the Young Ireland Movement, wrote in 1860:\nI have called it an artificial famine: that is to say, it was a famine which desolated a rich and fertile island that produced every year abundance and superabundance to sustain all her people and many more. The English, indeed, call the famine a \"dispensation of Providence\"; and ascribe it entirely to the blight on potatoes. But potatoes failed in like manner all over Europe, yet there was no famine save in Ireland. The British account of the matter, then, is first, a fraud; second, a blasphemy. The Almighty, indeed, sent the potato blight, but the English created the famine.\nStill, other critics saw reflected in the government's response its attitude to the so-called \"Irish Question\". Nassau Senior, an economics professor at Oxford University, wrote that the Famine \"would not kill more than one million people, and that would scarcely be enough to do any good\". In 1848, Denis Shine Lawlor suggested that Russell was a student of the Elizabethan poet Edmund Spenser, who had calculated \"how far English colonisation and English policy might be most effectively carried out by Irish starvation\". Charles Trevelyan, the civil servant with most direct responsibility for the government's handling of the famine, described it in 1848 as \"a direct stroke of an all-wise and all-merciful Providence\", which laid bare \"the deep and inveterate root of social evil\"; he affirmed that the Famine was \"the sharp but effectual remedy by which the cure is likely to be effected. God grant that the generation to which this opportunity has been offered may rightly perform its part...\"\nHistorical analysis.\nChristine Kinealy has written that \"the major tragedy of the Irish Famine of 1845\u20131852 marked a watershed in modern Irish history. Its occurrence, however, was neither inevitable nor unavoidable\". The underlying factors which combined to cause the famine were aggravated by an inadequate government response. Kinealy notes that the \"government had to do something to help alleviate the suffering\" but that \"it became apparent that the government was using its information not merely to help it formulate its relief policies, but also as an opportunity to facilitate various long-desired changes within Ireland\".\nJoel Mokyr writes that, \"There is no doubt that Britain could have saved Ireland,\" and compares the \u00a39.5 million the government spent on famine relief in Ireland to the \u00a363.9 million it would spend a few years later on the \"utterly futile\" Crimean War. Mokyr argues that, despite its formal integration into the United Kingdom, Ireland was effectively a foreign country to the British, who were therefore unwilling to spend resources that could have saved hundreds of thousands of lives.\nSome also pointed to the structure of the British Empire as a contributing factor. James Anthony Froude wrote that \"England governed Ireland for what she deemed her own interest, making her calculations on the gross balance of her trade ledgers, and leaving moral obligations aside, as if right and wrong had been blotted out of the statute book of the Universe.\" Dennis Clark, an Irish-American historian and critic of empire, claimed the famine was \"the culmination of generations of neglect, misrule and repression. It was an epic of English colonial cruelty and inadequacy. For the landless cabin dwellers, it meant emigration or extinction...\"\nPosition of the British government.\nThe British government has not expressly apologized for its role in the famine. But in 1997, at a commemoration event in County Cork, the actor Gabriel Byrne read out a message by Prime Minister Tony Blair that acknowledged the inadequacy of the government response. It asserted that \"those who governed in London at the time failed their people through standing by while a crop failure turned into a massive human tragedy\". The message was well received by the Irish media, where it was understood as the long-sought-after British apology. Archive documents released in 2021 showed that the message was not in fact written or approved by Blair, who could not be reached by aides at the time. It was therefore approved by Blair's principal private secretary John Holmes on his own initiative.\nGenocide question.\nThe vast majority of historians reject the claim that the British government's response to the famine constituted a genocide. Their position is partially based on the fact that, with regard to famine related deaths, there was a lack of intent to commit genocide. Although contemporary commentators blamed the mass death on the actions of the British government, rather than the blight, for a mass-death atrocity to be defined as a genocide, it must include the intentional destruction of a people. \nIn 1996, the U.S. state of New Jersey included the famine in the \"Holocaust and Genocide Curriculum\" of its secondary schools. In the 1990s, Irish-American lobbying groups campaigned vigorously to include the study of the Irish Famine in school curriculums, alongside studies of the Holocaust, slavery and other similar atrocities. The New Jersey curriculum was pushed by such lobbying groups and was drafted by the librarian James Mullin. Following criticism, the New Jersey Holocaust Commission requested statements from two academics that the Irish famine was genocide, which was eventually provided by law professors Charles E. Rice and Francis Boyle, who had not been previously known for studying Irish history. They concluded that the British government deliberately pursued a race- and ethnicity-based policy aimed at destroying the Irish people and that the policy of mass starvation amounted to genocide per retrospective application of article 2 of the Hague Convention of 1948.\nHistorian Donald Akenson, who has written 24 books on Ireland, stated that \"When you see [the word \"Holocaust\" used with regard to the Great Famine], you know that you are encountering famine-porn. It is inevitably part of a presentation that is historically unbalanced and, like other kinds of pornography, is distinguished by a covert (and sometimes overt) appeal to misanthropy and almost always an incitement to hatred.\"\nIrish historian Cormac \u00d3 Gr\u00e1da rejected the claim that the British government's response to the famine was a genocide and he also stated that \"no academic historian continues to take the claim of 'genocide' seriously\". He argued that \"genocide includes murderous intent, and it must be said that not even the most bigoted and racist commentators of the day sought the extermination of the Irish\", and he also stated that most people in Whitehall \"hoped for better times for Ireland\". Additionally, he stated that the claim of genocide overlooks \"the enormous challenge facing relief agencies, both central and local, public and private\". \u00d3 Gr\u00e1da thinks that a case of neglect is easier to sustain than a case of genocide.\nJohn Leazer, professor of history at Carthage College, Wisconsin, wrote that the binary framing of the debate about the British government's, and particularly Trevelyan's, actions as being good or bad is \"unsatisfactory\" and that the entire debate surrounding the question of genocide serves to oversimplify and obfuscate complex factors behind the actions of the government as a whole and individuals within it.\nWriting in 2008, historian Robbie Mcveigh highlighted that while discussions around whether the Great Irish Famine was genocidal in nature have a long history, the tools of genocide analysis were never employed to assess such claims. Scholars highlight the similarity of British policies around and in response to the Irish famine and other cases of famine and starvation in the British empire and colonial regimes, with Mcveigh stating in the other cases they \"appear not as horrendous imperial incompetence but rather a deliberate administrative policy of genocide\", and calls for more rigorous investigation of the history of Ireland in genocide studies. There have been later genocide scholars who support the description of the famine as a genocide. Neysa King has characterised specifically the relief efforts of the Russell administration from late 1846 to 1849 as genocide, while acknowledging the roots of the famine lay elsewhere. Nat Hill, director of research at Genocide Watch, has stated that \"While the potato famine may not fit perfectly into the legal and political definitions of 'genocide', it should be given equal consideration in history as an egregious crime against humanity\".\nMemorials.\nIreland's National Famine Memorial is situated in Murrisk Millennium Peace Park, a five-acre park overlooking the Atlantic Ocean in the village of Murrisk, County Mayo at the foot of Croagh Patrick mountain. Designed by Irish artist John Behan, the memorial consists of a bronze sculpture of a coffin ship with skeletons interwoven through the rigging symbolising the many emigrants that did not survive the journey across the ocean to Britain, America and elsewhere. It was unveiled on 20 July 1997 by then-President Mary Robinson. The Famine Commemoration Committee who led the project chose the site in Murrisk as they felt it was \"...entirely fitting that the national famine memorial [..] be located in the west, which suffered most during the Famine with one in four of the population of Connaught dying in those terrible years.\"\nThe National Famine Commemoration Day is observed annually in Ireland, usually on a Sunday in May.\nIt is also memorialized in many locations throughout Ireland, especially in those regions of Ireland which suffered the greatest losses, and it is also memorialized overseas, particularly in cities with large populations which are descended from Irish immigrants, such as New York City. Among the memorials in the US is the Irish Hunger Memorial near a section of the Manhattan waterfront.\n\"Kindred Spirits\", a large stainless steel sculpture of nine eagle feathers by artist Alex Pentek was erected in 2017 in the Irish town of Midleton, County Cork, to thank the Choctaw people for its financial assistance during the famine.\nAn annual Great Famine walk from Doolough to Louisburgh, County Mayo was inaugurated in 1988 and has been led by such notable personalities as Archbishop Desmond Tutu of South Africa and representatives of the Choctaw nation of Oklahoma. The walk, organised by Afri, takes place on the first or second Saturday of May and links the memory of the famine with contemporary human rights issues.\nIn 1994, Sinead O'Connor released \"Famine,\" about historical representations of the Famine and the role of the English government. She performed the song on \"Later ... with Jools Holland\" in 1996.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFootnotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nSources.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "14727", "revid": "50519108", "url": "https://en.wikipedia.org/wiki?curid=14727", "title": "Isle of Man", "text": "Self-governing British Crown dependency in the Irish Sea\nThe Isle of Man ( , also ), or Mann ( ), is a self-governing British Crown Dependency in the Irish Sea, between Great Britain and Ireland. As head of state, Charles III holds the title Lord of Mann and is represented by a Lieutenant Governor. The government of the United Kingdom is responsible for the Isle of Man's military defence and represents it abroad, but the Isle of Man still has a separate international identity.\nHumans have lived on the island since before 6500\u00a0BC. Gaelic cultural influence began in the 5th century AD, when Irish missionaries following the teaching of St Patrick began settling the island, and the Manx language, a branch of the Goidelic languages, emerged. In 627, King Edwin of Northumbria conquered the Isle of Man along with most of Mercia. In the 9th century, Norsemen established the thalassocratic Kingdom of the Isles, which included the Hebrides and the Northern Isles, along with the Isle of Man as the southernmost island. Magnus III, King of Norway from 1093 to 1103, reigned as King of Man and the Isles between 1099 and 1103.\nIn 1266, King Magnus VI of Norway sold his suzerainty over Man to King Alexander III of Scotland under the Treaty of Perth. After a period of alternating rule by the Kings of Scotland and England, the island came under the feudal lordship of the English Crown in 1399. The lordship revested in the British Crown in 1765, but the island did not become part of the 18th-century Kingdom of Great Britain, nor of its successors, the United Kingdom of Great Britain and Ireland and the present-day United Kingdom of Great Britain and Northern Ireland. It has always retained its internal self-government. In 1881, the Isle of Man Parliament, Tynwald, became the first national legislative body in the world to give women the right to vote in a general election, although this excluded married women.\nThe Manx economy is bolstered by its status as a low tax and offshore banking destination. Insurance and online gambling each generate 17% of the GNI, followed by information and communications technology and banking with 9% each. This status has, however, also brought the problems of money laundering, financial crime, and the financing of terrorism. The Isle of Man is also known for the TT (Tourist Trophy) Motorcycle Races, and the Manx cat, a breed with short or no tails. In 2016, UNESCO awarded the Isle of Man biosphere reserve status.\nName.\nThe earliest reference to the Isle of Man occurs in Pliny's \"Natural History\", which mentions an island named \"Monapia\" (likely an error for *\"Manavia\") lying between Britain and Ireland. This has been traced to the Brittonic *\"Manaua\", meaning \"mountain island\" or \"high island\". The same root may appear in \"M\u00f4n\", the Welsh name for Anglesey. The island is known in Welsh as \"Manaw\" and in Manx as \"Mannin\", or in full, \"Ellan Vannin\" (i.e. \"island of Man\", with lenition of the first consonant). \"Mannin\" was originally a dative form, the nominative being \"Mana\".\nMan was associated in legend with Manann\u00e1n mac Lir, the Gaelic god of the sea, and was sometimes said to have taken its name from him. It is more likely, however, that the reverse is true.\nHistory.\nIn the later part of the Mesolithic Period c.8000\u00a0BC, the island was cut off from the surrounding islands as sea levels rose following the end of the last ice age. Humans colonised it by travelling by sea some time before 6500\u00a0BC. The first occupants were hunter-gatherers and fishermen. Examples of their tools are kept at the Manx Museum.\nThe Neolithic Period marked the beginning of farming, and the people began to build megalithic monuments, such as Cashtal yn Ard in Maughold parish, King Orry's Grave in Laxey, Mull Hill near Cregneash and Ballaharra Stones at St John's. There were also the local Ronaldsway and Bann cultures.\nDuring the Bronze Age, the size of burial mounds decreased. The people put bodies into stone-lined graves with ornamental containers. The Bronze Age burial mounds survived as long-lasting markers around the countryside.\nThe ancient Romans knew of the island and called it \".\" During the four centuries when Rome ruled the Province of Britannia, the Roman military controlled the Irish Sea, providing safe passage of agricultural goods from the productive farms of Anglesey to Roman settlements at the English \u2013 Scottish frontier. Only a few Roman artefacts have been found on Man, suggesting a lack of strategic value of Man during the era of Britannia. No Roman lighthouses or signal towers have yet been found on Man.\nAround the 5th century AD, large-scale migration from Ireland precipitated a process of Gaelicisation, evidenced by Ogham inscriptions, and the Manx language developed. It is a Goidelic language closely related to Irish and Scottish Gaelic.\nIn the 7th century, Man came under control of the Anglo-Saxon King Edwin of Northumbria, who then launched raids from Man into Ireland. How much influence the Northumbrians exerted on Man is unknown, but very few place names on Man are of Old English origin.\nVikings arrived at the end of the 8th century. They established Tynwald and introduced many land divisions that still exist. In 1266 King Magnus VI of Norway ceded the islands to Alexander III, King of Scots, in the Treaty of Perth. But Scottish rule over Man did not become firmly established until 1275, when the Manx were defeated in the Battle of Ronaldsway, near Castletown.\nIn 1290 King Edward I of England sent Walter de Huntercombe to take possession of Man. It remained in English hands until 1313, when Robert the Bruce took it after besieging Castle Rushen for five weeks. In 1314, it was retaken for the English by John Bacach of Argyll. In 1317, it was retaken for the Scots by Thomas Randolph, 1st Earl of Moray and Lord of the Isle of Man. It was held by the Scots until 1333. For some years thereafter control passed back and forth between the two kingdoms until the English took it for the final time in 1346. The English Crown delegated its rule of the island to a series of lords and magnates. Tynwald passed laws concerning the government of the island in all respects and had control over its finances, but was subject to the approval of the Lord of Mann.\nIn 1765, the Act of Revestment occurred, whereby the feudal rights of the Dukes of Atholl as Lords of Man were purchased and revested into the British Crown.\nIn 1866, the Isle of Man obtained limited home rule, with partly democratic elections to the House of Keys, but the Legislative Council was appointed by the Crown. Since then, democratic government has been gradually extended. (The vote was extended to women on equal terms with men, and most of the Legislative Council is now elected by the House of Keys.)\nDuring both World Wars, the island was used for the internment of people originating from enemy countries.\nIn recent times, the economy of the island has benefited from regulatory arbitrage in various contexts, such as low taxes. These have attracted wealthy individuals and, together with relatively low government interference, industries such as offshore financial services and more recently gambling.\nThe Isle of Man has designated more than 250 historic sites as registered buildings.\nGeography.\nThe Isle of Man is an island located in the middle of the northern Irish Sea, almost equidistant from England to the east, Northern Ireland to the west and Scotland (closest) to the north, while Wales to the south is almost the distance of the Republic of Ireland to the southwest. It is long and, at its widest point, wide. It has an area of around . Besides the island of Man itself, the political unit of the Isle of Man includes some nearby small islands: the seasonally inhabited Calf of Man, Chicken Rock (on which stands an unstaffed lighthouse), St Patrick's Isle and St Michael's Isle. The last two of these are connected to the main island by permanent roads/causeways.\nRanges of hills in the north and south are separated by a central valley. The northern plain, by contrast, is relatively flat, consisting mainly of deposits from glacial advances from western Scotland during colder times. There are more recently deposited shingle beaches at the northernmost point, the Point of Ayre. The island has one mountain higher than , Snaefell, with a height of . According to an old saying, from the summit one can see six kingdoms: those of Man, Scotland, England, Ireland, Wales and Heaven. Some versions add a seventh kingdom, that of the sea, or Neptune.\nClimate.\nThe Isle of Man has a temperate oceanic climate (K\u00f6ppen \"Cfb\"). Average rainfall is higher than averaged over the territory of the British Isles, because the Isle of Man is far enough from Ireland for the prevailing south-westerly winds to accumulate moisture. Average rainfall is highest at Snaefell, where it is around a year. At lower levels it can be around a year. In drier spots, the Isle of Man is sunnier than either Ireland or the majority of England at 1,651 hours per year at the official Ronaldsway station. The highest recorded temperature was in Ronaldsway on 12 July 1983. Due to the moderate surface temperatures of the Irish Sea, the island does not receive bursts of heat that sometimes can hit Northern England. The stable water temperature also means that air frost is rare, averaging just ten occasions per year.\nGovernance.\nThe United Kingdom is responsible for the island's defence and ultimately for good governance, and for representing the island in international forums, while the island's own parliament and government have competence over all domestic matters.\nPolitical structure.\nThe island's parliament, Tynwald, is claimed to have been in continuous existence since 979 or earlier, purportedly making it the oldest continuously governing body in the world, though evidence supports a much later date. Tynwald is a bicameral or tricameral legislature, comprising the House of Keys (directly elected by universal suffrage with a voting age of 16 years) and the Legislative Council (consisting of indirectly elected and ex-officio members). These two bodies also meet together in joint session as Tynwald Court.\nThe executive branch of government is the Council of Ministers, which is composed of Members of Tynwald (usually Members of the House of Keys, though Members of the Legislative Council may also be appointed as Ministers). It is headed by the Chief Minister.\nVice-regal functions of the head of state are performed by a lieutenant governor.\nExternal relations and security.\nIn various laws of the United Kingdom, \"the United Kingdom\" is defined to exclude the Isle of Man. Historically, the UK has taken care of its external and defence affairs and retains paramount power to legislate for the Island. However, in 2007, the Isle of Man and the UK signed an agreement that established frameworks for the development of the international identity of the Isle of Man. There is no separate Manx citizenship. Citizenship is covered by UK law, and Manx people are classed as British citizens. There is a long history of relations and cultural exchange between the Isle of Man and Ireland. The Isle of Man's historic Manx language and its modern revived variant are closely related to both Scottish Gaelic and the Irish language and, in 1947, \u00c9amon de Valera, the Taoiseach of Ireland, spearheaded efforts to save the dying Manx language.\nDefence.\nThe Isle of Man is not part of the United Kingdom; however, the UK is responsible for its defence and external affairs. There are no independent military forces on the Isle of Man, although HMS \"Ramsey\" was affiliated with the town of the same name. From 1938 to 1955, there existed the Manx Regiment of the British Territorial Army (TA), which saw extensive action during the Second World War. During the English Civil War, the 7th Earl of Derby, who was also the Lord of Mann, conscripted 10 men from each parish (170 in total) to fight for the Royalist cause; the majority were killed at the Battle of Wigan Lane in 1651. In 1779, the Manx Fencible Corps, a fencible regiment of three companies, was raised; it was disbanded in 1783 at the end of the American War of Independence. Later, the Royal Manx Fencibles was raised at the time of the French Revolutionary Wars and Napoleonic Wars. The 1st Battalion (of 3 companies) was raised in 1793. A 2nd Battalion (of 10 companies) was raised in 1795, and it saw action during the Irish Rebellion of 1798. The regiment was disbanded in 1802. A third body of Manx Fencibles was raised in 1803 to defend the island during the Napoleonic Wars and to assist the Revenue. It was disbanded in 1811. The Isle of Man Home Guard was raised during the Second World War for home defence. In 2015 a multi-capability recruiting and training unit of the British Army Reserve was established in Douglas.\nManxman status.\nThere is no citizenship of the Isle of Man as such; Isle of Man residents are entitled to British citizenship and can obtain a full UK British passport or British Isle of Man passport.\nThe Passport Office, Isle of Man, Douglas, accepts and processes applications for the Lieutenant Governor of the Isle of Man, who is formally responsible for issuing Isle of Man\u2013issued British passports, titled \"\"British passport \u2013 Isle of Man\"\". The powers conferred on the UK Secretary of State by the British Nationality Act 1981 extend to and are exercised in the Isle of Man by the Lieutenant Governor.\nIsle of Man-issued British passports can presently be issued to any British citizen resident in the Isle of Man and to British citizens who have a qualifying close personal connection to the Isle of Man but are now resident either in the UK or in either one of the two other Crown Dependencies, the Bailiwick of Jersey or the Bailiwick of Guernsey.\nEuropean Union.\nThe Isle of Man was never part of either the EEC or the European Union (EU), nor did it have a special status, and thus it did not take part in the 2016 (Brexit) referendum on the UK's EU membership. However, it was included within the EU's customs area, as part of Protocol 3 of the UK's Act of Accession to the Treaty of Rome, allowing Manx goods to be traded throughout the EU without tariffs.\nIt was not part of the EU's internal market and there were still limitations on the movement of capital, services and labour.\nEU citizens were entitled to travel and reside, but not work, in the island without restriction.\nIn 2017, the UK confirmed that the Crown Dependencies' positions were included in the Brexit negotiations. The Brexit withdrawal agreement explicitly included the Isle of Man in its territorial scope, but makes no other mention of it.\nCommonwealth of Nations.\nThe Isle of Man is not a member of the Commonwealth of Nations. By virtue of its relationship with the United Kingdom, it takes part in several Commonwealth institutions, including the Commonwealth Parliamentary Association and the Commonwealth Games. The Government of the Isle of Man has made calls for a more integrated relationship with the Commonwealth, including more direct representation and enhanced participation in Commonwealth organisations and meetings, including Commonwealth Heads of Government Meetings. The Chief Minister of the Isle of Man has said: \"A closer connection with the Commonwealth itself would be a welcome further development of the island's international relationships.\"\nPolitics.\nMost Manx politicians stand for election as independents rather than as representatives of political parties. Although political parties do exist, their influence is not as strong as in the United Kingdom.\nThere are three political parties in the Isle of Man:\nThere are also a number of pressure groups on the island. Mec Vannin advocate the establishment of a sovereign republic. The Positive Action Group campaign for three key elements to be introduced into the governance of the island: open accountable government, rigorous control of public finances and a fairer society.\nLocal government.\nLocal government on the Isle of Man is based partly on the island's 17 ancient parishes. There are four types of local authorities:\nEach of these districts has its own body of commissioners.\nLGBT rights.\nThe Isle of Man was the last place in the British Isles to legalise same-sex sexual activity. While it had been legal in England and Wales since 1967, it remained illegal in the Isle of Man until 1992.\nThe Isle of Man's former Chief Minister Howard Quayle issued an \"unqualified apology\" to gay men convicted of same-sex offences under previous Manx laws.\nPublic services.\nEducation.\nPublic education is overseen by the Department of Education, Sport &amp; Culture. Thirty-two primary schools, five secondary schools and the University College Isle of Man function under the department.\nHealth.\nTwo-thirds of residents of Man are overweight or obese, four in ten are physically inactive, one-quarter are binge drinkers, one in twelve smoke cigarettes and about 15% are in poor general health. Healthcare is provided via a public health scheme by the Department of Health and Social Care for residents and visitors from the UK.\nCrime.\nThe Crime Severity Rate in Man, which largely measures crimes directed against persons or property, remains substantially less than that in the United Kingdom, although the rate of violent crime has been increasing in recent years. Most violent crime is associated with the trade in illegal drugs.\nThe Government of Man has laid out a strategy entailing a \"whole-Island approach\" to address the serious problems of money laundering, financial crime and terrorism financing.\nEmergency services.\nThe Isle of Man Government maintains five emergency services. These are:\nAll of these services are controlled directly by the Department of Home Affairs of the Isle of Man Government and are independent of the United Kingdom. Nonetheless, the Isle of Man Constabulary voluntarily submits to inspection by the British inspectorate of police, and the Isle of Man Coastguard contracts His Majesty's Coastguard (UK) for air-sea rescue operations.\nCrematorium.\nThe island's sole crematorium is located in Glencrutchery Road, Douglas, and operated by the Douglas Borough Council. Usually staffed by four, in March 2020 an increase of staff to 12 was announced by the Council leader, responding to the threat of the COVID-19 pandemic, which could require more staff.\nEconomy.\nThe Isle of Man has no capital gains tax, wealth tax, stamp duty, or inheritance tax and a top rate of income tax of 22% (as of April 2024). A tax cap is in force: the maximum amount of tax payable by an individual is \u00a3200,000 or \u00a3400,000 for couples choosing to have their incomes jointly assessed. Personal income is assessed and taxed on a worldwide income basis rather than a remittance basis. This means that all income earned throughout the world is assessable for Manx tax rather than only income earned in or brought into the island. The standard rate of corporation tax for residents and non-residents is 0%. Retail business profits above \u00a3500,000 and banking business income are taxed at 10%, while rental (or other) income from land and buildings situated on the Isle of Man is taxed at 20%.\nMan's low corporate tax burden and absence of public registries of corporate ownership provides tax avoidance and tax evasion strategies for individuals and corporations; this results in a large influx of funds from those in pursuit of tax advantage and financial confidentiality. The relative importance of agriculture, fishing and tourism in the Isle of Man, the former mainstays of the economy, has accordingly declined. As is typical of the low-tax crown dependencies, Man's economy features financial services, shell corporations for high-technology companies, online gambling and online gaming, cinema production and tax havens for high net worth individuals. These activities have brought some high-income jobs to Man, as hundreds of local residents serve as \"straw man\" directors and shareholders of shell companies. Similar schemes provide a means for high net worth individuals to reduce their tax obligations and to shield their financial dealings from public scrutiny. As described in the Paradise Papers, the Isle of Man economy features extensive illegal economic activity including tax evasion, money laundering from drug sales, money transfers from weapons sales, and looting of public treasuries of other nation states (particularly Russia). These funds are mostly funneled into the London financial markets. Online gambling sites provided about 10% of the Manx government's revenue in 2014.\nThere has been an effort to regulate these illicit activities on Man, though the impact of legal measures instituted by the Man government remains uncertain. As of June, 2023, Man remains out of compliance with standards for Anti-Money Laundering &amp; Countering the Financing of Terrorism requirements according to Moneyval, the European Union's Committee of Experts on the Evaluation of Anti-Money Laundering Measures and the Financing of Terrorism.\nThe Isle of Man Department for Enterprise manages the diversified economy in 12 key sectors. The largest sectors by GNP are insurance and online casino operations with 17% of GNP each, followed by ICT and banking with 9% each. The 2016 census lists 41,636 total employed. The largest sectors by employment are \"medical and health\", \"financial and business services\", construction, retail and public administration. Manufacturing, focused on aerospace and the food and drink industry, employs almost 2000 workers and contributes about 5% of gross domestic product (GDP). The sector provides laser optics, industrial diamonds, electronics, plastics and aerospace precision engineering. Tourism, agriculture and fishing, once the mainstays of the economy, now make very little contributions to the island's GDP. The unemployment rate on Man is less than 1%.\nTrade takes place mostly with the United Kingdom. The island is in customs union with the UK, and related revenues are pooled and shared under the Common Purse Agreement. This means that the Isle of Man cannot have the lower excise revenues on alcohol and other goods that are enjoyed in the Channel Islands.\nThe Manx government promotes island locations for making films by offering financial support. Since 1995, over 100 films have been made on the island. Most recently the island has taken a much wider strategy to attract the general digital media industry in film, television, video and esports.\nThe Isle of Man Government Lottery operated from 1986 to 1997. Since 2 December 1999 the island has participated in the United Kingdom National Lottery. The island is the only jurisdiction outside the United Kingdom where it is possible to play the UK National Lottery. Since 2010 it has also been possible for projects in the Isle of Man to receive national lottery Good Causes Funding. The good causes funding is distributed by the Manx Lottery Trust. Tynwald receives the 12% lottery duty for tickets sold in the island.\nTourist numbers peaked in the first half of the 20th century, prior to the boom in cheap travel to Southern Europe that also saw the decline of tourism in many similar English seaside resorts. The Isle of Man tourism board has recently invested in \"Dark Sky Discovery\" sites to diversify its tourism industry. It is expected that dark skies will generally be nominated by the public across the UK. However, the Isle of Man tourism board tasked someone from their team to nominate 27 places on the island as a civil task. This cluster of the highest quality \"Milky Way\" sites is now well promoted within the island. This government push has effectively given the island a headstart in the number of recognised Dark Sky sites. However, this has created a distorted view when compared to the UK where this is not promoted on a national scale. There, Dark Sky sites are expected to be nominated over time by the public across a full range of town, city and countryside locations rather than \"en masse\" by government departments.\nIn 2017 an office of The International Stock Exchange was opened to provide a boost for the island's finance industry.\nCommunications.\nThe main telephone provider on the Isle of Man is Manx Telecom. The island has two mobile operators: Manx Telecom, previously known as Manx Pronto, and Sure. Cloud9 operated as a third mobile operator on the island for a short time but has since withdrawn.\nBroadband internet services are available through four local providers: Wi-Manx, Domicilium, Manx Computer Bureau and Manx Telecom, non-local offerings have begun to offer coverage with recent investment from Starlink which is available island wide. The island does not have its own ITU country code but is accessed via the British country code (+44). Telephone numbers are part of the British telephone numbering plan, with local dialling codes 01624 for landlines and 07524, 07624 and 07924 for mobiles. Calls to the island from the UK, however, are generally charged differently from those within the UK and may or may not be included in any \"inclusive minutes\" packages.\nIn 1996, the Isle of Man Government obtained permission to use the .im national top-level domain (TLD) and has ultimate responsibility for its use. The domain is managed from day to day by Domicilium, an island-based internet service provider. In December 2007, the Manx Electricity Authority and its telecommunications subsidiary, e-llan Communications, commissioned the laying of a new fibre-optic link that connects the island to a worldwide fibre-optic network. In August 2021 it was reported that Elon Musk's satellite internet service, Starlink, had been granted a licence to operate from a ground station on the island.\nThe Isle of Man has three radio stations: Manx Radio, Energy FM and 3FM.\nThere is no insular television service, but local transmitters retransmit British mainland digital broadcasts via the free-to-air digital terrestrial service Freeview. The Isle of Man is served by BBC North West for BBC One and BBC Two television services, and ITV Granada for ITV.\nMany television services are available by satellite, such as Sky and Freesat from the group of satellites at 28.2\u00b0 East, as well as services from a range of other satellites around Europe such as the Astra satellites at 19.2\u00b0 east and Hot Bird.\nThe Isle of Man has three newspapers, all weeklies and owned by Media Isle of Man, formerly Isle of Man Newspapers, a division of the media company The Tindle Group. The \"Isle of Man Courier\" (distribution 36,318) is free and distributed to homes on the island. The other two newspapers are \"Isle of Man Examiner\" (circulation 13,276) and the \"Manx Independent\" (circulation 12,255).\nPostal services are the responsibility of the Isle of Man Post Office, which took over from the UK's General Post Office in 1973. Independent postal services such as DHL, FedEx and Hermes Europe are also present.\nTransport.\nThere is a comprehensive bus network, operated by the government-owned bus operator Bus Vannin.\nThe Isle of Man Sea Terminal in Douglas has regular ferries to and from Heysham and to and from Liverpool, with a more restricted timetable operating in winter. The two vessels are \"Manannan\" and \"Manxman\". The latter, named by the public in mid 2020 and built by Hyundai, arrived in 2023 and soon had largely taken over from the \"Ben My Chree\". There are also limited summer-only services to and from Belfast and Dublin. The Dublin route also operates at Christmas. At the time of the Isle of Man TT a limited number of sailings operate to and from Larne in Northern Ireland. All ferries are operated by the Isle of Man Steam Packet Company.\nThe only commercial airport on the island is the Isle of Man Airport at Ronaldsway. There are direct scheduled and chartered flights to numerous airports in the United Kingdom and Ireland.\nThe island has a total of of public roads, all of which are paved. There is no overriding national speed limit; only local speed limits are set, and some roads have no speed limit. Rules about reckless driving and most other driving regulations are enforced in a similar way to the UK. There is a requirement for regular vehicle examinations for some vehicles (similar to the MOT test in the UK).\nThe island used to have an extensive narrow-gauge railway system, both steam-operated and electric, but the majority of the steam railway tracks were taken out of service many years ago and the track removed. As of 2023[ [update]], there is a steam railway between Douglas and Port Erin, an electric railway between Douglas and Ramsey and an electric mountain railway which climbs Snaefell.\nOne of the oldest operating horse tram services is located on the sea front in the capital, Douglas. It was founded in 1876.\nSpace commerce.\nThe Isle of Man has become a centre for emerging private space travel companies. A number of the competitors in the Google Lunar X Prize, a $30\u00a0million competition for the first privately funded team to send a robot to the Moon, are based on the island. The team summit for the X Prize was held on the island in October 2010. In January 2011 two research space stations owned by Excalibur Almaz arrived on the island and were kept in an aircraft hangar at the airfield at the former RAF Jurby near Jurby.\nElectricity supply.\nThe electricity supply on the Isle of Man is run by the Manx Utilities Authority. The Isle of Man is connected to Great Britain's national grid by a 40\u00a0MW alternating current link (Isle of Man to England Interconnector). There are also hydroelectric, natural gas and diesel generators. The government has also planned a 700 MW offshore wind farm, roughly half the size of Walney Wind Farm.\nGas supply.\nGas for lighting and heating has been supplied to users on the Isle of Man since 1836, firstly as town gas, then as liquefied petroleum gas (LPG); since 2003 natural gas has been available. The future use of hydrogen as a supplementary or substitute fuel is being studied.\nCannabis cultivation.\nIn June 2021, the law prohibiting commercial cultivation of cannabis on the Isle of Man was repealed, and the government of Man, for the first time, offered licences for production and export of cannabis. In February 2022, Man resident and local billionaire John Whittaker, through his firm Peel NRE, proposed to spend US$136 million for the construction of warmhouses for cannabis cultivation and research facilities, and to develop the business. It was announced that zoning permits had been granted for development of the facility. Although the availability of medical cannabis is heavily restricted within the UK, there has been an effort to develop the cannabis industry on the Channel Islands of Jersey and Guernsey.\nCulture.\nThe Manx are a Celtic nation.\nThe culture of the Isle of Man is often promoted as being influenced by its Celtic and, to a lesser extent, its Norse origins. Proximity to the UK, popularity as a UK tourist destination in Victorian times and immigration from Britain have all meant that the cultures of Great Britain have been influential at least since Revestment. Revival campaigns have attempted to preserve the surviving vestiges of Manx culture after a long period of Anglicisation, and there has been significantly increased interest in the Manx language, history and musical tradition.\nLanguage.\nThe official languages of the Isle of Man are English and Manx. Manx has traditionally been spoken but has been stated to be \"critically endangered\". However, it now has a growing number of young speakers. It is increasingly evident on the island: for instance, in public notices and its increasing use in the Tynwald ceremony.\nManx is a Goidelic Celtic language and is one of a number of insular Celtic languages spoken in the British Isles. Manx has been officially recognised as a legitimate autochthonous regional language under the European Charter for Regional or Minority Languages, ratified by the United Kingdom on 27 March 2001 on behalf of the Isle of Man government.\nManx is closely related to Irish and Scottish Gaelic but is orthographically sui generis.\nOn the island, the Manx greetings ' (good morning) and ' (good afternoon) can often be heard. As in Irish and Scottish Gaelic, the concepts of \"evening\" and \"afternoon\" are referred to with one word. Two other Manx expressions often heard are \"Gura mie eu\" (\"Thank you\"; familiar 2nd person singular form \"Gura mie ayd\") and \"\", meaning \"time enough\", which represents a stereotypical view of the Manx attitude to life.\nIn the 2011 Isle of Man census, approximately 1,800 residents stated that they could read, write and speak the Manx language.\nSymbols.\nFor centuries, the island's symbol has been the so-called \"three legs of Man\" (), a triskelion of three legs conjoined at the thigh. The Manx triskelion, which dates back with certainty to the late 13th century, is of uncertain origin. It has been suggested that its origin lies in Sicily, an island which has been associated with the triskelion since ancient times. The two islands' symbols could be related via the Norman rulers of Sicily: the Hauteville family.\nThe symbol appears in the island's official flag and official coat of arms, as well as its currency. The Manx triskelion may be reflected in the island's motto, \"Quocunque jeceris stabit\", which appears as part of the island's coat of arms. The Latin motto translates as \"whichever way you throw, it will stand\" or \"whithersoever you throw it, it will stand\". It dates to the late 17th century when it is known to have appeared on the island's coinage. It may be understood to refer to the caltrop, a military device with one spike always pointing upwards. The motto itself originally featured on the family badge of the Byzantine/Roman General Flavius Belisarius (505 \u2013 565 AD) along with a representation of a caltrop. It has also been suggested that the motto originally referred to the poor quality of coinage which was common at the time\u2014as in \"however it is tested it will pass\".\nThe ragwort or \"cushag\" has been referred to as the Manx national flower.\nReligion.\nThe predominant religious tradition of the Isle of Man is Christianity, adhered to by 54.7% of the Manx according to the 2021 census. At the same time, 43.8% of the population had no religion, 0.5% adhered to Islam, 0.5% to Buddhism, 0.4% to Hinduism, 0.2% to Judaism and 0.2% to other religions.\nBefore the Protestant Reformation, the island had a long history as part of the unified Catholic Church. In the years following the Reformation, the religious authorities on the island, and later the population of the island, accepted the religious authority of the British monarchy, Anglicanism and the Church of England. The Isle of Man also came under the influence of Irish religious tradition. The island forms a separate diocese called Sodor and Man, which in the distant past comprised the medieval kingdom of Man and the Scottish isles (\"Su\u00f0reyjar\" in Old Norse). Nowadays, it consists of sixteen parishes, and since 1541 has been part of the Province of York.\nOther Christian denominations and other religions also operate on the Isle of Man. The second largest denomination is the Methodist Church, whose Isle of Man District is close in numbers to the Anglican diocese. Then, there are eight Catholic parish churches, included in the Catholic Archdiocese of Liverpool, as well as a presence of Eastern Orthodox Christians. Additionally, there are five Baptist churches, four Pentecostal churches, the Salvation Army, a ward of the Church of Jesus Christ of Latter-day Saints, two congregations of Jehovah's Witnesses, two United Reformed churches, as well as other Christian churches.\nThe Manx Muslim community has a mosque in Douglas, while Jews also have a history on the island. In 2022, the island's first Buddhist temple was established in Baldrine.\nMyth, legend and folklore.\nIn Manx mythology, the island was ruled by the sea god Manann\u00e1n, who would draw his misty cloak around the island to protect it from invaders. One of the principal folk theories about the origin of the name \"Man\" is that it is named after Manann\u00e1n.\nIn the Manx tradition of folklore, there are many stories of mythical creatures and characters. These include the , a malevolent spirit which according to legend, blew the roof off St Trinian's Church in a fit of rage; the ; the ; and the , a ghostly black dog which wandered the walls and corridors of Peel Castle.\nThe Isle of Man is also said to be home to fairies, known locally as \"the little folk\" or \"themselves\". There is a famous Fairy Bridge, and it is said to be bad luck if one fails to wish the fairies good morning or afternoon when passing over it. It used to be a tradition to leave a coin on the bridge to ensure good luck. Other types of fairies include the .\nAn old Irish story tells how Lough Neagh was formed when Ireland's legendary giant Fionn mac Cumhaill (commonly anglicised to Finn McCool) ripped up a portion of the land and tossed it at a Scottish rival. He missed and the chunk of earth landed in the Irish Sea, thus creating the island.\nPeel Castle has been proposed as a possible location of the Arthurian Avalon or as the location of the Grail Castle, site of Lancelot's encounter with the sword bridge of King Maleagant.\nOne of the most oft-repeated myths is that people found guilty of witchcraft were rolled down Slieau Whallian, a hill near St John's, in a barrel. However, this is a 19th-century legend derived from a Scottish legend, which in turn comes from a German legend. Separately, a witchcraft museum was opened at the Witches Mill, Castletown in 1951, despite there never being a witches' coven on that site; the myth was only created with the opening of the museum. However, there has been a strong tradition of herbalism and the use of charms to prevent and cure illness and disease in people and animals.\nMusic.\nThe music of the Isle of Man reflects Celtic, Norse and other influences, including from its neighbours, Scotland, Ireland, England and Wales. A wide range of music is performed on the island, such as rock, blues, jazz and pop.\nIts traditional folk music has undergone a revival since the 1970s, starting with a music festival called in Ramsey. This was part of a general revival of the Manx language and culture after the death of the last native speaker of Manx in 1974.\nOrchestral and song composer Haydn Wood grew up on the Isle of Man, moving there in 1885, aged three years old. The island and its folk tunes inspired Wood's music, resulting in the compositions \"Manx Rhapsody (Mylecharaine), Manx Countryside Sketches, Manx Overture,\" and the 1933 tone poem \"\" (Manx for \"Dear Isle of Man\"), based on four Manx folk tunes and scored for wind band. His older brother Harry Wood (1868\u20131939) was also a musician: a violinist, composer and conductor who became known as \"Manxland's King of Music\".\nThe Isle of Man is mentioned in the Who song \"Happy Jack\" as the homeland of the song's titular character, who is always in a state of ecstasy, no matter what happens to him. The song \"The Craic was 90 in the Isle of Man\" by Christy Moore describes a lively visit during the Island's tourism heyday. The Island is also the birthplace of Maurice, Robin and Barry Gibb, of the Bee Gees; a bronze statue of the trio was unveiled on Douglas promenade in July 2021.\nFood.\nIn the past, the basic national dish of the island was \"spuds and herrin\", boiled potatoes and herring. This plain dish was supported by the subsistence farmers of the island, who for centuries crofted the land and fished the sea. Chips, cheese and gravy, a dish similar to poutine, is found in most of the island's fast-food outlets. It consists of thick-cut chips, covered in shredded Cheddar cheese and topped with a thick gravy. However, as of the Isle of Man Food &amp; Drink Festival 2018, queen scallops (\"queenies\") have been crowned the Manx national dish with many restaurants, hotels and pubs serving local wild queen scallops.\nSeafood has traditionally accounted for a large proportion of the local diet. Although commercial fishing has declined in recent years, local delicacies include Manx kippers (smoked herrings) which are produced by the smokeries in Peel on the west coast of the island, albeit mainly from North Sea herring these days. The smokeries also produce other specialities including smoked salmon and bacon.\nCrab, lobster and scallops are commercially fished; further, the queen scallop is regarded as a particular delicacy, with a light, sweet flavour. Cod, ling and mackerel are often angled for the table, and freshwater trout and salmon can be taken from the local rivers and lakes, supported by the government fish hatchery at Cornaa on the east coast.\nCattle, sheep, pigs and poultry are all commercially farmed; Manx lamb from the hill farms is a popular dish. The Loaghtan, the indigenous breed of Manx sheep, has a rich, dark meat that has found favour with chefs, featuring in dishes on the BBC's \"MasterChef\" series.\nManx cheese has also found some success, featuring smoked and herb-flavoured varieties, and is stocked by many of the UK's supermarket chains. Manx cheese took bronze medals in the 2005 British Cheese Awards and sold 578 tonnes over the year. Manx cheddar has been exported to Canada where it is available in some supermarkets.\nBeer is brewed on a commercial scale by Okells Brewery, which was established in 1850 and is the island's largest brewer. Other breweries include Bushy's Brewery, Hooded Ram, Odin, Radical Brewing, Noa Brewhouse and Kaneens Brewery. The Isle of Man's Pure Beer Act of 1874, which resembles the German , is still in effect: under this Act, brewers may only use water, malt, sugar and hops in their brews.\nSport.\nThe Isle of Man is represented as a nation in the Commonwealth Games and the Island Games and hosted the IV Commonwealth Youth Games in 2011. Manx athletes have won three gold medals at the Commonwealth Games, including the one by cyclist Mark Cavendish in 2006 in the Scratch race. The Island Games were first held on the island in 1985 and again in 2001. FC Isle of Man was founded in 2019 and is a North West Counties League team.\nIsle of Man teams and individuals participate in many sports both on and off the island including rugby union, football, gymnastics, field hockey, netball, taekwondo, bowling, obstacle course racing and cricket. The FC Isle of Man compete in the North West Counties Football League Premier Division. It being an island, many types of watersports are also popular with residents.\nMotorcycle racing.\nThe main international event associated with the island is the Isle of Man Tourist Trophy race, colloquially known as \"The TT\", which began in 1907. It takes place in late May and early June. The TT is now an international road racing event for motorcycles, which used to be part of the World Championship, and is long considered to be one of the \"greatest motorcycle sporting events of the world\". Taking place over a two-week period, it has become a festival for motorcycling culture, makes a huge contribution to the island's economy and has become part of Manx identity. For many, the Isle carries the title \"road racing capital of the world\".\nThe Manx Grand Prix is a separate motorcycle event for amateurs and private entrants that uses the same Snaefell Mountain Course in late August and early September.\nCammag.\nPrior to the introduction of football in the 19th century, cammag was the island's traditional sport. It is similar to the Irish hurling and the Scottish game of shinty. Nowadays there is an annual match at St John's.\nTheatre and cinema.\nBuilt in 1899, to the designs of architect Frank Matcham, and restored in 1976 to its original splendor, the government-owned Gaiety Theatre and Opera House on the Douglas Promenade presents plays, musicals, concerts and comedy shows year-round. Within the Gaiety Theatre Complex, the Broadway Cinema has a capacity of 154 and doubles as a conference venue.\nThe Palace Cinema is located next to the derelict Castle Mona hotel and is operated by the Sefton Group. It has two screens: Screen One holds 293 customers, while Screen Two is smaller with a capacity of just 95. It was extensively refurbished in August 2011.\nFauna.\nTwo domestic animals are specifically connected to the Isle of Man, though they are also found elsewhere.\nThe Manx cat is a breed of cat noted for its genetic mutation resulting in a shortened tail. The length of this tail can range from a few inches, known as a \"stumpy\", to being completely nonexistent, or \"rumpy\". Manx cats display a range of colours and usually have somewhat longer hind legs compared to most cats. The cats have been used as a symbol of the Isle of Man on coins and stamps; and at one time the Manx government operated a breeding centre to ensure the continuation of the breed.\nThe Manx Loaghtan sheep is a breed native to the island. It has dark brown wool and four, or sometimes six, horns. The meat is considered to be a delicacy. There are several flocks on the island and others have been started in England and Jersey.\nA more recent arrival on the island is the red-necked wallaby, which is now established on the island following an escape from the Wildlife Park. The local police report an increasing number of wallaby-related calls.\nThere are also many feral goats in Garff, a matter which was raised in Tynwald Court in January 2018.\nIn March 2016, the Isle of Man became the first entire territory to be adopted into UNESCO's Network of Biosphere Reserves.\nDemographics.\nPopulation.\nAt the 2021 census, the Isle of Man was home to 84,069 people, of whom 26,677 resided in the island's capital, Douglas. The population increased by 755 people between the 2016 and 2021 censuses.\nCensus.\nThe Isle of Man Full Census, last held in 2021, has been a decennial occurrence since 1821, with interim censuses being introduced from 1966. It is separate from, but similar to, the Census in the United Kingdom.\n0\u201314 years: 16.27% (male 7,587, female 6,960)\n15\u201324 years: 11.3% (male 5,354, female 4,750)\n25\u201354 years: 38.48% (male 17,191, female 17,217)\n55\u201364 years: 13.34% (male 6,012, female 5,919)\n65 years and over: 20.6% (male 8,661, female 9,756) (2018 est.)\n131 people/km2 (339 people/sq\u00a0mi) (2005 est.)\nTotal: 4 deaths/1,000 live births\nMale: 4 deaths/1,000 live births\nFemale: 4 deaths/1,000 live births (2018 est.)\nCountry comparison to the world: 191\n Total population: 81.4 years\n Male: 78.1 years\n Female: 83.6 years (2021 est.)\n Country comparison to the world: 29\n \"Total fertility rate\": 1.92 children born/woman (2018 est.)\n \"noun:\" Manxman (men), Manxwoman (women)\n \"adjective:\" Manx\n White: 94.7%\n Asian: 3.1%\n Black: 0.6%\n Other: 0.6%\n Mixed: 1.0%\n Christianity: 54.7%\n No religion: 43.8%\n Buddhism: 0.5%\n Islam: 0.5%\n Hinduism: 0.4%\n Judaism: 0.2%\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nBibliography.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "14728", "revid": "152211", "url": "https://en.wikipedia.org/wiki?curid=14728", "title": "Iberian alphabet", "text": ""}
{"id": "14729", "revid": "40071619", "url": "https://en.wikipedia.org/wiki?curid=14729", "title": "Italic languages", "text": "Branch of the Indo-European language family\nThe Italic languages form a branch of the Indo-European language family, whose earliest known members were spoken on the Italian Peninsula in the first millennium BC. The most important of the ancient Italic languages was Latin, the official language of ancient Rome, which conquered the other Italic peoples before the common era. The other Italic languages became extinct in the first centuries AD as their speakers were assimilated into the Roman Empire and shifted to some form of Latin. Between the third and eighth centuries AD, Vulgar Latin (perhaps influenced by substrata from the other Italic languages) diversified into the Romance languages, which are the only Italic languages natively spoken today, while Literary Latin also survived.\nBesides Latin, the known ancient Italic languages are Faliscan (the closest to Latin), Umbrian and Oscan (or Osco-Umbrian), and South Picene. Other Indo-European languages once spoken in the peninsula whose inclusion in the Italic branch is disputed are Venetic and Siculian. These long-extinct languages are known only from inscriptions in archaeological finds.\nIn the first millennium BC, several (other) non-Italic languages were spoken in the peninsula, including members of other branches of Indo-European (such as Celtic and Greek) as well as at least one non-Indo-European one, Etruscan.\nIt is generally believed that those 1st millennium Italic languages descend from Indo-European languages brought by migrants to the peninsula sometime in the 2nd millennium BC through Bell Beaker and Urnfield culture groups north and east of the Alps. However, the source of those migrations and the history of the languages in the peninsula are still a matter of debate among historians. In particular, it is debated whether the ancient Italic languages all descended from a single Proto-Italic language after its arrival in the region, or whether the migrants brought two or more Indo-European languages that were only distantly related.\nWith over 900 million native speakers, the Romance languages make Italic the second-most-widely spoken branch of the Indo-European family, after Indo-Iranian at 1.7 billion native speakers. However, in academia the ancient Italic languages form a separate field of study from the medieval and modern Romance languages. This article focuses on the ancient languages. For information on the academic study of the Romance languages, see Romance studies.\nMost Italic languages (including Romance) are generally written in Old Italic scripts (or the descendant Latin alphabet and its adaptations), which descend from the alphabet used to write the non-Italic Etruscan language, which was derived from the Greek alphabet. The notable exceptions are Judaeo-Spanish (also known as Ladino), which is sometimes written in the Hebrew, Greek, or Cyrillic script, and some forms of Romanian, which are written in the Cyrillic script.\nHistory of the concept.\nHistorical linguists have generally concluded that the ancient Indo-European languages of the Italian peninsula that were not identifiable as belonging to other branches of Indo-European, such as Greek, belonged to a single branch of the family, parallel for example to Celtic and Germanic. The founder of this theory is Antoine Meillet (1866\u20131936).\nThis unitary theory has been criticized by, among others, Alois Walde, Vittore Pisani and Giacomo Devoto, who proposed that the Latino-Faliscan and Osco-Umbrian languages constituted two distinct branches of Indo-European. This view gained acceptance in the second half of the 20th century, though proponents such as Rix later rejected the idea, and the unitary theory remains dominant in contemporary scholarship.\nClassification.\nThe following classification, proposed by Michiel de Vaan (2008), is generally agreed on, although some scholars have recently disputed the inclusion of Venetic in the Italic branch.\n&lt;templatestyles src=\"Tree list/styles.css\" /&gt;\nHistory.\nProto-Italic period.\nProto-Italic was probably originally spoken by Italic tribes north of the Alps. In particular, early contacts with Celtic and Germanic speakers are suggested by linguistic evidence.\nBakkum defines Proto-Italic as a \"chronological stage\" without an independent development of its own, but extending over late Proto-Indo-European and the initial stages of Proto-Latin and Proto-Sabellic. Meiser's dates of 4000 BC to 1800 BC, well before Mycenaean Greek, are described by him as being \"as good a guess as anyone's\". Schrijver argues for a Proto-Italo-Celtic stage, which he suggests was spoken in \"approximately the first half or the middle of the 2nd millennium BC\", from which Celtic split off first, then Venetic, before the remainder, Italic, split into Latino-Faliscan and Sabellian.\nItalic peoples probably moved towards the Italian Peninsula during the second half of the 2nd millennium BC, gradually reaching the southern regions. Although an equation between archeological and linguistic evidence cannot be established with certainty, the Proto-Italic language is generally associated with the Terramare (1700\u20131150 BC) and Proto-Villanovan culture (1200\u2013900 BC).\nLanguages of Italy in the Iron Age.\nAt the start of the Iron Age, around 700 BC, Ionian Greek settlers from Euboea established colonies along the coast of southern Italy. They brought with them the alphabet, which they had learned from the Phoenicians; specifically, what we now call Western Greek alphabet. The invention quickly spread through the whole peninsula, across language and political barriers. Local adaptations (mainly minor letter shape changes and the dropping or addition of a few letters) yielded several Old Italic alphabets.\nThe inscriptions show that, by 700 BC, many languages were spoken in the region, including members of several branches of Indo-European and several non-Indo-European languages. The most important of the latter was Etruscan, attested by evidence from more than 10,000 inscriptions and some short texts. No relation has been found between Etruscan and any other known language, and there is still no clue about its possible origin (except for inscriptions on the island of Lemnos in the eastern Mediterranean). Other possibly non-Indo-European languages present at the time were Rhaetian in the Alpine region, Ligurian around present-day Genoa, and some unidentified languages in Sardinia. Those languages have left some detectable imprint in Latin.\nThe largest language in southern Italy, except Ionic Greek spoken in the Greek colonies, was Messapian, known from some 260 inscriptions dating from the 6th and 5th centuries BC. There is a historical connection of Messapian with the Illyrian tribes, added to the archaeological connection in ceramics and metals existing between both peoples, which motivated the hypothesis of linguistic connection. But the evidence of Illyrian inscriptions is reduced to personal names and places, which makes it difficult to support such a hypothesis.\nIt has also been proposed by some scholars, although not confirmed, that the Lusitanian language may have belonged to the Italic family.\nTimeline of Latin.\nIn the history of Latin of ancient times, there are several periods:\nAs the Roman Republic extended its political dominion over the whole of the Italian peninsula, Latin became dominant over the other Italic languages, which ceased to be spoken perhaps sometime in the 1st century AD. From Vulgar Latin, the Romance languages emerged.\nThe Latin language gradually spread beyond Rome, along with the growth of the power of this state, displacing, beginning in the 4th and 3rd centuries BC, the languages of other Italic tribes, as well as Illyrian, Messapian and Venetic, etc. The Romanisation of the Italian Peninsula was basically complete by the 1st century BC; except for the south of Italy and Sicily, where the dominance of Greek was preserved.\nThe attribution of Ligurian is controversial.\nOrigin theories.\nThe main debate concerning the origin of the Italic languages mirrors that on the origins of the Greek ones, except that there is no record of any \"early Italic\" to play the role of Mycenaean Greek.\nAll that is known about the linguistic landscape of Italy is from inscriptions made after the introduction of the alphabet in the peninsula, around 700 BC onwards, and from Greek and Roman writers several centuries later. The oldest known samples come from Umbrian and Faliscan inscriptions from the 7th century BC. Their alphabets were clearly derived from the Etruscan alphabet, which was derived from the Western Greek alphabet not much earlier than that. There is no reliable information about the languages spoken before that time. Some conjectures can be made based on toponyms, but they cannot be verified.\nThere is no guarantee that the intermediate phases between those old Italic languages and Indo-European will be found. The question of whether Italic originated outside Italy or developed by assimilation of Indo-European and other elements within Italy, approximately on or within its current range there, remains.\nAn extreme view of some linguists and historians is that there never was a unique \"Proto-Italic\" whose diversification resulted in an \"Italic branch\" of Indo-European.\nSome linguists, like Silvestri and Rix, further argue that no common Proto-Italic can be reconstructed such that its phonological system may have developed into those of Latin and Osco-Umbrian through consistent phonetic changes and that its phonology and morphology can be consistently derived from those of Proto-Indo-European. However, Rix later changed his mind and became an outspoken supporter of Italic as a family.\nThose linguists propose instead that the ancestors of the 1st millennium Indo-European languages of Italy were two or more different languages that separately descended from Indo-European in a more remote past and separately entered Europe, possibly by different routes or at different times. That view stems in part from the difficulty in identifying a common Italic homeland in prehistory, or reconstructing an ancestral \"Common Italic\" or \"Proto-Italic\" language from which those languages could have descended. Some common features that seem to connect the languages may be just a sprachbund phenomenon \u2013 a linguistic convergence due to contact over a long period, as in the most widely accepted version of the Italo-Celtic hypothesis.\nCharacteristics.\nGeneral and specific characteristics of the pre-Roman Italic languages:\nPhonology.\nThe most distinctive feature of the Italic languages is the development of the PIE voiced aspirated stops. In initial position, *b\u02b0-, *d\u02b0- and *g\u02b7\u02b0- merged to /f-/, while *g\u02b0- became /h-/, although Latin also has *g\u02b0- &gt; /w-/ and /g-/ in special environments.\nIn medial position, all voiced aspirated stops have a distinct reflex in Latin, with different outcome for -*g\u02b0- and *g\u02b7\u02b0- if preceded by a nasal. In Osco-Umbrian, they generally have the same reflexes as in initial position, although Umbrian shows a special development if preceded by a nasal, just as in Latin. Most probably, the voiced aspirated stops went through an intermediate stage *-\u03b2-, *-\u00f0-, *-\u0263- and *-\u0263\u02b7- in Proto-Italic.\nThe voiceless and plain voiced stops (*p, *t, *k, *k\u02b7; *b, *d, *g, *g\u02b7) remained unchanged in Latin, except for the minor shift of *g\u02b7 &gt; /w/. In Osco-Umbrian, the labiovelars *k\u02b7 and *g\u02b7 became the labial stops /p/ and /b/, e.g. Oscan \"pis\" 'who?' (cf. Latin \"quis\") and \"bivus\" 'alive (nom.pl.)' (cf. Latin \"vivus\").\nGrammar.\nIn grammar there are basically three innovations shared by the Osco-Umbrian and the Latino-Faliscan languages:\nIn turn, these shared innovations are one of the main arguments in favour of an Italic group, questioned by other authors.\nLexical comparison.\nAmong the Indo-European languages, the Italic languages share a higher percentage of lexicon with the Celtic and the Germanic ones, three of the four traditional \"centum\" branches of Indo-European (together with Greek).\nThe following table shows a lexical comparison of several Italic languages:\nThe asterisk indicates reconstructed forms based on indirect linguistic evidence and not forms directly attested in any inscription.\nFrom the point of view of Proto-Indo-European, the Italic languages are fairly conservative. In phonology, the Italic languages are centum languages by merging the palatals with the velars (Latin \"centum\" has a /k/) but keeping the combined group separate from the labio-velars. In morphology, the Italic languages preserve six cases in the noun and the adjective (nominative, accusative, genitive, dative, ablative, vocative) with traces of a seventh (locative), but the dual of both the noun and the verb has completely disappeared. From the position of both morphological innovations and uniquely shared lexical items, Italic shows the greatest similarities with Celtic and Germanic, with some of the shared lexical correspondences also being found in Baltic and Slavic.\nP-Italic and Q-Italic languages.\nSimilar to Celtic languages, the Italic languages are also divided into P- and Q-branches, depending on the reflex of Proto-Indo-European *\"k\u02b7\". In the languages of the Osco-Umbrian branch, *\"k\u02b7\" gave \"p\", whereas the languages of the Latino-Faliscan branch preserved it (Latin \"qu\" ).\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nSources.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "14730", "revid": "6046731", "url": "https://en.wikipedia.org/wiki?curid=14730", "title": "IRC", "text": "Protocol for real-time Internet chat and messaging\nIRC (Internet Relay Chat) is a text-based chat system for instant messaging. IRC is designed for group communication in discussion forums, called \"channels\", but also allows one-on-one communication via private messages as well as chat and data transfer, including file sharing.\nInternet Relay Chat is implemented as an application layer protocol to facilitate communication in the form of text. The chat process works on a client\u2013server networking model. Users connect, using a client\u2014which may be a web app, a standalone desktop program, or embedded into part of a larger program\u2014to an IRC server, which may be part of a larger IRC network. Examples of ways used to connect include the programs Mibbit, KiwiIRC, mIRC and the paid service IRCCloud.\nIRC usage has been declining steadily since 2003, losing 60 percent of its users by 2012. In April 2011, the top 100 IRC networks served more than 200,000 users at a time.\nHistory.\nIRC was created by Jarkko Oikarinen in August 1988 to replace a program called MUT (MultiUser Talk) on a BBS called OuluBox at the University of Oulu in Finland, where he was working at the Department of Computer Science. Jarkko intended to extend the BBS software he administered, to allow news in the Usenet style, real time discussions and similar BBS features. The first part he implemented was the chat part, which he did with borrowed parts written by his friends Jyrki Kuoppala and Jukka Pihl. The first IRC network was running on a single server named tolsun.oulu.fi. Oikarinen found inspiration in a chat system known as Bitnet Relay, which operated on the BITNET.\nJyrki Kuoppala pushed Oikarinen to ask Oulu University to free the IRC code so that it also could be run outside of Oulu, and after they finally got it released, Jyrki Kuoppala immediately installed another server. This was the first \"IRC network\". Oikarinen got some friends at the Helsinki University of Technology and Tampere University of Technology to start running IRC servers when his number of users increased and other universities soon followed. At this time Oikarinen realized that the rest of the BBS features probably would not fit in his program.\nOikarinen contacted people at the University of Denver and Oregon State University. They had their own IRC network running and wanted to connect to the Finnish network. They had obtained the program from one of Oikarinen's friends, Vijay Subramaniam\u2014the first non-Finnish person to use IRC. IRC then grew larger and got used on the entire Finnish national network\u2014FUNET\u2014and then connected to Nordunet, the Scandinavian branch of the Internet. In November 1988, IRC had spread across the Internet and in the middle of 1989, there were some 40 servers worldwide.\nEFnet.\nIn August 1990, the first major disagreement took place in the IRC world. The \"A-net\" (Anarchy net) included a server named eris.berkeley.edu. It was all open, required no passwords and had no limit on the number of connects. As Greg \"wumpus\" Lindahl explains: \"it had a wildcard server line, so people were hooking up servers and nick-colliding everyone\". The \"Eris Free Network\", EFnet, made the eris machine the first to be Q-lined (Q for quarantine) from IRC. In wumpus' words again: \"Eris refused to remove that line, so I formed EFnet. It wasn't much of a fight; I got all the hubs to join, and almost everyone else got carried along.\" A-net was formed with the eris servers, while EFnet was formed with the non-eris servers. History showed most servers and users went with EFnet. Once A-net disbanded, the name EFnet became meaningless, and once again it was the one and only IRC network.\nAround that time IRC was used to report on the 1991 Soviet coup d'\u00e9tat attempt throughout a media blackout. It was previously used in a similar fashion during the Gulf War. Chat logs of these and other events are kept in the ibiblio archive.\nUndernet fork.\nAnother fork effort, the first that made a lasting difference, was initiated by \"Wildthang\" in the United States in October 1992. (It forked off the EFnet ircd version 2.8.10). It was meant to be just a test network to develop bots on but it quickly grew to a network \"for friends and their friends\". In Europe and Canada a separate new network was being worked on and in December the French servers connected to the Canadian ones, and by the end of the month, the French and Canadian network was connected to the US one, forming the network that later came to be called \"The Undernet\".\nThe \"undernetters\" wanted to take ircd further in an attempt to make it use less bandwidth and to try to sort out the channel chaos (netsplits and takeovers) that EFnet started to suffer from. For the latter purpose, the Undernet implemented timestamps, new routing and offered the CService\u2014a program that allowed users to register channels and then attempted to protect them from troublemakers. The first server list presented, from 15 February 1993, includes servers from the U.S., Canada, France, Croatia and Japan. On 15 August, the new user count record was set to 57 users.\nIn May 1993, RFC 1459 was published and details a simple protocol for client/server operation, channels, one-to-one and one-to-many conversations. A significant number of extensions like CTCP, colors and formats are not included in the protocol specifications, nor is character encoding, which led various implementations of servers and clients to diverge. Software implementation varied significantly from one network to the other, each network implementing their own policies and standards in their own code bases.\nDALnet fork.\nDuring the summer of 1994, the Undernet was itself forked. The new network was called DALnet (named after its founder: dalvenjah), formed for better user service and more user and channel protections. One of the more significant changes in DALnet was use of longer nicknames (the original ircd limit being 9 letters). DALnet ircd modifications were made by Alexei \"Lefler\" Kosut. DALnet was thus based on the Undernet ircd server, although the DALnet pioneers were EFnet abandoners. According to James Ng, the initial DALnet people were \"ops in #StarTrek sick from the constant splits/lags/takeovers/etc\".\nDALnet quickly offered global WallOps (IRCop messages that can be seen by users who are +w (/mode NickName +w)), longer nicknames, Q:Lined nicknames (nicknames that cannot be used i.e. ChanServ, IRCop, NickServ, etc.), global K:Lines (ban of one person or an entire domain from a server or the entire network), IRCop only communications: GlobOps, +H mode showing that an IRCop is a \"helpop\" etc. Much of DALnet's new functions were written in early 1995 by Brian \"Morpher\" Smith and allow users to own nicknames, control channels, send memos, and more.\nIRCnet fork.\nIn July 1996, after months of flame wars and discussions on the mailing list, there was yet another split due to disagreement in how the development of the ircd should evolve. Most notably, the \"European\" (most of those servers were in Europe) side that later named itself IRCnet argued for nick and channel delays whereas the EFnet side argued for timestamps. There were also disagreements about policies: the European side had started to establish a set of rules directing what IRCops could and could not do, a point of view opposed by the US side.\nMost (not all) of the IRCnet servers were in Europe, while most of the EFnet servers were in the US. This event is also known as \"The Great Split\" in many IRC societies. EFnet has since (as of August 1998) grown and passed the number of users it had then. In the (northern) autumn of the year 2000, EFnet had some 50,000 users and IRCnet 70,000.\nModern IRC.\nIRC has changed much over its life on the Internet. New server software has added a multitude of new features.\nAs of 2016[ [update]], a new standardization effort is under way under a working group called IRCv3, which focuses on more advanced client features such as instant notifications, better history support and improved security. As of 2019[ [update]], no major IRC networks have fully adopted the proposed standard.\nAs of \u00a02021,[ [update]] there are 481 different IRC networks known to be operating, of which the open source Libera Chat, founded in May 2021, has the most users, with 20,374 channels on 26 servers; between them, the top 100 IRC networks share over 100 thousand channels operating on about one thousand servers.\nAfter its golden era during the 1990s and early 2000s (240,000 users on QuakeNet in 2004), IRC has seen a significant decline, losing around 60% of users between 2003 and 2012, with users moving to social media platforms such as Facebook or Twitter, but also to open platforms such as XMPP which was developed in 1999. Certain networks such as Freenode have not followed the overall trend and have more than quadrupled in size during the same period. However, Freenode, which in 2016 had around 90,000 users, has since declined to about 9,300 users.\nThe largest IRC networks have traditionally been grouped as the \"Big Four\"\u2014a designation for networks that top the statistics. The Big Four networks change periodically, but due to the community nature of IRC there are a large number of other networks for users to choose from.\nHistorically the \"Big Four\" were:\nIRC reached 6 million simultaneous users in 2001 and 10 million users in 2004\u20132005, dropping to around 350k in 2021.\nThe top 100 IRC networks have around 230k users connected at peak hours.\nTimeline.\nTimeline of major networks:\nTechnical information.\nIRC is an open protocol that uses TCP and, optionally, TLS. An IRC server can connect to other IRC servers to expand the IRC network. Users access IRC networks by connecting a client to a server. There are many client implementations, such as mIRC, HexChat and irssi, and server implementations, e.g. the original IRCd. Most IRC servers do not require users to register an account but a nickname is required before being connected.\nIRC was originally a plain text protocol (although later extended), which on request was assigned port 194/TCP by IANA. However, the \"de facto\" standard has always been to run IRC on 6667/TCP and nearby port numbers (for example TCP ports 6660\u20136669, 7000) to avoid having to run the IRCd software with root privileges.\nThe protocol specified that characters were 8-bit but did not specify the character encoding the text was supposed to use. This can cause problems when users using different clients and/or different platforms want to converse.\nAll client-to-server IRC protocols in use today are descended from the protocol implemented in the irc2.4.0 version of the IRC2 server, and documented in RFC 1459. Since RFC 1459 was published, the new features in the irc2.10 implementation led to the publication of several revised protocol documents (RFC 2810, RFC 2811, RFC 2812 and RFC 2813); however, these protocol changes have not been widely adopted among other implementations.\nAlthough many specifications on the IRC protocol have been published, there is no official specification, as the protocol remains dynamic. Virtually no clients and very few servers rely strictly on the above RFCs as a reference.\nMicrosoft made an extension for IRC in 1998 via the proprietary IRCX. They later stopped distributing software supporting IRCX, instead developing the proprietary MSNP.\nThe standard structure of a network of IRC servers is a tree. Messages are routed along only necessary branches of the tree but network state is sent to every server and there is generally a high degree of implicit trust between servers. However, this architecture has a number of problems. A misbehaving or malicious server can cause major damage to the network and any changes in structure, whether intentional or a result of conditions on the underlying network, require a net-split and net-join. This results in a lot of network traffic and spurious quit/join messages to users and temporary loss of communication to users on the splitting servers. Adding a server to a large network means a large background bandwidth load on the network and a large memory load on the server. Once established, however, each message to multiple recipients is delivered in a fashion similar to multicast, meaning each message travels a network link exactly once. This is a strength in comparison to non-multicasting protocols such as Simple Mail Transfer Protocol (SMTP) or Extensible Messaging and Presence Protocol (XMPP).\nAn IRC daemon can be used on a local area network (LAN). IRC can thus be used to facilitate communication between people within the local area network (internal communication).\nCommands and replies.\nIRC has a line-based structure. Clients send single-line messages to the server, receive replies to those messages and receive copies of some messages sent by other clients. In most clients, users can enter commands by prefixing them with a '/'. Depending on the command, these may either be handled entirely by the client, or (generally for commands the client does not recognize) passed directly to the server, possibly with some modification.\nDue to the nature of the protocol, automated systems cannot always correctly pair a sent command with its reply with full reliability and are subject to guessing.\nChannels.\nThe basic means of communicating to a group of users in an established IRC session is through a \"channel\". Channels on a network can be displayed using the IRC command \"LIST\", which lists all currently available channels that do not have the modes +s or +p set, on that particular network.\nUsers can \"join\" a channel using the \"JOIN\" command, in most clients available as \"/join #channelname\". Messages sent to the joined channels are then relayed to all other users.\nChannels that are available across an entire IRC network are prefixed with a '#', while those local to a server use '&amp;'. Other less common channel types include '+' channels\u2014'modeless' channels without operators\u2014and '!' channels, a form of timestamped channel on normally non-timestamped networks.\nModes.\nUsers and channels may have \"modes\" that are represented by individual case-sensitive letters and are set using the \"MODE\" command. User modes and channel modes are separate and can use the same letter to mean different things (e.g. user mode \"i\" is invisible mode while channel mode \"i\" is invite only.) Modes are usually set and unset using the mode command that takes a target (user or channel), a set of modes to set (+) or unset (-) and any parameters the modes need.\nSome channel modes take parameters and other channel modes apply to a user on a channel or add or remove a mask (e.g. a ban mask) from a list associated with the channel rather than applying to the channel as a whole. Modes that apply to users on a channel have an associated symbol that is used to represent the mode in names replies (sent to clients on first joining a channel and use of the names command) and in many clients also used to represent it in the client's displayed list of users in a channel or to display an own indicator for a user's modes.\nIn order to correctly parse incoming mode messages and track channel state the client must know which mode is of which type and for the modes that apply to a user on a channel which symbol goes with which letter. In early implementations of IRC this had to be hard-coded in the client but there is now a de facto standard extension to the protocol called ISUPPORT that sends this information to the client at connect time using numeric 005.\nThere is a small design fault in IRC regarding modes that apply to users on channels: the names message used to establish initial channel state can only send one such mode per user on the channel, but multiple such modes can be set on a single user. For example, if a user holds both operator status (+o) and voice status (+v) on a channel, a new client will be unable to see the mode with less priority (i.e. voice). Workarounds for this are possible on both the client and server side; a common solution is to use IRCv3 \"multi-prefix\" extension.\nStandard (RFC 1459) modes.\nMany daemons and networks have added extra modes or modified the behavior of modes in the above list.\nChannel operators.\nA \"channel operator\" is a client on an IRC channel that manages the channel.\nIRC channel operators can be easily seen by the symbol or icon next to their name (varies by client implementation, commonly a \"@\" symbol prefix, a green circle, or a Latin letter \"+o\"/\"o\").\nOn most networks, an operator can:\nOperators.\nThere are also users who maintain elevated rights on their local server, or the entire network; these are called IRC operators, sometimes shortened to IRCops or Opers (not to be confused with channel operators). As the implementation of the IRCd varies, so do the privileges of the IRC operator on the given IRCd. RFC 1459 claims that IRC operators are \"a necessary evil\" to keep a clean state of the network, and as such they need to be able to disconnect and reconnect servers. Additionally, to prevent malicious users or even harmful automated programs from entering IRC, IRC operators are usually allowed to disconnect clients and completely ban IP addresses or complete subnets. Networks that carry services (NickServ et al.) usually allow their IRC operators also to handle basic \"ownership\" matters. Further privileged rights may include overriding channel bans (being able to join channels they would not be allowed to join, if they were not opered), being able to op themselves on channels where they would not be able without being opered, being auto-opped on channels always and so forth.\nHostmasks.\nA hostmask is a unique identifier of an IRC client connected to an IRC server. IRC servers, services, and other clients, including bots, can use it to identify a specific IRC session.\nThe format of a hostmask is codice_1. The hostmask looks similar to, but should not be confused with an e-mail address.\nThe nick part is the nickname chosen by the user and may be changed while connected.\nThe user part is the username reported by ident on the client. If ident is not available on the client, the username specified when the client connected is used after being prefixed with a tilde.\nThe host part is the hostname the client is connecting from. If the IP address of the client cannot be resolved to a valid hostname by the server, it is used instead of the hostname.\nBecause of the privacy implications of exposing the IP address or hostname of a client, some IRC daemons also provide privacy features, such as InspIRCd or UnrealIRCd's \"+x\" mode. This hashes a client IP address or masks part of a client's hostname, making it unreadable to users other than IRCops. Users may also have the option of requesting a \"virtual host\" (or \"vhost\"), to be displayed in the hostmask to allow further anonymity. Some IRC networks, such as Libera Chat or Freenode, use these as \"cloaks\" to indicate that a user is affiliated with a group or project.\nURI scheme.\nThere are three provisional recognized uniform resource identifier (URI) schemes for Internet Relay Chat: codice_2, codice_3, and codice_4. When supported, they allow hyperlinks of various forms, including\n irc://&lt;host&gt;[:&lt;port&gt;]/[&lt;channel&gt;[?&lt;channel_keyword&gt;]]\n ircs://&lt;host&gt;[:&lt;port&gt;]/[&lt;channel&gt;[?&lt;channel_keyword&gt;]]\n irc6://&lt;host&gt;[:&lt;port&gt;]/[&lt;channel&gt;[?&lt;channel_keyword&gt;]]\n(where items enclosed within brackets ([,]) are optional) to be used to (if necessary) connect to the specified host (or network, if known to the IRC client) and join the specified channel. (This can be used within the client itself, or from another application such as a Web browser). irc is the default URI, irc6 specifies a connection to be made using IPv6, and ircs specifies a secure connection.\nPer the specification, the usual hash symbol (#) will be prepended to channel names that begin with an alphanumeric character\u2014allowing it to be omitted. Some implementations (for example, mIRC) will do so \"unconditionally\" resulting in a (usually unintended) extra (for example, ##channel), if included in the URL.\nSome implementations allow multiple channels to be specified, separated by commas.\nChallenges.\nIssues in the original design of IRC were the amount of shared state data being a limitation on its scalability, the absence of unique user identifications leading to the nickname collision problem, lack of protection from netsplits by means of cyclic routing, the trade-off in scalability for the sake of real-time user presence information, protocol weaknesses providing a platform for abuse, no transparent and optimizable message passing, and no encryption. Some of these issues have been addressed in Modern IRC.\nAttacks.\nBecause IRC connections may be unencrypted and typically span long time periods, they are an attractive target for DoS/DDoS attackers and hackers. Because of this, careful security policy is necessary to ensure that an IRC network is not susceptible to an attack such as a takeover war. IRC networks may also K-line or G-line users or servers that have a harming effect.\nSome IRC servers support SSL/TLS connections for security purposes. This helps stop the use of packet sniffer programs to obtain the passwords of IRC users, but has little use beyond this scope due to the public nature of IRC channels. SSL connections require both client and server support (that may require the user to install SSL binaries and IRC client specific patches or modules on their computers). Some networks also use SSL for server-to-server connections, and provide a special channel flag (such as codice_5) to only allow SSL-connected users on the channel, while disallowing operator identification in clear text, to better utilize the advantages that SSL provides.\nIRC served as an early laboratory for many kinds of Internet attacks, such as using fake ICMP unreachable messages to break TCP-based IRC connections (nuking) to annoy users or facilitate takeovers.\nAbuse prevention.\nOne of the most contentious technical issues surrounding IRC implementations, which survives to this day, is the merit of \"Nick/Channel Delay\" vs. \"Timestamp\" protocols. Both methods exist to solve the problem of denial-of-service attacks, but take very different approaches.\nThe problem with the original IRC protocol as implemented was that when two servers split and rejoined, the two sides of the network would simply merge their channels. If a user could join on a \"split\" server, where a channel that existed on the other side of the network was empty, and gain operator status, they would become a channel operator of the \"combined\" channel after the netsplit ended; if a user took a nickname that existed on the other side of the network, the server would kill both users when rejoining (a \"nick collision\"). This was often abused to \"mass-kill\" all users on a channel, thus creating \"opless\" channels where no operators were present to deal with abuse. Apart from causing problems within IRC, this encouraged people to conduct denial-of-service attacks against IRC servers in order to cause netsplits, which they would then abuse.\nThe nick delay (ND) and channel delay (CD) strategies aim to prevent abuse by delaying reconnections and renames. After a user signs off and the nickname becomes available, or a channel ceases to exist because all its users parted (as often happens during a netsplit), the server will not allow any user to use that nickname or join that channel, until a certain period of time (the \"delay\") has passed. The idea behind this is that even if a netsplit occurs, it is useless to an abuser because they cannot take the nickname or gain operator status on a channel, and thus no collision of a nickname or \"merging\" of a channel can occur. To some extent, this inconveniences legitimate users, who might be forced to briefly use a different name after rejoining (appending an underscore is popular).\nThe timestamp protocol is an alternative to nick/channel delays which resolves collisions using timestamped priority. Every nickname and channel on the network is assigned a timestamp\u00a0\u2013 the date and time when it was created. When a netsplit occurs, two users on each side are free to use the same nickname or channel, but when the two sides are joined, only one can survive. In the case of nicknames, the newer user, according to their TS, is killed; when a channel collides, the members (users on the channel) are merged, but the channel operators on the \"losing\" side of the split lose their channel operator status.\nTS is a much more complicated protocol than ND/CD, both in design and implementation, and despite having gone through several revisions, some implementations still have problems with \"desyncs\" (where two servers on the same network disagree about the current state of the network), and allowing too much leniency in what was allowed by the \"losing\" side. Under the original TS protocols, for example, there was no protection against users setting bans or other modes in the losing channel that would then be merged when the split rejoined, even though the users who had set those modes lost their channel operator status. Some modern TS-based IRC servers have also incorporated some form of ND and/or CD in addition to timestamping in an attempt to further curb abuse.\nMost networks today use the timestamping approach. The timestamp versus ND/CD disagreements caused several servers to split away from EFnet and form the newer IRCnet. After the split, EFnet moved to a TS protocol, while IRCnet used ND/CD.\nIn recent versions of the IRCnet ircd, as well as ircds using the TS6 protocol (including Charybdis), ND has been extended/replaced by a mechanism called SAVE. This mechanism assigns every client a UID upon connecting to an IRC server. This ID starts with a number, which is forbidden in nicks (although some ircds, namely IRCnet and InspIRCd, allow clients to switch to their own UID as the nickname).\nIf two clients with the same nickname join from different sides of a netsplit (\"nick collision\"), the first server to see this collision will force \"both\" clients to change their nick to their UID, thus saving both clients from being disconnected. On IRCnet, the nickname will also be locked for some time (ND) to prevent both clients from changing back to the original nickname, thus colliding again.\nClients.\nClient software.\nClient software exists for various operating systems or software packages, as well as web-based or inside games. Many different clients are available for the various operating systems, including Windows, Unix and Linux, macOS and mobile operating systems (such as iOS and Android). On Windows, mIRC is one of the most popular clients. Some Linux distributions come with an IRC client preinstalled, such as Linux Mint which comes with HexChat preinstalled.\nSome programs which are extensible through plug-ins also serve as platforms for IRC clients. For instance, a client called ERC, written entirely in Emacs Lisp, is included in v.22.3 of Emacs. Therefore, any platform that can run Emacs can run ERC.\nA number of web browsers have built-in IRC clients, such as:\nWeb-based clients, such as Mibbit and open source KiwiIRC, can run in most browsers.\nGames such as \"War\u00a7ow\", \"Unreal Tournament\" (up to Unreal Tournament 2004), \"Uplink\", \"Spring Engine\"-based games, 0 A.D. and \"ZDaemon\" have included IRC.\nUstream's chat interface is IRC with custom authentication as well as Twitch's (formerly Justin.tv).\nBots.\nA typical use of bots in IRC is to provide IRC services or specific functionality within a channel such as to host a chat-based game or provide notifications of external events. However, some IRC bots are used to launch malicious attacks such as denial of service, spamming, or exploitation.\nBouncer.\nA program that runs as a daemon on a server and functions as a persistent proxy is known as a BNC or bouncer. The purpose is to maintain a connection to an IRC server, acting as a relay between the server and client, or simply to act as a proxy. Should the client lose network connectivity, the BNC may stay connected and archive all traffic for later delivery, allowing the user to resume their IRC session without disrupting their connection to the server.\nFurthermore, as a way of obtaining a bouncer-like effect, an IRC client (typically text-based, for example Irssi) may be run on an always-on server to which the user connects via ssh. This also allows devices that only have ssh functionality, but no actual IRC client installed themselves, to connect to the IRC, and it allows sharing of IRC sessions.\nTo keep the IRC client from quitting when the ssh connection closes, the client can be run inside a terminal multiplexer such as GNU Screen or tmux, thus staying connected to the IRC network(s) constantly and able to log conversation in channels that the user is interested in, or to maintain a channel's presence on the network. Modelled after this setup, in 2004 an IRC client following the client\u2013server, called Smuxi, was launched.\nSearch engines.\nThere are numerous search engines available to aid the user in finding what they are looking for on IRC. Generally the search engine consists of two parts, a \"back-end\" (or \"spider/crawler\") and a front-end \"search engine\".\nThe back-end (spider/webcrawler) is the work horse of the search engine. It is responsible for crawling IRC servers to index the information being sent across them. The information that is indexed usually consists solely of channel text (text that is publicly displayed in public channels). The storage method is usually some sort of relational database, like MySQL or Oracle.\nThe front-end \"search engine\" is the user interface to the database. It supplies users with a way to search the database of indexed information to retrieve the data they are looking for. These front-end search engines can also be coded in numerous programming languages.\nMost search engines have their own spider that is a single application responsible for crawling IRC and indexing data itself; however, others are \"user based\" indexers. The latter rely on users to install their \"add-on\" to their IRC client; the add-on is what sends the database the channel information of whatever channels the user happens to be on.\nMany users have implemented their own ad hoc search engines using the logging features built into many IRC clients. These search engines are usually implemented as bots and dedicated to a particular channel or group of associated channels.\nCharacter encoding.\nIRC still lacks a single globally accepted standard convention for how to transmit characters outside the 7-bit ASCII repertoire.\nIRC servers normally transfer messages from a client to another client just as byte sequences, without any interpretation or recoding of characters. The IRC protocol (unlike e.g. MIME or HTTP) lacks mechanisms for announcing and negotiating character encoding options. This has put the responsibility for choosing the appropriate character codec on the client. In practice, IRC channels have largely used the same character encodings that were also used by operating systems (in particular Unix derivatives) in the respective language communities:\nToday, the UTF-8 encoding of Unicode/ISO 10646 would be the most likely contender for a single future standard character encoding for all IRC communication, if such standard ever relaxed the 510-byte message size restriction. UTF-8 is ASCII compatible and covers the superset of all other commonly used coded character set standards.\nFile sharing.\nMuch like conventional P2P file sharing, users can create file servers that allow them to share files with each other by using customised IRC bots or scripts for their IRC client. Often users will group together to distribute warez via a network of IRC bots.\nTechnically, IRC provides no file transfer mechanisms itself; file sharing is implemented by IRC \"clients\", typically using the Direct Client-to-Client (DCC) protocol, in which file transfers are negotiated through the exchange of private messages between clients. The vast majority of IRC clients feature support for DCC file transfers, hence the view that file sharing is an integral feature of IRC. The commonplace usage of this protocol, however, sometimes also causes DCC spam. DCC commands have also been used to exploit vulnerable clients into performing an action such as disconnecting from the server or exiting the client.\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "14731", "revid": "7903804", "url": "https://en.wikipedia.org/wiki?curid=14731", "title": "Ideogram", "text": "Symbol that represents an idea or concept\nAn ideogram or ideograph (from Greek 'idea' + 'to write') is a symbol that is used within a given writing system to represent an idea or concept in a given language. (Ideograms are contrasted with phonograms, which indicate sounds of speech and thus are independent of any particular language.) Some ideograms are more arbitrary than others: some are only meaningful assuming preexisting familiarity with some convention; others more directly resemble their signifieds. Ideograms that represent physical objects by visually illustrating them are called \"pictograms\".\nTerminology.\nLogograms.\nIdeograms are not to be equated with logograms, which represent specific morphemes in a language. In a broad sense, ideograms may form part of a writing system otherwise based on other principles, like the examples above in the phonetic English writing system\u2014while also potentially representing the same idea across several languages, as they do not correspond to a specific spoken word. There may not always be a single way to read a given ideograph. While remaining logograms assigned to morphemes, specific Chinese characters like \u27e8\u27e9 'middle' may be classified as ideographs in a narrower sense, given their origin and visual structure.\nPictograms and indicatives.\n\"Pictograms\", depending on the definition, are ideograms that represent an idea either through a direct iconic resemblance to what is being referenced, or otherwise more broadly visually represent or illustrate it. In proto-writing systems, pictograms generally comprised most of the available symbols. Their use could also be extended via the rebus principle: for example, the pictorial Dongba symbols without Geba annotation cannot represent the Naxi language, but are used as a mnemonic for the recitation of oral literature. Some systems also use \"indicatives\", which denote abstract concepts. Sometimes, the word \"ideogram\" is used to refer exclusively to indicatives, contrasting them with pictograms.\nThe word \"ideogram\" has historically often been used to describe Egyptian hieroglyphs, Sumerian cuneiform, and Chinese characters. However, these symbols represent semantic elements of a language, and not the underlying ideas directly\u2014their use generally requires knowledge of a specific spoken language. Modern scholars refer to these symbols instead as \"logograms\", and generally avoid calling them \"ideograms\". Most logograms include some representation of the pronunciation of the corresponding word in the language, often using the rebus principle. Later systems used selected symbols to represent the sounds of the language, such as the adaptation of the logogram for 'ox' as the letter aleph representing the initial glottal stop. However, some logograms still meaningfully depict the meaning of the morpheme they represent visually. Pictograms are shaped like the object that the word refers to, such as an icon of a bull denoting the Semitic word 'ox'. Other logograms may visually represent meaning via more abstract techniques.\nMany Egyptian hieroglyphs and cuneiform graphs could be used either logographically or phonetically. For example, the Sumerian \"dingir\" \u27e8\u27e9 could represent the word 'deity', the god An or the word 'sky'. In Akkadian, the graph \u27e8\u27e9 could represent the stem 'deity', the word 'sky', or the syllable .\nWhile Chinese characters generally function as logograms, three of the six classes in the traditional classification are ideographic (or \"semantographic\") in origin, as they have no phonetic component:\nExample of ideograms are the DOT pictograms, a collection of 50 symbols developed during the 1970s by the American Institute of Graphic Arts at the request of the United States Department of Transportation. Initially used to mark airports, the system gradually became more widespread.\nPure signs.\nMany ideograms only represent ideas by convention. For example, a red octagon only carries the meaning of 'stop' due to the public association and reification of that meaning over time. In the field of semiotics, these are a type of pure \"sign\", a term which also includes symbols using non-graphical media. Modern analysis of Chinese characters reveals that pure signs are as old as the system itself, with prominent examples including the numerals representing numbers larger than four, including \u27e8\u27e9 'five', and \u27e8\u27e9 'eight'. These do not indicate anything about the quantities they represent visually or phonetically, only conventionally.\nTypes.\nMathematical notation.\nA mathematical symbol is a type of ideogram.\nHistory.\nAs true writing systems emerged from systems of pure ideograms, later societies with phonetic writing were often compelled by the intuitive connection between pictures, diagrams and logograms\u2014though ultimately ignorant of the latter's necessary phonetic dimension. Greek speakers began regularly visiting Egypt during the 7th century\u00a0BC. Ancient Greek writers generally mistook the Egyptian writing system to be purely ideographic. According to tradition, the Greeks had acquired the ability to write, among other things, from the Egyptians through Pythagoras (c.\u2009570\u00a0\u2013 c.\u2009495\u00a0BC), who had been directly taught their silent form of \"symbolic teaching\". Beginning with Plato (428\u2013347\u00a0BC), the conception of hieroglyphs as ideograms was rooted in a broader philosophical conception of most language as an imperfect and obfuscatory image of reality. The views of Plato involved an ontologically separate world of forms, but those of his student Aristotle (384\u2013322\u00a0BC) instead saw the forms as abstracts, identical in the mind of every person. For both, ideography was a more perfect representation of the forms possessed by the Egyptians. The Aristotelian framework would be the foundation for the conception of language in the Mediterranean world into the medieval era.\nAccording to the classical theory, because ideographs directly reflected the forms, they were the only \"true language\", and had the unique ability to communicate arcane wisdom to readers. The ability to read Egyptian hieroglyphs had been lost during late antiquity, in the context of the country's Hellenization and Christianization. However, the traditional notion that the latter trends compelled the abandonment of hieroglyphic writing has been rejected by recent scholarship.\nEurope only became fully acquainted with written Chinese near the end of the 16th century, and initially related the system to their existing framework of ideography as partially informed by Egyptian hieroglyphs. Ultimately, Jean-Fran\u00e7ois Champollion's successful decipherment of hieroglyphs in 1823 stemmed from an understanding that they did represent spoken Egyptian language, as opposed to being purely ideographic. Champollion's insight in part stemmed from his familiarity with the work of French sinologist Jean-Pierre Abel-R\u00e9musat regarding \"fanqie\", which demonstrated that Chinese characters were often used to write sounds, and not just ideas.\nProposed universal languages.\nInspired by these conceptions of ideography, several attempts have been made to design a universal written language\u2014i.e., an ideography whose interpretations are accessible to all people with no regard to the languages they speak. An early proposal was made in 1668 by John Wilkins in \"An Essay Towards a Real Character, and a Philosophical Language\". More recently, Blissymbols was devised by Charles K. Bliss in 1949, and currently includes over 2,000 graphs.\nReferences.\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nWorks cited.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "14732", "revid": "277086", "url": "https://en.wikipedia.org/wiki?curid=14732", "title": "Irish Republican Army (1919\u20131922)", "text": "Irish paramilitary organisation\nThe Irish Republican Army (IRA; ) was an Irish republican revolutionary paramilitary organisation who waged a guerrilla campaign against the British occupation of Ireland in the 1919\u20131921 Irish War of Independence. It was descended from the Irish Volunteers, an organisation established on 25 November 1913 that staged the Easter Rising in April 1916. In 1919, the Irish Republic that had been proclaimed during the Easter Rising was formally established by an elected assembly (D\u00e1il \u00c9ireann), and the Irish Volunteers were recognised by D\u00e1il \u00c9ireann as its legitimate army. \nFollowing the signing in 1921 of the Anglo-Irish Treaty, which ended the War of Independence, a split occurred within the IRA. Members who supported the treaty formed the nucleus of the Irish National Army. However, the majority of the IRA was opposed to the treaty. The anti-treaty IRA fought a civil war against the Free State Army in 1922\u20131923, with the intention of creating a fully independent all-Ireland republic. Having lost the civil war, this group remained in existence, with the intention of overthrowing the governments of both the Irish Free State and Northern Ireland and achieving the Irish Republic proclaimed in 1916.\nThis organisation was the ancestor of many groups also known as the Irish Republican Army, and distinguished from them as the Old IRA.\nOrigins.\nThe Irish Volunteers, founded in 1913, staged the Easter Rising, which aimed at ending British rule in Ireland, in 1916. Following the suppression of the Rising, thousands of Volunteers were imprisoned or interned, leading to the break-up of the organisation. It was reorganised in 1917 following the release of first the internees and then the prisoners. At the army convention held in Dublin in October 1917, \u00c9amon de Valera was elected president, Michael Collins Director for Organisation and Cathal Brugha Chairman of the Resident Executive.\nFollowing the success of Sinn F\u00e9in in the general election of 1918 and the setting up of the First D\u00e1il (the legislature of the Irish Republic), Volunteers commenced military action against the Royal Irish Constabulary (RIC), the paramilitary police force in Ireland, and subsequently against the British Army. It began with the Soloheadbeg Ambush, when members of the Third Tipperary Brigade led by S\u00e9umas Robinson, Se\u00e1n Treacy, Dan Breen and Se\u00e1n Hogan, seized a quantity of gelignite, killing two RIC constables in the process.\nThe D\u00e1il leadership worried that the Volunteers would not accept its authority, given that, under their own constitution, they were bound to obey \"their\" own executive and no other body. In August 1919, Brugha proposed to the D\u00e1il that the Volunteers be asked to swear allegiance to the D\u00e1il, but one commentator states that another year passed before the movement took an oath of allegiance to the Irish Republic and its government in \"August 1920\". In sharp contrast, a contemporary in the struggle for Irish independence notes that by late 1919, the term \"Irish Republican Army (IRA)\" was replacing \"Volunteers\" in everyday usage. This change is attributed to the Volunteers, having accepted the authority of the D\u00e1il, being referred to as the \"army of the Irish Republic\", popularly known as the \"Irish Republican Army\". Already in September 1917, a group of men from counties Clare and Tipperary charged with illegal drilling were claiming to be soldiers of the \"Irish Republican Army\". They refused to recognise the legitimacy of the court and insisted they be treated as prisoners of war.\nA power struggle continued between Brugha and Collins, both cabinet ministers, over who had the greater influence. Brugha was nominally the superior as Minister for Defence, but Collins's power base came from his position as Director of Organisation of the IRA and from his membership on the Supreme Council of the Irish Republican Brotherhood (IRB). De Valera resented Collins's clear power and influence, which he saw as coming more from the secretive IRB than from his position as a Teachta D\u00e1la (TD) and minister in the Aireacht. Brugha and de Valera both urged the IRA to undertake larger, more conventional military actions for the propaganda effect but were ignored by Collins and Mulcahy. Brugha at one stage proposed the assassination of the entire British cabinet. This was also discounted due to its presumed negative effect on British public opinion. Moreover, many members of the D\u00e1il, notably Arthur Griffith, did not approve of IRA violence and would have preferred a campaign of passive resistance to the British rule. The D\u00e1il belatedly accepted responsibility for IRA actions in April 1921, just three months before the end of the Irish War of Independence.\nIn practice, the IRA was commanded by Collins, with Richard Mulcahy as second in command. These men were able to issue orders and directives to IRA guerrilla units around the country and at times to send arms and organisers to specific areas. However, because of the localised and irregular character of the war, they were only able to exert limited control over local IRA commanders such as Tom Barry, Liam Lynch in Cork and Se\u00e1n Mac Eoin in Longford.\nThe IRA claimed a total strength of 70,000, but only about 3,000 were actively engaged in fighting against the Crown. The IRA distrusted those Irishmen who had fought in the British Army during the First World War as potential informers, but there were a number of exceptions such as Emmet Dalton, Tom Barry and Martin Doyle. The IRA divided its members into three classes, namely \"unreliable\", \"reliable\" and \"active\". The \"unreliable\" members were those who were nominally IRA members but did not do very much for the struggle, \"reliable\" members played a supporting role in the war while occasionally fighting and the \"active\" men those who were engaged in full-time fighting. Of the IRA brigades only about one to two-thirds were considered to be \"reliable\" while those considered \"active\" were even smaller. A disproportionate number of the \"active\" IRA men were teachers, medical students, shoemakers and bootmakers; those engaged in building trades like painters, carpenters and bricklayers; draper's assistants and creamery workers. The Canadian historian Peter Hart wrote \"...the guerrillas were disproportionately skilled, trained and urban\". Farmers and fishermen tended to be underrepresented in the IRA. Those Irishmen engaged in white-collar trades or working as skilled labourers were much more likely to be involved in cultural nationalist groups like the Gaelic League than farmers or fishermen and thus to have a stronger sense of Irish nationalism. Furthermore, the authority of the Crown tended to be stronger in towns and cities than in the countryside. Thus, those engaged in Irish nationalist activities in urban areas were much more likely to come into conflict with the Crown, leading to a greater chance of radicalisation. Finally, the British tactic of blowing up the homes of IRA members had the effect of discouraging many farmers from joining the struggle as the destruction of the family farm could easily reduce a farmer and his family to destitution. Of the \"active\" IRA members, three-quarters were in their late teens or early 20s and only 5% of the \"active\" men were in the age range of 40 or older. The \"active\" members were overwhelmingly single men with only 4% being married or engaged in a relationship. The life of an \"active\" IRA man with the stress of living on the run and constantly being in hiding tended to attract single men who could adjust to this lifestyle far more easily than a man in a relationship. Furthermore, the IRA preferred to recruit single men as it was found that singles could devote themselves more wholeheartedly to the struggle.\nWomen were active in the republican movement, but almost no women fought with the IRA whose \"active\" members were almost entirely male. The IRA was not a sectarian group and went out of its way to proclaim it was open to all Irishmen, but its membership was largely Catholic with virtually no Protestants serving as \"active\" IRA men. Hart wrote that in his study of the IRA membership that he found only three Protestants serving as \"active\" IRA men between 1919 and 1921. Of the 917 IRA men convicted by British courts under the Defence of the Realm Act in 1919, only one was a Protestant. The majority of those serving in the IRA were practising Catholics, but there was a large minority of \"pagans\" as atheists or non-practising Catholics who were known in Ireland. The majority of the IRA men serving in metropolitan Britain were permanent residents with very few sent over from Ireland. The majority of the IRA men operating in Britain were Irish-born, but there was a substantial minority who were British-born, something that made them especially insistent on asserting their Irish identity.\nIrish War of Independence.\nIRA campaign and organisation.\nThe IRA fought a guerrilla war against the Crown forces in Ireland from 1919 to July 1921. The most intense period of the war was from November 1920 onwards. The IRA campaign can broadly be split into three phases. The first, in 1919, involved the re-organisation of the Irish Volunteers as a guerrilla army and only sporadic attacks. Organisers such as Ernie O'Malley were sent around the country to set up viable guerrilla units. On paper, there were 100,000 or so Volunteers enrolled after the conscription crisis of 1918. However, only about 15,000 of these participated in the guerrilla war. In 1919, Collins, the IRA's Director of Intelligence, organised the \"Squad\"\u2014an assassination unit based in Dublin that killed police involved in intelligence work (the Irish playwright Brendan Behan's father Stephen Behan was a member of the Squad). Typical of Collins's sardonic sense of humour, the Squad was often referred to as his \"Twelve Apostles\". In addition, there were some arms raids on RIC barracks. By the end of 1919, four Dublin Metropolitan Police and 11 RIC men had been killed. The RIC abandoned most of their smaller rural barracks in late 1919. Around 400 of these were burned in a co-ordinated IRA operation around the country in April 1920.\nThe second phase of the IRA campaign, roughly from January to July 1920, involved attacks on the fortified police barracks located in the towns. Between January and June 1920, 16 of these were destroyed and 29 badly damaged. Several events of late 1920 greatly escalated the conflict. Firstly, the British declared martial law in parts of the country\u2014allowing for internment and executions of IRA men. Secondly, they deployed paramilitary forces, the Black and Tans and Auxiliary Division, and more British Army personnel into the country. Thus, the third phase of the war (roughly August 1920 \u2013 July 1921) involved the IRA taking on a greatly expanded British force, moving away from attacking well-defended barracks and instead using ambush tactics. To this end the IRA was re-organised into \"flying columns\"\u2014permanent guerrilla units, usually about 20 strong, although sometimes larger. In rural areas, the flying columns usually had bases in remote mountainous areas.\nThe most high-profile violence of the war took place in Dublin in November 1920 and is still known as Bloody Sunday. In the early hours of the morning, Collins' \"Squad\" killed 14 British spies. In reprisal, that afternoon, British forces opened fire on a football crowd at Croke Park, killing 14 civilians. Towards the end of the day, two prominent Republicans and another man who had been arrested the previous day were killed by Crown Forces.\nWhile most areas of the country saw some violence in 1919\u20131921, the brunt of the war was fought in Dublin and the southern province of Munster. In Munster, the IRA carried out a significant number of successful actions against British troops, for instance, the ambushing and killing of 16 of 18 Auxiliaries by Tom Barry's column at Kilmicheal in West Cork in November 1920, or Liam Lynch's men killing 13 British soldiers near Millstreet early in the next year. At the Crossbarry Ambush in March 1921, 100 or so of Barry's men fought a sizeable engagement with a British column of 1,200, escaping from the British encircling manoeuvre. In Dublin, the \"Squad\" and elements of the IRA Dublin Brigade were amalgamated into the \"Active Service Unit\", under Oscar Traynor, which tried to carry out at least three attacks on British troops a day. Usually, these consisted of shooting or grenade attacks on British patrols. Outside Dublin and Munster, there were only isolated areas of intense activity. For instance, the County Longford IRA under Se\u00e1n Mac Eoin carried out a number of well-planned ambushes and successfully defended the village of Ballinalee against Black and Tan reprisals in a three-hour gun battle. In County Mayo, large-scale guerrilla action did not break out until spring 1921, when two British forces were ambushed at Carrowkennedy and Tourmakeady. Elsewhere, fighting was more sporadic and less intense.\nIn Belfast, the war had a character all of its own. The city had a Protestant and unionist majority and IRA actions were responded to with reprisals against the Catholic population, including killings (such as the McMahon killings and the Arnon Street killings) the burning of many homes \u2013 as on Belfast's Bloody Sunday. The IRA in Belfast and the North generally, although involved in protecting the Catholic community from loyalists and state forces, undertook a retaliatory arson campaign against factories and commercial premises. On 22 May 1922 the new Northern Ireland government introduced internment (imprisonment without trial). Over 500 men from Tyrone, Derry, Fermanagh, Armagh and Belfast were arrested (all of the internees were republicans). The violence in Belfast alone, which continued until October 1922 (long after the truce in the rest of the country), claimed the lives of between 400 and 500 people. (see The Troubles in Ulster (1920\u20131922))\nIn April 1921, the IRA was again reorganised, in line with the D\u00e1il's endorsement of its actions, along the lines of a regular army. Divisions were created based on region, with commanders being given responsibility, in theory, for large geographical areas. In practice, this had little effect on the localised nature of the guerrilla warfare.\nIn May 1921, the IRA in Dublin attacked and burned the Custom House. The action was a serious setback as five members were killed and eighty captured.\nBy the end of the war in July 1921, the IRA was hard-pressed by the deployment of more British troops into the most active areas and a chronic shortage of arms and ammunition. It has been estimated that the IRA had only about 3,000 rifles (mostly captured from the British) during the war, with a larger number of shotguns and pistols. An ambitious plan to buy arms from Italy in 1921 collapsed when the money did not reach the arms dealers. Towards the end of the war, some Thompson submachine guns were imported from the United States; however 495 of these were intercepted by the American authorities and the remainder only reached Ireland shortly before the Truce.\nBy June 1921, Collins' assessment was that the IRA was within weeks, possibly even days, of collapse. It had few weapons or ammunition left. Moreover, almost 5,000 IRA men had been imprisoned or interned and over 500 killed. Collins and Mulcahy estimated that the number of effective guerrilla fighters was down to 2,000\u20133,000. However, in the summer of 1921, the war was abruptly ended.\nThe British recruited hundreds of World War I veterans into the RIC and sent them to Ireland. Because there was initially a shortage of RIC uniforms, the veterans at first wore a combination of dark green RIC uniforms and khaki British Army uniforms, which inspired the nickname \"Black and Tans\". The brutality of the Black and Tans is now well-known, although the greatest violence attributed to the Crown's forces was often that of the Auxiliary Division of the Constabulary. One of the strongest critics of the Black and Tans was King George V who in May 1921 told Lady Margery Greenwood that \"he hated the idea of the Black and Tans.\"\nThe IRA was also involved in the destruction of many stately homes in Munster. The Church of Ireland Gazette recorded numerous instances of Unionists and Loyalists being shot, burnt or forced from their homes during the early 1920s. In County Cork between 1920 and 1923 the IRA shot over 200 civilians of whom over 70 (or 36%) were Protestants: five times the percentage of Protestants in the civilian population. This was due to the historical inclination of Protestants towards loyalty to the United Kingdom. A convention of Irish Protestant Churches in Dublin in May 1922 signed a resolution placing \"on record\" that \"hostility to Protestants by reason of their religion has been almost, if not wholly, unknown in the twenty-six counties in which Protestants are in the minority.\"\nMany historic buildings in Ireland were destroyed during the war, most famously the Custom House in Dublin, which was disastrously attacked on de Valera's insistence, to the horror of the more militarily experienced Collins. As he feared, the destruction proved a pyrrhic victory for the Republic, with so many IRA men killed or captured that the IRA in Dublin suffered a severe blow.\nThis was also a period of social upheaval in Ireland, with frequent strikes as well as other manifestations of class conflict. In this regard, the IRA acted to a large degree as an agent of social control and stability, driven by the need to preserve cross-class unity in the national struggle, and on occasion being used to break strikes.\nAssessments of the effectiveness of the IRA's campaign vary. They were never in a position to engage in conventional warfare. The political, military and financial costs of remaining in Ireland were higher than the British government was prepared to pay and this in a sense forced them into negotiations with the Irish political leaders. According to historian Michael Hopkinson, the guerrilla warfare \"was often courageous and effective\". Historian David Fitzpatrick observes, \"The guerrilla fighters...were vastly outnumbered by the forces of the Crown... The success of the Irish Volunteers in surviving so long is therefore noteworthy.\"\nTruce and treaty.\nDavid Lloyd George, the British Prime Minister, at the time, found himself under increasing pressure (both internationally and from within the British Isles) to try to salvage something from the situation. This was a complete reversal on his earlier position. He had consistently referred to the IRA as a \"murder gang\" up until then. An unexpected olive branch came from King George V, who, in a speech in Belfast called for reconciliation on all sides, changed the mood and enabled the British and Irish Republican governments to agree to a truce. The Truce was agreed on 11 July 1921. On 8 July, de Valera met General Nevil Macready, the British commander in chief in Ireland and agreed terms. The IRA was to retain its arms and the British Army was to remain in barracks for the duration of peace negotiations. Many IRA officers interpreted the truce only as a temporary break in fighting. They continued to recruit and train volunteers, with the result that the IRA had increased its number to over 72,000 men by early 1922.\nNegotiations on an Anglo-Irish Treaty took place in late 1921 in London. The Irish delegation was led by Arthur Griffith and Michael Collins.\nThe most contentious areas of the Treaty for the IRA were abolition of the Irish Republic declared in 1919, the status of the Irish Free State as a dominion in the British Commonwealth and the British retention of the so-called Treaty Ports on Ireland's south coast. These issues were the cause of a split in the IRA and ultimately, the Irish Civil War.\nUnder the Government of Ireland Act 1920, Ireland was partitioned, creating Northern Ireland and Southern Ireland. Under the terms of the Anglo-Irish agreement of 6 December 1921, which ended the war (1919\u201321), Northern Ireland was given the option of withdrawing from the new Irish Free State or remaining part of the United Kingdom. After the Northern Ireland parliament chose to do the latter an Irish Boundary Commission was then set up to review the border.\nIrish leaders expected that it would so reduce Northern Ireland's size, by transferring nationalist areas to the Irish Free State, as to make it economically unviable. Partition was not by itself the key breaking point between pro- and anti-Treaty campaigners; both sides expected the Boundary Commission to greatly reduce Northern Ireland. Moreover, Michael Collins was planning a clandestine guerrilla campaign against the Northern state using the IRA. In early 1922, he sent IRA units to the border areas and sent arms to northern units. It was only afterwards, when partition was confirmed, that a united Ireland became the preserve of anti-Treaty Republicans.\nIRA and the Anglo-Irish Treaty.\nThe IRA leadership was deeply divided over the decision by the D\u00e1il to ratify the Treaty. Despite the fact that Michael Collins \u2013 the de facto leader of the IRA \u2013 had negotiated the Treaty, many IRA officers were against it. Of the General Headquarters (GHQ) staff, nine members were in favour of the Treaty while four opposed it. The majority of the IRA rank-and-file were against the Treaty; in January\u2013June 1922, their discontent developed into open defiance of the elected civilian Provisional government of Ireland.\nBoth sides agreed that the IRA's allegiance was to the (elected) D\u00e1il of the Irish Republic, but the anti-Treaty side argued that the decision of the D\u00e1il to accept the Treaty (and set aside the Irish Republic) meant that the IRA no longer owed that body its allegiance. They called for the IRA to withdraw from the authority of the D\u00e1il and to entrust the IRA Executive with control over the army. On 16 January, the first IRA division \u2013 the 2nd Southern Division led by Ernie O'Malley \u2013 repudiated the authority of the GHQ. A month later, on 18 February, Liam Forde, O/C of the IRA Mid-Limerick Brigade, issued a proclamation stating that: \"We no longer recognise the authority of the present head of the army, and renew our allegiance to the existing Irish Republic\". This was the first unit of the IRA to break with the pro-Treaty government.\nOn 22 March, Rory O'Connor held what was to become an infamous press conference and declared that the IRA would no longer obey the D\u00e1il as (he said) it had violated its Oath to uphold the Irish Republic. He went on to say that \"we repudiate the D\u00e1il ... We will set up an Executive which will issue orders to the IRA all over the country.\" In reply to the question on whether this meant they intended to create a military dictatorship, O'Connor said: \"You can take it that way if you like.\"\nOn 28 March, the (anti-Treaty) IRA Executive issued statement stating that Minister of Defence (Richard Mulcahy) and the Chief-of-Staff (Eoin O'Duffy) no longer exercised any control over the IRA. In addition, it ordered an end to the recruitment to the new military and police forces of the Provisional Government. Furthermore, it instructed all IRA units to reaffirm their allegiance to the Irish Republic on 2 April.\nThe stage was set for civil war over the Treaty.\nCivil War.\nThe pro-treaty IRA soon became the nucleus of the new (regular) Irish National Army created by Collins and Richard Mulcahy. British pressure, and tensions between the pro- and anti-Treaty factions of the IRA, led to a bloody civil war ending in the defeat of the anti-Treaty side. On 24 May 1923, Frank Aiken, the (anti-treaty) IRA chief of staff, called a ceasefire. Many left political activity altogether, but a minority continued to insist that the new Irish Free State, created by the \"illegitimate\" Treaty, was an illegitimate state. They asserted that their \"IRA Army Executive\" was the real government of a still-existing Irish Republic. The IRA of the civil war and subsequent organisations that have used the name claim lineage from that group, which is covered in full at Irish Republican Army (1922\u20131969).\n\"For information on later organisations using the name Irish Republican Army, see the table below. For a genealogy of organisations using the name \"IRA\" after 1922, see List of organisations known as the Irish Republican Army\".\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "14734", "revid": "42117739", "url": "https://en.wikipedia.org/wiki?curid=14734", "title": "Iron", "text": "element with atomic number 26 (Fe)\nIron is a chemical element; it has symbol Fe (from la\u00a0'iron') and atomic number 26. It is a metal that belongs to the first transition series and group 8 of the periodic table. It is, by mass, the most common element on Earth, forming much of Earth's outer and inner core. It is the fourth most abundant element in the Earth's crust. In its metallic state it was mainly deposited by meteorites.\nExtracting usable metal from iron ores requires kilns or furnaces capable of reaching , about 500\u00a0\u00b0C (900\u00a0\u00b0F) higher than that required to smelt copper. Humans started to master that process in Eurasia during the 2nd millennium BC and the use of iron tools and weapons began to displace copper alloys \u2013 in some regions, only around 1200\u00a0BC. That event is considered the transition from the Bronze Age to the Iron Age. In the modern world, iron alloys, such as steel, stainless steel, cast iron and special steels, are by far the most common industrial metals, due to their mechanical properties and low cost. The iron and steel industry is thus very important economically, and iron is the cheapest metal, with a price of a few dollars per kilogram or pound.\nPristine and smooth pure iron surfaces are a mirror-like silvery-gray. Iron reacts readily with oxygen and water to produce brown-to-black hydrated iron oxides, commonly known as rust. Unlike the oxides of some other metals that form passivating layers, rust occupies more volume than the metal and thus flakes off, exposing more fresh surfaces for corrosion. Chemically, the most common oxidation states of iron are iron(II) and iron(III). Iron shares many properties with other transition metals, including the other group 8 elements, ruthenium and osmium. Iron forms compounds in a wide range of oxidation states, \u22122 to +7. Iron also forms many coordination complexes; some of them, such as ferrocene, ferrioxalate, and Prussian blue have substantial industrial, medical, or research applications.\nThe body of an adult human contains about 4 grams (0.005% body weight) of iron, mostly in hemoglobin and myoglobin. These two proteins play essential roles in oxygen transport by blood and oxygen storage in muscles. To maintain the necessary levels, human iron metabolism requires a minimum of iron in the diet. Iron is also the metal at the active site of many important redox enzymes dealing with cellular respiration and oxidation and reduction in plants and animals.\nCharacteristics.\nAllotropes.\nAt least four allotropes of iron (differing atom arrangements in the solid) are known, conventionally denoted \u03b1, \u03b3, \u03b4, and \u03b5.\nThe first three forms are observed at ordinary pressures. As molten iron cools past its freezing point of 1538\u00a0\u00b0C, it crystallizes into its \u03b4 allotrope, which has a body-centered cubic (bcc) crystal structure. As it cools further to 1394\u00a0\u00b0C, it changes to its \u03b3-iron allotrope, a face-centered cubic (fcc) crystal structure, or austenite. At 912\u00a0\u00b0C and below, the crystal structure again becomes the bcc \u03b1-iron allotrope.\nThe physical properties of iron at very high pressures and temperatures have also been studied extensively, because of their relevance to theories about the cores of the Earth and other planets. Above approximately 10\u00a0GPa and temperatures of a few hundred kelvin or less, \u03b1-iron changes into another hexagonal close-packed (hcp) structure, which is also known as \u03b5-iron. The higher-temperature \u03b3-phase also changes into \u03b5-iron, but does so at higher pressure.\nSome controversial experimental evidence exists for a stable \u03b2 phase at pressures above 50\u00a0GPa and temperatures of at least 1500\u00a0K. It is supposed to have an orthorhombic or a double hcp structure. (Confusingly, the term \"\u03b2-iron\" is sometimes also used to refer to \u03b1-iron above its Curie point, when it changes from being ferromagnetic to paramagnetic, even though its crystal structure has not changed.)\nThe Earth's inner core is generally presumed to consist of an iron-nickel alloy with \u03b5 (or \u03b2) structure.\nMelting and boiling points.\nThe melting and boiling points of iron, along with its enthalpy of atomization, are lower than those of the earlier 3d elements from scandium to chromium, showing the lessened contribution of the 3d electrons to metallic bonding as they are attracted more and more into the inert core by the nucleus; however, they are higher than the values for the previous element manganese because that element has a half-filled 3d sub-shell and consequently its d-electrons are not easily delocalized. This same trend appears for ruthenium but not osmium.\nThe melting point of iron is experimentally well defined for pressures less than 50\u00a0GPa. For greater pressures, published data (as of 2007) still varies by tens of gigapascals and over a thousand kelvin.\nMagnetic properties.\nBelow its Curie point of , \u03b1-iron changes from paramagnetic to ferromagnetic: the spins of the two unpaired electrons in each atom generally align with the spins of its neighbors, creating an overall magnetic field. This happens because the orbitals of those two electrons (d\"z\"2 and d\"x\"2 \u2212 \"y\"2) do not point toward neighboring atoms in the lattice, and therefore are not involved in metallic bonding.\nIn the absence of an external source of magnetic field, the atoms get spontaneously partitioned into magnetic domains, about 10\u00a0micrometers across, such that the atoms in each domain have parallel spins, but some domains have other orientations. Thus a macroscopic piece of iron will have a nearly zero overall magnetic field.\nApplication of an external magnetic field causes the domains that are magnetized in the same general direction to grow at the expense of adjacent ones that point in other directions, reinforcing the external field. This effect is exploited in devices that need to channel magnetic fields to fulfill design function, such as electrical transformers, magnetic recording heads, and electric motors. Impurities, lattice defects, or grain and particle boundaries can \"pin\" the domains in the new positions, so that the effect persists even after the external field is removed \u2013 thus turning the iron object into a (permanent) magnet.\nSimilar behavior is exhibited by some iron compounds, such as the ferrites including the mineral magnetite, a crystalline form of the mixed iron(II,III) oxide (although the atomic-scale mechanism, ferrimagnetism, is somewhat different). Pieces of magnetite with natural permanent magnetization (lodestones) provided the earliest compasses for navigation. Particles of magnetite were extensively used in magnetic recording media such as core memories, magnetic tapes, floppies, and disks, until they were replaced by cobalt-based materials.\nIsotopes.\nIron has four stable isotopes: 54Fe (5.845% of natural iron), 56Fe (91.754%), 57Fe (2.119%) and 58Fe (0.282%). Twenty-four artificial isotopes have also been created. Of these stable isotopes, only 57Fe has a nuclear spin (\u2212&lt;templatestyles src=\"Fraction/styles.css\" /&gt;1\u20442). The nuclide 54Fe theoretically can undergo double electron capture to 54Cr, but the process has never been observed and only a lower limit on the half-life of 4.4\u00d71020 years has been established.\n60Fe is an extinct radionuclide of long half-life (2.6\u00a0million years). It is not found on Earth, but its ultimate decay product is its granddaughter, the stable nuclide 60Ni. Much of the past work on isotopic composition of iron has focused on the nucleosynthesis of 60Fe through studies of meteorites and ore formation. In the last decade, advances in mass spectrometry have allowed the detection and quantification of minute, naturally occurring variations in the ratios of the stable isotopes of iron. Much of this work is driven by the Earth and planetary science communities, although applications to biological and industrial systems are emerging.\nIn phases of the meteorites \"Semarkona\" and \"Chervony Kut,\" a correlation between the concentration of 60Ni, the granddaughter of 60Fe, and the abundance of the stable iron isotopes provided evidence for the existence of 60Fe at the time of formation of the Solar System. Possibly the energy released by the decay of 60Fe, along with that released by 26Al, contributed to the remelting and differentiation of asteroids after their formation 4.6\u00a0billion years ago. The abundance of 60Ni present in extraterrestrial material may bring further insight into the origin and early history of the Solar System.\nThe most abundant iron isotope 56Fe is of particular interest to nuclear scientists because it represents the most common endpoint of nucleosynthesis. Since 56Ni (14 alpha particles) is easily produced from lighter nuclei in the alpha process in nuclear reactions in supernovae (see silicon burning process), it is the endpoint of fusion chains inside extremely massive stars. Although adding more alpha particles is possible, but nonetheless the sequence does effectively end at 56Ni because conditions in stellar interiors cause the competition between photodisintegration and the alpha process to favor photodisintegration around 56Ni. This 56Ni, which has a half-life of about 6\u00a0days, is created in quantity in these stars, but soon decays by two successive positron emissions within supernova decay products in the supernova remnant gas cloud, first to radioactive 56Co, and then to stable 56Fe. As such, iron is the most abundant element in the core of red giants, and is the most abundant metal in iron meteorites and in the dense metal cores of planets such as Earth. It is also very common in the universe, relative to other stable metals of approximately the same atomic weight. Iron is the sixth most abundant element in the universe, and the most common refractory element.\nAlthough a further tiny energy gain could be extracted by synthesizing 62Ni, which has a marginally higher binding energy than 56Fe, conditions in stars are unsuitable for this process. Element production in supernovas greatly favor iron over nickel, and in any case, 56Fe still has a lower mass per nucleon than 62Ni due to its higher fraction of lighter protons. Hence, elements heavier than iron require a supernova for their formation, involving rapid neutron capture by starting 56Fe nuclei.\nIn the far future of the universe, assuming that proton decay does not occur, cold fusion occurring via quantum tunnelling would cause the light nuclei in ordinary matter to fuse into 56Fe nuclei. Fission and alpha-particle emission would then make heavy nuclei decay into iron, converting all stellar-mass objects to cold spheres of pure iron.\nOrigin and occurrence in nature.\nCosmogenesis.\nIron's abundance in rocky planets like Earth is due to its abundant production during the runaway fusion and explosion of type Ia supernovae, which scatters the iron into space.\nMetallic iron.\nMetallic or native iron is rarely found on the surface of the Earth because it tends to oxidize. However, both the Earth's inner and outer core, which together account for 35% of the mass of the whole Earth, are believed to consist largely of an iron alloy, possibly with nickel. Electric currents in the liquid outer core are believed to be the origin of the Earth's magnetic field. The other terrestrial planets (Mercury, Venus, and Mars) as well as the Moon are believed to have a metallic core consisting mostly of iron. The M-type asteroids are also believed to be partly or mostly made of metallic iron alloy.\nThe rare iron meteorites are the main form of natural metallic iron on the Earth's surface. Items made of cold-worked meteoritic iron have been found in various archaeological sites dating from a time when iron smelting had not yet been developed; and the Inuit in Greenland have been reported to use iron from the Cape York meteorite for tools and hunting weapons. About 1 in 20 meteorites consist of the unique iron-nickel minerals taenite (35\u201380% iron) and kamacite (90\u201395% iron). Native iron is also rarely found in basalts that have formed from magmas that have come into contact with carbon-rich sedimentary rocks, which have reduced the oxygen fugacity sufficiently for iron to crystallize. This is known as telluric iron and is described from a few localities, such as Disko Island in West Greenland, Yakutia in Russia and B\u00fchl in Germany.\nMantle minerals.\nFerropericlase , a solid solution of periclase (MgO) and w\u00fcstite (FeO), makes up about 20% of the volume of the lower mantle of the Earth, which makes it the second most abundant mineral phase in that region after silicate perovskite ; it also is the major host for iron in the lower mantle. At the bottom of the transition zone of the mantle, the reaction \u03b3- transforms \u03b3-olivine into a mixture of silicate perovskite and ferropericlase and vice versa. In the literature, this mineral phase of the lower mantle is also often called magnesiow\u00fcstite. Silicate perovskite may form up to 93% of the lower mantle, and the magnesium iron form, , is considered to be the most abundant mineral in the Earth, making up 38% of its volume.\nEarth's crust.\nWhile iron is the most abundant element on Earth, most of this iron is concentrated in the inner and outer cores. The fraction of iron that is in Earth's crust only amounts to about 5% of the overall mass of the crust and is thus only the fourth most abundant element in that layer (after oxygen, silicon, and aluminium).\nMost of the iron in the crust is combined with various other elements to form many iron minerals. An important class is the iron oxide minerals such as hematite (Fe2O3), magnetite (Fe3O4), and siderite (FeCO3), which are the major ores of iron. Many igneous rocks also contain the sulfide minerals pyrrhotite and pentlandite. During weathering, iron tends to leach from sulfide deposits as the sulfate and from silicate deposits as the bicarbonate. Both of these are oxidized in aqueous solution and precipitate in even mildly elevated pH as iron(III) oxide.\nLarge deposits of iron are banded iron formations, a type of rock consisting of repeated thin layers of iron oxides alternating with bands of iron-poor shale and chert. The banded iron formations were laid down in the time between https://\u00a0million years ago and https://\u00a0million years ago.\nMaterials containing finely ground iron(III) oxides or oxide-hydroxides, such as ochre, have been used as yellow, red, and brown pigments since pre-historical times. They contribute as well to the color of various rocks and clays, including entire geological formations like the Painted Hills in Oregon and the Buntsandstein (\"colored sandstone\", British Bunter). Through \"Eisensandstein\" (a jurassic 'iron sandstone', e.g. from Donzdorf in Germany) and Bath stone in the UK, iron compounds are responsible for the yellowish color of many historical buildings and sculptures. The proverbial red color of the surface of Mars is derived from an iron oxide-rich regolith.\nSignificant amounts of iron occur in the iron sulfide mineral pyrite (FeS2), but it is difficult to extract iron from it and it is therefore not exploited. In fact, iron is so common that production generally focuses only on ores with very high quantities of it.\nAccording to the International Resource Panel's Metal Stocks in Society report, the global stock of iron in use in society is 2,200\u00a0kg per capita. More-developed countries differ in this respect from less-developed countries (7,000\u201314,000 vs 2,000\u00a0kg per capita).\nOceans.\nOcean science demonstrated the role of the iron in the ancient seas in both marine biota and climate.\nChemistry and compounds.\nIron shows the characteristic chemical properties of the transition metals, namely the ability to form variable oxidation states differing by steps of one and a very large coordination and organometallic chemistry: indeed, it was the discovery of an iron compound, ferrocene, that revolutionalized the latter field in the 1950s. Iron is sometimes considered as a prototype for the entire block of transition metals, due to its abundance and the immense role it has played in the technological progress of humanity. Its 26 electrons are arranged in the configuration [Ar]3d64s2, of which the 3d and 4s electrons are relatively close in energy, and thus a number of electrons can be ionized.\nIron forms compounds mainly in the oxidation states +2 (iron(II), \"ferrous\") and +3 (iron(III), \"ferric\"). Iron also occurs in higher oxidation states, e.g., the purple potassium ferrate (K2FeO4), which contains iron in its +6 oxidation state. The anion [FeO4]\u2013 with iron in its +7 oxidation state, along with an iron(V)-peroxo isomer, has been detected by infrared spectroscopy at 4\u00a0K after cocondensation of laser-ablated Fe atoms with a mixture of O2/Ar. Iron(IV) is a common intermediate in many biochemical oxidation reactions. Numerous organoiron compounds contain formal oxidation states of +1, 0, \u22121, or even \u22122. The oxidation states and other bonding properties are often assessed using the technique of M\u00f6ssbauer spectroscopy. Many mixed valence compounds contain both iron(II) and iron(III) centers, such as magnetite and Prussian blue (). The latter is used as the traditional \"blue\" in blueprints.\nIron is the first of the transition metals that cannot reach its group oxidation state of +8, although its heavier congeners ruthenium and osmium can, with ruthenium having more difficulty than osmium. Ruthenium exhibits an aqueous cationic chemistry in its low oxidation states similar to that of iron, but osmium does not, favoring high oxidation states in which it forms anionic complexes. In the second half of the 3d transition series, vertical similarities down the groups compete with the horizontal similarities of iron with its neighbors cobalt and nickel in the periodic table, which are also ferromagnetic at room temperature and share similar chemistry. As such, iron, cobalt, and nickel are sometimes grouped together as the iron triad.\nUnlike many other metals, iron does not form amalgams with mercury. As a result, mercury is traded in standardized 76 pound flasks (34\u00a0kg) made of iron.\nIron is by far the most reactive element in its group; it is pyrophoric when finely divided and dissolves easily in dilute acids, giving Fe2+. However, it does not react with concentrated nitric acid and other oxidizing acids due to the formation of an impervious oxide layer, which can nevertheless react with hydrochloric acid. High-purity iron, called electrolytic iron, is considered to be resistant to rust, due to its oxide layer.\nBinary compounds.\nOxides and sulfides.\nIron forms various oxide and hydroxide compounds; the most common are iron(II,III) oxide (Fe3O4), and iron(III) oxide (Fe2O3). Iron(II) oxide also exists, though it is unstable at room temperature. Despite their names, they are actually all non-stoichiometric compounds whose compositions may vary. These oxides are the principal ores for the production of iron (see bloomery and blast furnace). They are also used in the production of ferrites, useful magnetic storage media in computers, and pigments. The best known sulfide is iron pyrite (FeS2), also known as fool's gold owing to its golden luster. It is not an iron(IV) compound, but is actually an iron(II) polysulfide containing Fe2+ and S22- ions in a distorted sodium chloride structure.\nHalides.\nThe binary ferrous and ferric halides are well-known. The ferrous halides typically arise from treating iron metal with the corresponding hydrohalic acid to give the corresponding hydrated salts.\n Fe + 2 HX \u2192 FeX2 + H2 (X = F, Cl, Br, I)\nIron reacts with fluorine, chlorine, and bromine to give the corresponding ferric halides, ferric chloride being the most common.\n 2 Fe + 3 X2 \u2192 2 FeX3 (X = F, Cl, Br)\nFerric iodide is an exception, being thermodynamically unstable due to the oxidizing power of Fe3+ and the high reducing power of I\u2212:\n 2 I\u2212 + 2 Fe3+ \u2192 I2 + 2 Fe2+ (E0 = +0.23 V)\nFerric iodide, a black solid, is not stable in ordinary conditions, but can be prepared through the reaction of iron pentacarbonyl with iodine and carbon monoxide in the presence of hexane and light at the temperature of \u221220\u00a0\u00b0C, with oxygen and water excluded. Complexes of ferric iodide with some soft bases are known to be stable compounds.\nSolution chemistry.\nThe standard reduction potentials in acidic aqueous solution for some common iron ions are given below:\nThe red-purple tetrahedral ferrate(VI) anion is such a strong oxidizing agent that it oxidizes ammonia to nitrogen (N2) and water to oxygen:\n4 FeO42- + 34 H2O \u2192 4 + 20 OH- + 3 O2\nThe pale-violet hexaquo complex is an acid such that above pH 0 it is fully hydrolyzed:\nAs pH rises above 0 the above yellow hydrolyzed species form and as it rises above 2\u20133, reddish-brown hydrous iron(III) oxide precipitates out of solution. Although Fe3+ has a d5 configuration, its absorption spectrum is not like that of Mn2+ with its weak, spin-forbidden d\u2013d bands, because Fe3+ has higher positive charge and is more polarizing, lowering the energy of its ligand-to-metal charge transfer absorptions. Thus, all the above complexes are rather strongly colored, with the single exception of the hexaquo ion \u2013 and even that has a spectrum dominated by charge transfer in the near ultraviolet region. On the other hand, the pale green iron(II) hexaquo ion does not undergo appreciable hydrolysis. Carbon dioxide is not evolved when carbonate anions are added, which instead results in white iron(II) carbonate being precipitated out. In excess carbon dioxide this forms the slightly soluble bicarbonate, which occurs commonly in groundwater, but it oxidises quickly in air to form iron(III) oxide that accounts for the brown deposits present in a sizeable number of streams.\nCoordination compounds.\nDue to its electronic structure, iron has a very large coordination and organometallic chemistry.\nMany coordination compounds of iron are known. A typical six-coordinate anion is hexachloroferrate(III), [FeCl6]3\u2212, found in the mixed salt tetrakis(methylammonium) hexachloroferrate(III) chloride. Complexes with multiple bidentate ligands have geometric isomers. For example, the \"trans\"-chlorohydridobis(bis-1,2-(diphenylphosphino)ethane)iron(II) complex is used as a starting material for compounds with the moiety. The ferrioxalate ion with three oxalate ligands displays helical chirality with its two non-superposable geometries labelled \"\u039b\" (lambda) for the left-handed screw axis and \"\u0394\" (delta) for the right-handed screw axis, in line with IUPAC conventions. Potassium ferrioxalate is used in chemical actinometry and along with its sodium salt undergoes photoreduction applied in old-style photographic processes. The dihydrate of iron(II) oxalate has a polymeric structure with co-planar oxalate ions bridging between iron centres with the water of crystallisation located forming the caps of each octahedron, as illustrated below.\nIron(III) complexes are quite similar to those of chromium(III) with the exception of iron(III)'s preference for \"O\"-donor instead of \"N\"-donor ligands. The latter tend to be rather more unstable than iron(II) complexes and often dissociate in water. Many Fe\u2013O complexes show intense colors and are used as tests for phenols or enols. For example, in the ferric chloride test, used to determine the presence of phenols, iron(III) chloride reacts with a phenol to form a deep violet complex:\n3 ArOH + FeCl3 \u2192 Fe(OAr)3 + 3 HCl (Ar = aryl)\nAmong the halide and pseudohalide complexes, fluoro complexes of iron(III) are the most stable, with the colorless [FeF5(H2O)]2\u2212 being the most stable in aqueous solution. Chloro complexes are less stable and favor tetrahedral coordination as in [FeCl4]\u2212; [FeBr4]\u2212 and [FeI4]\u2212 are reduced easily to iron(II). Thiocyanate is a common test for the presence of iron(III) as it forms the blood-red [Fe(SCN)(H2O)5]2+. Like manganese(II), most iron(III) complexes are high-spin, the exceptions being those with ligands that are high in the spectrochemical series such as cyanide. An example of a low-spin iron(III) complex is [Fe(CN)6]3\u2212. Iron shows a great variety of electronic spin states, including every possible spin quantum number value for a d-block element from 0 (diamagnetic) to &lt;templatestyles src=\"Fraction/styles.css\" /&gt;5\u20442 (5 unpaired electrons). This value is always half the number of unpaired electrons. Complexes with zero to two unpaired electrons are considered low-spin and those with four or five are considered high-spin.\nIron(II) complexes are less stable than iron(III) complexes but the preference for \"O\"-donor ligands is less marked, so that for example is known while is not. They have a tendency to be oxidized to iron(III) but this can be moderated by low pH and the specific ligands used.\nOrganometallic compounds.\nOrganoiron chemistry is the study of organometallic compounds of iron, where carbon atoms are covalently bound to the metal atom. They are many and varied, including cyanide complexes, carbonyl complexes, sandwich and half-sandwich compounds.\nPrussian blue or \"ferric ferrocyanide\", Fe4[Fe(CN)6]3, is an old and well-known iron-cyanide complex, extensively used as pigment and in several other applications. Its formation can be used as a simple wet chemistry test to distinguish between aqueous solutions of Fe2+ and Fe3+ as they react (respectively) with potassium ferricyanide and potassium ferrocyanide to form Prussian blue.\nAnother old example of an organoiron compound is iron pentacarbonyl, Fe(CO)5, in which a neutral iron atom is bound to the carbon atoms of five carbon monoxide molecules. The compound can be used to make carbonyl iron powder, a highly reactive form of metallic iron. Thermolysis of iron pentacarbonyl gives triiron dodecacarbonyl, , a complex with a cluster of three iron atoms at its core. Collman's reagent, disodium tetracarbonylferrate, is a useful reagent for organic chemistry; it contains iron in the \u22122 oxidation state. Cyclopentadienyliron dicarbonyl dimer contains iron in the rare +1 oxidation state.\nA landmark in this field was the discovery in 1951 of the remarkably stable sandwich compound ferrocene , by Pauson and Kealy and independently by Miller and colleagues, whose surprising molecular structure was determined only a year later by Woodward and Wilkinson and Fischer.\nFerrocene is still one of the most important tools and models in this class.\nIron-centered organometallic species are used as catalysts. The Kn\u00f6lker complex, for example, is a transfer hydrogenation catalyst for ketones.\nIndustrial uses.\nThe iron compounds produced on the largest scale in industry are iron(II) sulfate (FeSO4\u00b77H2O) and iron(III) chloride (FeCl3). The former is one of the most readily available sources of iron(II), but is less stable to aerial oxidation than Mohr's salt (). Iron(II) compounds tend to be oxidized to iron(III) compounds in the air.\nHistory.\nDevelopment of iron metallurgy.\nIron is one of the elements undoubtedly known to the ancient world. It has been worked, or wrought, for millennia. However, iron artefacts of great age are much rarer than objects made of gold or silver due to the ease with which iron corrodes. The technology developed slowly, and even after the discovery of smelting it took many centuries for iron to replace bronze as the metal of choice for tools and weapons.\nMeteoritic iron.\nBeads made from meteoric iron in 3500\u00a0BC or earlier were found in Gerzeh, Egypt by G. A. Wainwright. The beads contain 7.5% nickel, which is a signature of meteoric origin since iron found in the Earth's crust generally has only minuscule nickel impurities.\nMeteoric iron was highly regarded due to its origin in the heavens and was often used to forge weapons and tools. For example, a dagger made of meteoric iron was found in the tomb of Tutankhamun, containing similar proportions of iron, cobalt, and nickel to a meteorite discovered in the area, deposited by an ancient meteor shower. Items that were likely made of iron by Egyptians date from 3000 to 2500\u00a0BC.\nMeteoritic iron is comparably soft and ductile and easily cold forged but may get brittle when heated because of the nickel content.\nWrought iron.\n \nThe first iron production started in the Middle Bronze Age, but it took several centuries before iron displaced bronze. Samples of smelted iron from Asmar, Mesopotamia and Tall Chagar Bazaar in northern Syria were made sometime between 3000 and 2700\u00a0BC. The Hittites established an empire in north-central Anatolia around 1600\u00a0BC. They appear to be the first to understand the production of iron from its ores and regard it highly in their society. The Hittites began to smelt iron between 1500 and 1200\u00a0BC and the practice spread to the rest of the Near East after their empire fell in 1180\u00a0BC. The subsequent period is called the Iron Age.\nArtifacts of smelted iron are found in India dating from 1800 to 1200\u00a0BC, and in the Levant from about 1500\u00a0BC (suggesting smelting in Anatolia or the Caucasus). Alleged references (compare history of metallurgy in South Asia) to iron in the Indian Vedas have been used for claims of a very early usage of iron in India respectively to date the texts as such. The rigveda term \"ayas\" (metal) refers to copper, while iron which is called as \"\u015by\u0101ma ayas\", literally \"black copper\", first is mentioned in the post-rigvedic Atharvaveda.\nSome archaeological evidence suggests iron was smelted in Zimbabwe and southeast Africa as early as the eighth century BC. Iron working was introduced to Greece in the late 11th century\u00a0BC, from which it spread quickly throughout Europe.\nThe spread of ironworking in Central and Western Europe is associated with Celtic expansion. According to Pliny the Elder, iron use was common in the Roman era. In the lands of what is now considered China, iron appears approximately 700\u2013500\u00a0BC. Iron smelting may have been introduced into China through Central Asia. The earliest evidence of the use of a blast furnace in China dates to the 1st century AD, and cupola furnaces were used as early as the Warring States period (403\u2013221 BC). Usage of the blast and cupola furnace remained widespread during the Tang and Song dynasties.\nDuring the Industrial Revolution in Britain, Henry Cort began refining iron from pig iron to wrought iron (or bar iron) using innovative production systems. In 1783 he patented the puddling process for refining iron ore. It was later improved by others, including Joseph Hall.\nCast iron.\nCast iron was first produced in China during 5th century BC, but was hardly in Europe until the medieval period. The earliest cast iron artifacts were discovered by archaeologists in what is now modern Luhe County, Jiangsu in China. Cast iron was used in ancient China for warfare, agriculture, and architecture. During the medieval period, means were found in Europe of producing wrought iron from cast iron (in this context known as pig iron) using finery forges. For all these processes, charcoal was required as fuel.\nMedieval blast furnaces were about tall and made of fireproof brick; forced air was usually provided by hand-operated bellows. Modern blast furnaces have grown much bigger, with hearths fourteen meters in diameter that allow them to produce thousands of tons of iron each day, but essentially operate in much the same way as they did during medieval times.\nIn 1709, Abraham Darby I established a coke-fired blast furnace to produce cast iron, replacing charcoal, although continuing to use blast furnaces. The ensuing availability of inexpensive iron was one of the factors leading to the Industrial Revolution. Toward the end of the 18th century, cast iron began to replace wrought iron for certain purposes, because it was cheaper. Carbon content in iron was not implicated as the reason for the differences in properties of wrought iron, cast iron, and steel until the 18th century.\nSince iron was becoming cheaper and more plentiful, it also became a major structural material following the building of the innovative first iron bridge in 1778. This bridge still stands today as a monument to the role iron played in the Industrial Revolution. Following this, iron was used in rails, boats, ships, aqueducts, and buildings, as well as in iron cylinders in steam engines. Railways have been central to the formation of modernity and ideas of progress and various languages refer to railways as \"iron road\" (e.g. French , German , Turkish , Russian , Chinese, Japanese, and Korean \u9435\u9053, Vietnamese \"\").\nSteel.\nSteel (with smaller carbon content than pig iron but more than wrought iron) was first produced in antiquity by using a bloomery. Blacksmiths in Luristan in western Persia were making good steel by 1000\u00a0BC. Then improved versions, Wootz steel by India and Damascus steel were developed around 300\u00a0BC and AD\u00a0500 respectively. These methods were specialized, and so steel did not become a major commodity until the 1850s.\nNew methods of producing it by carburizing bars of iron in the cementation process were devised in the 17th century. In the Industrial Revolution, new methods of producing bar iron without charcoal were devised and these were later applied to produce steel. In the late 1850s, Henry Bessemer invented a new steelmaking process, involving blowing air through molten pig iron, to produce mild steel. This made steel much more economical, thereby leading to wrought iron no longer being produced in large quantities.\nFoundations of modern chemistry.\nIn 1774, Antoine Lavoisier used the reaction of water steam with metallic iron inside an incandescent iron tube to produce hydrogen in his experiments leading to the demonstration of the conservation of mass, which was instrumental in changing chemistry from a qualitative science to a quantitative one.\nSymbolic role.\nIron plays a certain role in mythology and has found various usage as a metaphor and in folklore. The Greek poet Hesiod's \"Works and Days\" (lines 109\u2013201) lists different ages of man named after metals like gold, silver, bronze and iron to account for successive ages of humanity. The Iron Age was closely related with Rome, and in Ovid's \"Metamorphoses\"\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The Virtues, in despair, quit the earth; and the depravity of man becomes universal and complete. Hard steel succeeded then.\u2014\u200a\nAn example of the importance of iron's symbolic role may be found in the German Campaign of 1813. Frederick William III commissioned then the first Iron Cross as military decoration. Berlin iron jewellery reached its peak production between 1813 and 1815, when the Prussian royal family urged citizens to donate gold and silver jewellery for military funding. The inscription \"Ich gab Gold f\u00fcr Eisen\" (I gave gold for iron) was used as well in later war efforts.\n&lt;templatestyles src=\"Template:Visible anchor/styles.css\" /&gt;Production of metallic iron.\nLaboratory routes.\nFor a few limited purposes when it is needed, pure iron is produced in the laboratory in small quantities by reducing the pure oxide or hydroxide with hydrogen, or forming iron pentacarbonyl and heating it to 250\u00a0\u00b0C so that it decomposes to form pure iron powder. Another method is electrolysis of ferrous chloride onto an iron cathode.\nMain industrial route.\nNowadays, the industrial production of iron or steel consists of two main stages. In the first stage, iron ore is reduced with coke in a blast furnace, and the molten metal is separated from gross impurities such as silicate minerals. This stage yields an alloy \u2013 pig iron \u2013 that contains relatively large amounts of carbon. In the second stage, the amount of carbon in the pig iron is lowered by oxidation to yield wrought iron, steel, or cast iron. Other metals can be added at this stage to form alloy steels.\nBlast furnace processing.\nThe blast furnace is loaded with iron ores, usually hematite or magnetite , along with coke (coal that has been separately baked to remove volatile components) and flux (limestone or dolomite). \"Blasts\" of air pre-heated to 900\u00a0\u00b0C (sometimes with oxygen enrichment) is blown through the mixture, in sufficient amount to turn the carbon into carbon monoxide:\nThis reaction raises the temperature to about 2000\u00a0\u00b0C. The carbon monoxide reduces the iron ore to metallic iron:\nSome iron in the high-temperature lower region of the furnace reacts directly with the coke:\nThe flux removes silicaceous minerals in the ore, which would otherwise clog the furnace: The heat of the furnace decomposes the carbonates to calcium oxide, which reacts with any excess silica to form a slag composed of calcium silicate or other products. At the furnace's temperature, the metal and the slag are both molten. They collect at the bottom as two immiscible liquid layers (with the slag on top), that are then easily separated. The slag can be used as a material in road construction or to improve mineral-poor soils for agriculture.\nSteelmaking thus remains one of the largest industrial contributors of CO2 emissions in the world.\nSteelmaking.\nThe pig iron produced by the blast furnace process contains up to 4\u20135% carbon (by mass), with small amounts of other impurities like sulfur, magnesium, phosphorus, and manganese. This high level of carbon makes it relatively weak and brittle. Reducing the amount of carbon to 0.002\u20132.1% produces steel, which may be up to 1000 times harder than pure iron. A great variety of steel articles can then be made by cold working, hot rolling, forging, machining, etc. Removing the impurities from pig iron, but leaving 2\u20134% carbon, results in cast iron, which is cast by foundries into articles such as stoves, pipes, radiators, lamp-posts, and rails.\nSteel products often undergo various heat treatments after they are forged to shape. Annealing consists of heating them to 700\u2013800\u00a0\u00b0C for several hours and then gradual cooling. It makes the steel softer and more workable.\nDirect iron reduction.\nOwing to environmental concerns, alternative methods of processing iron have been developed. \"Direct iron reduction\" reduces iron ore to a ferrous lump called \"sponge\" iron or \"direct\" iron that is suitable for steelmaking. Two main reactions comprise the direct reduction process:\nNatural gas is partially oxidized (with heat and a catalyst):\nIron ore is then treated with these gases in a furnace, producing solid sponge iron:\nSilica is removed by adding a limestone flux as described above.\nThermite process.\nIgnition of a mixture of aluminium powder and iron oxide yields metallic iron via the thermite reaction:\nAlternatively pig iron may be made into steel (with up to about 2% carbon) or wrought iron (commercially pure iron). Various processes have been used for this, including finery forges, puddling furnaces, Bessemer converters, open hearth furnaces, basic oxygen furnaces, and electric arc furnaces. In all cases, the objective is to oxidize some or all of the carbon, together with other impurities. On the other hand, other metals may be added to make alloy steels.\nMolten oxide electrolysis.\nMolten oxide electrolysis (MOE) uses electrolysis of molten iron oxide to yield metallic iron. It is studied in laboratory-scale experiments and is proposed as a method for industrial iron production that has no direct emissions of carbon dioxide. It uses a liquid iron cathode, an anode formed from an alloy of chromium, aluminium and iron, and the electrolyte is a mixture of molten metal oxides into which iron ore is dissolved. The current keeps the electrolyte molten and reduces the iron oxide. Oxygen gas is produced in addition to liquid iron. The only carbon dioxide emissions come from any fossil fuel-generated electricity used to heat and reduce the metal.\nApplications.\nAs structural material.\nIron is the most widely used of all the metals, accounting for over 90% of worldwide metal production. Its low cost and high strength often make it the material of choice to withstand stress or transmit forces, such as the construction of machinery and machine tools, rails, automobiles, ship hulls, concrete reinforcing bars, and the load-carrying framework of buildings. Since pure iron is quite soft, it is most commonly combined with alloying elements to make steel.\nMechanical properties.\nThe mechanical properties of iron and its alloys are extremely relevant to their structural applications. Those properties can be evaluated in various ways, including the Brinell test, the Rockwell test and the Vickers hardness test.\nThe properties of pure iron are often used to calibrate measurements or to compare tests. However, the mechanical properties of iron are significantly affected by the sample's purity: pure, single crystals of iron are actually softer than aluminium, and the purest industrially produced iron (99.99%) has a hardness of 20\u201330\u00a0Brinell. The pure iron (99.9%\uff5e99.999%), especially called electrolytic iron, is industrially produced by electrolytic refining.\nAn increase in the carbon content will cause a significant increase in the hardness and tensile strength of iron. Maximum hardness of 65 Rc is achieved with a 0.6% carbon content, although the alloy has low tensile strength. Because of the softness of iron, it is much easier to work with than its heavier congeners ruthenium and osmium.\nTypes of steels and alloys.\n\u03b1-Iron is a fairly soft metal that can dissolve only a small concentration of carbon (no more than 0.021% by mass at 910\u00a0\u00b0C). Austenite (\u03b3-iron) is similarly soft and metallic but can dissolve considerably more carbon (as much as 2.04% by mass at 1146\u00a0\u00b0C). This form of iron is used in the type of stainless steel used for making cutlery, and hospital and food-service equipment.\nCommercially available iron is classified based on purity and the abundance of additives. Pig iron has 3.5\u20134.5% carbon and contains varying amounts of contaminants such as sulfur, silicon and phosphorus. Pig iron is not a saleable product, but rather an intermediate step in the production of cast iron and steel. The reduction of contaminants in pig iron that negatively affect material properties, such as sulfur and phosphorus, yields cast iron containing 2\u20134% carbon, 1\u20136% silicon, and small amounts of manganese. Pig iron has a melting point in the range of 1420\u20131470\u00a0K, which is lower than either of its two main components, and makes it the first product to be melted when carbon and iron are heated together. Its mechanical properties vary greatly and depend on the form the carbon takes in the alloy.\n\"White\" cast irons contain their carbon in the form of cementite, or iron carbide (Fe3C). This hard, brittle compound dominates the mechanical properties of white cast irons, rendering them hard, but unresistant to shock. The broken surface of a white cast iron is full of fine facets of the broken iron carbide, a very pale, silvery, shiny material, hence the appellation. Cooling a mixture of iron with 0.8% carbon slowly below 723\u00a0\u00b0C to room temperature results in separate, alternating layers of cementite and \u03b1-iron, which is soft and malleable and is called pearlite for its appearance. Rapid cooling, on the other hand, does not allow time for this separation and creates hard and brittle martensite. The steel can then be tempered by reheating to a temperature in between, changing the proportions of pearlite and martensite. The end product below 0.8% carbon content is a pearlite-\u03b1Fe mixture, and that above 0.8% carbon content is a pearlite-cementite mixture.\nIn gray iron the carbon exists as separate, fine flakes of graphite, and also renders the material brittle due to the sharp edged flakes of graphite that produce stress concentration sites within the material. A newer variant of gray iron, referred to as ductile iron, is specially treated with trace amounts of magnesium to alter the shape of graphite to spheroids, or nodules, reducing the stress concentrations and vastly increasing the toughness and strength of the material.\nWrought iron contains less than 0.25% carbon but large amounts of slag that give it a fibrous characteristic. Wrought iron is more corrosion resistant than steel. It has been almost completely replaced by mild steel, which corrodes more readily than wrought iron, but is cheaper and more widely available. Carbon steel contains 2.0% carbon or less, with small amounts of manganese, sulfur, phosphorus, and silicon. Alloy steels contain varying amounts of carbon as well as other metals, such as chromium, vanadium, molybdenum, nickel, tungsten, etc. Their alloy content raises their cost, and so they are usually only employed for specialist uses. One common alloy steel, though, is stainless steel. Recent developments in ferrous metallurgy have produced a growing range of microalloyed steels, also termed 'HSLA' or high-strength, low alloy steels, containing tiny additions to produce high strengths and often spectacular toughness at minimal cost.\nAlloys with high purity elemental makeups (such as alloys of electrolytic iron) have specifically enhanced properties such as ductility, tensile strength, toughness, fatigue strength, heat resistance, and corrosion resistance.\nApart from traditional applications, iron is also used for protection from ionizing radiation. Although it is lighter than another traditional protection material, lead, it is much stronger mechanically.\nThe main disadvantage of iron and steel is that pure iron, and most of its alloys, suffer badly from rust if not protected in some way, a cost amounting to over 1% of the world's economy. Painting, galvanization, passivation, plastic coating and bluing are all used to protect iron from rust by excluding water and oxygen or by cathodic protection. The mechanism of the rusting of iron is as follows:\nCathode: 3 O2 + 6 H2O + 12 e\u2212 \u2192 12 OH\u2212\nAnode: 4 Fe \u2192 4 Fe2+ + 8 e\u2212; 4 Fe2+ \u2192 4 Fe3+ + 4 e\u2212\nOverall: 4 Fe + 3 O2 + 6 H2O \u2192 4 Fe3+ + 12 OH\u2212 \u2192 4 Fe(OH)3 or 4 FeO(OH) + 4 H2O\nThe electrolyte is usually iron(II) sulfate in urban areas (formed when atmospheric sulfur dioxide attacks iron), and salt particles in the atmosphere in seaside areas.\nCatalysts and reagents.\nBecause Fe is inexpensive and nontoxic, much effort has been devoted to the development of Fe-based catalysts and reagents. Iron is however less common as a catalyst in commercial processes than more expensive metals. In biology, Fe-containing enzymes are pervasive.\nIron catalysts are traditionally used in the Haber\u2013Bosch process for the production of ammonia and the Fischer\u2013Tropsch process for conversion of carbon monoxide to hydrocarbons for fuels and lubricants. Powdered iron in an acidic medium is used in the Bechamp reduction, the conversion of nitrobenzene to aniline.\nIron compounds.\nIron(III) oxide mixed with aluminium powder can be ignited to create a thermite reaction, used in welding large iron parts (like rails) and purifying ores. Iron(III) oxide and oxyhydroxide are used as reddish and ocher pigments.\nIron(III) chloride finds use in water purification and sewage treatment, in the dyeing of cloth, as a coloring agent in paints, as an additive in animal feed, and as an etchant for copper in the manufacture of printed circuit boards. It can also be dissolved in alcohol to form tincture of iron, which is used as a medicine to stop bleeding in canaries.\nIron(II) sulfate is used as a precursor to other iron compounds. It is also used to reduce chromate in cement. It is used to fortify foods and treat iron deficiency anemia. Iron(III) sulfate is used in settling minute sewage particles in tank water. Iron(II) chloride is used as a reducing flocculating agent, in the formation of iron complexes and magnetic iron oxides, and as a reducing agent in organic synthesis.\nSodium nitroprusside is a drug used as a vasodilator. It is on the World Health Organization's List of Essential Medicines.\nBiological and pathological role.\nIron is required for life. The iron\u2013sulfur clusters are pervasive and include nitrogenase, the enzymes responsible for biological nitrogen fixation. Iron-containing proteins participate in transport, storage and use of oxygen. Iron proteins are involved in electron transfer.\nExamples of iron-containing proteins in higher organisms include hemoglobin, cytochrome (see high-valent iron), and catalase. The average adult human contains about 0.005% body weight of iron, or about four grams, of which three quarters is in hemoglobin\u2014a level that remains constant despite only about one milligram of iron being absorbed each day, because the human body recycles its hemoglobin for the iron content.\nMicrobial growth may be assisted by oxidation of iron(II) or by reduction of iron(III).\nBiochemistry.\nIron acquisition poses a problem for aerobic organisms because ferric iron is poorly soluble near neutral pH. Thus, these organisms have developed means to absorb iron as complexes, sometimes taking up ferrous iron before oxidising it back to ferric iron. In particular, bacteria have evolved very high-affinity sequestering agents called siderophores.\nAfter uptake in human cells, iron storage is precisely regulated. A major component of this regulation is the protein transferrin, which binds iron ions absorbed from the duodenum and carries it in the blood to cells. Transferrin contains Fe3+ in the middle of a distorted octahedron, bonded to one nitrogen, three oxygens and a chelating carbonate anion that traps the Fe3+ ion: it has such a high stability constant that it is very effective at taking up Fe3+ ions even from the most stable complexes. At the bone marrow, transferrin is reduced from Fe3+ to Fe2+ and stored as ferritin to be incorporated into hemoglobin. \nThe most commonly known and studied bioinorganic iron compounds (biological iron molecules) are the heme proteins: examples are hemoglobin, myoglobin, and cytochrome P450. These compounds participate in transporting gases, building enzymes, and transferring electrons. Metalloproteins are a group of proteins with metal ion cofactors. Some examples of iron metalloproteins are ferritin and rubredoxin. Many enzymes vital to life contain iron, such as catalase, lipoxygenases, and IRE-BP.\nHemoglobin is an oxygen carrier that occurs in red blood cells and contributes their color, transporting oxygen in the arteries from the lungs to the muscles where it is transferred to myoglobin, which stores it until it is needed for the metabolic oxidation of glucose, generating energy. Here the hemoglobin binds to carbon dioxide, produced when glucose is oxidized, which is transported through the veins by hemoglobin (predominantly as bicarbonate anions) back to the lungs where it is exhaled. In hemoglobin, the iron is in one of four heme groups and has six possible coordination sites; four are occupied by nitrogen atoms in a porphyrin ring, the fifth by an imidazole nitrogen in a histidine residue of one of the protein chains attached to the heme group, and the sixth is reserved for the oxygen molecule it can reversibly bind to. When hemoglobin is not attached to oxygen (and is then called deoxyhemoglobin), the Fe2+ ion at the center of the heme group (in the hydrophobic protein interior) is in a high-spin configuration. It is thus too large to fit inside the porphyrin ring, which bends instead into a dome with the Fe2+ ion about 55\u00a0picometers above it. In this configuration, the sixth coordination site reserved for the oxygen is blocked by another histidine residue.\nWhen deoxyhemoglobin picks up an oxygen molecule, this histidine residue moves away and returns once the oxygen is securely attached to form a hydrogen bond with it. This results in the Fe2+ ion switching to a low-spin configuration, resulting in a 20% decrease in ionic radius so that now it can fit into the porphyrin ring, which becomes planar. Additionally, this hydrogen bonding results in the tilting of the oxygen molecule, resulting in a Fe\u2013O\u2013O bond angle of around 120\u00b0 that avoids the formation of Fe\u2013O\u2013Fe or Fe\u2013O2\u2013Fe bridges that would lead to electron transfer, the oxidation of Fe2+ to Fe3+, and the destruction of hemoglobin. This results in a movement of all the protein chains that leads to the other subunits of hemoglobin changing shape to a form with larger oxygen affinity. Thus, when deoxyhemoglobin takes up oxygen, its affinity for more oxygen increases, and vice versa. Myoglobin, on the other hand, contains only one heme group and hence this cooperative effect cannot occur. Thus, while hemoglobin is almost saturated with oxygen in the high partial pressures of oxygen found in the lungs, its affinity for oxygen is much lower than that of myoglobin, which oxygenates even at low partial pressures of oxygen found in muscle tissue. As described by the Bohr effect (named after Christian Bohr, the father of Niels Bohr), the oxygen affinity of hemoglobin diminishes in the presence of carbon dioxide.\nCarbon monoxide and phosphorus trifluoride are poisonous to humans because they bind to hemoglobin similarly to oxygen, but with much more strength, so that oxygen can no longer be transported throughout the body. Hemoglobin bound to carbon monoxide is known as carboxyhemoglobin. This effect also plays a minor role in the toxicity of cyanide, but there the major effect is by far its interference with the proper functioning of the electron transport protein cytochrome a. The cytochrome proteins also involve heme groups and are involved in the metabolic oxidation of glucose by oxygen. The sixth coordination site is then occupied by either another imidazole nitrogen or a methionine sulfur, so that these proteins are largely inert to oxygen\u2014with the exception of cytochrome a, which bonds directly to oxygen and thus is very easily poisoned by cyanide. Here, the electron transfer takes place as the iron remains in low spin but changes between the +2 and +3 oxidation states. Since the reduction potential of each step is slightly greater than the previous one, the energy is released step-by-step and can thus be stored in adenosine triphosphate. Cytochrome a is slightly distinct, as it occurs at the mitochondrial membrane, binds directly to oxygen, and transports protons as well as electrons, as follows:\n4 Cytc2+ + O2 + 8H \u2192 4 Cytc3+ + 2 H2O + 4H\nAlthough the heme proteins are the most important class of iron-containing proteins, the iron\u2013sulfur proteins are also very important, being involved in electron transfer, which is possible since iron can exist stably in either the +2 or +3 oxidation states. These have one, two, four, or eight iron atoms that are each approximately tetrahedrally coordinated to four sulfur atoms; because of this tetrahedral coordination, they always have high-spin iron. The simplest of such compounds is rubredoxin, which has only one iron atom coordinated to four sulfur atoms from cysteine residues in the surrounding peptide chains. Another important class of iron\u2013sulfur proteins is the ferredoxins, which have multiple iron atoms. Transferrin does not belong to either of these classes.\nThe ability of sea mussels to maintain their grip on rocks in the ocean is facilitated by their use of organometallic iron-based bonds in their protein-rich cuticles. Based on synthetic replicas, the presence of iron in these structures increased elastic modulus 770 times, tensile strength 58 times, and toughness 92 times. The amount of stress required to permanently damage them increased 76 times.\nNutrition.\nDiet.\nIron is pervasive, but particularly rich sources of dietary iron include red meat, oysters, beans, poultry, fish, leaf vegetables, watercress, tofu, and blackstrap molasses. Bread and breakfast cereals are sometimes specifically fortified with iron.\nIron provided by dietary supplements is often found as iron(II) fumarate, although iron(II) sulfate is cheaper and is absorbed equally well. Elemental iron, or reduced iron, despite being absorbed at only one-third to two-thirds the efficiency (relative to iron sulfate), is often added to foods such as breakfast cereals or enriched wheat flour. Iron is most available to the body when chelated to amino acids and is also available for use as a common iron supplement. Glycine, the least expensive amino acid, is most often used to produce iron glycinate supplements.\nDietary recommendations.\nThe U.S. Institute of Medicine (IOM) updated Estimated Average Requirements (EARs) and Recommended Dietary Allowances (RDAs) for iron in 2001. The current EAR for iron for women ages 14\u200d\u2013\u200d18 is 7.9\u00a0mg/day, 8.1\u00a0mg/day for ages 19\u200d\u2013\u200d50 and 5.0\u00a0mg/day thereafter (postmenopause). For men, the EAR is 6.0\u00a0mg/day for ages 19 and up. The RDA is 15.0\u00a0mg/day for women ages 15\u200d\u2013\u200d18, 18.0\u00a0mg/day for ages 19\u200d\u2013\u200d50 and 8.0\u00a0mg/day thereafter. For men, 8.0\u00a0mg/day for ages 19 and up. RDAs are higher than EARs so as to identify amounts that will cover people with higher-than-average requirements. RDA for pregnancy is 27\u00a0mg/day and, for lactation, 9\u00a0mg/day. For children ages 1\u200d\u2013\u200d3 years 7\u00a0mg/day, 10\u00a0mg/day for ages 4\u20138 and 8\u00a0mg/day for ages 9\u200d\u2013\u200d13. As for safety, the IOM also sets Tolerable upper intake levels (ULs) for vitamins and minerals when evidence is sufficient. In the case of iron, the UL is set at 45\u00a0mg/day. Collectively the EARs, RDAs and ULs are referred to as Dietary Reference Intakes.\nThe European Food Safety Authority (EFSA) refers to the collective set of information as Dietary Reference Values, with Population Reference Intake (PRI) instead of RDA, and Average Requirement instead of EAR. AI and UL are defined the same as in the United States. For women the PRI is 13\u00a0mg/day ages 15\u200d\u2013\u200d17 years, 16\u00a0mg/day for women ages 18 and up who are premenopausal and 11\u00a0mg/day postmenopausal. For pregnancy and lactation, 16\u00a0mg/day. For men the PRI is 11\u00a0mg/day ages 15 and older. For children ages 1 to 14, the PRI increases from 7 to 11\u00a0mg/day. The PRIs are higher than the U.S. RDAs, with the exception of pregnancy. The EFSA reviewed the same safety question did not establish a UL.\nInfants may require iron supplements if they are bottle-fed cow's milk. Frequent blood donors are at risk of low iron levels and are often advised to supplement their iron intake.\nFor U.S. food and dietary supplement labeling purposes, the amount in a serving is expressed as a percent of Daily Value (%DV). For iron labeling purposes, 100% of the Daily Value was 18\u00a0mg, and as of May\u00a027, 2016[ [update]] remained unchanged at 18\u00a0mg. A table of the old and new adult daily values is provided at Reference Daily Intake.\nDeficiency.\nIron deficiency is the most common nutritional deficiency in the world. When loss of iron is not adequately compensated by adequate dietary iron intake, a state of latent iron deficiency occurs, which over time leads to iron-deficiency anemia if left untreated, which is characterised by an insufficient number of red blood cells and an insufficient amount of hemoglobin. Children, pre-menopausal women (women of child-bearing age), and people with poor diet are most susceptible to the disease. Most cases of iron-deficiency anemia are mild, but if not treated can cause problems like fast or irregular heartbeat, complications during pregnancy, and delayed growth in infants and children.\nThe brain is resistant to acute iron deficiency due to the slow transport of iron through the blood brain barrier. Acute fluctuations in iron status (marked by serum ferritin levels) do not reflect brain iron status, but prolonged nutritional iron deficiency is suspected to reduce brain iron concentrations over time. In the brain, iron plays a role in oxygen transport, myelin synthesis, mitochondrial respiration, and as a cofactor for neurotransmitter synthesis and metabolism. Animal models of nutritional iron deficiency report biomolecular changes resembling those seen in Parkinson's and Huntington's disease. However, age-related accumulation of iron in the brain has also been linked to the development of Parkinson's.\nExcess.\nIron uptake is tightly regulated by the human body, which has no regulated physiological means of excreting iron. Only small amounts of iron are lost daily due to mucosal and skin epithelial cell sloughing, so control of iron levels is primarily accomplished by regulating uptake. Regulation of iron uptake is impaired in some people as a result of a genetic defect that maps to the HLA-H gene region on chromosome 6 and leads to abnormally low levels of hepcidin, a key regulator of the entry of iron into the circulatory system in mammals. In these people, excessive iron intake can result in iron overload disorders, known medically as hemochromatosis. Many people have an undiagnosed genetic susceptibility to iron overload, and are not aware of a family history of the problem. For this reason, people should not take iron supplements unless they suffer from iron deficiency and have consulted a doctor. Hemochromatosis is estimated to be the cause of 0.3\u20130.8% of all metabolic diseases of Caucasians. \nOverdoses of ingested iron can cause excessive levels of free iron in the blood. High blood levels of free ferrous iron react with peroxides to produce highly reactive free radicals that can damage DNA, proteins, lipids, and other cellular components. Iron toxicity occurs when the cell contains free iron, which generally occurs when iron levels exceed the availability of transferrin to bind the iron. Damage to the cells of the gastrointestinal tract can also prevent them from regulating iron absorption, leading to further increases in blood levels. Iron typically damages cells in the heart, liver and elsewhere, causing adverse effects that include coma, metabolic acidosis, shock, liver failure, coagulopathy, long-term organ damage, and even death. Humans experience iron toxicity when the iron exceeds 20\u00a0milligrams for every kilogram of body mass; 60\u00a0milligrams per kilogram is considered a lethal dose. Overconsumption of iron, often the result of children eating large quantities of ferrous sulfate tablets intended for adult consumption, is one of the most common toxicological causes of death in children under six. The Dietary Reference Intake (DRI) sets the Tolerable Upper Intake Level (UL) for adults at 45\u00a0mg/day. For children under fourteen years old the UL is 40\u00a0mg/day.\nThe medical management of iron toxicity is complicated, and can include use of a specific chelating agent called deferoxamine to bind and expel excess iron from the body.\nADHD.\nSome research has suggested that low thalamic iron levels may play a role in the pathophysiology of ADHD. Some researchers have found that iron supplementation can be effective especially in the inattentive subtype of the disorder.\nSome researchers in the 2000s suggested a link between low levels of iron in the blood and ADHD. A 2012 study found no such correlation.\nCancer.\nThe role of iron in cancer defense can be described as a \"double-edged sword\" because of its pervasive presence in non-pathological processes. People having chemotherapy may develop iron deficiency and anemia, for which intravenous iron therapy is used to restore iron levels. Iron overload, which may occur from high consumption of red meat, may initiate tumor growth and increase susceptibility to cancer onset, particularly for colorectal cancer.\nMarine systems.\nIron plays an essential role in marine systems and can act as a limiting nutrient for planktonic activity. Because of this, too much of a decrease in iron may lead to a decrease in growth rates in phytoplanktonic organisms such as diatoms. Iron can also be oxidized by marine microbes under conditions that are high in iron and low in oxygen.\nIron can enter marine systems through adjoining rivers and directly from the atmosphere. Once iron enters the ocean, it can be distributed throughout the water column through ocean mixing and through recycling on the cellular level. In the arctic, sea ice plays a major role in the store and distribution of iron in the ocean, depleting oceanic iron as it freezes in the winter and releasing it back into the water when thawing occurs in the summer. The iron cycle can fluctuate the forms of iron from aqueous to particle forms altering the availability of iron to primary producers. Increased light and warmth increases the amount of iron that is in forms that are usable by primary producers.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nBibliography.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nFurther reading.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;"}
{"id": "14735", "revid": "29691676", "url": "https://en.wikipedia.org/wiki?curid=14735", "title": "IEEE 802.15", "text": "Set of IEEE standards for wireless personal area networks\nIEEE 802.15 is a working group of the Institute of Electrical and Electronics Engineers (IEEE) IEEE 802 standards committee which specifies Wireless Specialty Networks (WSN) standards. The working group was formerly known as Working Group for Wireless Personal Area Networks.\nThe number of Task Groups in IEEE 802.15 varies based on the number of active projects. The current list of active projects can be found on the https://.\nIEEE 802.15.1: WPAN / Bluetooth.\nTask group one is based on Bluetooth technology. It defines physical layer (PHY) and medium access control (MAC) specification for wireless connectivity with fixed, portable and moving devices within or entering personal operating space. Standards were issued in 2002 and 2005.\nIEEE 802.15.2: Coexistence.\nTask group two addresses the coexistence of wireless personal area networks (WPAN) with other wireless devices operating in unlicensed frequency bands such as wireless local area networks (WLAN). The IEEE 802.15.2-2003 standard was published in 2003 and task group two went into \"hibernation\".\nIEEE 802.15.3: High Rate WPAN.\nIEEE 802.15.3-2003.\nIEEE 802.15.3-2003 is a MAC and PHY standard for high-rate (11 to 55\u00a0Mbit/s) WPANs. The standard can be downloaded via the IEEE Get program, which is funded by IEEE 802 volunteers.\nIEEE 802.15.3a.\nIEEE P802.15.3a was an attempt to provide a higher speed ultra-wideband PHY enhancement amendment to IEEE 802.15.3 for applications that involve imaging and multimedia. The members of the task group were not able to come to an agreement choosing between two technology proposals, Multi-band Orthogonal Frequency Division Multiplexing (MB-OFDM) and Direct Sequence UWB (DS-UWB), backed by two different industry alliances and was withdrawn in January 2006. Documents related to the development of IEEE 802.15.3a are archived on the IEEE document server.\nIEEE 802.15.3b-2006.\nIEEE 802.15.3b-2005 amendment was released on May 5, 2006. It enhanced 802.15.3 to improve implementation and interoperability of the MAC. This amendment includes many optimizations, corrected errors, clarified ambiguities, and added editorial clarifications while preserving backward compatibility. Among other changes, the amendment defined the following new features:\nIEEE 802.15.3c-2009.\nIEEE 802.15.3c-2009 was published on September 11, 2009. The task group TG3c developed a millimeter-wave-based alternative physical layer (PHY) for the existing 802.15.3 Wireless Personal Area Network (WPAN) Standard 802.15.3-2003. The IEEE 802.15.3 Task Group 3c (TG3c) was formed in March 2005. This mmWave WPAN is defined to operate in the 57\u201366\u00a0GHz range. Depending on the geographical region, anywhere from 2 to 9\u00a0GHz of bandwidth is available (for example, 57\u201364\u00a0GHz is available as unlicensed band defined by FCC 47 CFR 15.255 in North America). The millimeter-wave WPAN allows very high data rate, short range (10 m) for applications including high-speed internet access, streaming content download (video on demand, HDTV, home theater, etc.), real-time streaming and wireless data bus for cable replacement. A total of three PHY modes were defined in the standard:\nIEEE 802.15.3d-2017.\nIEEE Std 802.15.3d-2017 defines an alternative physical layer (PHY) at the lower THz frequency range between 252\u00a0GHz and 325\u00a0GHz for switched point-to-point links is defined in this amendment. Two PHY modes are defined that enable data rates of up to 100\u00a0Gb/s using eight different bandwidths between 2.16\u00a0GHz and 69.12\u00a0GHz.\nIEEE 802.15.3e-2017.\nIEEE Std 802.15.3e-2017 provides an alternative physical layer (PHY) and a modified medium access control (MAC) layer is defined in this amendment. Two PHY modes have been defined that enable data rates up to 100\u00a0Gb/s using the 60\u00a0GHz band. MIMO and aggregation methods have been defined to increase the maximum achievable communication speeds. Stack acknowledgment has been defined to improve the medium access control (MAC) efficiency when used in a point-to-point (P2P) topology between two devices.\nIEEE 802.15.3f-2017.\nIEEE Std 802.15.3f-2017 extends the RF channelization of the millimeter wave PHYs to allow for use of the spectrum up to 71\u00a0GHz. 802.15.3f was initiated because several regulatory domains extended the licensed exempt 60\u00a0GHz bands up to 71\u00a0GHz. \nIEEE 802.15.4: Low Rate WPAN.\nIEEE 802.15.4-2003 (Low Rate WPAN) deals with low data rate but very long battery life (months or even years) and very low complexity. The standard defines both the physical (Layer 1) and data-link (Layer 2) layers of the OSI model. The first edition of the 802.15.4 standard was released in May 2003. Several standardized and proprietary networks (or mesh) layer protocols run over 802.15.4-based networks, including IEEE 802.15.5, Zigbee, Thread, 6LoWPAN, WirelessHART, and ISA100.11a.\nWPAN Low Rate Alternative PHY (4a).\nIEEE 802.15.4a (formally called IEEE 802.15.4a-2007) is an amendment to IEEE 802.15.4 specifying additional physical layers (PHYs) to the original standard. The principal interest was in providing higher precision ranging and localization capability (1 meter accuracy and better), higher aggregate throughput, adding scalability to data rates, longer range, and lower power consumption and cost. The selected baselines are two optional PHYs consisting of a UWB Pulse Radio (operating in unlicensed UWB spectrum) and a Chirp Spread Spectrum (operating in unlicensed 2.4\u00a0GHz spectrum). The Pulsed UWB Radio is based on Continuous Pulsed UWB technology (see C-UWB) and will be able to deliver communications and high precision ranging.\nRevision and Enhancement (4b).\nIEEE 802.15.4b was approved in June 2006 and was published in September 2006 as IEEE 802.15.4-2006. The IEEE 802.15 task group 4b was chartered to create a project for specific enhancements and clarifications to the IEEE 802.15.4-2003 standard, such as resolving ambiguities, reducing unnecessary complexity, increasing flexibility in security key usage, considerations for newly available frequency allocations, and others.\nPHY Amendment for China (4c).\nIEEE 802.15.4c was approved in 2008 and was published in January 2009. This defines a PHY amendment that adds new RF spectrum specifications to address the Chinese regulatory changes which have opened the 314-316\u00a0MHz, 430-434\u00a0MHz, and 779-787\u00a0MHz bands for Wireless PAN use within China.\nPHY and MAC Amendment for Japan (4d).\nThe IEEE 802.15 Task Group 4d was chartered to define an amendment to the 802.15.4-2006 standard. The amendment defines a new PHY and such changes to the MAC as are necessary to support a new frequency allocation (950\u00a0MHz -956\u00a0MHz) in Japan while coexisting with passive tag systems in the band.\nMAC Amendment for Industrial Applications (4e).\nThe IEEE 802.15 Task Group 4e is chartered to define a MAC amendment to the existing standard 802.15.4-2006. The intent of this amendment is to enhance and add functionality to the 802.15.4-2006 MAC to a) better support the industrial markets and b) permit compatibility with modifications being proposed within the Chinese WPAN. Specific enhancements were made to add channel hopping and a variable time slot option compatible with ISA100.11a. These changes were approved in 2011.\nPHY and MAC Amendment for Active RFID (4f).\nThe IEEE 802.15.4f Active RFID System Task Group is chartered to define new wireless Physical (PHY) layer(s) and enhancements to the 802.15.4-2006 standard MAC layer which are required to support new PHY(s) for active RFID system bi-directional and location determination applications.\nPHY Amendment for Smart Utility Networks (4g).\nIEEE 802.15.4g Smart Utility Networks (SUN) Task Group is chartered to create a PHY amendment to 802.15.4 to provide a standard that facilitates very large-scale process control applications such as the utility smart grid network capable of supporting large, geographically diverse networks with minimal infrastructure, with potentially millions of fixed endpoints. In 2012 they released the 802.15.4g radio standard.\nThe Telecommunications Industry Association TR-51 committee develops standards for similar applications.\nEnhanced Ultra Wideband (UWB) Physical Layers (PHYs) and Associated Ranging Techniques (4z).\nApproved in 2020, amendment to the UWB PHYs (e.g. with coding options) to increase accuracy and exchange ranging related information between the participating devices.\nIEEE 802.15.5: Mesh Networking.\nIEEE 802.15.5 provides the architectural framework enabling WPAN devices to promote interoperable, stable, and scalable wireless mesh networking. This standard is composed of two parts: low-rate WPAN mesh and high-rate WPAN mesh networks. The low-rate mesh is built on IEEE 802.15.4-2006 MAC, while the high rate mesh utilizes IEEE 802.15.3/3b MAC. The common features of both meshes include network initialization, addressing, and multi-hop unicasting. In addition, the low-rate mesh supports multicasting, reliable broadcasting, portability support, trace route and energy saving function, and the high-rate mesh supports multihop time-guaranteed service.\nMesh networking for IEEE 802.15.1 networks is beyond the scope of IEEE 802.15.5, and is instead carried out within the Bluetooth mesh working group.\nIEEE 802.15.6: Body Area Networks.\nIn December 2011, the IEEE 802.15.6 task group approved a draft of a standard for Body Area Network (BAN) technologies. The draft was approved on 22 July 2011 by Letter Ballot to start the Sponsor Ballot process. Task Group 6 was formed in November 2007 to focus on a low-power and short-range wireless standard to be optimized for devices and operation on, in, or around the human body (but not limited to humans) to serve a variety of applications including medical, consumer electronics, and personal entertainment.\nIEEE 802.15.7: Visible Light Communication.\nThe inaugural meeting for Task Group 7 was held during January 2009, where it was chartered to write standards for free-space optical communication using visible light. The 802.15.7-2011 Standard was published in September 2011. In 2015, a new task group was launched to revise the 802.15.7 standard, with several new PHY layers and MAC routines to support optical camera communications (OCC) and light fidelity (LiFi). As the new draft became too large, in March 2017, the 802.15 Working Group decided to continue 802.15.7 with OCC only, which is broadcast only, and to create a new task group 802.15.13 to work on a new standard for LiFi, which obviously needed a significantly revised MAC layer, besides new PHYs. The revision of 802.15.7-2018 was published in April 2019. In September 2020, a new PAR was approved, and a new task group started to work on a first amendment P802.15.7a aiming at increased data rate and longer range for OCC. \nIEEE P802.15.8: Peer Aware Communications.\nIEEE P802.15.8 received IEEE Standards Board approval on 29 March 2012 to form a Task Group to develop a standard for Peer Aware Communications (PAC) optimized for peer-to-peer and infrastructure-less communications with fully distributed coordination operating in bands below 11\u00a0GHz. The proposed standard is targeting data rates greater than 100\u00a0kbit/s with scalable data rates up to 10\u00a0Mbit/s. Features of the proposed include:\nThe draft standard is under development, more information can be found on the http://.\nIEEE P802.15.9: Key Management Protocol.\nIEEE P802.15.9 received IEEE Standards Board approval on 7 December 2011 to form a Task Group to develop a recommended practice for the transport of Key Management Protocol (KMP) datagrams. The recommended practice will define a message framework based on Information Elements as a transport method for key management protocol (KMP) datagrams and guidelines for the use of some existing KMPs with IEEE Std 802.15.4. The recommended practice will not create a new KMP.\nWhile IEEE Std 802.15.4 has always supported datagram security, it has not provided a mechanism for establishing the keys used by this feature. Lack of key management support in IEEE Std 802.15.4 can result in weak keys, which is a common avenue for attacking the security system. Adding KMP support is critical to a proper security framework. Some of the existing KMPs that it may address are IETF's PANA, HIP, IKEv2, IEEE Std 802.1X, and 4-Way-Handshake.\nThe draft recommended practice is under development, more information can be found on the http://.\nIEEE P802.15.10: Layer 2 Routing.\nIEEE P802.15.10 received IEEE Standards Board approval on 23 August 2013 to form a Task Group to develop a recommended practice for routing packets in dynamically changing 802.15.4 wireless networks (changes on the order of a minute time frame), with minimal impact to route handling. The goal is to extend the coverage area as the number of nodes\nincrease. The route related capabilities that the recommended practice will provide include the following:\nThe draft recommended practice is under development; more information can be found on the http://.\nIEEE 802.15.13: Multi-Gigabit/s Optical Wireless Communications.\nThe first meeting of Task Group 13 was held during March 2017, aiming at a new standard on light fidelity (LiFi), i.e. mobile communications by using the light. The aim is to address industrial applications, i.e. ultra-reliable, low-latency connectivity with negligible jitter for next-generation IoT. Compared to 802.15.7, the group decided to rewrite the standard entirely, based on existing and new contributions, to meet those targets. The group first worked on a low-power pulsed modulation PHY (PM-PHY) using On-Off-Keying (OOK) with frequency-domain equalization (FDE) and also a high-bandwidth PHY (HB-PHY) based on orthogonal frequency-division multiplexing (OFDM) adopted from ITU-T G.9991. The group also decided to implement mobility by considering access points in the infrastructure and mobile users in the service area as inputs and outputs of a distributed multiple-input multiple-output (D-MIMO) link. 802.15.13 supports D-MIMO natively with a minimalistic design, suitable for specialty applications. It is implementable on low-cost FPGAs and off-the-shelf computing hardware. The Working Group letter ballot and the IEEE SA Ballot were started in November 2019 and November 2020, respectively. Publication is expected mid of 2022.\nWireless Next Generation Standing Committee.\nThe IEEE P802.15 Wireless Next Generation Standing Committee (SCwng) is chartered to facilitate and stimulate presentations and discussions on new wireless related technologies that may be subject for new 802.15 standardization projects or to address the whole 802.15 work group with issues or concerns with techniques or technologies.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "14736", "revid": "7903804", "url": "https://en.wikipedia.org/wiki?curid=14736", "title": "IEEE 802", "text": "IEEE standards for local and metropolitan area networks\nIEEE 802 is a family of Institute of Electrical and Electronics Engineers (IEEE) standards for local area networks (LANs), personal area networks (PANs), and metropolitan area networks (MANs). The IEEE 802 LAN/MAN Standards Committee (LMSC) maintains these standards. The IEEE 802 family of standards has had twenty-four members, numbered 802.1 through 802.24, with a working group of the LMSC devoted to each. However, not all of these working groups are currently active.\nThe IEEE 802 standards are restricted to computer networks carrying variable-size packets, unlike cell relay networks, for example, in which data is transmitted in short, uniformly sized units called cells. Isochronous signal networks, in which data is transmitted as a steady stream of octets, or groups of octets, at regular time intervals, are also outside the scope of the IEEE 802 standards.\nThe number 802 has no significance: it was simply the next number in the sequence that the IEEE used for standards projects.\nThe services and protocols specified in IEEE 802 map to the lower two layers (data link and physical) of the seven-layer Open Systems Interconnection (OSI) networking reference model. IEEE 802 divides the OSI data link layer into two sub-layers: logical link control (LLC) and medium access control (MAC), as follows: \nEverything above LLC is explicitly out of scope for IEEE 802 (as \"upper layer protocols\", presumed to be parts of equally non-OSI Internet reference model).\nThe most widely used standards are for Ethernet, Bridging and Virtual Bridged LANs, Wireless LAN, Wireless PAN, Wireless MAN, Wireless Coexistence, Media Independent Handover Services, and Wireless RAN. \nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "14737", "revid": "194203", "url": "https://en.wikipedia.org/wiki?curid=14737", "title": "IEEE", "text": ""}
{"id": "14738", "revid": "910180", "url": "https://en.wikipedia.org/wiki?curid=14738", "title": "IEEE 1003", "text": ""}
{"id": "14739", "revid": "910180", "url": "https://en.wikipedia.org/wiki?curid=14739", "title": "IEEE 802.11", "text": "Wireless network standard\nIEEE 802.11 is part of the IEEE 802 set of local area network (LAN) technical standards, and specifies the set of medium access control (MAC) and physical layer (PHY) protocols for implementing wireless local area network (WLAN) computer communication. The standard and amendments provide the basis for wireless network products using the Wi-Fi brand and are the world's most widely used wireless computer networking standards. IEEE 802.11 is used in most home and office networks to allow laptops, printers, smartphones, and other devices to communicate with each other and access the Internet without connecting wires.\nThe standards are created and maintained by the Institute of Electrical and Electronics Engineers (IEEE) LAN/MAN Standards Committee (IEEE 802). The base version of the standard was released in 1997 and has had subsequent amendments. While each amendment is officially revoked when it is incorporated in the latest version of the standard, the corporate world tends to market to the revisions because they concisely denote the capabilities of their products. As a result, in the marketplace, each revision tends to become its own standard. 802.11x is a shorthand for \"any version of 802.11\", to avoid confusion with \"802.11\" used specifically for the original 1997 version.\nIEEE 802.11 uses various radio frequencies, including, but not limited to, 2.4\u00a0GHz, 5\u00a0GHz, 6\u00a0GHz, and 60\u00a0GHz frequency bands. Although IEEE 802.11 specifications list channels that might be used, the allowed radio frequency spectrum availability varies significantly by regulatory domain.\nThe protocols are typically used on a network stack in conjunction with IEEE 802.2, and are designed to interwork seamlessly with Ethernet, and are very often used to carry Internet Protocol traffic. IEEE 802.11 is also a basis for vehicle-based communication networks with IEEE 802.11p.\nGeneral description.\nThe 802.11 family consists of a series of half-duplex over-the-air modulation techniques that use the same basic protocol. The 802.11 protocol family employs carrier-sense multiple access with collision avoidance (CSMA/CA) whereby equipment listens to a channel for other users (including non 802.11 users) before transmitting each frame (some use the term \"packet\", which may be ambiguous: \"frame\" is more technically correct).\n802.11-1997 was the first wireless networking standard in the family, but 802.11b was the first widely accepted one, followed by 802.11a, 802.11g, 802.11n, 802.11ac, and 802.11ax. Other standards in the family (c\u2013f, h, j) are service amendments that are used to extend the current scope of the existing standard, which amendments may also include corrections to a previous specification.\n802.11b and 802.11g use the 2.4-GHz ISM band, operating in the United States under Part 15 of the U.S. Federal Communications Commission Rules and Regulations. 802.11n can also use that 2.4-GHz band. Because of this choice of frequency band, 802.11b/g/n equipment may occasionally suffer interference in the 2.4-GHz band from microwave ovens, cordless telephones, and Bluetooth devices. 802.11b and 802.11g control their interference and susceptibility to interference by using direct-sequence spread spectrum (DSSS) and orthogonal frequency-division multiplexing (OFDM) signaling methods, respectively.\n802.11a uses the 5\u00a0GHz U-NII band which, for much of the world, offers at least 23 non-overlapping, 20-MHz-wide channels. This is an advantage over the 2.4-GHz, ISM-frequency band, which offers only three non-overlapping, 20-MHz-wide channels where other adjacent channels overlap (see: list of WLAN channels). Better or worse performance with higher or lower frequencies (channels) may be realized, depending on the environment. 802.11n and 802.11ax can use either the 2.4\u00a0GHz or 5\u00a0GHz band; 802.11ac uses only the 5\u00a0GHz band.\nThe segment of the radio frequency spectrum used by 802.11 varies between countries. In the US, 802.11a and 802.11g devices may be operated without a license, as allowed in Part 15 of the FCC Rules and Regulations. Frequencies used by channels one through six of 802.11b and 802.11g fall within the 2.4\u00a0GHz amateur radio band. Licensed amateur radio operators may operate 802.11b/g devices under Part 97 of the FCC Rules and Regulations, allowing increased power output but not commercial content or encryption.\nGenerations.\n&lt;templatestyles src=\"template:row hover highlight/styles.css\"/&gt;\nIn 2018, the Wi-Fi Alliance began using a consumer-friendly generation numbering scheme for the publicly used 802.11 protocols. Wi-Fi generations 1\u20138 use the 802.11b, 802.11a, 802.11g, 802.11n, 802.11ac, 802.11ax, 802.11be and 802.11bn protocols, in that order.\nHistory.\n802.11 technology has its origins in a 1985 ruling by the U.S. Federal Communications Commission that released the ISM band for unlicensed use.\nIn 1991 NCR Corporation/AT&amp;T (now Nokia Labs and LSI Corporation) invented a precursor to 802.11 in Nieuwegein, the Netherlands. The inventors initially intended to use the technology for cashier systems. The first wireless products were brought to the market under the name WaveLAN with raw data rates of 1 Mbit/s and 2 Mbit/s.\nVic Hayes, who held the chair of IEEE 802.11 for 10 years, and has been called the \"father of Wi-Fi\", was involved in designing the initial 802.11b and 802.11a standards within the IEEE. He, along with Bell Labs Engineer Bruce Tuch, approached IEEE to create a standard.\nIn 1999, the Wi-Fi Alliance was formed as a trade association to hold the Wi-Fi trademark under which most products are sold.\nThe major commercial breakthrough came with Apple's adoption of Wi-Fi for their iBook series of laptops in 1999. It was the first mass consumer product to offer Wi-Fi network connectivity, which was then branded by Apple as AirPort. One year later IBM followed with its ThinkPad 1300 series in 2000.\nProtocol.\n&lt;templatestyles src=\"template:row hover highlight/styles.css\"/&gt;\n802.11-1997 (802.11 legacy).\nThe original version of the standard IEEE 802.11 was released in 1997 and clarified in 1999, but is now obsolete. It specified two net bit rates of 1 or 2 megabits per second (Mbit/s), plus forward error correction code. It specified three alternative physical layer technologies: diffuse infrared operating at 1 Mbit/s; frequency-hopping spread spectrum operating at 1 Mbit/s or 2 Mbit/s; and direct-sequence spread spectrum operating at 1 Mbit/s or 2 Mbit/s. The latter two radio technologies used microwave transmission over the Industrial Scientific Medical frequency band at 2.4\u00a0GHz. Some earlier WLAN technologies used lower frequencies, such as the U.S. 900\u00a0MHz ISM band.\nLegacy 802.11 with direct-sequence spread spectrum was rapidly supplanted and popularized by 802.11b.\n802.11a (OFDM waveform).\n802.11a, published in 1999, uses the same data link layer protocol and frame format as the original standard, but an OFDM based air interface (physical layer) was added.\nIt operates in the 5\u00a0GHz band with a maximum net data rate of 54 Mbit/s, plus error correction code, which yields realistic net achievable throughput in the mid-20\u00a0Mbit/s. It has seen widespread worldwide implementation, particularly within the corporate workspace.\nSince the 2.4\u00a0GHz band is heavily used to the point of being crowded, using the relatively unused 5\u00a0GHz band gives 802.11a a significant advantage. However, this high carrier frequency also brings a disadvantage: the effective overall range of 802.11a is less than that of 802.11b/g. In theory, 802.11a signals are absorbed more readily by walls and other solid objects in their path due to their smaller wavelength, and, as a result, cannot penetrate as far as those of 802.11b. In practice, 802.11b typically has a higher range at low speeds (802.11b will reduce speed to 5.5 Mbit/s or even 1 Mbit/s at low signal strengths). 802.11a also suffers from interference, but locally there may be fewer signals to interfere with, resulting in less interference and better throughput.\n802.11b.\nThe 802.11b standard has a maximum raw data rate of 11 Mbit/s (Megabits per second) and uses the same media access method defined in the original standard. 802.11b products appeared on the market in early 2000, since 802.11b is a direct extension of the modulation technique defined in the original standard. The dramatic increase in throughput of 802.11b (compared to the original standard) along with simultaneous substantial price reductions led to the rapid acceptance of 802.11b as the definitive wireless LAN technology.\nDevices using 802.11b experience interference from other products operating in the 2.4\u00a0GHz band. Devices operating in the 2.4\u00a0GHz range include microwave ovens, Bluetooth devices, baby monitors, cordless telephones, and some amateur radio equipment. As unlicensed intentional radiators in this ISM band, they must not interfere with and must tolerate interference from primary or secondary allocations (users) of this band, such as amateur radio.\n802.11g.\nIn June 2003, a third modulation standard was ratified: 802.11g. This works in the 2.4\u00a0GHz band (like 802.11b), but uses the same OFDM based transmission scheme as 802.11a. It operates at a maximum physical layer bit rate of 54 Mbit/s exclusive of forward error correction codes, or about 22 Mbit/s average throughput. 802.11g hardware is fully backward compatible with 802.11b hardware, and therefore is encumbered with legacy issues that reduce throughput by ~21% when compared to 802.11a.\nThe then-proposed 802.11g standard was rapidly adopted in the market starting in January 2003, well before ratification, due to the desire for higher data rates as well as reductions in manufacturing costs. By summer 2003, most dual-band 802.11a/b products became dual-band/tri-mode, supporting a and b/g in a single mobile adapter card or access point. Details of making b and g work well together occupied much of the lingering technical process; in an 802.11g network, however, the activity of an 802.11b participant will reduce the data rate of the overall 802.11g network.\nLike 802.11b, 802.11g devices also suffer interference from other products operating in the 2.4\u00a0GHz band, for example, wireless keyboards.\n802.11-2007.\nIn 2003, task group TGma was authorized to \"roll up\" many of the amendments to the 1999 version of the 802.11 standard. REVma or 802.11ma, as it was called, created a single document that merged 8 amendments (802.11a, b, d, e, g, h, i, j) with the base standard. Upon approval on 8 March 2007, 802.11REVma was renamed to the then-current base standard IEEE 802.11-2007.\n802.11n.\n802.11n is an amendment that improves upon the previous 802.11 standards; its first draft of certification was published in 2006. The 802.11n standard was retroactively labelled as Wi-Fi 4 by the Wi-Fi Alliance. The standard added support for multiple-input multiple-output antennas (MIMO). 802.11n operates on both the 2.4\u00a0GHz and the 5\u00a0GHz bands. Support for 5\u00a0GHz bands is optional. Its net data rate ranges from 54 Mbit/s to 600 Mbit/s. The IEEE has approved the amendment, and it was published in October 2009. \nPrior to the final ratification, enterprises were already migrating to 802.11n networks based on the Wi-Fi Alliance's certification of products conforming to a 2007 draft of the 802.11n proposal. Early Intel WiFi cards were not compatible with the final standard. Many rival access points and cards also did not support 5\u00a0GHz at all.\n802.11-2012.\nIn May 2007, task group TGmb was authorized to \"roll up\" many of the amendments to the 2007 version of the 802.11 standard. REVmb or 802.11mb, as it was called, created a single document that merged ten amendments (802.11k, r, y, n, w, p, z, v, u, s) with the 2007 base standard. In addition much cleanup was done, including a reordering of many of the clauses. Upon publication on 29 March 2012, the new standard was referred to as IEEE 802.11-2012.\n802.11ac.\nIEEE 802.11ac-2013 is an amendment to IEEE 802.11, published in December 2013, that builds on 802.11n. The 802.11ac standard was retroactively labelled as Wi-Fi 5 by the Wi-Fi Alliance. Changes compared to 802.11n include wider channels (80 or 160\u00a0MHz versus 40\u00a0MHz) in the 5\u00a0GHz band, more spatial streams (up to eight versus four), higher-order modulation (up to 256-QAM vs. 64-QAM), and the addition of Multi-user MIMO (MU-MIMO). The Wi-Fi Alliance separated the introduction of ac wireless products into two phases (\"waves\"), named \"Wave 1\" and \"Wave 2\". From mid-2013, the alliance started certifying Wave 1 802.11ac products shipped by manufacturers, based on the IEEE 802.11ac Draft 3.0 (the IEEE standard was not finalized until later that year). In 2016 Wi-Fi Alliance introduced the Wave 2 certification, to provide higher bandwidth and capacity than Wave 1 products. Wave 2 products include additional features like MU-MIMO, 160\u00a0MHz channel width support, support for more 5\u00a0GHz channels, and four spatial streams (with four antennas; compared to three in Wave 1 and 802.11n, and eight in IEEE's 802.11ax specification).\n802.11ad.\nIEEE 802.11ad is an amendment that defines a new physical layer for 802.11 networks to operate in the 60\u00a0GHz millimeter wave spectrum. This frequency band has significantly different propagation characteristics than the 2.4\u00a0GHz and 5\u00a0GHz bands where Wi-Fi networks operate. Products implementing the 802.11ad standard are sold under the WiGig brand name, with a certification program developed by the Wi-Fi Alliance. The peak transmission rate of 802.11ad is 7 Gbit/s.\nIEEE 802.11ad is a protocol used for very high data rates (about 8 Gbit/s) and for short range communication (about 1\u201310 meters).\nTP-Link announced the world's first 802.11ad router in January 2016.\nThe WiGig standard as of 2021 has been published after being announced in 2009 and added to the IEEE 802.11 family in December 2012.\n802.11af.\nIEEE 802.11af, also referred to as \"White-Fi\" and \"Super Wi-Fi\", is an amendment, approved in February 2014, that allows WLAN operation in TV white space spectrum in the VHF and UHF bands between 54 and 790\u00a0MHz. It uses cognitive radio technology to transmit on unused TV channels, with the standard taking measures to limit interference for primary users, such as analog TV, digital TV, and wireless microphones. Access points and stations determine their position using a satellite positioning system such as GPS, and use the Internet to query a geolocation database (GDB) provided by a regional regulatory agency to discover what frequency channels are available for use at a given time and position. The physical layer uses OFDM and is based on 802.11ac. The propagation path loss as well as the attenuation by materials such as brick and concrete is lower in the UHF and VHF bands than in the 2.4\u00a0GHz and 5\u00a0GHz bands, which increases the possible range. The frequency channels are 6 to 8\u00a0MHz wide, depending on the regulatory domain. Up to four channels may be bonded in either one or two contiguous blocks. MIMO operation is possible with up to four streams used for either space\u2013time block code (STBC) or multi-user (MU) operation. The achievable data rate per spatial stream is 26.7 Mbit/s for 6 and 7\u00a0MHz channels, and 35.6 Mbit/s for 8\u00a0MHz channels. With four spatial streams and four bonded channels, the maximum data rate is 426.7 Mbit/s for 6 and 7\u00a0MHz channels and 568.9 Mbit/s for 8\u00a0MHz channels.\n802.11-2016.\nIEEE 802.11-2016 which was known as IEEE 802.11 REVmc, is a revision based on IEEE 802.11-2012, incorporating 5 amendments (11ae, 11aa, 11ad, 11ac, 11af). In addition, existing MAC and PHY functions have been enhanced and obsolete features were removed or marked for removal. Some clauses and annexes have been renumbered.\n802.11ah.\nIEEE 802.11ah, published in 2017, defines a WLAN system operating at sub-1\u00a0GHz license-exempt bands. Due to the favorable propagation characteristics of the low-frequency spectra, 802.11ah can provide improved transmission range compared with the conventional 802.11 WLANs operating in the 2.4\u00a0GHz and 5\u00a0GHz\u00a0bands. 802.11ah can be used for various purposes including large-scale sensor networks, extended-range hotspots, and outdoor Wi-Fi for cellular WAN carrier traffic offloading, whereas the available bandwidth is relatively narrow. The protocol intends consumption to be competitive with low-power Bluetooth, at a much wider range.\n802.11ai.\nIEEE 802.11ai is an amendment to the 802.11 standard that added new mechanisms for a faster initial link setup time.\n802.11aj.\nIEEE 802.11aj is a derivative of 802.11ad for use in the 45\u00a0GHz unlicensed spectrum available in some regions of the world (specifically China); it also provides additional capabilities for use in the 60\u00a0GHz band.\nAlternatively known as China Millimeter Wave (CMMW).\n802.11aq.\nIEEE 802.11aq is an amendment to the 802.11 standard that will enable pre-association discovery of services. This extends some of the mechanisms in 802.11u that enabled device discovery to discover further the services running on a device, or provided by a network.\n802.11-2020.\nIEEE 802.11-2020, which was known as IEEE 802.11 REVmd, is a revision based on IEEE 802.11-2016 incorporating 5 amendments (11ai, 11ah, 11aj, 11ak, 11aq). In addition, existing MAC and PHY functions have been enhanced and obsolete features were removed or marked for removal. Some clauses and annexes have been added.\n802.11ax.\nIEEE 802.11ax is the successor to 802.11ac, marketed as Wi-Fi 6 (2.4\u00a0GHz and 5\u00a0GHz) and Wi-Fi 6E (6\u00a0GHz) by the Wi-Fi Alliance. It is also known as \"High Efficiency\" Wi-Fi, for the overall improvements to Wi-Fi 6 clients in \"dense environments\". For an individual client, the maximum improvement in data rate (PHY speed) against the predecessor (802.11ac) is only 39% (for comparison, this improvement was nearly 500% for the predecessors). Yet, even with this comparatively minor 39% figure, the goal was to provide \"4 times\" the throughput-per-area of 802.11ac (hence \"High Efficiency\"). The motivation behind this goal was the deployment of WLAN in dense environments such as corporate offices, shopping malls and dense residential apartments. This is achieved by means of a technique called OFDMA, which is basically multiplexing in the \"frequency domain\" (as opposed to \"spatial\" multiplexing, as in 802.11ac). This is equivalent to cellular technology applied into Wi-Fi.\nThe IEEE 802.11ax\u20112021 standard was approved on February 9, 2021.\n802.11ay.\nIEEE 802.11ay is a standard that is being developed, also called EDMG: Enhanced Directional MultiGigabit PHY. It is an amendment that defines a new physical layer for 802.11 networks to operate in the 60\u00a0GHz millimeter wave spectrum. It will be an extension of the existing 11ad, aimed to extend the throughput, range, and use-cases. The main use-cases include indoor operation and short-range communications due to atmospheric oxygen absorption and inability to penetrate walls. The peak transmission rate of 802.11ay is 40 Gbit/s. The main extensions include: channel bonding (2, 3 and 4), MIMO (up to 4 streams) and higher modulation schemes. The expected range is 300\u2013500 m.\n802.11ba.\nIEEE 802.11ba Wake-up Radio (WUR) Operation is an amendment to the IEEE 802.11 standard that enables energy-efficient operation for data reception without increasing latency. The target active power consumption to receive a WUR packet is less than 1 milliwatt and supports data rates of 62.5 kbit/s and 250 kbit/s. The WUR PHY uses MC-OOK (multicarrier OOK) to achieve extremely low power consumption.\n802.11bb.\nIEEE 802.11bb is a networking protocol standard in the IEEE 802.11 set of protocols that uses infrared light for communications.\n802.11be.\nIEEE 802.11be Extremely High Throughput (EHT) is the next amendment to the 802.11 IEEE standard, and is designated as Wi-Fi 7. It builds upon 802.11ax, focusing on WLAN indoor and outdoor operation with stationary and pedestrian speeds in the 2.4\u00a0GHz, 5\u00a0GHz, and 6\u00a0GHz frequency bands.\nCommon misunderstandings about achievable throughput.\nAcross all variations of 802.11, maximum achievable throughputs are given either based on measurements under ideal conditions or in the layer-2 data rates. However, this does not apply to typical deployments in which data is being transferred between two endpoints, of which at least one is typically connected to a wired infrastructure and the other endpoint is connected to an infrastructure via a wireless link.\nThis means that, typically, data frames pass an 802.11 (WLAN) medium and are being converted to 802.3 (Ethernet) or vice versa. Due to the difference in the frame (header) lengths of these two media, the application's packet size determines the speed of the data transfer. This means applications that use small packets (e.g., VoIP) create dataflows with high-overhead traffic (i.e., a low goodput). Other factors that contribute to the overall application data rate are the speed with which the application transmits the packets (i.e., the data rate) and, of course, the energy with which the wireless signal is received. The latter is determined by distance and by the configured output power of the communicating devices.\nThe same references apply to the attached graphs that show measurements of UDP throughput. Each represents an average (UDP) throughput (please note that the error bars are there but barely visible due to the small variation) of 25 measurements. Each is with a specific packet size (small or large) and with a specific data rate (10 kbit/s \u2013 100 Mbit/s). Markers for traffic profiles of common applications are included as well. These figures assume there are no packet errors, which, if occurring, will lower the transmission rate further.\nChannels and frequencies.\n802.11b, 802.11g, and 802.11n-2.4 utilize the 2.400\u20132.500 GHz spectrum, one of the ISM bands. 802.11a, 802.11n, and 802.11ac use the more heavily regulated 4.915\u20135.825 GHz band. These are commonly referred to as the \"2.4\u00a0GHz and 5\u00a0GHz bands\" in most sales literature. Each spectrum is sub-divided into \"channels\" with a center frequency and bandwidth, analogous to how radio and TV broadcast bands are sub-divided.\nThe 2.4\u00a0GHz band is divided into 14 channels spaced 5\u00a0MHz apart, beginning with channel\u00a01, which is centered on 2.412\u00a0GHz. The latter channels have additional restrictions or are unavailable for use in some regulatory domains.\nThe channel numbering of the 5.725\u20135.875 GHz spectrum is less intuitive due to the differences in regulations between countries. These are discussed in greater detail on the list of WLAN channels.\nChannel spacing within the 2.4\u00a0GHz band.\nIn addition to specifying the channel center frequency, 802.11 also specifies (in Clause 17) a spectral mask defining the permitted power distribution across each channel. The mask requires the signal to be attenuated a minimum of 20\u00a0dB from its peak amplitude at \u00b111\u00a0MHz from the center frequency, the point at which a channel is effectively 22\u00a0MHz wide. One consequence is that stations can use only every fourth or fifth channel without overlap.\nAvailability of channels is regulated by country, constrained in part by how each country allocates radio spectrum to various services. At one extreme, Japan permits the use of all 14 channels for 802.11b, and 1\u201313 for 802.11g/n-2.4. Other countries such as Spain initially allowed only channels 10 and 11, and France allowed only 10, 11, 12, and 13; however, Europe now allow channels 1 through 13. North America and some Central and South American countries allow only 1 through 11.\nSince the spectral mask defines only power output restrictions up to \u00b111\u00a0MHz from the center frequency to be attenuated by \u221250\u00a0dBr, it is often assumed that the energy of the channel extends no further than these limits. It is more correct to say that the overlapping signal on any channel should be sufficiently attenuated to interfere with a transmitter on any other channel minimally, given the separation between channels. Due to the near\u2013far problem a transmitter can impact (desensitize) a receiver on a \"non-overlapping\" channel, but only if it is close to the victim receiver (within a meter) or operating above allowed power levels. Conversely, a sufficiently distant transmitter on an overlapping channel can have little to no significant effect.\nConfusion often arises over the amount of channel separation required between transmitting devices. 802.11b was based on direct-sequence spread spectrum (DSSS) modulation and utilized a channel bandwidth of 22\u00a0MHz, resulting in \"three\" \"non-overlapping\" channels (1, 6, and 11). 802.11g was based on OFDM modulation and utilized a channel bandwidth of 20\u00a0MHz. This occasionally leads to the belief that \"four\" \"non-overlapping\" channels (1, 5, 9, and 13) exist under 802.11g. However, this is not the case as per 17.4.6.3 Channel Numbering of operating channels of the IEEE Std 802.11 (2012), which states, \"In a multiple cell network topology, overlapping and/or adjacent cells using different channels can operate simultaneously without interference if the distance between the center frequencies is at least 25\u00a0MHz.\"\nand section 18.3.9.3 and Figure 18-13.\nThis does not mean that the technical overlap of the channels recommends the non-use of overlapping channels. The amount of inter-channel interference seen on a configuration using channels 1, 5, 9, and 13 (which is permitted in Europe, but not in North America) is barely different from a three-channel configuration, but with an entire extra channel.\nHowever, overlap between channels with more narrow spacing (e.g. 1, 4, 7, 11 in North America) may cause unacceptable degradation of signal quality and throughput, particularly when users transmit near the boundaries of AP cells.\nRegulatory domains and legal compliance.\nIEEE uses the phrase \"regdomain\" to refer to a legal regulatory region. Different countries define different levels of allowable transmitter power, time that a channel can be occupied, and different available channels. Domain codes are specified for the United States, Canada, ETSI (Europe), Spain, France, Japan, and China.\nMost Wi-Fi certified devices default to \"regdomain\" 0, which means least common denominator settings, i.e., the device will not transmit at a power above the allowable power in any nation, nor will it use frequencies that are not permitted in any nation.\nThe \"regdomain\" setting is often made difficult or impossible to change so that the end-users do not conflict with local regulatory agencies such as the United States' Federal Communications Commission.\nLayer 2 \u2013 Datagrams.\nThe datagrams are called \"frames\". Current 802.11 standards specify frame types for use in the transmission of data as well as management and control of wireless links.\nFrames are divided into very specific and standardized sections. Each frame consists of a \"MAC header\", \"payload\", and \"frame check sequence\" (FCS). Some frames do not have payloads.\nThe first two bytes of the MAC header form a frame control field specifying the form and function of the frame. This frame control field is subdivided into the following sub-fields:\nThe next two bytes are reserved for the Duration ID field, indicating how long the field's transmission will take so other devices know when the channel will be available again. This field can take one of three forms: Duration, Contention-Free Period (CFP), and Association ID (AID).\nAn 802.11 frame can have up to four address fields. Each field can carry a MAC address. Address 1 is the receiver, Address 2 is the transmitter, Address 3 is used for filtering purposes by the receiver. Address 4 is only present in data frames transmitted between access points in an Extended Service Set or between intermediate nodes in a mesh network.\nThe remaining fields of the header are:\nThe payload or frame body field is variable in size, from 0 to 2304 bytes plus any overhead from security encapsulation, and contains information from higher layers.\nThe Frame Check Sequence (FCS) is the last four bytes in the standard 802.11 frame. Often referred to as the Cyclic Redundancy Check (CRC), it allows for integrity checks of retrieved frames. As frames are about to be sent, the FCS is calculated and appended. When a station receives a frame, it can calculate the FCS of the frame and compare it to the one received. If they match, it is assumed that the frame was not distorted during transmission.\nManagement frames.\nManagement frames are not always authenticated, and allow for the maintenance, or discontinuance, of communication. Some common 802.11 subtypes include:\nThe body of a management frame consists of frame-subtype-dependent fixed fields followed by a sequence of information elements (IEs).\nThe common structure of an IE is as follows:\nControl frames.\nControl frames facilitate the exchange of data frames between stations. Some common 802.11 control frames include:\nData frames.\nData frames carry packets from web pages, files, etc. within the body. The body begins with an IEEE 802.2 header, with the Destination Service Access Point (DSAP) specifying the protocol, followed by a Subnetwork Access Protocol (SNAP) header if the DSAP is hex AA, with the organizationally unique identifier (OUI) and protocol ID (PID) fields specifying the protocol. If the OUI is all zeroes, the protocol ID field is an EtherType value. Almost all 802.11 data frames use 802.2 and SNAP headers, and most use an OUI of 00:00:00 and an EtherType value.\nSimilar to TCP congestion control on the internet, frame loss is built into the operation of 802.11. To select the correct transmission speed or Modulation and Coding Scheme, a rate control algorithm may test different speeds. The actual packet loss rate of Access points varies widely for different link conditions. There are variations in the loss rate experienced on production Access points, between 10% and 80%, with 30% being a common average. It is important to be aware that the link layer should recover these lost frames. If the sender does not receive an Acknowledgement (ACK) frame, then it will be resent.\nStandards and amendments.\nWithin the IEEE 802.11 Working Group, the following IEEE Standards Association Standards and Amendments exist:\nIn process.\n802.11F and 802.11T are recommended practices rather than standards and are capitalized as such.\n802.11m is used for standard maintenance. 802.11ma was completed for 802.11-2007, 802.11mb for 802.11-2012, 802.11mc for 802.11-2016, 802.11md for 802.11-2020, and 802.11me for 802.11-2024.\nStandard vs. amendment.\nBoth the terms \"standard\" and \"amendment\" are used when referring to the different variants of IEEE standards.\nAs far as the IEEE Standards Association is concerned, there is only one current standard; it is denoted by IEEE 802.11 followed by the date published. IEEE 802.11-2024 is the only version currently in publication, superseding previous releases. The standard is updated by means of amendments. Amendments are created by task groups (TG). Both the task group and their finished document are denoted by 802.11 followed by one or two lower case letters, for example, IEEE 802.11a or IEEE 802.11ax. Updating 802.11 is the responsibility of task group m. In order to create a new version, TGm combines the previous version of the standard and all published amendments. TGm also provides clarification and interpretation to industry on published documents. New versions of the IEEE 802.11 were published in 1999, 2007, 2012, 2016, 2020, and 2024.\nNomenclature.\nVarious terms in 802.11 are used to specify aspects of wireless local-area networking operation and may be unfamiliar to some readers.\nFor example, \"time unit\" (usually abbreviated \"TU\") is used to indicate a unit of time equal to 1024 microseconds. Numerous time constants are defined in terms of TU (rather than the nearly equal millisecond).\nAlso, the term \"portal\" is used to describe an entity that is similar to an 802.1H bridge. A portal provides access to the WLAN by non-802.11 LAN STAs.\nSecurity.\nIn 2001, a group from the University of California, Berkeley presented a paper describing weaknesses in the 802.11 Wired Equivalent Privacy (WEP) security mechanism defined in the original standard; they were followed by Fluhrer, Mantin, and Shamir's paper titled \"Weaknesses in the Key Scheduling Algorithm of RC4\". Not long after, Adam Stubblefield and AT&amp;T publicly announced the first verification of the attack. In the attack, they were able to intercept transmissions and gain unauthorized access to wireless networks.\nThe IEEE set up a dedicated task group to create a replacement security solution, 802.11i (previously, this work was handled as part of a broader 802.11e effort to enhance the MAC layer). The Wi-Fi Alliance announced an interim specification called Wi-Fi Protected Access (WPA) based on a subset of the then-current IEEE 802.11i draft. These started to appear in products in mid-2003. IEEE 802.11i (also known as WPA2) itself was ratified in June 2004, and uses the Advanced Encryption Standard (AES), instead of RC4, which was used in WEP. The modern recommended encryption for the home/consumer space is WPA2 (AES Pre-Shared Key), and for the enterprise space is WPA2 along with a RADIUS authentication server (or another type of authentication server) and a strong authentication method such as EAP-TLS.\nIn January 2005, the IEEE set up yet another task group \"w\" to protect management and broadcast frames, which previously were sent unsecured. Its standard was published in 2009.\nIn December 2011, a security flaw was revealed that affects some wireless routers with a specific implementation of the optional Wi-Fi Protected Setup (WPS) feature. While WPS is not a part of 802.11, the flaw allows an attacker within the range of the wireless router to recover the WPS PIN and, with it, the router's 802.11i password in a few hours.\nIn late 2014, Apple announced that its iOS\u00a08 mobile operating system would scramble MAC addresses during the pre-association stage to thwart retail footfall tracking made possible by the regular transmission of uniquely identifiable probe requests. Android 8.0 \"Oreo\" introduced a similar feature, named \"MAC randomization\".\nWi-Fi users may be subjected to a Wi-Fi deauthentication attack to eavesdrop, attack passwords, or force the use of another, usually more expensive access point.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFootnotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "14740", "revid": "1313889556", "url": "https://en.wikipedia.org/wiki?curid=14740", "title": "Initialism", "text": ""}
{"id": "14741", "revid": "40544698", "url": "https://en.wikipedia.org/wiki?curid=14741", "title": "Irn-Bru", "text": "Scottish carbonated soft drink\nIrn-Bru ( \"iron brew\", ) is a Scottish carbonated soft drink, often described as \"Scotland's other national drink\" after Scotch whisky. Introduced in 1901, the drink is produced in Westfield, Cumbernauld, North Lanarkshire, by A.G. Barr of Glasgow. As well as being sold throughout the United Kingdom, Irn-Bru is available throughout the world and can usually be bought where there is a significant community of people from Scotland. The brand also has its own tartan. It has been the top-selling soft drink in Scotland for over a century, competing directly with global brands such as Coca-Cola.\nThe flavour of Irn-Bru is known to be difficult to describe, a fact that has even been used in the manufacturers' advertising. Public surveys have turned up words such as Tutti Frutti, bubble gum, cream soda, and even an undertone of iron or rust that has been referred to as 'girders'.\nOriginally selling it as Iron Brew, the drink's makers, A.G. Barr, were forced to change the name of the drink in 1946 following a change in the law that stipulated that the marketing of products be \"literally true\". As the drink did not contain much iron, nor was it brewed, the passage of this legislation led the company to change the product's name to the presently used Irn-Bru. Irn-Bru has long been the most popularly consumed soft drink in Scotland, consistently beating rivals such as Coca-Cola, Pepsi and Fanta, and reportedly sells 20 cans every second throughout Scotland. Irn-Bru is sold in a number of international food and drink markets, including countries such as the Netherlands, Spain, Belgium, Malta, certain countries of the African continent, the Middle East, and North America.\nOverview and history.\nAppearance and overview.\nIrn-Bru is known for its bright orange colour and unique flavour. As of 1999, it contained 0.002% of ammonium ferric citrate, sugar, 32 flavouring agents including caffeine and quinine (but not in Australia), and two controversial colourings (Sunset Yellow FCF E110 and Ponceau 4R E124). On 27 January 2010, soft-drink manufacturer A.G. Barr agreed to a Food Standards Agency voluntary ban on these two colourings although no date was set for their replacement.\nAfter lobbying by First Minister of Scotland Alex Salmond, a proposed restriction of Sunset Yellow to 10\u00a0mg/litre was eased to 20\u00a0mg/litre in 2011 \u2013 the same amount present in Irn-Bru. As of August 2024, Irn-Bru still contains these colourings.\nOrigins.\nThe first Iron Brew drink was produced by the Maas &amp; Waldstein chemicals company of New York in 1889 under the name IRONBREW. The drink was popular across North America and was widely copied. A similar beverage was launched in 1898 by London essence firm Stevenson &amp; Howell that supplied soft drinks manufacturers in the UK and colonies. Many local bottlers around the UK began selling their own version of the beverage.\nDespite the official launch date for Barr's Iron Brew being given as 1901, the firms AG Barr &amp; Co (Glasgow) and Robert Barr (Falkirk) jointly launched their own Iron Brew drink at least two years earlier, according to a document in the firm's archives which indicates that the drink was already enjoying strong sales by May 1899. The strongman image which Barr's adopted for their bottle labels and advertising had been trademarked by the firm Stevenson &amp; Howell in 1898. Barr's ordered their labels directly from Stevenson &amp; Howell, which also sold Barr's many of the individual flavours with which they mixed their own drinks. An advertisement for Barr's Iron Brew dated 1900 featuring the original strongman label can be found in Falkirk's Local History Archives.\nTrademark.\nBarr's trademark application for the brand name Irn-Bru dates from July 1946 when the drink was still off sale because of wartime regulations. The firm first commercialised their drink using this new name in 1948 once government SDI consolidation of the soft drinks industry had ended. The name change followed the introduction of new labelling restrictions which cracked down on spurious health claims and introduced minimum standards for drinks claiming to contain minerals such as iron. However, according to Robert Barr OBE (chairman 1947\u20131978), there was also a commercial rationale behind the unusual spelling. \"Iron Brew\" had come to be understood as a generic product category in the UK, whereas adopting the name \"Irn-Bru\" allowed the firm to have a legally protected brand identity that would enable the firm to benefit from the popularity of their wartime \"Adventures of Ba-Bru\" comic strip advertising. (The \"Iron Brew\" name has continued to be used for many versions of the drink sold by rival manufacturers.)\nPopularity and new variants.\n1980 saw the introduction of Low Calorie Irn-Bru: this was re-launched in 1991 as Diet Irn-Bru and again in 2011 as Irn-Bru Sugar Free. The Irn-Bru 32 energy drink variant was launched in 2006, but was discontinued shortly after.\nIrn-Bru has long been the most popular soft drink in Scotland, with Coca-Cola second, but competition between the two brands brought their sales to roughly equal levels by 2003. It is also the third best selling soft drink in the UK, after Coca-Cola and Pepsi, outselling high-profile brands such as Fanta, Dr Pepper, Sprite and 7 Up. This success in defending its home market (a feat claimed only by Irn-Bru, Inca Kola and Thums Up; Thums Up sold out to Coca-Cola in 1993, and Inka Kola owners Corporaci\u00f3n Lindley S.A. entered into a joint venture with Coca-Cola in 1999, giving up all rights to the name outside Peru) led to ongoing speculation that Coca-Cola, PepsiCo, Inc. or its UK brand franchisee Britvic would attempt to buy A.G. Barr. In November 2012 AG Barr and Britvic announced a merger proposal, but in July 2013 the merger collapsed when terms could not be agreed.\nIrn-Bru's advertising slogans used to be 'Scotland's other National Drink', referring to whisky, and 'Made in Scotland from girders', a reference to the rusty colour of the drink; though the closest one can come to substantiating this claim is the 0.002% ammonium ferric citrate listed in the ingredients.\nFiery Irn-Bru, a limited edition variant, was released in autumn 2011. It was packaged with a black and orange design, and with the signature man icon with an added image of a fire. It featured the traditional Irn-Bru flavour with an aftertaste similar to ginger.\nIrn-Bru was also sold in reusable 750 ml glass bottles which, like other Barr's drinks, were able to be returned to the manufacturer in exchange for a 30 pence (previously 20p) deposit paid on purchase. This scheme was widely available in shops across Scotland and led to the colloquial term for an empty: a \"glass cheque\". As a result of a 40% drop in returned bottles since the 1990s Barr deemed the washing and re-filling process uneconomical, and on 1 January 2016 ceased the scheme.\nNew logo.\n2016 saw the introduction of the current logo, conveying \"strength\" and an \"industrial feel\", and a new diet variant called Irn-Bru Xtra in different branding to the existing sugar free variety in a similar fashion to Coca-Cola Zero and Pepsi Max.\nBarr changed the formula of Irn-Bru in January 2018 in response to a sugar tax implemented in the UK in April 2018, intended to combat obesity. By reducing the sugar content to less than 5g per 100ml, Barr has made Irn-Bru exempt from the tax. The manufacturer asserted that \"most people will not be able to tell the difference in flavour between the old and new formulas\", but fans of the drink launched an unsuccessful 'Save Real Irn-Bru' campaign to stop or reverse the change, and began stocking up on the more sugary formula.\nIn May 2019, Barr announced a new energy drink variant of Irn-Bru called Irn-Bru Energy, which was released on 1 July 2019.\nIn October 2019, Barr announced the launch of the \"Irn-Bru 1901\". The drink would be available for a limited time and use the original recipe from 1901. In March 2021, Barr announced the relaunch of \"Irn-Bru 1901\" as a permanent addition to the Irn-Bru lineup.\nIrn-Bru was the only soft drink on sale at the 2021 United Nations Climate Change Conference (COP26) in Glasgow, Scotland, due to a sponsorship arrangement. Member of the US House of Representatives Alexandria Ocasio-Cortez tried Irn-Bru at COP26 and said she loved it, and that it tasted just like the Latino soda Kola Champagne. The response from others at the conference ranged from strong dislike to strong liking. The volume of editorial and opinion publicity the drink gained on social and print media was described as \"the summit's surprise\", coverage worth millions. However, AG Barr's share price remained relatively flat at the time.\nProduction.\nIt is produced in Westfield, Cumbernauld, North Lanarkshire, since Barr's moved out of their Parkhead, Glasgow factory in the mid-2000s. In 2011, Irn-Bru closed their factory in Mansfield, making the Westfield plant in Cumbernauld the main location for production. Other manufacturing locations include the English city of Sheffield.\nMarketing.\nBarr's actively promoted their Irn-Bru from the outset, with some of their earliest ads featuring world champion wrestlers and Highland Games athletes Donald Dinnie and Alex Munro who endorsed the drink by means of personal testimonials. In the 1930s, the firm began a long-running series of comic strip ads entitled \"The Adventures of Ba-Bru\" which ran in various local papers from April 1939 until October 1970. The last traces of this campaign, a large neon sign featuring Ba-Bru which stood in Union St above Glasgow Central railway station, was removed in 1983 and replaced with an illuminated display featuring the tagline \"Your Other National Drink\".\nBarr has a long-established gimmick associating Irn-Bru with Scottishness, stemming from the claim of its being Scotland's most popular soft drink. A tagline, \"Made in Scotland from girders\", was used for several years from the 1980s, usually featuring Irn-Bru drinkers becoming unusually strong, durable or magnetic.\nAn advertising campaign launched in Spring 2000 aimed to \"dramatise the extraordinary appeal of Irn-Bru in a likeably maverick style\". David Amers, Planning Director, said: \"Irn-Bru is the likeable maverick of the soft drinks market and these ads perfectly capture the brand's spirit.\" One involved a grandfather (played by actor Robert Wilson) who removed his false teeth to spoil his grandson's interest in his can of Irn-Bru. A further TV advertisement featured a senior citizen in a mobility scooter robbing a local shopping market of a supply of Irn-Bru.\nIn 2004 the company created a new concept \"Phenomenal\". In 2006 the company launched its first Christmas adverts. This campaign consisted of a parody commercial of a popular Christmas Cartoon, \"The Snowman\", and was effective in interesting American audiences in the Irn-Bru brand. A sequel to the commercial would later be released in December 2018.\nFurther advertising campaigns for Irn-Bru appeared in conjunction with the release of Irn-Bru 32 in 2006.\nA 2009 advertisement for the product featured a group of high school pupils performing a musical number, with the refrain \"It's fizzy, it's ginger, it's phenomenal!\" It was a parody of \"High School Musical\", and starred Jack Lowden. In 2012 the company changed its slogan to \"gets you through\", which see a number of people drinking Irn-Bru to get through tough situations. In response to the Coca-Cola 'Share a Coke' campaign, Barr decided to produce thousands of limited edition 750 ml bottles of \"Irn-Bru\" with the names 'Fanny', 'Senga', 'Rab' and 'Tam' on the label, mimicking that by Coca-Cola. The use of the name 'Fanny' ties in with one of \"Irn-Bru\"'s controversial marketing advertisements.\nOne of the most controversial Irn-Bru television adverts evoked 1950s entertainment. A mother plays the piano, while the father and two children deliver a song which ends with the mother singing: \"...even though I used to be a man\". This advertisement was broadcast in 2000, but when it was repeated in 2003, it led to seventeen complaints about it being offensive to members of the transgender community. Issue A14 of the Ofcom Advertising Complaints bulletin reports that the children's response to their mother's claim was not offensive. According to the advertising agency Leith, the advertisement was meant to \"create a sense of humour while confirming the maverick nature of the brand\". However, the scene involving the mother shaving at the end of the advertisement was deemed by Ofcom to be \"capable of causing offence by strongly reinforcing negative stereotypes\", and so it was taken off the air.\nIn 2003, an Irn-Bru commercial which showed a midwife trying to entice a baby from its mother's womb during a difficult delivery sparked fifty complaints. Some saw it as upsetting to women who had suffered miscarriages. One billboard that drew criticism featured a young woman in a bikini along with the slogan \"Diet Irn-Bru. I never knew four-and-a-half inches could give so much pleasure\". Another featured a picture of a cow with the slogan \"When I'm a burger, I want to be washed down with Irn-Bru\". This billboard resulted in over 700 complaints but was cleared by advertisement watchdogs. According to a 2003 BBC report, a billboard which featured a depressed goth and the slogan \"Cheer up Goth. Have an Irn-Bru.\" was also criticised for inciting bullying.\nBrand portfolio.\nMcCowan's also produced Irn-Bru Bars, chewy, fizzy, bright orange confectionery bars which taste strongly of Irn-Bru, though production ended in late 2005. Irn-Bru sorbet is available in some speciality ice cream shops in Scotland.\nThe drink can be used as a mixer with alcoholic beverages, mainly vodka and whisky. Barr launched an alcopop drink combining Irn-Bru and Bell's whisky, although this proved to be unpopular and was discontinued.\nExports and foreign markets.\nAustralia.\nIn Australia, Irn-Bru was manufactured and distributed under licence by Occasio Australia until 2009. It was available in 500 ml and 1.25-litre in both standard and diet. The drink enjoyed growing success in the country, with its first advertising campaign launched in Queensland in September 2007. It was initially available in major chains such as Coles and Woolworths, Caltex service stations and in many independent grocers and convenience stores. It was then delisted at Coles Supermarkets. Because of manufacturing and bottling issues, Occasio ceased local production in late 2009. It is now imported direct from the UK and distributed by British Provender, and can again be found in the international sections of major supermarket chains and some convenience stores.\nCanada.\nIrn-Bru sold in Canada contained no caffeine until 2011, following the decision by Health Canada to repeal the ban on caffeine on non cola soft drinks in March 2010. Non-cola soft drinks can now contain up to 150ppm of caffeine. Now bottles of Irn-Bru have the label 'Now Contains caffeine' on the packaging. Irn-Bru in Canada is distributed by TFB &amp; Associates Ltd from Markham, Ontario but is packaged by A.G. Barr in Glasgow, Scotland. Irn-Bru can be found at Sobeys, Co-op and Walmart supermarkets. The now-defunct McKinlay soft-drink company in Glace Bay, Cape Breton, Nova Scotia, Canada, offered its own non-licensed beverage called \"Irn-Bru\" and later \"Cape Breton's Irn-Bru\". It was a brown carbonated soft-drink with a fruity cola taste.\nThe standard Irn-Bru distributed in Canada also contains the \"Not a source of iron\" disclaimer on the label.\nThe UK version of the drink (with caffeine) was imported by speciality retailers to Canada, given the large Scottish populations in Canada, with the country accounting for the largest number of Scottish expats in the world.\nIn 2014, Irn-Bru was incorrectly reported to have been one of a number of imported products, including Marmite, banned in Canada as a result of its additives in its ingredients due to a shipment being confiscated; however, a statement released by the Government of Canada in October 2020 reiterated that \"Irn-Bru and Marmite are not banned for sale in Canada. These products have been available on Canadian store shelves for more than a decade and will continue to be sold in stores across Canada. ...Imported products, including Irn Bru and Marmite, that meet Canadian requirements under Canada's Food and Drug Regulations are and will continue to be available for sale in Canada.\"\nMiddle East.\nIrn-Bru is available throughout the Middle East. It is found mostly in LuLu supermarkets.\nEurope.\nIrn-Bru entered the Norwegian market in May 2008. They had to withdraw from the market again in 2009 as a result of problems with production agreements and lack of funding for marketing. They were believed to be sponsoring the Norwegian First Division club Mj\u00f8ndalen IF in 2009. This later turned out to be fraud carried out by a third-party company, and Mj\u00f8ndalen IF never received any sponsorship from Irn-Bru, even though the team played the 2009 season with the Irn-Bru logo on their shirts. It is available in the Republic of Ireland, increasingly being stocked in BWG and ADM Londis supplied stores, as well as in supermarkets owned by Dunnes Stores and Tesco Ireland. In Ireland generally, the drink mainly sells in County Donegal.\nOther European territories where Irn Bru is sold include Spain, the Netherlands, Germany, Gibraltar, Belgium, Poland, Malta, Greece and Cyprus. In September 2010, profits in England and Wales had increased, with half year pre-tax profits rising 18.8% to \u00a316 million. By July 2024, A.G. Barr, the manufacturers of the drink, were estimated to make \u00a3221 million in sales in England alone for the first six months (January\u2013June) of 2024, a 7% increase in sales from the previous year.\nRussia.\nIrn-Bru began being sold in Russia in 1997, and by 2002, it had become their third best selling soft drink. After its original bottler went out of business, a new deal was signed for the drink to be manufactured and distributed in larger quantities by the Pepsi Bottling Group of Russia in 2002. Its popularity has been attributed to the drink's apparent similarity to discontinued Soviet-era soft drinks. As of 2011, Irn-Bru sales in Russia were still growing.\nOn 4 March 2022, due to the ongoing 2022 Russian invasion of Ukraine, A.G. Barr cut ties with the Russian market.\nUnited States.\nIrn-Bru and Diet Irn-Bru have been formulated since 2002 by A.G. Barr to meet the regulations for food colouring of the Food &amp; Drug Administration (FDA). Ponceau 4R, used in the UK formulation, is prohibited by the FDA. Barr uses alternative food and drink colourants manufactured by a US company approved by the FDA. The product labelling also meets US labelling standards on nutritional information and bar code.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "14742", "revid": "50415367", "url": "https://en.wikipedia.org/wiki?curid=14742", "title": "Internet Standard", "text": "Standard published by the Internet Engineering Task Force\nIn computer network engineering, an Internet Standard is a normative specification of a technology or methodology applicable to the Internet. Internet Standards are created and published by the Internet Engineering Task Force (IETF). They allow interoperation of hardware and software from different sources which allows internets to function. As the Internet became global, Internet Standards became the lingua franca of worldwide communications.\nEngineering contributions to the IETF start as an Internet Draft, may be promoted to a Request for Comments, and may eventually become an Internet Standard.\nAn Internet Standard is characterized by technical maturity and usefulness. The IETF also defines a Proposed Standard as a less mature but stable and well-reviewed specification. A Draft Standard was an intermediate level, discontinued in 2011. A Draft Standard was an intermediary step that occurred after a Proposed Standard but prior to an Internet Standard.\nAs put in RFC 2026: In general, an Internet Standard is a specification that is stable and well-understood, is technically competent, has multiple, independent, and interoperable implementations with substantial operational experience, enjoys significant public support, and is recognizably useful in some or all parts of the Internet.\nOverview.\nAn Internet Standard is documented by a Request for Comments (RFC) or a set of RFCs. A specification that is to become a Standard or part of a Standard begins as an Internet Draft, and is later, usually after several revisions, accepted and published by the RFC Editor as an RFC and labeled a \"Proposed Standard\". Later, an RFC is elevated as \"Internet Standard\", with an additional sequence number, when maturity has reached an acceptable level. Collectively, these stages are known as the \"Standards Track\", and are defined in RFC 2026 and RFC 6410. The label \"Historic\" is applied to deprecated Standards Track documents or obsolete RFCs that were published before the Standards Track was established.\nOnly the IETF, represented by the Internet Engineering Steering Group (IESG), can approve Standards Track RFCs. The definitive list of Internet Standards is maintained in the http://. Previously, STD 1 used to maintain a snapshot of the list.\nHistory and the purpose of Internet Standards.\nInternet standards are a set of rules that devices have to follow when they connect in a network. Since the technology has evolved, the rules of the engagement between computers had to evolve with it. These are the protocols that are in place used today. Most of these were developed long before the Internet Age, going as far back as the 1970s, not long after the creation of personal computers.\nTCP/IP\nThe official date for when the first internet went live is January 1, 1983. The Transmission Control Protocol/Internet Protocol (TCP/IP) went into effect. ARPANET (Advanced Research Projects Agency Network) and the Defense Data Network were the networks to implement the Protocols. These protocols are considered to be the essential part of how the Internet works because they define the rules by which the connections between servers operate. They are still used today by implementing various ways data is sent via global networks.\nIPsec\nInternet Protocol Security is a collection of protocols that ensure the integrity of encryption in the connection between multiple devices. The purpose of this protocol is to protect public networks. According to IETF Datatracker the group dedicated to its creation was proposed into existence on 25 November 1992. Half a year later the group was created and not long after in the mid 1993 the first draft was published.\nHTTP\nHyperText Transfer Protocol is one of the most commonly used protocols today in the context of the World Wide Web. HTTP is a simple protocol to govern how documents, that are written in HyperText Mark Language(HTML), are exchanged via networks. This protocol is the backbone of the Web allowing for the whole hypertext system to exist practically. It was created by the team of developers spearheaded by Tim Berners-Lee. Berners-Lee is responsible for the proposal of its creation, which he did in 1989. August 6, 1991 is the date he published the first complete version of HTTP on a public forum. This date subsequently is considered by some to be the official birth of the World Wide Web. HTTP has been continually evolving since its creation, becoming more complicated with time and progression of networking technology. By default HTTP is not encrypted so in practice HTTPS is used, which stands for HTTP Secure.\nTLS/SSL\nTLS stands for Transport Layer Security which is a standard that enables two different endpoints to interconnect sturdy and privately. TLS came as a replacement for SSL. Secure Sockets Layers was first introduced before the creation of HTTPS and it was created by Netscape. As a matter of fact HTTPS was based on SSL when it first came out. It was apparent that one common way of encrypting data was needed so the IETF specified TLS 1.0 in RFC 2246 in January, 1999. It has been upgraded since. Last version of TLS is 1.3 from RFC 8446 in August 2018.\nOSI Model\nThe Open Systems Interconnection model began its development in 1977. It was created by the International Organization for Standardization. It was officially published and adopted as a standard for use in 1979. It was then updated several times and the final version. It took a few years for the protocol to be presented in its final form. ISO 7498 was published in 1984. Lastly in 1995 the OSI model was revised again satisfy the urgent needs of uprising development in the field of computer networking.\nUDP\nThe goal of User Datagram Protocol was to find a way to communicate between two computers as quickly and efficiently as possible. UDP was conceived and realized by David P. Reed in 1980. Essentially the way it works is using compression to send information. Data would be compressed into a datagram and sent point to point. This proved to be a secure way to transmit information and despite the drawback of losing quality of data UDP is still in use.\nStandardization process.\nBecoming a standard is a two-step process within the Internet Standards Process: \"Proposed Standard\" and \"Internet Standard\". These are called \"maturity levels\" and the process is called the \"Standards Track\".\nIf an RFC is part of a proposal that is on the Standards Track, then at the first stage, the standard is proposed and subsequently organizations decide whether to implement this Proposed Standard. After the criteria in RFC 6410 is met (two separate implementations, widespread use, no errata etc.), the RFC can advance to Internet Standard.\nThe Internet Standards Process is defined in several \"Best Current Practice\" documents, notably http:// (currently[ [update]] RFC 2026 and RFC 6410). There were previously three standard maturity levels: \"Proposed Standard\", \"Draft Standard\" and \"Internet Standard\". RFC 6410 reduced this to two maturity levels.\nProposed Standard.\nRFC 2026 originally characterized Proposed Standards as immature specifications, but this stance was annulled by RFC 7127.\nA \"Proposed Standard\" specification is stable, has resolved known design choices, has received significant community review, and appears to enjoy enough community interest to be considered valuable. Usually, neither implementation nor operational experience is required for the designation of a specification as a Proposed Standard.\nProposed Standards are of such quality that implementations can be deployed in the Internet. However, as with all technical specifications, Proposed Standards may be revised if problems are found or better solutions are identified, when experiences with deploying implementations of such technologies at scale is gathered.\nMany Proposed Standards are actually deployed on the Internet and used extensively, as stable protocols. Actual practice has been that full progression through the sequence of standards levels is typically quite rare, and most popular IETF protocols remain at Proposed Standard.\nDraft Standard.\nIn October 2011, RFC 6410 merged the second and third maturity levels into one \"Internet Standard\". Existing older \"Draft Standards\" retain that classification, absent explicit actions. For old \"Draft Standards\" two possible actions are available, which must be approved by the IESG: A \"Draft Standard\" may be reclassified as an \"Internet Standard\" as soon as the criteria in RFC 6410 are satisfied; or, after two years since RFC 6410 was approved as BCP (October 2013), the IESG can choose to reclassify an old \"Draft Standard\" as \"Proposed Standard\".\nInternet Standard.\nAn Internet Standard is characterized by a high degree of technical maturity and by a generally held belief that the specified protocol or service provides significant benefit to the Internet community. Generally Internet Standards cover interoperability of systems on the Internet through defining protocols, message formats, schemas, and languages. \nAn Internet Standard ensures that hardware and software produced by different vendors can work together. Having a standard makes it much easier to develop software and hardware that link different networks because software and hardware can be developed one layer at a time. Normally, the standards used in data communication are called protocols.\nAll Internet Standards are given a number in the STD series. The series was summarized in its first document, STD 1 (RFC 5000), until 2013, but this practice was retired in RFC 7100. The definitive list of Internet Standards is now maintained by the RFC Editor.\nDocuments submitted to the IETF editor and accepted as an RFC are not revised; if the document has to be changed, it is submitted again and assigned a new RFC number. When an RFC becomes an Internet Standard (STD), it is assigned an STD number but retains its RFC number. When an Internet Standard is updated, its number is unchanged but refers to a different RFC or set of RFCs. For example, in 2007 RFC 3700 was an Internet Standard (STD 1) and in May 2008 it was replaced with RFC 5000. RFC 3700 received \"Historic\" status, and RFC 5000 became STD 1.\nThe list of Internet standards was originally published as STD 1 but this practice has been abandoned in favor of an online list maintained by the RFC Editor.\nOrganizations of Internet Standards.\nThe standardization process is divided into three steps:\nThere are five Internet standards organizations: the Internet Engineering Task Force (IETF), Internet Society (ISOC), Internet Architecture Board (IAB), Internet Research Task Force (IRTF), World Wide Web Consortium (W3C). All organizations are required to use and express the Internet language in order to remain competitive in the current Internet phase. Some basic aims of the Internet Standards Process are; ensure technical excellence; earlier implementation and testing; perfect, succinct as well as easily understood records.\nCreating and improving the Internet Standards is an ongoing effort and Internet Engineering Task Force plays a significant role in this regard. These standards are shaped and available by the Internet Engineering Task Force (IETF). It is the leading Internet standards association that uses well-documented procedures for creating these standards. Once circulated, those standards are made easily accessible without any cost.\nTill 1993, the United States federal government was supporting the IETF. Now, the Internet Society's Internet Architecture Board (IAB) supervises it. It is a bottom-up organization that has no formal necessities for affiliation and does not have an official membership procedure either. It watchfully works with the World Wide Web Consortium (W3C) and other standard development organizations. Moreover, it heavily relies on working groups that are constituted and proposed to an Area Director. IETF relies on its working groups for expansion of IETF conditions and strategies with a goal to make the Internet work superior. The working group then operates under the direction of the Area Director and progress an agreement. After the circulation of the proposed charter to the IESG and IAB mailing lists and its approval then it is further forwarded to the public IETF. It is not essential to have the complete agreement of all working groups and adopt the proposal. IETF working groups are only required to recourse to check if the accord is strong.\nLikewise, the Working Group produce documents in the arrangement of RFCs which are memorandum containing approaches, deeds, examination as well as innovations suitable to the functioning of the Internet and Internet-linked arrangements. In other words, Requests for Comments (RFCs) are primarily used to mature a standard network protocol that is correlated with network statements. Some RFCs are aimed to produce information while others are required to publish Internet standards. The ultimate form of the RFC converts to the standard and is issued with a numeral. After that, no more comments or variations are acceptable for the concluding form. This process is followed in every area to generate unanimous views about a problem related to the internet and develop internet standards as a solution to different glitches. There are eight common areas on which IETF focus and uses various working groups along with an area director. In the \"general\" area it works and develops the Internet standards. In \"Application\" area it concentrates on internet applications such as Web-related protocols. Furthermore, it also works on the development of internet infrastructure in the form of PPP extensions. IETF also establish principles and description standards that encompass the Internet protocol suite (TCP/IP). The Internet Architecture Board (IAB) along with the Internet Research Task Force (IRTF) counterpart the exertion of the IETF using innovative technologies.\nThe IETF is the standards making organization concentrate on the generation of \"standard\" stipulations of expertise and their envisioned usage. The IETF concentrates on matters associated with the progress of current Internet and TCP/IP know-how. It is alienated into numerous working groups (WGs), every one of which is accountable for evolving standards and skills in a specific zone, for example routing or security. People in working groups are volunteers and work in fields such as equipment vendors, network operators and different research institutions. Firstly, it works on getting the common consideration of the necessities that the effort should discourse. Then an IETF Working Group is formed and necessities are ventilated in the influential Birds of a Feather (BoF) assemblies at IETF conferences.\nInternet Engineering Task Force.\nThe Internet Engineering Task Force (IETF) is the premier internet standards organization. It follows an open and well-documented processes for setting internet standards. The resources that the IETF offers include RFCs, internet-drafts, IANA functions, intellectual property rights, standards process, and publishing and accessing RFCs.\nTypes of Internet Standards.\nThere are two ways in which an Internet Standard is formed and can be categorized as one of the following: \"de jure\" standards and \"de facto\" standards. A de facto standard becomes a standard through widespread use within the tech community. A de jure standard is formally created by official standard-developing organizations. These standards undergo the Internet Standards Process. Common de jure standards include ASCII, SCSI, and Internet protocol suite.\nInternet Standard Specifications.\nSpecifications subject to the Internet Standards Process can be categorized into one of the following: Technical Specification (TS) and Applicability Statement (AS). A Technical Specification is a statement describing all relevant aspects of a protocol, service, procedure, convention, or format. This includes its scope and its intent for use, or \"domain of applicability\". However, a TSs use within the Internet is defined by an Applicability Statement. An AS specifies how, and under what circumstances, TSs may be applied to support a particular Internet capability. An AS identifies the ways in which relevant TSs are combined and specifies the parameters or sub-functions of TS protocols. An AS also describes the domains of applicability of TSs, such as Internet routers, terminal server, or datagram-based database servers. An AS also applies one of the following \"requirement levels\" to each of the TSs to which it refers:\nCommon Standards.\nWeb Standards.\nTCP/ IP Model &amp; associated Internet Standards\nWeb standards are a type of internet standard which define aspects of the World Wide Web. They allow for the building and rendering of websites. The three key standards used by the World Wide Web are Hypertext Transfer Protocol, HTML, and URL. Respectively, they specify the transfer of data between a browser and a web server, the content and layout of a web page, and what web page identifiers mean.\nNetwork Standards.\nNetwork standards are a type of internet standard which defines rules for data communication in networking technologies and processes. Internet standards allow for the communication procedure of a device to or from other devices.\nIn reference to the TCP/IP Model, common standards and protocols in each layer are as follows:\nThe future of Internet Standards.\nThe Internet has been viewed as an open playground, free for people to use and communities to monitor. However, large companies have shaped and molded it to best fit their needs. The future of internet standards will be no different. Currently, there are widely used but insecure protocols such as the Border Gateway Protocol (BGP) and Domain Name System (DNS).\u00a0 This reflects common practices that focus more on innovation than security.\u00a0 Companies have the power to improve these issues.\u00a0 With the Internet in the hands of the industry, users must depend on businesses to protect vulnerabilities present in these standards.\nWays to make BGP and DNS safer already exist but they are not widespread. For example, there is the existing BGP safeguard called Routing Public Key Infrastructure (RPKI). It is a database of routes that are known to be safe and have been cryptographically signed. Users and companies submit routes and check other users' routes for safety. If it were more widely adopted, more routes could be added and confirmed. However, RPKI is picking up momentum. As of December 2020, tech giant Google registered 99% of its routes with RPKI. They are making it easier for businesses to adopt BGP safeguards. DNS also has a security protocol with a low adoption rate: DNS Security Extensions (DNSSEC). Essentially, at every stage of the DNS lookup process, DNSSEC adds a signature to data to show it has not been tampered with.\nSome companies have taken the initiative to secure internet protocols. It is up to the rest to make it more widespread.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "14743", "revid": "26021349", "url": "https://en.wikipedia.org/wiki?curid=14743", "title": "ISOC", "text": "ISOC is an abbreviation which may refer to:\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "14744", "revid": "5563803", "url": "https://en.wikipedia.org/wiki?curid=14744", "title": "ITU-T", "text": "Standardization Sector of the International Telecommunication Union\nThe International Telecommunication Union Telecommunication Standardization Sector (ITU-T) is one of the three Sectors (branches) of the International Telecommunication Union (ITU). It is responsible for coordinating standards for telecommunications and Information Communication Technology, such as X.509 for cybersecurity, Y.3172 and Y.3173 for machine learning, and H.264/MPEG-4 AVC for video compression, between its Member States, Private Sector Members, and Academia Members.\nThe World Telecommunication Standardization Assembly (WTSA), the sector's governing conference, convenes every four years.\nITU-T has a permanent secretariat called the Telecommunication Standardization Bureau (TSB), which is based at the ITU headquarters in Geneva, Switzerland. The current director of the TSB is Seizo Onoe (of Japan), whose 4-year term commenced on 1 January 2023. Seizo Onoe succeeded Chaesub Lee of South Korea, who was director from 1 January 2015 until 31 December 2022.\nPrimary function.\nThe ITU-T mission is to ensure the efficient and timely production of standards covering all fields of telecommunications and Information Communication Technology (ICTs) on a worldwide basis, as well as defining tariff and accounting principles for international telecommunication services.\nThe international standards that are produced by the ITU-T are referred to as \"Recommendations\" (with the word capitalized to distinguish its meaning from the common parlance sense of the word \"recommendation\"), as they become mandatory only when adopted as part of a national law.\nSince the ITU-T is part of the ITU, which is a United Nations specialized agency, its standards carry more formal international weight than those of most other standards development organizations that publish technical specifications of a similar form.\nHistory.\nAt the initiative of Napoleon III, the French government invited international participants to a conference in Paris in 1865 to facilitate and regulate international telegraph services. A result of the conference was the founding of the forerunner of the modern ITU.\nAt the 1925 Paris conference, the ITU created two consultative committees to deal with the complexities of the international telephone services, known as () and with long-distance telegraphy ().\nIn view of the basic similarity of many of the technical problems faced by the and , a decision was taken in 1956 to merge them into a single entity, the International Telegraph and Telephone Consultative Committee (, in ). The first Plenary Assembly of the new organization was held in Geneva, Switzerland in December 1956.\nIn 1992, the Plenipotentiary Conference (the top policy-making conference of ITU) saw a reform of ITU, giving the Union greater flexibility to adapt to an increasingly complex, interactive and competitive environment. The was renamed the Telecommunication Standardization Sector (ITU-T), as one of three Sectors of the Union alongside the Radiocommunication Sector (ITU-R) and the Telecommunication Development Sector (ITU-D).\nHistorically, the Recommendations of the were presented at plenary assemblies for endorsement, held every four years, and the full set of Recommendations were published after each plenary assembly. However, the delays in producing texts, and translating them into other working languages, did not suit the fast pace of change in the telecommunications industry.\n\"Real time\" standardization.\nThe rise of the personal computer industry in the early 1980s created a new common practice among both consumers and businesses of adopting \"bleeding edge\" communications technology even if it was not yet standardized. Thus, standards organizations had to put forth standards much faster, or find themselves ratifying de facto standards after the fact. One of the most prominent examples of this was the Open Document Architecture project, which began in 1985 when a profusion of software firms around the world were still furiously competing to shape the future of the electronic office, and was completed in 1999 long after Microsoft Office's then-secret binary file formats had become established as the global de facto standard.\nThe ITU-T now operates under much more streamlined processes. The time between an initial proposal of a draft document by a member company and the final approval of a full-status ITU-T Recommendation can now be as short as a few months (or less in some cases). This makes the standardization approval process in the ITU-T much more responsive to the needs of rapid technology development than in the ITU's historical past. New and updated Recommendations are published on an almost daily basis, and nearly all of the library of over 3,270 Recommendations is now free of charge online. (About 30 specifications jointly maintained by the ITU-T and ISO/IEC are not available for free to the public.)\nITU-T has moreover tried to facilitate cooperation between the various forums and standard-developing organizations (SDOs). This collaboration is necessary to avoid duplication of work and the consequent risk of conflicting standards in the market place.\nIn the work of standardization, ITU-T cooperates with other SDOs, e.g., the International Organization for Standardization (ISO) and the Internet Engineering Task Force (IETF).\nDevelopment of Recommendations.\nMost of the work of ITU-T is carried out by its Sector Members and Associates, while the Telecommunication Standardization Bureau (TSB) is the executive arm of ITU-T and coordinator for a number of workshops and seminars to progress existing work areas and explore new ones. The events cover a wide array of topics in the field of information and communication technologies (ICT) and attract high-ranking experts as speakers, and attendees from engineers to high-level management from all industry sectors.\nThe technical work, the development of Recommendations, of ITU-T is managed by Study Groups (SGs), such as Study Group 13 for network standards, Study Group 16 for multimedia standards, and Study Group 17 for security standards, which are created by the World Telecommunication Standardization Assembly (WTSA) which is held every four years. As part of the deliberations, WTSA has instructed ITU to hold the Global Standards Symposium, which unlike WTSA is open to public for participation. The people involved in these SGs are experts in telecommunications from all over the world. There are currently 11 SGs. Study groups meet face to face (or virtually under exceptional circumstances) according to a calendar issued by the TSB. SGs are augmented by Focus Groups (FGs), an instrument created by ITU-T, providing a way to quickly react to ICT standardization needs and allowing great flexibility in terms of participation and working methods. The key difference between SGs and FGs is that the latter have greater freedom to organize and finance themselves, and to involve non-members in their work, but they do not have the authority to approve Recommendations. Focus Groups can be created very quickly, are usually short-lived and can choose their own working methods, leadership, financing, and types of deliverables. Current Focus Groups include the ITU-WHO Focus Group on Artificial Intelligence for Health (FG-AI4H) as well as Machine Learning for 5G (which developed Y.3172), Quantum Information Technologies for Networks, and Artificial Intelligence for Assisted and Autonomous Driving.\nAlternative Approval Process.\nThe Alternative Approval Process (AAP) is a fast-track approval procedure that was developed to allow standards to be brought to market in the timeframe that industry now demands. The AAP is defined in ITU-T Recommendation A.8.\nThis dramatic overhaul of standards-making by streamlining approval procedures was implemented in 2001 and is estimated to have cut the time involved in this critical aspect of the standardization process by 80 to 90 percent. This means that an average standard that took around four years to approve and publish until the mid nineties, and two years until 1997, can now be approved in an average of two months, or as little as five weeks.\nBesides streamlining the underlying procedures involved in the approval process, an important contributory factor to the use of AAP is electronic document handling. Once the approval process has begun the rest of the process can be completed electronically, in the vast majority of cases, with no further physical meetings.\nThe introduction of AAP also formalizes public/private partnership in the approval process by providing equal opportunities for both sector members and member states in the approval of technical standards.\nA panel of SG experts drafts a proposal that is then forwarded at an SG meeting to the appropriate body which decides if it is sufficiently ready to be designated a draft text and thus gives its consent for further review at the next level.\nAfter this Consent has been given, TSB announces the start of the AAP procedure by posting the draft text to the ITU-T website and calling for comments. This gives the opportunity for all members to review the text. This phase, called \"last call\", is a four-week period in which comments can be submitted by member states and sector members.\nIf no comments other than editorial corrections are received, the Recommendation is considered approved since no issues were identified that might need any further work. However, if there are any comments, the SG chairman, in consultation with TSB, sets up a comment resolution process by the concerned experts. The revised text is then posted on the web for an \"additional review\" period of three weeks.\nSimilar to the last call phase, in \"additional review\" the Recommendation is considered as approved if no comments are received. If comments are received, it is apparent that there are some issues that still need more work, and the draft text and all comments are sent to the next Study Group meeting for further discussion and possible approval.\nThose Recommendations considered as having policy or regulatory implications are approved through what is known as the Traditional Approval Process (TAP), which allows a longer period for reflection and commenting by member states. TAP Recommendations are also translated into the six working languages of ITU (Arabic, Chinese, English, French, Russian, and Spanish).\nSeries and Recommendations.\nITU-T Recommendations are the names given to telecommunications and computer protocol specification documents published by ITU-T.\nRecommendation categorization.\nITU-T assigns each Recommendation a name based on the series and Recommendation number. The name starts with the letter of the series the Recommendation belongs to. Each series encompasses a broad category of Recommendations, such as \"H-Series Recommendations: Audiovisual and multimedia systems\". The series letter is followed by a period and the Recommendation number, which uniquely identifies the Recommendation within the series. Often, a range of related Recommendations are further grouped within the series and given adjacent numbers, such as \"H.200-H.499: Infrastructure of audiovisual services\" or \"H.260-H.279: Coding of moving video\". Many numbers are \"skipped\" to give room for future Recommendations to be adjacent to related Recommendations. Recommendations can be revised or \"superseded\" and keep their existing Recommendation number.\nIndividual ITU-T Recommendations.\nSource:\nInternational Telecommunication Regulations (ITRs).\nIn addition to the ITU-T Recommendations, which have non-mandatory status unless they are adopted in national laws, ITU-T is also the custodian of a binding international treaty, the International Telecommunication Regulations. The ITRs go back to the earliest days of the ITU when there were two separate treaties, dealing with telegraph and telephone. The ITRs were adopted, as a single treaty, at the World Administrative Telegraphy and Telephone Conference held in Melbourne, 1988 (WATTC-88).\nThe ITRs comprise ten articles which deal, \"inter alia\", with the definition of international telecommunication services, cooperation between countries and national administrations, safety of life and priority of telecommunications and charging and accounting principles. The adoption of the ITRs in 1988 is often taken as the start of the wider liberalization process in international telecommunications, though a few countries, including United States and United Kingdom, had made steps to liberalize their markets before 1988.\nThe Constitution and Convention of ITU provides for the amendment of ITRs through a World Conference on International Telecommunications (WCIT). Accordingly, in 1998 there began a process of review of the ITRs; and in 2009 extensive preparations began for such a conference, WCIT-12. In addition to \"regional preparatory meetings\", the ITU Secretariat developed 13 \"Background Briefs on key issues\" that were expected to be discussed at the conference. Convened by former ITU secretary-general Hamadoun Tour\u00e9, the Conference, WCIT-12, was then held in Dubai, United Arab Emirates, during the period 3\u201314 December 2014.\nAI for Good.\nThe Standardization Sector of ITU also organizes AI for Good, the United Nations platform for the sustainable development of Artificial Intelligence.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "14745", "revid": "12723358", "url": "https://en.wikipedia.org/wiki?curid=14745", "title": "Indian", "text": "Indian or Indians may refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "14746", "revid": "44342819", "url": "https://en.wikipedia.org/wiki?curid=14746", "title": "Internalization (disambiguation)", "text": ""}
{"id": "14747", "revid": "84755", "url": "https://en.wikipedia.org/wiki?curid=14747", "title": "Ionic", "text": "Ionic or Ionian may refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "14749", "revid": "50749987", "url": "https://en.wikipedia.org/wiki?curid=14749", "title": "Indium", "text": "element with atomic number 49 (In)\nIndium is a chemical element; it has symbol In and atomic number 49. It is a silvery-white post-transition metal and one of the softest elements. Chemically, indium is similar to gallium and thallium, and its properties are largely intermediate between the two. It was discovered in 1863 by Ferdinand Reich and Hieronymous Theodor Richter by spectroscopic methods and named for the indigo blue line in its spectrum.\nIndium is used primarily in the production of flat-panel displays as indium tin oxide (ITO), a transparent and conductive coating applied to glass. It is also used in the semiconductor industry, in low-melting-point metal alloys such as solders and soft-metal high-vacuum seals. It is used in the manufacture of blue and white LED circuits, mainly to produce Indium gallium nitride p-type semiconductor substrates. It is produced exclusively as a by-product during the processing of the ores of other metals, chiefly from sphalerite and other zinc sulfide ores.\nIndium has no biological role and its compounds are toxic when inhaled or injected into the bloodstream, although they are poorly absorbed following ingestion.\nEtymology.\nThe name comes from the Latin word \"indicum\" meaning violet or indigo. The word \"indicum\" means \"Indian\", as the naturally based dye indigo was originally exported to Europe from India.\nProperties.\nPhysical.\nIndium is a shiny silvery-white, highly ductile post-transition metal with a bright luster. It is so soft (Mohs hardness 1.2) that it can be cut with a knife and leaves a visible line like a pencil when rubbed on paper. It is a member of group 13 on the periodic table and its properties are mostly intermediate between its vertical neighbors gallium and thallium. As with tin, a high-pitched cry is heard when indium is bent \u2013 a crackling sound due to crystal twinning. Like gallium, indium is able to wet glass. Like both, indium has a low melting point, 156.60\u00a0\u00b0C (313.88\u00a0\u00b0F); higher than its lighter homologue, gallium, but lower than its heavier homologue, thallium, and lower than tin. The boiling point is 2072\u00a0\u00b0C (3762\u00a0\u00b0F), higher than that of thallium, but lower than gallium, conversely to the general trend of melting points, but similarly to the trends down the other post-transition metal groups because of the weakness of the metallic bonding with few electrons delocalized.\nThe density of indium, 7.31\u00a0g/cm3, is also greater than gallium, but lower than thallium. Below the critical temperature, 3.41\u00a0K, indium becomes a superconductor. Indium crystallizes in the body-centered tetragonal crystal system in the space group \"I\"4/\"mmm\" (lattice parameters:\u00a0\"a\"\u00a0=\u00a0325\u00a0pm, \"c\"\u00a0=\u00a0495\u00a0pm): this is a slightly distorted face-centered cubic structure, where each indium atom has four neighbours at 324\u00a0pm distance and eight neighbours slightly further (336\u00a0pm). Indium has greater solubility in liquid mercury than any other metal (more than 50 mass percent of indium at 0\u00a0\u00b0C). Indium displays a ductile viscoplastic response, found to be size-independent in tension and compression. However it does have a size effect in bending and indentation, associated to a length-scale of order 50\u2013100\u00a0\u03bcm, significantly large when compared with other metals.\nIsotopes.\nIndium has 39 known isotopes, ranging in mass number from 97 to 135. Only two isotopes occur naturally as primordial nuclides: indium-113, the only stable isotope, and indium-115, which has a half-life of 4.41\u00d71014 years, four orders of magnitude greater than the age of the Universe and nearly 30,000 times greater than half-life of thorium-232. The half-life of 115In is very long because the beta decay to 115Sn is spin-forbidden. Indium-115 makes up 95.7% of all indium. Indium is one of three known elements (the others being tellurium and rhenium) of which the stable isotope is less abundant in nature than the long-lived primordial radioisotopes.\nThe stablest artificial isotope is indium-111, with a half-life of approximately 2.8\u00a0days. All other isotopes have half-lives shorter than 5 hours. Indium also has 47 meta states, among which indium-114m1 (half-life about 49.51\u00a0days) is the most stable, more stable than the ground state of any indium isotope other than the primordial. All decay by isomeric transition. The indium isotopes lighter than 113In predominantly decay through electron capture or positron emission to form cadmium isotopes, while the indium isotopes heavier than 113In predominantly decay through beta-minus decay to form tin isotopes.\nChemistry.\nIndium has 49 electrons, with an electronic configuration of [Kr]4d105s25p1. In compounds, indium most commonly donates the three outermost electrons to become indium(III), In3+. In some cases, the pair of 5s-electrons are not donated, resulting in indium(I), In+. The stabilization of the monovalent state is attributed to the inert pair effect, in which relativistic effects lowers the energy of the 5s-orbital, observed in heavier elements. Thallium (indium's heavier homolog) shows an even stronger effect, manifested by the pervasiveness of thallium(I) vs thallium(III), Gallium (indium's lighter homolog) is only rarely observed in the +1 oxidation state. Thus, although thallium(III) is a moderately strong oxidizing agent, indium(III) is not, and many indium(I) compounds are powerful reducing agents. While the energy required to include the s-electrons in chemical bonding is lowest for indium among the group 13 metals, bond energies decrease down the group so that by indium, the energy released in forming two additional bonds and attaining the +3 state is not always enough to outweigh the energy needed to involve the 5s-electrons. Indium(I) oxide and hydroxide are more basic and indium(III) oxide and hydroxide are more acidic.\nA number of standard electrode potentials, depending on the reaction under study, are reported for indium, reflecting the decreased stability of the +3 oxidation state:\nIndium metal does not react with water, but it is oxidized by stronger oxidizing agents such as halogens to give indium(III) compounds. It does not form a boride, silicide, or carbide. \nIndium is rather basic in aqueous solution, showing only slight amphoteric characteristics, and unlike its lighter homologs aluminium and gallium, it is insoluble in aqueous alkaline solutions.\nIndium(III) compounds.\nHydrides and halides.\nThe hydride InH3 has at best a transitory existence in ethereal solutions at low temperatures. It polymerizes in the absence of bases. Lewis bases stabilize a rich collection of indium hydrides of the formula LInH3 (L = tertiary phosphine and N-Heterocyclic carbenes).\nChlorination, bromination, and iodination of In produce colorless InCl3, InBr3, and yellow InI3. The compounds are Lewis acids, somewhat akin to the better known aluminium trihalides. Again like the related aluminium compound, InF3 is polymeric.\nIndium halides dissolves in water to give aquo complexes such as [Ir(H2O)6]3+ and [IrCl2(H2O)4]+. Similar complexes can be prepared from nitrates and acetates. Overall, the pattern is similar to that for aluminium(III).\nChalcogenides and pnictides.\nIndium derivatives of chalcogenides (O, S, Se, Te) are well developed. Indium(III) oxide, In2O3, forms when indium metal is burned in air or when the hydroxide or nitrate is heated. The analogous sesqui-chalcogenides with sulfur, selenium, and tellurium are also known.\nThe chemistry of indium pnictides (N, P, As, Sb) is also well known, motivated by their relevance to semiconductor technology. Direct reaction of indium metal with the pnictogens For applications in microelectronics, the P, As, and Sb derivatives are made by reactions of trimethylindium:\n (E = P, As, Sb)\nMany of these derivatives are prone to hydrolysis.\nIndium(I) compounds.\nIndium(I) compounds are not common. The chloride, bromide, and iodide are deeply colored, unlike the parent trihalides from which they are prepared. The fluoride is known only as an unstable gas. Indium(I) oxide black powder is produced when indium(III) oxide decomposes upon heating to 700\u00a0\u00b0C.\nCompounds in other oxidation states.\nLess frequently, indium forms compounds in oxidation state +2 and even fractional oxidation states. Usually such materials feature In\u2013In bonding, most notably in the halides In2X4 and [In2X6]2\u2212, and various subchalcogenides such as In4Se3. Several other compounds are known to combine indium(I) and indium(III), such as InI6(InIIICl6)Cl3, InI5(InIIIBr4)2(InIIIBr6), and InIInIIIBr4.\nOrganoindium compounds.\nOrganoindium compounds feature In\u2013C bonds. Most are In(III) derivatives, but cyclopentadienylindium(I) is an exception. It was the first known organoindium(I) compound, and is polymeric, consisting of zigzag chains of alternating indium atoms and cyclopentadienyl complexes. Perhaps the best-known organoindium compound is trimethylindium, In(CH3)3, used to prepare certain semiconducting materials.\nHistory.\nIn 1863, German chemists Ferdinand Reich and Hieronymus Theodor Richter were testing ores from the mines around Freiberg, Saxony. They dissolved the minerals pyrite, arsenopyrite, galena and sphalerite in hydrochloric acid and distilled raw zinc chloride. Reich, who was color-blind, employed Richter as an assistant for detecting the colored spectral lines. Knowing that ores from that region sometimes contain thallium, they searched for the green thallium emission spectrum lines. Instead, they found a bright blue line. Because that blue line did not match any known element, they hypothesized a new element was present in the minerals. They named the element indium, from the indigo color seen in its spectrum, after the Latin \"indicum\", meaning 'of India'.\nRichter went on to isolate the metal in 1864. An ingot of was presented at the World Fair 1867. Reich and Richter later fell out when the latter claimed to be the sole discoverer.\nOccurrence.\nIndium is created by the long-lasting (up to thousands of years) s-process (slow neutron capture) in low-to-medium-mass stars (range in mass between 0.6 and 10 solar masses). When a silver-109 atom captures a neutron, it transmutes into silver-110, which then undergoes beta decay to become cadmium-110. Capturing further neutrons, it becomes cadmium-115, which decays to indium-115 by another beta decay. This explains why the radioactive isotope is more abundant than the stable one. The stable indium isotope, indium-113, is one of the p-nuclei, the origin of which is not fully understood; although indium-113 is known to be made directly in the s- and r-processes (rapid neutron capture), and also as the daughter of very long-lived cadmium-113, which has a half-life of about eight quadrillion years, this cannot account for all indium-113.\nIndium is the 68th most abundant element in Earth's crust at approximately 50 ppb. This is similar to the crustal abundance of silver, bismuth and mercury. It very rarely forms its own minerals, or occurs in elemental form. Fewer than 10 indium minerals such as roquesite (CuInS2) are known, and none occur at sufficient concentrations for economic extraction. Instead, indium is usually a trace constituent of more common ore minerals, such as sphalerite and chalcopyrite. From these, it can be extracted as a by-product during smelting. While the enrichment of indium in these deposits is high relative to its crustal abundance, it is insufficient, at current prices, to support extraction of indium as the main product.\nDifferent estimates exist of the amounts of indium contained within the ores of other metals. However, these amounts are not extractable without mining of the host materials (see Production and availability). Thus, the availability of indium is fundamentally determined by the \"rate\" at which these ores are extracted, and not their absolute amount. This is an aspect that is often forgotten in the current debate, e.g. by the Graedel group at Yale in their criticality assessments, explaining the paradoxically low depletion times some studies cite.\nProduction and availability.\nIndium is produced exclusively as a by-product during the processing of the ores of other metals. Its main source material are sulfidic zinc ores, where it is mostly hosted by sphalerite. Minor amounts are also extracted from sulfidic copper ores. During the roast-leach-electrowinning process of zinc smelting, indium accumulates in the iron-rich residues. From these, it can be extracted in different ways. It may also be recovered directly from the process solutions. Further purification is done by electrolysis. The exact process varies with the mode of operation of the smelter.\nIts by-product status means that indium production is constrained by the amount of sulfidic zinc (and copper) ores extracted each year. Therefore, its availability needs to be discussed in terms of supply potential. The supply potential of a by-product is defined as that amount which is economically extractable from its host materials \"per year\" under current market conditions (i.e. technology and price). Reserves and resources are not relevant for by-products, since they \"cannot\" be extracted independently from the main-products. Recent estimates put the supply potential of indium at a minimum of 1,300 t/yr from sulfidic zinc ores and 20 t/yr from sulfidic copper ores. These figures are significantly greater than current production (655 t in 2016). Thus, major future increases in the by-product production of indium will be possible without significant increases in production costs or price. The average indium price in 2016 was US$240/kg, down from US$705/kg in 2014.\nChina is a leading producer of indium (290 tonnes in 2016), followed by South Korea (195 t), Japan (70 t) and Canada (65 t). The Teck Resources refinery in Trail, British Columbia, is a large single-source indium producer, with an output of 32.5\u00a0tonnes in 2005, 41.8\u00a0tonnes in 2004 and 36.1\u00a0tonnes in 2003.\nThe primary consumption of indium worldwide is LCD production. Demand rose rapidly from the late 1990s to 2010 with the popularity of LCD computer monitors and television sets, which now account for 50% of indium consumption. Increased manufacturing efficiency and recycling (especially in Japan) maintain a balance between demand and supply. According to the UNEP, indium's end-of-life recycling rate is less than 1%.\nApplications.\nIndustrial uses.\nIn 1924, indium was found to have a valued property of stabilizing non-ferrous metals, and that became the first significant use for the element. The first large-scale application for indium was coating bearings in high-performance aircraft engines during World War II, to protect against damage and corrosion; this is no longer a major use of the element. New uses were found in fusible alloys, solders, and electronics. In the 1950s, tiny beads of indium were used for the emitters and collectors of PNP alloy-junction transistors. In the middle and late 1980s, the development of indium phosphide semiconductors and indium tin oxide thin films for liquid-crystal displays (LCD) aroused much interest. By 1992, the thin-film application had become the largest end use.\nIndium(III) oxide and indium tin oxide (ITO) are used as a transparent conductive coating on glass substrates in electroluminescent panels. Indium tin oxide is used as an infrared radiation filter in low-pressure sodium-vapor lamps. The infrared radiation is reflected back into the lamp, which increases the temperature within the tube and improves the performance of the lamp.\nIndium has many semiconductor-related applications. Some indium compounds, such as indium antimonide and indium phosphide, are semiconductors with useful properties: one precursor is usually trimethylindium (TMI), which is also used as the semiconductor dopant in II\u2013VI compound semiconductors. InAs and InSb are used for low-temperature transistors and InP for high-temperature transistors. The compound semiconductors InGaN and InGaP are used in light-emitting diodes (LEDs) and laser diodes. Indium is used in photovoltaics as the semiconductor copper indium gallium selenide (CIGS), also called CIGS solar cells, a type of second-generation thin-film solar cell. Indium is used in PNP bipolar junction transistors with germanium: when soldered at low temperature, indium does not stress the germanium.\nIndium wire is used as a vacuum seal and a thermal conductor in cryogenics and ultra-high-vacuum applications, in such manufacturing applications as gaskets that deform to fill gaps. Owing to its great plasticity and adhesion to metals, Indium sheets are sometimes used for cold-soldering in microwave circuits and waveguide joints, where direct soldering is complicated. Indium is an ingredient in the gallium\u2013indium\u2013tin alloy galinstan, which is liquid at room temperature and replaces mercury in some thermometers. Other alloys of indium with bismuth, cadmium, lead, and tin, which have higher but still low melting points (between 50 and 100\u00a0\u00b0C), are used in fire sprinkler systems and heat regulators.\nIndium is one of many substitutes for mercury in alkaline batteries to prevent the zinc from corroding and releasing hydrogen gas. Indium is added to some dental amalgam alloys to decrease the surface tension of the mercury and allow for less mercury and easier amalgamation.\nIndium's high neutron-capture cross-section for thermal neutrons makes it suitable for use in control rods for nuclear reactors, typically in an alloy of 80% silver, 15% indium, and 5% cadmium. In nuclear engineering, the (n,n') reactions of 113In and 115In are used to determine magnitudes of neutron fluxes.\nIn 2009, Professor Mas Subramanian and former graduate student Andrew Smith at Oregon State University discovered that indium can be combined with yttrium and manganese to form an intensely blue, non-toxic, inert, fade-resistant pigment, YInMn blue, the first new inorganic blue pigment discovered in 200 years.\nMedical applications.\nRadioactive indium-111 (in very small amounts) is used in nuclear medicine tests, as a radiotracer to follow the movement of labeled proteins and white blood cells to diagnose different types of infection. Indium compounds are mostly not absorbed upon ingestion and are only moderately absorbed on inhalation; they tend to be stored temporarily in the muscles, skin, and bones before being excreted, and the biological half-life of indium is about two weeks in humans. It is also tagged to growth hormone analogues like octreotide to find growth hormone receptors in neuroendocrine tumors.\nBiological role and precautions.\n&lt;templatestyles src=\"Chembox/styles.css\"/&gt;\nChemical compound\nIndium has no metabolic role in any organism. According to one overview \"no evidence of any health hazard from industrial use of indium.\"\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "14750", "revid": "11104410", "url": "https://en.wikipedia.org/wiki?curid=14750", "title": "Iodine", "text": "element with atomic number 53 (I)\nIodine is a chemical element; it has symbol I and atomic number 53. The heaviest of the stable halogens, it exists at standard conditions as a semi-lustrous, non-metallic solid that melts to form a deep violet liquid at , and boils to a violet gas at . The element was discovered by the French chemist Bernard Courtois in 1811 and was named two years later by Joseph Louis Gay-Lussac, after the Ancient Greek , meaning 'violet'.\nIodine occurs in many oxidation states, including iodide (I\u2212), iodate (IO3-), and the various periodate anions. As the heaviest essential mineral nutrient, iodine is required for the synthesis of thyroid hormones. Iodine deficiency affects about two billion people and is the leading preventable cause of intellectual disabilities.\nThe dominant producers of iodine today are Chile and Japan. Due to its high atomic number and ease of attachment to organic compounds, it has also found favour as a non-toxic radiocontrast material. Because of the specificity of its uptake by the human body, radioactive isotopes of iodine can also be used to treat thyroid cancer. Iodine is also used as a catalyst in the industrial production of acetic acid and some polymers.\nIt is on the World Health Organization's List of Essential Medicines.\nHistory.\nIn 1811, iodine was discovered by French chemist Bernard Courtois, who was born to a family of manufacturers of saltpetre (an essential component of gunpowder). At the time of the Napoleonic Wars, saltpetre was in great demand in France. Saltpetre produced from French nitre beds required sodium carbonate, which could be isolated from seaweed collected on the coasts of Normandy and Brittany. To isolate the sodium carbonate, seaweed was burned and the ashes washed with water. While investigating the cause of corrosion to the copper vessels used in the process, Courtois added an excess of sulfuric acid to the waste remaining and a cloud of violet vapour arose. He noted that the vapour crystallised on cold surfaces, forming dark crystals. Courtois suspected that this material was a new element but lacked funding to pursue it further.\nCourtois gave samples to his friends, Charles Bernard Desormes (1777\u20131838) and Nicolas Cl\u00e9ment (1779\u20131841), to continue research. He also gave some of the substance to chemist Joseph Louis Gay-Lussac (1778\u20131850), and to physicist Andr\u00e9-Marie Amp\u00e8re (1775\u20131836). On 29 November 1813, Desormes and Cl\u00e9ment made Courtois' discovery public by describing the substance to a meeting of the Imperial Institut de France. On 6 December 1813, Gay-Lussac found and announced that the new substance was either an element or a compound of oxygen and he found that it is an element. Gay-Lussac suggested the name \"iode\" (anglicised as \"iodine\"), from the Ancient Greek (, \"violet\"), because of the colour of iodine vapour. Amp\u00e8re had given some of his sample to British chemist Humphry Davy (1778\u20131829), who experimented on the substance and noted its similarity to chlorine and also found it as an element. Davy sent a letter dated 10 December to the Royal Society stating that he had identified a new element called iodine. Arguments erupted between Davy and Gay-Lussac over who identified iodine first, but both scientists found that both of them identified iodine first and also knew that Courtois is the first one to isolate the element.\nIn 1873, the French medical researcher Casimir Davaine (1812\u20131882) discovered the antiseptic action of iodine. Antonio Grossich (1849\u20131926), an Istrian-born surgeon, was among the first to use sterilisation of the operative field. In 1908, he introduced tincture of iodine as a way to rapidly sterilise the human skin in the surgical field.\nIn early periodic tables, iodine was often given the symbol \"J\", for \"Jod\", its name in German; in German texts, \"J\" is still frequently used in place of \"I\".\nProperties.\nIodine is the fourth halogen, being a member of group 17 in the periodic table, below fluorine, chlorine, and bromine; since astatine and tennessine are radioactive, iodine is the heaviest stable halogen. Iodine has an electron configuration of [Kr]5s24d105p5, with the seven electrons in the fifth and outermost shell being its valence electrons. Like the other halogens, it is one electron short of a full octet and is hence an oxidising agent, reacting with many elements in order to complete its outer shell, although in keeping with periodic trends, it is the weakest oxidising agent among the stable halogens: it has the lowest electronegativity among them, just 2.66 on the Pauling scale (compare fluorine, chlorine, and bromine at 3.98, 3.16, and 2.96 respectively; astatine continues the trend with an electronegativity of 2.2). Elemental iodine hence forms diatomic molecules with chemical formula I2, where two iodine atoms share a pair of electrons in order to each achieve a stable octet for themselves; at high temperatures, these diatomic molecules reversibly dissociate a pair of iodine atoms. Similarly, the iodide anion, I\u2212, is the strongest reducing agent among the stable halogens, being the most easily oxidised back to diatomic I2. (Astatine goes further, being indeed unstable as At\u2212 and readily oxidised to At0 or At+.)\nThe halogens darken in colour as the group is descended: fluorine is a very pale yellow, chlorine is greenish-yellow, bromine is reddish-brown, and iodine is violet.\nElemental iodine is slightly soluble in water, with one gram dissolving in 3450\u00a0mL at 20\u00a0\u00b0C and 1280\u00a0mL at 50\u00a0\u00b0C; potassium iodide may be added to increase solubility via formation of triiodide ions, among other polyiodides. Nonpolar solvents such as hexane and carbon tetrachloride provide a higher solubility. Polar solutions, such as aqueous solutions, are brown, reflecting the role of these solvents as Lewis bases; on the other hand, nonpolar solutions are violet, the colour of iodine vapour. Charge-transfer complexes form when iodine is dissolved in polar solvents, hence changing the colour. Iodine is violet when dissolved in carbon tetrachloride and saturated hydrocarbons but deep brown in alcohols and amines, solvents that form charge-transfer adducts.\nThe melting and boiling points of iodine are the highest among the halogens, conforming to the increasing trend down the group, since iodine has the largest electron cloud among them that is the most easily polarised, resulting in its molecules having the strongest Van der Waals interactions among the halogens. Similarly, iodine is the least volatile of the halogens, though the solid still can be observed to give off purple vapour. Due to this property iodine is commonly used to demonstrate sublimation directly from solid to gas, which gives rise to a misconception that it does not melt in atmospheric pressure. Because it has the largest atomic radius among the halogens, iodine has the lowest first ionisation energy, lowest electron affinity, lowest electronegativity and lowest reactivity of the halogens.\nThe interhalogen bond in diiodine is the weakest of all the halogens. As such, 1% of a sample of gaseous iodine at atmospheric pressure is dissociated into iodine atoms at 575\u00a0\u00b0C. Temperatures greater than 750\u00a0\u00b0C are required for fluorine, chlorine, and bromine to dissociate to a similar extent. Most bonds to iodine are weaker than the analogous bonds to the lighter halogens. Gaseous iodine is composed of I2 molecules with an I\u2013I bond length of 266.6\u00a0pm. The I\u2013I bond is one of the longest single bonds known. It is even longer (271.5\u00a0pm) in solid orthorhombic crystalline iodine, which has the same crystal structure as chlorine and bromine. (The record is held by iodine's neighbour xenon: the Xe\u2013Xe bond length is 308.71\u00a0pm.) As such, within the iodine molecule, significant electronic interactions occur with the two next-nearest neighbours of each atom, and these interactions give rise, in bulk iodine, to a shiny appearance and semiconducting properties. Iodine is a two-dimensional semiconductor with a band gap of 1.3\u00a0eV (125\u00a0kJ/mol): it is a semiconductor in the plane of its crystalline layers and an insulator in the perpendicular direction.\nIsotopes.\nNaturally occurring iodine consists of one stable isotope, 127I, and is a mononuclidic element for atomic weight, which is thus a constant of nature determined by that isotope. Radioisotopes are known from 108I to 147I. As other isotopes have half-lives too short to be primordial, it is also monoisotopic.\nThe longest-lived of the radioactive isotopes of iodine is iodine-129, which has a half-life of 16.1\u00a0million\u00a0years, decaying via beta decay to stable xenon-129. Some iodine-129 was formed along with iodine-127 before the formation of the Solar System, but it has by now completely decayed away, making it an extinct radionuclide. Its former presence may be determined from an excess of its daughter xenon-129, but early attempts to use this characteristic to date the supernova source for elements in the Solar System are made difficult by alternative nuclear processes giving iodine-129 and by iodine's volatility at higher temperatures. Due to its mobility in the environment iodine-129 has been used to date very old groundwaters. \nThe vast majority of iodine-129 on Earth today derives from human nuclear activity. Iodine-129 increased 3-8 orders of magnitude after nuclear activity began.\nA small amount of naturally occurring iodine-129 forms from cosmic ray spallation of atmospheric xenon and as a fission product; the ratio 129I/127I is about 10\u221212. \nExcited states of iodine-127 and iodine-129 are often used in M\u00f6ssbauer spectroscopy.\nThe other iodine radioisotopes have much shorter half-lives, less than 60 days. Some of them have medical applications involving the thyroid gland, where the iodine that enters the body is stored and concentrated. Iodine-123 (half-life 13.223 hours) and decays by electron capture to tellurium-123, emitting gamma radiation; it is used in nuclear medicine imaging, including single photon emission computed tomography (SPECT) and X-ray computed tomography (X-Ray CT) scans. Iodine-125 (half-life 59.392 days) is similar, decaying by electron capture to tellurium-125 and emitting low-energy gamma radiation; the second-longest-lived iodine radioisotope, it has uses in biological assays, nuclear medicine imaging and in radiation therapy as brachytherapy to treat a number of conditions, including prostate cancer, uveal melanomas, and brain tumours. Finally, iodine-131 (half-life 8.0249 days) beta-decays to xenon-131 and also emits gamma radiation. It is also be used for medicinal purposes in radiation therapy to the thyroid, when tissue destruction is desired after iodine uptake by the tissue.\nIodine-131 is a common fission product and thus is present in high levels in radioactive fallout. It may then be absorbed through contaminated food, and will also accumulate in the thyroid and damage it through its radiation. The primary risk from exposure to high levels of iodine-131 is the chance occurrence of radiogenic thyroid cancer in later life. Other risks include the possibility of non-cancerous growths and thyroiditis. Protection against the negative effects of iodine-131 upon a release is effected by saturating the thyroid gland with stable iodine-127 in the form of potassium iodide tablets, taken daily for optimal prophylaxis.\nIodine-131 has also been used as a radioactive tracer.\nChemistry and compounds.\nIodine is quite reactive, but it is less so than the lighter halogens, and it is a weaker oxidant. For example, it does not halogenate carbon monoxide, nitric oxide, and sulfur dioxide, which chlorine does. Many metals react with iodine. For the same reason, however, since iodine has the lowest ionisation energy among the halogens and is the most easily oxidised of them, it has a more significant cationic chemistry and its higher oxidation states are rather more stable than those of bromine and chlorine, for example in iodine heptafluoride.\nCharge-transfer complexes.\nThe iodine molecule, I2, dissolves in CCl4 and aliphatic hydrocarbons to give bright violet solutions. In these solvents the absorption band maximum occurs in the 520 \u2013 540\u00a0nm region and is assigned to a \u03c0* to \"\u03c3\"* transition. When I2 reacts with Lewis bases in these solvents a blue shift in I2 peak is seen and the new peak (230 \u2013 330\u00a0nm) arises that is due to the formation of adducts, which are referred to as charge-transfer complexes.\nHydrogen iodide.\nThe simplest compound of iodine is hydrogen iodide, HI. It is a colourless gas that reacts with oxygen to give water and iodine. Although it is useful in iodination reactions in the laboratory, it does not have large-scale industrial uses, unlike the other hydrogen halides. Commercially, it is usually made by reacting iodine with hydrogen sulfide or hydrazine:\n2 I2 + N2H4 H2O\u27f6 4 HI + N2\nAt room temperature, it is a colourless gas, like all of the hydrogen halides except hydrogen fluoride, since hydrogen cannot form strong hydrogen bonds to the large and only mildly electronegative iodine atom. It melts at and boils at . It is an endothermic compound that can exothermically dissociate at room temperature, although the process is very slow unless a catalyst is present: the reaction between hydrogen and iodine at room temperature to give hydrogen iodide does not proceed to completion. The H\u2013I bond dissociation energy is likewise the smallest of the hydrogen halides, at 295\u00a0kJ/mol.\nAqueous hydrogen iodide is known as hydroiodic acid, which is a strong acid. Hydrogen iodide is exceptionally soluble in water: one litre of water will dissolve 425 litres of hydrogen iodide, and the saturated solution has only four water molecules per molecule of hydrogen iodide. Commercial so-called \"concentrated\" hydroiodic acid usually contains 48\u201357% HI by mass; the solution forms an azeotrope with boiling point at 56.7\u00a0g HI per 100\u00a0g solution. Hence hydroiodic acid cannot be concentrated past this point by evaporation of water. Unlike gaseous hydrogen iodide, hydroiodic acid has major industrial use in the manufacture of acetic acid by the Cativa process.\nOther binary iodine compounds.\nWith the exception of the noble gases, nearly all elements on the periodic table up to einsteinium (EsI3 is known) are known to form binary compounds with iodine. Until 1990, nitrogen triiodide was only known as an ammonia adduct. Ammonia-free NI3 was found to be isolable at \u2013196 \u00b0C but spontaneously decomposes at 0 \u00b0C. For thermodynamic reasons related to electronegativity of the elements, neutral sulfur and selenium iodides that are stable at room temperature are also nonexistent, although S2I2 and SI2 are stable up to 183 and 9 K, respectively. As of 2022, no neutral binary selenium iodide has been unambiguously identified (at any temperature). Sulfur-iodine and selenium-iodine polyatomic cations (e.g., [S2I42+][AsF6\u2013]2 and [Se2I42+][Sb2F11\u2013]2) have been prepared and characterised crystallographically.\nGiven the large size of the iodide anion and iodine's weak oxidising power, high oxidation states are difficult to achieve in binary iodides, the maximum known being in the pentaiodides of niobium, tantalum, and protactinium. Iodides can be made by reaction of an element or its oxide, hydroxide, or carbonate with hydroiodic acid, and then dehydrated by mildly high temperatures combined with either low pressure or anhydrous hydrogen iodide gas. These methods work best when the iodide product is stable to hydrolysis. Other syntheses include high-temperature oxidative iodination of the element with iodine or hydrogen iodide, high-temperature iodination of a metal oxide or other halide by iodine, a volatile metal halide, carbon tetraiodide, or an organic iodide. For example, molybdenum(IV) oxide reacts with aluminium(III) iodide at 230\u00a0\u00b0C to give molybdenum(II) iodide. An example involving halogen exchange is given below, involving the reaction of tantalum(V) chloride with excess aluminium(III) iodide at 400\u00a0\u00b0C to give tantalum(V) iodide:\n&lt;chem display=\"block\"&gt;3TaCl5 + \\underset{(excess)}{5AlI3} -&gt; 3TaI5 + 5AlCl3&lt;/chem&gt;\nLower iodides may be produced either through thermal decomposition or disproportionation, or by reducing the higher iodide with hydrogen or a metal, for example:\n&lt;chem display=\"block\"&gt;TaI5{} + Ta -&gt;[\\text{thermal gradient}] [\\ce{630^\\circ C\\ -&gt;\\ 575^\\circ C}] Ta6I14&lt;/chem&gt;\nMost metal iodides with the metal in low oxidation states (+1 to +3) are ionic. Nonmetals tend to form covalent molecular iodides, as do metals in high oxidation states from +3 and above. Both ionic and covalent iodides are known for metals in oxidation state +3 (e.g. scandium iodide is mostly ionic, but aluminium iodide is not). Ionic iodides MI\"n\" tend to have the lowest melting and boiling points among the halides MX\"n\" of the same element, because the electrostatic forces of attraction between the cations and anions are weakest for the large iodide anion. In contrast, covalent iodides tend to instead have the highest melting and boiling points among the halides of the same element, since iodine is the most polarisable of the halogens and, having the most electrons among them, can contribute the most to van der Waals forces. Naturally, exceptions abound in intermediate iodides where one trend gives way to the other. Similarly, solubilities in water of predominantly ionic iodides (e.g. potassium and calcium) are the greatest among ionic halides of that element, while those of covalent iodides (e.g. silver) are the lowest of that element. In particular, silver iodide is very insoluble in water and its formation is often used as a qualitative test for iodine.\nIodine halides.\nThe halogens form many binary, diamagnetic interhalogen compounds with stoichiometries XY, XY3, XY5, and XY7 (where X is heavier than Y), and iodine is no exception. Iodine forms all three possible diatomic interhalogens, a trifluoride and trichloride, as well as a pentafluoride and, exceptionally among the halogens, a heptafluoride. Numerous cationic and anionic derivatives are also characterised, such as the wine-red or bright orange compounds of ICl2+ and the dark brown or purplish black compounds of I2Cl+. Apart from these, some pseudohalides are also known, such as cyanogen iodide (ICN), iodine thiocyanate (ISCN), and iodine azide (IN3).\nIodine monofluoride (IF) is unstable at room temperature and disproportionates very readily and irreversibly to iodine and iodine pentafluoride, and thus cannot be obtained pure. It can be synthesised from the reaction of iodine with fluorine gas in trichlorofluoromethane at \u221245\u00a0\u00b0C, with iodine trifluoride in trichlorofluoromethane at \u221278\u00a0\u00b0C, or with silver(I) fluoride at 0\u00a0\u00b0C. Iodine monochloride (ICl) and iodine monobromide (IBr), on the other hand, are moderately stable. The former, a volatile red-brown compound, was discovered independently by Joseph Louis Gay-Lussac and Humphry Davy in 1813\u20131814 not long after the discoveries of chlorine and iodine, and it mimics the intermediate halogen bromine so well that Justus von Liebig was misled into mistaking bromine (which he had found) for iodine monochloride. Iodine monochloride and iodine monobromide may be prepared simply by reacting iodine with chlorine or bromine at room temperature and purified by fractional crystallisation. Both are quite reactive and attack even platinum and gold, though not boron, carbon, cadmium, lead, zirconium, niobium, molybdenum, and tungsten. Their reaction with organic compounds depends on conditions. Iodine chloride vapour tends to chlorinate phenol and salicylic acid, since when iodine chloride undergoes homolytic fission, chlorine and iodine are produced and the former is more reactive. However, iodine chloride in carbon tetrachloride solution results in iodination being the main reaction, since now heterolytic fission of the I\u2013Cl bond occurs and I+ attacks phenol as an electrophile. However, iodine monobromide tends to brominate phenol even in carbon tetrachloride solution because it tends to dissociate into its elements in solution, and bromine is more reactive than iodine. When liquid, iodine monochloride and iodine monobromide dissociate into I2X+ and IX2- ions (X = Cl, Br); thus they are significant conductors of electricity and can be used as ionising solvents.\nIodine trifluoride (IF3) is an unstable yellow solid that decomposes above \u221228\u00a0\u00b0C. It is thus little-known. It is difficult to produce because fluorine gas would tend to oxidise iodine all the way to the pentafluoride; reaction at low temperature with xenon difluoride is necessary. Iodine trichloride, which exists in the solid state as the planar dimer I2Cl6, is a bright yellow solid, synthesised by reacting iodine with liquid chlorine at \u221280\u00a0\u00b0C; caution is necessary during purification because it easily dissociates to iodine monochloride and chlorine and hence can act as a strong chlorinating agent. Liquid iodine trichloride conducts electricity, possibly indicating dissociation to ICl2+ and ICl4- ions.\nIodine pentafluoride (IF5), a colourless, volatile liquid, is the most thermodynamically stable iodine fluoride, and can be made by reacting iodine with fluorine gas at room temperature. It is a fluorinating agent, but is mild enough to store in glass apparatus. Again, slight electrical conductivity is present in the liquid state because of dissociation to IF4+ and IF6-. The pentagonal bipyramidal iodine heptafluoride (IF7) is an extremely powerful fluorinating agent, behind only chlorine trifluoride, chlorine pentafluoride, and bromine pentafluoride among the interhalogens: it reacts with almost all the elements even at low temperatures, fluorinates Pyrex glass to form iodine(VII) oxyfluoride (IOF5), and sets carbon monoxide on fire.\nIodine oxides and oxoacids.\nIodine oxides are the most stable of all the halogen oxides, because of the strong I\u2013O bonds resulting from the large electronegativity difference between iodine and oxygen, and they have been known for the longest time. The stable, white, hygroscopic iodine pentoxide (I2O5) has been known since its formation in 1813 by Gay-Lussac and Davy. It is most easily made by the dehydration of iodic acid (HIO3), of which it is the anhydride. It will quickly oxidise carbon monoxide completely to carbon dioxide at room temperature, and is thus a useful reagent in determining carbon monoxide concentration. It also oxidises nitrogen oxide, ethylene, and hydrogen sulfide. It reacts with sulfur trioxide and peroxydisulfuryl difluoride (S2O6F2) to form salts of the iodyl cation, [IO2]+, and is reduced by concentrated sulfuric acid to iodosyl salts involving [IO]+. It may be fluorinated by fluorine, bromine trifluoride, sulfur tetrafluoride, or chloryl fluoride, resulting iodine pentafluoride, which also reacts with iodine pentoxide, giving iodine(V) oxyfluoride, IOF3. A few other less stable oxides are known, notably I4O9 and I2O4; their structures have not been determined, but reasonable guesses are IIII(IVO3)3 and [IO]+[IO3]\u2212 respectively.\nMore important are the four oxoacids: hypoiodous acid (HIO), iodous acid (HIO2), iodic acid (HIO3), and periodic acid (HIO4 or H5IO6). When iodine dissolves in aqueous solution, the following reactions occur:\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\nHypoiodous acid is unstable to disproportionation. The hypoiodite ions thus formed disproportionate immediately to give iodide and iodate:\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\nIodous acid and iodite are even less stable and exist only as a fleeting intermediate in the oxidation of iodide to iodate, if at all. Iodates are by far the most important of these compounds, which can be made by oxidising alkali metal iodides with oxygen at 600\u00a0\u00b0C and high pressure, or by oxidising iodine with chlorates. Unlike chlorates, which disproportionate very slowly to form chloride and perchlorate, iodates are stable to disproportionation in both acidic and alkaline solutions. From these, salts of most metals can be obtained. Iodic acid is most easily made by oxidation of an aqueous iodine suspension by electrolysis or fuming nitric acid. Iodate has the weakest oxidising power of the halates, but reacts the quickest.\nMany periodates are known, including not only the expected tetrahedral IO4-, but also square-pyramidal IO53-, octahedral orthoperiodate IO65-, [IO3(OH)3]2\u2212, [I2O8(OH2)]4\u2212, and I2O94-. They are usually made by oxidising alkaline sodium iodate electrochemically (with lead(IV) oxide as the anode) or by chlorine gas:\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\nThey are thermodymically and kinetically powerful oxidising agents, quickly oxidising Mn2+ to MnO4-, and cleaving glycols, \u03b1-diketones, \u03b1-ketols, \u03b1-aminoalcohols, and \u03b1-diamines. Orthoperiodate especially stabilises high oxidation states among metals because of its very high negative charge of \u22125. Orthoperiodic acid, H5IO6, is stable, and dehydrates at 100\u00a0\u00b0C in a vacuum to Metaperiodic acid, HIO4. Attempting to go further does not result in the nonexistent iodine heptoxide (I2O7), but rather iodine pentoxide and oxygen. Periodic acid may be protonated by sulfuric acid to give the I(OH)6+ cation, isoelectronic to Te(OH)6 and Sb(OH)6-, and giving salts with bisulfate and sulfate.\nPolyiodine compounds.\nWhen iodine dissolves in strong acids, such as fuming sulfuric acid, a bright blue paramagnetic solution including I2+ cations is formed. A solid salt of the diiodine cation may be obtained by oxidising iodine with antimony pentafluoride:\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\nThe salt I2Sb2F11 is dark blue, and the blue tantalum analogue I2Ta2F11 is also known. Whereas the I\u2013I bond length in I2 is 267\u00a0pm, that in I2+ is only 256\u00a0pm as the missing electron in the latter has been removed from an antibonding orbital, making the bond stronger and hence shorter. In fluorosulfuric acid solution, deep-blue I2+ reversibly dimerises below \u221260\u00a0\u00b0C, forming red rectangular diamagnetic I42+. Other polyiodine cations are not as well-characterised, including bent dark-brown or black I3+ and centrosymmetric \"C\"2\"h\" green or black I5+, known in the AsF6- and AlCl4- salts among others.\nThe only important polyiodide anion in aqueous solution is linear triiodide, I3-. Its formation explains why the solubility of iodine in water may be increased by the addition of potassium iodide solution:\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\nMany other polyiodides may be found when solutions containing iodine and iodide crystallise, such as I5-, I9-, I42-, and I82-, whose salts with large, weakly polarising cations such as Cs+ may be isolated.\nOrganoiodine compounds.\nOrganoiodine compounds have been fundamental in the development of organic synthesis, such as in the Hofmann elimination of amines, the Williamson ether synthesis, the Wurtz coupling reaction, and in Grignard reagents.\nThe carbon\u2013iodine bond is a common functional group that forms part of core organic chemistry; formally, these compounds may be thought of as organic derivatives of the iodide anion. The simplest organoiodine compounds, alkyl iodides, may be synthesised by the reaction of alcohols with phosphorus triiodide; these may then be used in nucleophilic substitution reactions, or for preparing Grignard reagents. The C\u2013I bond is the weakest of all the carbon\u2013halogen bonds due to the minuscule difference in electronegativity between carbon (2.55) and iodine (2.66). As such, iodide is the best leaving group among the halogens, to such an extent that many organoiodine compounds turn yellow when stored over time due to decomposition into elemental iodine; as such, they are commonly used in organic synthesis, because of the easy formation and cleavage of the C\u2013I bond. They are also significantly denser than the other organohalogen compounds thanks to the high atomic weight of iodine. A few organic oxidising agents like the iodanes contain iodine in a higher oxidation state than \u22121, such as 2-iodoxybenzoic acid, a common reagent for the oxidation of alcohols to aldehydes, and iodobenzene dichloride (PhICl2), used for the selective chlorination of alkenes and alkynes. One of the more well-known uses of organoiodine compounds is the so-called iodoform test, where iodoform (CHI3) is produced by the exhaustive iodination of a methyl ketone (or another compound capable of being oxidised to a methyl ketone), as follows:\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\nSome drawbacks of using organoiodine compounds as compared to organochlorine or organobromine compounds is the greater expense and toxicity of the iodine derivatives, since iodine is expensive and organoiodine compounds are stronger alkylating agents. For example, iodoacetamide and iodoacetic acid denature proteins by irreversibly alkylating cysteine residues and preventing the reformation of disulfide linkages.\nHalogen exchange to produce iodoalkanes by the Finkelstein reaction is slightly complicated by the fact that iodide is a better leaving group than chloride or bromide. The difference is nevertheless small enough that the reaction can be driven to completion by exploiting the differential solubility of halide salts, or by using a large excess of the halide salt. In the classic Finkelstein reaction, an alkyl chloride or an alkyl bromide is converted to an alkyl iodide by treatment with a solution of sodium iodide in acetone. Sodium iodide is soluble in acetone and sodium chloride and sodium bromide are not. The reaction is driven toward products by mass action due to the precipitation of the insoluble salt.\nOccurrence and production.\nIodine is the least abundant of the stable halogens, comprising only 0.46\u00a0parts per million of Earth's crustal rocks (compare: fluorine: 544\u00a0ppm, chlorine: 126\u00a0ppm, bromine: 2.5\u00a0ppm) making it the 60th most abundant element. Iodide minerals are rare, and most deposits that are concentrated enough for economical extraction are iodate minerals instead. Examples include lautarite, Ca(IO3)2, and dietzeite, 7Ca(IO3)2\u00b78CaCrO4. These are the minerals that occur as trace impurities in the caliche, found in Chile, whose main product is sodium nitrate. In total, they can contain at least 0.02% and at most 1% iodine by mass. Sodium iodate is extracted from the caliche and reduced to iodide by sodium bisulfite. This solution is then reacted with freshly extracted iodate, resulting in comproportionation to iodine, which may be filtered off.\nThe caliche was the main source of iodine in the 19th century and continues to be important today, replacing kelp (which is no longer an economically viable source), but in the late 20th century brines emerged as a comparable source. The Japanese Minami Kant\u014d gas field east of Tokyo and the American Anadarko Basin gas field in northwest Oklahoma are the two largest such sources. The brine is hotter than 60\u00a0\u00b0C from the depth of the source. The brine is first purified and acidified using sulfuric acid, then the iodide present is oxidised to iodine with chlorine. An iodine solution is produced, but is dilute and must be concentrated. Air is blown into the solution to evaporate the iodine, which is passed into an absorbing tower, where sulfur dioxide reduces the iodine. The hydrogen iodide (HI) is reacted with chlorine to precipitate the iodine. After filtering and purification the iodine is packed.\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;2 HI + Cl2 \u2192 I2\u2191 + 2 HCl\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;I2 + 2 H2O + SO2 \u2192 2 HI + H2SO4\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;2 HI + Cl2 \u2192 I2\u2193 + 2 HCl\nThese sources ensure that Chile and Japan are the largest producers of iodine today. The companies Sociedad Qu\u00edmica y Minera (SQM) and Cosayach lead iodine mining in Chile. Alternatively, the brine may be treated with silver nitrate to precipitate out iodine as silver iodide, which is then decomposed by reaction with iron to form metallic silver and a solution of iron(II) iodide. The iodine is then liberated by displacement with chlorine.\nLarge purple clouds of sublimated iodine have been observed at iodine extraction sites.\nApplications.\nAbout half of all produced iodine goes into various organoiodine compounds, another 15% remains as the pure element, another 15% is used to form potassium iodide, and another 15% for other inorganic iodine compounds. Among the major uses of iodine compounds are catalysts, animal feed supplements, stabilisers, dyes, colourants and pigments, pharmaceutical, sanitation (from tincture of iodine), and photography; minor uses include smog inhibition, cloud seeding, and various uses in analytical chemistry.\nX-ray imaging.\nAs an element with high electron density and atomic number, iodine efficiently absorbs X-rays. X-ray radiocontrast agents is the top application for iodine. In this application, Organoiodine compounds are injected intravenously. This application is often in conjunction with advanced X-ray techniques such as angiography and CT scanning. At present, all water-soluble radiocontrast agents rely on iodine-containing compounds.\nIodine absorbs X-rays with energies less than 33.3\u00a0keV due to the photoelectric effect of the innermost electrons. \nBiocide.\nUse of iodine as a biocide represents a major application of the element, ranked 2nd by weight. Elemental iodine (I2) is used as an antiseptic in medicine. A number of water-soluble compounds, from triiodide (I3\u2212, generated \"in situ\" by adding iodide to poorly water-soluble elemental iodine) to various iodophors, slowly decompose to release I2 when applied.\nOptical polarising films.\nThin-film-transistor liquid crystal displays rely on polarisation. The liquid crystal transistor is sandwiched between two polarising films and illuminated from behind. The two films prevent light transmission unless the transistor in the middle of the sandwich rotates the light. Iodine-impregnated polymer films are used in polarising optical components with the highest transmission and degree of polarisation.\nCo-catalyst.\nAnother significant use of iodine is as a cocatalyst for the production of acetic acid by the Monsanto and Cativa processes. In these technologies, hydroiodic acid converts the methanol feedstock into methyl iodide, which undergoes carbonylation. Hydrolysis of the resulting acetyl iodide regenerates hydroiodic acid and gives acetic acid. The majority of acetic acid is produced by these approaches.\nNutrition.\nSalts of iodide and iodate are used extensively in human and animal nutrition. This application reflects the status of iodide as an essential element, being required for two hormones. The production of ethylenediamine dihydroiodide, provided as a nutritional supplement for livestock, consumes a large portion of available iodine. Iodine is a component of iodised salt. \nA saturated solution of potassium iodide is used to treat acute thyrotoxicosis. It is also used to block uptake of iodine-131 in the thyroid gland (see isotopes section above), when this isotope is used as part of radiopharmaceuticals (such as iobenguane) that are not targeted to the thyroid or thyroid-type tissues.\nOthers.\nInorganic iodides find specialised uses. Titanium, zirconium, hafnium, and thorium are purified by the Van Arkel\u2013de Boer process, which involves the reversible formation of the tetraiodides of these elements. Silver iodide is a major ingredient to traditional photographic film. Thousands of kilograms of silver iodide are used annually for cloud seeding to induce rain.\nThe organoiodine compound erythrosine is an important food colouring agent. Perfluoroalkyl iodides are precursors to important surfactants, such as perfluorooctanesulfonic acid.\n125I is used as the radiolabel in investigating which ligands go to which plant pattern recognition receptors (PRRs).\nAn iodine based thermochemical cycle has been evaluated for hydrogen production using energy from nuclear power. The cycle has three steps. At , iodine reacts with sulfur dioxide and water to give hydrogen iodide and sulfuric acid:\nAfter a separation stage, at sulfuric acid splits in sulfur dioxide and oxygen:\nHydrogen iodide, at , gives hydrogen and the initial element, iodine:\nThe yield of the cycle (ratio between lower heating value of the produced hydrogen and the consumed energy for its production, is approximately 38%. As of 2020[ [update]], the cycle is not a competitive means of producing hydrogen.\nSpectroscopy.\nThe spectrum of the iodine molecule, I2, consists of (not exclusively) tens of thousands of sharp spectral lines in the wavelength range 500\u2013700\u00a0nm. It is therefore a commonly used wavelength reference (secondary standard). By measuring with a spectroscopic Doppler-free technique while focusing on one of these lines, the hyperfine structure of the iodine molecule reveals itself. A line is now resolved such that either 15 components (from even rotational quantum numbers, \"J\"even), or 21 components (from odd rotational quantum numbers, \"J\"odd) are measurable.\nCaesium iodide and thallium-doped sodium iodide are used in crystal scintillators for the detection of gamma rays. The efficiency is high and energy dispersive spectroscopy is possible, but the resolution is rather poor.\nChemical analysis.\nThe iodide and iodate anions can be used for quantitative volumetric analysis, for example in iodometry. Iodine and starch form a blue complex, and this reaction is often used to test for either starch or iodine and as an indicator in iodometry. The iodine test for starch is still used to detect counterfeit banknotes printed on starch-containing paper.\nThe iodine value is the mass of iodine in grams that is consumed by 100 grams of a chemical substance typically fats or oils. Iodine numbers are often used to determine the amount of unsaturation in fatty acids. This unsaturation is in the form of double bonds, which react with iodine compounds.\nPotassium tetraiodomercurate(II), K2HgI4, is also known as Nessler's reagent. It is once was used as a sensitive spot test for ammonia. Similarly, Mayer's reagent (potassium tetraiodomercurate(II) solution) is used as a precipitating reagent to test for alkaloids. Aqueous alkaline iodine solution is used in the iodoform test for methyl ketones.\nBiological role.\nIodine is an essential element for life and, at atomic number \"Z\" = 53, is the heaviest element commonly needed by living organisms. (Lanthanum and the other lanthanides, as well as tungsten with \"Z\" = 74 and uranium with \"Z\" = 92, are used by a few microorganisms.) It is required for the synthesis of the growth-regulating thyroid hormones tetraiodothyronine and triiodothyronine (T4 and T3 respectively, named after their number of iodine atoms). A deficiency of iodine leads to decreased production of T3 and T4 and a concomitant enlargement of the thyroid tissue in an attempt to obtain more iodine, causing the disease goitre. The major form of thyroid hormone in the blood is tetraiodothyronine (T4), which has a longer life than triiodothyronine (T3). In humans, the ratio of T4 to T3 released into the blood is between 14:1 and 20:1. T4 is converted to the active T3 (three to four times more potent than T4) within cells by deiodinases (5'-iodinase). These are further processed by decarboxylation and deiodination to produce iodothyronamine (T1a) and thyronamine (T0a'). All three isoforms of the deiodinases are selenium-containing enzymes; thus metallic selenium is needed for triiodothyronine and tetraiodothyronine production.\nIodine accounts for 65% of the molecular weight of T4 and 59% of T3. Fifteen to 20\u00a0mg of iodine is concentrated in thyroid tissue and hormones, but 70% of all iodine in the body is found in other tissues, including mammary glands, eyes, gastric mucosa, thymus, cerebrospinal fluid, choroid plexus, arteries, cervix, salivary glands. During pregnancy, the placenta is able to store and accumulate iodine. In the cells of those tissues, iodine enters directly by sodium-iodide symporter (NIS). The action of iodine in mammal tissues is related to fetal and neonatal development, and in the other tissues, it is known. \nDietary recommendations and intake.\nThe daily levels of intake recommended by the United States National Academy of Medicine are between 110 and 130 \u03bcg for infants up to 12 months, 90\u00a0\u03bcg for children up to eight years, 130\u00a0\u03bcg for children up to 13 years, 150\u00a0\u03bcg for adults, 220\u00a0\u03bcg for pregnant women and 290\u00a0\u03bcg for lactating women. The Tolerable Upper Intake Level (TUIL) for adults is 1,100\u00a0\u03bcg/day. This upper limit was assessed by analysing the effect of supplementation on thyroid-stimulating hormone.\nThe European Food Safety Authority (EFSA) refers to the collective set of information as Dietary Reference Values, with Population Reference Intake (PRI) instead of RDA, and Average Requirement instead of EAR; AI and UL are defined the same as in the United States. For women and men ages 18 and older, the PRI for iodine is set at 150\u00a0\u03bcg/day; the PRI during pregnancy and lactation is 200\u00a0\u03bcg/day. For children aged 1\u201317 years, the PRI increases with age from 90 to 130\u00a0\u03bcg/day. These PRIs are comparable to the U.S. RDAs with the exception of that for lactation.\nThe thyroid gland needs 70\u00a0\u03bcg/day of iodine to synthesise the requisite daily amounts of T4 and T3. The higher recommended daily allowance levels of iodine seem necessary for optimal function of a number of body systems, including mammary glands, gastric mucosa, salivary glands, brain cells, choroid plexus, thymus, arteries.\nNatural food sources of iodine include seafood which contains fish, seaweeds, kelp, shellfish and other foods which contain dairy products, eggs, meats, vegetables, so long as the animals ate iodine richly, and the plants are grown on iodine-rich soil. Iodised salt is fortified with potassium iodate, a salt of iodine, potassium, oxygen.\nAs of 2000, the median intake of iodine from food in the United States was 240 to 300\u00a0\u03bcg/day for men and 190 to 210\u00a0\u03bcg/day for women. The general US population has adequate iodine nutrition, with lactating women and pregnant women having a mild risk of deficiency. In Japan, consumption was considered much higher, ranging between 5,280\u00a0\u03bcg/day to 13,800\u00a0\u03bcg/day from wakame and kombu that are eaten, both in the form of kombu and wakame and kombu and wakame umami extracts for soup stock and potato chips. However, new studies suggest that Japan's consumption is closer to 1,000\u20133,000\u00a0\u03bcg/day. The adult UL in Japan was last revised to 3,000\u00a0\u03bcg/day in 2015.\nAfter iodine fortification programs such as iodisation of salt have been done, some cases of iodine-induced hyperthyroidism have been observed (so-called Jod-Basedow phenomenon). The condition occurs mainly in people above 40 years of age, and the risk is higher when iodine deficiency is high and the first rise in iodine consumption is high.\nDeficiency.\nIn areas where there is little iodine in the diet, which are remote inland areas and faraway mountainous areas where no iodine rich foods are eaten, iodine deficiency gives rise to hypothyroidism, symptoms of which are extreme fatigue, goitre, mental slowing, depression, low weight gain, and low basal body temperatures. Iodine deficiency is the leading cause of preventable intellectual disability, a result that occurs primarily when babies or small children are rendered hypothyroidic by no iodine. The addition of iodine to salt has largely destroyed this problem in wealthier areas, but iodine deficiency remains a serious public health problem in poorer areas today. Iodine deficiency is also a problem in certain areas of all continents of the world. Information processing, fine motor skills, and visual problem solving are normalised by iodine repletion in iodine-deficient people.\nPrecautions.\nToxicity.\n&lt;templatestyles src=\"Chembox/styles.css\"/&gt;\nChemical compound\nThe safe upper limit for iodine consumption is ; higher doses may be dangerous for people with certain thyroid issues. However the average Japanese person consumes 5-14 times this much dietary iodine from seaweed (kombu) with no evident toxicity.\nLiquid Povidone-iodine (Betadine) trapped against the skin resulted in chemical burns in some rare cases.\nOccupational exposure.\nThe U.S. Occupational Safety and Health Administration (OSHA) has set the legal limit (Permissible exposure limit) for iodine exposure in the workplace at 0.1 ppm (1\u00a0mg/m3) during an 8-hour workday. The National Institute for Occupational Safety and Health (NIOSH) has set a Recommended exposure limit (REL) of 0.1\u00a0ppm (1\u00a0mg/m3) during an 8-hour workday. At levels of 2 ppm, iodine is immediately dangerous to life and health.\nReaction to iodinated contrast media.\nIodinated contrast media used in computed tomographic medical scans may cause adverse reactions, from a mild rash to fatal anaphylaxis, in some people. Previous reactions to the media is the strongest indicator of future issues. Such reactions have led to the misconception (widely held, even among physicians) that some people are allergic to iodine itself. Improvements in the formulation of the contrast media has decreased the probability of hypersensitivity reactions.\nUS DEA List I status.\nPhosphorus reduces iodine to hydroiodic acid, which is a reagent effective for reducing ephedrine and pseudoephedrine to methamphetamine. For this reason, iodine was designated by the United States Drug Enforcement Administration as a List I precursor chemical under 21 CFR 1310.02.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "14751", "revid": "28481209", "url": "https://en.wikipedia.org/wiki?curid=14751", "title": "IKEA", "text": "Multinational furniture company founded in Sweden\nIKEA ( , ) is a multinational conglomerate founded in Sweden that designs and sells &lt;templatestyles src=\"Template:Visible anchor/styles.css\" /&gt;ready-to-assemble furniture, household goods, and various related services.\nIKEA was started in 1943 by Ingvar Kamprad, and has been the world's largest furniture retailer since 2008. The brand name is an acronym of the initials of the names of \"Ingvar Kamprad\", the founder, \"Elmtaryd\", the family farm where Kamprad was born, and \"Agunnaryd\", Kamprad's hometown in Sm\u00e5land, southern Sweden.\nThe company is primarily known for its modernist furniture designs, simple approach to interior design, and immersive shopping concept, based around decorated room settings within big-box stores, where customers can interact with products. In addition, the firm is known for its ready-to-assemble model of furniture sales, continuous product development, and attention to cost control other elements which have allowed IKEA to establish lower prices than its competitors.\nIKEA is owned and operated by a series of not-for-profit and for-profit corporations collectively known and managed as Inter IKEA Group and Ingka Group. The IKEA brand itself is owned and managed by Inter IKEA Systems B.V., a company incorporated and headquartered in the Netherlands. \nAs of April\u00a02025[ [update]], there are 483 IKEA stores operating in 63 countries, and in fiscal year 2024, \u20ac45.1billion worth of IKEA goods were sold. IKEA stores are operated under franchise from Inter IKEA Systems B.V., which handles branding, design, manufacturing, and supply. Ingka Group operates the majority of IKEA stores as a franchisee and pays royalties to Inter IKEA Systems B.V. Some IKEA stores are also operated by independent franchises. The IKEA website contains about 12,000 products and there were over 4.6billion visitors to IKEA's websites in FY2024.\nHistory.\nIn 1943, the 17-year-old Ingvar Kamprad founded IKEA as a mail-order sales business and began to resell furniture five years later. The first store was opened in \u00c4lmhult, Sm\u00e5land, Sweden, in 1958, under the name \"M\u00f6bel-IK\u00c9A\" ( meaning \"furniture\" in Swedish).\"IKEA\" is an acronym that stands for \"Ingvar Kamprad\", the name of the founder, \"Elmtaryd\", the name of the farm on which he grew up, and \"Agunnaryd\", the name of village close to Elmtaryd.\nThe first stores outside Sweden were opened in Norway (1963) and Denmark (1969). The stores spread to other parts of Europe in the 1970s, with the first store outside Scandinavia opening in Switzerland (1973), followed by West Germany (1974), Japan (1974), Australia, Hong Kong (1975), Canada (1976), Singapore, Spain and the Netherlands (1978). IKEA further expanded in the 1980s, opening stores in countries such as France (1981), Belgium (1984), the United States (1985), the United Kingdom (1987), and Italy (1989). Germany and the United States, with 55 stores (three in Puerto Rico in the latter) each, are the company's biggest markets.\nIKEA entered Latin America in February 2010, opening in the Dominican Republic. As for the region's largest markets, on 8 April 2021, a store was opened in Mexico City.\nIn August 2018, IKEA opened its first store in India, in Hyderabad. There are now stores in Bengaluru and Mumbai.\nIn November 2021, IKEA opened its largest store in the world, measuring , in the Philippines, at the Mall of Asia Complex in Pasay City, Metro Manila ().\nIn March 2022, IKEA announced the closing of all 17 stores in Russia, resulting from the 2022 Russian invasion of Ukraine. Because of the ongoing war and unimproved situation in Russia, IKEA said on 15 June that it would sell factories, close offices and reduce its workforce. Later it became known that IKEA does not plan to sell its business but expected to return to Russia within two years. By October 2022, IKEA laid off about 10,000 Russian employees. In September 2023, the &lt;templatestyles src=\"Template:Visible anchor/styles.css\" /&gt;MEGA chain of 14 supermarkets, then owned by Ingka, was bought by the Russian Gazprombank.\nIKEA was hit hard by COVID-19 due to lockdowns in various countries, like in the UK and Canada. As a result of fallen demand, its annual catalogue ceased publication after 70 years in print. The prices of their products have risen significantly in 2022 owning to rising costs and inflation. In April 2022, IKEA shut down one of its stores in Guiyang when sales took a significant hit from the pandemic. Because of strict COVID-19 lockdowns in China, IKEA closed another store in Shanghai by July 2022.\nOn 10 August 2022, IKEA opened its first store in Chile, the first store in South America. Another store opened in Colombia in September 2023 in Bogot\u00e1, soon to be followed by a store in Peru.\nStore layout.\nTraditional store layout.\nIKEA stores are typically blue buildings with yellow accents \u2014 Sweden's national colours. They are often designed in a one-way layout, leading customers counter-clockwise along what IKEA calls \"the long natural way\", designed to encourage the customer to see the store in its entirety (as opposed to a traditional retail store, which allows a customer to go directly to the section where the desired goods and services are displayed). There are often shortcuts to other parts of the showroom.\nThe sequence first involves going through the furniture showrooms, making note of selected items. The showroom usually consists of simulated room settings where customers can see the actual furniture in use, e.g., a living room with a sofa, a TV set, a bookcase, and a dining table, accessorized with plants, cushions, rugs, lamps, plates, glasses, and cutlery. Showroom sections are usually displayed in the order of the rooms of a house: living rooms, dining rooms, kitchens, bedrooms, and children\u2019s rooms. The customer then collects a shopping cart and proceeds to an open-shelf \"Market Hall\" warehouse for smaller items. Lastly, the self-service furniture warehouse stores the showroom products in flat-pack form for the customer to collect the ones previously noted. Sometimes, they are directed to collect products from an external warehouse on the same site or at a site nearby after purchase. Finally, customers pay for their products at a cash register. Not all furniture is stocked at the store level, such as particular sofa colours needing to be shipped from a warehouse to the customer's home or the store.\nMost stores follow the layout of having the showroom upstairs with the marketplace and self-service warehouse downstairs. Some stores are single-level, while others have separate warehouses to allow more stock to be kept on-site. Single-level stores are found predominantly in areas where the cost of land would be less than the cost of building a two-level store. Some stores have dual-level warehouses with machine-controlled silos to allow large quantities of stock to be accessed throughout the selling day.\nMost IKEA stores offer an \"as-is\" or \"bargain corner\" (recently rebranded as \"re-shop and re-use\") area at the end of the warehouse, just before the cash registers. Returned, damaged, and formerly showcased products are displayed here and sold with a significant discount.\nIn March 2022, IKEA swiftly exited the Russian market, due to Russia's invasion of Ukraine, leading to a surplus of items that were earmarked for the Russian market in IKEA's warehouses. To offload these items quickly, IKEA sold them in a number of non-Russian IKEA stores near the bargain corner at a discount.\nAlternative smaller store formats.\nThe majority of IKEA stores are located outside of city centres, primarily because of land cost and traffic access. Smaller store formats have been unsuccessfully tested in the past (the \"midi\" concept in the early 1990s, which was tested in Ottawa and Heerlen with , or a \"boutique\" shop in Manhattan).\nNew formats for full-size stores.\nA new format for a full-size, city centre store was introduced with the opening of the Manchester store, situated in Ashton-under-Lyne in 2006. Another store, in Coventry, opened in December 2007. The store had seven floors and a flow different from that of other IKEA stores; however, it closed down in 2020 due to the site being deemed unsuitable for future business. IKEA's Southampton store that opened in February 2009 is also in the city centre and built in an urban style similar to that of the Coventry store. IKEA built these stores in response to UK government restrictions on large retail establishments outside city centres.\nAdaptation to Japanese market.\nJapan was another market where IKEA performed badly, exited the market completely, and then re-entered with an alternative store design and layout with which it finally found success. IKEA entered the Japanese market in 1974 through a franchise arrangement with a local partner, only to withdraw in failure in 1986. Japan was one of the first markets outside its original core European market. Despite Japan being the then-second-largest economy in the world, IKEA did not adapt its store layout strategy to the Japanese consumer. Japanese consumers did not have a culture of DIY furniture assembly, and many in the early days had no way to haul flat-packs home to their small apartments. Nor did the store layouts familiar to European customers initially make sense to Japanese consumers, so before re-entering the Japanese market in 2006, IKEA management did extensive local market research on more effective store layouts. One area of local adaptation was the room displays common to every IKEA store worldwide. Rather than just replicate a European room layout, the Japan management was careful to set up room displays more closely resembling Japanese apartment rooms, such as one for \"a typical Japanese teenage boy who likes baseball and computer games\".\nInner-city stores.\nIKEA adapted its store location and services to the 'inner-city' format for expansion in China, unlike other countries where IKEA stores, for economic and planning restrictions reasons, tend to be just outside city centres. In China, planning restrictions are less of an issue due to the lack of cars for much of its customer base. Accordingly, in store design alternatives, IKEA has had to offer store locations and formats closer to public transportation. The store design alternative thinking and strategy in China has been to locate stores to facilitate access for non-car owning customers. In some locations in China, IKEA stores can be found not in the usual suburban or near airport locations like other countries, but rather places such as downtown shopping centres with a 'mini-IKEA' store to attract shoppers. One store design alternative trend IKEA has implemented has been 'pop-up' stores along social media platforms in its advertising strategy, for the first time as a company, to reach new customer demographics while still reinforcing its global brand locally in China.\nIKEA moved into Topshop's former flagship store on 214 Oxford Street, central London, with the store officially opening on 1 May 2025.\nSmall-sized stores.\nIn Hong Kong, where shop space is limited and costly, IKEA has opened four stores, all in multi-storey commercial buildings. They are smaller than other IKEA stores but large by Hong Kong standards. In addition to tailoring store sizes for specific countries, IKEA alters the sizes of products to accommodate cultural differences. In 2015, IKEA announced it would attempt smaller store designs at locations in Canada. IKEA claimed this new model would allow it to expand quickly into new markets rather than spending years opening a full-size store.\nIn 2020, IKEA opened at Al Wahda Mall in Abu Dhabi, United Arab Emirates, which, at , was one of the smallest IKEA stores to date. The company also opened at 360 Mall in Kuwait and in Harajuku, a trendy part of Tokyo, that same year. The size of the Kuwaiti 360 Mall store was slightly larger than Al Wahda's (despite bringing a similar concept), at , built as an extension of the mall. As for IKEA Harajuku, the , 7-storey store houses the chain's first and only \"konbini\" concept. In 2021, IKEA opened another one of its smallest stores, located at the JEM Mall in Jurong East, Singapore. Replacing the liquidated department store Robinsons, IKEA Jurong is only , encompassing three levels; it was the first location in Southeast Asia that did not provide the \"Market Hall\" warehouse in its store. Also during 2021, IKEA opened a small-store-format location on Bali, Indonesia, replacing the liquidated former Giant hypermarket. IKEA Bali is dubbed \"Customer Meeting Point\", and is the smallest store to open thus far, at .\nIn 2022, another smaller store was opened inside Livat Hammersmith, London, at , followed by a store inside Mall Taman Anggrek, Jakarta, which was opened on 7 April 2022.\nProducts and services.\nFurniture and homeware.\nRather than being sold pre-assembled, much of IKEA's furniture is designed to be assembled by the customer. The company claims that this helps reduce costs and use of packaging by not shipping air; the volume of a bookcase, for example, is considerably less if it is shipped unassembled rather than assembled. This is also more practical for European customers using public transport, because flat packs can be more easily carried.\nIKEA contends that it has been a pioneering force in sustainable approaches to mass consumer culture. Kamprad calls this \"democratic design\", meaning that the company applies an integrated approach to manufacturing and design (see also environmental design). In response to the explosion of human population and material expectations in the 20th and 21st centuries, the company implements economies of scale, capturing material streams and creating manufacturing processes that hold costs and resource use down, such as the extensive use of medium-density fibreboard (\"MDF\"), also called \"particle board\".\nNotable items of IKEA furniture include the Po\u00e4ng armchair, the Billy bookcase, and the Klippan sofa, all of which have sold by the tens of millions since the late 1970s and early 1980s.\nThe IKEA and LEGO brands teamed up to create a range of simple storage solutions for children and adults.\nThe \"IKEA Effect\".\nThe IKEA effect, a term commonly used to describe the unique philosophy of IKEA product's customer assembly. Recent studies show customers willingness to pay is increased dramatically when customers contribute to the final product. IKEA products are notably easy to hack and DIY, which also increases sales among customers. The term IKEA Hackers comes from a group who hack and create new things using IKEA products. DIY creates community through contribution, and this phenomenon is called the \"IKEA Effect\".\nFurniture and product naming.\nIKEA products are identified by one-word (occasionally, two-word) names, predominantly in the Swedish language (or otherwise Scandinavian in origin). With few exceptions, most product names are based on a special naming system developed by the company. The company founder Kamprad was dyslexic, and found that naming the furniture with proper names and words, rather than a long product code, made the products easier to identify and remember. Products are usually named after locations in Scandinavian countries, using names of places in Sweden for sofas and coffee tables, Denmark for textiles, and Norway for beds. Lamps get their names from seas and lakes, while outdoor furniture is named after islands.\nA number of IKEA's products bearing Swedish names have (or have had) pronunciations that are humorous to some and offensive to others (but no less \"lost-in-translation\"), by not only English-speakers but speakers of many different languages. At times, this product identification has resulted in certain names being changed or withdrawn completely from certain markets. More often than not, this confusion is simply a result of the Swedish language not being executed correctly, let alone understood, by the reader; nonetheless, this has resulted in potentially \"naughty\"\u2014or even gravely offensive\u2014connotations, depending on the area in question. Notable examples (for English-speakers) include a since-discontinued (2013) computer desk called \"jerker\" (referring to \"the jerks\" or \"jerks\"), a foliar plant spray called \"fukta\" (\"moisten\"), a workbench called \"fartfull\" (\"speedy\", \"quick\"), and a table called \"lyckhem\" (pronounced roughly as \"look-em\"), meaning \"bliss\" or a \"happy home\".\nDue to several products being named after real places, some locales have ended-up sharing names with objects considered generally unpleasant, such as a toilet brush being named after the lake of Bolmen, or a rubbish bin named after the Norwegian village of Tofte. In November 2021, VisitSweden.com launched a jocular campaign named \"Discover the Originals\", which invited tourists to visit the physical locations that have received such unfortunate associations with IKEA products.\nDesign services.\nIn March 2021, IKEA launched IKEA Studio in partnership with Apple Inc., an app enabling customers to design full-scale rooms with IKEA furniture using augmented reality on an iPhone.\nSmart home.\nIn 2016, IKEA started a move into the smart home business. The IKEA TR\u00c5DFRI smart lighting kit was one of the first ranges signalling this change. IKEA has also started a partnership with Philips Hue. The wireless charging furniture, integrating wireless Qi charging into everyday furniture, is another strategy for the smart home business.\nA collaboration to build Sonos smart speaker technology into furniture sold by IKEA was announced in December 2017. The first products resulting from the collaboration launched in August 2019.\nUnder the product name SYMFONISK, IKEA and Sonos have made two distinct wireless speakers that integrate with existing Sonos households or can be used to start with the Sonos ecosystem, one that's also a lamp and another that's a more traditional-looking bookshelf speaker. Both products, as well as accessories for the purpose of mounting the bookshelf speakers, have gone on sale worldwide on 1 August.\nFrom the start, IKEA SYMFONISK can only be controlled from the Sonos app, but IKEA added support for the speakers in their own Home Smart app to be paired with scenes that control both the lights, air purifiers, smart plugs and smart blinds together with the speakers.\nHouses and flats.\nIKEA has also expanded its product base to include flat-pack houses and apartments, in an effort to cut the prices involved in a first-time buyer's home. The IKEA product, named BoKlok, was launched in Sweden in 1996 in a joint venture with Skanska. Now working in the Nordic countries and in the UK, sites confirmed in England include London, Ashton-under-Lyne, Leeds, Gateshead, Warrington, Bristol, and Liverpool.\nSolar PV systems.\nAt the end of September 2013, the company announced that solar panel packages, so-called \"residential kits\", for houses would be sold at 17 UK stores by mid-2014. The decision followed a successful pilot project at the Lakeside IKEA store, whereby one photovoltaic system was sold almost every day. The solar CIGS panels are manufactured by Solibro, a German-based subsidiary of the Chinese company Hanergy. By the end of 2014, IKEA began to sell Solibro's solar residential kits in the Netherlands and in Switzerland. In November 2015, IKEA ended its contract with Hanergy and in April 2016 started working with Solarcentury to sell solar panels in the United Kingdom. The deal would allow customers to be able to order panels online and at three stores before being expanded to all United Kingdom stores by the end of summer.\nFurniture rental.\nIn April 2019, the company announced that it would begin test marketing a new concept, renting furniture to customers. One of the motivating factors was that inexpensive IKEA products were viewed as \"disposable\" and often ended up being scrapped after a few years of use. This was at a time when, especially younger buyers, said they wanted to minimize their impact on the environment. The company understood this view. In an interview, Jesper Brodin, the chief executive of Ingka Group (the largest franchisee of IKEA stores), commented that \"climate change and unsustainable consumption are among the biggest challenges we face in society\". The other strategic objectives of the plan were to be more affordable and more convenient. The company said it would test the rental concept in all 30 markets by 2020, expecting it to increase the number of times a piece of furniture would be used before recycling.\nRestaurant and food markets.\nThe first IKEA store opened in 1958 with a small cafe that transitioned into a full-blown restaurant in 1960 that, until 2011, sold branded Swedish prepared specialist foods, such as meatballs, packages of gravy, lingonberry jam, various biscuits and crackers, and salmon and fish roe spread. The new label has a variety of items, including chocolates, meatballs, jams, pancakes, salmon, and various drinks.\nAlthough the cafes primarily serve Swedish food, the menu varies based on the culture, food, and location of each store. With restaurants in 38 countries, the menu often incorporates local dishes, including shawarma in Saudi Arabia and the UAE, poutine in Canada, macarons in France, and gelato in Italy. In Indonesia, the Swedish meatballs recipe is changed to accommodate the country's halal requirements. Stores in Israel sell kosher food under rabbinical supervision. The kosher restaurants are separated into dairy and meat areas.\nIn many locations, the IKEA restaurants open daily before the rest of the store and serve breakfast. All food products are based on Swedish recipes and traditions. Food accounted for 5% of IKEA's sales by 2019.\nIKEA sells plant-based meatballs made from potatoes, apples, pea protein, and oats in all of its stores. According to United States journalist Avery Yale Kamila, IKEA began testing its plant-based meatballs in 2014, then launched the plant-based meatballs in 2015 and began testing vegan hot dogs in 2018. In 2019, journalist James Hansen reported in Eater London that IKEA would only sell vegetarian food at Christmas time.\nSm\u00e5land.\nEvery store has a children's play area, named Sm\u00e5land (Swedish for \"small lands\"; it is also the Swedish province of Sm\u00e5land where founder Kamprad was born). Parents drop off their children at a gate to the playground and pick them up after they arrive at another entrance. In some stores, parents are given free pagers by the on-site staff, which the staff can use to summon parents whose children need them earlier than expected; in others, staff summon parents through announcements over the in-store public address system or by calling them on their mobile phones. The largest Sm\u00e5land play area is located at the IKEA store in Navi Mumbai, India.\nIKEA Preowned.\nIn August 2024, Ikea announced it would be trialing an online marketplace where customers can connect to buy and sell pre-owned items made by Ikea.\nThe marketplace, called \"IKEA Preowned\", would run from August until December 2024 and be centred on the cities of Oslo, Norway and Madrid, Spain.\nOther ventures.\nUntil 28 September 2023, IKEA owned &amp; operated the MEGA Family Shopping Centre chain in Russia. Its operations have since been sold to Gazprombank.\nOn 8 August 2008, IKEA UK launched a virtual mobile phone network called IKEA Family Mobile, which ran on T-Mobile. At launch it was the cheapest pay-as-you-go network in the UK. In June 2015 the network announced that its services would cease to operate from 31 August 2015.\nAs of 2012[ [update]], IKEA has a joint venture with TCL to provide Uppleva integrated HDTV and entertainment system products.\nIn mid-August 2012, the company announced that it would establish a chain of 100 economy hotels in Europe, but, unlike its few existing hotels in Scandinavia, they would not carry the IKEA name, nor would they use IKEA furniture and furnishings \u2013 they would be operated by an unnamed international group of hoteliers. As of 30 April 2018, however, the company owned only a single hotel, the IKEA Hotell in \u00c4lmhult, Sweden.\nIt was previously planned to open another one, in New Haven, Connecticut, United States, after converting the historic Pirelli Building. The company received approval for the concept from the city's planning commission in mid-November 2018; the building was to include 165 rooms, and the property would offer 129 dedicated parking spaces. Research in April 2019 provided no indication that the hotel had been completed as of that time. The building was then sold to Connecticut architect and developer Becker + Becker for $1.2million. Opening in 2022 under Hotel Marcel, it is managed by Charlestowne Hotels and became part of Hilton's Tapestry Collection.\nFrom 2016 to 2018, IKEA sold a commuter belt-driven bicycle, the Sladda.\nIn September 2017, IKEA announced it would be acquiring the UD company TaskRabbit. The deal, completed later that year, has TaskRabbit operating as an independent company.\nIn March 2020, IKEA announced that it had partnered with Pizza Hut Hong Kong on a joint venture. IKEA launched a new side table called S\u00c4VA. The table, designed to resemble a pizza saver, would be boxed in packaging resembling a pizza box, and the building instructions included a suggestion to order a Swedish meatball pizza from Pizza Hut, which would contain the same meatballs served in IKEA restaurants.\nIn April 2020, IKEA acquired AI imaging startup Geomagical Labs.\nIn July 2020, IKEA opened a concept store in the Harajuku district of Tokyo, Japan, where it launched its first ever apparel line.\nIngka Centres, IKEA's malls division, announced in December 2021 that it would open two malls, anchored by IKEA stores, in Gurugram and Noida in India at a cost of around (). Both malls are expected to open by 2025.\nIn 2016, IKEA Canada partnered with the Setsun\u00e9 Indigenous Fashion Incubator, co-founded by Sage Paul, to design and produce the collection \u00c5TERST\u00c4LLA, which means to restore, heal, or redecorate, and it was made entirely from salvaged Ikea textiles, reflecting the traditional Indigenous value to \"use everything\".\nCorporate structure.\nIKEA is owned and operated by a series of not-for-profit and for-profit corporations. The corporate structure is divided into two main parts: operations and franchising.\nINGKA Holding B.V., based in the Netherlands, owns the Ingka Group, which takes care of the centres, retails, customer fulfillment, and all the other services related to IKEA products. The IKEA brand is owned and managed by Inter IKEA Systems B.V., based in the Netherlands, owned by Inter IKEA Holding B.V. Inter IKEA Holding is also in charge of design, manufacturing and supply of IKEA products.\nInter IKEA Systems is owned by Inter IKEA Holding BV, a company registered in the Netherlands, formerly registered in Luxembourg (under the name Inter IKEA Holding SA). Inter IKEA Holding, in turn, is owned by the Interogo Foundation, based in Liechtenstein. In 2016, the INGKA Holding sold its design, manufacturing and logistics subsidiaries to Inter IKEA Holding.\nIn June 2013, Ingvar Kamprad resigned from the board of Inter IKEA Holding SA, and his youngest son, Mathias Kamprad, replaced Per Ludvigsson as the chairman of the holding company. Following his decision to step down, the 87-year-old founder explained, \"I see this as a good time for me to leave the board of Inter IKEA Group. By that we are also taking another step in the generation shift that has been ongoing for some years.\" After the 2016 company restructure, Inter IKEA Holding SA no longer exists, having reincorporated in the Netherlands. Mathias Kamprad became a board member of the Inter IKEA Group and the Interogo Foundation. Mathias and his two older brothers, who also have leadership roles at IKEA, work on the corporation's overall vision and long-term strategy.\nControl by Kamprad.\nAlong with helping IKEA make a non-taxable profit, IKEA's complicated corporate structure allowed Kamprad to maintain tight control over the operations of INGKA Holding, and thus the operation of most IKEA stores. The INGKA Foundation's five-person executive committee was chaired by Kamprad. It appoints a board of INGKA Holding, approves any changes to INGKA Holding's bylaws, and has the right to preempt new share issues. If a member of the executive committee quits or dies, the other four members appoint their replacement.\nIn Kamprad's absence, the foundation's bylaws include specific provisions requiring it to continue operating the INGKA Holding group and specifying that shares can be sold only to another foundation with the same objectives as the INGKA Foundation.\nFinancial information.\nThe net profit of IKEA Group (which does not include Inter IKEA systems) in fiscal year 2009 (after paying franchise fees to Inter IKEA systems) was \u20ac2.538billion on sales of \u20ac21.846billion. Because INGKA Holding is owned by the non-profit INGKA Foundation, none of this profit is taxed. The foundation's nonprofit status also means that the Kamprad family cannot reap these profits directly, but the Kamprads do collect a portion of IKEA sales profits through the franchising relationship between INGKA Holding and Inter IKEA Systems.\nAs a franchisee, the Ingka Group pays 3% of royalties to Inter IKEA Systems. Inter IKEA Systems collected \u20ac631million of franchise fees in 2004 but reported pre-tax profits of only \u20ac225million in 2004. One of the major pre-tax expenses that Inter IKEA systems reported was \u20ac590million of \"other operating charges\". IKEA has refused to explain these charges, but Inter IKEA Systems appears to make large payments to I.I. Holding, another Luxembourg-registered group that, according to \"The Economist,\" \"is almost certain to be controlled by the Kamprad family\". I.I. Holding made a profit of \u20ac328million in 2004.\nIn 2004, the Inter IKEA group of companies and I.I. Holding reported combined profits of \u20ac553m and paid \u20ac19m in taxes, or approximately 3.5 percent.\nIKEA has avoided millions of euros in taxes performing some intricate mechanisms and it was noted by the EU back in 2017. The main countries where they operated their business using tax loopholes were the Netherlands, Luxembourg, and Belgium.\nPublic Eye, a non-profit organisation in Switzerland that promotes corporate responsibility, has formally criticised IKEA for its tax avoidance strategies. In 2007, the organisation nominated IKEA for one of its Public Eye \"awards\", which highlight corporate irresponsibility.\nIn February 2016, the Greens / EFA group in the European Parliament issued a report entitled \"https://\" on the tax planning strategies of IKEA and their possible use to avoid tax in several European countries. The report was sent to Pierre Moscovici, the European Commissioner for Economic and Financial Affairs, Taxation and Customs, and Margrethe Vestager, the European Commissioner for Competition, expressing the hope that it would be of use to them in their respective roles \"to advance the fight for tax justice in Europe\".\nManufacturing, logistics, and labour.\nAlthough IKEA originated in Sweden, their household products and furniture products are manufactured in many different countries, in order to achieve cost efficiency. For most of its products, the final assembly is performed by the end-user (consumer).\nSwedwood, an IKEA subsidiary, produces all of the company's wood-based products, with the largest Swedwood factory located in Southern Poland. According to the subsidiary, over 16,000 employees across 50 sites in 10 countries manufacture the 100million pieces of furniture that IKEA sells annually. IKEA furniture uses the hardwood alternative particle board. Hultsfred, a factory in southern Sweden, is the company's sole supplier.\nDistribution centre efficiency and flexibility have been one of IKEA's ongoing priorities, and thus it has implemented automated, robotic warehouse systems and warehouse management systems (WMS). Such systems facilitate a merger of the traditional retail and mail order sales channels into an omni-channel fulfillment model. In 2020, Ikea was noted by \"Supply Chain\" magazine as having one of the most automated warehouse systems in the world.\nIn the 1980s under the rule of the Romanian dictator Nicolae Ceau\u0219escu, Romania's secret police, the Securitate, received six-figure payments from IKEA. According to declassified files at the National College for Studying the Securitate Archives, IKEA agreed to overcharge for products made in Romania and some of the overpayment funds were deposited into an account controlled by the Securitate.\nLabour practices.\nDuring the 1980s, IKEA kept its costs down by using production facilities in East Germany. A portion of the workforce at those factories consisted of political prisoners. This fact, revealed in a report by Ernst &amp; Young commissioned by the company, resulted from the intermingling of criminals and political dissidents in the state-owned production facilities IKEA contracted with, a practice which was generally known in West Germany. IKEA was one of a number of companies, including West German firms, which benefited from this practice. The investigation resulted from attempts by former political prisoners to obtain compensation. In November 2012, IKEA admitted being aware at the time of the possibility of use of forced labour and failing to exercise sufficient control to identify and avoid it. A summary of the Ernst &amp; Young report was released on 16 November 2012.\nIn 2018, Ikea was accused of union busting when employees sought to organize, using such tactics as captive audience meetings.\nIKEA was named one of the 100 Best Companies for Working Mothers in 2004 and 2005 by \"Working Mothers\" magazine. It ranked 80 in Fortune's 200 Best Companies to Work For in 2006 and in October 2008, IKEA Canada LP was named one of \"Canada's Top 100 Employers\" by Mediacorp Canada Inc.\nEnvironmental initiatives.\nUmbrella initiatives.\nAfter initial environmental issues like the highly publicized formaldehyde scandals in the early 1980s and 1992, IKEA took a proactive stance on environmental issues and tried to prevent future incidents through a variety of measures. In 1990, IKEA invited Karl-Henrik Rob\u00e8rt, founder of the Natural Step, to address its board of directors. Robert's system conditions for sustainability provided a strategic approach to improving the company's environmental performance. In 1990, IKEA adopted the Natural Step framework as the basis for its environmental plan. This led to the development of an Environmental Action Plan, which was adopted in 1992. The plan focused on structural change, allowing IKEA to \"maximize the impact of resources invested and reduce the energy necessary to address isolated issues\". The environmental measures taken include the following:\nIn 2000, IKEA introduced its code of conduct for suppliers that covers social, safety, and environmental questions. Today, IKEA has around 60 auditors who perform hundreds of supplier audits every year. The main purpose of these audits is to make sure that the IKEA suppliers follow the law in each country where they are based.\nAs of March\u00a02018[ [update]], IKEA has signed on with 25 other companies to participate in the British Retail Consortium's Better Retail Better World initiative, which challenges companies to meet objectives outlined by the United Nations Sustainable Development Goals.\nProduct life cycle.\nTo make IKEA a more sustainable company, a product life cycle was created. For the idea stage, products should be flat-packed so that more items can be shipped at once; products should also be easier to dismantle and recycle. Raw materials are used, and since wood and cotton are two of IKEA's most important manufacturing products, the company works with environmentally friendly forests and cotton, whereby the excessive use of chemicals and water is avoided.\nIKEA stores recycle waste and many run on renewable energy. All employees are trained in environmental and social responsibility, while public transit is one of the priorities when the location of stores is considered. Also, the coffee and chocolate served at IKEA stores is UTZ Certified.\nThe last stage of the life cycle is the end of life. Most IKEA stores recycle light bulbs and drained batteries, and the company is also exploring the recycling of sofas and other home furnishing products.\nEnergy sources.\nIn August 2008, IKEA announced that it had created IKEA GreenTech, a \u20ac50million venture capital fund. Located in Lund (a university town in Sweden), it will invest in 8\u201310 companies in the coming five years with a focus on solar panels, alternative light sources, product materials, energy efficiency, and water saving and purification. The aim is to commercialise green technologies for sale in IKEA stores within 3\u20134 years.\nOn 17 February 2011, IKEA announced its plans to develop a wind farm in Dalarna County, Sweden, furthering its goal of using only renewable energy to fuel its operations. As of June\u00a02012[ [update]], 17 United States IKEA stores are powered by solar panels, with 22 additional installations in progress, and IKEA owns the 165 MW Cameron Wind farm in Cameron County on the South Texas coast and a 42 MW coastal wind farm in Finland.\nIn September 2019, IKEA announced that they would be investing $2.8billion in renewable energy infrastructure. The company is targeting making their entire supply chain climate positive by 2030.\nSourcing of wood.\nThe group is responsible for approximately 1% of world commercial-product wood consumption, making it the largest individual user of wood in the world. IKEA claims to use 99.5% recycled or FSC-certified wood. However, IKEA has been shown to be involved in unsustainable and most likely illegal logging of old-growth and protected forests in multiple Eastern European countries in recent years.\nIKEA is the world's largest buyer and retailer of wood. In 2015, IKEA claimed to use 1% of the world's supply of timber.\nAccording to IKEA's 2021 \"Sustainability Report\", 99.5% of all wood that the company uses is either recycled or meets the standards of the Forest Stewardship Council. IKEA states that \"[a]ll wood used for IKEA products must meet our critical requirements that ensure it's not (e.g.) sourced from illegally harvested forests [...]\". However, despite these claims, IKEA has been involved in unsustainable and most likely illegal logging of wood in multiple Eastern European countries in recent years. It has been accused of greenwashing by organisations such as Corporate Europe Observatory and Greenpeace which criticized the company's logging practices in Russian, Romanian and Ukrainian forests.\nIKEA owns about of forest in the US and about in Europe.\nOn 14 January 2021, IKEA announced that Ingka Investments had acquired approximately near the Altamaha River Basin in the US state of Georgia from The Conservation Fund. The acquisition comes with the agreement \"to protect the land from fragmentation, restore the longleaf pine forest, and safe-guard the habitat of the gopher tortoise\".\nIKEA is reported to be the largest private landowner in Romania since 2015.\nUse of wood.\nIn 2011, the company examined its wood consumption and noticed that almost half of its global pine and spruce consumption was for the fabrication of pallets. The company consequently started a transition to the use of paper pallets and the \"OptiLedge system\". The OptiLedge product is completely recyclable, made from 100% virgin high-impact copolymer polypropylene (PP) plastic. The system is a \"unit load alternative to the use of a pallet. The system consists of the OptiLedge (usually used in pairs), aligned and strapped to the bottom carton to form a base layer upon which to stack more products. Corner boards are used when strapping to minimize the potential for package compression.\" The conversion began in Germany and Japan, before its introduction into the rest of Europe and North America. The system has been marketed to other companies, and IKEA has formed the OptiLedge company to manage and sell the product.\nPackaging and bags.\nSince March 2013, IKEA has stopped providing plastic bags to customers, but offers reusable bags for sale. The IKEA restaurants also only offer reusable plates, knives, forks, spoons, etc. Toilets in some IKEA WC-rooms have been outfitted with dual-function flushers. IKEA has recycling bins for compact fluorescent lamps (CFLs), energy-saving bulbs, and batteries.\nIn 2001, IKEA was one of the first companies to operate its own cross-border goods trains through several countries in Europe.\nElectric vehicles.\nIKEA has expanded its sustainability plan in the UK to include electric car charge points for customers at all locations by the end of 2013. The effort will include Nissan and Ecotricity and promise to deliver an 80% charge in 30 minutes.\nFrom 2016, IKEA has only sold energy-efficient LED lightbulbs, lamps, and light fixtures. LED lightbulbs use as little as 15% of the power of a regular incandescent light bulb.\nDonations made by IKEA.\nThe INGKA Foundation is officially dedicated to promoting \"innovations in architecture and interior design\". The net worth of the foundation exceeded the net worth of the much better known Gates Foundation (now the largest private foundation in the world) for a period. However, most of the Group's profit is spent on investment.\nIKEA is involved in several international charitable causes, particularly in partnership with UNICEF, including:\nIKEA also supports American Forests to restore forests and reduce pollution.\nOn 3 March 2022, IKEA announced \u20ac20million donation to UNHCR for relief support of Ukrainians who suffer from the 2022 Russian invasion of Ukraine.\nIKEA donated \u20ac10\u00a0million to Doctors Without Borders for its work in Syria in response to the 2023 Turkey\u2013Syria earthquake.\nIKEA Social Initiative.\nIn September 2005, IKEA Social Initiative was formed to manage the company's social involvement on a global level. IKEA Social Initiative is headed by Marianne Barner.\nThe main partners of IKEA Social Initiative are UNICEF and Save the Children.\nOn 23 February 2009, at the ECOSOC event in New York, UNICEF announced that IKEA Social Initiative had become the agency's largest corporate partner, with total commitments of more than US$180million (\u00a3281,079,000).\nExamples of involvement:\nIn 2009, Sweden's largest television station, SVT, revealed that IKEA's money\u2014the three per cent collection from each store\u2014does not actually go to a charitable foundation in the Netherlands, as IKEA has said. Inter IKEA is owned by a foundation in Liechtenstein, called Interogo, which has amassed $12billion (\u00a318billion), and is controlled by the Kamprad family.\nMarketing.\nCatalogue.\nIKEA used to publish an annual catalogue, first published in Swedish in 1951. It is considered to be the main marketing tool of the company, consuming 70% of its annual marketing budget. The catalogue is distributed both in stores and by mail, with most of it being produced by IKEA Communications AB in IKEA's hometown of \u00c4lmhult, Sweden. At its peak in 2016, 200million copies of the catalogue were distributed in 32 languages to more than 50 markets. In December 2020, IKEA announced that they would cease publication of both the print and digital versions of the catalogue, with the 2021 edition (released in 2020) being the final edition.\nIKEA Family.\nIn common with some other retailers, IKEA launched a loyalty card called \"IKEA Family\". The card is free of charge and can be used to obtain discounts on certain products found in-store. It is available worldwide. In conjunction with the card, IKEA also publishes and sells a printed quarterly magazine titled \"IKEA Family Live\" which supplements the card and catalogue. The magazine is already printed in thirteen languages and an English edition for the United Kingdom was launched in February 2007. It is expected to have a subscription of over 500,000.\nIKEA Place app.\nOn 12 September 2017, IKEA announced the augmented reality app, IKEA Place, following by Apple's release of its ARkit technology and iOS 11. IKEA Place helps consumers to visualize true to scale IKEA products into real environment.\nAdvertising.\nIn 1994, IKEA ran a commercial in the United States, titled \"Dining Room\", widely thought to be the first to feature a homosexual couple; it aired for several weeks before being withdrawn after calls for a boycott and a bomb threat directed at IKEA stores. Other IKEA commercials appeal to the wider LGBTQ community, one featuring a transgender woman.\nIn 2002, the inaugural television component of the \"Unb\u00f6ring\" campaign, titled \"Lamp\", went on to win several awards, including a Grand Clio, Golds at the London International Awards and the ANDY Awards, and the Grand Prix at the Cannes Lions International Advertising Festival, the most prestigious awards ceremony in the advertising community.\nA debate ensued between Fraser Patterson, Chief Executive of Onis, and Andrew McGuinness, partner at Beattie McGuinness Bungay (BMB), the advertising and PR agency that was awarded the \u00a312 million IKEA account. The essence of the debate was that BMB claimed to be unaware of Onis's campaign as Onis was not an advertising agency. Onis's argument was that its advertising could be seen in prominent landmarks throughout London, having already been accredited, showing concern about the impact IKEA's campaign would have on the originality of its own. BMB and IKEA subsequently agreed to provide Onis with a feature page on the IKEA campaign site linking through to Onis's website for a period of one year.\nIn 2008, IKEA paired up with the makers of the video game \"The Sims 2\" to make a stuff pack called \"IKEA Home Stuff\", featuring many IKEA products. It was released on 24 June 2008 in North America and on 26 June 2008 in Europe. It is the second stuff pack with a major brand, the first being \"The Sims 2 H&amp;M Fashion Stuff\".\nIKEA took over the title sponsorship of Philadelphia's annual Thanksgiving Day parade in 2008, replacing Boscov's, which filed for bankruptcy in August 2008.\nIn November 2008, a subway train decorated in IKEA style was introduced in Novosibirsk, Russia. Four cars were turned into a mobile showroom of the Swedish design. The redesigned train, which features colourful seats and fancy curtains, carried passengers until 6 June 2009.\nIn March 2010, IKEA developed an event in four important M\u00e9tro stations in Paris, in which furniture collections are displayed in high-traffic spots, giving potential customers a chance to check out the brand's products. The M\u00e9tro walls were also filled with prints that showcase IKEA interiors.\nIn September 2017, IKEA launched the \"IKEA Human Catalogue\" campaign, in which memory champion Yanjaa Wintersoul memorized all 328 pages of the catalogue in minute detail in just a week before its launch. To prove the legitimacy and accuracy of the campaign, live demonstrations were held at press conferences in IKEA stores across Malaysia, Singapore, Thailand as well as a Facebook Live event held at the Facebook Singapore headquarters and talk show demonstrations in the US with Steve Harvey among others. The advertising campaign was hugely successful winning numerous industry awards including the Webby award 2018 for best social media campaign, an Ogilvy award and is currently a contender for the Cannes Lions 2018.\nIn 2020, IKEA conducted a \"Buy Back Friday\" campaign with a message to present a new life to old furniture instead of offering customers to buy new items for Black Friday.\nIn June 2021, IKEA said it had suspended adverts on GB News because of concerns the channel's content would go against its aim to be inclusive. In a statement, IKEA said: \"We have safeguards in place to prevent our advertising from appearing on platforms that are not in line with our humanistic values. We are in the process of investigating how this may have occurred to ensure it won't happen again in future, and have suspended paid display advertising in the meantime.\"\nAt the end of August 2023, IKEA launched a 6-second advertisement titled \u201cAds That Skip You\u201d highlighting the benefits of neat organization. Created by agency Leo Burnett India, the ad illustrates quickly finding items with time to press \"skip ad.\" The view-through rate exceeded expectations by over 35%, reaching above 90% in all targeted markets. Additionally, there was an overall increase of 32% in clicks compared to the original target. In September 2024, IKEA added a fresh twist to its marketing strategy by transforming everyday windows into out-of-home advertising spaces.\nIn popular culture.\nIn 2018, the company's plush toy shark \"Bl\u00e5haj\" was widely used in an internet meme, with social media users posting humorous photos of it in their homes.\nIKEA has been referenced a number of times in novelty music. In 2003, American musician Jonathan Coulton released the song \"IKEA\" on the album \"Smoking Monkey\". In 2005, British musician Mitch Benn with the band The Distractions penned the novelty song \"Ikea\". In December 2019, comedy metal band Nanowar of Steel released the song \"Valhallelujah\" which is dedicated to Odin and IKEA. The music video features a longship with the sail adorned with the IKEA logo, and a fictional IKEA catalogue written in Old Norse runes. The lyrics include references to various IKEA products, namely BEDDINGE, KIVIK, VITTSJ\u00d6, KNOPPARP, BEST\u00c5 and SLATTUM.\nThe 1999 American movie Fight Club references IKEA furniture to show the consumerist culture of modern times.\nIKEA stores have been featured in many works of fiction. Some examples include:\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "14752", "revid": "17087306", "url": "https://en.wikipedia.org/wiki?curid=14752", "title": "Iridium", "text": "element with atomic number 77 (Ir)\nIridium is a chemical element; it has symbol Ir and atomic number 77. This very hard, brittle, silvery-white transition metal of the platinum group, is considered the second-densest naturally occurring metal (after osmium) with a density of as defined by experimental X-ray crystallography. 191Ir and 193Ir are the only two naturally occurring isotopes of iridium, as well as the only stable isotopes; the latter is the more abundant. It is one of the most corrosion-resistant metals, even at temperatures as high as .\nIridium was discovered in 1803 in the acid-insoluble residues of platinum ores by the British chemist Smithson Tennant. The name \"iridium\", derived from the Greek word \"iris\" (rainbow), refers to the various colors of its compounds. Iridium is one of the rarest elements in Earth's crust, with an estimated annual production of only in 2023.\nThe dominant uses of iridium and its alloys are in high-performance spark plugs, crucibles for recrystallization of semiconductors at high temperatures, and electrodes for the production of chlorine in the chloralkali process. Important compounds of iridium are chlorides and iodides in industrial catalysis. Iridium is a component of some OLEDs.\nIridium is found in meteorites in much higher abundance than in the Earth's crust. For this reason, the unusually high abundance of iridium in the clay layer at the Cretaceous\u2013Paleogene boundary gave rise to the Alvarez hypothesis that the impact of a massive extraterrestrial object caused the extinction of non-avian dinosaurs and many other species 66\u00a0million years ago, now known to be produced by the impact that formed the Chicxulub crater. Similarly, an iridium anomaly in core samples from the Pacific Ocean suggested the Eltanin impact of about 2.5\u00a0million years ago.\nCharacteristics.\nPhysical properties.\nA member of the platinum group metals, iridium is white, resembling platinum, but with a slight yellowish cast. Because of its hardness, brittleness, and very high melting point, solid iridium is difficult to machine, form, or work; thus powder metallurgy is commonly employed instead. It is the only metal to maintain good mechanical properties in air at temperatures above . It has the 10th highest boiling point among all elements and becomes a superconductor at temperatures below .\nIridium's modulus of elasticity is the second-highest among the metals, being surpassed only by osmium. This, together with a high shear modulus and a very low figure for Poisson's ratio (the relationship of longitudinal to lateral strain), indicate the high degree of stiffness and resistance to deformation that have rendered its fabrication into useful components a matter of great difficulty. Despite these limitations and iridium's high cost, a number of applications have developed where mechanical strength is an essential factor in some of the extremely severe conditions encountered in modern technology.\nThe measured density of iridium is only slightly lower (by about 0.12%) than that of osmium, the densest metal known. Some ambiguity occurred regarding which of the two elements was denser, due to the small size of the difference in density and difficulties in measuring it accurately, but, with increased accuracy in factors used for calculating density, X-ray crystallographic data yielded densities of for iridium and for osmium.\nIridium is extremely brittle, to the point of being hard to weld because the heat-affected zone cracks, but it can be made more ductile by addition of small quantities of titanium and zirconium (0.2% of each apparently works well).\nThe Vickers hardness of pure platinum is 56\u00a0HV, whereas platinum with 50% of iridium can reach over 500\u00a0HV.\nChemical properties.\nIridium is the most corrosion-resistant metal known. It is not attacked by acids, including aqua regia, but it can be dissolved in concentrated hydrochloric acid in the presence of sodium perchlorate. In the presence of oxygen, it reacts with cyanide salts. Traditional oxidants also react, including the halogens and oxygen at higher temperatures. Iridium also reacts directly with sulfur at atmospheric pressure to yield iridium disulfide.\nIsotopes.\nIridium has two naturally occurring stable isotopes, 191Ir and 193Ir, with natural abundances of 37.3% and 62.7%, respectively. At least 37 radioisotopes have also been synthesized, ranging in mass number from 164 to 202. 192Ir, which falls between the two stable isotopes, is the most stable radioisotope, has a half-life of 73.82\u00a0days, and finds application in brachytherapy and in industrial radiography, particularly for nondestructive testing of welds in steel in the oil and gas industries; iridium-192 sources have been involved in a number of radiological accidents. Three other isotopes have half-lives of at least a day\u2014188Ir, 189Ir, and 190Ir. Isotopes with masses below 191 decay by some combination of \u03b2+ decay, \u03b1 decay, and (rare) proton emission. Synthetic isotopes heavier than 193 decay by \u03b2\u2212 decay, and 192Ir has both, but \u03b2+ decay (95.24%) dominates over electron capture (4.76%).\nAt least 32 metastable isomers have been characterized, ranging in mass number from 164 to 197. The most stable of these is 192m2Ir, which decays by isomeric transition with a half-life of 241\u00a0years, making it more stable than any of iridium's ground-state radioisotopes.\nThe isotope 191Ir was the first one of any element to be shown to present a M\u00f6ssbauer effect. This renders it useful for M\u00f6ssbauer spectroscopy for research in physics, chemistry, biochemistry, metallurgy, and mineralogy.\nChemistry.\nOxidation states.\nIridium forms compounds in oxidation states between \u22123 and +9, but the most common oxidation states are +1, +2, +3, and +4. Well-characterized compounds containing iridium in the +6 oxidation state include and the oxides and . Iridium(VIII) oxide () was generated under matrix isolation conditions at 6 K in argon. The highest oxidation state (+9), which is also the highest recorded for \"any\" element, is found in gaseous .\nBinary compounds.\nIridium does not form binary hydrides. Only one binary oxide is well-characterized: iridium dioxide, IrO2. It is a blue black solid that adopts the fluorite structure. A sesquioxide, Ir2O3, has been described as a blue-black powder, which is oxidized to IrO2 by HNO3. The corresponding disulfides, diselenides, sesquisulfides, and sesquiselenides are known, as well as IrS3.\nBinary trihalides, IrX3, are known for all of the halogens. For oxidation states +4 and above, only the tetrafluoride, pentafluoride and hexafluoride are known. Iridium hexafluoride, IrF6, is a volatile yellow solid, composed of octahedral molecules. It decomposes in water and is reduced to IrF4. Iridium pentafluoride is also a strong oxidant, but it is a tetramer, Ir4F20, formed by four corner-sharing octahedra.\nComplexes.\nIridium has extensive coordination chemistry.\nIridium in its complexes is always low-spin. Ir(III) and Ir(IV) generally form octahedral complexes. Polyhydride complexes are known for the +5 and +3 oxidation states. One example is (iPr = isopropyl). The ternary hydride Mg6Ir2H11 is believed to contain both the IrH54- and the 18-electron IrH45- anion.\nIridium also forms oxyanions with oxidation states +4 and +5. K2IrO3 and KIrO3 can be prepared from the reaction of potassium oxide or potassium superoxide with iridium at high temperatures. Such solids are not soluble in conventional solvents.\nJust like many elements, iridium forms important chloride complexes. Hexachloroiridic (IV) acid, H2IrCl6, and its ammonium salt are common iridium compounds from both industrial and preparative perspectives. They are intermediates in the purification of iridium and used as precursors for most other iridium compounds, as well as in the preparation of anode coatings. The IrCl62- ion has an intense dark brown color, and can be readily reduced to the lighter-colored IrCl63- and vice versa. Iridium trichloride, IrCl3, which can be obtained in anhydrous form from direct oxidation of iridium powder by chlorine at 650\u00a0\u00b0C, or in hydrated form by dissolving Ir2O3 in hydrochloric acid, is often used as a starting material for the synthesis of other Ir(III) compounds. Another compound used as a starting material is potassium hexachloroiridate(III), .\nOrganoiridium chemistry.\nOrganoiridium compounds contain iridium\u2013carbon bonds. Early studies identified the very stable tetrairidium dodecacarbonyl, Ir4(CO)12. In this compound, each of the iridium atoms is bonded to the other three, forming a tetrahedral cluster. The discovery of Vaska's complex (IrCl(CO)[P(C6H5)3]2) opened the door for oxidative addition reactions, a process fundamental to useful reactions. For example, Crabtree's catalyst, a homogeneous catalyst for hydrogenation reactions.\nIridium complexes played a pivotal role in the development of carbon\u2013hydrogen bond activation (C\u2013H activation), which promises to allow functionalization of hydrocarbons, which are traditionally regarded as unreactive.\nHistory.\nPlatinum group.\nThe discovery of iridium is intertwined with that of platinum and the other metals of the platinum group. The first European reference to platinum appears in 1557 in the writings of the Italian humanist Julius Caesar Scaliger as a description of an unknown noble metal found between Dari\u00e9n and Mexico, \"which no fire nor any Spanish artifice has yet been able to liquefy\". From their first encounters with platinum, the Spanish generally saw the metal as a kind of impurity in gold, and it was treated as such. It was often simply thrown away, and there was an official decree forbidding the adulteration of gold with platinum impurities.\nIn 1735, Antonio de Ulloa and Jorge Juan y Santacilia saw Native Americans mining platinum while the Spaniards were travelling through Colombia and Peru for eight years. Ulloa and Juan found mines with the whitish metal nuggets and took them home to Spain. Ulloa returned to Spain and established the first mineralogy lab in Spain and was the first to systematically study platinum, which was in 1748. His historical account of the expedition included a description of platinum as being neither separable nor calcinable. Ulloa also anticipated the discovery of platinum mines. After publishing the report in 1748, Ulloa did not continue to investigate the new metal. In 1758, he was sent to superintend mercury mining operations in Huancavelica.\nIn 1741, Charles Wood, a British metallurgist, found various samples of Colombian platinum in Jamaica, which he sent to William Brownrigg for further investigation.\nIn 1750, after studying the platinum sent to him by Wood, Brownrigg presented a detailed account of the metal to the Royal Society, stating that he had seen no mention of it in any previous accounts of known minerals. Brownrigg also made note of platinum's extremely high melting point and refractory metal-like behaviour toward borax. Other chemists across Europe soon began studying platinum, including Andreas Sigismund Marggraf, Torbern Bergman, J\u00f6ns Jakob Berzelius, William Lewis, and Pierre Macquer. In 1752, Henrik Scheffer published a detailed scientific description of the metal, which he referred to as \"white gold\", including an account of how he succeeded in fusing platinum ore with the aid of arsenic. Scheffer described platinum as being less pliable than gold, but with similar resistance to corrosion.\nDiscovery.\nChemists who studied platinum dissolved it in aqua regia (a mixture of hydrochloric and nitric acids) to create soluble salts. They always observed a small amount of a dark, insoluble residue. Joseph Louis Proust thought that the residue was graphite. The French chemists Victor Collet-Descotils, Antoine Fran\u00e7ois, comte de Fourcroy, and Louis Nicolas Vauquelin also observed the black residue in 1803, but did not obtain enough for further experiments.\nIn 1803 British scientist Smithson Tennant (1761\u20131815) analyzed the insoluble residue and concluded that it must contain a new metal. Vauquelin treated the powder alternately with alkali and acids and obtained a volatile new oxide, which he believed to be of this new metal\u2014which he named \"ptene\", from the Greek word \"pt\u0113n\u00f3s\", \"winged\". Tennant, who had the advantage of a much greater amount of residue, continued his research and identified the two previously undiscovered elements in the black residue, iridium and osmium. He obtained dark red crystals (probably of Na2[IrCl6]\u00b7\"n\"H2O) by a sequence of reactions with sodium hydroxide and hydrochloric acid. He named iridium after Iris (), the Greek winged goddess of the rainbow and the messenger of the Olympian gods, because many of the salts he obtained were strongly colored. Discovery of the new elements was documented in a letter to the Royal Society on June 21, 1804.\nMetalworking and applications.\nBritish scientist John George Children was the first to melt a sample of iridium in 1813 with the aid of \"the greatest galvanic battery that has ever been constructed\" (at that time). The first to obtain high-purity iridium was Robert Hare in 1842. He found it had a density of around and noted the metal is nearly immalleable and very hard. The first melting in appreciable quantity was done by Henri Sainte-Claire Deville and Jules Henri Debray in 1860. They required burning more than of pure O2 and H2 gas for each of iridium.\nThese extreme difficulties in melting the metal limited the possibilities for handling iridium. John Isaac Hawkins was looking to obtain a fine and hard point for fountain pen nibs, and in 1834 managed to create an iridium-pointed gold pen. In 1880, John Holland and William Lofland Dudley were able to melt iridium by adding phosphorus and patented the process in the United States; British company Johnson Matthey later stated they had been using a similar process since 1837 and had already presented fused iridium at a number of World Fairs. The first use of an alloy of iridium with ruthenium in thermocouples was made by Otto Feussner in 1933. These allowed for the measurement of high temperatures in air up to .\nIn Munich, Germany in 1957 Rudolf M\u00f6ssbauer, in what has been called one of the \"landmark experiments in twentieth-century physics\", discovered the resonant and recoil-free emission and absorption of gamma rays by atoms in a solid metal sample containing only 191Ir. This phenomenon, known as the M\u00f6ssbauer effect resulted in the awarding of the Nobel Prize in Physics in 1961, at the age 32, just three years after he published his discovery.\nOccurrence.\nAlong with many elements having atomic weights higher than that of iron, iridium is only naturally formed by the r-process (rapid neutron capture) in neutron star mergers and possibly rare types of supernovae.\nIridium is one of the nine least abundant stable elements in Earth's crust, having an average mass fraction of 0.001\u00a0ppm in crustal rock; gold is 4 times more abundant, platinum is 10 times more abundant, silver and mercury are 80 times more abundant. Osmium, tellurium, ruthenium, rhodium and rhenium are about as abundant as iridium. In contrast to its low abundance in crustal rock, iridium is relatively common in meteorites, with concentrations of 0.5\u00a0ppm or more. The overall concentration of iridium on Earth is thought to be much higher than what is observed in crustal rocks, but because of the density and siderophilic (\"iron-loving\") character of iridium, it descended below the crust and into Earth's core when the planet was still molten.\nIridium is found in nature as an uncombined element or in natural alloys, especially the iridium\u2013osmium alloys osmiridium (osmium-rich) and iridosmium (iridium-rich). In nickel and copper deposits, the platinum group metals occur as sulfides, tellurides, antimonides, and arsenides. In all of these compounds, platinum can be exchanged with a small amount of iridium or osmium. As with all of the platinum group metals, iridium can be found naturally in alloys with raw nickel or raw copper. A number of iridium-dominant minerals, with iridium as the species-forming element, are known. They are exceedingly rare and often represent the iridium analogues of the above-given ones. The examples are irarsite and cuproiridsite, to mention some. Within Earth's crust, iridium is found at highest concentrations in three types of geologic structure: igneous deposits (crustal intrusions from below), impact craters, and deposits reworked from one of the former structures. The largest known primary reserves are in the Bushveld igneous complex in South Africa, (near the largest known impact structure, the Vredefort impact structure) though the large copper\u2013nickel deposits near Norilsk in Russia, and the Sudbury Basin (also an impact crater) in Canada are also significant sources of iridium. Smaller reserves are found in the United States. Iridium is also found in secondary deposits, combined with platinum and other platinum group metals in alluvial deposits. The alluvial deposits used by pre-Columbian people in the Choc\u00f3 Department of Colombia are still a source for platinum-group metals. As of 2003, world reserves have not been estimated.\nMarine oceanography.\nIridium is found within marine organisms, sediments, and the water column. The abundance of iridium in seawater and organisms is relatively low, as it does not readily form chloride complexes. The abundance in organisms is about 20 parts per trillion, or about five orders of magnitude less than in sedimentary rocks at the Cretaceous\u2013Paleogene (K\u2013T) boundary. The concentration of iridium in seawater and marine sediment is sensitive to marine oxygenation, seawater temperature, and various geological and biological processes.\nIridium in sediments can come from cosmic dust, volcanoes, precipitation from seawater, microbial processes, or hydrothermal vents, and its abundance can be strongly indicative of the source. It tends to associate with other ferrous metals in manganese nodules. Iridium is one of the characteristic elements of extraterrestrial rocks, and, along with osmium, can be used as a tracer element for meteoritic material in sediment. For example, core samples from the Pacific Ocean with elevated iridium levels suggested the Eltanin impact of about 2.5\u00a0million years ago.\nSome of the mass extinctions, such as the Cretaceous extinction, can be identified by anomalously high concentrations of iridium in sediment, and these can be linked to major asteroid impacts.\nCretaceous\u2013Paleogene boundary presence.\nThe Cretaceous\u2013Paleogene boundary of 66 million years ago, marking the temporal border between the Cretaceous and Paleogene periods of geological time, was identified by a thin stratum of iridium-rich clay. A team led by Luis Alvarez proposed in 1980 an extraterrestrial origin for this iridium, attributing it to an asteroid or comet impact. Their theory, known as the Alvarez hypothesis, is now widely accepted to explain the extinction of the non-avian dinosaurs. A large buried impact crater structure with an estimated age of about 66 million years was later identified under what is now the Yucat\u00e1n Peninsula (the Chicxulub crater). Dewey M. McLean and others argue that the iridium may have been of volcanic origin instead, because Earth's core is rich in iridium, and active volcanoes such as Piton de la Fournaise, in the island of R\u00e9union, are still releasing iridium.\nProduction.\nWorldwide production of iridium was about in 2018. The price is high and varying (see table). Illustrative factors that affect the price include oversupply of Ir crucibles\nand changes in LED technology.\nPlatinum metals occur together as dilute ores. Iridium is one of the rarer platinum metals: for every 190 tonnes of platinum obtained from ores, only 7.5 tonnes of iridium is isolated. To separate the metals, they must first be brought into solution. Two methods for rendering Ir-containing ores soluble are (i) fusion of the solid with sodium peroxide followed by extraction of the resulting glass in aqua regia and (ii) extraction of the solid with a mixture of chlorine with hydrochloric acid. From soluble extracts, iridium is separated by precipitating solid ammonium hexachloroiridate ((NH4)2IrCl6) or by extracting IrCl62- with organic amines. The first method is similar to the procedure Tennant and Wollaston used for their original separation. The second method can be planned as continuous liquid\u2013liquid extraction and is therefore more suitable for industrial scale production. In either case, the product, an iridium chloride salt, is reduced with hydrogen, yielding the metal as a powder or \"sponge\", which is amenable to powder metallurgy techniques. Iridium is also obtained commercially as a by-product from nickel and copper mining and processing. During electrorefining of copper and nickel, noble metals such as silver, gold and the platinum group metals as well as selenium and tellurium settle to the bottom of the cell as \"anode mud\", which forms the starting point for their extraction.\n&lt;templatestyles src=\"template:row hover highlight/styles.css\"/&gt;&lt;templatestyles src=\"Template:Static row numbers/styles.css\" /&gt;\nApplications.\nDue to iridium's resistance to corrosion it has industrial applications. The main areas of use are electrodes for producing chlorine and other corrosive products, OLEDs, crucibles, catalysts (e.g. acetic acid), and ignition tips for spark plugs.\nMetal and alloys.\nResistance to heat and corrosion are the bases for several uses of iridium and its alloys.\nOwing to its high melting point, hardness, and corrosion resistance, iridium is used to make crucibles. Such crucibles are used in the Czochralski process to produce oxide single-crystals (such as sapphires) for use in computer memory devices and in solid state lasers. The crystals, such as gadolinium gallium garnet and yttrium gallium garnet, are grown by melting pre-sintered charges of mixed oxides under oxidizing conditions at temperatures up to .\nCertain long-life aircraft engine parts are made of an iridium alloy, and an iridium\u2013titanium alloy is used for deep-water pipes because of its corrosion resistance. Iridium is used for multi-pored spinnerets, through which a plastic polymer melt is extruded to form fibers, such as rayon. Osmium\u2013iridium is used for compass bearings and for balances.\nBecause of their resistance to arc erosion, iridium alloys are used by some manufacturers for the centre electrodes of spark plugs, and iridium-based spark plugs are particularly used in aviation.\nCatalysis.\nIridium compounds are used as catalysts in the Cativa process for carbonylation of methanol to produce acetic acid.\nIridium complexes are often active for asymmetric hydrogenation both by traditional hydrogenation. and transfer hydrogenation. This property is the basis of the industrial route to the chiral herbicide (S)-metolachlor. As practiced by Syngenta on the scale of 10,000 tons/year, the complex [Ir(COD)Cl]2 in the presence of Josiphos ligands.\nMedical imaging.\nThe radioisotope iridium-192 is one of the two most important sources of energy for use in industrial \u03b3-radiography for non-destructive testing of metals. Additionally, Ir is used as a source of gamma radiation for the treatment of cancer using brachytherapy, a form of radiotherapy where a sealed radioactive source is placed inside or next to the area requiring treatment. Specific treatments include high-dose-rate prostate brachytherapy, biliary duct brachytherapy, and intracavitary cervix brachytherapy. Iridium-192 is normally produced by neutron activation of isotope iridium-191 in natural-abundance iridium metal.\nPhotocatalysis and OLEDs.\nIridium complexes are key components of white OLEDs. Similar complexes are used in photocatalysis.\nScientific.\nAn alloy of 90% platinum and 10% iridium was used in 1889 to construct the International Prototype Meter and kilogram mass, kept by the International Bureau of Weights and Measures near Paris. The meter bar was replaced as the definition of the fundamental unit of length in 1960 by a line in the atomic spectrum of krypton, but the kilogram prototype remained the international standard of mass until 20 May 2019, when the kilogram was redefined in terms of the Planck constant.\nHistorical.\nIridium\u2013osmium alloys were previously used in fountain pen nib tips. The first major use of iridium was in 1834 in nibs mounted on gold. Starting in 1944, the Parker 51 fountain pen was fitted with a nib tipped by a ruthenium and iridium alloy (with 3.8% iridium). The tip material in modern fountain pens is still conventionally called \"iridium\", although there is seldom any iridium in it; other metals such as ruthenium, osmium, and tungsten have taken its place.\nAn iridium\u2013platinum alloy was used for the touch holes or vent pieces of cannon. According to a report of the Paris Exhibition of 1867, one of the pieces being exhibited by Johnson and Matthey \"has been used in a Whitworth gun for more than 3000 rounds, and scarcely shows signs of wear yet. Those who know the constant trouble and expense which are occasioned by the wearing of the vent-pieces of cannon when in active service, will appreciate this important adaptation\".\nThe pigment \"iridium black\", which consists of very finely divided iridium, is used for painting porcelain an intense black; it was said that \"all other porcelain black colors appear grey by the side of it\".\nPrecautions and hazards.\nIridium in bulk metallic form is not biologically important or hazardous to health due to its lack of reactivity with tissues; there are only about 20\u00a0parts per trillion of iridium in human tissue. Like most metals, finely divided iridium powder can be hazardous to handle, as it is an irritant and may ignite in air. Iridium is relatively unhazardous otherwise, with the only effect of Iridium ingestion being irritation of the digestive tract. However, soluble salts, such as the iridium halides, could be hazardous due to elements other than iridium or due to iridium itself. At the same time, most iridium compounds are insoluble, which makes absorption into the body difficult.\nA radioisotope of iridium, 192Ir, is dangerous, like other radioactive isotopes. The only reported injuries related to iridium concern accidental exposure to radiation from 192Ir used in brachytherapy. High-energy gamma radiation from 192Ir can increase the risk of cancer. External exposure can cause burns, radiation poisoning, and death. Ingestion of 192Ir can burn the linings of the stomach and the intestines. 192Ir, 192mIr, and 194mIr tend to deposit in the liver, and can pose health hazards from both gamma and beta radiation.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "14753", "revid": "44062", "url": "https://en.wikipedia.org/wiki?curid=14753", "title": "IOC (disambiguation)", "text": "IOC most commonly refers to the International Olympic Committee.\nIOC or IoC may also refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nOther uses.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "14761", "revid": "15454761", "url": "https://en.wikipedia.org/wiki?curid=14761", "title": "International Phonetic Alphabet", "text": "System of phonetic notation\nThe International Phonetic Alphabet (IPA) is an alphabetic system of phonetic notation based primarily on the Latin script. It was devised by the International Phonetic Association in the late 19th century as a standard written representation for the sounds of speech. The IPA is used by linguists, lexicographers, foreign language students and teachers, speech\u2013language pathologists, singers, actors, constructed language creators, and translators.\nThe IPA is designed to represent those qualities of speech that are part of lexical (and, to a limited extent, prosodic) sounds in spoken (oral) language: phones, intonation and the separation of syllables. To represent additional qualities of speech\u00a0\u2013 such as tooth gnashing, lisping, and sounds made with a cleft palate\u00a0\u2013 an extended set of symbols may be used.\nSegments are transcribed by one or more IPA symbols of two basic types: letters and diacritics. For example, the sound of the English letter \u27e8t\u27e9 may be transcribed in IPA with a single letter: , or with a letter plus diacritics: , depending on how precise one wishes to be. Similarly, the French letter \u27e8t\u27e9 may be transcribed as either or : and are two different, though similar, sounds. Slashes are used to signal phonemic transcription; therefore, is more abstract than either or and might refer to either, depending on the context and language.\nOccasionally, letters or diacritics are added, removed, or modified by the International Phonetic Association. As of the most recent change in 2005, there are 107 segmental letters, an indefinitely large number of suprasegmental letters, 44 diacritics (not counting composites), and four extra-lexical prosodic marks in the IPA. These are illustrated in the current IPA chart, posted below in this article and on the International Phonetic Association's website.\nHistory.\nIn 1886, a group of French and English language teachers, led by the French linguist Paul Passy, formed what would be known from 1897 onwards as the International Phonetic Association (in French, ). The idea of the alphabet had been suggested to Passy by Otto Jespersen. It was developed by Passy along with other members of the association, principally Daniel Jones.\nThe original IPA alphabet was based on the Romic alphabet, an English spelling reform created by Henry Sweet that, in turn, was based on the Palaeotype alphabet of Alexander John Ellis, itself derived from Lepsius Standard Alphabet first used for transcribing Ancient Egyptian into German.\nThe original intent was to make it usable for other languages; the values of the symbols were allowed to vary from language to language. For example, the sound (the \"sh\" in \"shoe\") was originally represented with the letter \u27e8c\u27e9 for English but with \u27e8x\u27e9 for French and German; with German, \u27e8c\u27e9 was used for the sound of \"Bach\". With a growing number of transcribed languages this proved impractical, and in 1888 the values of the letters were made uniform across languages. This would provide the base for all future revisions.\nSince its creation, the IPA has undergone a number of revisions. After relatively frequent revisions and expansions from the 1890s to the 1940s, the IPA remained nearly static until the Kiel Convention in 1989, which substantially revamped the alphabet. A smaller revision took place in 1993 with the resurrection of letters for mid central vowels and the retirement of letters for voiceless implosives. The alphabet was last revised in May 2005 with the addition of a letter for a labiodental flap. Apart from the addition and removal of symbols, changes to the IPA have consisted largely of renaming symbols and categories and in modifying typefaces.\nExtensions to the International Phonetic Alphabet for speech pathology (extIPA) were created in 1990 and were officially adopted by the International Clinical Phonetics and Linguistics Association in 1994.\nThey were substantially revised in 2015 with lesser changes in 2025.\nDescription.\nThe general principle of the IPA is to provide one letter for each distinctive sound (phoneme). This means that:\nThe alphabet is designed for transcribing sounds (phones), not phonemes, though it is used for phonemic transcription as well. A few letters that did not indicate specific sounds have been retired\u00a0\u2013 \u27e8\u27e9, once used for the \"compound\" tone of Swedish and Norwegian, and \u27e8\u27e9, once used for the moraic nasal of Japanese\u00a0\u2013 though one remains: \u27e8\u27e9, used for the sj-sound of Swedish. When the IPA is used for broad phonetic or for phonemic transcription, the letter\u2013sound correspondence can be rather loose. The IPA has recommended that more 'familiar' letters be used when that would not cause ambiguity. For example, \u27e8\u27e9 and \u27e8\u27e9 for and , \u27e8\u27e9 for or , \u27e8\u27e9 for , etc. Indeed, in the illustration of Hindi in the IPA \"Handbook\", the letters \u27e8\u27e9 and \u27e8\u27e9 are used for and ; in the 1949 \"Principles\", they had been used as shortcuts for and in Twi.\nAmong the symbols of the IPA, 107 letters represent consonants and vowels, 31 diacritics are used to modify these, and 17 additional signs indicate suprasegmental qualities such as length, tone, stress, and intonation. These are organized into a chart; the chart displayed here is the official chart as posted at the website of the IPA.\nLetter forms.\nThe International Phonetic Alphabet is based on the Latin script, and uses as few non-Latin letters as possible. The non-Latin letters are meant to harmonize with the Latin letters. For this reason, most letters are either Latin, Greek, or modifications thereof. Some letters are neither: for example, the letter denoting the glottal stop, \u27e8\u27e9, originally had the form of a question mark with the dot removed. A few letters, such as that of the voiced pharyngeal fricative, \u27e8\u27e9, were inspired by other writing systems (in this case, the Arabic letter \u27e8\ufec9\u27e9, \"\", via the reversed apostrophe).\nThe Association created the IPA so that the sound values of most letters would correspond to \"international usage\" (approximately Classical Latin). Hence, the consonant letters \u27e8\u27e9, \u27e8\u27e9, \u27e8\u27e9, \u27e8\u27e9, \u27e8\u27e9, \u27e8\u27e9, \u27e8\u27e9, \u27e8\u27e9, \u27e8\u27e9, \u27e8\u27e9, \u27e8\u27e9, \u27e8\u27e9, \u27e8\u27e9, \u27e8\u27e9, and \u27e8\u27e9 have more or less their word-initial values in English (\"g\" as in \"gill\", \"h\" as in \"hill\", though \"p t k\" are unaspirated as in \"spill, still, skill\"); and the vowel letters \u27e8\u27e9, \u27e8\u27e9, \u27e8\u27e9, \u27e8\u27e9, \u27e8\u27e9 correspond to the (long) sound values of Latin: is like the vowel in \"machine\", is as in \"rule\", etc. Other Latin letters, particularly \u27e8\u27e9, \u27e8\u27e9 and \u27e8\u27e9, differ from English, but have their IPA values in Latin or other European languages.\nBeyond the letters themselves, there are secondary symbols which aid in transcription. Diacritic marks can be combined with the letters to add tone and phonetic detail such as secondary articulation. There are also special symbols for prosodic features such as stress and intonation.\nTypography.\nThe basic Latin inventory was extended by adding small-capital and cursive forms, overlapping diacritics such as hooks, and rotation. The sound values of these letters are related to those of the original letters or to those of letters that they were modified to resemble. \nFor example, rotated letters were popular in the era of mechanical typesetting, as they had the advantage of not requiring the casting of special type for IPA symbols, much as the sorts for \u27e8b\u27e9 and \u27e8q\u27e9, \u27e8d\u27e9 and \u27e8p\u27e9, \u27e8n\u27e9 and \u27e8u\u27e9, and \u27e86\u27e9 and \u27e89\u27e9 had traditionally often pulled double duty to reduce printers' costs. Thus rotated \u27e8\u27e9 recall \"a e r w\", while rotated \u27e8\u27e9 recall \"o j b y u/w \u1d00 y/\u03bb\".\nThere are several letters from the Greek alphabet, though their sound values may differ from Greek. For most Greek letters, subtly different glyph shapes have been devised for the IPA, specifically \u27e8\u27e9, \u27e8\u27e9, \u27e8\u27e9, \u27e8\u27e9, \u27e8\u27e9 and \u27e8\u27e9, which are encoded in Unicode separately from their parent Greek letters. One, however \u2013 \u27e8\u27e9 \u2013 has only its Greek form, while for \u27e8\u27e9 and \u27e8\u27e9, both Greek and Latin forms are in common use.\nIconicity.\nThe graphic derivation of letters and diacritics may be iconic:\nBrackets and transcription delimiters.\nThere are two principal types of brackets used to set off (delimit) IPA transcriptions:\nLess common conventions include:\nAll three of the above are provided by the IPA \"Handbook\". The following are not, but may be seen in IPA transcription or in associated material (especially angle brackets):\nSome examples of contrasting brackets in the literature:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;the alternations \u00a0\u2013 in plural formation in one class of nouns, as in \"knife\" \u00a0\u2013 \"knives\" , which can be represented morphophonemically as }\u00a0\u2013 }. The morphophoneme } stands for the phoneme set }.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\u2014 \"f-finals held in Barcelona and Madrid.\"\nOther representations.\nIPA letters have cursive forms designed for use in manuscripts and when taking field notes, but the \"Handbook\" recommended against their use, as cursive IPA is \"harder for most people to decipher\". A braille representation of the IPA for blind or visually impaired professionals and students has also been developed.\nModifying the IPA chart.\nThe International Phonetic Alphabet is occasionally modified by the Association. After each modification, the Association provides an updated simplified presentation of the alphabet in the form of a chart. (See History of the IPA.) Not all aspects of the alphabet can be accommodated in a chart of the size published by the IPA. The alveolo-palatal and epiglottal consonants, for example, are not included in the consonant chart for reasons of space rather than of theory (two additional columns would be required, one between the retroflex and palatal columns and the other between the pharyngeal and glottal columns), and the lateral flap would require an additional row for that single consonant, so they are listed instead under the catchall block of \"other symbols\". The indefinitely large number of tone letters would make a full accounting impractical even on a larger page, and only a few examples are shown, and even the tone diacritics are not complete; the reversed tone letters are not illustrated at all.\nThe procedure for modifying the alphabet or the chart is to propose the change in the \"Journal of the IPA.\" (See, for example, December 2008 on an open central unrounded vowel and August 2011 on central approximants.) Reactions to the proposal may be published in the same or subsequent issues of the Journal (as in August 2009 on the open central vowel). A formal proposal is then put to the Council of the IPA \u2013 which is elected by the membership \u2013 for further discussion and a formal vote.\nMany users of the alphabet, including the leadership of the Association itself, deviate from its standardized usage.\nThe \"Journal of the IPA\" finds it acceptable to mix IPA and extIPA symbols in consonant charts in their articles. (For instance, including the extIPA letter \u27e8\u27e9, rather than \u27e8\u27e9, in an illustration of the IPA.)\nUsage.\nOf more than 160 IPA symbols, relatively few will be used to transcribe speech in any one language, with various levels of precision. A precise phonetic transcription, in which sounds are specified in detail, is known as a \"narrow transcription\". A coarser transcription with less detail is called a \"broad transcription.\" Both are relative terms, and both are generally enclosed in square brackets. Broad phonetic transcriptions may restrict themselves to easily heard details, or only to details that are relevant to the discussion at hand, and may differ little if at all from phonemic transcriptions, but they make no theoretical claim that all the distinctions transcribed are necessarily meaningful in the language. The term 'broad' may furthermore carry implication that diacritics are avoided (at least as far as possible) or even that the transcription is restricted to the letters of the ISO basic Latin alphabet.\nFor example, the English word \"little\" may be transcribed broadly as , approximately describing many pronunciations. A narrower transcription may focus on individual or dialectical details: in General American, in Cockney, or in Southern US English.\nPhonemic transcriptions, which express the conceptual counterparts of spoken sounds, are usually enclosed in slashes (/ /) and tend to use simpler letters with few diacritics. The choice of IPA letters may reflect theoretical claims of how speakers conceptualize sounds as phonemes or they may be merely a convenience for typesetting. Phonemic approximations between slashes do not have absolute sound values. For instance, in English, either the vowel of \"pick\" or the vowel of \"peak\" may be transcribed as , so that \"pick\", \"peak\" would be transcribed as or as ; and neither is identical to the vowel of the French \"\", which would also be transcribed . By contrast, a narrow phonetic transcription of \"pick\", \"peak\", \"pique\" could be: , , .\nLinguists.\nIPA is popular for transcription by linguists. Some American linguists, however, use a mix of IPA with Americanist phonetic notation or Sinological phonetic notation or otherwise use nonstandard symbols for various reasons. Authors who employ such nonstandard use are encouraged to include a chart or other explanation of their choices, which is good practice in general, as linguists differ in their understanding of the exact meaning of IPA symbols and common conventions change over time.\nDictionaries.\nEnglish.\nMany British dictionaries, including the \"Oxford English Dictionary\" and some learner's dictionaries such as the \"Oxford Advanced Learner's Dictionary\" and the \"Cambridge Advanced Learner's Dictionary\", now use the International Phonetic Alphabet to represent the pronunciation of words. However, most American (and some British) volumes use one of a variety of pronunciation respelling systems, intended to be more comfortable for readers of English and to be more acceptable across dialects, without the implication of a preferred pronunciation that the IPA might convey. For example, the respelling systems in many American dictionaries (such as \"Merriam-Webster\") use \u27e8y\u27e9 for IPA and \u27e8sh\u27e9 for IPA , reflecting the usual spelling of those sounds in English.\nOther languages.\nThe IPA is also not universal among dictionaries in languages other than English. Monolingual dictionaries of languages with phonemic orthographies generally do not bother with indicating the pronunciation of most words, and tend to use respelling systems for words with unexpected pronunciations. Dictionaries produced in Israel use the IPA rarely and sometimes use the Hebrew alphabet for transcription of foreign words. Bilingual dictionaries that translate from foreign languages into Russian usually employ the IPA, but monolingual Russian dictionaries occasionally use pronunciation respelling for foreign words. The IPA is more common in bilingual dictionaries, but there are exceptions here too. Mass-market bilingual Czech dictionaries, for instance, tend to use the IPA only for sounds not found in Czech.\nStandard orthographies and case variants.\nIPA letters have been incorporated into the alphabets of various languages, notably via the Africa Alphabet in many sub-Saharan languages such as Hausa, Fula, Akan, Gbe languages, Manding languages, Lingala, etc. Capital case variants have been created for use in these languages. For example, Kabiy\u00e8 of northern Togo has \u0189 \u0256, \u014a \u014b, \u0194 \u0263, \u0186 \u0254, \u0190 \u025b, \u01b2 \u028b. These, and others, are supported by Unicode, but appear in Latin ranges other than the IPA extensions.\nIn the IPA itself, however, only lower-case letters are used. The 1949 edition of the IPA handbook indicated that an asterisk \u27e8*\u27e9 might be prefixed to indicate that a word was a proper name, and this convention was used by \"Le Ma\u00eetre Phon\u00e9tique\", which was written in IPA rather than in English or French orthography, but it was not included in the 1999 \"Handbook\", which notes the contrary use of the asterisk as a placeholder for a sound or feature that does not have a symbol.\nClassical singing.\nThe IPA has widespread use among classical singers during preparation as they are frequently required to sing in a variety of foreign languages. They are also taught by vocal coaches to perfect diction and improve tone quality and tuning. Opera librettos are authoritatively transcribed in IPA, such as Nico Castel's volumes and Timothy Cheek's book \"Singing in Czech\". Opera singers' ability to read IPA was used by the site \"Visual Thesaurus\", which employed several opera singers \"to make recordings for the 150,000 words and phrases in VT's lexical database\u00a0... for their vocal stamina, attention to the details of enunciation, and most of all, knowledge of IPA\".\nLetters.\nThe International Phonetic Association organizes the letters of the IPA into three categories: pulmonic consonants, non-pulmonic consonants, and vowels.\nPulmonic consonant letters are arranged singly or in pairs of voiceless (tenuis) and voiced sounds, with these then grouped in columns from front (labial) sounds on the left to back (glottal) sounds on the right. In official publications by the IPA, two columns are omitted to save space, with the letters listed among \"other symbols\" even though theoretically they belong in the main chart. They are arranged in rows from full closure (occlusives: stops and nasals) at top, to brief closure (vibrants: trills and taps), to partial closure (fricatives), and finally minimal closure (approximants) at bottom, again with a row left out to save space. In the table below, a slightly different arrangement is made: All pulmonic consonants are included in the pulmonic-consonant table, and the vibrants and laterals are separated out so that the rows reflect the common lenition pathway of \"stop \u2192 fricative \u2192 approximant\", as well as the fact that several letters pull double duty as both fricative and approximant; affricates may then be created by joining stops and fricatives from adjacent cells. Shaded cells represent articulations that are judged to be impossible or not distinctive.\nVowel letters are also grouped in pairs\u00a0\u2013 of unrounded and rounded vowel sounds\u00a0\u2013 with these pairs also arranged from front on the left to back on the right, and from maximal closure at top to minimal closure at bottom. No vowel letters are omitted from the chart, though in the past some of the mid central vowels were listed among the \"other symbols\".\nConsonants.\nPulmonic consonants.\nA pulmonic consonant is a consonant made by obstructing the glottis (the space between the vocal folds) or oral cavity (the mouth) and either simultaneously or subsequently letting out air from the lungs. Pulmonic consonants make up the majority of consonants in the IPA, as well as in human language. All consonants in English fall into this category.\nThe pulmonic consonant table, which includes most consonants, is arranged in rows that designate manner of articulation, meaning how the consonant is produced, and columns that designate place of articulation, meaning where in the vocal tract the consonant is produced. The main chart includes only consonants with a single place of articulation.\n&lt;templatestyles src=\"IPA common/styles.css\" /&gt;\nNotes\nNon-pulmonic consonants.\nNon-pulmonic consonants are sounds whose airflow is not dependent on the lungs. These include clicks (found in the Khoisan languages and some neighboring Bantu languages of Africa), implosives (found in languages such as Sindhi, Hausa, Swahili and Vietnamese), and ejectives (found in many Amerindian and Caucasian languages).\n&lt;templatestyles src=\"IPA common/styles.css\" /&gt;\nNotes\nAffricates.\nAffricates and co-articulated stops are represented by two letters in sequence. For clarity, this digraph may be joined by a tie bar, which may appear either above or below the letters with no difference in meaning. Affricates are optionally represented by ligatures\u00a0\u2013 e.g. \u27e8\u27e9\u00a0\u2013 though this is no longer official IPA usage. Alternatively, a superscript notation for a consonant release is sometimes used to transcribe affricates, for example \u27e8\u27e9 for , although in precise notation this would indicate a fricative release rather than an affricate. The letters for the palatal plosives \u27e8\u27e9 and \u27e8\u27e9 are often used as a convenience for and or similar affricates, even in official IPA publications, so they must be interpreted with care.\n&lt;templatestyles src=\"IPA common/styles.css\" /&gt;\nBecause in a true affricate the plosive element and the fricative element are homorganic, and the place of articulation of an affricate is most audible in the fricative element, the letter for the former will not always be precisely transcribed where such precision would be redundant. For example, while the English \"ch\" sound is in close transcription, the diacritic is commonly left off, for . Similarly, and are more commonly written and , and in the ligatures there is only a single retroflex hook.\nCo-articulated consonants.\nCo-articulated consonants are sounds that involve two simultaneous places of articulation (are pronounced using two parts of the vocal tract). In English, the in \"went\" is a coarticulated consonant, being pronounced by rounding the lips and raising the back of the tongue. Similar sounds are and . In some languages, plosives can be double-articulated, for example in the name of Laurent Gbagbo.\n&lt;templatestyles src=\"IPA common/styles.css\" /&gt;\nNotes\nWith the implosives, authors may not bother to redundantly mark both letters as implosive, but instead write them as less-cluttered \u27e8\u27e9 and even \u27e8\u27e9.\nVowels.\nThe IPA defines a vowel as a sound which occurs at a syllable center. Below is a chart depicting the vowels of the IPA. The IPA maps the vowels according to the position of the tongue.\n&lt;templatestyles src=\"IPA common/styles.css\" /&gt;\nThe vertical axis of the chart is mapped by vowel height. Vowels pronounced with the tongue lowered are at the bottom, and vowels pronounced with the tongue raised are at the top. For example, (the first vowel in \"father\") is at the bottom because the tongue is lowered in this position. (the vowel in \"meet\") is at the top because the sound is said with the tongue raised to the roof of the mouth.\nIn a similar fashion, the horizontal axis of the chart is determined by vowel backness. Vowels with the tongue moved towards the front of the mouth (such as , the vowel in \"met\") are to the left in the chart, while those in which it is moved to the back (such as , the vowel in \"but\") are placed to the right in the chart.\nIn places where vowels are paired, the right represents a rounded vowel (in which the lips are rounded) while the left is its unrounded counterpart.\nDiphthongs.\nDiphthongs may be written as simple sequences of letters, but for clarity they are commonly specified with a non-syllabic diacritic, as in \u27e8\u27e9 or \u27e8\u27e9, or with a superscript for the on- or off-glide, as in \u27e8\u27e9 or \u27e8\u27e9. Sometimes a tie bar is used: \u27e8\u27e9, especially when it is difficult to tell if the diphthong is characterized by an on-glide or an off-glide, or when it is variable.\nDiacritics and prosodic notation.\nDiacritics are used for phonetic detail. They are added to IPA letters to indicate a modification or specification of that letter's normal pronunciation.\nBy being made superscript, any IPA letter may function as a diacritic, conferring elements of its articulation to the base letter. Those superscript letters listed below are specifically provided for by the IPA \"Handbook\"; other uses can be illustrated with \u27e8\u27e9 ( with fricative release), \u27e8\u27e9 ( with affricate onset), \u27e8\u27e9 (prenasalized ), \u27e8\u27e9 ( with breathy voice), \u27e8\u27e9 (glottalized ), \u27e8\u27e9 ( with a flavor of , i.e. a voiceless alveolar retracted sibilant), \u27e8\u27e9 ( with diphthongization), \u27e8\u27e9 (compressed ). Superscript diacritics placed after a letter are ambiguous between simultaneous modification of the sound and phonetic detail at the end of the sound. For example, labialized \u27e8\u27e9 may mean either simultaneous and or else with a labialized release. Superscript diacritics placed before a letter, on the other hand, normally indicate a modification of the onset of the sound (\u27e8\u27e9 glottalized , \u27e8\u27e9 with a glottal onset). (See .)\nNotes:\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nA diacritic may be moved to avoid conflicts of space. One that is normally placed below a letter may be moved above it to avoid a descender or another diacritic, as with the voiceless ring on \u27e8\u27e9, and vice versa with the tie bar on \u27e8\u27e9, though the tie bar is basically in free variation. Exceptions are the tilde, trema and caron/wedge \u2013 and, in extIPA, the bridge \u2013 which are defined differently when placed above and below a letter.\nA couple additional superscript letters are found for secondary articulation. In the \"Handbook\", for example, \u27e8\u27e9 is used for voiced aspiration. \u27e8\u27e9 is commonly seen with languages such as Twi where consonants may be simultaneously palatalized and labialized, while \u27e8\u27e9 may be used for glottalized sounds without specifying whether they are ejective or have creaky voice. ExtIPA provides \u27e8\u27e9 for uvularization, and the Voice Quality Symbols provide a couple more. However, only limited set of IPA letters are used in this fashion; for all others, superscripting indicates more ambiguous shading of the sound.\nThe state of the glottis can be finely transcribed with diacritics. A series of alveolar plosives ranging from open-glottis to closed-glottis phonation is:\nAdditional diacritics are provided by the Extensions to the IPA for speech pathology.\nSuprasegmentals.\nThese symbols describe the features of a language above the level of individual consonants and vowels, that is, at the level of syllable, word or phrase. These include prosody, pitch, length, stress, intensity, tone and gemination of the sounds of a language, as well as the rhythm and intonation of speech. Various ligatures of pitch/tone letters and diacritics are provided for by the Kiel Convention and used in the IPA \"Handbook\" despite not being found in the summary of the IPA alphabet found on the one-page chart.\nUnder capital letters below we will see how a carrier letter may be used to indicate suprasegmental features such as labialization or nasalization. Some authors omit the carrier letter, for e.g. suffixed or prefixed , or place a spacing variant of a diacritic such as \u27e8\u27e9 or \u27e8\u27e9 at the beginning or end of a word to indicate that it applies to the entire word.\nNotes:\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nThe old staveless tone letters, which are effectively obsolete, include high \u27e8\u27e9, mid \u27e8\u27e9 [not supported by Unicode], low \u27e8\u27e9, rising \u27e8\u27e9, falling \u27e8\u27e9, low rising \u27e8\u27e9 and low falling \u27e8\u27e9.\nStress.\nOfficially, the stress marks \u27e8\u27e9 appear before the stressed syllable, and thus mark the syllable boundary as well as stress (though the syllable boundary may still be explicitly marked with a period). Occasionally the stress mark is placed immediately before the nucleus of the syllable, after any consonantal onset. In such transcriptions, the stress mark does not mark a syllable boundary. The primary stress mark may be doubled \u27e8\u27e9 for extra stress (such as prosodic stress). The secondary stress mark is sometimes seen doubled \u27e8\u27e9 for extra-weak stress, but this convention has not been adopted by the IPA. Some dictionaries place both stress marks before a syllable, \u27e8\u27e9, to indicate that pronunciations with either primary or secondary stress are heard, though this is not IPA usage.\nBoundary markers.\nThere are three boundary markers: \u27e8\u27e9 for a syllable break, \u27e8\u27e9 for a minor prosodic break and \u27e8\u27e9 for a major prosodic break. The tags 'minor' and 'major' are intentionally ambiguous. Depending on need, 'minor' may vary from a foot break to a break in list-intonation to a continuing\u2013prosodic unit boundary (equivalent to a comma), and while 'major' is often any intonation break, it may be restricted to a final\u2013prosodic unit boundary (equivalent to a period). The 'major' symbol may also be doubled, \u27e8\u27e9, for a stronger break.\nAlthough not part of the IPA, the following additional boundary markers are often used in conjunction with the IPA: \u27e8\u27e9 for a mora or mora boundary, \u27e8\u27e9 for a syllable or syllable boundary, \u27e8\u27e9 for a morpheme boundary, \u27e8\u27e9 for a word boundary (may be doubled, \u27e8\u27e9, for e.g. a breath-group boundary), \u27e8\u27e9 for a phrase or intermediate boundary and \u27e8\u27e9 for a prosodic boundary. For example, C# is a word-final consonant, %V a post-pausa vowel, and \u03c3C a syllable-initial consonant.\nPitch and tone.\n\u27e8\u27e9 are defined in the \"Handbook\" as \"upstep\" and \"downstep\", concepts from tonal languages. However, the upstep symbol can also be used for pitch reset, and the IPA \"Handbook\" uses it for prosody in the illustration for Portuguese, a non-tonal language.\nPhonetic pitch and phonemic tone may be indicated by either diacritics placed over the nucleus of the syllable\u00a0\u2013 e.g., high-pitch \u27e8\u27e9\u00a0\u2013 or by Chao tone letters placed either before or after the word or syllable. There are three graphic variants of the tone letters: with or without a stave, and facing left or facing right from the stave. The stave was introduced with the 1989 Kiel Convention, as was the option of placing a staved letter after the word or syllable, while retaining the older conventions. There are therefore six ways to transcribe pitch/tone in the IPA: i.e., \u27e8\u27e9, \u27e8\u27e9, \u27e8\u27e9, \u27e8\u27e9, \u27e8\u27e9 and \u27e8\u27e9 for a high pitch/tone. Of the tone letters, only left-facing staved letters and a few representative combinations are shown in the summary on the \"Chart\", and in practice it is currently more common for tone letters to occur after the syllable/word than before, as in the Chao tradition. Placement before the word is a carry-over from the pre-Kiel IPA convention, as is still the case for the stress and upstep/downstep marks. The IPA endorses the Chao tradition of using the left-facing tone letters, \u27e8\u27e9, for underlying tone, and the right-facing letters, \u27e8\u27e9, for surface tone, as occurs in tone sandhi, and for the intonation of non-tonal languages. In the Portuguese illustration in the 1999 \"Handbook\", for example, tone letters are placed before a word or syllable to indicate prosodic pitch (equivalent to global rise and global fall, but allowing more precision), and in the Cantonese illustration they are placed after a word/syllable to indicate lexical tone. Theoretically therefore prosodic pitch and lexical tone could be simultaneously transcribed in a single text, though this is not a formalized distinction.\nRising and falling pitch, as in contour tones, are indicated by combining the pitch diacritics and letters in the table, such as grave plus acute for rising and acute plus grave for falling . Only six combinations of two diacritics are supported, and only across three levels (high, mid, low), despite the diacritics supporting five levels of pitch in isolation. The four other explicitly approved rising and falling diacritic combinations are high/mid rising , low rising , high falling , and low/mid falling .\nThe Chao tone letters, on the other hand, may be combined in any pattern, and are therefore used for more complex contours and finer distinctions than the diacritics allow, such as mid-rising , extra-high falling , etc. There are 20 such possibilities. However, in Chao's original proposal, which was adopted by the IPA in 1989, he stipulated that the half-high and half-low letters \u27e8\u27e9 may be combined with each other, but not with the other three tone letters, so as not to create spuriously precise distinctions. With this restriction, there are 8 possibilities.\nThe old staveless tone letters tend to be more restricted than the staved letters, though not as restricted as the diacritics. Technically they support as many distinctions as the staved letters, but in the decades prior to the Kiel Convention only three pitch levels were provided for level tones, and only two for contour tones. Unicode supports default or high-pitch \u27e8\u27e9 and low-pitch \u27e8\u27e9. Only a single mid-pitch tone is supported: \u27e8\u27e9. The IPA had also used dots for neutral tones, but the corresponding dotted Chao tone letters were not adopted at the Kiel Convention.\nAlthough tone diacritics and tone letters are presented as equivalent on the chart, \"this was done only to simplify the layout of the chart. The two sets of symbols are not comparable in this way.\" Using diacritics, a high tone is \u27e8\u27e9 and a low tone is \u27e8\u27e9; in tone letters, these are \u27e8\u27e9 and \u27e8\u27e9. One can double the diacritics for extra-high \u27e8\u27e9 and extra-low \u27e8\u27e9; there is no parallel to this using tone letters. Instead, tone letters have mid-high \u27e8\u27e9 and mid-low \u27e8\u27e9; again, there is no equivalent among the diacritics. Thus in a three-register tone system, \u27e8\u27e9 are equivalent to \u27e8\u27e9, while in a four-register system, \u27e8\u27e9 may be equivalent to \u27e8\u27e9.\nThe correspondence breaks down even further once they start combining. For more complex tones, one may combine three or four tone diacritics in any permutation, though in practice only generic peaking (rising-falling) and dipping (falling-rising) combinations are used. Chao tone letters are required for finer detail (, etc.). Although only 10 peaking and dipping tones were proposed in Chao's original, limited set of tone letters, phoneticians often make finer distinctions, and indeed an example is found on the IPA Chart. The system allows the transcription of 112 peaking and dipping pitch contours, including tones that are level for part of their length.\nMore complex contours are possible. Chao gave an example of (mid-high-low-mid) from English prosody.\nChao tone letters generally appear after each syllable, for a language with syllable tone (e.g. \u27e8\u27e9) or after the phonological word, for a language with word tone (e.g. \u27e8\u27e9 for the same change in pitch). The IPA gives the option of placing the tone letters before the word or syllable (\u27e8\u27e9, \u27e8\u27e9), and illustrates this for prosody, but it is rare for lexical tone. Reversed tone letters may be used to clarify that they apply to the following rather than to the preceding syllable (\u27e8\u27e9, \u27e8\u27e9). The staveless letters are not directly supported by Unicode, but some fonts allow the stave in Chao tone letters to be suppressed.\nComparative degree.\nIPA diacritics may be doubled to indicate an extra degree (greater intensity) of the feature indicated. This is a productive process, but apart from extra-high and extra-low tones being marked by doubled high- and low-tone diacritics, \u27e8\u27e9, the major prosodic break \u27e8\u27e9 being marked as a doubled minor break \u27e8\u27e9, and a couple other instances, such usage is not enumerated by the IPA.\nFor example, the stress mark may be doubled (or even tripled, as may be the prosodic-break bar, \u27e8\u27e9) to indicate an extra degree of stress, such as prosodic stress in English. An example in French, with a single stress mark for normal prosodic stress at the end of each prosodic unit (marked as a minor prosodic break), and a double or even triple stress mark for contrastive/emphatic stress: \".\" Similarly, a doubled secondary stress mark \u27e8\u27e9 is commonly used for tertiary (extra-light) stress, though a proposal to officially adopt this was rejected. In a similar vein, the effectively obsolete staveless tone letters were once doubled for an emphatic rising intonation \u27e8\u27e9 and an emphatic falling intonation \u27e8\u27e9.\nLength is commonly extended by repeating the length mark, which may be phonetic, as in etc., as in English \"shhh!\" , or phonemic, as in the \"overlong\" segments of Estonian:\nDelimiters are similar: double slashes indicate extra phonemic (morpho-phonemic), double square brackets especially precise transcription, and double parentheses especially unintelligible.\nOccasionally other diacritics are doubled:\nThe extIPA provides combining parentheses for weak intensity, which when combined with a doubled diacritic indicate an intermediate degree. For instance, increasing degrees of nasalization of the vowel might be written \u27e8\u27e9.\nAmbiguous letters.\nAs noted above, IPA letters are often used quite loosely in broad transcription if no ambiguity would arise in a particular language. Because of that, IPA letters have not generally been created for sounds that are not distinguished in individual languages. A distinction between voiced fricatives and approximants is only partially implemented by the IPA, for example. Even with the relatively recent addition of the palatal fricative \u27e8\u27e9 and the velar approximant \u27e8\u27e9 to the alphabet, other letters, though defined as fricatives, are often ambiguous between fricative and approximant. For forward places, \u27e8\u27e9 and \u27e8\u27e9 can generally be assumed to be fricatives unless they carry a lowering diacritic. Rearward, however, \u27e8\u27e9 and \u27e8\u27e9 are perhaps more commonly intended to be approximants even without a lowering diacritic. \u27e8\u27e9 and \u27e8\u27e9 are similarly either fricatives or approximants, depending on the language, or even glottal \"transitions\", without that often being specified in the transcription.\nAnother common ambiguity is among the letters for palatal consonants. \u27e8\u27e9 and \u27e8\u27e9 are not uncommonly used as a typographic convenience for affricates, typically and , while \u27e8\u27e9 and \u27e8\u27e9 are commonly used for palatalized alveolar and . To some extent this may be an effect of analysis, but it is common to match up single IPA letters to the phonemes of a language, without overly worrying about phonetic precision.\nIt has been argued that the lower-pharyngeal (epiglottal) fricatives \u27e8\u27e9 and \u27e8\u27e9 are better characterized as trills, rather than as fricatives that have incidental trilling. This has the advantage of merging the upper-pharyngeal fricatives together with the epiglottal plosive and trills into a single pharyngeal column in the consonant chart. However, in Shilha Berber the epiglottal fricatives are not trilled. Although they might be transcribed \u27e8\u27e9 to indicate this, the far more common transcription is \u27e8\u27e9, which is therefore ambiguous between languages.\nAmong vowels, \u27e8\u27e9 is officially a front vowel, but is more commonly treated as a central vowel. The difference, to the extent it is even possible, is not phonemic in any language.\nFor all phonetic notation, it is good practice for an author to specify exactly what they mean by the symbols that they use.\nSuperscript letters.\nSuperscript IPA letters are used to indicate secondary aspects of articulation. These may be aspects of simultaneous articulation that are considered to be in some sense less dominant than the basic sound, or may be transitional articulations that are interpreted as secondary elements. Examples include secondary articulation; onsets, releases, aspiration and other transitions; shades of sound; light epenthetic sounds and incompletely articulated sounds. Morphophonemically, superscripts may be used for assimilation, e.g. \u27e8\u27e9 for the effect of labialization on a vowel , which may be realized as phonemic . The IPA and ICPLA endorse Unicode encoding of superscript variants of all contemporary segmental letters in the IPA proper and of all additional fricatives in extIPA, including the \"implicit\" IPA retroflex letters \u27e8\u27e9.\nSuperscripts are often used as a substitute for the tie bar, for example \u27e8\u27e9 for and \u27e8\u27e9 or \u27e8\u27e9 for . However, in precise notation there is a difference between a fricative release in and the affricate , between a velar onset in and doubly articulated .\nSuperscript letters can be meaningfully modified by combining diacritics, just as baseline letters can. For example, a superscript dental nasal in \u27e8\u27e9, a superscript voiceless velar nasal in \u27e8\u27e9, and labial-velar prenasalization in \u27e8\u27e9. Although the diacritic may seem a bit oversized compared to the superscript letter it modifies, e.g. \u27e8\u27e9, this can be an aid to legibility, just as it is with the composite superscript c-cedilla \u27e8\u27e9 and rhotic vowels \u27e8\u27e9. Superscript length marks can be used to indicate the length of aspiration of a consonant, e.g. . Another option is to use extIPA parentheses and a doubled diacritic: \u27e8\u27e9.\nObsolete and nonstandard symbols.\nA number of IPA letters and diacritics have been retired or replaced over the years. This number includes duplicate symbols, symbols that were replaced due to user preference, and unitary symbols that were rendered with diacritics or digraphs to reduce the inventory of the IPA. The rejected symbols are now considered obsolete, though some are still seen in the literature.\nThe IPA once had several pairs of duplicate symbols from alternative proposals, but eventually settled on one or the other. An example is the vowel letter \u27e8\u27e9, rejected in favor of \u27e8\u27e9. Affricates were once transcribed with ligatures, such as \u27e8\u27e9 (and others, some of which are not found in Unicode). These have been officially retired but are still used. Letters for specific combinations of primary and secondary articulation have also been mostly retired, with the idea that such features should be indicated with tie bars or diacritics: \u27e8\u27e9 for is one. In addition, the rare voiceless implosives, \u27e8\u27e9, were dropped soon after their introduction and are now usually written \u27e8\u27e9. The original set of click letters, \u27e8\u27e9, was retired but is still sometimes seen, as the current pipe letters \u27e8\u27e9 can cause problems with legibility, especially when used with brackets ([ ] or / /), the letter \u27e8\u27e9 (small L), or the prosodic marks \u27e8\u27e9. (For this reason, some publications which use the current IPA pipe letters disallow IPA brackets.)\nIndividual non-IPA letters may find their way into publications that otherwise use the standard IPA. This is especially common with:\nIn addition, it is common to see \"ad hoc\" typewriter substitutions, generally capital letters, for when IPA support is not available, e.g. S for \u27e8\u27e9. (See also SAMPA and X-SAMPA substitute notation.)\nExtensions.\nThe Extensions to the International Phonetic Alphabet for Disordered Speech, commonly abbreviated \"extIPA\" and sometimes called \"Extended IPA\", are symbols whose original purpose was to accurately transcribe disordered speech. At the Kiel Convention in 1989, a group of linguists drew up the initial extensions, which were based on the previous work of the PRDS (Phonetic Representation of Disordered Speech) Group in the early 1980s. The extensions were first published in 1990, then modified, and published again in 1994 in the \"Journal of the International Phonetic Association\", when they were officially adopted by the ICPLA. While the original purpose was to transcribe disordered speech, linguists have used the extensions to designate a number of sounds within standard communication, such as hushing, gnashing teeth, and smacking lips, as well as regular lexical sounds such as lateral fricatives that do not have standard IPA symbols.\nIn addition to the Extensions to the IPA for disordered speech, there are the conventions of the Voice Quality Symbols, which include a number of symbols for additional airstream mechanisms and secondary articulations in what they call \"voice quality\".\nAssociated notation.\nCapital letters and various characters on the number row of the keyboard are commonly used to extend the alphabet in various ways.\nAssociated symbols.\nThere are various punctuation-like conventions for linguistic transcription that are commonly used together with IPA. Some of the more common are:\n(a) A reconstructed form.\n(b) An ungrammatical form (including an unphonemic form).\n(a) A reconstructed form, deeper (more ancient) than a single \u27e8*\u27e9, used when reconstructing even further back from already-starred forms.\n(b) An ungrammatical form. A less common convention than \u27e8*\u27e9 (b), this is sometimes used when reconstructed and ungrammatical forms occur in the same text.\nCapital letters.\nFull capital letters are not used as IPA symbols, except as typewriter substitutes (e.g. N for \u27e8\u27e9, S for \u27e8\u27e9, O for \u27e8\u27e9 \u2013 see SAMPA). They are, however, often used in conjunction with the IPA in two cases:\nWildcards are commonly used in phonology to summarize syllable or word shapes, or to show the evolution of classes of sounds. For example, the possible syllable shapes of Mandarin can be abstracted as ranging from (an atonic vowel) to (a consonant-glide-vowel-nasal syllable with tone), and word-final devoicing may be schematized as \u2192 /_#. They are also used in historical linguistics for a sound that is posited but whose nature has not been determined beyond some generic category such as {nasal} or {uvular}. In speech pathology, capital letters represent indeterminate sounds, and may be superscripted to indicate they are weakly articulated: e.g. is a weak indeterminate alveolar, a weak indeterminate velar.\nThere is a degree of variation between authors as to the capital letters used, but these are ubiquitous in English-language material:\nOther common conventions are:\nThe letters can be modified with IPA diacritics, for example:\n\u27e8\u27e9, \u27e8\u27e9, \u27e8\u27e9 are also commonly used for high, mid and low tone, with \u27e8\u27e9 for rising tone and \u27e8\u27e9 for falling tone, rather than transcribing them overly precisely with IPA tone letters or with ambiguous digits. When distinguishing five levels of pitch, \u27e8\u27e9 and \u27e8\u27e9 may be used for 'extra high' and 'extra low'. Arbitrary sequences of letters such as \u27e8\u27e9 may be used for tone phonemes, especially when comparing across related languages.\nTypical examples of archiphonemic use of capital letters are:\nSimilar usage is found for \"phonemic\" analysis, where a language does not distinguish sounds that have separate letters in the IPA. For instance, Castillian Spanish has been analyzed as having phonemes and , which surface as and in voiceless environments and as and in voiced environments (e.g. \u2192 , vs \u2192 , or \u2192 ).\n\u27e8\u27e9, \u27e8\u27e9 and \u27e8\u27e9 have completely different meanings as Voice Quality Symbols, where they stand for \"voice\" (VoQS jargon for secondary articulation), \"falsetto\" and \"creak\". These three letters may take diacritics to indicate what kind of voice quality an utterance has, and may be used as carrier letters to extract a suprasegmental feature that occurs on all susceptible segments in a stretch of IPA. For instance, the transcription of Scottish Gaelic 'cat' and 'cats' (Islay dialect) can be made more economical by extracting the suprasegmental labialization of the words: and . The conventional wildcards \u27e8\u27e9 or \u27e8\u27e9 might be used instead of VoQS \u27e8\u27e9 so that the reader does not misinterpret \u27e8\u27e9 as meaning that only vowels are labialized (i.e. for all segments labialized, for all consonants labialized), or the carrier letter may be omitted altogether (e.g. , or ). (See for other transcription conventions.)\nThis summary is to some extent valid internationally, but linguistic material written in other languages may have different associations with capital letters used as wildcards. For example, in German \u27e8\u27e9 and \u27e8\u27e9 are used for 'consonant' and 'vowel'; in Russian, \u27e8\u27e9 and \u27e8\u27e9 are used for (, 'consonant') and (, 'vowel'). In French, tone may be transcribed with \u27e8\u27e9 and \u27e8\u27e9 for 'high' and 'low'; Russian appears to be the opposite, with \u27e8\u27e9 for (, 'high') and \u27e8\u27e9 for (, 'low').\nSegments without letters.\nThe blank cells on the summary IPA chart can be filled without much difficulty if the need arises.\nThe missing retroflex letters, namely \u27e8\u27e9, are \"implicit\" in the alphabet, and the IPA supported their adoption into Unicode. Attested in the literature are the retroflex implosive \u27e8\u27e9, the voiceless retroflex lateral fricative \u27e8\u27e9, the retroflex lateral flap \u27e8\u27e9 and the retroflex click \u27e8\u27e9; the first is also mentioned in the IPA \"Handbook\", and the lateral fricatives are provided for by the extIPA.\nThe epiglottal trill is arguably covered by the generally trilled epiglottal \"fricatives\" \u27e8\u27e9. Ad hoc letters for near-close central vowels, \u27e8\u27e9, are used in some descriptions of English, though those are specifically reduced vowels\u00a0\u2013 forming a set with the IPA reduced vowels \u27e8\u27e9\u00a0\u2013 and the simple points in vowel space are easily transcribed with diacritics: \u27e8\u27e9 or \u27e8\u27e9. Diacritics are able to fill in most of the remainder of the charts. If a sound cannot be transcribed, an asterisk \u27e8\u27e9 may be used, either as a letter or as a diacritic (as in \u27e8\u27e9 sometimes seen for the Korean \"fortis\" velar).\nConsonants.\nRepresentations of consonant sounds outside of the core set are created by adding diacritics to letters with similar sound values. The Spanish bilabial and dental approximants are commonly written as lowered fricatives, and respectively. Similarly, voiced lateral fricatives can be written as raised lateral approximants, , though the extIPA also provides \u27e8\u27e9 for the first of these. A few languages such as Banda have a bilabial flap as the preferred allophone of what is elsewhere a labiodental flap. It has been suggested that this be written with the labiodental flap letter and the advanced diacritic, .\nSimilarly, a labiodental trill would be written (bilabial trill and the dental sign), and the labiodental plosives are now universally \u27e8\u27e9 rather than the \"ad hoc\" letters \u27e8\u27e9 once found in Bantuist literature. Other taps can be written as extra-short plosives or laterals, e.g. , though in some cases the diacritic would need to be written below the letter. A retroflex trill can be written as a retracted , just as non-subapical retroflex fricatives and uvular laterals sometimes are. The palatal trill, while not strictly impossible, is very difficult to pronounce and has no formal symbol in the IPA or ExtIPA because it is not found in any known language.\nVowels.\nThe vowels are similarly manageable by using diacritics for raising, lowering, fronting, backing, centering, and mid-centering. For example, the unrounded equivalent of can be transcribed as mid-centered , and the rounded equivalent of as raised or lowered (though for those who conceive of vowel space as a triangle, simple already is the rounded equivalent of ). True mid vowels are lowered or raised , while centered and (or, less commonly, ) are near-close and open central vowels, respectively.\nThe only known vowels that cannot be represented in this scheme are vowels with unexpected roundedness. For unambiguous transcription, such sounds would require dedicated diacritics. Possibilities include \u27e8\u27e9 or \u27e8\u27e9 for protrusion and \u27e8\u27e9 (or VoQS \u27e8\u27e9) for compression. However, these transcriptions suggest that the sounds are diphthongs, and so while they may be clear for a language like Swedish where they are diphthongs, they may be misleading for languages such as Japanese where they are monophthongs.\nThe extIPA 'spread' diacritic \u27e8\u27e9 is sometimes seen for compressed \u27e8\u27e9, \u27e8\u27e9, \u27e8\u27e9, \u27e8\u27e9, though again the intended meaning would need to be explained or they would be interpreted as being spread the way that cardinal is. For protrusion (\"w\"-like labialization without velarization), Ladefoged &amp; Maddieson use the old IPA omega diacritic for labialization, \u27e8\u27e9, for protruded \u27e8\u27e9, \u27e8\u27e9, \u27e8\u27e9, \u27e8\u27e9. This is an adaptation of an old IPA convention of rounding an unrounded vowel letter like \"i\" with a subscript omega (\u27e8\u27e9) and unrounding a rounded letter like \"u\" with a subscript turned omega.\nIts inverse, a turned omega diacritic \u27e8\u27e9, was adopted into Unicode in 2025 and is under consideration to mark compression in extIPA.\nKelly &amp; Local use a combining \"w\" diacritic \u27e8\u27e9 for protrusion (e.g. \u27e8\u27e9) and a combining \"\u028d\" diacritic \u27e8\u27e9 for compression (e.g. \u27e8\u27e9). Because their transcriptions are manuscript, these are effectively the same symbols as the old IPA diacritics, which indeed are historically cursive \"w\" and \"\u028d\". However, the more angular \u27e8\u27e9 of typescript might misleadingly suggest the vowel is protruded and voiceless (like ) rather than compressed and voiced.\nSymbol names.\nIn both print and speech, an IPA symbol is often distinguished from the sound it transcribes because IPA letters very often do not have their cardinal IPA values in practice. This is commonly the case in phonemic and broad phonetic transcription, making articulatory descriptions of IPA letters, such as \"mid front rounded vowel\" or \"voiced velar stop\", inappropriate as names for those letters. While the \"Handbook of the International Phonetic Association\" states that no official names exist for its symbols, it admits the presence of one or two common names for each. The symbols also have nonce names in the Unicode standard. In many cases, the names in Unicode and the IPA \"Handbook\" differ. For example, the \"Handbook\" calls \u27e8\u27e9 \"epsilon\", while Unicode calls it \"small letter open e\".\nThe traditional names of the Latin and Greek letters are usually used for unmodified letters. Letters which are not directly derived from these alphabets, such as \u27e8\u27e9, may have a variety of names, sometimes based on the appearance of the symbol or on the sound that it represents. In Unicode, some of the letters of Greek origin have Latin forms for use in IPA; the others use the characters from the Greek block.\nFor diacritics, there are two methods of naming. For traditional diacritics, the IPA notes the name in a well known language; for example, \u27e8\u27e9 is \"e-acute\", based on the name of the diacritic in English and French. Non-traditional diacritics are often named after objects they resemble, so \u27e8\u27e9 is called \"d-bridge\".\nGeoffrey Pullum and William Ladusaw list a variety of names in use for both current and retired IPA symbols in their \"Phonetic Symbol Guide\". Many of them found their way into Unicode.\nComputer support.\nUnicode.\nUnicode supports nearly all of the IPA. Apart from basic Latin and Greek and general punctuation, the primary blocks are IPA Extensions, Spacing Modifier Letters and Combining Diacritical Marks, with lesser support from Phonetic Extensions, Phonetic Extensions Supplement, Combining Diacritical Marks Supplement, and scattered characters elsewhere. The extended IPA is supported primarily by those blocks and Latin Extended-G.\nIPA numbers.\nAfter the Kiel Convention in 1989, most IPA symbols were assigned an identifying number to prevent confusion between similar characters during the printing of manuscripts. The codes were never much used and have been superseded by Unicode.\nTypefaces.\nMany typefaces have support for IPA characters, but good diacritic rendering remains rare. Web browsers generally do not need any configuration to display IPA characters, provided that a typeface capable of doing so is available to the operating system.\nFree fonts.\nTypefaces that provide full IPA and nearly full extIPA support, including properly rendering the diacritics, include Gentium, Charis SIL, Doulos SIL, and Andika developed by SIL International. Indeed, the IPA chose Doulos to publish their chart in Unicode format.\nIn addition to the level of support found in commercial and system fonts, these fonts support the full range of old-style (pre-Kiel) staveless tone letters, through a character variant option that suppresses the stave of the Chao tone letters. They also have an option to maintain the ~ vowel distinction in italics. The only notable gaps are with the extIPA: the combining parentheses, which enclose diacritics, are not supported, nor is the enclosing circle that marks unidentified sounds, and which Unicode considers to be a copy-edit mark and thus not eligible for Unicode support.\nThe basic Latin Noto fonts commissioned by Google also have significant IPA support, including diacritic placement, only failing with the more obscure IPA and extIPA characters and superscripts of the Latin Extended-F and Latin Extended-G blocks. The extIPA parentheses are included, but they do not enclose diacritics as they are supposed to.\nDejaVu is the second free Unicode font chosen by the IPA to publish their chart. It was last updated in 2016 and so does not support the Latin F or G blocks. Stacked diacritics tend to overstrike each other.\nAs of 2018[ [update]], the IPA was developing their own font, \"unitipa\", based on TIPA.\nProprietary system fonts.\nCalibri, the former default font of Microsoft Office, has nearly complete IPA support with good diacritic rendering, though it is not as complete as some free fonts (see image at right). Other widespread Microsoft fonts, such as Arial and Times New Roman, have poor support.\nThe Apple system fonts Geneva, Lucida Grande and Hiragino (certain weights) have only basic IPA support.\nNotable commercial fonts.\nBrill has complete IPA and extIPA coverage of characters added to Unicode by 2020, with good diacritic and tone-letter support. It is a commercial font but is freely available for non-commercial use.\nASCII and keyboard transliterations.\nSeveral systems have been developed that map the IPA symbols to ASCII characters. Notable systems include SAMPA and X-SAMPA. The usage of mapping systems in on-line text has to some extent been adopted in the context input methods, allowing convenient keying of IPA characters that would be otherwise unavailable on standard keyboard layouts.\nIETF language tags.\nIETF language tags have registered fonipa as a variant subtag identifying text as written in IPA.\nThus, an IPA transcription of English could be tagged as en-fonipa.\nFor the use of IPA without attribution to a concrete language, und-fonipa is available.\nComputer input using on-screen keyboard.\nOnline IPA keyboard utilities are available, though none of them cover the complete range of IPA symbols and diacritics. Examples are the \"IPA 2018 i-charts\" hosted by the IPA, \"IPA character picker\" by Richard Ishida at GitHub, \"Type IPA phonetic symbols\" at TypeIt.org, and an \"IPA Chart keyboard\" by Weston Ruter also at GitHub. In April 2019, Google's Gboard for Android added an IPA keyboard to its platform. For iOS there are multiple free keyboard layouts available, such as the \"IPA Phonetic Keyboard\".\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\nFootnotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nWorks cited.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nExternal links.\n&lt;templatestyles src=\"IPA common/styles.css\" /&gt;&lt;templatestyles src=\"IPA pulmonic consonants/styles.css\" /&gt;&lt;templatestyles src=\"IPA co-articulated consonants/styles.css\" /&gt;&lt;templatestyles src=\"IPA vowels/styles.css\" /&gt;"}
{"id": "14762", "revid": "50759449", "url": "https://en.wikipedia.org/wiki?curid=14762", "title": "Inspector Morse", "text": "Fictional character by Colin Dexter\nDetective Chief Inspector Endeavour Morse, GM, is the eponymous fictional character in the series of detective novels by British author Colin Dexter.\nOn television he was portrayed by John Thaw in a 33-episode drama series, \"Inspector Morse\" (1987\u20132000), and by Shaun Evans in the prequel series \"Endeavour\" (2012\u20132023). The older Morse is a senior Criminal Investigation Department (CID) officer, while the younger is a detective constable rising through the ranks with the Oxford City Police and, in later seasons, Thames Valley Police.\nMorse presents, to some, a reasonably sympathetic personality, despite his sullen and snobbish temperament. He is known for his classic Jaguar Mark 2 (a Lancia in the early novels), thirst for English real ale, and love of classical music (especially opera and Wagner), poetry, art and cryptic crossword puzzles. In his later career he is usually assisted by Sergeant Robbie Lewis, a partnership and formal friendship which is fundamental to the series.\nMorse uses Lewis\u2019 first name, Robbie for the first time in S5, E5 \"Promised Land\" before going to face a kidnapper and potential killer.\nBiography.\nFamily.\nMorse's father was a taxi driver. In the episode of the television adaptation \"Cherubim and Seraphim\", it is revealed that Morse's parents divorced when he was 12. He remained with his mother until her death three years later, upon which he had to return to his father. Morse had a dreadful relationship with his stepmother Gwen. He claims that he only read poetry to annoy her, and that her petty bullying almost drove him to suicide. He has a half-sister named Joyce with whom he is on better terms. Morse was devastated when Joyce's daughter Marilyn took her own life.\nMorse prefers to use only his surname, and is generally evasive when asked about his first name, sometimes joking that it is \"Inspector\". \"Everyone just calls me Morse. I do have a first name.\" In \"The Dead of Jericho\" it is remarked that \"he had never quite forgiven his parents for christening their only offspring as they had.\" Also in \"The Dead of Jericho\", and in \"The Wench Is Dead\", it is noted that his initial is E. At the end of \"Death Is Now My Neighbour\", his name is revealed to be Endeavour. Two-thirds of the way through the television episode based on the book, he gives the cryptic clue \"My whole life's effort has revolved around Eve, nine letters\". In the series, it is noted that Morse's reluctance to use his Christian name led to his receiving the nickname \"Pagan\" (Deceived by Flight) while at Stamford School (which Colin Dexter, the author of the Morse novels, attended). In the novels, Morse's first name came from the vessel HMS \"Endeavour\"; his mother was a member of the Religious Society of Friends (Quakers) who have a tradition of \"virtue names\", and his father admired Captain James Cook.\nDexter was a fan of cryptic crossword and named Morse after champion setter Jeremy Morse, one of Dexter's arch-rivals in writing crossword clues. Dexter used to walk along the bank of the River Thames at Oxford, opposite the boathouse belonging to 22nd Oxford Sea Scout Group; the building is named \"T.S. Endeavour\".\nEducation.\nAlthough details of Morse's education are kept vague, it is hinted that he won a scholarship to study at St John's College, Oxford. He lost the scholarship as the result of poor academic performance stemming from a failed love affair, which is mentioned in the second episode of the third series, \"The Last Enemy\", and recounted in detail in the novel \"The Riddle of the Third Mile\", Chapter 7. Further details are revealed piece-by-piece in the prequel series. He often reflects on such renowned scholars as A. E. Housman who, like himself, failed to get an academic degree from Oxford.\nCareer.\nAfter university, he entered the army on National Service. This included serving in West Germany with the Royal Corps of Signals as a cipher clerk. Upon leaving, he joined the police at Carshall-Newtown, before being posted to Oxford with the Oxford City Police. He was awarded the George Medal in the last episode of \"Endeavour\" Series 4, which he refrains from wearing on his uniform. He is assigned to a uniformed position in Series 6 despite having his opinions and observations disregarded by CID.\nHabits and personality.\nMorse is the embodiment of middle-class Englishness, with a set of prejudices and assumptions to match, although his background, being the son of a taxi driver, might be considered working class. He claims to have a private income from his father driving for the Aga Khan, but this may be a joke. Due to his manners and bearing, he is sometimes considered gentleman detective, the staple of British detective fiction, in contrast to the working-class lifestyle of his assistant Lewis. In the novels, Lewis is Welsh, but in the TV series this is altered to a Tyneside (Geordie) background, appropriately for the actor Kevin Whately. Morse is in his forties at the start of the books (\"Service of all the Dead\", Chapter Six: \"\u2026 a bachelor still, forty-seven years old \u2026\"), and Lewis slightly younger (e.g. \"The Secret of Annexe 3\", Chapter Twenty-Six: \"a slightly younger man \u2013 another policeman, and one also in plain clothes\"). John Thaw was 45 at the beginning of shooting the TV series and Kevin Whately was 36.\nMorse's relationships with authority, the establishment, bastions of power and the status quo, are markedly ambiguous, as are some of his relations with women. He is frequently portrayed as patronising female characters, and once stereotyped the female sex as not naturally prone to crime, being caring and non-violent, but also often empathises with women. He is not shy to show his liking for attractive women and often dates those involved in cases. Indeed, a woman he falls in love with sometimes turns out to be the culprit.\nMorse is highly intelligent. He is a crossword addict and dislikes grammatical and spelling errors; in every personal or private document that he receives, he manages to point out at least one mistake. He claims that his approach to crime-solving is deductive, and one of his key tenets is that \"there is a 50 per cent chance that the person who finds the body is the murderer\". Morse uses immense intuition and his fantastic memory to apprehend the perpetrator.\nAmong Morse's conservative tastes are that he likes to drink real ale and whisky, (which he calls \u201cbrain food\u201d) and likes to drink while thinking about cases despite doctors\u2019 advice on cutting down. In the early novels, Morse drives a Lancia. In the television and radio productions (and reprints of the novels), this is altered to a Jaguar Mark 2. His favourite music is opera, which is echoed in the soundtracks to the television series. The original music is by Barrington Pheloung, which has been made into Morse Code and spells out Inspector Morse.\nHis dying words, said to Jim Strange, (who liked calling Morse, \u201cmatey\u201d due to their long working relationship together), are \"Thank Lewis for me.\"\nMorse is portrayed as being an atheist. However, in some scenes, he does entertain the possibility of God and/or quote the Bible from memory, agreeing with the phrases, as he does with lines from various literary books/texts.\nNovels.\nThe novels in the series are:\nInspector Morse also appears in several stories in Dexter's short story collection, \"Morse's Greatest Mystery and Other Stories\" (1993, expanded edition 1994).\nIn other media.\nTelevision.\n\"Inspector Morse\" (1987\u20132000).\nThe Inspector Morse novels were made into a TV series (also called \"Inspector Morse\") for the British commercial TV network ITV. The series was made by Zenith Productions for Central (a company later acquired by Carlton) and comprised 33\u00a0two-hour episodes (100\u00a0minutes excluding commercials)\u201420\u00a0more episodes than there are novels\u2014produced between 6 January 1987 and 15 November 2000. The last episode was adapted from the final novel \"The Remorseful Day\", in which Morse dies from a heart attack. Morse was played by John Thaw and Lewis by Kevin Whateley.\n\"Lewis\" (2006\u20132015).\nA spin-off series, similarly comprising 33\u00a0two-hour episodes and based on the television incarnation of Lewis, was titled \"Lewis\"; it first aired on 29 January 2006 and last showed on 10 November 2015. The spin-off consisted the following cast members: Kevin Whately as DI Robbie Lewis, Laurence Fox as DS James Hathaway, Clare Holman as Dr Laura Hobson and Rebecca Front as CS Jean Innocent.\n\"Endeavour\" (2012\u20132023).\nIn August 2011, ITV announced plans to film a prequel drama called \"Endeavour\", with author Colin Dexter's participation. English actor Shaun Evans was cast as a young Morse in his early career. The pilot episode was broadcast on 2 January 2012 on ITV. The prequel was made by Mammoth Screen. Four new episodes were televised from 14 April 2013, showing Morse's early cases working for DI Fred Thursday (Roger Allam) and with Jim Strange (Sean Rigby), initially as PC Jim Strange, later DS Jim Strange, and pathologist Max De Bryn (James Bradshaw), plus Chief Superintendent Reginald Bright (Anton Lesser), DS Peter Jakes (Jack Laskey), WPC Shirley Trewlove (Dakota Blue Richards), DC George Fancy (Lewis Peek), DI Ronnie Box (Simon Harrison) and DS Alan Jago (Richard Riddell). Alongside the police department, the prequel also consisted of Fred Thursday\u2019s family members: Win Thursday, (Caroline O\u2019Neill), Sam Thursday (Jack Bannon), Joan Thursday (Sara Vickers) and the newspaper editor Dorothea Frazil (Abigail Thaw). A second series of four episodes followed, screening between 30 March 2014 and 20 April 2014. On 3 January 2016, the third series aired, also containing four episodes. A fourth series was aired, once again with four episodes, on 8 January 2017. Filming of a fifth series of six episodes began in early 2017 with the first episode of the fifth series aired on 4 February 2018. On 10 February 2019 the sixth series aired, which comprises four 1-hour-30-minute episodes. A seventh series of three episodes was filmed in late 2019, aired on 9 February 2020 and in August 2019 ITV announced that the series has been recommissioned for an eighth series, screened on 12 September 2021, also containing three episodes. Morse was voted number two on the top 25 list in ITV's Britain's Favourite Detective first broadcast on 30 August 2020.\nOn 23 May 2022, a day after filming began for the ninth series, ITV announced that \"Endeavour\" would end production after a decade on air at the conclusion of the ninth series, bringing the total number of \"Endeavour\" episodes to 36. The ninth and final series comprised the final three episodes, which aired from 26 February 2023 to 12 March 2023.\nRadio.\nAn adaptation by Melville Jones of \"Last Bus to Woodstock\" featured in BBC Radio 4's \"Saturday Night Theatre\" series in June 1985, with Andrew Burt as Morse and Christopher Douglas as Lewis.\nIn the 1990s, an occasional BBC Radio 4 series (for \"The Saturday Play\") was made starring the voices of John Shrapnel as Morse and Robert Glenister as Lewis. The series was written by Guy Meredith and directed by Ned Chaillet. Episodes included: \"The Wench is Dead\" (23 March 1992); \"Last Seen Wearing\" (28 May 1994); and \"The Silent World of Nicholas Quinn\" (10 February 1996).\nIn 2017, Alma Cullen dramatised her 2010 Morse stage play \"House of Ghosts\" as a Radio 4 production starring Neil Pearson as Morse, and Lee Ingleby as Lewis. A year later, Cullen penned an original drama entitled \"Morse: In The Shallows\", with Pearson and Ingleby reprising their roles.\nTheatre.\nAn Inspector Morse stage play appeared in 2010, written by Alma Cullen (writer of four Morse screenplays for ITV). The part of Morse was played by Colin Baker. The play, entitled \"Morse\u2014House of Ghosts\", saw DCI Morse looking to his past, when an old acquaintance becomes the lead suspect in a murder case that involves the on-stage death of a young actress. The play toured the UK from August to December 2010. Subsequent stagings include Weymouth, Dorset in 2015 with Nigel Fairs, and an upcoming touring production starring Tom Chambers.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "14763", "revid": "80913", "url": "https://en.wikipedia.org/wiki?curid=14763", "title": "History of the Isle of Man", "text": " \nThe Isle of Man had become physically separated from Great Britain and Ireland by 6500 BC. It appears that colonisation took place by sea sometime during the Mesolithic era (about 6500 BC). The island has been visited by various raiders and trading peoples over the years. After being settled by people from Ireland in the first millennium AD, the Isle of Man was converted to Christianity and then suffered raids by Vikings from Norway. After becoming subject to Norwegian suzerainty as part of the Kingdom of Mann and the Isles, the Isle of Man later became a possession of the Scottish and then the English crowns.\nSince 1866, the Isle of Man has been a Crown Dependency and democratic self-government.\nPrehistory.\nThe Isle of Man effectively became an island around 8,500 years ago at around the time when rising sea levels caused by the melting glaciers cut Mesolithic Britain off from continental Europe for the last time. There had earlier been a land bridge between the Isle of Man and Cumbria, but the location and opening of the land bridge remain poorly understood.\nThe earliest traces of people on the Isle of Man date back to the Mesolithic Period (Middle Stone Age, 8000 BC - 4000 BC). The first residents lived in small natural shelters, hunting, gathering and fishing for their food. They used small tools made of flint or bone, examples of which have been found near the coast. Examples of these artifacts are kept at the Manx National Heritage museum.\nThe Neolithic Period marked the coming of farming, improved stone tools and pottery. During this period megalithic monuments began to appear around the island. Examples are found at Cashtal yn Ard near Maughold, King Orry's Grave in Laxey, Meayll Circle near Cregneash, and Ballaharra Stones in St John's. The builders of the megaliths were not the only culture during this time; there are also remains of the local Ronaldsway culture (lasting from the late Neolithic into the Bronze Age).\nIn the Iron Age, large hill forts appeared on hill summits and smaller promontory forts along the coastal cliffs, while large timber-framed roundhouses were built.\nIt is not known if the Romans ever made a landing on the island and if they did, little evidence has been discovered. There is evidence for contact with Roman Britain as an amphora was discovered at the settlement on the South Barrule; it is hypothesised this may have been trade goods or plunder.\nMiddle Ages.\nEarly Middle Ages.\nIn the late Roman period, there was strong Irish (Gaelic) influence throughout the Irish Sea, as well as Irish raiding and settlement on the west coast of Britain. The Romans referred to these Irish Gaels as \"Scoti\". The Roman historian Orosius wrote in the 5th century that the Isle of Man () was inhabited by the Irish. The oldest known language on the Isle of Man was Archaic Irish, which is found on stone inscriptions in the Ogham alphabet, dating to around the 5th century. Ogham stones found in the south of Mann are monolingual Irish (like Ballaqueeney Ogham Stone), while those in the north are bilingual Irish and Latin (like Knock y Doonee Ogham Stone). The Ballaqueeney stone seems to commemorate one of the Conailli, an Irish tribe who lived on the coast of what is now County Louth in Ireland.\nThe \"Annals of Ulster\" record an Irish expedition to the Isle of Man by the Ulaid in AD 577, followed by their withdrawal the following year. The annals say that the Ulaid king B\u00e1et\u00e1n mac Cairill (572\u2013581) had \"cleared\" the Isle of Man, which could mean that he expelled the Conailli from the island.\nIt is generally assumed that Irish invasion or immigration formed the basis of the Manx language.\nAccording to Manx tradition, Saint Patrick was responsible for converting the island to Christianity. He is said to have sent Germanus and the Irish missionary Maughold (Macc Cuill) to the island in the 5th century. Muirch\u00fa's 7th century \"Life of Patrick\" says that when Macc Cuill landed on the island, there were already Christians. Their spiritual leaders were Conindrus and Rumilus, which seem to be Romano-British names. 'Long cist' burials, which are known from almost 100 sites on the island, seem to have arrived with Christianity from Roman Britain. So far, the earliest have been radiocarbon dated to the 4th\u20135th century; these are at Balladoole and Rushen Abbey. Most of these burials are associated with small early chapels called keeills (from Irish \"cill\"); there are more than 200 scattered across the island.\nFrom the 7th century, there is evidence of Celtic Britons on the Isle of Man, and possible Brittonic control over the island. A stone cross found on the northeast coast, dated to the 8th or 9th century, is inscribed \"Crux Guriat\" (Guriat's cross). This is a Brittonic name. It probably refers to Gwriad ab Elidyr, father of Merfyn Frych; the latter ruled the Welsh kingdom of Gwynedd from 825 to 844 and founded its second ruling dynasty, the Merfynion. Early medieval Welsh genealogies suggest that Merfyn came from the Isle of Man. In the 8th century, Anglo-Saxon historian Bede wrote that Britons dwelt on the island.\nEven if the supposed conquest of Mann by Edwin of Northumbria, in 616, did take place, it could not have led to any permanent results, for when the English were driven from the coasts of Cumberland and Lancashire soon afterwards, they could not well have retained their hold on the island to the west of these coasts. One can speculate, however, that when Ecgfri\u00f0's Northumbrians laid Ireland waste from Dublin to Drogheda in 684, they temporarily occupied Mann.\nViking Age and Norse kingdom.\nThe period of Scandinavian domination is divided into two main epochs \u2013 before and after the conquest of Mann by Godred Crovan in 1079. Warfare and unsettled rule characterise the earlier epoch, the later saw comparatively more peace.\nBetween about AD 800 and 815 the Vikings came to Mann chiefly for plunder. Between about 850 and 990, when they settled, the island fell under the rule of the Scandinavian Kings of Dublin and between 990 and 1079, it became subject to the powerful Earls of Orkney.\nThere was a mint producing coins on Mann between c. 1025 and c. 1065. These Manx coins were minted from an imported type 2 Hiberno-Norse penny die from Dublin. Hiberno-Norse coins were first minted under Sihtric, King of Dublin. This illustrates that Mann may have been under the thumb of Dublin at this time.\nLittle is known about the conqueror, Godred Crovan. According to the \"Chronicon Manniae\" he subdued Dublin, and a great part of Leinster, and held the Scots in such subjection that supposedly no one who set out to build a vessel dared to insert more than three bolts. The memory of such a ruler would be likely to survive in tradition, and it seems probable therefore that he is the person commemorated in Manx legend under the name of King Gorse or Orry. He created the Kingdom of Mann and the Isles in around 1079 including the south-western islands of Scotland until 1164, when two separate kingdoms were formed from it. In 1154, later known as the Diocese of Sodor and Man, was formed by the Catholic Church.\nThe islands under his rule were called the (South isles, in contrast to the North isles\", i.e. Orkney and Shetland), consisting of the Hebrides, all the smaller western islands of Scotland, and Mann. At a later date his successors took the title of (King of Mann and of the Isles). The kingdom's capital was on St Patrick's Isle, where Peel Castle was built on the site of a Celtic monastery.\nOlaf, Godred's son, exercised considerable power and according to the Chronicle, maintained such close alliance with the kings of Ireland and Scotland that no one ventured to disturb the Isles during his time (1113\u20131152). In 1156 his son Godred (reigned 1153\u20131158), who for a short period also ruled over Dublin, lost the smaller islands off the coast of Argyll as a result of a quarrel with Somerled (the ruler of Argyll). An independent sovereignty thus appeared between the two divisions of his kingdom.\nIn the 1130s the Catholic Church sent a small mission to establish the first bishopric on the Isle of Man, and appointed Wimund as the first bishop. He soon afterwards embarked with a band of followers on a career of murder and looting throughout Scotland and the surrounding islands.\nDuring the whole of the Scandinavian period, the Isles remained nominally under the suzerainty of the Kings of Norway but the Norwegians only occasionally asserted it with any vigour. The first such king to assert control over the region was likely Magnus Barelegs, at the turn of the 12th century. It was not until Hakon Hakonarson's 1263 expedition that another king returned to the Isles.\nDecline of Norse rule.\nFrom the middle of the 12th century until 1217 the suzerainty had remained of a very shadowy character; Norway had become a prey to civil dissensions. But after that date it became a reality, and Norway consequently came into collision with the growing power of the kingdom of Scotland.\nEarly in the 13th century, when Ragnald (reigned 1187\u20131229) paid homage to King John of England (reigned 1199\u20131216), we hear for the first time of English intervention in the affairs of Mann. But a period of Scots domination would precede the establishment of full English control.\nFinally, in 1261, Alexander III of Scotland sent envoys to Norway to negotiate for the cession of the isles, but their efforts led to no result. He therefore initiated a war, which ended in the indecisive Battle of Largs against the Norwegian fleet in 1263. However, the Norwegian king Haakon Haakonsson died the following winter, and this allowed King Alexander to bring the war to a successful conclusion. Magnus Olafsson, King of Mann and the Isles (reigned 1252\u20131265), who had campaigned on the Norwegian side, had to surrender all the islands over which he had ruled, except Mann, for which he did homage. Two years later Magnus died and in 1266 King Magnus VI of Norway ceded the islands, including Mann, to Scotland in the Treaty of Perth in consideration of the sum of 4,000 marks (known as in Scotland) and an annuity of 100 marks. But Scotland's rule over Mann did not become firmly established until 1275, when the Manx suffered defeat in the decisive Battle of Ronaldsway, near Castletown.\nEnglish dominance.\nIn 1290 King Edward I of England sent Walter de Huntercombe to seize possession of Mann, and it remained in English hands until 1313, when Robert Bruce took it after besieging Castle Rushen for five weeks. In about 1333 King Edward III of England granted Mann to William de Montacute, 3rd Baron Montacute (later the 1st Earl of Salisbury), as his absolute possession, without reserving any service to be rendered to him.\nThen, in 1346, the Battle of Neville's Cross decided the long struggle between England and Scotland in England's favour. King David II of Scotland, Robert Bruce's last male heir, had been captured in the Battle of Neville's Cross and ransomed; however, when Scotland was unable to raise one of the ransom instalments, David made a secret agreement with King Edward III of England to cancel it, in return for transferring the Scottish kingdom to an English prince.\nFollowing the secret agreement, there followed a confused period when Mann sometimes experienced English rule and sometimes Scottish. In 1388 the island was \"ravaged\" by Sir William Douglas of Nithsdale on his way home from the destruction of the town of Carlingford.\nIn 1392 William de Montacute's son sold the island, including sovereignty, to Sir William le Scrope. In 1399 Henry Bolinbroke brought about the beheading of Le Scrope, who had taken the side of Richard II when Bolinbroke usurped the throne and appointed himself Henry IV. The island then came into the de facto possession of Henry, who granted it to Henry Percy, 1st Earl of Northumberland; but following the latter's later attainder, Henry IV, in 1405, made a lifetime grant of it, with the patronage of the bishopric, to Sir John Stanley. In 1406 this grant was extended \u2013 on a feudatory basis under the English Crown \u2013 to Sir John's heirs and assigns, the feudal fee being the service of rendering homage and two falcons to all future Kings of England on their coronations.\nEarly Modern period.\nWith the accession of the Stanleys to the throne there begins a more settled epoch in Manx history. Though the island's new rulers rarely visited its shores, they placed it under governors, who, in the main, seem to have treated it with the justice of the time. Of the thirteen members of the family who ruled in Mann, the second Sir John Stanley (1414\u20131432), James, the 7th Earl (1627\u20131651), and the 10th Earl of the same name (1702\u20131736) had the most important influence on it. They first curbed the power of the spiritual barons, introduced trial by jury, which superseded trial by battle, and ordered the laws to be written. The second, known as the Great Stanley, and his wife, Charlotte de la Tremoille (or Tremouille), are probably the most striking figures in Manx history.\nWars of the Three Kingdoms and Interregnum; 1642 to 1660.\nIn June 1643, shortly after the beginning of the Wars of the Three Kingdoms, James Stanley, 7th Earl of Derby, returned to Mann to find the island on the brink of rebellion. Among the causes were complaints at the level of tithes payable to the Church of England, and Derby's attempts to replace the Manx \u2018tenure of straw\u2019 by which many of his tenants held their lands, a customary tenure akin to freehold, with commercial leases. He managed to restore the situation through a series of meetings, but made minimal concessions.\nSix months after Charles I was executed on 30 January 1649, Derby received a summons from General Ireton to surrender the island, but declined to do so. In August 1651, he and 300 Manxmen landed in Lancashire to take part in the Third English Civil War; defeated at Wigan Lane on 25 August 1651, Derby escaped with only 30 troops to join Charles II. Captured after the Battle of Worcester in September, he was imprisoned in Chester Castle, tried by court-martial and executed at Bolton on 15 October.\nSoon after Stanley's death, the Manx Militia, under the command of William Christian (known by his Manx name of Illiam Dhone), rose against the Countess and captured all the insular forts except Rushen and Peel. They were then joined by a Parliamentarian force sent from the mainland, led by Colonels Thomas Birch and Robert Duckenfield, to whom the Countess surrendered after a brief resistance.\nOliver Cromwell had appointed Thomas Fairfax \"Lord of Mann and the Isles\" in September 1651, so that Mann continued under a monarchical government and remained in the same relation to England as before.\n1660 Restoration.\nThe restoration of Stanley government in 1660 therefore caused as little friction and alteration as its temporary cessation had. One of the first acts of the new Lord, Charles Stanley, 8th Earl of Derby, was to order Christian to be tried. He was found guilty and executed. Of the other persons implicated in the rebellion only three were excepted from the general amnesty. But by Order in Council, Charles II pardoned them, and the judges responsible for the sentence on Christian were punished.\nCharles Stanley's next act was to dispute the permanency of the tenants' holdings, which they had not at first regarded as being affected by the acceptance of leases, a proceeding which led to an almost open rebellion against his authority and to the neglect of agriculture, in lieu of which the people devoted themselves to the fisheries and to contraband trade.\nCharles Stanley, who died in 1672, was succeeded first by his son William Richard George Stanley, 9th Earl of Derby until his death in 1702.\nThe agrarian question subsided only in 1704, when James Stanley, 10th Earl of Derby, William's brother and successor, largely through the influence of Bishop Wilson, entered into a compact with his tenants, which became embodied in an Act, called the Act of Settlement. Their compact secured the tenants in the possession of their estates in perpetuity subject only to a fixed rent, and a small fine on succession or alienation. From the great importance of this act to the Manx people it has been called their \"Magna Carta\". As time went on, and the value of the estates increased, the rent payable to the Lord became so small in proportion as to be almost nominal, being extinguished by purchase in 1916.\nRevestment.\nJames died in 1736, and the suzerainty of the isle passed to James Murray, 2nd Duke of Atholl, his first cousin and heir general. In 1764 he was succeeded by his only surviving child Charlotte, Baroness Strange, and her husband, John Murray, who (in right of his wife) became Lord of Mann. In about 1720 the contraband trade had greatly increased. In 1726 Parliament had checked it somewhat for a time, but during the last ten years of the Atholl regime (1756\u20131765) it assumed such proportions that, in the interests of the Imperial revenue, it became necessary to suppress it. With a view to so doing, Parliament passed the Isle of Man Purchase Act 1765 (commonly called the \"Revestment Act\" by the Manx), under which it purchased the rights of the Atholls as Lords of Mann, including the customs revenues of the island, for the sum of \u00a370,000 sterling, and granted an annuity to the Duke and Duchess. The Atholls still retained their manorial rights, the patronage of the bishopric, and certain other perquisites, until they sold them for the sum of \u00a3417,144 in 1828.\nUp to the time of the revestment\u200c, Tynwald had passed laws concerning the government of the island in all respects and had control over its finances, subject to the approval of the Lord of Mann. After the revestment, or rather after the passage of the Smuggling Act 1765 (commonly called the\" Mischief Act\" by the Manx), the Parliament at Westminster legislated with respect to customs, harbours and merchant shipping, and, in measures of a general character, it occasionally inserted clauses permitting the enforcement in the island of penalties in contravention of the Acts of which they formed part. It also assumed the control of the insular customs duties. Such changes, rather than the transference of the full suzerainty to the King of Great Britain and Ireland, modified the (unwritten) constitution of the Isle of Man. Its ancient laws and tenures remained untouched, but in many ways the revestment affected it adversely. The hereditary Lords of Mann had seldom, if ever, functioned as model rulers, but most of them had taken some personal share in its government, and had interested themselves in the well-being of the inhabitants. But now the whole direction of its affairs became the work of officials who regarded the island as a pestilent nest of smugglers, from which it seemed their duty to extract as much revenue as possible.\nThere was some alleviation of this state of things between 1793 and 1826, when John Murray, 4th Duke of Atholl served as governor, since, though he quarrelled with the House of Keys and unduly cared for his own pecuniary interests, he did occasionally exert himself to promote the welfare of the island. After his departure the English officials resumed their sway, but they showed more consideration than before. Moreover, since smuggling, which the Isle of Man Purchase Act had only checked \u2013 not suppressed \u2013 had by that time almost disappeared, and since the Manx revenue had started to produce a large and increasing surplus, the authorities looked more favourably on the Isle of Man, and, thanks to this fact and to the representations of the Manx people to British ministers in 1837, 1844 and 1853, it obtained a somewhat less stringent customs tariff and an occasional dole towards erecting its much neglected public works.\nModern period.\nSince 1866, when the Isle of Man obtained a nominal measure of Home Rule, the Manx people have made remarkable progress, and currently form a prosperous community, with a thriving offshore financial centre, a tourist industry (albeit smaller than in the past) and a variety of other industries.\nThe Isle of Man was a base for alien civilian internment camps in both the First World War (1914\u201318) and the Second World War (1939\u201345). During the First World War there were two camps: one a requisitioned holiday camp in Douglas and the other the purpose-built Knockaloe camp near Peel in the parish of Patrick. During the Second World War there were a number of smaller camps in Douglas, Peel, Port Erin and Ramsey. The (now disbanded) Manx Regiment was raised in 1938 and saw action during the Second World War.\nOn 2 August 1973, a flash fire killed between 50 and 53 people at the Summerland amusement centre in Douglas.\nGreater autonomy.\nThe early 20th century saw a revival of music and dance, and a limited revival of the Manx language \u2013 although the last \"native\" speaker of Manx Gaelic died in the 1970s. In July 1947 the Taoiseach of the Republic of Ireland, \u00c9amon de Valera, visited, and was so dissatisfied with the lack of support for Manx that he immediately had two recording vans sent over.\nDuring the 20th century the Manx tourist economy declined, as the English and Irish started flying to Spain for package holidays. The Manx Government responded to this by successfully promoting the island, with its low tax rates, as an offshore financial centre, although Man has avoided a place on a 2009 UK blacklist of tax havens. The financial centre has had its detractors who have pointed to the potential for money laundering.\nIn 1949 an Executive Council, chaired by the Lieutenant-Governor and including members of Tynwald, was established. This marked the start of a transfer of executive power from the unelected Lieutenant-Governor to democratically elected Manx politicians. Finance and the police passed to Manx control between 1958 and 1976. In 1980 a chairman elected by Tynwald replaced the Lieutenant-Governor as Chairman of the Executive Council. Following legislation in 1984, the Executive Council was reconstituted in 1985 to include the chairmen of the eight principal Boards; in 1986 they were given the title of Minister and the chairman was re-titled \"Chief Minister\". In 1986 Sir Miles Walker CBE became the first Chief Minister of the Isle of Man. In 1990 the Executive Council was renamed the \"Council of Ministers\".\nThe 1960s also saw a rise in Manx nationalism, spawning the parties Mec Vannin and the Manx National Party, as well as the now defunct (literally \"Underground\"), which mounted a direct-action campaign of spray-painting and attempted house-burning.\nOn 5 July 1973 control of the postal service passed from the UK General Post Office to the new Isle of Man Post, which began to issue its own postage stamps.\nThe 1990s and early 21st century have seen a greater recognition of indigenous Manx culture, including the opening of the first Manx-language primary school.\nSince 1983 the Isle of Man government has designated more than 250 historic structures as Registered Buildings of the Isle of Man.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "14764", "revid": "15881234", "url": "https://en.wikipedia.org/wiki?curid=14764", "title": "Geography of the Isle of Man", "text": " \nThe Isle of Man is an island in the Irish Sea, between Great Britain and Ireland in Northern Europe, with a population of almost 85,000. It is a British Crown dependency. It has a small islet, the Calf of Man, to its south. It is located at .\nDimensions.\nArea:\n\"Land:\"\n\"Water:\"\n (100 ha)\n\"Total:\"\nThis makes it:\nCoast and territorial sea.\nThe Isle of Man has a coastline of , and a territorial sea extending to a maximum of 12 nm from the coast, or the midpoint between it and other countries. The total territorial sea area is about 4000\u00a0km2 or 1500 sq miles, which is about 87% of the total area of the jurisdiction of the Isle of Man. The Isle of Man only holds exclusive fishing rights in the first 3 nm. The territorial sea is managed by the Isle of Man Government Department of Infrastructure.\nThe Raad ny Foillan long-distance footpath runs around the Manx coast.\nClimate.\nThe Isle of Man enjoys a temperate climate, with cool summers and mild winters. Average rainfall is high compared to the majority of the British Isles, due to its location to the western side of Great Britain and sufficient distance from Ireland for moisture to be accumulated by the prevailing south-westerly winds. Average rainfall is highest at Snaefell, where it is around a year. At lower levels, it can fall to around a year.\nTemperatures remain fairly cool, with the recorded maximum being at Ronaldsway.\nTerrain.\nThe island's terrain is varied. There are two mountainous areas divided by a central valley which runs between Douglas and Peel. The highest point in the Isle of Man, Snaefell, is in the northern area and reaches above sea level. The northern end of the island is a flat plain, consisting of glacial tills and marine sediments. To the south, the island is more hilly, with distinct valleys. There is no land below sea level.\nNatural hazards and environmental issues.\nThere are few severe natural hazards, the most common being high winds, rough seas and dense fog. In recent years there has been a marked increase in the frequency of high winds, heavy rains, summer droughts and flooding both from heavy rain and from high seas. Snow fall has decreased significantly over the past century while temperatures are increasing year-round with rainfall decreasing.\nAir pollution, marine pollution and waste disposal are issues in the Isle of Man.\nProtected or recognised sites for nature conservation.\nIn order of importance, international first, non-statutory last. Note that ASSIs and MNRs have equal levels of statutory protection under the Wildlife Act 1990.\nRamsar sites.\nDesignated:\nCandidate:\nImportant Marine Mammal Areas.\nIn 2024, the IUCN Marine Mammal Protected Areas Task Force recognised that 17,610km2 of the central Irish Sea as being of global importance for marine mammals, known as the Central Irish Sea Important Marine Mammal Area. This includes about half of Manx marine territorial waters.\nImportant Bird Areas.\nThe UK RSPB and UK JNCC have designated five areas of the Isle of Man which are of global significance to birdlife.\nAreas of Special Scientific Importance.\nThere are 25 ASSIs on the Isle of Man as of November 2022. One additional ASSI has been designated but later rescinded (Ramsey Estuary). Dates below refer to year of formal confirmation.\nMarine Nature Reserves.\nThe Island's first marine nature reserve was designated in Ramsey Bay in October 2011. In 2018, nine further Marine Nature Reserves were given statutory protection. The ten Marine Nature Reserves around the Isle of Man cover over 10% of the country's territorial waters, in accordance with international requirements.\nEelgrass Conservation Zones (Statutory \u2013 within MNRs).\nEelgrass \"Zostera marina\" is a legally protected species on the Isle of Man. Between 2011 and 2018, four strictly protected Eelgrass Conservation Zones have been designated to protect this important species.\nEelgrass Voluntary Zones (Non-statutory \u2013 both in and outside MNRs).\nIn 2023, three existing statutory Eelgrass Conservation Zones were expanded on a voluntary basis (noting that, regardless of this 'voluntary' status, the species is still legally fully protected from reckless disturbance), with a further new site identified.\nBird Sanctuaries.\nBird sanctuaries were formerly designated by that name under the Wild Birds Protection Act 1932. This designation was superseded by \"Areas of Special Protection for Birds\" under the Wildlife Act 1990; however, the following formerly designated Bird Sanctuaries remain protected:\nRegistered Heathland.\nProtected from unlicensed burning or destruction by the Heath Burning Act 2003.\nNature Reserves and Wildlife Sites.\nManx Wildlife Trust Reserves.\nManx Wildlife Trust (MWT) was founded on 6 March 1973 and is the Isle of Man\u2019s leading nature conservation charity.\nAs of May 2025, MWT manages 32 nature reserves, including the Calf of Man which is managed with and on behalf of Manx National Trust. These reserves total , or around 2% of the Isle of Man and include:\nDesignated Wildlife Sites.\nThe Isle of Man has (as of March 2023) 92 non-statutory 'Wildlife Sites' covering in addition to the 10.4\u00a0km of coastline. As of 30 January 2009 this total was 45 wildlife sites, covering about 195 ha of land and an additional of inter-tidal coast. Wildlife Sites are not recognised in law, but are recognised in terms of Government policy, including planning and zonation (by the Isle of Man Strategic Plan) and agricultural policy (under Cross Compliance regulations). Wildlife Sites are shown on the MANNGIS Island Environment map.\nManx National Trust Landholdings.\nThe following properties are under the protection of Manx National Heritage. The Manx National Trust owns properties in 15 of the 17 Manx parishes (all except Jurby and Michael).\nGeology.\nThe majority of the island is formed from highly faulted and folded sedimentary rocks of the Ordovician period. There is a belt of younger Silurian rocks along the west coast between Niarbyl and Peel, and a small area of Devonian sandstones around Peel. A band of Carboniferous period rocks underlies part of the northern plain, but is nowhere seen at the surface; however similar age rocks do outcrop in the south between Castletown, Silverdale and Port St Mary. Permo- Triassic age rocks are known to lie beneath the Point of Ayre but, as with the rest of the northern plain, these rocks are concealed by substantial thicknesses of superficial deposits.\nThe island has significant deposits of copper, lead and silver, zinc, iron, and plumbago (a mix of graphite and clay). There are also quarries of black marble, limestone flags, clay schist, and granite. These are all modern, and there was no noticeable exploitation of metals or minerals before the modern era.\nDemographics.\nThe island has a census-estimated population of 84,497 according to the most recent 2011 census: up from 79,805 in 2006 and 76,315 in 2001.\nThe island's largest town and administrative centre is Douglas, whose population is 23,000 \u2013 over a quarter of the population of the island. Neighbouring Onchan, Ramsey in the north, Peel in the west and the three southern ports of Castletown, Port Erin and Port St Mary are the island's other main settlements. Almost all its population lives on or very near the coast.\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "14765", "revid": "28991092", "url": "https://en.wikipedia.org/wiki?curid=14765", "title": "Demographics of the Isle of Man", "text": " \nDemographic features of the population of the Isle of Man include population density, ethnicity, level of education, health, economic status, and religious affiliations.\nVital statistics.\nStructure of the population.\n&lt;templatestyles src=\"Template:Hidden begin/styles.css\"/&gt;Population by Sex and Age Group (Census 24.IV.2016): \n&lt;templatestyles src=\"Template:Hidden begin/styles.css\"/&gt;Population by Sex and Age Group (Census 27.I.2021): \nLanguages.\nEnglish is spoken by the vast majority of the people. Manx, the language native to the isle, was once considered extinct as the last native speaker died in 1974. However, in early 21st century, the Isle of Man has seen a revival of the language: in 1991, about 0.9% of the population spoke Manx, and the same figure has increased to 2.4% by 2021. \n&lt;templatestyles src=\"Col-begin/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "14766", "revid": "5795946", "url": "https://en.wikipedia.org/wiki?curid=14766", "title": "Politics of the Isle of Man", "text": " \nThe government of the Isle of Man is a parliamentary representative democracy. The Monarch of the United Kingdom is also the head of state of the Isle of Man, and generally referred to as \"The King, Lord of Mann\". His representative on the island is the Lieutenant Governor of the Isle of Man, but his role is mostly ceremonial, though he does have the power to grant Royal Assent (the withholding of which is the same as a veto). Legislation of the Isle of Man defines \"the Crown in right of the Isle of Man\" as separate from the \"Crown in right of the United Kingdom\".\nThe Isle of Man is not part of the United Kingdom, and the island has no representation in the UK parliament. As a Crown Dependency, it is not subordinate to the government of the United Kingdom. The UK government, however, is responsible for defence and island's external affairs and could intervene in the domestic affairs of the island under its residual responsibilities to guarantee \"good government\" in all Crown dependencies. Manx people are British citizens under UK law \u2014 there is no separate Manx citizenship.\nThe legislative power of the government is vested in a bicameral (sometimes called tricameral) parliament called Tynwald (said to be the world's oldest \"continuously existing\" parliament), which consists of the directly-elected House of Keys and the indirectly chosen Legislative Council. After every House of Keys general election, the members of Tynwald elect from amongst themselves the Chief Minister of the Isle of Man, who serves as the head of government for five years (until the next general election). Executive power is vested in the Lieutenant Governor (as Governor-in-Council), the Chief Minister, and the Isle of Man's Council of Ministers. The judiciary is independent of the executive and the legislature.\nDouglas, the largest town on the Isle of Man (now a city), is its capital and seat of government, where the Government offices and the parliament chambers (Tynwald) are located.\nExecutive branch.\nThe Head of State is the Lord of Mann, which is a hereditary position held by the British monarch (currently King Charles III). The Lieutenant Governor is appointed by the King, on the advice of the UK's Secretary of State for Justice, for a five-year term and nominally exercises executive power on behalf of the King. The Chief Minister is elected by the House of Keys (formerly by Tynwald) following every House of Keys general election and serves for five years until the next general election.\nWhen acting as Lord of Mann, the King acts on the advice of the Secretary of State for Justice and Lord Chancellor of the United Kingdom having prime responsibility as Privy Counsellor for Manx affairs.\nThe executive branch under the Chief Minister is referred to as \"the Government\" or the \"Civil Service\", and consists of the Council of Ministers, nine Departments, ten Statutory Boards and three Offices. Each Department is run by a Minister who reports directly to the Council of Ministers. This does not include any military positions, as defence is the responsibility of the United Kingdom.\nLegislative branch.\nThe Manx legislature is Tynwald, which consists of two chambers or \"branches\". The House of Keys has 24 members, elected for a five-year term in two-seat constituencies by the whole island. The minimum voting age is 16. The Legislative Council has eleven members: the President of Tynwald, the Bishop of Sodor and Man, the Attorney General (non-voting) and eight other members elected by the House of Keys for a five-year term, with four retiring at a time. (In the past they have often already been Members of the House of Keys, but must leave the Keys if elected to the Council.) There are also joint sittings of the Tynwald Court (the two branches together).\nPolitical parties and elections.\nIn the 2021 Manx general election, the Manx Labour Party won two seats and the Liberal Vannin Party won one seat; all 21 remaining seats were won by independents.\nMost Manx politicians stand for election as independents rather than as representatives of political parties. Though political parties do exist, their influence is not nearly as strong as in the United Kingdom. Consequently, much Manx legislation develops through consensus among the members of Tynwald, which contrasts with the much more adversarial nature of the British Parliament.\nThe largest political party is the Liberal Vannin Party, which promotes liberalism, greater Manx independence and more accountability in Government.\nThe Manx Labour Party is unaffiliated to the British Labour Party.\nA political pressure group Mec Vannin advocates the establishment of a sovereign republic.\nThe Isle of Man Green Party, which was founded in 2016, holds two local government seats and promotes Green politics.\nThe island also formerly had a Manx National Party. There are Manx members in the Celtic League, a political pressure group that advocates greater co-operation between and political autonomy for the Celtic nations.\nIntervention of the United Kingdom.\nThe UK Parliament has paramount power to legislate for the Isle of Man on all matters, but it is a long-standing convention that it does not do so on domestic (\"insular\") matters without Tynwald's consent.\nOccasionally, the UK Parliament acts against the wishes of Tynwald: the most recent example was the Marine, &amp;c., Broadcasting (Offences) Act 1967, which banned pirate radio stations from operating in Manx waters. Legislation to accomplish this was defeated on its second reading in the House of Keys, prompting Westminster to legislate directly.\nThe UK has had several disputes with the European Court of Human Rights about the Isle of Man's laws concerning birching (corporal punishment) in the case of \"Tyrer v. the United Kingdom\", and sodomy.\nJudicial branch.\nThe lowest courts in the Isle of Man are presided over by the High Bailiff and the Deputy High Bailiff, along with lay Justices of the Peace. The High Court of Justice consists of three civil divisions and is presided over by a Deemster. Appeals are dealt with by the Staff of Government Division with final appeal to the Judicial Committee of the Privy Council in the United Kingdom. The head of the Judiciary is the First Deemster and Clerk of the Rolls. The other High and Appeal Court Judges are the Second Deemster, the Third Deemster and the Judge of Appeal, all of whom are appointed by the Lieutenant Governor.\nThe Court of General Gaol Delivery is the criminal court for serious offences (effectively the equivalent of a Crown Court in England). It is theoretically not part of the High Court, but is effectively the criminal division of the court. The Second Deemster normally sits as the judge in this court. In 1992, His Honour Deemster Callow passed the last sentence of death in a court in the British Islands (which was commuted to life imprisonment). Capital punishment in the Isle of Man was formally abolished by Tynwald in 1993 (although the last execution on the island took place in 1872).\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "14767", "revid": "1271019027", "url": "https://en.wikipedia.org/wiki?curid=14767", "title": "Economy of the Isle of Man", "text": "The economy of the Isle of Man is a low-tax economy with insurance, online gambling operators and developers, information and communications technology (ICT), and offshore banking forming key sectors of the island's economy.\nAs an offshore financial centre located in the Irish Sea, the Isle of Man is within the British Isles but does not form part of the United Kingdom and was never a part of the European Union.\nAs of 2016, the Crown dependency's gross national income (GNI) per capita was US$89,970 as assessed by the World Bank. The Isle of Man Government's own National Income Report shows the largest sectors of the economy are insurance and eGaming with 17% of GNI each, followed by ICT and banking with 9% each, with tourist accommodation in the lowest sector at 0.3%.\nEconomic performance.\nAfter 32 years of continued Gross Domestic Product (GDP) growth, the financial year 2015/16 showed the first drop in GDP, of 0.9%, triggered by decline in eGaming revenues.\nThe unemployment rate is around 5%.\nProperty prices are flat or declining, but recent figures also show an increase in resident income tax payers.\nThe government's policy of offering incentives to high-technology companies and financial institutions to locate on the island has expanded employment opportunities in high-income industries. Agriculture, fishing, and the hospitality industry, once the mainstays of the economy, now make declining contributions to the island's GNP. The hospitality sector contributed just of 0.3% of GNP in 2015/16, and 629 jobs in 2016. eGaming and ICT contribute the great bulk of GNP. The stability of the island's government and its openness for business make the Isle of Man an attractive alternative jurisdiction (DAW Index ranked 3).\nEconomic strategy.\nIn the Vision2020 the Isle of Man government lays out the national strategy of economic growth, seeking an increase of the economically active population an promoting the Island as an 'Enterprise Island, \"Tech Isle', 'Manufacturing centre of excellence', 'Offshore energy hub', 'Destination Island' and for 'Distinctive local food and drink'. The government has published its national economic strategies for several emerging sectors: aerospace, biomed, digital media, ICT.\nTaxation and trade.\nTax rates.\nThe Isle of Man is a low-tax economy with no capital gains tax, wealth tax, stamp duty, or inheritance tax; and a top rate of income tax of 22%. A tax cap is in force: the maximum amount of tax payable by an individual is \u00a3200,000; or \u00a3400,000 for couples if they choose to have their incomes jointly assessed. Personal income is assessed and taxed on a total worldwide income basis rather than on a remittance basis. This means that all income earned throughout the world is assessable for Manx tax, rather than only income earned in or brought into the Island.\nThe standard rate of corporation tax for residents and non-residents is 0%; retail business profits above \u00a3500,000 and banking business income are taxed at 10%, and rental (or other) income from land and buildings situated on the Isle of Man is taxed at 22%.\nTrade.\nTrade is mostly with the United Kingdom. The Isle of Man has free access to European Union markets for goods, but only has restricted access for services, people, or financial products.\nTax transparency and the offshore banking debate.\nThe Isle of Man as an offshore financial centre has been repeatedly featured in the press as a tax haven, most recently in the wake of the Paradise Papers.\nThe Organisation for Economic Co-operation and Development's (OECD) Global Forum on Transparency and Exchange of Information for Tax Purposes has rated the Isle of Man as 'top compliant' for a second time: a status which only three jurisdictions in the world have achieved so far. The island has become the second nation after Austria to ratify a multilateral convention with the OECD to implement measures to prevent Base Erosion and Profit Shifting (BEPS).\nIn a report the European Council lists the Isle of Man together with the other two Crown Dependencies (Guernsey and Jersey) as well as Bermuda, the Cayman Islands and Vanuatu, as committed to addressing the Council's concerns of \"Existence of tax regimes that facilitate offshore structures which attract profits without real economic activity\" by 2018.\nSectors.\nThe Isle of Man's Department for Enterprise manages the diversified economy in twelve key sectors. The largest individual sectors by GNI are insurance and eGaming with 17% of GNI each, followed by ICT and banking with 9% each. The 2016 census lists 41,636 total employed. The largest sectors by employment are \"medical and health\", \"financial and business services\", construction, retail and public administration. Manufacturing, focused on aerospace and the food and drink industry, employs almost 2000 workers and contributes about 5% of GDP. The sector provides laser optics, industrial diamonds, electronics, plastics and aerospace precision engineering.\nFinance sector.\nInsurance, banking (includes retail banking, offshore banking and other banking services), other finance and business services, and corporate service providers together contribute the most to the GNI and most of the jobs, with 10,057 people employed in 2016.\neGaming &amp; ICT.\nAmong the largest employers of the Island's private sector are eGaming (online gambling) companies like The Stars Group, Microgaming, Newfield, and Playtech. The Manx eGaming Association MEGA is representing the sector. Licenses are issued by the Gambling Supervision Commission.\nIn 2005 PokerStars, one of the world's largest online poker sites, relocated its headquarters to the Isle of Man from Costa Rica. In 2006, RNG Gaming a large gaming software developer of P2P tournaments and Get21, a multiplayer online blackjack site, based their corporate offices on the island.\nThe Isle of Man Government Lottery operated from 1986 to 1997. Since 2 December 1999 the island has participated in the United Kingdom National Lottery. The island is the only jurisdiction outside the United Kingdom where it is possible to play the UK National Lottery. Since 2010 it has also been possible for projects in the Isle of Man to receive national lottery Good Causes Funding. The good causes funding is distributed by the Manx Lottery Trust. Tynwald receives the 12p lottery duty for tickets sold in the Island.\nThe shortage of workers with ICT skills is tackled by several initiatives, like an IT and education campus, a new cyber security degree at the University College of Man, a Code Club, and a work permit waiver for skilled immigrants.\nFilmmaking and digital media.\nSince 1995 Isle of Man Film has co-financed and co-produced over 100 feature film and television dramas which have all filmed on the Island.\nAmong the most successful productions funded in part by Isle of Man Film agency were \"Waking Ned\", where the Manx countryside stood in for rural Ireland, and films like \"Stormbreaker\", \"Shergar\", \"Tom Brown's Schooldays\", \"I Capture the Castle\", \"The Libertine\", \"Island at War\" (TV series), \"Five Children and It\", \"Colour Me Kubrick\", \"Sparkle\", and others. Other films that have been filmed on the Isle of Man include \"Thomas and the Magic Railroad\", \"Harry Potter and the Chamber of Secrets\", \"Keeping Mum and Mindhorn.\"\n2011 Isle of Man Film Oxford Economics was commissioned by Isle of Man Film Ltd to conduct a study into the economic impact of the film industry on the Isle of. Man. The recommendation of this report for Isle of Man Film was to partner with a more established film institution in the UK to source more Isle of Man film production opportunities. This led to the investment of the Isle of Man Government to take shares in Pinewood Shepperton Plc which were sold later with profit.\nOnce one of the busiest areas of film production in the British Isles, the Isle of Man hopes to use its strong foundation in film to grow its television and new digital media industry. In a recent Isle of Man Department of Economic Development strategic review, the Island's over 2,000 jobs counting digital sector features 'digital media' and the creative industries, and embraces partnerships with the industry and its individual sector bodies like the Isle of Media, a new media cluster.\nMotorsports.\nHosting of motorsports events, like the Isle of Man Car Rally and the more-prominent TT motorcycle races, contributes to the tourism economy.\nTourism.\nTourism in the Isle of Man developed from advances in transport to the island. In 1819 the first steamship \"Robert Bruce\" came to the island, only seven years after the first steam vessel in the UK. In the 1820s, tourism was growing due to improved transport. The island government's own report for the financial years 2014/15-2015/16 shows tourist accommodation to be in the lowest sector at 0.3%, ranking slightly above 'mining and quarrying' (0.1%).\nInfrastructure.\nElectricity.\nSince 1999, the Isle of Man has received electricity through the world's second longest submarine AC cable, the 90\u00a0kV Isle of Man to England Interconnector, as well as from a natural gas power station in Douglas, an oil power station in Peel and a small hydro-electric power station in Sulby Glen.\nGas.\nGas for lighting and heating has been supplied to users on the Isle of Man since 1836, firstly as town gas, then as liquid petroleum gas (LPG); since 2003 natural gas has been available. The future use of hydrogen as a supplementary or substitute fuel is being studied.\nBroadband.\nThe Island is connected with five submarine cables to the UK and Ireland.\nWhile the Isle of Man Communications Commission refers to Akamai\u2019s recent State of the Internet Report for Q1 2017, with \"the Island ranked 8th in the world for percentage of broadband connections with &gt;4\u00a0Mb/s connectivity, with 96% of users connecting at speeds greater than 4\u00a0Mb/s\", an \"international league table of broadband speeds puts the Isle of Man at 50th in the world\". Manx Telecom recently announced to roll out Fibre-to-the-Home (FTTH) superfast broadband with download speeds of up to 1Gigabit per second.\nTravel links.\nRonaldsway Airport links the Isle of Man with six airlines to eleven UK and Irish scheduled flight destinations.\nThe Steam Packet Company provides ferry services to Liverpool, Heysham, Belfast and Dublin.\nStatistics.\nLabour force\u2014by occupation:\nagriculture, forestry and fishing 3%, manufacturing 11%, construction 10%, transport and communication 8%, wholesale and retail distribution 11%, professional and scientific services 18%, public administration 6%, banking and finance 18%, tourism 2%, entertainment and catering 3%, miscellaneous services 10%\nUnemployment rate:\nnominally 5.0% (July 2020)\nIndustries:\nfinancial services, light manufacturing, tourism\nAgriculture\u2014products:\ncereals, vegetables, cattle, sheep, pigs, poultry\nExports:\n$NA\nExports\u2014commodities:\ntweeds, herring, processed shellfish, beef, lamb\nExports\u2014partners:\nUK\nImports:\n$NA\nImports\u2014commodities:\ntimber, fertilizers, fish\nImports\u2014partners:\nUK\nDebt\u2014external:\n$NA\nEconomic aid\u2014recipient:\n$NA\nCurrency:\n1 Isle of Man pound = 100 pence\nExchange rates:\nthe Manx pound is at par with the British pound\nFiscal year:\n1 April \u2013 31 March\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "14768", "revid": "1318536118", "url": "https://en.wikipedia.org/wiki?curid=14768", "title": "Communications in the Isle of Man", "text": "The Isle of Man has an extensive communications infrastructure consisting of telephone cables, submarine cables, and an array of television and mobile phone transmitters and towers.\nTelecommunications.\nTelegraph.\nThe history of Manx telecommunications starts in 1859, when the &lt;templatestyles src=\"Template:Visible anchor/styles.css\" /&gt;Isle of Man Electric Telegraph Company was formed on the Island with the intention of connecting across the Island by telegraph, and allowing messages to be sent onwards to the UK. In August 1859, a long cable was commissioned from Glass, Elliot and Company of Greenwich and laid from Cranstal (north of Ramsey) to St Bees in Cumbria using the chartered cable ship \"Resolute\". The cable was single-core, with gutta-percha insulation.\nTwenty miles of overhead cable were also erected from Cranstal south to Ramsey, and on to Douglas. In England, the telegraph was connected to Whitehaven and the circuits of the Electric Telegraph Company.\nThe telegraph offices were located at 64 Athol Street, Douglas (also the company's head office) and at East Quay, Ramsey (now Marina House).\nOn 10 August 1860 the company was statutorily incorporated by the &lt;templatestyles src=\"Template:Visible anchor/styles.css\" /&gt;Isle of Man Electric Telegraph Company's Act 1860, an Act of Tynwald with a capital of \u00a35,500.\nAn Act to incorporate the Isle of Man Electric Telegraph Company and to enable such company to make arrangements for the working of Telegraphs in the Isle of Man.\nThe currents at Cranstal proved too strong, and in 1864 the cable was taken up and relaid further south, at Port-e-Vullen in Ramsey Bay. It was later relaid to land even further south at Port Cornaa.\nFollowing the 1869 finalisation of UK telegraph nationalisation into a General Post Office monopoly, the Isle of Man Electric Telegraph Company was nationalised in 1870 under the Telegraph Act 1870 (33 &amp; 34 Vict. c. 88) (an act of Parliament) at a cost to the British Government of \u00a316,106 (paid in 1872 following arbitration proceedings over the value). Prior to nationalisation, the Island's telegraph operations had been performing poorly and the company's share price valued it at around \u00a3100.\nSubsequent to nationalisation, operations were taken over by the GPO. The internal telegraph system was extended within a year to Castletown and Peel, however by then the previous lack of modern communications in Castletown had already started the Isle of Man Government on its move to Douglas.\nDue to increasing usage in the years following nationalisation, further cables between Port Cornaa and St Bees were laid in 1875 and 1885.\nBy 1883 Smith's Directory listed several telegraph offices operated by the Post Office, in addition to those at Douglas, Ramsey, Castletown and Peel the telegraph was also available at Laxey, Ballaugh, and Port St. Mary.\nThroughout the First World War, the cable landing station at Port Cornaa was guarded by the Isle of Man Volunteer Corps.\nThe undersea telegraph cables have been disused since the 1950s, but remain in place.\nTeleport.\nA Teleport, with several earth stations, is currently under construction in the Isle of Man. SES Satellite Leasing, the entrepreneurial investment arm of https:// . The teleport is expected to enter into service in 2017. It will be a state-of-the-art facility providing satellite telemetry, tracking and commanding (TT&amp;C) facilities and capacity management, together with a wide range of teleport services such as uplink, downlink, and contribution services for broadcasters and data centres.\nTelephones.\nThe main telephone provider in the Isle of Man today is Manx Telecom.\nIn 1889 George Gillmore, formerly an electrician for the GPO's Manx telegraph operations, was granted a licence by the Postmaster General to operate the Isle of Man's first telephone service. Based in an exchange in Athol Street, early customers of Gilbert's telephone service included the Isle of Man Steam Packet Company and the Isle of Man Railway. Not having the resources to fund expansion or a link to England, Gillmore sold his licence to the National Telephone Company and stayed on as their manager on the island.\nBy 1901 there were 600 subscribers, and the telephone system had been extended to Ramsey, Castletown, Peel, Port Erin, Port St. Mary and Onchan.\nOn 1 January 1912 the National Telephone Company was nationalised and merged into the General Post Office by the Telephone Transfer Act 1911 (1 &amp; 2 Geo. 5. c. 26). Only Guernsey, Portsmouth and Hull remained outside of the GPO.\nIn 1922, the General Post Office offered to sell the island's telephone service to the Manx government, but the offer was not taken up. A similar arrangement in Jersey for that island's telephone service was concluded in 1923.\nThe first off-island telephone link was established in 1929, with the laying of a cable by the \"CS Faraday\" between Port Erin and Ballyhornan in Northern Ireland, a distance of 57\u00a0km, and then between Port Grenaugh and Blackpool, primarily to provide a link to Northern Ireland. The cable was completed on 6 June 1929 and the first call between the Isle of Man and the outside world was made on 28 June 1929 by Lieutenant Governor Sir Claude Hill in Douglas to the Postmaster General in Liverpool. The cable initially carried only two trunk circuits.\nIn 1942, a pioneering VHF frequency-modulated radio-link was established between Creg-na-Baa and the UK to provide an alternative to the sub-sea cable. This has since been discontinued.\nThis was augmented on 24 June 1943 by a long cable between Cemaes Bay in Anglesey and Port Erin, which had the world's first submerged repeater, laid by \"HMCS Iris\". The repeater doubled the possible number of circuits on the cable, and although it failed after only five months, its replacement worked for seven years.\nIn 1962 a further undersea cable was laid by \"HMTS Ariel\" between Colwyn Bay and the Island.\nHistorically, the telephone system in the Isle of Man had been run as a monopoly by the British General Post Office, and later British Telecommunications, and operated as part of the Liverpool telephone district.\nBy 1985 the privatised British Telecom had inherited the telephone operations of the GPO, including those in the Isle of Man. At this time the Manx Government announced that it would award a 20-year licence to operate the telephone system in a tender process. As part of this process, in 1986 British Telecom created a Manx-registered subsidiary company, Manx Telecom, to bid for the tender. It was believed that a local identity and management would be more politically acceptable in the tendering process as they competed with Cable &amp; Wireless to win the licence. Manx Telecom won the tender, and commenced operations under the new identity from 1 January 1987.\nOn 28 March 1988 an 8,000 telephone circuit fibre optic cable, the longest unregenerated system in Europe, was inaugurated. It links Port Grenaugh to Silecroft in Cumbria, and was laid in September 1987. The cable was buried in the seabed along its entire length.\nA further fibre optic cable, known as BT-MT1 was laid in October 1990 between Millom in Cumbria and Douglas, a distance of . Jointly operated by BT and Manx Telecom, it provides six channels each with a bandwidth of 140 Mbit/s. This cable remains in use today.\nIn July 1992, Mercury Communications laid the LANIS fibre-optic cables. LANIS-1 runs for between Port Grenaugh and Blackpool, and LANIS-2 runs for between the Isle of Man and Northern Ireland. They have six channels each with a bandwidth of 565\u00a0Mbit/s. The LANIS cables are now operated by Cable &amp; Wireless. The LANIS-1 cable was damaged 600 m off Port Grenaugh on 27 November 2006, causing loss of the link and resulting in temporary Internet access issues for some Manx customers whilst it was awaiting repair.\nOn 17 November 2001 Manx Telecom became part of mmO2 following the demerger of BT Wireless's operations from BT Group, and the company was owned by Telef\u00f3nica. On 4 June 2010 Manx Telecom was sold by Telef\u00f3nica to UK private equity investor HgCapital (who were buying the majority stake), alongside telecoms management company CPS Partners\nIn December 2007, the Manx Electricity Authority and its telecoms subsidiary, e-llan Communications, commissioned the lighting of a new undersea fibre-optic link. It was laid in 1999 between Blackpool and Douglas as part of the Isle of Man to England Interconnector which connects the Manx electricity system to the UK's National Grid.\nAccording to the CIA World Factbook, in 1999 there were 51,000 fixed telephone lines in use in the Isle of Man.\nThe Isle of Man is included within the UK telephone numbering system, and is accessed externally via UK area codes, rather than by its own country calling code. The area codes currently in use are: +44 1624 (landlines) and +44 7425 / +44 7624 / +44 7924 (mobiles).\nSubmarine communications cables in service.\nSubmarine cables in Manx waters are governed by the Submarine Cables Act 2003 (an Act of Tynwald).\nMobile telephones.\nThe mobile phone network operated by Manx Telecom has been used by O2 as an environment for developing and testing new products and services prior to wider rollout. In December 2001, the company became the first telecommunications operator in Europe to launch a live 3G network. In November 2005, the company became the first in Europe to offer its customers an HSDPA (3.5G) service.\nSure built their own mobile network on the island in 2007 and following various upgrades now deliver 2G/3G and 4G services\nInternet.\nIn 1996 the Isle of Man government obtained permission to use the .im national top level domain (TLD) and has ultimate responsibility for its use. The domain is managed on a daily basis by Domicilium (IOM) Limited, an island based Internet service provider. Broadband Internet services are available through five local providers which are Manx Telecom, https:// , https:// , https:// , https:// and BlueWave Communications.\nIn 2021 it was revealed Bluewave host a Ground station for the Starlink Satellite Internet system \nBroadcasting.\nRadio.\nThe public-service commercial radio station for the island is Manx Radio. Manx Radio is part funded by government grant, and partly by advertising. There are two other Manx-based FM radio stations, Energy FM and 3 FM.\nBBC national radio stations are also relayed locally via a transmitter located to the south of Douglas, relayed from Sandale transmitting station in Cumbria, as well as a signal feed from the Holme Moss transmitting station in West Yorkshire. The Douglas transmitter also broadcasts the BBC's DAB digital radio services and Classic FM.\nManx Radio is the only local service to broadcast on AM medium wave. No UK services are relayed via local AM transmitters. No longwave stations operate from the Island, although one (MusicMann 279) was proposed. There are currently no proposals to broadcast any of the three insular FM stations on DAB.\nTelevision.\nThere is no Island-specific television service. Local transmitters retransmit UK Freeview broadcasts. The BBC region is BBC North West and the ITV region is Granada Television.\nMany television services are available by satellite, such as Sky, and Freesat from the Astra 2/Eurobird 1 group, as well as services from a range of other satellites around Europe such as Astra 1 and Hot Bird.\nManx ViaSat-IOM, ManSat, Telesat-IOM companies uses the first communications satellite ViaSat-1 that launched in 2011 and positioned at the Isle of Man registered 115.1 degrees West longitude geostationary orbit point. In some areas, terrestrial television directly from the United Kingdom or Republic of Ireland can also be received.\nAnalogue television transmission ceased between 2008 and 2009, when limited local transmission of digital terrestrial television commenced. The UK's television licence regime extends to the island.\nThere is no Island-specific opt-out of the BBC regional news programme \"North West Tonight\", in the way that the Channel Islands get their own version of \"Spotlight\".\nTelevision was first received in the Isle of Man from the Holme Moss transmitter which started broadcasting BBC Television (later BBC One) from 12 October 1951. Signals from Holme Moss were easily received in the Isle of Man.\nITV television has been available on parts of the east of the Isle of Man on 3 May 1956 when Granada Television (and ABC Television from 5 May 1956 to 28 July 1968) transmissions started from the Winter Hill transmitting station, and to parts of the west of the island on 31 October 1959 from the Black Mountain transmitting station in Northern Ireland which broadcasts Ulster Television. Parts of the north of the Island received Border Television since 1 September 1961, initially directly from the Caldbeck transmitting station in Cumberland (later became Cumbria from 1974). On 26 March 1965, Border Television commenced relay of their signal through a local transmitter on Richmond Hill, above sea level and from the centre of Douglas. The site allowed reliable reception of the Caldbeck signal, which is rebroadcast on a different frequency. The high transmission tower was re-sited from London, where it had been used for early ITV transmissions. Richmond Hill was decommissioned after the close of 405-line broadcasts, although the 200\u00a0ft tower remained in use for radio with Manx Radio transmitting on 96.9\u00a0MHz and then 97.3\u00a0MHz until 1989. Manx Radio moved their FM service to the Carnane site and the frequency changed to the current 97.2\u00a0MHz.\nThe television broadcasts are now transmitted from a high transmitter on a hill to the south of Douglas. The transmitter is operated by Arqiva and is directly fed using a fibre optic cable. There are further sub-relay transmitters across the Island. Following a realignment of ITV regional services and the digital switchover, the Douglas relay switched ITV broadcasts to Granada Television on Thursday 17 July 2009.\nThe Broadcasting Act 1993 (An Act of Tynwald) allows for the establishment of local television services. Only one application for a licence to run such a service was received by the Communications Commission. That application was rejected.\nAccording to the CIA World Factbook, in 1999 there were 27,490 televisions in use in the Isle of Man.\nPost.\nIsle of Man Post issues its own stamps for use within the Island and for sending post off-Island. Only Manx stamps are valid for sending mail using the postal system. The Isle of Man adopted postcodes in 1993 using the prefix IM to fit in with the already established UK postcode system.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "14769", "revid": "27823944", "url": "https://en.wikipedia.org/wiki?curid=14769", "title": "Transport in the Isle of Man", "text": " \nThere are a number of transport services around the Isle of Man, mostly consisting of paved roads, public transport, rail services, sea ports and an airport.\nRoads.\nThe island has a total of of public roads, all of which are paved. Roads are numbered using a numbering scheme similar to the numbering schemes of Great Britain and Northern Ireland; each road is assigned a letter, which represents the road's category, followed by a 1 or 2 digit number. \"A\" roads are the main roads of the island whilst roads labelled \"B\", \"C\", \"D\" or \"U\" decrease in size and/or quality. (The C, D and U numbers are not marked on most maps or on signposts.) There is no national speed limit \u2013 some roads may be driven at any speed which is safe and appropriate. Careless and dangerous driving laws still apply, so one may not drive at absolutely any speed, and there are local speed limits on many roads. Many unrestricted roads have frequent bends which even the most experienced driver cannot see round. Drivers are limited to in the first full year after passing their driving test (Isle of Man citizens are permitted to start driving at the age of sixteen) and some are not used to having to make progress in the same way as on a larger road network such as that in the UK: even a cautious driver can get from anywhere in the island to anywhere else in no more than sixty minutes.\nSet against this is a strong culture of motor sport enthusiasm (pinnacled in the TT, but there are many events during the year) and many residents familiar with the roads are well used to traversing country roads at speeds illegal on similar roads elsewhere. This leads to a very diverse spread of both driving competence and speed. In an official survey in 2006 the introduction of blanket speed limits was refused by the population, suggesting that a large number appreciate the freedom.\nThere is a comprehensive bus network, operated by Bus Vannin, a department of the Isle of Man Government, with most routes originating or terminating in Douglas.\nAn organisation on the Isle of Man called the Fare Free Campaign supports making bus and tram travel on the island free of charge for all routes. One of the reasons the campaign gives for supporting this is to encourage people to change their transportation habits to help mitigate climate change.\nRailways.\nThe island has a total of of railway. There are seven separate public rail or tram systems on the island:\n\"a\" Reopened 2022, on a shortened route with its western terminus at Broadway.\nIn addition, in 2025 a short length of tramway on the Queen's Pier, Ramsey was partly reopened.\nAll of these routes are seasonal.\nAirports.\nThe only commercial airport on the island is the Isle of Man Airport at Ronaldsway. Scheduled services operate to and from various cities in the United Kingdom and Ireland, operated by several different airlines.\nThe island's other paved runways are at Jurby and Andreas. Jurby remains in Isle of Man Government ownership and is used for motorsport events and, previously, airshows, while Andreas is privately owned and used by a local glider club. The old Hall Caine Airport, a grass field near Ramsey, is no longer used.\nAircraft Register.\nThe Isle of Man Aircraft Register became operational on 1 May 2007.\nThe register is open to all non-commercial aircraft and is intended to be of particular interest to professionally flown corporate operators.\nAs of August 2025 a total of 1404 corporate and private aircraft had been registered.\nPorts and harbours.\nThere are ports at Castletown, Douglas, Peel, Port St Mary and Ramsey. Douglas is served by frequent ferries to/from England and occasional ferries to/from Ireland; the sole operator is the Isle of Man Steam Packet Company, with exclusive use of the Isle of Man Sea Terminal and the Douglas port linkspans under the conditions of the user agreement with the Isle of Man Government.\nMerchant marine.\nThe Isle of Man register comprised 404 merchant ships of 1,000 GT or over at the end of 2017.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "14770", "revid": "20836525", "url": "https://en.wikipedia.org/wiki?curid=14770", "title": "Military of the Isle of Man", "text": ""}
{"id": "14771", "revid": "20836525", "url": "https://en.wikipedia.org/wiki?curid=14771", "title": "Isle of Man/Transnational issues", "text": ""}
{"id": "14773", "revid": "49730707", "url": "https://en.wikipedia.org/wiki?curid=14773", "title": "Information theory", "text": "Scientific study of digital information\nInformation theory is the mathematical study of the quantification, storage, and communication of information. The field was established and formalized by Claude Shannon in the 1940s, though early contributions were made in the 1920s through the works of Harry Nyquist and Ralph Hartley. It is at the intersection of electronic engineering, mathematics, statistics, computer science, neurobiology, physics, and electrical engineering.\nA key measure in information theory is entropy. Entropy quantifies the amount of uncertainty involved in the value of a random variable or the outcome of a random process. For example, identifying the outcome of a fair coin flip (which has two equally likely outcomes) provides less information (lower entropy, less uncertainty) than identifying the outcome from a roll of a die (which has six equally likely outcomes). Some other important measures in information theory are mutual information, channel capacity, error exponents, and relative entropy. Important sub-fields of information theory include source coding, algorithmic complexity theory, algorithmic information theory and information-theoretic security.\nApplications of fundamental topics of information theory include source coding/data compression (e.g. for ZIP files), and channel coding/error detection and correction (e.g. for DSL). Its impact has been crucial to the success of the Voyager missions to deep space, the invention of the compact disc, the feasibility of mobile phones and the development of the Internet and artificial intelligence. The theory has also found applications in other areas, including statistical inference, cryptography, neurobiology, perception, signal processing, linguistics, the evolution and function of molecular codes (bioinformatics), thermal physics, molecular dynamics, black holes, quantum computing, information retrieval, intelligence gathering, plagiarism detection, pattern recognition, anomaly detection, the analysis of music, art creation, imaging system design, study of outer space, the dimensionality of space, and epistemology.\nOverview.\nInformation theory studies the transmission, processing, extraction, and utilization of information. Abstractly, information can be thought of as the resolution of uncertainty. In the case of communication of information over a noisy channel, this abstract concept was formalized in 1948 by Claude Shannon in a paper entitled \"A Mathematical Theory of Communication\", in which information is thought of as a set of possible messages, and the goal is to send these messages over a noisy channel, and to have the receiver reconstruct the message with low probability of error, in spite of the channel noise. Shannon's main result, the noisy-channel coding theorem, showed that, in the limit of many channel uses, the rate of information that is asymptotically achievable is equal to the channel capacity, a quantity dependent merely on the statistics of the channel over which the messages are sent.\nCoding theory is concerned with finding explicit methods, called \"codes\", for increasing the efficiency and reducing the error rate of data communication over noisy channels to near the channel capacity. These codes can be roughly subdivided into data compression (source coding) and error-correction (channel coding) techniques. In the latter case, it took many years to find the methods Shannon's work proved were possible.\nA third class of information theory codes are cryptographic algorithms (both codes and ciphers). Concepts, methods and results from coding theory and information theory are widely used in cryptography and cryptanalysis, such as the unit ban.\nHistorical background.\nThe landmark event \"establishing\" the discipline of information theory and bringing it to immediate worldwide attention was the publication of Claude Shannon's classic paper \"A Mathematical Theory of Communication\" in the \"Bell System Technical Journal\" in July and October 1948. Historian James Gleick rated the paper as the most important development of 1948, noting that the paper was \"even more profound and more fundamental\" than the transistor. He came to be known as the \"father of information theory\". Shannon outlined some of his initial ideas of information theory as early as 1939 in a letter to Vannevar Bush.\nPrior to this paper, limited information-theoretic ideas had been developed at Bell Labs, all implicitly assuming events of equal probability. Harry Nyquist's 1924 paper, \"Certain Factors Affecting Telegraph Speed\", contains a theoretical section quantifying \"intelligence\" and the \"line speed\" at which it can be transmitted by a communication system, giving the relation \"W\" = \"K\" log \"m\" (recalling the Boltzmann constant), where \"W\" is the speed of transmission of intelligence, \"m\" is the number of different voltage levels to choose from at each time step, and \"K\" is a constant. Ralph Hartley's 1928 paper, \"Transmission of Information\", uses the word \"information\" as a measurable quantity, reflecting the receiver's ability to distinguish one sequence of symbols from any other, thus quantifying information as \"H\" = log \"S\"\"n\" = \"n\" log \"S\", where \"S\" was the number of possible symbols, and \"n\" the number of symbols in a transmission. The unit of information was therefore the decimal digit, which since has sometimes been called the hartley in his honor as a unit or scale or measure of information. Alan Turing in 1940 used similar ideas as part of the statistical analysis of the breaking of the German second world war Enigma ciphers.\nMuch of the mathematics behind information theory with events of different probabilities were developed for the field of thermodynamics by Ludwig Boltzmann and J. Willard Gibbs. Connections between information-theoretic entropy and thermodynamic entropy, including the important contributions by Rolf Landauer in the 1960s, are explored in \"Entropy in thermodynamics and information theory\".\nIn Shannon's revolutionary and groundbreaking paper, the work for which had been substantially completed at Bell Labs by the end of 1944, Shannon for the first time introduced the qualitative and quantitative model of communication as a statistical process underlying information theory, opening with the assertion: \n\"The fundamental problem of communication is that of reproducing at one point, either exactly or approximately, a message selected at another point.\"\nWith it came the ideas of: \nQuantities of information.\nInformation theory is based on probability theory and statistics, where quantified information is usually described in terms of bits. Information theory often concerns itself with measures of information of the distributions associated with random variables. One of the most important measures is called entropy, which forms the building block of many other measures. Entropy allows quantification of measure of information in a single random variable. \nAnother useful concept is mutual information defined on two random variables, which describes the measure of information in common between those variables, which can be used to describe their correlation. The former quantity is a property of the probability distribution of a random variable and gives a limit on the rate at which data generated by independent samples with the given distribution can be reliably compressed. The latter is a property of the joint distribution of two random variables, and is the maximum rate of reliable communication across a noisy channel in the limit of long block lengths, when the channel statistics are determined by the joint distribution.\nThe choice of logarithmic base in the following formulae determines the unit of information entropy that is used. A common unit of information is the bit or shannon, based on the binary logarithm. Other units include the nat, which is based on the natural logarithm, and the decimal digit, which is based on the common logarithm.\nIn what follows, an expression of the form \"p\" log \"p\" is considered by convention to be equal to zero whenever \"p\" = 0. This is justified because formula_1 for any logarithmic base.\nEntropy of an information source.\nBased on the probability mass function of a source, the Shannon entropy \"H\", in units of bits per symbol, is defined as the expected value of the information content of the symbols.\nThe amount of information conveyed by an individual source symbol formula_2 with probability formula_3 is known as its self-information or surprisal, formula_4. This quantity is defined as:\nformula_5\nA less probable symbol has a larger surprisal, meaning its occurrence provides more information. The entropy formula_6 is the weighted average of the surprisal of all possible symbols from the source's probability distribution:\nformula_7\nIntuitively, the entropy formula_8 of a discrete random variable \"X\" is a measure of the amount of \"uncertainty\" associated with the value of formula_9 when only its distribution is known. A high entropy indicates the outcomes are more evenly distributed, making the result harder to predict.\nFor example, if one transmits 1000 bits (0s and 1s), and the value of each of these bits is known to the receiver (has a specific value with certainty) ahead of transmission, no information is transmitted. If, however, each bit is independently and equally likely to be 0 or 1, 1000 shannons of information (more often called bits) have been transmitted.\nProperties.\nA key property of entropy is that it is maximized when all the messages in the message space are equiprobable. For a source with n possible symbols, where formula_10 for all formula_11, the entropy is given by:\nformula_12\nThis maximum value represents the most unpredictable state.\nFor a source that emits a sequence of formula_13 symbols that are independent and identically distributed (i.i.d.), the total entropy of the message is formula_14 bits. If the source data symbols are identically distributed but not independent, the entropy of a message of length formula_13 will be less than formula_14.\nUnits.\nThe choice of the logarithmic base in the entropy formula determines the unit of entropy used:\nBinary Entropy Function.\nThe special case of information entropy for a random variable with two outcomes (a Bernoulli trial) is the binary entropy function. This is typically calculated using a base-2 logarithm, and its unit is the shannon. If one outcome has probability p, the other has probability \"1\" \u2212 \"p\". The entropy is given by:\nformula_17\nThis function is depicted in the plot shown above, reaching its maximum of 1 bit when \"p\" = 0.5, corresponding to the highest uncertainty.\nJoint entropy.\nThe joint entropy of two discrete random variables \"X\" and \"Y\" is merely the entropy of their pairing: (\"X\", \"Y\"). This implies that if \"X\" and \"Y\" are independent, then their joint entropy is the sum of their individual entropies.\nFor example, if (\"X\", \"Y\") represents the position of a chess piece\u2014\"X\" the row and \"Y\" the column, then the joint entropy of the row of the piece and the column of the piece will be the entropy of the position of the piece.\nformula_18\nDespite similar notation, joint entropy should not be confused with cross-entropy.\nConditional entropy (equivocation).\nThe conditional entropy or \"conditional uncertainty\" of \"X\" given random variable \"Y\" (also called the \"equivocation\" of \"X\" about \"Y\") is the average conditional entropy over \"Y\":\nformula_19\nBecause entropy can be conditioned on a random variable or on that random variable being a certain value, care should be taken not to confuse these two definitions of conditional entropy, the former of which is in more common use. A basic property of this form of conditional entropy is that:\n formula_20\nMutual information (transinformation).\n\"Mutual information\" measures the amount of information that can be obtained about one random variable by observing another. It is important in communication where it can be used to maximize the amount of information shared between sent and received signals. The mutual information of \"X\" relative to \"Y\" is given by:\nformula_21\nwhere SI (\"S\"pecific mutual Information) is the pointwise mutual information.\nA basic property of the mutual information is that:\n formula_22\nThat is, knowing formula_23, we can save an average of \"I\"(\"X\"; \"Y\") bits in encoding \"formula_9\" compared to not knowing formula_25.\nMutual information is symmetric:\n formula_26\nMutual information can be expressed as the average Kullback\u2013Leibler divergence (information gain) between the posterior probability distribution of \"formula_9\" given the value of formula_23 and the prior distribution on formula_9:\n formula_30\nIn other words, this is a measure of how much, on the average, the probability distribution on formula_9 will change if we are given the value of \"formula_23\". This is often recalculated as the divergence from the product of the marginal distributions to the actual joint distribution:\n formula_33\nMutual information is closely related to the log-likelihood ratio test in the context of contingency tables and the multinomial distribution and to Pearson's \u03c72 test: mutual information can be considered a statistic for assessing independence between a pair of variables, and has a well-specified asymptotic distribution.\nKullback\u2013Leibler divergence (information gain).\nThe \"Kullback\u2013Leibler divergence\" (or \"information divergence\", \"information gain\", or \"relative entropy\") is a way of comparing two distributions: a \"true\" probability distribution &amp;NoBreak;&amp;NoBreak;, and an arbitrary probability distribution &amp;NoBreak;&amp;NoBreak;. If we compress data in a manner that assumes &amp;NoBreak;&amp;NoBreak; is the distribution underlying some data, when, in reality, &amp;NoBreak;&amp;NoBreak; is the correct distribution, the Kullback\u2013Leibler divergence is the number of average additional bits per datum necessary for compression. It is thus defined\nformula_34\nAlthough it is sometimes used as a 'distance metric', KL divergence is not a true metric since it is not symmetric and does not satisfy the triangle inequality (making it a semi-quasimetric).\nAnother interpretation of the KL divergence is the \"unnecessary surprise\" introduced by a prior from the truth: suppose a number \"formula_9\" is about to be drawn randomly from a discrete set with probability distribution &amp;NoBreak;&amp;NoBreak;. If Alice knows the true distribution &amp;NoBreak;&amp;NoBreak;, while Bob believes (has a prior) that the distribution is &amp;NoBreak;&amp;NoBreak;, then Bob will be more surprised than Alice, on average, upon seeing the value of formula_9. The KL divergence is the (objective) expected value of Bob's (subjective) surprisal minus Alice's surprisal, measured in bits if the \"log\" is in base 2. In this way, the extent to which Bob's prior is \"wrong\" can be quantified in terms of how \"unnecessarily surprised\" it is expected to make him.\nDirected Information.\n\"Directed information\", formula_37, is an information theory measure that quantifies the information flow from the random process formula_38 to the random process formula_39. The term \"directed information\" was coined by James Massey and is defined as:\nformula_40,\nwhere formula_41 is the conditional mutual information formula_42.\nIn contrast to \"mutual\" information, \"directed\" information is not symmetric. The formula_37 measures the information bits that are transmitted causally from formula_44 to formula_45. The Directed information has many applications in problems where causality plays an important role such as capacity of channel with feedback, capacity of discrete memoryless networks with feedback, gambling with causal side information, compression with causal side information,\nreal-time control communication settings, and in statistical physics.\nOther quantities.\nOther important information theoretic quantities include the R\u00e9nyi entropy and the Tsallis entropy (generalizations of the concept of entropy), differential entropy (a generalization of quantities of information to continuous distributions), and the conditional mutual information. Also, pragmatic information has been proposed as a measure of how much information has been used in making a decision.\nCoding theory.\nCoding theory is one of the most important and direct applications of information theory. It can be subdivided into source coding theory and channel coding theory. Using a statistical description for data, information theory quantifies the number of bits needed to describe the data, which is the information entropy of the source.\nThis division of coding theory into compression and transmission is justified by the information transmission theorems, or source\u2013channel separation theorems that justify the use of bits as the universal currency for information in many contexts. However, these theorems only hold in the situation where one transmitting user wishes to communicate to one receiving user. In scenarios with more than one transmitter (the multiple-access channel), more than one receiver (the broadcast channel) or intermediary \"helpers\" (the relay channel), or more general networks, compression followed by transmission may no longer be optimal.\nSource theory.\nAny process that generates successive messages can be considered a source of information. A memoryless source is one in which each message is an independent identically distributed random variable, whereas the properties of ergodicity and stationarity impose less restrictive constraints. All such sources are stochastic. These terms are well studied in their own right outside information theory.\nRate.\nInformation \"rate\" is the average entropy per symbol. For memoryless sources, this is merely the entropy of each symbol, while, in the case of a stationary stochastic process, it is:\nformula_46\nthat is, the conditional entropy of a symbol given all the previous symbols generated. For the more general case of a process that is not necessarily stationary, the \"average rate\" is:\nformula_47\nthat is, the limit of the joint entropy per symbol. For stationary sources, these two expressions give the same result.\nThe information rate is defined as: \nformula_48\nIt is common in information theory to speak of the \"rate\" or \"entropy\" of a language. This is appropriate, for example, when the source of information is English prose. The rate of a source of information is related to its redundancy and how well it can be compressed, the subject of source coding.\nChannel capacity.\nCommunications over a channel is the primary motivation of information theory. However, channels often fail to produce exact reconstruction of a signal; noise, periods of silence, and other forms of signal corruption often degrade quality.\nConsider the communications process over a discrete channel. A simple model of the process is shown below:\nformula_49\nHere formula_9 represents the space of messages transmitted, and formula_23 the space of messages received during a unit time over our channel. Let \"p\"(\"y\"|\"x\") be the conditional probability distribution function of \"formula_23\" given formula_9. We will consider \"p\"(\"y\"|\"x\") to be an inherent fixed property of our communications channel (representing the nature of the \"noise\" of our channel). Then the joint distribution of \"formula_9\" and \"formula_23\" is completely determined by our channel and by our choice of \"f\"(\"x\"), the marginal distribution of messages we choose to send over the channel. Under these constraints, we would like to maximize the rate of information, or the \"signal\", we can communicate over the channel. The appropriate measure for this is the mutual information, and this maximum mutual information is called the channel capacity and is given by:\nformula_56\nThis capacity has the following property related to communicating at information rate \"R\" (where \"R\" is usually bits per symbol). For any information rate \"R\" &lt; \"C\" and coding error \"\u03b5\" &gt; 0, for large enough \"N\", there exists a code of length \"N\" and rate \u2265 R and a decoding algorithm, such that the maximal probability of block error is \u2264 \"\u03b5\"; that is, it is always possible to transmit with arbitrarily small block error. In addition, for any rate \"R\" &gt; \"C\", it is impossible to transmit with arbitrarily small block error.\n\"Channel coding\" is concerned with finding such nearly optimal codes that can be used to transmit data over a noisy channel with a small coding error at a rate near the channel capacity.\nChannels with memory and directed information.\nIn practice many channels have memory. Namely, at time formula_57 the channel is given by the conditional probabilityformula_58.\nIt is often more comfortable to use the notation formula_59 and the channel become formula_60.\nIn such a case the capacity is given by the mutual information rate when there is no feedback available and the Directed information rate in the case that either there is feedback or not (if there is no feedback the directed information equals the mutual information).\nFungible information.\nFungible information is the information for which the means of encoding is not important. Classical information theorists and computer scientists are mainly concerned with information of this sort. It is sometimes referred as speakable information.\nApplications to other fields.\nIntelligence uses and secrecy applications.\nInformation theoretic concepts apply to cryptography and cryptanalysis. Turing's information unit, the ban, was used in the Ultra project, breaking the German Enigma machine code and hastening the end of World War II in Europe. Shannon himself defined an important concept now called the unicity distance. Based on the redundancy of the plaintext, it attempts to give a minimum amount of ciphertext necessary to ensure unique decipherability.\nInformation theory leads us to believe it is much more difficult to keep secrets than it might first appear. A brute force attack can break systems based on asymmetric key algorithms or on most commonly used methods of symmetric key algorithms (sometimes called secret key algorithms), such as block ciphers. The security of all such methods comes from the assumption that no known attack can break them in a practical amount of time.\nInformation theoretic security refers to methods such as the one-time pad that are not vulnerable to such brute force attacks. In such cases, the positive conditional mutual information between the plaintext and ciphertext (conditioned on the key) can ensure proper transmission, while the unconditional mutual information between the plaintext and ciphertext remains zero, resulting in absolutely secure communications. In other words, an eavesdropper would not be able to improve his or her guess of the plaintext by gaining knowledge of the ciphertext but not of the key. However, as in any other cryptographic system, care must be used to correctly apply even information-theoretically secure methods; the Venona project was able to crack the one-time pads of the Soviet Union due to their improper reuse of key material.\nPseudorandom number generation.\nPseudorandom number generators are widely available in computer language libraries and application programs. They are, almost universally, unsuited to cryptographic use as they do not evade the deterministic nature of modern computer equipment and software. A class of improved random number generators is termed cryptographically secure pseudorandom number generators, but even they require random seeds external to the software to work as intended. These can be obtained via extractors, if done carefully. The measure of sufficient randomness in extractors is min-entropy, a value related to Shannon entropy through R\u00e9nyi entropy; R\u00e9nyi entropy is also used in evaluating randomness in cryptographic systems. Although related, the distinctions among these measures mean that a random variable with high Shannon entropy is not necessarily satisfactory for use in an extractor and so for cryptography uses.\nSeismic exploration.\nOne early commercial application of information theory was in the field of seismic oil exploration. Work in this field made it possible to strip off and separate the unwanted noise from the desired seismic signal. Information theory and digital signal processing offer a major improvement of resolution and image clarity over previous analog methods.\nSemiotics.\nSemioticians Doede Nauta and Winfried N\u00f6th both considered Charles Sanders Peirce as having created a theory of information in his works on semiotics. Nauta defined semiotic information theory as the study of \"the internal processes of coding, filtering, and information processing.\"\nConcepts from information theory such as redundancy and code control have been used by semioticians such as Umberto Eco and Ferruccio Rossi-Landi to explain ideology as a form of message transmission whereby a dominant social class emits its message by using signs that exhibit a high degree of redundancy such that only one message is decoded among a selection of competing ones.\nIntegrated process organization of neural information.\nQuantitative information theoretic methods have been applied in cognitive science to analyze the integrated process organization of neural information in the context of the binding problem in cognitive neuroscience. In this context, either an information-theoretical measure, such as functional clusters (Gerald Edelman and Giulio Tononi's functional clustering model and dynamic core hypothesis (DCH)) or effective information (Tononi's integrated information theory (IIT) of consciousness), is defined (on the basis of a reentrant process organization, i.e. the synchronization of neurophysiological activity between groups of neuronal populations), or the measure of the minimization of free energy on the basis of statistical methods (Karl J. Friston's free energy principle (FEP), an information-theoretical measure which states that every adaptive change in a self-organized system leads to a minimization of free energy, and the Bayesian brain hypothesis).\nMiscellaneous applications.\nInformation theory also has applications in the search for extraterrestrial intelligence, black holes, bioinformatics, and gambling.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nApplications.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nTheory.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nConcepts.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\nThe classic work.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nOther journal articles.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nTextbooks on information theory.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nOther books.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "14774", "revid": "28481209", "url": "https://en.wikipedia.org/wiki?curid=14774", "title": "Information explosion", "text": "Rapid increase in the amount of published information or data\nThe information explosion is the rapid increase in the amount of published information or data and the effects of this abundance. As the amount of available data grows, the problem of managing the information becomes more difficult, which can lead to information overload. The Online Oxford English Dictionary indicates use of the phrase in a March 1964 \"New Statesman\" article. \"The New York Times\" first used the phrase in its editorial content in an article by Walter Sullivan on June 7, 1964, in which he described the phrase as \"much discussed\". (p11.) The earliest known use of the phrase was in a speech about television by NBC president Pat Weaver at the Institute of Practitioners of Advertising in London on September 27, 1955. The speech was rebroadcast on radio station WSUI in Iowa City and excerpted in the \"Daily Iowan\" newspaper two months later.\nMany sectors are seeing this rapid increase in the amount of information available such as healthcare, supermarkets, and governments. Another sector that is being affected by this phenomenon is journalism. Such a profession, which in the past was responsible for the dissemination of information, may be suppressed by the overabundance of information today.\nTechniques to gather knowledge from an overabundance of electronic information (e.g., data fusion may help in data mining) have existed since the 1970s. Another common technique to deal with such amount of information is qualitative research. Such approaches aim to organize the information, synthesizing, categorizing and systematizing in order to be more usable and easier to search.\nGrowth patterns.\nA new metric that is being used in an attempt to characterize the growth in person-specific information, is the disk storage per person (DSP), which is measured in megabytes/person (where megabytes is 106 bytes and is abbreviated MB). Global DSP (GDSP) is the total rigid disk drive space (in MB) of new units sold in a year divided by the world population in that year. The GDSP metric is a crude measure of how much disk storage could possibly be used to collect person-specific data on the world population. \nIn 1983, one million fixed drives with an estimated total of 90 terabytes were sold worldwide; 30MB drives had the largest market segment. In 1996, 105 million drives, totaling 160,623 terabytes were sold with 1 and 2 gigabyte drives leading the industry. By the year 2000, with 20GB drive leading the industry, rigid drives sold for the year are projected to total 2,829,288 terabytes Rigid disk drive sales to top $34 billion in 1997.\nAccording to Latanya Sweeney, there are three trends in data gathering today:\nType 1. Expansion of the number of fields being collected, known as the \u201ccollect more\u201d trend.\nType 2. Replace an existing aggregate data collection with a person-specific one, known as the \u201ccollect specifically\u201d trend.\nType 3. Gather information by starting a new person-specific data collection, known as the \u201ccollect it if you can\u201d trend.\nRelated terms.\nSince \"information\" in electronic media is often used synonymously with \"data\", the term \"information explosion\" is closely related to the concept of \"data flood\" (also dubbed \"data deluge\"). Sometimes the term \"information flood\" is used as well. All of those basically boil down to the ever-increasing amount of electronic data exchanged per time unit. A term that covers the potential negative effects of information explosion is \"information inflation\". The awareness about non-manageable amounts of data grew along with the advent of ever more powerful data processing since the mid-1960s.\nChallenges.\nEven though the abundance of information can be beneficial in several levels, some problems may be of concern such as privacy, legal and ethical guidelines, filtering and data accuracy. Filtering refers to finding useful information in the middle of so much data, which relates to the job of data scientists. A typical example of a necessity of data filtering (data mining) is in healthcare since in the next years is due to have EHRs (Electronic Health Records) of patients available. With so much information available, the doctors will need to be able to identify patterns and select important data for the diagnosis of the patient. On the other hand, according to some experts, having so much public data available makes it difficult to provide data that is actually anonymous.\nAnother point to take into account is the legal and ethical guidelines, which relates to who will be the owner of the data and how frequently he/she is obliged to the release this and for how long.\nWith so many sources of data, another problem will be accuracy of such. An untrusted source may be challenged by others, by ordering a new set of data, causing a repetition in the information.\nAccording to Edward Huth, another concern is the accessibility and cost of such information. The accessibility rate could be improved by either reducing the costs or increasing the utility of the information. The reduction of costs according to the author, could be done by associations, which should assess which information was relevant and gather it in a more organized fashion.\nWeb servers.\nAs of August 2005, there were over 70 million web servers. As of \u00a02007[ [update]] there were over 135 million web servers.\nBlogs.\nAccording to Technorati, the number of blogs doubles about every 6 months with a total of 35.3 million blogs as of \u00a02006http://. This is an example of the early stages of logistic growth, where growth is approximately exponential, since blogs are a recent innovation. As the number of blogs approaches the number of possible producers (humans), saturation occurs, growth declines, and the number of blogs eventually stabilizes.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "14775", "revid": "47587808", "url": "https://en.wikipedia.org/wiki?curid=14775", "title": "Inch", "text": "Unit of length\n&lt;templatestyles src=\"Template:Infobox/styles-images.css\" /&gt;\nThe inch (symbol: in or \u2033) is a unit of length in the British Imperial and the United States customary systems of measurement. It is equal to yard or of a foot. Derived from the Roman uncia (\"twelfth\"), the word \"inch\" is also sometimes used to translate similar units in other measurement systems, usually understood as deriving from the width of the human thumb.\nStandards for the exact length of an inch have varied in the past, but since the adoption of the international yard during the 1950s and 1960s the inch has been based on the metric system and defined as exactly 25.4mm.\nName.\nThe English word \"inch\" () was an early borrowing from Latin \"\" (\"one-twelfth; Roman inch; Roman ounce\"). The vowel change from Latin to Old English (which became Modern English ) is known as umlaut. The consonant change from the Latin (spelled \"c\") to English is palatalisation. Both were features of Old English phonology; see and for more information.\n\"Inch\" is cognate with \"ounce\" (), whose separate pronunciation and spelling reflect its reborrowing in Middle English from Anglo-Norman \"unce\" and \"ounce\".\nIn many other European languages, the word for \"inch\" is the same as or derived from the word for \"thumb\", as a man's thumb is about an inch wide (and this was even sometimes used to define the inch). In the Dutch language a term for inch is \"engelse duim\" (english thumb). Examples include (\"inch\") and ' (\"thumb\"); (\"thumb\"); Danish and (\"inch\") ' (\"thumb\"); (whence and ); ; Georgian: , ; ; (\"inch\") and ' (\"thumb\"); (\"duim\"); (\"thumb\"); (\"inch\") and ' (\"thumb\"); and (\"inch\") and \"tumme\" (\"thumb\").\nUsage.\nImperial or hybrid countries.\nThe inch is a commonly used customary unit of length in the United States, Canada, and the United Kingdom. For the United Kingdom, guidance on public sector use states that, since 1 October 1995, without time limit, the inch (along with the foot) is to be used as a primary unit for road signs and related measurements of distance (with the possible exception of clearance heights and widths) and may continue to be used as a secondary or supplementary indication following a metric measurement for other purposes.\nWorldwide.\nInches are used for display screens (e.g. televisions and computer monitors) worldwide. It is the official Japanese standard for electronic parts, especially display screens, and is the industry standard throughout continental Europe for display screens. However, many countries across the world which use the metric system, such as France, Germany or Turkey often supplement it with centimetres in advertisements, catalogues and packages.\nInches are commonly used to specify the diameter of vehicle wheel rims, and the corresponding inner diameter of tyres in tyre codes.\nTechnical details.\nThe international standard symbol for inch is in (see ISO 31-1, Annex A) but traditionally the inch is denoted by a double prime, which is often approximated by a double quote symbol, and the foot by a prime, which is often approximated by an apostrophe. For example; \"three feet, two inches\" can be written as 3\u2032 2\u2033. (This is akin to how the first and second \"cuts\" of the hour are likewise indicated by prime and double prime symbols, and also the first and second cuts of the degree.)\nSubdivisions of an inch are typically written using dyadic fractions with odd number numerators; for example, \"two and three-eighths of an inch\" would be written as \u2033 and not as 2.375\u2033 nor as \u2033. However, for engineering purposes fractions are commonly given to three or four places of decimals and have been for many years.\nEquivalents.\n1 international inch is equal to:\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nHistory.\nThe earliest known reference to the inch in England is from the \"Laws of \u00c6thelberht\" dating to the early 7th century, surviving in a single manuscript, the \"Textus Roffensis\" from 1120. Paragraph LXVII sets out the fine for wounds of various depths: one inch, one shilling; two inches, two shillings, etc.\nAn Anglo-Saxon unit of length was the barleycorn. After 1066, 1\u00a0inch was equal to 3 barleycorns, which continued to be its legal definition for several centuries, with the barleycorn being the base unit. One of the earliest such definitions is that of 1324, where the legal definition of the inch was set out in a statute of Edward II of England, defining it as \"three grains of barley, dry and round, placed end to end, lengthwise\".\nSimilar definitions are recorded in both English and Welsh medieval law tracts. One, dating from the first half of the 10th century, is contained in the Laws of Hywel Dda which superseded those of Dyfnwal, an even earlier definition of the inch in Wales. Both definitions, as recorded in \"Ancient Laws and Institutes of Wales\" (vol i., pp.\u00a0184, 187, 189), are that \"three lengths of a barleycorn is the inch\".\nKing David I of Scotland in his Assize of Weights and Measures (c. 1150) is said to have defined the Scottish inch as the width of an average man's thumb at the base of the nail, even including the requirement to calculate the average of a small, a medium, and a large man's measures. However, the oldest surviving manuscripts date from the early 14th century and appear to have been altered with the inclusion of newer material.\nIn 1814, Charles Butler, a mathematics teacher at Cheam School, recorded the old legal definition of the inch to be \"three grains of sound ripe barley being taken out the middle of the ear, well dried, and laid end to end in a row\", and placed the barleycorn, not the inch, as the base unit of the English Long Measure system, from which all other units were derived. John Bouvier similarly recorded in his 1843 law dictionary that the barleycorn was the fundamental measure. Butler observed, however, that \"[a]s the length of the barley-corn cannot be fixed, so the inch according to this method will be uncertain\", noting that a standard inch measure was now [i.e. by 1843] kept in the Exchequer chamber, Guildhall, and \"that\" was the legal definition of the inch.\nThis was a point also made by George Long in his 1842 \"Penny Cyclop\u00e6dia\", observing that standard measures had since surpassed the barleycorn definition of the inch, and that to recover the inch measure from its original definition, in case the standard measure were destroyed, would involve the measurement of large numbers of barleycorns and taking their average lengths. He noted that this process would not perfectly recover the standard, since it might introduce errors of anywhere between one hundredth and one tenth of an inch in the definition of a yard.\nBefore the adoption of the international yard and pound, various definitions were in use. In the United Kingdom and most countries of the British Commonwealth, the inch was defined in terms of the Imperial Standard Yard. The United States adopted the conversion factor 1 metre = 39.37 inches by an act in 1866. In 1893, Mendenhall ordered the physical realisation of the inch to be based on the international prototype metres numbers 21 and 27, which had been received from the CGPM, together with the previously adopted conversion factor.\nAs a result of the definitions above, the U.S. inch was effectively defined as 25.4000508\u00a0mm (with a reference temperature of 68 degrees Fahrenheit) and the UK inch at 25.399977\u00a0mm (with a reference temperature of 62 degrees Fahrenheit). When Carl Edvard Johansson started manufacturing gauge blocks in inch sizes in 1912, Johansson's compromise was to manufacture gauge blocks with a nominal size of 25.4mm, with a reference temperature of 20 degrees Celsius, accurate to within a few parts per million of both official definitions. Because Johansson's blocks were so popular, his blocks became the \"de facto\" standard for manufacturers internationally, with other manufacturers of gauge blocks following Johansson's definition by producing blocks designed to be equivalent to his.\nIn 1930, the British Standards Institution adopted an inch of exactly 25.4\u00a0mm. The American Standards Association followed suit in 1933. By 1935, industry in 16 countries had adopted the \"industrial inch\" as it came to be known, effectively endorsing Johansson's pragmatic choice of conversion ratio.\nIn 1946, the Commonwealth Science Congress recommended a yard of exactly 0.9144\u00a0metres for adoption throughout the British Commonwealth. This was adopted by Canada in 1951; the United States on 1 July 1959; Australia in 1961, effective 1 January 1964; and the United Kingdom in 1963, effective on 1 January 1964. The new standards gave an inch of exactly 25.4\u00a0mm, 1.7 millionths of an inch longer than the old imperial inch and 2 millionths of an inch shorter than the old US inch.\nRelated units.\nUS survey inches.\nThe United States retained the -metre definition for surveying, producing a 2 millionth part difference between standard and US survey inches. This is approximately \u00a0inch per mile; 12.7 kilometres is exactly standard inches and exactly survey inches. This difference is substantial when doing calculations in State Plane Coordinate Systems with coordinate values in the hundreds of thousands or millions of feet.\nIn 2020, the National Institute of Standards and Technology announced that the U.S. survey foot would \"be phased out\" on 1 January 2023 and be superseded by the international foot (also known as the foot) equal to 0.3048\u00a0metres exactly, for all further applications. This implies that the survey inch was replaced by the international inch.\nContinental inches.\nBefore the adoption of the metric system, several European countries had customary units whose name translates into \"inch\". The French \"pouce\" measured roughly 27.0\u00a0mm, at least when applied to describe the calibre of artillery pieces. The Amsterdam foot (\"voet\") consisted of 11 Amsterdam inches (\"duim\"). The Amsterdam foot is about 8% shorter than an English foot.\nScottish inch.\nThe now obsolete Scottish inch (), of a Scottish foot, was about 1.0016 imperial inches (about ).\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "14776", "revid": "7903804", "url": "https://en.wikipedia.org/wiki?curid=14776", "title": "Inn", "text": "Establishment providing lodging, food, and drink\nInns are generally establishments or buildings where travelers can seek lodging, and usually, food and drink. Inns are typically located in the country or along a highway. Before the advent of motorized transportation, they also provided accommodation for horses.\nAn innkeeper is the person who runs an inn.\nHistory.\nInns in Europe were possibly first established when the Romans built their system of Roman roads 2,000 years ago. Many inns in Europe are several centuries old. In addition to providing for the needs of travelers, inns traditionally acted as community gathering places.\nHistorically, inns provided not only food and lodging, but stabling and fodder for the travelers' horses, as well. Famous London examples of inns include The George and The Tabard. However, there is no longer a formal distinction between an inn and several other kinds of establishments: many pubs use the name \"inn\", either because they are long established and may have been formerly coaching inns, or to summon up a particular kind of image.\nInns were like bed and breakfasts, with a community dining room which was also used for town meetings or rented for wedding parties. The front, facing the road, was ornamental and welcoming for travelers. The back also usually had at least one livery barn for travelers to keep their horses. There were no lobbies as in modern inns; rather, the innkeeper would answer the door for each visitor and judge the people whom he decided to accommodate, it was up to the visitors to convince the innkeeper for accommodation. In some English towns, bye-laws would require innkeepers to offer all visitors a bed. Many inns were simply large houses that had extra rooms for renting. An inn may have had several uses, for example, Goat Inn, Bottle Bank \"a pub 'where a person could get drunk, commit an offence, and be arrested, tried and sentenced without leaving the building', because it had other rooms which were used as a police station and a court\"\nIn 14th-century England, the courtyards of the inns were often not paved or cobbled but rather flattened earth or mud. These inns would be made of two-story timber framed buildings with steep shingle roofs. Stable boys were in charge of stabling horses at the rear yard of the inn where they are watered and fed. Usual foods served included pottage, bread and cheese with ale for drinking. In some towns, innkeepers are only allowed to offer food and drinks to guests. The better managed inns would place fresh rushes on the floor, mixed with rose petals, lavender and herbs. Lighting would be dim, as candles were made of tallow. For toilet facilities, inns would simply provide a seat and a barrel which were emptied every morning. Beds would accommodate more than one man, sometimes even a dozen.\nDuring the 19th century, the inn played a major role in the growing transportation system of England. Industry was on the rise, and people were traveling more in order to keep and maintain business. The English inn was considered an important part of English infrastructure, as it helped maintain a smooth flow of travel throughout the country.\nAs modes of transport have evolved, tourist lodging has adapted to serve each generation of traveler. A stagecoach made frequent stops at roadside coaching inns for water, food, and horses. A passenger train stopped only at designated stations in the city center, around which were built grand railway hotels. Motorcar traffic on old-style two-lane highways might have paused at any camp, cabin court, or motel along the way, while freeway traffic was restricted to access from designated off-ramps to side roads which quickly become crowded with hotel chain operators.\nThe original functions of an inn are now usually split among separate establishments. For example, hotels, lodges and motels might provide the traditional functions of an inn but focus more on lodging customers than on other services; public houses (pubs) are primarily alcohol-serving establishments; and restaurants and taverns serve food and drink. (Hotels often contain restaurants serving full breakfasts and meals, thus providing all of the functions of traditional inns. Economy, limited service properties, however, lack a kitchen and bar, and therefore claim at most an included continental breakfast.)\nThe lodging aspect of the word \"inn\" lives on in some hotel brand names, like Holiday Inn, and the Inns of Court in London were once accommodations for members of the legal profession. Some laws refer to lodging operators as \"innkeepers\".\nForms.\nOther forms of inns exist throughout the world. Among them are the honjin and ryokan of Japan, caravanserai of Central Asia and the Middle East, and jiuguan in ancient China.\nIn Asia Minor, during the periods of rule by the Seljuk and Ottoman Turks, impressive structures functioning as inns () were built because inns were considered socially significant. These inns provided accommodations for people and either their vehicles or animals, and served as a resting place to those traveling on foot or by other means.\nThese inns were built between towns if the distance between municipalities was too far for one day's travel. These structures, called caravansarais, were inns with large courtyards and ample supplies of water for drinking and other uses. They typically contained a caf\u00e9, in addition to supplies of food and fodder. After the caravans traveled a while they would take a break at these caravansarais, and often spend the night to rest the human travelers and their animals.\nUsage of the term.\nThe term \"inn\" historically characterized a rural hotel which provided lodging, food and refreshments, and accommodations for travelers' horses. To capitalize on this nostalgic image many typically lower end and middling modern motor hotel operators seek to distance themselves from similar motels by styling themselves \"inns\", regardless of services and accommodations provided. Examples are Comfort Inn, Days Inn, Holiday Inn, Knights Inn, and Premier Inn.\nThe term \"inn\" is also retained in its historic use in many laws governing motels and hotels, often known as \"innkeeper's acts\", or refer to h\u00f4teliers and motel operators as \"innkeepers\" in the body of the legislation These laws typically define the innkeepers' liability for valuables entrusted to them by clients and determine whether an innkeeper holds any lien against such goods. In some jurisdictions, an offense named as \"defrauding an innkeeper\" prohibits fraudulently obtaining \"food, lodging, or other accommodation at any hotel, inn, boarding house, or eating house\"; in this context, the term is often an anachronism as the majority of modern restaurants are free-standing and not attached to coaching inns or tourist lodging."}
{"id": "14777", "revid": "51007625", "url": "https://en.wikipedia.org/wiki?curid=14777", "title": "International Olympiad in Informatics", "text": "Annual programming competition\nThe International Olympiad in Informatics (IOI) is an annual competitive programming competition and one of the International Science Olympiads for secondary school students. The first IOI was held in 1989 in Pravetz, Bulgaria.\nEach country sends a team of up to four students, plus one team leader, one deputy leader, and guests. Students in each country are selected for their country's team through national computing contests. Students at the IOI compete on an individual basis. There is no official team ranking.\nThe contest consists of two days of solving six complicated algorithmic tasks by writing computer programs in C++. All task materials are published on each year's contest website soon after the competition ends.\nCompetition structure and participation.\nOn each of the two competition days, the competitors are typically given three problems which they have to solve in five hours. Each student works on their own to solve the problems with no outside help, specifically no communication with other contestants, books, web access, etc. Contestants are typically allowed to bring non-programmable wired keyboards and mice. Usually to solve a task the contestant has to write a computer program (in C++) and submit it before the five-hour competition time ends. The program is graded based on secret test data. Since IOI 2010, tasks are divided into subtasks with graduated difficulty, and points are awarded only when all tests for a particular subtask yield correct results, within specific time and memory limits. In some cases, the contestant's program has to interact with a secret computer library, which allows problems where the input is not fixed, but depends on the program's actions \u2013 for example in game problems (a.k.a. interactive problems). Another type of problem has the inputs publicly available, for these, the contestants have to submit an output file instead of a program, and it is up to them whether they obtain the output files by writing a program (possibly exploiting special characteristics of the input), or by hand, or by a combination of these means. Pascal has been removed as an available programming language as of 2019.:11\nIOI 2010 for the first time had a live web scoreboard with real-time provisional results. Submissions will be scored as soon as possible during the contest, and the results posted. Contestants will be aware of their scores, but not others', and may resubmit to improve their scores. Starting from 2012, IOI has been using the Contest Management System (CMS) for developing and monitoring the contest.\nThe scores from the two competition days and all problems are summed up separately for each contestant. Medals are awarded depending on their relative total score. The top 50% of the contestants are awarded medals, such that the relative number of gold : silver : bronze : no medal is approximately 1:2:3:6 (thus 1/12 of the contestants get a gold medal).\nPrior to IOI 2010, students who did not receive medals did not have their scores published, although the scores of students who did not receive medals are still not available in the official results, they are known from the live web scoreboard. In IOI 2012 the top 3 nations ranked by aggregate score (Russia, China and USA) were subsequently awarded during the closing ceremony.\nAnalysis of female performance shows 77.9% of women obtain no medal, while 49.2% of men obtain no medal. \"The average female participation was 4.4% in 1989\u20131994 and 2.2% in 1996\u20132014.\" It also suggests much higher participation of women on the national level, claiming sometimes double-digit percentages in total participation on the first stage. President of the IOI (2011-2014), Richard Forster, says the competition has difficulty attracting women and that in spite of trying to solve it, \"none of us have hit on quite what the problem is, let alone the solution.\" The European Girls\u2019 Olympiad in Informatics (EGOI), which was first held in 2021 was started with the goal to increscent female participants at IOI and other Informatics Olympiads.\nIn IOI 2017 held in Iran, due to not being able to participate in Iran, the Israeli students participated in an offsite competition organized by IOI in Russia.:11 Due to visa issues, the full USA team was unable to attend, although one contestant Zhezheng Luo was able to attend by traveling with the Chinese team and winning gold medal and 3rd place in standings.\nIn IOI 2019 held in Azerbaijan, the Armenia team did not participate due to the dispute between the two countries, despite the guarantees provided and official invitation letter sent by the host Azerbaijan.\nDue to the COVID-19 pandemic, both the IOI 2020 and IOI 2021, originally scheduled to be hosted by Singapore, were held as online contests. The IOI 2022, hosted by Indonesia, was held as a hybrid event, with around 25% of the contestants participating online.\nIn response to the invasion of Ukraine, students from Russia and Belarus can only participate as individuals under the IOI flag but not as national delegations starting from IOI 2022, and they would only participate online for IOI 2022. From 2023 onwards they would participate in person, but under the IOI flag.\nIn response to the conflict and humanitarian crisis in Gaza, students from Israel can only participate as individuals under the IOI flag but not as a national delegation from IOI 2025 onwards. Over two thirds of the delegations voted in favour of the sanction in the IOI General Assembly.\nMembers.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nFormer members.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nTop Performances.\nThe following is a list of the top performers in the history of the IOI, with the list containing any contestant with at least 3 gold medals. The P sign indicates a perfect score, a rare achievement in IOI history. The U sign indicates an unofficial participation, where a contestant participated in a host's second team. Also, first (I), second (II) and third (III) places among gold medalists are indicated where appropriate.\nFeeder competitions.\nMost participating countries use feeder competitions to select their team. They are usually referred to as National Olympiad in Informatics and is the course of selection of the country's top team or persons to participate in the IOI. A number of these are listed below:\n1.&lt;templatestyles src=\"Citation/styles.css\"/&gt;^a IOI 2020 virtual closing ceremony was held on September 23, 2020.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "14779", "revid": "90654", "url": "https://en.wikipedia.org/wiki?curid=14779", "title": "Iota", "text": "Ninth letter in the Greek alphabet\n \nIota (; , uppercase \u0399, lowercase \u03b9; ) is the ninth letter of the Greek alphabet. It was derived from the Phoenician letter Yodh. Letters that arose from this letter include the Latin I and J, the Cyrillic \u0406 (\u0406, \u0456), Yi (\u0407, \u0457), and Je (\u0408, \u0458), and iotated letters (e.g. Yu (\u042e, \u044e)). In the system of Greek numerals, iota has a value of 10.\nIota represents the close front unrounded vowel . In early forms of ancient Greek, it occurred in both long and short versions, but this distinction was lost in Koine Greek. Iota participated as the second element in falling diphthongs, with both long and short vowels as the first element. Where the first element was long, the iota was lost in pronunciation at an early date, and was written in polytonic orthography as iota subscript, in other words as a very small \u03b9 under the main vowel. Examples include \u1fbc \u1fb3 \u1fcc \u1fc3 \u1ffc \u1ff3. The former diphthongs became digraphs for simple vowels in Koine Greek.\nThe word is used in a common English phrase, \"not one iota\", meaning \"not the slightest amount\". This refers to iota, the smallest letter, or possibly yodh, \u05d9, the smallest letter in the Hebrew alphabet. The English word \"jot\" derives from iota. The German, Polish, Portuguese, and Spanish name for the letter J (\"Jot\" / \"jota\") is derived from iota.\nUnicode.\nFor accented Greek characters, see Greek diacritics: Computer encoding.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "14780", "revid": "47555821", "url": "https://en.wikipedia.org/wiki?curid=14780", "title": "ISP (disambiguation)", "text": "ISP often refers to Internet service provider.\nISP may also refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nScience and technology.\nOther uses in science and technology.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "14783", "revid": "7611264", "url": "https://en.wikipedia.org/wiki?curid=14783", "title": "Erectile dysfunction", "text": "Form of sexual dysfunction in males\nMedical condition&lt;templatestyles src=\"Template:Infobox/styles-images.css\" /&gt;\nErectile dysfunction (ED), also referred to as impotence, is a form of sexual dysfunction in males characterized by the persistent or recurring inability to achieve or maintain a penile erection with sufficient rigidity and duration for satisfactory sexual activity. It is the most common sexual problem in males and can cause psychological distress due to its impact on self-image and sexual relationships. The term \"erectile dysfunction\" does not encompass other erection-related disorders, such as priapism.\nThe majority of ED cases are attributed to physical risk factors and predictive factors. These factors can be categorized as vascular, neurological, local penile, hormonal, and drug-induced. Notable predictors of ED include aging, cardiovascular disease, diabetes mellitus, high blood pressure, obesity, abnormal lipid levels in the blood, hypogonadism, smoking, depression, and medication use. Approximately 10% of cases are linked to psychosocial factors, encompassing conditions such as depression, stress, and problems within relationships. ED is reported in 18% of males aged 50 to 59 years, and 37% in males aged 70 to 75.\nTreatment of ED encompasses addressing the underlying causes, lifestyle modification, and addressing psychosocial issues. In many instances, medication-based therapies are used, specifically PDE5 inhibitors such as sildenafil. These drugs function by dilating blood vessels, facilitating increased blood flow into the spongy tissue of the penis, analogous to opening a valve wider to enhance water flow in a fire hose. Less frequently employed treatments encompass prostaglandin pellets inserted into the urethra, the injection of smooth-muscle relaxants and vasodilators directly into the penis, penile implants, the use of penis pumps, and vascular surgery.\nSigns and symptoms.\nED is characterized by the persistent or recurring inability to achieve or maintain an erection of the penis with sufficient rigidity and duration for satisfactory sexual activity. It is defined as the \"persistent or recurrent inability to achieve and maintain a penile erection of sufficient rigidity to permit satisfactory sexual activity for at least 3 months.\"\nPsychological impact.\nED often has an impact on the emotional well-being of both males and their partners. Many males do not seek treatment due to feelings of embarrassment. About 75% of diagnosed cases of ED go untreated.\nCauses.\nCauses of or contributors to ED include the following:\nSurgical intervention for a number of conditions may remove anatomical structures necessary to erection, damage nerves, or impair blood supply. ED is a common complication of treatments for prostate cancer, including prostatectomy and destruction of the prostate by external beam radiation, although the prostate gland itself is not necessary to achieve an erection. As far as inguinal hernia surgery is concerned, in most cases, and in the absence of postoperative complications, the operative repair can lead to a recovery of the sexual life of people with preoperative sexual dysfunction, while, in most cases, it does not affect people with a preoperative normal sexual life.\nED can also be associated with bicycling due to both neurological and vascular problems due to compression. The increased risk appears to be about 1.7-fold.\nConcerns that use of pornography can cause ED have little support in epidemiological studies, according to a 2015 literature review. According to Gunter de Win, a Belgian professor and sex researcher, \"Put simply, respondents who watch 60 minutes a week and think they're addicted were more likely to report sexual dysfunction than those who watch a care-free 160 minutes weekly.\"\nIn seemingly rare cases, medications such as SSRIs, isotretinoin (Accutane) and finasteride (Propecia) are reported to induce long-lasting iatrogenic disorders characterized by sexual dysfunction symptoms, including erectile dysfunction in males; these disorders are known as post-SSRI sexual dysfunction (PSSD), post-retinoid sexual dysfunction/post-Accutane syndrome (PRSD/PAS), and post-finasteride syndrome (PFS). These conditions remain poorly understood and lack effective treatments, although they have been suggested to share a common etiology.\nPathophysiology.\nPenile erection is managed by two mechanisms: the reflex erection, which is achieved by directly touching the penile shaft, and the psychogenic erection, which is achieved by erotic or emotional stimuli. The former involves the peripheral nerves and the lower parts of the spinal cord, whereas the latter involves the limbic system of the brain. In both cases, an intact neural system is required for a successful and complete erection. Stimulation of the penile shaft by the nervous system leads to the secretion of nitric oxide (NO), which causes the relaxation of the smooth muscles of the corpora cavernosa (the main erectile tissue of the penis), and subsequently penile erection. Additionally, adequate levels of testosterone (produced by the testes) and an intact pituitary gland are required for the development of a healthy erectile system. As can be understood from the mechanisms of a normal erection, impotence may develop due to hormonal deficiency, disorders of the neural system, lack of adequate penile blood supply or psychological problems. \nDiagnosis.\nIn many cases, the diagnosis can be made based on the person's history of symptoms. In other cases, a physical examination and laboratory investigations are done to rule out more serious causes such as hypogonadism or prolactinoma.\nOne of the first steps is to distinguish between physiological and psychological ED. Determining whether involuntary erections are present is important in eliminating the possibility of psychogenic causes for ED. Obtaining full erections occasionally, such as nocturnal penile tumescence when asleep (that is, when the mind and psychological issues, if any, are less present), tends to suggest that the physical structures are functionally working. Similarly, performance with manual stimulation, as well as any performance anxiety or acute situational ED, may indicate a psychogenic component to ED.\nAnother factor leading to ED is diabetes mellitus, a well known cause of neuropathy. ED is also related to generally poor physical health, poor dietary habits, obesity, and most specifically cardiovascular disease, such as coronary artery disease and peripheral vascular disease. Screening for cardiovascular risk factors, such as smoking, dyslipidemia, hypertension, and alcoholism, is helpful.\nIn some cases, the simple search for a previously undetected groin hernia can prove useful since it can affect sexual functions in males and is relatively easily curable.\nThe current\u00a0\u2013 as of April\u00a02025[ [update]]\u00a0\u2013 edition of the \"Diagnostic and Statistical Manual of Mental Disorders\" (DSM-5-TR) lists \"Erectile Disorder\" (ICD-10-CM code: F52.21) as a diagnosis. According to the DSM, it \"is the more specific DSM-5 diagnostic category in which erectile dysfunction persists for at least 6 months and causes distress in the individual.\" The ICD-10, to which the DSM refers regarding \"Erectile dysfunction\", lists it under \"Failure of genital response\" (F52.2). The latest edition of the ICD\u00a0\u2013 namely, the ICD-11\u00a0\u2013 lists the condition as \"Male erectile dysfunction\" (https://).\nUltrasonography.\nPenile ultrasonography with doppler can be used to examine the erect penis. Most cases of ED of organic causes are related to changes in blood flow in the corpora cavernosa, represented by occlusive artery disease (in which less blood is allowed to enter the penis), most often of atherosclerotic origin, or due to failure of the veno-occlusive mechanism (in which too much blood circulates back out of the penis). Before the Doppler sonogram, the penis should be examined in B mode, in order to identify possible tumors, fibrotic plaques, calcifications, or hematomas, and to evaluate the appearance of the cavernous arteries, which can be tortuous or atheromatous.\nErection can be induced by injecting 10\u201320\u00a0\u03bcg of prostaglandin E1, with evaluations of the arterial flow every five minutes for 25\u201330\u00a0min (see image). The use of prostaglandin E1 is contraindicated in patients with predisposition to priapism (e.g., those with sickle cell anemia), anatomical deformity of the penis, or penile implants. Phentolamine (2\u00a0mg) is often added. Visual and tactile stimulation produces better results. Some authors recommend the use of sildenafil by mouth to replace the injectable drugs in cases of contraindications, although the efficacy of such medication is controversial.\nBefore the injection of the chosen drug, the flow pattern is monophasic, with low systolic velocities and an absence of diastolic flow. After injection, systolic and diastolic peak velocities should increase, decreasing progressively with vein occlusion and becoming negative when the penis becomes rigid (see image below). The reference values vary across studies, ranging from &gt; 25\u00a0cm/s to &gt; 35\u00a0cm/s. Values above 35\u00a0cm/s indicate the absence of arterial disease, values below 25\u00a0cm/s indicate arterial insufficiency, and values of 25\u201335\u00a0cm/s are indeterminate because they are less specific (see image below). The data obtained should be correlated with the degree of erection observed. If the peak systolic velocities are normal, the final diastolic velocities should be evaluated, those above 5\u00a0cm/s being associated with venogenic ED.\nTreatment.\nTreatment depends on the underlying cause. In general, exercise, particularly of the aerobic type, is effective for preventing ED during midlife. Counseling can be used if the underlying cause is psychological, including how to lower stress or anxiety related to sex. Medications by mouth and vacuum erection devices are first-line treatments, followed by injections of drugs into the penis, as well as penile implants. Vascular reconstructive surgeries are beneficial in certain groups. Treatments, other than surgery, do not fix the underlying physiological problem, but are used as needed before sex.\nMedications.\nThe PDE5 inhibitors sildenafil (Viagra), vardenafil (Levitra) and tadalafil (Cialis) are prescription drugs which are taken by mouth. As of 2018, sildenafil is available in the UK without a prescription. Additionally, a cream combining alprostadil with the permeation enhancer DDAIP has been approved in Canada as a first line treatment for ED. Penile injections, on the other hand, can involve one of the following medications: papaverine, phentolamine, and prostaglandin E1, also known as alprostadil. In addition to injections, there is an alprostadil suppository that can be inserted into the urethra. Once inserted, an erection can begin within 10 minutes and last up to an hour. Medications to treat ED may cause a side effect called priapism.\nPrevalence of medical diagnosis.\nIn a study published in 2016, based on US health insurance claims data, out of 19,833,939 US males aged \u226518 years, only 1,108,842 (5.6%), were medically diagnosed with erectile dysfunction or on a PDE5I prescription (\"\u03bc\" age 55.2 years, \"\u03c3\" 11.2 years). Prevalence of diagnosis or prescription was the highest for age group 60\u201369 at 11.5%, lowest for age group 18\u201329 at 0.4%, and 2.1% for 30\u201339, 5.7% for 40\u201349, 10% for 50\u201359, 11% for 70\u201379, 4.6% for 80\u201389, 0.9% for \u226590, respectively.\nFocused shockwave therapy.\nFocused shockwave therapy involves passing short, high frequency acoustic pulses through the skin and into the penis. These waves break down any plaques within the blood vessels, encourage the formation of new vessels, and stimulate repair and tissue regeneration.\nFocused shockwave therapy appears to work best for males with vasculogenic ED, which is a blood vessel disorder that affects blood flow to tissue in the penis. The treatment is painless and has no known side effects. Treatment with shockwave therapy can lead to a significant improvement of the IIEF (International Index of Erectile Function).\nTestosterone.\nMen with low levels of testosterone can experience ED. Taking testosterone may help maintain an erection. Males with type 2 diabetes are twice as likely to have lower levels of testosterone, and are three times more likely to experience ED than non-diabetic men.\nPumps.\nA vacuum erection device helps draw blood into the penis by applying negative pressure. This type of device is sometimes referred to as penis pump and may be used just prior to sexual intercourse. Several types of FDA approved vacuum therapy devices are available under prescription. When pharmacological methods fail, a purpose-designed external vacuum pump can be used to attain erection, with a separate compression ring fitted to the base of the penis to maintain it. These pumps should be distinguished from other penis pumps (supplied without compression rings) which, rather than being used for temporary treatment of impotence, are claimed to increase penis length if used frequently, or vibrate as an aid to masturbation. More drastically, inflatable or rigid penile implants may be fitted surgically.\nVibrators.\nThe vibrator was invented in the late 19th century as a medical instrument for pain relief and the treatment of various ailments. Sometimes described as a massager, the vibrator is used on the body to produce sexual stimulation. Several clinical studies have found vibrators to be an effective solution for Erectile Dysfunction. Examples of FDA registered vibrators for erectile dysfunction include MysteryVibe's Tenuto and Reflexonic's Viberect.\nSurgery.\nOften, as a last resort, if other treatments have failed, the most common procedure is prosthetic implants which involves the insertion of artificial rods into the penis. Some sources show that vascular reconstructive surgeries are viable options for some people.\nAlternative medicine.\nThe Food and Drug Administration (FDA) does not recommend alternative therapies to treat sexual dysfunction. Many products are advertised as \"herbal viagra\" or \"natural\" sexual enhancement products, but no clinical trials or scientific studies support the effectiveness of these products for the treatment of ED, and synthetic chemical compounds similar to sildenafil have been found as adulterants in many of these products. The FDA has warned consumers that any sexual enhancement product that claims to work as well as prescription products is likely to contain such a contaminant. A 2021 review indicated that ginseng had \"only trivial effects on erectile function or satisfaction with intercourse compared to placebo\".\nHistory.\nAttempts to treat the symptoms described by ED date back well over 1,000 years. In the 8th century, males of Ancient Rome and Greece wore talismans of rooster and goat genitalia, believing these talismans would serve as an aphrodisiac and promote sexual function. In the 13th century, Albertus Magnus recommended ingesting roasted wolf penis as a remedy for impotence. During the late 16th and 17th centuries in France, male impotence was considered a crime, as well as legal grounds for a divorce. The practice, which involved inspection of the complainants by court experts, was declared obscene in 1677.\nThe first major publication describing a broad medicalization of sexual disorders was the first edition of the \"Diagnostic and Statistical Manual of Mental Disorders\" in 1952. In the early 20th century, medical folklore held that 90-95% of cases of ED were psychological in origin, but around the 1980s research took the opposite direction of searching for physical causes of sexual dysfunction, which also happened in the 1920s and 30s. Physical causes as explanations continue to dominate literature when compared with psychological explanations as of 2022[ [update]]. \nTreatments in the 80s for ED included penile implants and intracavernosal injections. The first successful vacuum erection device, or penis pump, was developed by Vincent Marie Mondat in the early 1800s. A more advanced device based on a bicycle pump was developed by Geddings Osbon, a Pentecostal preacher, in the 1970s. In 1982, he received FDA approval to market the product. John R. Brinkley initiated a boom in male impotence treatments in the U.S. in the 1920s and 1930s, with radio programs that recommended expensive goat gland implants and \"mercurochrome\" injections as the path to restored male virility, including operations by surgeon Serge Voronoff.\nModern drug therapy for ED made a significant advance in 1983, when British physiologist Giles Brindley dropped his trousers and demonstrated to a shocked Urodynamics Society audience showing his papaverine-induced erection. The current most common treatment for ED, the oral PDE5 inhibitor known as sildenafil (Viagra) was approved for use for Pfizer by the FDA in 1998, which at the time of release was the fastest selling drug in history. Sildenafil largely replaced SSRI treatments for ED at the time and proliferated new types of specialised pharmaceutical marketing which emphasised social connotations of ED and Viagra rather than its physical effects.\nAnthropology.\nAnthropological research presents ED not as a disorder but, as a normal, and sometimes even welcome sign of healthy aging. Wentzell's study of 250 Mexican males in their 50s and 60s found that \"most simply did not see decreasing erectile function as a biological pathology\". The males interviewed described the decrease in erectile function \"as an aid for aging in socially appropriate ways\". A common theme amongst the interviewees showed that respectable older males shifted their focus toward the domestic sphere into a \"second stage of life\". The Mexican males of this generation often pursued sex outside of marriage; decreasing erectile function acted as an aid to overcoming infidelity thus helping to attain the ideal \"second stage\" of life. A 56-year-old about to retire from the public health service said he would now \"dedicate myself to my wife, the house, gardening, caring for the grandchildren\u2014the Mexican classic\". Wentzell found that treating ED as a pathology was antithetical to the social view these males held of themselves, and their purpose at this stage of their lives.\nIn the 20th and 21st centuries, anthropologists investigated how common treatments for ED are built upon assumptions of institutionalized social norms. In offering a range of clinical treatments to 'correct' a person's ability to produce an erection, biomedical institutions encourage the public to strive for prolonged sexual function. Anthropologists argue that a biomedical focus places emphasis on the biological processes of fixing the body thereby disregarding holistic ideals of health and aging. By relying on a wholly medical approach, Western biomedicine can become blindsided by bodily dysfunctions which can be understood as appropriate functions of age, and not as a medical problem. Anthropologists understand that a biosocial approach to ED considers a person's decision to undergo clinical treatment more likely a result of \"society, political economy, history, and culture\" than a matter of personal choice. In rejecting biomedical treatment for ED, males can challenge common forms of medicalized social control by deviating from what is considered the normal approach to dysfunction.\nLexicology.\nThe Latin term \"impotentia coeundi\" describes simple inability to insert the penis into the vagina; it is now mostly replaced by more precise terms, such as \"erectile dysfunction\" (ED). The study of ED within medicine is covered by andrology, a sub-field within urology. Research indicates that ED is common, and it is suggested that approximately 40% of males experience symptoms compatible with ED, at least occasionally. The condition is also on occasion called \"phallic impotence\". Its antonym, or opposite condition, is priapism.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "14787", "revid": "37005538", "url": "https://en.wikipedia.org/wiki?curid=14787", "title": "Iran\u2013Contra affair", "text": "1985\u20131987 political scandal in the U.S.\nThe Iran\u2013Contra affair (; ), also referred to as the Iran\u2013Contra scandal, the Iran Initiative, or simply Iran\u2013Contra, was a political scandal in the United States that centered on arms trafficking to Iran between 1981 and 1986, facilitated by senior officials of the Ronald Reagan administration. The administration hoped to use the proceeds of the arms sale to fund the Contras, an anti-Sandinista rebel group in Nicaragua. Under the Boland Amendments, a series of laws passed by Congress and signed by Reagan, further funding of the Contras by legislative appropriations was prohibited by Congress, but the Reagan administration continued funding them secretly using non-appropriated funds.\nThe administration's justification for the arms shipments was that they were part of an attempt to free seven U.S. hostages being held in Lebanon by Hezbollah, an Islamist paramilitary group connected to Iran's Islamic Revolutionary Guard Corps. The idea to exchange arms for hostages was proposed by Manucher Ghorbanifar, an expatriate Iranian arms dealer. Some within the Reagan administration hoped the sales would influence Iran to get Hezbollah to release the hostages.\nAfter the Lebanese magazine \"Ash-Shiraa\" reported on the weapon dealings in November 1986, it broke international news, prompting Reagan to appear on national television. He claimed that while the weapons transfers had indeed occurred, the U.S. did not trade arms for hostages. The investigation was impeded when large volumes of documents relating to the affair were destroyed or withheld from investigators by Reagan administration officials. In March 1987, Reagan made a further nationally televised address, saying he was taking full responsibility for the affair and stating that \"what began as a strategic opening to Iran deteriorated, in its implementation, into trading arms for hostages.\"\nThe affair was investigated by Congress and by the three-person, Reagan-appointed Tower Commission. Neither investigation found evidence that President Reagan himself knew of the extent of the multiple programs. Additionally, U.S. Deputy Attorney General Lawrence Walsh was appointed independent counsel in December 1986 to investigate possible criminal actions by officials involved in the scheme. In the end, several dozen administration officials were indicted, including Secretary of Defense Caspar Weinberger and Lieutenant Colonel Oliver North. Eleven convictions resulted, some of which were vacated on appeal. The rest of those indicted or convicted were all pardoned in the final days of the presidency of George H. W. Bush, who had been vice president at the time of the affair. Only one Iran\u2013Contra defendant served a prison sentence, some others received probation, and some others had trials pending and then received a pardon. Former Independent Counsel Walsh noted that, in issuing the pardons, Bush appeared to have been preempting being implicated himself by evidence that came to light during the Weinberger trial and noted that there was a pattern of \"deception and obstruction\" by Bush, Weinberger, and other senior Reagan administration officials. Walsh submitted his final report on 4 August 1993 and later wrote an account of his experiences as counsel, \"Firewall: The Iran-Contra Conspiracy and Cover-Up\".\nBackground.\nPrior to the Iranian Revolution, the U.S. was the largest seller of arms to Iran under Mohammad Reza Pahlavi, and the vast majority of the weapons that the Islamic Republic of Iran inherited in January 1979 were U.S.-made. To maintain this arsenal, Iran required a steady supply of spare parts to replace those broken and worn out.\nIn November 1979, after Iranian students stormed the U.S. embassy in Tehran and took 66 Americans hostage, U.S. President Jimmy Carter imposed an arms embargo on Iran. In September 1980, Iraq invaded Iran and Iran desperately needed weapons and spare parts for its current weaponry. After Ronald Reagan took office as president on 20 January 1981 and the hostages were released, he vowed to continue Carter's policy of blocking arms sales to Iran on the grounds that Iran supported terrorism. However, a group of senior Reagan administration officials in the Senior Interdepartmental Group conducted a secret study on 21 July 1981 and concluded that the arms embargo was ineffective because Iran could always buy arms and spare parts for its U.S. weapons elsewhere, while, at the same time, the arms embargo opened the door for Iran to fall into the Soviet sphere of influence as the Kremlin could sell Iran weapons if the U.S. would not. The conclusion was that the U.S. should start selling Iran arms as soon as it was politically possible. This was made more difficult politically due to Ayatollah Khomeini's openly declared goal of exporting his Islamic revolution all over the Middle East and overthrowing the governments of Iraq, Kuwait, Saudi Arabia, and the other states around the Persian Gulf, which led to the Americans perceiving Khomeini as a major threat to the U.S.\nIn the spring of 1983, the U.S. launched Operation Staunch, a wide-ranging diplomatic effort to persuade other nations all over the world not to sell arms or spare parts for weapons to Iran. This was at least part of the reason the Iran\u2013Contra affair proved so humiliating for the U.S. when the story first broke in November 1986 that the U.S. itself was selling arms to Iran.\nAt the same time that the U.S. government was considering its options on selling arms to Iran, Contra militants based in Honduras were waging a guerrilla war to topple the FSLN revolutionary government of Nicaragua. Almost from the time he took office in 1981, a major goal of the Reagan administration was the overthrow of the left-wing Sandinista government in Nicaragua and to support the Contra rebels.\nThe Reagan administration's policy toward Nicaragua produced a major clash between the executive and legislative branches as Congress sought to limit, if not curb altogether, the ability of the White House to support the Contras. Direct U.S. funding of the Contras insurgency was made illegal through the Boland Amendment, the name given to three U.S. legislative amendments between 1982 and 1984 aimed at limiting U.S. government assistance to Contra militants. By 1984, funding for the Contras had run out; and, in October of that year, a total ban came into effect. The second Boland Amendment, in effect from 3 October 1984 to 3 December 1985, stated:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;During the fiscal year 1985 no funds available to the Central Intelligence Agency, the Department of Defense or any other agency or entity of the United States involved in intelligence activities may be obligated or expended for the purpose of or which may have the effect of supporting directly or indirectly military or paramilitary operations in Nicaragua by any nation, organization, group, movement, or individual.\nIn violation of the Boland Amendment, senior officials of the Reagan administration continued to secretly arm and train the Contras and provide arms to Iran, an operation they called \"the Enterprise\". Given the Contras' heavy dependence on U.S. military and financial support, the second Boland Amendment threatened to break the Contra movement and led to President Reagan ordering in 1984 that the NSC \"keep the Contras together 'body and soul'\", no matter what Congress voted for.\nA major legal debate at the center of the Iran\u2013Contra affair concerned the question of whether the National Security Council (or NSC) was part of the \"any other agency or entity of the United States involved in intelligence activities\" covered by the Boland Amendment. The Reagan administration argued it was not, and many in Congress argued that it was. The majority of constitutional scholars have asserted the NSC did indeed fall within the purview of the second Boland Amendment, though the amendment did not mention the NSC by name.\nThe broader constitutional question at stake was the power of Congress versus the power of the presidency. The Reagan administration argued that, because the constitution assigned the right to conduct foreign policy to the executive, its efforts to overthrow the government of Nicaragua were a presidential prerogative that Congress had no right to try to halt via the Boland Amendments. By contrast, congressional leaders argued that the constitution had assigned Congress control of the budget, and Congress had every right to use that power not to fund projects they disapproved of, such as attempting to overthrow the government of Nicaragua.\nAs part of the effort to circumvent the Boland Amendment, the NSC established \"the Enterprise\", an arms-smuggling network headed by a retired U.S. Air Force officer turned arms dealer Richard Secord that supplied arms to the Contras. It was ostensibly a private sector operation, but in fact was controlled by the NSC. To fund \"the Enterprise\", the Reagan administration was constantly on the look-out for funds that came from outside the U.S. government, thus not technically violating the exact phrasing of the Amendment regardless of the money's ultimate purpose. Ironically, military aid to the Contras was reinstated with congressional consent in October 1986, a month before the scandal broke.\nIn his 1995 memoir \"My American Journey\", General Colin Powell, the U.S. Deputy National Security Advisor, wrote that the weapons sales to Iran were used \"for purposes prohibited by the elected representatives of the American people [...] in a way that avoided accountability to the President and Congress. It was wrong.\"\nIn 1985, Panamanian dictator Manuel Noriega offered to help the U.S. by allowing Panama as a staging ground for operations against the FSLN and offering to train Contras in Panama, but this would later be overshadowed by the Iran\u2013Contra affair itself. At around the same time, the Soviet Bloc also engaged in arms deals with ideologically opponent buyers, possibly involving some of the same players as the Iran\u2013Contra affair. In 1986, a complex operation involving East Germany's Stasi and the Danish-registered ship \"Pia Vesta\" ultimately aimed to sell Soviet arms and military vehicles to South Africa's Armscor, using various intermediaries to distance themselves from the deal. Noriega was apparently one of these intermediaries but backed out on the deal as the ship and weapons were seized at a Panamanian port. The \"Pia Vesta\" led to a small controversy, as the Panamanian and Peruvian governments in 1986 accused the U.S. and each other of being involved in the East Germany-originated shipment.\nArms sales to Iran.\nAs reported in \"The New York Times\" in 1991, \"continuing allegations that Reagan campaign officials made a deal with the Iranian Government of Ayatollah Ruhollah Khomeini in the fall of 1980\" led to \"limited investigations\". However \"limited\", those investigations established that \"Soon after taking office in 1981, the Reagan Administration secretly and abruptly changed United States policy.\" Secret Israeli arms sales and shipments to Iran began in that year, even as, in public, the Reagan administration presented a different face, and \"aggressively promoted a public campaign [...] to stop worldwide transfers of military goods to Iran\". \"The New York Times\" explains: \"Iran at that time was in dire need of arms and spare parts for its American-made arsenal to defend itself against Iraq, which had attacked it in September 1980\", while \"Israel [a US ally] was interested in keeping the war between Iran and Iraq going to ensure that these two potential enemies remained preoccupied with each other\". Major General Avraham Tamir, a high-ranking Israeli Defense Ministry official in 1981, said there was an \"oral agreement\" to allow the sale of \"spare parts\" to Iran. This was based on an \"understanding\" with Secretary of State Alexander Haig (which a Haig adviser denied). This account was confirmed by a former senior US diplomat with a few modifications. The diplomat claimed that \"[Ariel] Sharon violated it, and Haig backed away\". A former \"high-level\" Central Intelligence Agency (CIA) official who saw reports of arms sales to Iran by Israel in the early 1980s estimated that the total was about $2 billion a year\u2014but also said, \"The degree to which it was sanctioned I don't know.\"\nOn or about 11 June 1985, a draft National Security Decision Directive was written at the behest of National Security Adviser Robert McFarlane which called for the US to begin a rapprochement with the Islamic Republic of Iran. The paper read:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Dynamic political evolution is taking place inside Iran. Instability caused by the pressures of the Iraq-Iran war, economic deterioration and regime in-fighting create the potential for major changes inside Iran. The Soviet Union is better positioned than the U.S. to exploit and benefit from any power struggle that results in changes from the Iranian regime [...]. The U.S. should encourage Western allies and friends to help Iran meet its import requirements so as to reduce the attractiveness of Soviet assistance [...]. This includes provision of selected military equipment.\nDefense Secretary Caspar Weinberger was highly negative, writing on his copy of McFarlane's paper: \"This is almost too absurd to comment on [...] like asking Qaddafi to Washington for a cozy chat.\" Secretary of State George Shultz was also opposed, asking that having designated Iran a State Sponsor of Terrorism in January 1984, how could the US possibly sell arms to Iran? Only the Director of the CIA William J. Casey supported McFarlane's plan to start selling arms to Iran.\nIn early July 1985, the historian Michael Ledeen, a consultant of National Security Adviser Robert McFarlane, requested assistance from Israeli Prime Minister Shimon Peres for help in the sale of arms to Iran. Having talked to an Israeli diplomat David Kimche and Ledeen, McFarlane learned that the Iranians were prepared to have Hezbollah release US hostages in Lebanon in exchange for Israelis shipping Iran US weapons. Having been designated a State Sponsor of Terrorism since January 1984, Iran was in the midst of the Iran\u2013Iraq War and could find few Western nations willing to supply it with weapons. The idea behind the plan was for Israel to ship weapons through an intermediary (identified as Manucher Ghorbanifar) to the Islamic Republic as a way of aiding a supposedly moderate, politically influential faction within the regime of Ayatollah Khomeini who was believed to be seeking a rapprochement with the US; after the transaction, the US would reimburse Israel with the same weapons, while receiving monetary benefits. McFarlane in a memo to Shultz and Weinberger wrote:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The short term dimension concerns the seven hostages; the long term dimension involves the establishment of a private dialogue with Iranian officials on the broader relations [...]. They sought specifically the delivery from Israel of 100 TOW missiles [...].\nThe plan was discussed with President Reagan on 18 July 1985 and then again on 6 August 1985. Shultz at the latter meeting warned Reagan that \"we were just falling into the arms-for-hostages business and we shouldn't do it\".\nThe Americans believed that there was a moderate faction within the Islamic Republic headed by Akbar Hashemi Rafsanjani, the powerful speaker of the \"Majlis\" who was seen as a leading potential successor to Khomeini and who was alleged to want a rapprochement with the US. The Americans believed that Rafsanjani had the power to order Hezbollah to free the US hostages and establishing a relationship with him by selling Iran arms would ultimately place Iran back within the US sphere of influence. It remains unclear if Rafsanjani really wanted a rapprochement with the US or was just deceiving Reagan administration officials who were willing to believe that he was a moderate who would effect a rapprochement. Rafsanjani, whose nickname was \"the Shark\", was described by the UK journalist Patrick Brogan as a man of great charm and formidable intelligence known for his subtlety and ruthlessness whose motives in the Iran\u2013Contra affair remain completely mysterious. The Israeli government required that the sale of arms meet high-level approval from the US government, and, when McFarlane convinced them that the US government approved the sale, Israel obliged by agreeing to sell the arms.\nIn 1985, President Reagan entered Walter Reed National Military Medical Center for colon cancer surgery. Reagan's recovery was nothing short of miserable, as the 74-year-old President admitted having little sleep for days in addition to his immense physical discomfort. While doctors seemed to be confident that the surgery was successful, the discovery of his localized cancer was a daunting realization for Reagan. From seeing the recovery process of other patients, as well as medical \"experts\" on television predicting his death to be soon, Reagan's typical optimistic outlook was dampened. These factors were bound to contribute to psychological distress in the midst of an already distressing situation. Additionally, Reagan's invocation of the 25th Amendment prior to the surgery was a risky and unprecedented decision that smoothly flew under the radar for the duration of the complex situation. While it only lasted slightly longer than the length of the procedure (approximately seven hours and 54 minutes), this temporary transfer of power was never formally recognized by the White House. It was later revealed that this decision was made on the grounds that \"Mr. Reagan and his advisors did not want his actions to establish a definition of incapacitation that would bind future presidents.\" Reagan expressed this transfer of power in two identical letters that were sent to the speaker of the House of Representatives, Representative Tip O'Neill, and the president pro tempore of the senate, Senator Strom Thurmond.\nWhile the President was recovering in the hospital, McFarlane met with him and told him that representatives from Israel had contacted the National Security Agency to pass on confidential information from what Reagan later described as the \"moderate\" Iranian faction headed by Rafsanjani opposed to the Ayatollah's hardline anti-US policies. The visit from McFarlane in Reagan's hospital room was the first visit from an administration official outside of Donald Regan since the surgery. The meeting took place five days after the surgery and only three days after doctors gave the news that his polyp had been malignant. The three participants of this meeting had very different recollections of what was discussed during its 23-minute duration. Months later, Reagan even stated that he \"had no recollection of a meeting in the hospital in July with McFarlane and that he had no notes which would show such a meeting\". This does not come as a surprise considering the possible short and long-term effects of anesthesia on patients above the age of 60, in addition to his already weakened physical and mental state.\nAccording to Reagan, these Iranians sought to establish a quiet relationship with the US, before establishing formal relationships upon the death of the aging Ayatollah. In Reagan's account, McFarlane told Reagan that the Iranians, to demonstrate their seriousness, offered to persuade the Hezbollah militants to release the seven US hostages. McFarlane met with the Israeli intermediaries; Reagan claimed that he allowed this because he believed that establishing relations with a strategically located country, and preventing the Soviet Union from doing the same, was a beneficial move. Although Reagan claims that the arms sales were to a \"moderate\" faction of Iranians, the Walsh Iran\u2013Contra Report states that the arms sales were \"to Iran\" itself, which was under the control of the Ayatollah.\nFollowing the Israeli\u2013US meeting, Israel requested permission from the US to sell a small number of BGM-71 TOW antitank missiles to Iran, claiming that this would aid the \"moderate\" Iranian faction, by demonstrating that the group actually had high-level connections to the US government. Reagan initially rejected the plan, until Israel sent information to the US showing that the \"moderate\" Iranians were opposed to terrorism and had fought against it. Now having a reason to trust the \"moderates\", Reagan approved the transaction, which was meant to be between Israel and the \"moderates\" in Iran, with the US reimbursing Israel. In his 1990 autobiography \"An American Life\", Reagan claimed that he was deeply committed to securing the release of the hostages; it was this compassion that supposedly motivated his support for the arms initiatives. The president requested that the \"moderate\" Iranians do everything in their capability to free the hostages held by Hezbollah. Reagan always publicly insisted after the scandal broke in late 1986 that the purpose behind the arms-for-hostages trade was to establish a working relationship with the \"moderate\" faction associated with Rafsanjani to facilitate the reestablishment of the US\u2013Iranian alliance after the soon to be expected death of Khomeini, to end the Iran\u2013Iraq War and end Iranian support for Islamic terrorism while downplaying the importance of freeing the hostages in Lebanon as a secondary issue. By contrast, when testifying before the Tower Commission, Reagan declared that the hostage issue was the main reason for selling arms to Iran.\nThe following arms were supplied to Iran:\nFirst few arms sales.\nThe first arms sales to Iran began in 1981, though the official paper trail has them beginning in 1985 (see above). On 20 August 1985, Israel sent 96 US-made TOW missiles to Iran through an arms dealer Manucher Ghorbanifar. Subsequently, on 14 September 1985, 408 more TOW missiles were delivered. On 15 September 1985, following the second delivery, Reverend Benjamin Weir was released by his captors, the Islamic Jihad Organization. On 24 November 1985, 18 Hawk antiaircraft missiles were delivered.\nModifications in plans.\nRobert McFarlane resigned on 4 December 1985, stating that he wanted to spend more time with his family, and was replaced by Admiral John Poindexter. Two days later, Reagan met with his advisors at the White House, where a new plan was introduced. This called for a slight change in the arms transactions: instead of the weapons going to the \"moderate\" Iranian group, they would go to \"moderate\" Iranian army leaders. As each weapons delivery was made from Israel by air, hostages held by Hezbollah would be released. Israel would continue to be reimbursed by the US for the weapons. Though staunchly opposed by Secretary of State George Shultz and Secretary of Defense Caspar Weinberger, the plan was authorized by Reagan, who stated that, \"We were not trading arms for hostages, nor were we negotiating with terrorists\". In his notes of a meeting held in the White House on 7 December 1985, Weinberger wrote he told Reagan that this plan was illegal, writing:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;I argued strongly that we have an embargo that makes arms sales to Iran illegal and President couldn't violate it and that 'washing' transactions through Israel wouldn't make it legal. Shultz, Don Regan agreed.\nWeinberger's notes have Reagan saying he \"could answer charges of illegality but he couldn't answer charge [\"sic\"] that 'big strong President Reagan passed up a chance to free hostages'.\" Now retired National Security Advisor McFarlane flew to London to meet with Israelis and Ghorbanifar in an attempt to persuade the Iranian to use his influence to release the hostages before any arms transactions occurred; this plan was rejected by Ghorbanifar.\nOn the day of McFarlane's resignation, Oliver North, a military aide to the US National Security Council (NSC), proposed a new plan for selling arms to Iran, which included two major adjustments: instead of selling arms through Israel, the sale was to be direct at a markup; and a portion of the proceeds would go to the Contras, Nicaraguan paramilitary fighters waging guerrilla warfare against the Sandinista government, claiming power after an election full of irregularities. The dealings with the Iranians were conducted via the NSC with Admiral Poindexter and his deputy Colonel North, with the US historians Malcolm Byrne and Peter Kornbluh writing that Poindexter granted much power to North \"who made the most of the situation, often deciding important matters on his own, striking outlandish deals with the Iranians, and acting in the name of the president on issues that were far beyond his competence. All of these activities continued to take place within the framework of the president's broad authorization. Until the press reported on the existence of the operation, nobody in the administration questioned the authority of Poindexter's and North's team to implement the president's decisions\". North proposed a $15 million markup, while contracted arms broker Ghorbanifar added a 41-percent markup of his own. Other members of the NSC were in favor of North's plan; with large support, Poindexter authorized it without notifying President Reagan, and it went into effect. At first, the Iranians refused to buy the arms at the inflated price because of the excessive markup imposed by North and Ghorbanifar. They eventually relented, and, in February 1986, 1,000 TOW missiles were shipped to the country. From May to November 1986, there were additional shipments of miscellaneous weapons and parts.\nBoth the sale of weapons to Iran and the funding of the Contras attempted to circumvent not only stated administration policy, but also the Boland Amendment. Administration officials argued that, regardless of Congress restricting funds for the Contras, or any affair, the President (or in this case the administration) could carry on by seeking alternative means of funding such as private entities and foreign governments. Funding from one foreign country, Brunei, was botched when North's secretary, Fawn Hall, transposed the numbers of North's Swiss bank account number. A Swiss businessperson, suddenly $10 million richer, alerted the authorities of the mistake. The money was eventually returned to the Sultan of Brunei, with interest.\nOn 7 January 1986, John Poindexter proposed to Reagan a modification of the approved plan: instead of negotiating with the \"moderate\" Iranian political group, the US would negotiate with \"moderate\" members of the Iranian government. Poindexter told Reagan that Ghorbanifar had important connections within the Iranian government, so, with the hope of the release of the hostages, Reagan approved this plan as well. Throughout February 1986, weapons were shipped directly to Iran by the US (as part of Oliver North's plan), but none of the hostages were released. Retired National Security Advisor McFarlane conducted another international voyage, this one to Tehran\u2014bringing with him a gift of a Bible with a handwritten inscription by Ronald Reagan and, according to George W. Cave, a cake baked in the shape of a key. Howard Teicher described the cake as a joke between North and Ghorbanifar. McFarlane met directly with Iranian officials associated with Rafsanjani, who sought to establish US\u2013Iranian relations in an attempt to free the four remaining hostages.\nThe US delegation comprised McFarlane, North, Cave (a retired CIA officer who served as the group's translator), Teicher, Israeli diplomat Amiram Nir, and a CIA communicator. They arrived in Tehran in an Israeli plane carrying forged Irish passports on 25 May 1986. This meeting also failed. Much to McFarlane's disgust, he did not meet ministers, and instead met in his words \"third and fourth level officials\". At one point, an angry McFarlane shouted: \"As I am a Minister, I expect to meet with decision-makers. Otherwise, you can work with my staff.\" The Iranians requested concessions such as Israel's withdrawal from the Golan Heights, which the US rejected. More importantly, McFarlane refused to ship spare parts for the Hawk missiles until the Iranians had Hezbollah release the US hostages, whereas the Iranians wanted to reverse that sequence with the spare parts being shipped first before the hostages were freed. The differing negotiating positions led to McFarlane's mission going home after four days. After the failure of the secret visit to Tehran, McFarlane advised Reagan not to talk to the Iranians anymore, advice that was disregarded.\nSubsequent dealings.\nOn 26 July 1986, Hezbollah freed the US hostage Father Lawrence Jenco, former head of Catholic Relief Services in Lebanon. Following this, William J. Casey, head of the CIA, requested that the US authorize sending a shipment of small missile parts to Iranian military forces as a way of expressing gratitude. Casey also justified this request by stating that the contact in the Iranian government might otherwise lose face or be executed, and hostages might be killed. Reagan authorized the shipment to ensure that those potential events would not occur. North used this release to persuade Reagan to switch over to a \"sequential\" policy of freeing the hostages one by one, instead of the \"all or nothing\" policy that the Americans had pursued until then. By this point, the Americans had grown tired of Ghorbanifar who had proven himself a dishonest intermediary who played off both sides to his own commercial advantage. In August 1986, the Americans had established a new contact in the Iranian government, Ali Hashemi Bahramani, the nephew of Rafsanjani and an officer in the Revolutionary Guard. The fact that the Revolutionary Guard was deeply involved in international terrorism seemed only to attract the Americans more to Bahramani, who was seen as someone with the influence to change Iran's policies. Richard Secord, a US arms dealer, who was being used as a contact with Iran, wrote to North: \"My judgment is that we have opened up a new and probably better channel into Iran\". North was so impressed with Bahramani that he arranged for him to secretly visit Washington, D.C. and gave him a guided tour at midnight of the White House.\nNorth frequently met with Bahramani in the summer and autumn of 1986 in West Germany, discussing arms sales to Iran, the freeing of hostages held by Hezbollah and how best to overthrow President Saddam Hussein of Iraq and the establishment of \"a non-hostile regime in Baghdad\". In September and October 1986, three more Americans\u2014Frank Reed, Joseph Cicippio, and Edward Tracy\u2014were abducted in Lebanon by a separate terrorist group, who referred to them simply as \"G.I. Joe\", after the popular US toy. The reasons for their abduction are unknown, although it is speculated that they were kidnapped to replace the freed Americans. One more original hostage, David Jacobsen, was later released. The captors promised to release the remaining two, but the release never happened.\nDuring a secret meeting in Frankfurt in October 1986, North told Bahramani that \"Saddam Hussein must go\". North also claimed that Reagan had told him to tell Bahramani that: \"Saddam Hussein is an asshole.\" Bahramani during a secret meeting in Mainz informed North that Rafsanjani \"for his own politics [...] decided to get all the groups involved and give them a role to play\". Thus, all the factions in the Iranian government would be jointly responsible for the talks with the Americans and \"there would not be an internal war\". This demand of Bahramani caused much dismay on the US side as it made clear to them that they would not be dealing solely with a \"moderate\" faction in the Islamic Republic but rather with all the factions in the Iranian government\u2014including those who were very much involved in terrorism. Despite this, the talks were not broken off.\nDiscovery and scandal.\nAfter a leak by Mehdi Hashemi, a senior official in the Islamic Revolutionary Guard Corps, the Lebanese magazine \"Ash-Shiraa\" exposed the arrangement on 3 November 1986. According to Patrick Seale, it was the Syrian President Hafez Al-Assad who leaked the information, which he had received fom a Syrian agent in Tehran, to \"Ash-Shiraa\". According to Seymour Hersh, an unnamed former military officer told him that the leak may have been orchestrated by a covert team led by Arthur S. Moreau Jr., assistant to the chair of the US Joint Chiefs of Staff, due to fears the scheme had grown out of control.\nThis was the first public report of the weapons-for-hostages deal. The operation was discovered only after an airlift of guns (Corporate Air Services HPF821) was downed over Nicaragua. Eugene Hasenfus, who was captured by Nicaraguan authorities after surviving the plane crash, initially alleged in a press conference on Nicaraguan soil that two of his coworkers, Max Gomez and Ramon Medina, worked for the CIA. He later said he did not know whether they did or not. The Iranian government confirmed the \"Ash-Shiraa\" story, and, 10 days after the story was first published, President Reagan appeared on national television from the Oval Office on 13 November, stating:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nThe scandal was compounded when Oliver North destroyed or hid pertinent documents between 21 November and 25 November 1986. During North's trial in 1989, his secretary, Fawn Hall, testified extensively about helping North alter and shred official US National Security Council (NSC) documents from the White House. According to \"The New York Times\", enough documents were put into a government shredder to jam it. Hall also testified that she smuggled classified documents out of the Old Executive Office Building by concealing them in her boots and dress. North's explanation for destroying some documents was to protect the lives of individuals involved in Iran and Contra operations. It was not until 1993, years after the trial, that North's notebooks were made public, and only after the National Security Archive and Public Citizen sued the Office of the Independent Counsel under the Freedom of Information Act.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\nThe diversion of funds is revealed\nWhat is involved is that in the course of the arms transfers, which involved the United States providing the arms to Israel and Israel in turn transferring the arms\u2014in effect, selling the arms to representatives of Iran. Certain monies which were received in the transaction between representatives of Israel and representatives of Iran were taken and made available to the forces in Central America, which are opposing the Sandinista government there.\n \u2013 U.S. Attorney General Edwin Meese \n , White House news conference on November 25, 1986\nDuring the 1989 trial, North testified that on 21, 22 or 24 of November 1986, he witnessed Poindexter destroy what may have been the only signed copy of a presidential covert-action finding that sought to authorize CIA participation in the November 1985 Hawk missile shipment to Iran. U.S. Attorney General Edwin Meese admitted on 25 November that profits from weapons sales to Iran were made available to assist the Contra rebels in Nicaragua. On the same day, John Poindexter resigned, and President Reagan fired Oliver North. Poindexter was replaced by Frank Carlucci on 2 December 1986.\nWhen the story broke, many legal and constitutional scholars expressed dismay that the NSC, which was supposed to be just an advisory body to assist the President with formulating foreign policy, had \"gone operational\" by becoming an executive body covertly executing foreign policy on its own. The National Security Act of 1947, which created the NSC, gave it the vague right to perform \"such other functions and duties related to the intelligence as the National Security Council may from time to time direct.\" However, the NSC had usually, although not always, acted as an advisory agency until the Reagan administration when the NSC had \"gone operational\", a situation that was condemned by both the Tower Commission and by Congress as a departure from the norm. The American historian John Canham-Clyne asserted that the Iran\u2013Contra affair and the NSC \"going operational\" were not departures from the norm, but were the logical and natural consequence of the existence of the \"national security state\", the plethora of shadowy government agencies with multi-million dollar budgets operating with little oversight from Congress, the courts or the media, and for whom upholding national security justified almost everything. Canham-Clyne argued that for the \"national security state\", the law was an obstacle to be surmounted rather than something to uphold and that the Iran\u2013Contra affair was just \"business as usual\", something he asserted that the media missed by focusing on the NSC having \"gone operational\".\nIn \"Veil: The Secret Wars of the CIA 1981\u20131987\", journalist Bob Woodward chronicled the role of the CIA in facilitating the transfer of funds from the Iran arms sales to the Nicaraguan Contras spearheaded by Oliver North. According to Woodward, then-Director of the CIA William J. Casey admitted to him in February 1987 that he was aware of the diversion of funds to the Contras. The controversial admission occurred while Casey was hospitalized for a stroke, and, according to his wife, was unable to communicate. On 6 May 1987, William Casey died the day after Congress began public hearings on Iran\u2013Contra. Independent Counsel Lawrence Walsh later wrote: \"Independent Counsel obtained no documentary evidence showing Casey knew about or approved the diversion. The only direct testimony linking Casey to early knowledge of the diversion came from [Oliver] North.\" Gust Avrakodos, who was responsible for the arms supplies to the Afghans at this time, was aware of the operation as well and strongly opposed it, in particular the diversion of funds allotted to the Afghan operation. According to his Middle Eastern experts, the operation was pointless because the moderates in Iran were not in a position to challenge the fundamentalists. However, he was overruled by Clair George.\nTower Commission.\nOn 25 November 1986, President Reagan announced the creation of a Special Review Board to look into the matter; the following day, he appointed former Senator John Tower, former Secretary of State Edmund Muskie, and former National Security Adviser Brent Scowcroft to serve as members. This Presidential Commission took effect on 1 December and became known as the Tower Commission. The main objectives of the commission were to inquire into \"the circumstances surrounding the Iran\u2013Contra matter, other case studies that might reveal strengths and weaknesses in the operation of the National Security Council system under stress, and the manner in which that system has served eight different presidents since its inception in 1947\". The Tower Commission was the first presidential commission to review and evaluate the National Security Council.\nPresident Reagan appeared before the Tower Commission on 2 December 1986, to answer questions regarding his involvement in the affair. When asked about his role in authorizing the arms deals, he first stated that he had; later, he appeared to contradict himself by stating that he had no recollection of doing so. In his 1990 autobiography, \"An American Life\", Reagan acknowledges authorizing the shipments to Israel.\nThe report published by the Tower Commission was delivered to the president on 26 February 1987. The commission had interviewed 80 witnesses to the scheme, including Reagan, and two of the arms trade middlemen: Manucher Ghorbanifar and Adnan Khashoggi. The 200-page report was the most comprehensive of any released, criticizing the actions of Oliver North, John Poindexter, Caspar Weinberger, and others. It determined that President Reagan did not have knowledge of the extent of the program, especially about the diversion of funds to the Contras, although it argued that the president ought to have had better control of the National Security Council staff. The report heavily criticized Reagan for not properly supervising his subordinates or being aware of their actions. A major result of the Tower Commission was the consensus that Reagan should have listened to his National Security Advisor more, thereby placing more power in the hands of that chair.\nCongressional committees investigating the affair.\nIn January 1987, Congress announced it was opening an investigation into the Iran\u2013Contra affair. Depending upon one's political perspective, the congressional investigation into the Iran\u2013Contra affair was either an attempt by the legislative arm to gain control over an out-of-control executive arm, a partisan \"witch hunt\" by the Democrats against a Republican administration or a feeble effort by Congress that did far too little to rein in the \"imperial presidency\" that had run amok by breaking numerous laws. The Democratic-controlled United States Congress issued its own report on 18 November 1987, stating that \"If the president did not know what his national security advisers were doing, he should have.\" The congressional report wrote that the president bore \"ultimate responsibility\" for wrongdoing by his aides, and his administration exhibited \"secrecy, deception and disdain for the law\". It also read that \"the central remaining question is the role of the President in the Iran\u2013Contra affair. On this critical point, the shredding of documents by Poindexter, North and others, and the death of Casey, leave the record incomplete\".\nAftermath.\nReagan expressed regret with regard to the situation in a nationally televised address from the Oval Office on 4 March 1987, and in two other speeches. Reagan had not spoken to the American people directly for three months amidst the scandal, and he offered the following explanation for his silence:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The reason I haven't spoken to you before now is this: You deserve the truth. And as frustrating as the waiting has been, I felt it was improper to come to you with sketchy reports, or possibly even erroneous statements, which would then have to be corrected, creating even more doubt and confusion. There's been enough of that.\nReagan then took full responsibility for the acts committed:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;First, let me say I take full responsibility for my own actions and for those of my administration. As angry as I may be about activities undertaken without my knowledge, I am still accountable for those activities. As disappointed as I may be in some who served me, I'm still the one who must answer to the American people for this behavior.\nFinally, the president acknowledged that his previous assertions that the U.S. did not trade arms for hostages were incorrect:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;A few months ago I told the American people I did not trade arms for hostages. My heart and my best intentions still tell me that's true, but the facts and the evidence tell me it is not. As the Tower board reported, what began as a strategic opening to Iran deteriorated, in its implementation, into trading arms for hostages. This runs counter to my own beliefs, to administration policy, and to the original strategy we had in mind.\nReagan's role in these transactions is still not definitively known. It is unclear exactly what Reagan knew and when, and whether the arms sales were motivated by his desire to save the U.S. hostages. Oliver North wrote that \"Ronald Reagan knew of and approved a great deal of what went on with both the Iranian initiative and private efforts on behalf of the contras and he received regular, detailed briefings on both\u00a0... I have no doubt that he was told about the use of residuals for the Contras, and that he approved it. Enthusiastically.\" Handwritten notes by Defense Secretary Weinberger indicate that the President was aware of potential hostage transfers with Iran, as well as the sale of Hawk and TOW missiles to what he was told were \"moderate elements\" within Iran. Notes taken by Weinberger on 7 December 1985 record that Reagan said that \"he could answer charges of illegality but he couldn't answer charge that 'big strong President Reagan passed up a chance to free hostages'\". The Republican-written \"Report of the Congressional Committees Investigating the Iran-Contra Affair\" made the following conclusion:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;There is some question and dispute about precisely the level at which he chose to follow the operation details. There is no doubt, however, ... [that] the President set the US policy towards Nicaragua, with few if any ambiguities, and then left subordinates more or less free to implement it.\nDomestically, the affair precipitated a drop in President Reagan's popularity. His approval ratings suffered \"the largest single drop for any U.S. president in history\", from 67% to 46% in November 1986, according to a \"New York Times\"/CBS News poll. The \"Teflon President\", as Reagan was nicknamed by critics, survived the affair, however, and his approval rating recovered.\nInternationally, the damage was more severe. Magnus Ranstorp wrote, \"U.S. willingness to engage in concessions with Iran and the Hezbollah not only signaled to its adversaries that hostage-taking was an extremely useful instrument in extracting political and financial concessions for the West but also undermined any credibility of U.S. criticism of other states' deviation from the principles of no-negotiation and no concession to terrorists and their demands.\"\nIn Iran, Mehdi Hashemi, the leaker of the scandal, was executed in 1987, allegedly for activities unrelated to the scandal. Though Hashemi made a full video confession to numerous serious charges, some observers find the coincidence of his leak and the subsequent prosecution highly suspicious.\nIn 1994, just five years after leaving office, President Reagan announced that he had been diagnosed with Alzheimer's disease. Lawrence Walsh, who was appointed Independent Counsel in 1986 to investigate the transactions, later implied Reagan's declining health may have played a role in his handling of the situation. However, Walsh did note that he believed President Reagan's \"instincts for the country's good were right\".\nIndictments.\nThe Independent Counsel, Lawrence E. Walsh, chose not to re-try North or Poindexter. In total, several dozen people were investigated by Walsh's office.\nGeorge H. W. Bush's involvement.\nOn 27 July 1986, Israeli counterterrorism expert Amiram Nir briefed Vice President Bush in Jerusalem about the weapon sales to Iran.\nIn an interview with \"The Washington Post\" in August 1987, Bush stated that he was denied information about the operation and did not know about the diversion of funds. Bush said that he had not advised Reagan to reject the initiative because he had not heard strong objections to it. The \"Post\" quoted him as stating, \"We were not in the loop.\" The following month, Bush recounted meeting Nir in his September 1987 autobiography \"Looking Forward\", stating that he began to develop misgivings about the Iran initiative. He wrote that he did not learn the full extent of the Iran dealings until he was briefed by Senator David Durenberger regarding a Senate inquiry into them. Bush added the briefing with Durenberger left him with the feeling he had \"been deliberately excluded from key meetings involving details of the Iran operation\".\nIn January 1988 during a live interview with Bush on \"CBS Evening News\", Dan Rather told Bush that his unwillingness to speak about the scandal led \"people to say 'either George Bush was irrelevant or he was ineffective, he set himself outside of the loop.'\" Bush replied, \"May I explain what I mean by 'out of the loop'? No operational role.\"\nAlthough Bush publicly insisted that he knew little about the operation, his statements were contradicted by excerpts of his diary released by the White House in January 1993. An entry dated 5 November 1986 stated: \"On the news at this time is the question of the hostages\u00a0... I'm one of the few people that know fully the details, and there is a lot of flak and misinformation out there. It is not a subject we can talk about\u00a0...\"\nInternational involvement.\nFollowing the Iran-Contra Affair in 1987, covert military assistance from Taiwan to the Contras was exposed, with reports indicating that Ku Cheng-kang, the co-founder and chairman of World League for Freedom and Democracy played a key role in facilitating the aid. The Taiwanese Ministry of Foreign Affairs later confirmed these activities.\nPardons.\nOn 24 December 1992, after he had been defeated for reelection by Bill Clinton, President George H. W. Bush pardoned five administration officials who had been found guilty on charges relating to the affair. They were:\nBush also pardoned Caspar Weinberger, who had not yet come to trial. Attorney General William P. Barr advised the President on these pardons, especially that of Caspar Weinberger.\nIn response to these Bush pardons, Independent Counsel Lawrence E. Walsh, who headed the investigation of Reagan administration officials' criminal conduct in the Iran\u2013Contra scandal, stated that \"the Iran-contra cover-up, which has continued for more than six years, has now been completed.\" Walsh noted that in issuing the pardons Bush appears to have been preempting being implicated himself in the crimes of Iran\u2013Contra by evidence that was to come to light during the Weinberger trial, and noted that there was a pattern of \"deception and obstruction\" by Bush, Weinberger and other senior Reagan administration officials.\nModern interpretations.\nThe Iran\u2013Contra affair and the ensuing deception to protect senior administration officials (including President Reagan) was cast as an example of post-truth politics by Malcolm Byrne of George Washington University.\nReports and documents.\nThe 100th Congress formed a Joint Committee of the United States Congress (Congressional committees investigating the Iran\u2013Contra affair) and held hearings in mid-1987. Transcripts were published as: \"Iran-Contra Investigation: Joint Hearings Before the Senate Select Committee on Secret Military Assistance to Iran and the Nicaraguan Opposition and the House Select Committee to Investigate Covert Arms Transactions with Iran\" (U.S. GPO 1987\u201388). A closed Executive Session heard classified testimony from North and Poindexter; this transcript was published in a redacted format. The joint committee's final report was \"Report of the Congressional Committees Investigating the Iran-Contra Affair With Supplemental, Minority, and Additional Views\" (U.S. GPO 17 November 1987). The records of the committee are at the National Archives, but many are still non-public.\nTestimony was also heard before the House Foreign Affairs Committee, House Permanent Select Committee on Intelligence, and Senate Select Committee on Intelligence and can be found in the Congressional Record for those bodies. The Senate Intelligence Committee produced two reports: \"Preliminary Inquiry into the Sale of Arms to Iran and Possible Diversion of Funds to the Nicaraguan Resistance\" (2 February 1987) and \"Were Relevant Documents Withheld from the Congressional Committees Investigating the Iran-Contra Affair?\" (June 1989).\nThe Tower Commission Report was published as the \"Report of the President's Special Review Board\" (U.S. GPO 26 February 1987). It was also published as \"The Tower Commission Report\" by Bantam Books ().\nThe Office of Independent Counsel/Walsh investigation produced four interim reports to Congress. Its final report was published as the \"Final Report of the Independent Counsel for Iran/Contra Matters\". Walsh's records are available at the National Archives.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nFootnotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "14788", "revid": "937293", "url": "https://en.wikipedia.org/wiki?curid=14788", "title": "Infocom", "text": "American software company\nInfocom, Inc. was an American software company based in Cambridge, Massachusetts, that produced numerous works of interactive fiction. They also produced a business application, a relational database called \"Cornerstone\".\nInfocom was founded on June 22, 1979, by staff and students of Massachusetts Institute of Technology, and lasted as an independent company until 1986, when it was bought by Activision. Activision shut down the Infocom division in 1989, although they released some titles in the 1990s under the Infocom \"Zork\" brand. Activision abandoned the Infocom trademark in 2002.\nOverview.\nInfocom games are text adventures where users direct the action by entering short strings of words to give commands when prompted. Generally the program will respond by describing the results of the action, often the contents of a room if the player has moved within the virtual world. The user reads this information, decides what to do, and enters another short series of words. Examples include \"go west\", \"take flashlight\", or \"give the letter to the woman then ask her for a book\".\nInfocom games were written using a programming language called ZIL (Zork Implementation Language), itself derived directly from MDL, that compiled into a bytecode able to run on a standardized virtual machine called the Z-machine. As the games were text based and used variants of the same Z-machine interpreter, the interpreter had to be ported to new computer architectures only once per architecture, rather than once per game. Each game file included a sophisticated parser which allowed the user to type complex instructions to the game. Unlike earlier works of interactive fiction which only understood commands of the form 'verb noun', Infocom's parser could understand a wider variety of sentences. For instance one might type \"open the large door, then go west\", or \"go to festeron\".\nWith the Z-machine, Infocom was able to release most of their games for most popular home computers simultaneously: Apple II, Atari 8-bit computers, IBM PC compatibles, Amstrad CPC/PCW (one disc worked on both machines), Commodore 64, Plus/4, Commodore 128, Kaypro CP/M, TI-99/4A, Macintosh, Atari ST, Amiga, TRS-80, and TRS-80 Color Computer.\nHistory.\nFoundation and Zork.\nInfocom began as a collaboration between Massachusetts Institute of Technology (MIT) faculty and alumni, some of whom had previously worked a text-based adventure game called \"Zork\". Development of \"Zork\" began in 1977 at the MIT Laboratory for Computer Science, with an initial team including Tim Anderson, Marc Blank, and Dave Lebling, as well as Bruce Daniels. Inspired by \"Colossal Cave Adventure\", the developers aspired to improve on the formula with a more robust text parser and more logical puzzles. They did not announce their game while it was in development, but a lack of security on the MIT systems meant that anyone who could access the PDP-10 computer over the ARPANET could see what programs were being run. As a result, a small community of people discovered the new \"Zork\" adventure game and spread word of it under that name. This community interacted with the developers as they created the game, playtesting additions and submitting bug reports. \nInfocom was officially founded as a software company on June 22, 1979, with founding members Tim Anderson, Joel Berez, Marc Blank, Mike Broos, Scott Cutler, Stu Galley, Dave Lebling, J. C. R. Licklider, Chris Reeve, and Al Vezza. By the end of the year, the core \"Zork\" game was complete, and Berez was elected the company's president. The studio began seeking a professional publisher with store and distributor connections. After Microsoft passed on the project due to competition with their own \"Microsoft Adventure\" (1979), Infocom negotiated a publishing agreement with Personal Software, one of the first professional software publishing companies. However, Infocom grew wary of the publisher's lack of advertising for \"Zork I\", and lack of enthusiasm for additional episodes and games. The developer decided to self-publish their games from that moment forward, buying out Personal Software's remaining inventory of \"Zork\" games.\nFollowing its 1980 release, \"Zork I\" became a bestseller from 1983 through 1985. By 1986, the game had sold 380,000 copies, with 680,000 sales for the trilogy overall, comprising one-third of Infocom's two million game sales. Reviewers hailed \"Zork\" as the best adventure game to date, with later critics regarding it as one of the greatest games of all time. Historians noted the game as a foundation for the adventure game genre, as well as influencing the MUD and massively multiplayer online role-playing game genres.\nExpansion.\nLebling and Blank each authored several more games, and additional game writers (or \"Implementers\") were hired, notably including Steve Meretzky. Other popular and inventive titles included a number of sequels and spinoff games in the \"Zork\" series, \"The Hitchhiker's Guide to the Galaxy\" by Douglas Adams, and \"A Mind Forever Voyaging\".\nIn its first few years of operation, text adventures proved to be a huge revenue stream for the company. Whereas most computer games of the era would achieve initial success and then suffer a significant drop-off in sales, Infocom titles continued to sell for years and years. Employee Tim Anderson said of their situation, \"It was phenomenal \u2013 we had a basement that just printed money.\" By 1983 Infocom was perhaps the dominant computer-game company; for example, all ten of its games were on the \"Softsel\" top 40 list of best-selling computer games for the week of December 12, 1983, with \"Zork\" in first place and two others in the top ten. In late 1984, management declined an offer by publisher Simon &amp; Schuster to acquire Infocom for $28\u00a0million, far more than the board of directors's valuation of $10\u201312\u00a0million. In 1993, \"Computer Gaming World\" described this era as the \"Cambridge Camelot, where the Great Underground Empire was formed\".\nReception.\nInfocom games were popular, \"InfoWorld\" said, in part because \"in offices all over America (more than anyone realizes) executives and managers are playing games on their computers\". An estimated 25% had a computer game \"hidden somewhere in their drawers\", \"Inc.\" reported, and they preferred Infocom adventures to arcade games. The company stated that year that 75% of players were over 25 years old and that 80% were men; more women played its games than other companies', especially the mysteries. Most players enjoyed reading books; in 1987 president Joel Berez stated, \"[Infocom's] audience tends to be composed of heavy readers. We sell to the minority that does read\".\nA 1996 article in \"Next Generation\" said Infocom's \"games were noted for having more depth than any other adventure games, before or since.\" Three components proved key to Infocom's success: marketing strategy, rich storytelling and feelies. Whereas most game developers sold their games mainly in software stores, Infocom also distributed their games via bookstores. Infocom's products appealed more to those with expensive computers, such as the Macintosh, IBM PC, and Amiga. Berez stated that \"there is no noticeable correlation between graphics machines and our penetration. There is a high correlation between the price of the machine and our sales ... people who are putting more money into their machines tend to buy more of our software\". Since their games were text-based, patrons of bookstores were drawn to the Infocom games as they were already interested in reading. Unlike most computer software, Infocom titles were distributed under a no-returns policy, which allowed them to make money from a single game for a longer period of time.\nNext, Infocom titles featured strong storytelling and rich descriptions, eschewing the inherent restrictions of graphic displays and allowing users to use their own imaginations for the lavish and exotic locations the games described. Infocom's puzzles were unique in that they were usually tightly integrated into the storyline, and rarely did gamers feel like they were being made to jump through one arbitrary hoop after another, as was the case in many of the competitors' games. The puzzles were generally logical but also required close attention to the clues and hints given in the story, causing many gamers to keep copious notes as they went along.\nSometimes, though, Infocom threw in puzzles just for the humor of it\u2014if the user never ran into these, they could still finish the game. But discovering these early Easter Eggs was satisfying for some fans of the games. For example, one popular Easter egg was in the \"Enchanter\" game, which involves collecting magic spells to use in accomplishing the quest. One of these is a summoning spell, which the player needs to use to summon certain characters at different parts of the game. At one point the game mentions the \"Implementers\" who were responsible for creating the land of Zork. If the player tries to summon the Implementers, the game produces a vision of Dave Lebling and Marc Blank at their computers, surprised at this \"bug\" in the game and working feverishly to fix it.\nThird, the inclusion of \"feelies\"\u2014imaginative props and extras tied to the game's theme\u2014provided copy protection against copyright infringement. Some games were unsolvable without the extra content provided with the boxed game. And because of the cleverness and uniqueness of the feelies, users rarely felt like they were an intrusion or inconvenience, as was the case with most of the other copy-protection schemes of the time. Feelies also provided the player with a physical aspect to the gameplay of their text adventures, giving another dimension of strategy to what would other-wise just be a text parser.\nAlthough Infocom started out with \"Zork\", and although the \"Zork\" world was the centerpiece of their product line throughout the \"Zork\" and \"Enchanter\" series, the company quickly branched out into a wide variety of story lines: fantasy, science-fiction, mystery, horror, historical adventure, children's stories, and others that defied easy categorization. In an attempt to reach out to female customers, Infocom also produced \"Plundered Hearts\", which cast the gamer in the role of the heroine of a swashbuckling adventure on the high seas, and which required the heroine to use more feminine tactics to win the game, since hacking-and-slashing was not a very ladylike way to behave. Infocom also came out with \"Leather Goddesses of Phobos\" in 1986, which featured \"tame\", \"suggestive\", and \"lewd\" playing modes. It included among its \"feelies\" a \"scratch-and-sniff\" card with six odors that corresponded to cues given to the player during the game.\nInvisiclues.\nOriginally, hints for the game were provided as a \"pay-per-hint\" service created by Mike Dornbrook, called the Zork Users Group (ZUG). Dornbrook also started Infocom's customer newsletter, called \"The New Zork Times\", to discuss game hints and preview and showcase new products.\nThe pay-per-hint service eventually led to the development of InvisiClues: books with hints, maps, clues, and solutions for puzzles in the games. The answers to the puzzles were printed in invisible ink that only became visible when rubbed with a special marker that was provided with each book. Usually, two or more answers were given for each question that a gamer might have. The first answer would provide a subtle hint, the second a less subtle hint, and so forth until the last one gave an explicit walkthrough. Gamers could thus reveal only the hints that they needed to have to play the game. To prevent the mere questions (printed in normal ink) from giving away too much information about the game, a certain number of misleading fake questions were included in every InvisiClues book. Answers to these questions would start by giving misleading or impossible to carry out answers, before the final answer revealed that the question was a fake (and usually admonishing the player that revealing random clues from the book would spoil their enjoyment of the game). The InvisiClues books were regularly ranked in near the top of best seller lists for computer books.\nIn the Solid Gold line of re-releases, InvisiClues were integrated into the game. By typing \"HINT\" twice the player would open up a screen of possible topics where they could then reveal one hint at a time for each puzzle, just like the books.\nInteractive fiction.\nInfocom also released a small number of \"interactive fiction paperbacks\" (gamebooks), which were based on the games (such as \"Zork\") and featured the ability to choose a different path through the story. Similar to the \"Choose Your Own Adventure\" series, every couple of pages the book would give the reader the chance to make a choice, such as which direction they wanted to go or how they wanted to respond to another character. The reader would then choose one of the given answers and turn to the appropriate page. These books, however, never did sell particularly well, and quickly disappeared from the bookshelves.\n\"Cornerstone\".\nDespite their success with computer games, Vezza and other company founders hoped to produce successful business programs like Lotus Development, also founded by people from MIT and located in the same building as Infocom. Lotus released its first product, 1-2-3, in January 1983; within a year it had earned $53\u00a0million, compared to Infocom's $6\u00a0million. In 1982 Infocom started putting resources into a new division to produce business products. In 1985 they released a database product, \"Cornerstone\", aimed at capturing the then booming database market for small business. Though this application was hailed upon its release for ease of use, it sold only 10,000 copies; not enough to cover the development expenses.\nThe program failed for a number of reasons. Although it was packaged in a slick hard plastic carrying case and was a very good database for personal and home use, it was originally priced at USD$495 per copy and used copy-protected disks. Another serious miscalculation was that the program did not include any kind of scripting language, so it was not promoted by any of the database consultants that small businesses typically hired to create and maintain their DB applications. Reviewers were also consistently disappointed that Infocom\u2014noted for the natural language syntax of their games\u2014did not include a natural language query ability, which had been the most anticipated feature for this database application. In a final disappointment, \"Cornerstone\" was available only for IBM PCs; while \"Cornerstone\" had been programmed with its own virtual machine for maximum portability, it was not ported to any of the other platforms that Infocom supported for their games, so that feature had become essentially irrelevant. And because \"Cornerstone\" used this virtual machine for its processing, it suffered from slow, lackluster performance.\nChanging marketplace.\nInfocom's games' sales benefited significantly from the portability offered by running on top of a virtual machine. \"InfoWorld\" wrote in 1984 that \"the company always sells games for computers you don't normally think of as game machines, such as the DEC Rainbow or the Texas Instruments Professional Computer. This is one of the key reasons for the continued success of old titles such as Zork.\" Dornbrook estimated that year that of the 1.8\u00a0million home computers in America, one half million homes had Infocom games (\"all, if you count the pirated games\"). Computer companies sent prototypes of new systems to encourage Infocom to port Z-machine to them; the virtual machine supported more than 20 different systems, including orphaned computers for which Infocom games were among the only commercial products. The company produced the only third-party games available for the Macintosh at launch, and Berlyn promised that all 13 of its games would be available for the Atari ST within one month of its release.\nThe virtual machine significantly slowed \"Cornerstone\"'s execution speed, however. Businesses were moving \"en masse\" to the IBM PC platform by that time, so portability was no longer a significant differentiator. Infocom had sunk much of the money from games sales into \"Cornerstone\"; this, in addition to a slump in computer game sales, left the company in a very precarious financial position. By the time Infocom removed the copy-protection and reduced the price to less than $100, it was too late, and the market had moved on to other database solutions.\nBy 1982 the market was moving to graphic adventures. Infocom was interested in producing them, that year proposing to Penguin Software that Antonio Antiochia, author of its \"Transylvania\", provide artwork. Within Infocom the game designers tended to oppose graphics, while marketing and business employees supported using them for the company to remain competitive. The partnership negotiations failed, in part because of the difficulty of adding graphics to the Z-machine, and Infocom instead began a series of advertisements mocking graphical games as \"graffiti\" compared to the human imagination. The marketing campaign was very successful, and Infocom's success led to other companies like Broderbund and Electronic Arts also releasing their own text games.\nActivision takeover.\nAfter \"Cornerstone\"'s failure, Infocom laid off half of its 100 employees, and Activision acquired the company on June 13, 1986, for $7.5\u00a0million. The merger was pushed by Activision's CEO Jim Levy, who was a fan of Infocom games and felt their two companies were in similar situations. Berez stated that although the two companies' headquarters and product lines would remain separate, \"One of the effects of the merger will be for both of us to broaden our horizons\". He said that \"We're looking at graphics a lot\", while Activision was reportedly interested in using Infocom's parser.\nWhile relations were cordial between the two companies at first, Activision's ousting of Levy with new CEO Bruce Davis created problems in the working relationship with Infocom. Davis believed that his company had paid too much for Infocom and initiated a lawsuit against them to recoup some of the cost, along with changing the way Infocom was run. For example:\nLater years.\nBy 1988, rumors spread of disputes between Activision and Infocom. Infocom employees reportedly believed that Activision gave poorer-quality games to Infocom, such as Tom Snyder Productions' unsuccessful \"Infocomics\". Activision moved Infocom development to California in 1989, and the company was now just a publishing label. Rising costs and falling profits, exacerbated by the lack of new products in 1988 and technical issues with its DOS products, caused Activision to close Infocom in 1989, after which some of the remaining Infocom designers such as Steve Meretzky moved to the company Legend Entertainment, founded by Bob Bates and Mike Verdu, to continue creating games in the Infocom tradition.\nActivision itself was struggling in the marketplace following Davis' promotion to CEO. Activision had rebranded itself as Mediagenic and tried to produce business productivity software, but became significantly in debt. In 1991, Mediagenic was purchased by Bobby Kotick, who put into measures immediately to try to turn the company around, which included returning to its Activision name, and putting to use its past IP properties. This included the Infocom games; Kotick recognized the value of the branding of \"Zork\" and other titles. Activision began to sell bundles of the Infocom games that year, packaged as themed collections (usually by genre, such as the Science Fiction collection); in 1991, they published \"The Lost Treasures of Infocom\", followed in 1992 by \"The Lost Treasures of Infocom II\". These compilations featured nearly every game produced by Infocom before 1988. (\"Leather Goddesses of Phobos\" was not included in either bundle, but could be ordered via a coupon included with \"Lost Treasures II\".) The compilations lacked the \"feelies\" that came with each game, but in some cases included photographs of them. In 1996, the first bundles were followed by \"Classic Text Adventure Masterpieces of Infocom\", a single CD-ROM which contained the works of both collections. This release, however, was missing \"The Hitchhiker's Guide to the Galaxy\" and \"Shogun\" because the licenses from Douglas Adams' and James Clavell's estates had expired. Under Kotick's leadership, Activision also developed \"Return to Zork\", published under its Infocom label.\nEventually, Activision abandoned the \"Infocom\" name. The brand name was registered by Oliver Klaeffling of Germany in 2007, then was abandoned the following year. The Infocom trademark was then held by Pete Hottelet's Omni Consumer Products, who registered the name around the same time as Klaeffling in 2007. As of March 2017, the trademark is owned by infocom.xyz, according to Bob Bates.\nLegacy.\nWith the exception of \"The Hitchhiker's Guide to the Galaxy\" and \"Shogun\", the copyrights to the Infocom games are believed to be still held by Activision. \"Dungeon\", the mainframe precursor to the commercial Zork trilogy, is believed to be free for non-commercial use. but prohibited for commercial use. It was this copy that the popular Fortran mainframe version was based on. The C version was based on the Fortran version. and is available from The Interactive Fiction Archive as original FORTRAN source code, a Z-machine story file and as various native source ports. Many Infocom titles can be downloaded via the Internet, but only in violation of the copyright. Activision did at one point release the original trilogy for free-of-charge download as a promotion but prohibited redistribution and have since discontinued this. There are currently at least four Infocom sampler and demos available from the IF Archive as Z-machine story files which require a Z-machine interpreter to play. Interpreters are available for most computer platforms, the most widely used being the Frotz, Zip, and Nitfol interpreters.\nFive games (\"Zork I\", \"Planetfall\", \"The Hitchhiker's Guide to the Galaxy\", \"Wishbringer\" and \"Leather Goddesses of Phobos\") were re-released in Solid Gold format. The Solid Gold versions of those games include a built-in InvisiClues hint system.\nIn 2012, Activision released \"Lost Treasures of Infocom\" for iOS devices. In-app purchases provide access for 27 of the titles. It also lacks \"Shogun\" and \"The Hitchhiker's Guide to the Galaxy\" as well as \"Beyond Zork\", \"Zork Zero\" and \"Nord and Bert\".\nEfforts have been made to make the Infocom games source code available for preservation. In 2008, Jason Scott, a video game preservationist contributing towards the Internet Archive, received the so-called \"Infocom Drive\", a large archive of the entire contents of Infocom's main server made during the last few days before the company was relocated to California; besides source code for all of Infocom's games (including unreleased ones), it also contained the software manuals, design documents and other essential content alongside Infocom's business documentation. Scott later published all of the source files in their original Z-engine format to GitHub in 2019.\n\"Zork\" made a cameo appearance as an easter egg in Activision and Treyarch's \"\". It can be accessed from the main menu.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "14789", "revid": "50223803", "url": "https://en.wikipedia.org/wiki?curid=14789", "title": "Interactive fiction", "text": "Software genre\nInteractive fiction (IF) is software simulating environments in which players use text commands to control characters and influence the environment. Works in this form can be understood as literary narratives, either in the form of Interactive narratives or Interactive narrations. These works can also be understood as a form of video game, either in the form of an adventure game or role-playing game. In common usage, the term refers to text adventures, a type of adventure game where the entire interface can be \"text-only\", however, graphical text adventure games, where the text is accompanied by graphics (still images, animations or video) still fall under the text adventure category if the main way to interact with the game is by typing text. Some users of the term distinguish between interactive fiction, known as \"Puzzle-free\", that focuses on narrative, and \"text adventures\" that focus on puzzles.\nDue to their text-only nature, they sidestepped the problem of writing for widely divergent graphics architectures. This feature meant that interactive fiction games were easily ported across all the popular platforms at the time, including CP/M (not known for gaming or strong graphics capabilities). The number of interactive fiction works is increasing steadily as new ones are produced by an online community, using freely available development systems .\nThe term can also be used to refer to literary works that are not read in a linear fashion, known as gamebooks, where the reader is instead given choices at different points in the text; these decisions determine the flow and outcome of the story. The most famous example of this form of printed fiction is the \"Choose Your Own Adventure\" book series, and the collaborative \"addventure\" format has also been described as a form of interactive fiction. The term \"interactive fiction\" is sometimes used also to refer to visual novels, a type of interactive narrative software popular in Japan.\nMedium.\nText adventures are one of the oldest types of computer games and form a subset of the adventure genre. The player uses text input to control the game, and the game state is relayed to the player via text output. Interactive fiction usually relies on reading from a screen and on typing input, although text-to-speech synthesizers allow blind and visually impaired users to play interactive fiction titles as audio games.\nInput is usually provided by the player in the form of simple sentences such as \"get key\" or \"go east\", which are interpreted by a text parser. Parsers may vary in sophistication; the first text adventure parsers could only handle two-word sentences in the form of verb-noun pairs. Later parsers, such as those built on ZIL (Zork Implementation Language), could understand complete sentences. Later parsers could handle increasing levels of complexity parsing sentences such as \"open the red box with the green key then go north\". This level of complexity is the standard for works of interactive fiction today.\nDespite their lack of graphics, text adventures include a physical dimension where players move between rooms. Many text adventure games boasted their total number of rooms to indicate how much gameplay they offered. These games are unique in that they may create an \"illogical space\", where going north from area A takes you to area B, but going south from area B did not take you back to area A. This can create mazes that do not behave as players expect, and thus players must maintain their own map. These illogical spaces are much more rare in today's era of 3D gaming, and the Interactive Fiction community in general decries the use of mazes entirely, claiming that mazes have become arbitrary 'puzzles for the sake of puzzles' and that they can, in the hands of inexperienced designers, become immensely frustrating for players to navigate.\nInteractive fiction shares much in common with Multi-User Dungeons ('MUDs'). MUDs, which became popular in the mid-1980s, rely on a textual exchange and accept similar commands from players as do works of IF; however, since interactive fiction is single player, and MUDs, by definition, have multiple players, they differ enormously in gameplay styles. MUDs often focus gameplay on activities that involve communities of players, simulated political systems, in-game trading, and other gameplay mechanics that are not possible in a single player environment.\nWriting style.\nInteractive fiction features two distinct modes of writing: the player input and the game output. As described above, player input is expected to be in simple command form (imperative sentences). A typical command may be:&gt; PULL Lever\nThe responses from the game are usually written from a second-person point of view, in present tense. This is because, unlike in most works of fiction, the main character is closely associated with the player, and the events are seen to be happening as the player plays. While older text adventures often identified the protagonist with the player directly, newer games tend to have specific, well-defined protagonists with separate identities from the player. The classic essay \"Crimes Against Mimesis\" discusses, among other IF issues, the nature of \"You\" in interactive fiction. A typical response might look something like this, the response to \"look in tea chest\" at the start of \"Curses\":\n\"That was the first place you tried, hours and hours ago now, and there's nothing there but that boring old book. You pick it up anyway, bored as you are.\" \nMany text adventures, particularly those designed for humour (such as \"Zork\", \"The Hitchhiker's Guide to the Galaxy\", and \"Leather Goddesses of Phobos\"), address the player with an informal tone, sometimes including sarcastic remarks (see the transcript from \"Curses\", above, for an example). The late Douglas Adams, in designing the IF version of his 'Hitchhiker's Guide to the Galaxy', created a unique solution to the final puzzle of the game: the game requires the one solitary item that the player \"didn't\" choose at the outset of play.\nSome IF works dispense with second-person narrative entirely, opting for a first-person perspective ('I') or even placing the player in the position of an observer, rather than a direct participant. In some 'experimental' IF, the concept of self-identification is eliminated, and the player instead takes the role of an inanimate object, a force of nature, or an abstract concept; experimental IF usually pushes the limits of the concept and challenges many assumptions about the medium.\nHistory.\n1960s and 70s.\nNatural language processing.\nThough neither program was developed as a narrative work, the software programs ELIZA (1964\u20131966) and SHRDLU (1968\u20131970) can formally be considered early examples of interactive fiction, as both programs used natural language processing to take input from their user and respond in a virtual and conversational manner. ELIZA simulated a psychotherapist that appeared to provide human-like responses to the user's input, while SHRDLU employed an artificial intelligence that could move virtual objects around an environment and respond to questions asked about the environment's shape. The development of effective natural language processing would become an essential part of interactive fiction development.\n\"Adventure\".\nAround 1975, Will Crowther, a programmer and an amateur caver, wrote the first text adventure game, \"Adventure\" (originally called \"ADVENT\" because a filename could only be six characters long in the operating system he was using, and later named \"Colossal Cave Adventure\"). Having just gone through a divorce, he was looking for a way to connect with his two young children. Over the course of a few weekends, he wrote a text based cave exploration game that featured a sort of guide/narrator who spoke in full sentences and who understood simple two word commands that came close to natural English. Adventure was programmed in Fortran for the PDP-10. Crowther's original version was an accurate simulation of part of the real life Mammoth Cave, but also included fantasy elements (such as axe-wielding dwarves and a magic bridge).\nStanford University graduate student Don Woods discovered \"Adventure\" while working at the Stanford Artificial Intelligence Laboratory, and in 1977 obtained and expanded Crowther's source code (with Crowther's permission). Woods's changes were reminiscent of the writings of J. R. R. Tolkien, and included a troll, elves, and a volcano, which some claim is based on Mount Doom, but Woods says was not.\nIn early 1977, Adventure spread across ARPAnet, and has survived on the Internet to this day. The game has since been ported to many other operating systems, and was included with the floppy-disk distribution of Microsoft's MS-DOS 1.0 OS. \"Adventure\" is a cornerstone of the online IF community; there currently exist dozens of different independently programmed versions, with additional elements, such as new rooms or puzzles, and various scoring systems.\nThe popularity of \"Adventure\" led to the wide success of interactive fiction during the late 1970s, when home computers had little, if any, graphics capability. Many elements of the original game have survived into the present, such as the command 'xyzzy', which is now included as an Easter Egg in modern games, such as \"Microsoft Minesweeper\".\n\"Adventure\" was also directly responsible for the founding of Sierra Online (later Sierra Entertainment); Ken and Roberta Williams played the game and decided to design one of their own, but with graphics.\nCommercial era.\nAdventure International was founded by Scott Adams (not to be confused with the creator of Dilbert). In 1978, Adams wrote \"Adventureland\", which was loosely patterned after the (original) \"Colossal Cave Adventure\". He took out a small ad in a computer magazine in order to promote and sell \"Adventureland\", thus creating the first commercial adventure game. In 1979 he founded Adventure International, the first commercial publisher of interactive fiction. That same year, \"Dog Star Adventure\" was published in source code form in \"SoftSide\", spawning legions of similar games in BASIC.\nThe largest company producing works of interactive fiction was Infocom, which created the \"Zork\" series and many other titles, among them \"Trinity\", \"The Hitchhiker's Guide to the Galaxy\" and \"A Mind Forever Voyaging\".\nIn June 1977, Marc Blank, Bruce K. Daniels, Tim Anderson, and Dave Lebling began writing the mainframe version of \"Zork\" (also known as \"Dungeon\"), at the MIT Laboratory for Computer Science. The game was programmed in a computer language called MDL, a variant of LISP.\nThe term Implementer was the self-given name of the creators of the text adventure series Zork. It is for this reason that game designers and programmers can be referred to as an implementer, often shortened to \"Imp\", rather than a writer.\nIn early 1979, the game was completed. Ten members of the \"MIT Dynamics Modelling Group\" went on to join Infocom when it was incorporated later that year.\nIn order to make its games as portable as possible, Infocom developed the Z-machine, a custom virtual machine that could be implemented on a large number of platforms, and took standardized \"story files\" as input.\nIn a non-technical sense, Infocom was responsible for developing the interactive style that would be emulated by many later interpreters. The Infocom parser was widely regarded as the best of its era. It accepted complex, complete sentence commands like \"put the blue book on the writing desk\" at a time when most of its competitors parsers were restricted to simple two word verb-noun combinations such as \"put book\". The parser was actively upgraded with new features like undo and error correction, and later games would 'understand' multiple sentence input: 'pick up the gem and put it in my bag. take the newspaper clipping out of my bag then burn it with the book of matches'.\nSeveral companies offered optional commercial feelies (physical props associated with a game). The tradition of 'feelies' (and the term itself) is believed to have originated with \"Deadline\" (1982), the third Infocom title after \"Zork I\" and \"II\". When writing this game, it was not possible to include all of the information in the limited (80KB) disk space, so Infocom created the first feelies for this game; extra items that gave more information than could be included within the digital game itself. These included police interviews, the coroner's findings, letters, crime scene evidence and photos of the murder scene.\nThese materials were very difficult for others to copy or otherwise reproduce, and many included information that was essential to completing the game. Seeing the potential benefits of both aiding game-play immersion and providing a measure of creative copy-protection, in addition to acting as a deterrent to software piracy, Infocom and later other companies began creating feelies for numerous titles. In 1987, Infocom released a special version of the first three \"Zork\" titles together with plot-specific coins and other trinkets. This concept would be expanded as time went on, such that later game feelies would contain passwords, coded instructions, page numbers, or other information that would be required to successfully complete the game.\n1980s.\nUnited States.\nInteractive fiction became a standard product for many software companies. By 1982 \"Softline\" wrote that \"the demands of the market are weighted heavily toward hi-res graphics\" in games like Sierra's \"The Wizard and the Princess\" and its imitators. Such graphic adventures became the dominant form of the genre on computers with graphics, like the Apple II. By 1982 Adventure International began releasing versions of its games with graphics. The company went bankrupt in 1985. Synapse Software and Acornsoft were also closed in 1985, leaving Infocom as the leading company producing text-only adventure games on the Apple II with sophisticated parsers and writing, and still advertising its lack of graphics as a virtue. The company was bought by Activision in 1986 after the failure of \"Cornerstone\", Infocom's database software program, and stopped producing text adventures a few years later. Soon after, Telaium/Trillium also closed.\nOutside the United States.\nProbably the first commercial work of interactive fiction produced outside the U.S. was the dungeon crawl game of \"Acheton\", produced in Cambridge, England, and first commercially released by Acornsoft (later expanded and reissued by Topologika). Other leading companies in the UK were Magnetic Scrolls and Level 9 Computing. Also worthy of mention are Delta 4, Melbourne House, and the homebrew company Zenobi.\nIn the early 1980s Edu-Ware also produced interactive fiction for the Apple II as designated by the \"if\" graphic that was displayed on startup. Their titles included the \"Prisoner\" and \"Empire\" series (\"Empire I: World Builders\", \"Empire II: Interstellar Sharks\", \"Empire III: Armageddon\").\nIn 1981, CE Software published \"SwordThrust\" as a commercial successor to the \"Eamon\" gaming system for the Apple II. SwordThrust and Eamon were simple two-word parser games with many role-playing elements not available in other interactive fiction. While SwordThrust published seven different titles, it was vastly overshadowed by the non-commercial Eamon system which allowed private authors to publish their own titles in the series. By March 1984, there were 48 titles published for the Eamon system (and over 270 titles in total as of March 2013).\nIn Italy, interactive fiction games were mainly published and distributed through various magazines in included tapes. The largest number of games were published in the two magazines Viking and Explorer, with versions for the main 8-bit home computers (ZX Spectrum, Commodore 64, and MSX). The software house producing those games was Brainstorm Enterprise, and the most prolific IF author was Bonaventura Di Bello, who produced 70 games in the Italian language. The wave of interactive fiction in Italy lasted for a couple of years thanks to the various magazines promoting the genre, then faded and remains still today a topic of interest for a small group of fans and less known developers, celebrated on Web sites and in related newsgroups.\nIn Spain, interactive fiction was considered a minority genre, and was not very successful. The first Spanish interactive fiction commercially released was \"Yenght\" in 1983, by Dinamic Software, for the ZX Spectrum. Later on, in 1987, the same company produced an interactive fiction about \"Don Quijote\". After several other attempts, the company Aventuras AD, emerged from Dinamic, became the main interactive fiction publisher in Spain, including titles like a Spanish adaptation of \"Colossal Cave Adventure\", an adaptation of the Spanish comic \"El Jabato\", and mainly the \"Ci-U-Than\" trilogy, composed by \"La diosa de Cozumel\" (1990), \"Los templos sagrados\" (1991) and \"Chichen Itz\u00e1\" (1992). During this period, the Club de Aventuras AD (CAAD), the main Spanish speaking community around interactive fiction in the world, was founded, and after the end of Aventuras AD in 1992, the CAAD continued on its own, first with their own magazine, and then with the advent of Internet, with the launch of an active internet community that still produces interactive non commercial fiction nowadays.\nDuring the 1990s.\nLegend Entertainment was founded by Bob Bates and Mike Verdu in 1989. It started out from the ashes of Infocom. The text adventures produced by Legend Entertainment used (high-resolution) graphics as well as sound. Some of their titles include \"Eric the Unready\", the \"Spellcasting\" series and \"Gateway\" (based on Frederik Pohl's novels).\nThe last text adventure created by Legend Entertainment was \"Gateway II\" (1992), while the last game ever created by Legend was \"\" (2003) \u2013 the well-known first-person shooter action game using the Unreal Engine for both impressive graphics and realistic physics. In 2004, Legend Entertainment was acquired by Atari, who published \"Unreal II\" and released for both Microsoft Windows and Microsoft's Xbox.\nMany other companies such as Level 9 Computing, Magnetic Scrolls, Delta 4 and Zenobi had closed by 1992.\nIn 1991 and 1992, Activision released \"The Lost Treasures of Infocom\" in two volumes, a collection containing most of Infocom's games, followed in 1996 by \"Classic Text Adventure Masterpieces of Infocom\".\nModern era.\nAfter the decline of the commercial interactive fiction market in the 1990s, an online community eventually formed around the medium. In 1987, the Usenet newsgroup rec.arts.int-fiction was created, and was soon followed by rec.games.int-fiction. By custom, the topic of rec.arts.int-fiction is interactive fiction authorship and programming, while rec.games.int-fiction encompasses topics related to playing interactive fiction games, such as hint requests and game reviews. As of late 2011, discussions between writers have mostly moved from rec.arts.int-fiction to the Interactive Fiction Community Forum.\nOne of the most important early developments was the reverse-engineering of Infocom's Z-Code format and Z-Machine virtual machine in 1987 by a group of enthusiasts called the InfoTaskForce and the subsequent development of an interpreter for Z-Code story files. As a result, it became possible to play Infocom's work on modern computers.\nFor years, amateurs with the IF community produced interactive fiction works of relatively limited scope using the Adventure Game Toolkit and similar tools.\nThe breakthrough that allowed the interactive fiction community to truly prosper, however, was the creation and distribution of two sophisticated development systems. In 1987, Michael J. Roberts released TADS, a programming language designed to produce works of interactive fiction. In 1993, Graham Nelson released Inform, a programming language and set of libraries which compiled to a Z-Code story file. Each of these systems allowed anyone with sufficient time and dedication to create a game, and caused a growth boom in the online interactive fiction community.\nDespite the lack of commercial support, the availability of high quality tools allowed enthusiasts of the genre to develop new high quality games. Competitions such as the annual Interactive Fiction Competition for short works, the Spring Thing for longer works, and the XYZZY Awards, further helped to improve the quality and complexity of the games. Modern games go much further than the original \"Adventure\" style, improving upon Infocom games, which relied extensively on puzzle solving, and to a lesser extent on communication with non player characters, to include experimentation with writing and story-telling techniques.\nWhile the majority of modern interactive fiction that is developed is distributed for free, there are some commercial endeavors. In 1998, Michael Berlyn, a former Implementor at Infocom, started a new game company, Cascade Mountain Publishing, whose goals were to publish interactive fiction. Despite the Interactive Fiction community providing social and financial backing, Cascade Mountain Publishing went out of business in 2000. Buster Hudson, developer of \"The Wizard Sniffer\" (201\"7),\" emphasized that parser-based puzzle can be used to control the pacing or develop a character.\nOther commercial endeavors include: Peter Nepstad's \"\", several games by Howard Sherman published as Malinche Entertainment, The General Coffee Company's \"Future Boy!,\" \"Cypher\", a graphically enhanced cyberpunk game and various titles by \"Textfyre\". Emily Short was commissioned to develop the game \"City of Secrets\" but the project fell through and she ended up releasing it herself.\nNotable works.\nThe games that won both the Interactive Fiction Competition and the XYZZY Awards are \"All Roads\" (2001), \"Slouching Towards Bedlam\" (2003), \"Vespers\" (2005), \"Lost Pig\" (2007), \"Violet\" (2008), \"Aotearoa\" (2010), \"Coloratura\" (2013), and \" The Wizard Sniffer\" (2017).\nSoftware.\nDevelopment systems.\nThe original Interactive fiction Colossal Cave Adventure was programmed in Fortran, originally developed by IBM. Adventure's parsers could only handle two-word sentences in the form of verb-noun pairs.\nInfocom's games of 1979\u201388, such as Zork, were written using a LISP-like programming language called ZIL (Zork Implementation Language or Zork Interactive Language; it was referred to as both) that compiled into a byte code able to run on a standardized virtual machine called the Z-machine. As the games were text based and used variants of the same Z-machine interpreter, the interpreter only had to be ported to a computer once, rather than once each game. Each game file included a sophisticated parser which allowed the user to type complex instructions to the game. Unlike earlier works of interactive fiction which only understood commands of the form 'verb noun', Infocom's parser could understand a wider variety of sentences. For instance one might type \"open the large door, then go west\", or \"go to the hall\". With the Z-machine, Infocom was able to release most of their games for most popular home computers of the time simultaneously, including Apple II, Atari 8-bit computers, IBM PC compatibles, Amstrad CPC/PCW (one disc worked on both machines), Commodore 64, Plus/4, Commodore 128, Kaypro CP/M, TI-99/4A, Macintosh, Atari ST, Amiga, and TRS-80.\nDuring the 1990s Interactive fiction was mainly written with C-like languages, such as TADS 2 and Inform 6. A number of systems for writing interactive fiction now exist. The most popular remain Inform, TADS, or ADRIFT, but they diverged in their approach to IF-writing during the 2000s, giving today's IF writers an objective choice. By 2006 IFComp, most games were written for Inform, with a strong minority of games for TADS and ADRIFT, followed by a small number of games for other systems.\nWhile familiarity with a programming language leads many new authors to attempt to produce their own complete IF application, most established IF authors recommend use of a specialised IF language, arguing that such systems allow authors to avoid the technicalities of producing a full featured parser, while allowing broad community support. The choice of authoring system usually depends on the author's desired balance of ease of use versus power, and the portability of the final product.\nOther development systems include:\nInterpreters and virtual machines.\nInterpreters are the software used to play the works of interactive fiction created with a development system. Since they need to interact with the player, the \"story files\" created by development systems are programs in their own right. Rather than running directly on any one computer, they are programs run by Interpreters, or virtual machines, which are designed specially for IF. They may be part of the development system, or can be compiled together with the work of fiction as a standalone executable file.\nThe Z-machine was designed by the founders of Infocom, in 1979. They were influenced by the then-new idea of a virtual Pascal computer, but replaced P with Z for Zork, the celebrated adventure game of 1977\u201379. The Z-machine evolved during the 1980s but over 30 years later, it remains in use essentially unchanged. Glulx was designed by Andrew Plotkin in the late 1990s as a new-generation IF virtual machine. It overcomes the technical constraint on the Z-machine by being a 32-bit rather than 16-bit processor. Frotz is a modern Z-machine interpreter originally written in C (programming language) by Stefan Jokisch in 1995 for MS-DOS. Over time it was ported to other platforms, such as Unix, RISC OS, Mac OS and most recently iOS. Modern Glulx interpreters are based on \"Glulxe\", by Andrew Plotkin, and \"Git\", by Iain Merrick. Other interpreters include Zoom for Mac OS X, or for Unix or Linux, maintained by Andrew Hunter, and Spatterlight for Mac OS X, maintained by Tor Andersson.\nDistribution.\nIn addition to commercial distribution venues and individual websites, many works of free interactive fiction are distributed through community websites. These include the Interactive Fiction Database (IFDb), The Interactive Fiction Reviews Organization (IFRO), a game catalog and recommendation engine, and the Interactive Fiction Archive.\nWorks may be distributed for playing with in a separate interpreter. In which case they are often made available in the Blorb package format that many interpreters support. A filename ending .zblorb is a story file intended for a Z-machine in a Blorb wrapper, while a filename ending .gblorb is a story file intended for a Glulx in a Blorb wrapper. It is not common but IF files are sometimes also seen without a Blorb wrapping, though this usually means cover art, help files, and so forth are missing, like a book with the covers torn off. Z-machine story files usually have names ending .z5 or .z8, the number being a version number, and Glulx story files usually end .ulx.\nAlternatively, works may be distributed for playing in a web browser. For example, the 'Parchment' project is for web browser-based IF Interpreter, for both Z-machine and Glulx files.\nSome software such as Twine publishes directly to HTML, the standard language used to create web pages, reducing the requirement for an Interpreter or virtual machine.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "14790", "revid": "47188426", "url": "https://en.wikipedia.org/wiki?curid=14790", "title": "Ice hockey", "text": "Team winter sport\nIce hockey or simply known as hockey in North America, is a team sport played on ice skates, usually on an ice skating rink with lines and markings specific to the sport. It belongs to a family of sports called hockey. The two opposing teams score by using their ice hockey sticks to control and advance a vulcanized rubber hockey puck, and then shooting it into the net of the other team, each goal is worth one point. The team with the highest score after an hour of gameplay is declared the winner; ties are broken in overtime or a shootout. In a formal game, each team has six skaters on the ice at a time, barring any penalties, including a goaltender. It is a full contact game and one of the more physically demanding team sports. \nThe modern sport of ice hockey was developed in Canada, most notably in Montreal, where the first indoor game was played on March 3, 1875. It draws influence from shinty which originated in Scotland, as well as field hockey which originated in England. Some characteristics of ice hockey, such as the length of the ice rink and the use of a puck, have been retained to this day. Amateur ice hockey leagues began in the 1880s, and professional ice hockey originated around 1900. The Stanley Cup, emblematic of ice hockey club supremacy, was initially commissioned in 1892 as the \"Dominion Hockey Challenge Cup\" and was first awarded in 1893 to recognise the Canadian amateur champion and later became the championship trophy of the National Hockey League (NHL). In the early 1900s, the Canadian rules were adopted by the , in Paris, France, the precursor to the International Ice Hockey Federation (IIHF). The sport was played for the first time at the Olympics during the 1920 Summer Games\u2014today it is a mainstay at the Winter Olympics. In 1994, ice hockey was officially recognized as Canada's national winter sport.\nWhile women also played the game during its early formative years, it was not until the mid-1980s when organizers began to officially remove body checking from female ice hockey that it began to gain wider popularity, which by then had spread to Europe and a variety of other countries. The IIHF Women's World Championship was held in 1990, and women's play was introduced into the Olympics in 1998. &lt;templatestyles src=\"Template:TOC limit/styles.css\" /&gt;\nHistory.\nIce hockey is believed to have evolved from simple stick and ball games played in the 18th and 19th centuries in Britain, Ireland, and elsewhere, primarily bandy, hurling, and shinty. The North American sport of lacrosse, derived from tribal Native American games, was also influential. The former games were brought to North America and several similar winter games using informal rules developed, such as shinny and ice polo, but later were absorbed into a new organized game with codified rules which today is ice hockey.\nGame.\nWhile the general characteristics of the game remain constant, the exact rules depend on the particular code of play being used. The two most important codes are those of the IIHF and the NHL. Both of these codes, and others, originated from Canadian rules of ice hockey of the early 20th century.\nIce hockey is played on a \"hockey rink\". During normal play, there are six players on ice skates on the ice per side, one of them being the goaltender. The objective of the game is to score \"goals\" by shooting a hard vulcanized rubber disc, the \"puck\", into the opponent's goal net at the opposite end of the rink. The players use their sticks to pass or shoot the puck.\nWith certain restrictions, players may redirect the puck with any part of their body. Players may not hold the puck in their hand and are prohibited from using their hands to pass the puck to their teammates unless they are in the defensive zone. Players can knock a puck out of the air with their hands to themselves. Players are prohibited from kicking the puck into the opponent's goal, though unintentional redirections off their body or equipment, including skates, are permitted. Players may not intentionally bat the puck into the net with their hands or any part of their body.\nHockey is an off-side game, meaning that forward passes are allowed, unlike in rugby. Before the 1930s, hockey was an on-side game, meaning that only backward passes were allowed. Those rules emphasized individual stick-handling to drive the puck forward. With the arrival of offside rules, the forward pass transformed hockey into a true team sport, where individual performance diminished in importance relative to team play, which could now be coordinated over the entire surface of the ice as opposed to merely rearward players.\n \nThe six players on each team are typically divided into three forwards, two defencemen, and one goaltender. The term \"skaters\" typically applies to all players except goaltenders. The \"forward\" positions consist of a \"centre\" and two \"wingers\": a \"left wing\" and a \"right wing\". Forwards often play together as units or \"lines\", with the same three forwards always playing together. The \"defencemen\" usually stay together as a pair generally divided between left and right. Left and right side wingers or defencemen are generally positioned on the side on which they carry their stick. A substitution of an entire unit at once is called a \"line change\". Teams typically employ alternate sets of forward lines and defensive pairings when \"short-handed\" or on a \"power play\". The goaltender stands in a, usually blue, semi-circle called the \"crease\" in the defensive zone keeping pucks out of the goal. Substitutions are permitted at any time during the game, although during a stoppage of play the home team is permitted the final change. When players are substituted during play, it is called changing \"on the fly\". An NHL rule added in the 2005\u201306 season prevents a team from making any player substitutions after they \"ice\" the puck.\nThe boards surrounding the ice help keep the puck in play and they can also be used as tools to play the puck. Players are permitted to bodycheck opponents into the boards to stop progress. The referees, linesmen and the outsides of the goal are \"in play\" and do not stop the game when the puck or players either bounce into or collide with them. Play can be stopped if the goal is knocked out of position. Play often proceeds for minutes without interruption. After a stoppage, play is restarted with a faceoff. Two players face each other and an official drops the puck to the ice, where the two players attempt to gain control of the puck. Markings (circles) on the ice indicate the locations for the faceoff and guide the positioning of players.\nThree major rules of play in ice hockey limit the movement of the puck: \"offside\", \"icing\", and the puck going out of play. \nUnder IIHF rules, each team may carry a maximum of 20 players and two goaltenders on their roster. NHL rules restrict the total number of players per game to 18, plus two goaltenders. In the NHL, the players are usually divided into four lines of three forwards, and into three pairs of defencemen. On occasion, teams may elect to substitute an extra defenceman for a forward. The seventh defenceman may play as a substitute defenceman, spend the game on the bench, or if a team chooses to play four lines then this seventh defenceman may see ice-time on the fourth line as a forward.\nPeriods and overtime.\nA professional ice hockey game consists of three periods of twenty minutes, the clock running only when the puck is in play. There is a rest period between the three periods. The teams change ends after each period of play, including overtime. Recreational leagues and children's leagues often play shorter games, generally with three shorter periods of play.\nIf a tie occurs in tournament play, as well as in the NHL playoffs, North Americans favour \"sudden death overtime\", in which the teams continue to play twenty-minute periods until a goal is scored. Up until the 1999\u20132000 season, regular-season NHL games were settled with a single five-minute sudden death period with five players (plus a goalie) per side, with both teams awarded one point in the standings in the event of a tie. With a goal, the winning team would be awarded two points and the losing team none (just as if they had lost in regulation). The total elapsed time from when the puck first drops, is about 2 hours and 20 minutes for a 60-minute game.\nFrom the 1999\u20132000 until the 2003\u201304 seasons, the National Hockey League decided ties by playing a single five-minute sudden-death overtime period with each team having four skaters per side (plus the goalie). In the event of a tie, each team would still receive one point in the standings but in the event of a victory the winning team would be awarded two points in the standings and the losing team one point. The idea was to discourage teams from playing for a tie, since previously some teams might have preferred a tie and 1 point to risking a loss and zero points. The exception to this rule is if a team opts to pull their goalie in exchange for an extra skater during overtime and is subsequently scored upon (an \"empty net\" goal), in which case the losing team receives no points for the overtime loss. Since the 2015\u201316 season, the single five-minute sudden-death overtime session involves three skaters on each side. Since three skaters must always be on the ice in an NHL game, the consequences of penalties are slightly different from those during regulation play; any penalty during overtime that would result in a team losing a skater during regulation instead causes the other side to add a skater. Once the penalized team's penalty ends, the penalized skater exits the penalty box and the teams continue at 4-on-4 until the next stoppage of play, at which point the teams return to three skaters per side.\nInternational play and several North American professional leagues, including the NHL (in the regular season), now use an overtime period identical to that from 1999\u20132000 to 2003\u201304 followed by a penalty shootout. If the score remains tied after an extra overtime period, the subsequent shootout consists of three players from each team taking penalty shots. After these six total shots, the team with the most goals is awarded the victory. If the score is still tied, the shootout then proceeds to \"sudden death\". Regardless of the number of goals scored by either team during the shootout, the final score recorded will award the winning team one more goal than the score at the end of regulation time. In the NHL if a game is decided in overtime or by a shootout the winning team is awarded two points in the standings and the losing team is awarded one point. Ties no longer occur in the NHL.\nOvertime in the NHL playoffs differs from the regular season. In the playoffs there are no shootouts. If a game is tied after regulation, then a 20-minute period of 5-on-5 sudden-death overtime will be added. If the game is still tied after the overtime, another period is added until a team scores, which wins the match. Since 2019, the IIHF World Championships and the gold medal game in the Olympics use the same format, but in a 3-on-3 format.\nPenalties.\nIn ice hockey, infractions of the rules lead to a play stoppage whereby the play is restarted at a faceoff. Some infractions result in a \"penalty\" on a player or team. In the simplest case, the offending player is sent to the \"penalty box\" and their team must play with one less player on the ice for a designated time. \"Minor\" penalties last for two minutes, \"major\" penalties last for five minutes, and a \"double minor\" penalty is two \"consecutive\" penalties of two minutes duration. A single minor penalty may be extended by two minutes for causing visible injury to the victimized player. This is usually when blood is drawn during high sticking. Players may be also assessed personal extended penalties or game expulsions for misconduct in addition to the penalty or penalties their team must serve. The team that has been given a penalty is said to be playing \"short-handed\" while the opposing team is on a \"power play\".\nA two-minute minor penalty is often charged for lesser infractions such as tripping, elbowing, roughing, high-sticking, delay of the game, too many players on the ice, boarding, illegal equipment, charging (leaping into an opponent or body-checking him after taking more than two strides), holding, holding the stick (grabbing an opponent's stick), interference, hooking, slashing, kneeing, unsportsmanlike conduct (arguing a penalty call with referee, extremely vulgar or inappropriate verbal comments), \"butt-ending\" (striking an opponent with the knob of the stick), \"spearing\" (jabbing an opponent with the blade of the stick), or cross-checking. As of the 2005\u20132006 season, a minor penalty is also assessed for diving, where a player embellishes or simulates an offence. More egregious fouls may be penalized by a four-minute double-minor penalty, particularly those that injure the victimized player. These penalties end either when the time runs out or when the other team scores during the power play. In the case of a goal scored during the first two minutes of a double-minor, the penalty clock is set down to two minutes upon a score, effectively expiring the first minor penalty. \nFive-minute major penalties are called for especially violent instances of most minor infractions that result in intentional injury to an opponent, or when a minor penalty results in visible injury (such as bleeding), as well as for fighting. Major penalties are always served in full; they do not terminate on a goal scored by the other team. Major penalties assessed for fighting are typically offsetting, meaning neither team is short-handed and the players exit the penalty box upon a stoppage of play following the expiration of their respective penalties. The foul of boarding (defined as \"check[ing] an opponent in such a manner that causes the opponent to be thrown violently in the boards\") is penalized either by a minor or major penalty at the discretion of the referee, based on the violent state of the hit. A minor or major penalty for boarding is often assessed when a player checks an opponent from behind and into the boards.\nSome varieties of penalty do not require the offending team to play a man short. Concurrent five-minute major penalties in the NHL usually result from fighting. In the case of two players being assessed five-minute fighting majors, both the players serve five minutes without their team incurring a loss of player (both teams still have a full complement of players on the ice). This differs with two players from opposing sides getting minor penalties, at the same time or at any intersecting moment, resulting from more common infractions. In this case, both teams will have only four skating players (not counting the goaltender) until one or both penalties expire (if one penalty expires before the other, the opposing team gets a power play for the remainder of the time); this applies regardless of current pending penalties. In the NHL, a team always has at least three skaters on the ice. Thus, ten-minute \"misconduct\" penalties are served in full by the penalized player, but his team may immediately substitute another player on the ice \"unless\" a minor or major penalty is assessed in conjunction with the misconduct (a \"two-and-ten\" or \"five-and-ten\"). In this case, the team designates another player to serve the minor or major; both players go to the penalty box, but only the designee may not be replaced, and he is released upon the expiration of the two or five minutes, at which point the ten-minute misconduct begins. In addition, \"game misconducts\" are assessed for deliberate intent to inflict severe injury on an opponent (at the officials' discretion), or for a major penalty for a stick infraction or repeated major penalties. The offending player is ejected from the game and must immediately leave the playing surface (he does not sit in the penalty box); meanwhile, if an additional minor or major penalty is assessed, a designated player must serve out of that segment of the penalty in the box (similar to the above-mentioned \"two-and-ten\"). In some rare cases, a player may receive up to nineteen minutes in penalties for one string of plays. This could involve receiving a four-minute double-minor penalty, getting in a fight with an opposing player who retaliates, and then receiving a game misconduct after the fight. In this case, the player is ejected and two teammates must serve the double-minor and major penalties.\nA penalty shot is awarded to a player when the illegal actions of another player stop a clear scoring opportunity, most commonly when the player is on a breakaway. A penalty shot allows the obstructed player to pick up the puck on the centre red-line and attempt to score on the goalie with no other players on the ice, to compensate for the earlier missed scoring opportunity. A penalty shot is also awarded for a defender other than the goaltender covering the puck in the goal crease, a goaltender intentionally displacing his own goal posts during a breakaway to avoid a goal, a defender intentionally displacing his own goal posts when there is less than two minutes to play in regulation time or at any point during overtime, or a player or coach intentionally throwing a stick or other object at the puck or the puck carrier and the throwing action disrupts a shot or pass play.\nOfficials also stop play for puck movement violations, such as using one's hands to pass the puck in the offensive end, but no players are penalized for these offences. The sole exceptions are deliberately falling on or gathering the puck to the body, carrying the puck in the hand, and shooting the puck out of play in one's defensive zone (all penalized two minutes for delay of game).\nIn the NHL, a unique penalty applies to the goalies. The goalies now are forbidden to play the puck in the \"corners\" of the rink near their own net. This will result in a two-minute penalty against the goalie's team. Only in the area in front of the goal line and immediately behind the net (marked by two red lines on either side of the net) can the goalie play the puck.\nAn additional rule that has never been a penalty, but was an infraction in the NHL before recent rules changes, is the two-line offside pass. Prior to the 2005\u201306 NHL season, play was stopped when a pass from inside a team's defending zone crossed the centre line, with a face-off held in the defending zone of the offending team. Now, the centre line is no longer used in the NHL to determine a two-line pass infraction, a change that the IIHF had adopted in 1998. Players are now able to pass to teammates who are more than the blue and centre ice red line away.\nThe NHL has taken steps to speed up the game of hockey and create a game of finesse, by reducing the number of illegal hits, fights, and \"clutching and grabbing\" that occurred in the past. Rules are now more strictly enforced, resulting in more penalties, which provides more protection to the players and facilitates more goals being scored. The governing body for United States' amateur hockey has implemented many new rules to reduce the number of stick-on-body occurrences, as well as other detrimental and illegal facets of the game (\"zero tolerance\").\nIn men's hockey, but not in women's, a player may use his hip or shoulder to hit another player if the player has the puck or is the last to have touched it. This use of the hip and shoulder is called \"body checking\". Not all physical contact is legal\u2014in particular, hits from behind, hits to the head and most types of forceful stick-on-body contact are illegal.\nA \"delayed penalty call\" occurs when an offence is committed by the team that does not have possession of the puck. In this circumstance the team with possession of the puck is allowed to complete the play; that is, play continues until a goal is scored, a player on the opposing team gains control of the puck, or the team in possession commits an infraction or penalty of their own. Because the team on which the penalty was called cannot control the puck without stopping play, it is impossible for them to score a goal. In these cases, the team in possession of the puck can pull the goalie for an extra attacker without fear of being scored on. It is possible for the controlling team to mishandle the puck into their own net. If a delayed penalty is signalled and the team in possession scores, the penalty is still assessed to the offending player, but not served. In 2012, this rule was changed by the United States' National Collegiate Athletic Association (NCAA) for college level hockey. In college games, the penalty is still enforced even if the team in possession scores.\nOfficials.\nA typical game of hockey is governed by two to four \"officials\" on the ice, charged with enforcing the rules of the game. There are typically two \"linesmen\" who are mainly responsible for calling \"offside\" and \"icing\" violations, breaking up fights, and conducting faceoffs, and one or two \"referees\", who call goals and all other penalties. Linesmen can report to the referee(s) that a penalty should be assessed against an offending player in some situations. The restrictions on this practice vary depending on the governing rules. On-ice officials are assisted by off-ice officials who act as goal judges, time keepers, and official scorers.\nThe most widespread system is the \"three-man system\", which uses one referee and two linesmen. A less commonly used system is the two referee and one linesman system. This system is close to the regular three-man system except for a few procedure changes. Beginning with the National Hockey League, a number of leagues have implemented the \"four-official system\", where an additional referee is added to aid in the calling of penalties normally difficult to assess by one referee. The system is used in every NHL game since 2001, at IIHF World Championships, the Olympics and in many professional and high-level amateur leagues in North America and Europe.\nOfficials are selected by the league they work for. Amateur hockey leagues use guidelines established by national organizing bodies as a basis for choosing their officiating staffs. In North America, the national organizing bodies Hockey Canada and USA Hockey approve officials according to their experience level as well as their ability to pass rules knowledge and skating ability tests. Hockey Canada has officiating levels I through VI. USA Hockey has officiating levels 1 through 4.\nEquipment.\nProtective gear.\nSince men's ice hockey is a full-contact sport, body checks are allowed so injuries are a common occurrence. Protective equipment is mandatory and is enforced in all competitive situations. This includes a helmet with either a visor or a full face mask, shoulder pads, elbow pads, mouth guard, protective gloves, heavily padded shorts (also known as hockey pants) or a girdle, athletic cup (also known as a jock, for males; and jill, for females), shin pads, skates, and (optionally) a neck protector.\nGoaltenders.\nGoaltenders use different equipment. With hockey pucks approaching them at speeds of up to they must wear equipment with more protection. Goaltenders wear specialized goalie skates (these skates are built more for movement side to side rather than forwards and backwards), a jock or jill, large leg pads (there are size restrictions in certain leagues), blocking glove, catching glove, a chest protector, a goalie mask, and a large jersey. Goaltenders' equipment has continually become larger and larger, leading to fewer goals in each game and many official rule changes.\nIce skates.\nIce hockey skates are optimized for physical acceleration, speed and manoeuvrability. This includes rapid starts, stops, turns, and changes in skating direction. In addition, they must be rigid and tough to protect the skater's feet from contact with other skaters, sticks, pucks, the boards, and the ice itself. Rigidity also improves the overall manoeuvrability of the skate. Blade length, thickness (width), and curvature (rocker/radius) (front to back) and radius of hollow (across the blade width) are quite different from speed or figure skates. Hockey players usually adjust these parameters based on their skill level, position, and body type. The blade width of most skates are about thick.\nIce hockey stick.\nEach player other than the goaltender carries a stick consisting of a long, relatively wide, and slightly curved flat blade, attached to a shaft. The curve itself has a big impact on its performance. A deep curve allows for lifting the puck easier while a shallow curve allows for easier backhand shots. The flex of the stick also impacts the performance. Typically, a less flexible stick is meant for a stronger player since the player is looking for the right balanced flex that allows the stick to flex easily while still having a strong \"whip-back\" which sends the puck flying at high speeds. It is quite distinct from sticks in other sports games and most suited to hitting and controlling the flat puck. Its unique shape contributed to the early development of the game.\nThe goaltender carries a stick of a different design, with a larger blade and a wide, flat shaft. This stick is primarily intended to block shots, but the goaltender may use it to play the puck as well.\nInjury.\nIce hockey is a full-contact sport and carries a high risk of injury. Players are moving at speeds around approximately and much of the game revolves around the physical contact between the players. Skate blades, hockey sticks, shoulder contact, hip contact, and hockey pucks can all potentially cause injuries. Lace bite, an irritation felt on the front of the foot or ankle, is a common ice hockey injury.\nCompared to athletes who play other sports, ice hockey players are at higher risk of overuse injuries and injuries caused by early sports specialization by teenagers.\nAccording to the Hughston Health Alert, prior to the widespread use of helmets and face cages, \"Lacerations to the head, scalp, and face are the most frequent types of injury [in hockey].\"\nOne of the leading causes of head injury is body checking from behind. Due to the danger of delivering a check from behind, many leagues \u2013 including the NHL \u2013 have made this a major and game misconduct penalty. Another type of check that accounts for many of the player-to-player contact concussions is a check to the head resulting in a misconduct penalty (called \"head contact\"). In recent years, the NHL has implemented new rules which penalize and suspend players for illegal checks to the heads, as well as checks to unsuspecting players. Studies show that ice hockey causes 44.3% of all sports-related traumatic brain injuries among Canadian children.\nSome teams in the Swiss National League are testing out systems that combine helmet-integrated sensors and analysis software to reveal a player's ongoing brain injury risk during a game. These sensors provide players and coaches with real-time data on head impact strength, frequency, and severity. Furthermore, if the app determines that a particular impact has the potential to cause brain injury, it will alert the coach who can in turn seek medical attention for the individual.\nTactics.\nDefensive tactics.\nDefensive ice hockey tactics vary from more active to more conservative styles of play. One distinction is between man-to-man oriented defensive systems, and zonal oriented defensive systems, though a lot of teams use a combination between the two. Defensive skills involve \"pass interception\", \"shot blocking\", and \"stick checking\" (in which an attempt to take away the puck or cut off the puck lane is initiated by the stick of the defensive player). Tactical points of emphasis in ice hockey defensive play are concepts like \"managing gaps\" (gap control), \"boxing out\"' (not letting the offensive team go on the inside), and \"staying on the right side\" (of the puck). Another popular concept in ice hockey defensive tactics is that of playing a 200-foot game.\nChecking.\nAn important defensive tactic is checking\u2014attempting to take the puck from an opponent or to remove the opponent from play. \"Stick checking\", \"sweep checking\", and \"poke checking\" are legal uses of the stick to obtain possession of the puck. The \"neutral zone trap\" is designed to isolate the puck carrier in the neutral zone preventing him from entering the offensive zone. \"Body checking\" is using one's shoulder or hip to strike an opponent who has the puck or who is the last to have touched it (the last person to have touched the puck is still legally \"in possession\" of it, although a penalty is generally called if he is checked more than two seconds after his last touch). Body checking is also a penalty in certain leagues in order to reduce the chance of injury to players. Often the term checking is used to refer to body checking, with its true definition generally only propagated among fans of the game.\nOne of the most important strategies for a team is their \"forecheck\". Forechecking is the act of attacking the opposition in their defensive zone. Forechecking is an important part of the \"dump and chase\" strategy (i.e. shooting the puck into the offensive zone and then chasing after it). Each team uses their own unique system but the main ones are: 2\u20131\u20132, 1\u20132\u20132, and 1\u20134. The 2\u20131\u20132 is the most basic forecheck system where two forwards go in deep and pressure the opposition's defencemen, the third forward stays high and the two defencemen stay at the blueline. The 1\u20132\u20132 is a bit more conservative system where one forward pressures the puck carrier and the other two forwards cover the oppositions' wingers, with the two defencemen staying at the blueline. The 1\u20134 is the most defensive forecheck system, referred to as the neutral zone trap, where one forward applies pressure to the puck carrier around the oppositions' blueline and the other four players stand basically in a line by their blueline in hopes the opposition will skate into one of them. Another strategy is the left wing lock, which has two forwards pressure the puck and the left wing and the two defencemen stay at the blueline.\nOffensive tactics.\nOffensive tactics include improving a team's position on the ice by advancing the puck out of one's zone towards the opponent's zone, progressively by gaining lines, first your own blue line, then the red line and finally the opponent's blue line. NHL rules instated for the 2006 season redefined the offside rule to make the two-line pass legal; a player may pass the puck from behind his own blue line, past both that blue line and the centre red line, to a player on the near side of the opponents' blue line. Offensive tactics are designed ultimately to score a goal by taking a shot. When a player purposely directs the puck towards the opponent's goal, he or she is said to \"shoot\" the puck.\nA \"deflection\" is a shot that redirects a shot or a pass towards the goal from another player, by allowing the puck to strike the stick and carom towards the goal. A \"one-timer\" is a shot struck directly off a pass, without receiving the pass and shooting in two separate actions. \"Headmanning the puck\", also known as \"breaking out\", is the tactic of rapidly passing to the player farthest down the ice. \"Loafing\", also known as \"cherry-picking\", is when a player, usually a forward, skates behind an attacking team, instead of playing defence, in an attempt to create an easy scoring chance.\nA team that is losing by one or two goals in the last few minutes of play will often elect to \"pull the goalie\"; that is, remove the goaltender and replace him or her with an \"extra attacker\" on the ice in the hope of gaining enough advantage to score a goal. This is a desperate act, as it sometimes leads to the opposing team extending their lead by scoring a goal in the empty net.\nThere are many other little tactics used in the game of hockey. \"Cycling\" moves the puck along the boards in the offensive zone to create a scoring chance by making defenders tired or moving them out of position. \"Pinching\" is when a defenceman pressures the opposition's winger in the offensive zone when they are breaking out, attempting to stop their attack and keep the puck in the offensive zone. A \"saucer pass\" is a pass used when an opposition's stick or body is in the passing lane. It is the act of raising the puck over the obstruction and having it land on a teammate's stick.\nA deke, short for \"decoy\", is a feint with the body or stick to fool a defender or the goalie. Many modern players, such as Pavel Datsyuk, Sidney Crosby and Patrick Kane, have picked up the skill of \"dangling\", which is fancier deking and requires more stick handling skills.\nA tactic used by a player to keep possession of the puck is \"stick handling\" and also known as \"ragging\". A player can use their stick to manipulate the puck out of reach of opposing players, while attempting to skate past them. When combined with deking or dangling skills, a player can attempt an \"end-to-end rush\" and make a solo play to score. Ragging is also a common penalty-killing tactic to use up time during a penalty's duration.\nFights.\nAlthough fighting is officially prohibited in the rules, it is not an uncommon occurrence at the professional level, and its prevalence has been both a target of criticism and a considerable draw for the sport. At the professional level in North America fights are unofficially condoned. Enforcers and other players fight to demoralize the opposing players while exciting their own, as well as settling personal scores. A fight will also break out if one of the team's skilled players gets hit hard or someone receives what the team perceives as a dirty hit. The amateur game penalizes fisticuffs more harshly, as a player who receives a fighting major is also assessed at least a 10-minute misconduct penalty (NCAA and some Junior leagues) or a game misconduct penalty and suspension (high school and younger, as well as some casual adult leagues).\nWomen's ice hockey.\nHistory.\nWomen began playing the game of ice hockey in the late 19th century. Several games were recorded in the 1890s in Ottawa, Ontario, Canada. The women of Lord Stanley's family were known to participate in the game of ice hockey on the outdoor ice rink at Rideau Hall, the residence of Canada's Governor General.\nThe earliest available records of women's ice hockey were in the late 19th-century in Canada. Much like the men's game, women had previously been playing a conglomeration of stick-and-ball ice games. As with men's hockey, the women's game developed at first without an organizing body. A tournament in 1902 between Montreal and Trois-Rivi\u00e8res was billed as the first women's ice hockey championship tournament. Several tournaments, such as at the Banff Winter Carnival, were held in the early 20th century with numerous women's teams such as the Seattle Vamps and Vancouver Amazons. Organizations started to develop in the 1920s, such as the Ladies Ontario Hockey Association in Canada, and later, the Dominion Women's Amateur Hockey Association.\nStarting in Canada in 1961, the women's game spread to more universities after the \"Fitness and Amateur Sport Act\" came into force in whereby the Government of Canada made an official commitment to \"encourage, promote and develop fitness and amateur sport in Canada.\"\nToday, the women's game is played from youth through adult leagues, and at the university level in North America and internationally. In 2019, the Professional Women's Hockey Players Association was formed by over 150 players with the goal of creating a sustainable professional league for women's ice hockey in North America. Today, there are major professional women's hockey leagues: the Professional Women's Hockey League, with teams in the United States and Canada, and the Zhenskaya Hockey League, with teams in Russia and, previously, China.\nPrior to the professionalization of women's ice hockey in the 21st century, professional women hockey players who played against men tended to be goaltenders. The United States Hockey League (USHL) welcomed the first female professional ice hockey player in 1969\u201370, when the Marquette Iron Rangers signed 18-year-old goaltender Karen Koch. Only one woman has ever played in the National Hockey League (NHL), goaltender Manon Rh\u00e9aume. Rh\u00e9aume played in NHL pre-season games as a goaltender for the Tampa Bay Lightning against the St. Louis Blues and the Boston Bruins. In 2003, forward Hayley Wickenheiser played with the Kirkkonummi Salamat in the Finnish men's Suomi-sarja league. Women have occasionally competed in North American minor leagues: among them Rh\u00e9aume, and fellow goaltenders Kelly Dyer and Erin Whitten. Defenceman Angela Ruggiero became the first woman to actively play in a regular season professional hockey game in North America at a position other than goalie, playing in a single game for the Tulsa Oilers of the Central Hockey League.\nBetween 1995 and 2005 the number of women's hockey participants increased by 400 percent. In 2011, Canada had 85,827 women players, the United States had 65,609, Finland 4,760, Sweden 3,075 and Switzerland 1,172.\nWomen's ice hockey was added as an Olympic medal sport eight years after the first official women's ice hockey world championship in 1990, at the 1998 Winter Olympics in Nagano, Japan. \nWomen's World Championship.\nThe 1987 World Women's Hockey Tournament in Toronto was the first international competition in women's hockey, although it was not sanctioned by the IIHF. Two years later, the 1989 IIHF European Women Championships in West Germany was the first IIHF-sanctioned event and the first European Championship held in women's hockey, preceding the IIHF-sanctioned Women's World Championship. The first world ice hockey championship for women was the 1990 IIHF Women's World Championship in Ottawa. \nAs of 2025, more than forty national teams participate in the annual competition, across four divisions: ten teams play in the top division and twelve teams each in Division I, Division II, and Division III. From the introduction of women's ice hockey as a medal sport in 1998, the top division tournament was not held in Olympic years until a change was approved to the IIHF Statutes &amp; Bylaws in 2021; the 2022 top division tournament was the first to be held in an Olympic season.\nEquipment.\nPlayers in women's competition are required to wear protective full-face masks. At all levels, players must wear a pelvic protector, essentially the female equivalent of a jockstrap, known colloquially as a \"jill\" or \"jillstrap\". Other protective equipment for girls and women in ice hockey is sometimes specifically designed for the female body, such as shoulder pads designed to protect a women's breast area without reducing mobility.\nBody checking.\nBody checking has long been a divisive topic in women's hockey, and has largely been prohibited since the mid-1980s in Canada, and from there internationally. Canada's Rhonda Leeman Taylor was responsible for banning body contact from all Canadian national women's tournaments in 1983. Body checking in some of the women's hockey leagues in Canada was completely removed in 1986, which helped lead to a substantial increase in female participation in youth ice hockey in Canada.\nPrior to this point, body checking had been a part of the women's game in most cases, including in Europe. It was not until after the 1990 Women's World Championship that body checking was eliminated from women's hockey internationally. In addition, until the mid-2000s, obstruction and interference were allowed, including pushing players in front of the net, minor hooking, and setting picks. When the National Hockey League removed obstruction and interference in the mid-2000s, minor hockey leagues and female leagues followed suit. In women's IIHF ice hockey today, body checking is considered an \"illegal hit\" and is punishable by a minor penalty, major penalty and game misconduct, or match penalty.\nThe idea of reintroducing body checking to the female game after its removal in the 1980s and 1990s remains controversial. Some of those opposed to its reintroduction maintain it would lead to a loss of female participants, as once stated by Arto Sieppi, Finland's director of women's hockey. Sieppi made the statement in response to claims made by the head coach of Sweden's national women's team, Peter Elander, who had claimed its absence was due to patriarchal sexism.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Peter is a good friend of mine, but I totally disagree... First of all, it's a women's sport, and if bodychecking would be allowed, the number of young girls entering the game would decrease rapidly.\u2014\u200a\nThe Svenska damhockeyligan (SDHL), known as the Swedish Women's Hockey League in English, announced in 2022 that it would include body checking during its 2022\u201323 season, but would maintain a prohibition on open-ice hits. The new program also applies to the Damettan, Sweden's second-tier women's league. The Professional Women's Hockey League, the highest level of women's professional hockey, which debuted in 2024, also allows body checking. The PWHL rule-book outlines that body checking is permissible \"when there is a clear intention of playing the puck or attempting to 'gain possession' of the puck\", which is allowed principally along the boards. League executive Jayna Hefford has stated that body checking was included at the behest of players, and the league's physicality drew positive reviews when the league began play in January 2024.\nLeagues and championships.\nThe following is a list of professional ice hockey leagues by attendance:\nClub competition.\nNorth America.\nThe NHL is the best attended and most popular ice hockey league in the world, and is among the major professional sports leagues in the United States and Canada. The league's history began after Canada's National Hockey Association decided to disband in 1917; the result was the creation of the National Hockey League with four teams. The league expanded to the United States beginning in 1924 and had as many as 10 teams before contracting to six teams\u2014known today as the Original Six\u2014by 1942\u201343. In 1967, the NHL doubled in size to 12 teams, undertaking one of the greatest expansions in professional sports history. A few years later, in 1972, a new 12-team league, the World Hockey Association (WHA), was formed and its ensuing rivalry with the NHL caused a rapid escalation in players' salaries. In 1979, the 17-team NHL merged with the WHA creating a 21-team league. By 2017, the NHL had expanded to 31 teams, and after a realignment in 2013, these teams were divided into two conferences and four divisions. The league expanded to 32 teams in 2021.\nThe American Hockey League (AHL) is the primary developmental professional league for players aspiring to enter the NHL. It comprises 31 teams from the United States and Canada. It is run as a farm league to the NHL, with the vast majority of AHL players under contract to an NHL team. The ECHL (called the East Coast Hockey League before the 2003\u201304 season) is a mid-level minor league in the United States with a few players under contract to NHL or AHL teams.\nAs of 2019, there are three minor professional leagues with no NHL affiliations: the Federal Prospects Hockey League (FPHL), (LNAH), and the Southern Professional Hockey League (SPHL).\nU Sports ice hockey is the highest level of play at the Canadian university level under the auspices of U Sports, Canada's governing body for university sports. As these players compete at the university level, they are obligated to follow the rule of standard eligibility of five years.\nIn the United States especially, college hockey is popular and the best university teams compete in the annual NCAA Men's Ice Hockey Championship. The American Collegiate Hockey Association is composed of college teams at the club level.\nIn Canada, the Canadian Hockey League is an umbrella organization comprising three major junior leagues: the Ontario Hockey League, the Western Hockey League, and the Quebec Maritimes Junior Hockey League. It attracts players from Canada, the United States, and Europe. The major junior players are considered amateurs as they are under 21-years-old and not paid a salary, rather a stipend, and play a schedule similar to a professional league. Typically, the NHL drafts many players directly from the major junior leagues. In the United States, the United States Hockey League (USHL) is the highest junior league. Players in this league are also amateur with players required to be under 21-years old, but do not get a stipend, which allows players to retain their eligibility for participation in NCAA ice hockey.\nThe Professional Women's Hockey League is the highest level of club competition in women's hockey. It was founded in 2023 and debuted in 2024 with three teams in Canada and three in the United States.\nEurasia.\nThe Kontinental Hockey League (KHL) is the largest and most popular ice hockey league in Eurasia. The league is the direct successor to the Russian Super League, which in turn was the successor to the Soviet League, the history of which dates back to the Soviet adoption of ice hockey in the 1940s. The KHL was launched in 2008 with clubs predominantly from Russia, but featuring teams from other post-Soviet states. The league expanded beyond the former Soviet countries beginning in the 2011\u201312 season, with clubs in Croatia and Slovakia. The KHL currently comprises member clubs based in Belarus (1), China (1), Kazakhstan (1) and Russia (19) for a total of 22.\nThe second division of hockey in Eurasia is the Supreme Hockey League (VHL). This league features 24 teams from Russia and 2 from Kazakhstan. This league is currently being converted to a farm league for the KHL, similarly to the AHL's function in relation to the NHL. The third division is the Russian Hockey League, which features only teams from Russia. The Asia League, an international ice hockey league featuring clubs from China, Japan, South Korea, and the Russian Far East, is the successor to the Japan Ice Hockey League.\nThe highest junior league in Eurasia is the Junior Hockey League (MHL). It features 32 teams from post-Soviet states, predominantly Russia. The second tier to this league is the Junior Hockey League Championships (MHL-B).\nEurope.\nSeveral countries in Europe have their own top professional senior leagues. Many future KHL and NHL players start or end their professional careers in these leagues. The National League A in Switzerland, Swedish Hockey League in Sweden, SM-liiga in Finland, and Czech Extraliga in the Czech Republic are all very popular in their respective countries.\nBeginning in the 2014\u201315 season, the Champions Hockey League was launched, a league consisting of first-tier teams from several European countries, running parallel to the teams' domestic leagues. The competition is meant to serve as a Europe-wide ice hockey club championship. The competition is a direct successor to the European Trophy and is related to the 2008\u201309 tournament of the same name.\nThere are also several annual tournaments for clubs, held outside of league play. Pre-season tournaments include the European Trophy, Tampere Cup and the Pajulahti Cup. One of the oldest international ice hockey competition for clubs is the Spengler Cup, held every year in Davos, Switzerland, between Christmas and New Year's Day. It was first awarded in 1923 to the Oxford University Ice Hockey Club. The Memorial Cup, a competition for junior-level (age 20 and under) clubs is held annually from a pool of junior championship teams in Canada and the United States.\nInternational club competitions organized by the IIHF include the Continental Cup, the Victoria Cup and the European Women's Champions Cup. The World Junior Club Cup is an annual tournament of junior ice hockey clubs representing each of the top junior leagues.\nOther regions.\nThe Australian Ice Hockey League and New Zealand Ice Hockey League are represented by nine and five teams respectively. As of 2012, the two top teams of the previous season from each league compete in the Trans-Tasman Champions League.\nIce hockey in Africa is a small but growing sport; while no African ice hockey playing nation has a domestic national league, there are several regional leagues in South Africa.\nNational team competitions.\nIce hockey has been played at the Winter Olympics since 1924 (and was played at the summer games in 1920). Hockey is Canada's national winter sport, and Canadians are extremely passionate about the game. The nation has traditionally done very well at the Olympic Games, winning six of the first seven gold medals. By 1956, its amateur club teams and national teams could not compete with the teams of government-supported players from the Soviet Union. The USSR won all but two gold medals from 1956 to 1988. The United States won its first gold medal in 1960. On the way to winning the gold medal at the 1980 Lake Placid Olympics, amateur US college players defeated the heavily favoured Soviet squad\u2014an event known as the \"Miracle on Ice\" in the United States. Restrictions on professional players were fully dropped at the 1988 games in Calgary. NHL agreed to participate ten years later. The 1998 Games saw the full participation of players from the NHL, which suspended operations during the Games and has done so in subsequent Games up until 2018. The 2010 games in Vancouver were the first played in an NHL city since the inclusion of NHL players. The 2010 games were the first played on NHL-sized ice rinks, which are narrower than the IIHF standard.\nNational teams representing the member federations of the IIHF compete annually in the IIHF Ice Hockey World Championships. Teams are selected from the available players by the individual federations, without restriction on amateur or professional status. Since it is held in the spring, the tournament coincides with the annual NHL Stanley Cup playoffs and many of the top players are hence not available to participate in the tournament. Many of the NHL players who do play in the IIHF tournament come from teams eliminated before the playoffs or in the first round, and federations often hold open spots until the tournament to allow for players to join the tournament after their club team is eliminated. For many years, the tournament was an amateur-only tournament, but this restriction was removed, beginning in 1977.\nThe 1972 Summit Series and 1974 Summit Series, two series pitting the best Canadian and Soviet players without IIHF restrictions were major successes, and established a rivalry between Canada and the USSR. In the spirit of best-versus-best without restrictions on amateur or professional status, the series were followed by five Canada Cup tournaments, played in North America. Two NHL versus USSR series were also held: the 1979 Challenge Cup and Rendez-vous '87. The Canada Cup tournament later became the World Cup of Hockey, played in 1996, 2004 and 2016. The United States won in 1996 and Canada won in 2004 and 2016.\nSince the initial women's world championships in 1990, there have been fifteen tournaments. Women's hockey has been played at the Olympics since 1998. The only finals in the women's world championship or Olympics that did not involve both Canada and the United States were the 2006 Winter Olympic final between Canada and Sweden and 2019 World Championship final between the US and Finland.\nOther ice hockey tournaments featuring national teams include the World Junior Championship, the World U18 Championships, the World U-17 Hockey Challenge, the World Junior A Challenge, the Ivan Hlinka Memorial Tournament, the World Women's U18 Championships and the 4 Nations Cup. The annual Euro Hockey Tour, an unofficial European championship between the national men's teams of the Czech Republic, Finland, Russia and Sweden have been played since 1996\u201397.\nAttendance records.\nThe attendance record for an ice hockey game was set on December 11, 2010, when the University of Michigan's men's ice hockey team faced cross-state rival Michigan State in an event billed as \"The Big Chill at the Big House\". The game was played at Michigan's (American) football venue, Michigan Stadium in Ann Arbor, with a capacity of 109,901 as of the 2010 football season. When UM stopped sales to the public on May 6, 2010, with plans to reserve remaining tickets for students, over 100,000 tickets had been sold for the event. Ultimately, a crowd announced by UM as 113,411, the largest in the stadium's history (including football), saw the homestanding Wolverines win 5\u20130. \"Guinness World Records\", using a count of ticketed fans who actually entered the stadium instead of UM's figure of tickets sold, announced a final figure of 104,173.\nThe record was approached but not broken at the 2014 NHL Winter Classic, which also held at Michigan Stadium, with the Detroit Red Wings as the home team and the Toronto Maple Leafs as the opposing team with an announced crowd of 105,491. The record for an NHL Stanley Cup playoff game is 28,183, set on April 23, 1996, at the Thunderdome during a Tampa Bay Lightning \u2013 Philadelphia Flyers game.\nThe attendance record for a professional women's game was set on April 20, 2024, when a sold-out crowd of 21,105 people at the Bell Centre in Montreal watched a PWHL game between Montreal and Toronto.\nInternational status.\nIce hockey is most popular in Canada, Germany, Austria, Switzerland, Eastern Europe, Northern Europe, and the United States. Ice hockey is the official national winter sport of Canada. \nIn addition, ice hockey is the most popular winter sport in Austria, Belarus, the Czech Republic, Finland, Germany, Latvia, Norway, Russia, Slovakia, Sweden, and Switzerland. North America's National Hockey League (NHL) is the highest level for men's ice hockey and the strongest professional ice hockey league in the world. The Kontinental Hockey League (KHL) is the highest league in Russia and much of Eastern Europe. \nThe International Ice Hockey Federation (IIHF) is the formal governing body for international ice hockey, with the IIHF managing international tournaments and maintaining the IIHF World Ranking. Worldwide, the International Ice Hockey Federation has 83 member national associations, comprising 60 full members, 22 associate members, and one affiliate member.\nIn international competitions, the national teams of six countries (the Big Six) predominate: Canada, Czechia, Finland, Russia, Sweden, and the United States. Of the 69 medals awarded all-time in men's competition at the Olympics, only seven medals were not awarded to one of those countries (or two of their precursors: the Soviet Union for Russia, and Czechoslovakia for Czechia). In the annual Ice Hockey World Championships, 177 of 201 medals have been awarded to the six nations; Canada has won the most gold medals. Teams outside the Big Six have won only nine medals in either competition since 1953. \nThe World Cup of Hockey is organized by the National Hockey League and the National Hockey League Players' Association (NHLPA), unlike the annual World Championships and quadrennial Olympic tournament, both run by the International Ice Hockey Federation. World Cup games are played under NHL rules and not those of the IIHF, and the tournament occurs prior to the NHL pre-season, allowing for all NHL players to be available, unlike the World Championships, which overlaps with the NHL's Stanley Cup playoffs. Furthermore, all twelve Women's Olympic and 36 IIHF Women's World Championship medals were awarded to one of the Big Six. The Canadian national team or the United States national team have between them won every gold medal of either series.\nNumber of registered players by country.\nNumber of registered hockey players, including male, female and junior, provided by the respective countries' federations. This list only includes the 39 of 84 IIHF member countries with more than 1,000 registered players as of March 2025.\nVariants.\nPond hockey.\nPond hockey is a form of ice hockey played generally as pick-up hockey on lakes, ponds and artificial outdoor rinks during the winter. Pond hockey is commonly referred to in hockey circles as shinny. Its rules differ from traditional hockey because there is no hitting and very little shooting, placing a greater emphasis on skating, stickhandling and passing abilities. Since 2002, the World Pond Hockey Championship has been played on Roulston Lake in Tobique Valley, New Brunswick, Canada. Since 2006, the US Pond Hockey Championships have been played in Minneapolis, Minnesota, and the Canadian National Pond Hockey Championships have been played in Huntsville, Ontario.\nSledge hockey.\nSledge hockey is an adaption of ice hockey designed for players who have a physical disability. Players are seated in sleds and use a specialized hockey stick that also helps the player navigate on the ice. The sport was created in Sweden in the early 1960s and is played under similar rules to ice hockey.\nIn popular culture.\nIce hockey is the official winter sport of Canada. Ice hockey, partially because of its popularity as a major professional sport, has been a source of inspiration for numerous films, television episodes and songs in Canadian and American popular culture.\nReferences.\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "14791", "revid": "910180", "url": "https://en.wikipedia.org/wiki?curid=14791", "title": "IEEE 802.3", "text": "Collection of standards for wired Ethernet\nIEEE 802.3 is a working group and a collection of standards defining the physical layer and data link layer's media access control (MAC) of wired Ethernet. The standards are produced by the working group of the Institute of Electrical and Electronics Engineers (IEEE). This set of standards generally applies to local area networks (LANs) and has some wide area network (WAN) applications. Physical connections are made between network nodes and, usually, various network infrastructure devices (hubs, switches, routers) by various types of copper cables or optical fiber.\n802.3 standards support the IEEE 802.1 network architecture.\n802.3 also defines a LAN access method using carrier-sense multiple access with collision detection (CSMA/CD).\nCommunication standards.\n&lt;templatestyles src=\"template:sticky header/styles.css\"/&gt;\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "14793", "revid": "6707", "url": "https://en.wikipedia.org/wiki?curid=14793", "title": "Integral data types", "text": ""}
{"id": "14794", "revid": "218586", "url": "https://en.wikipedia.org/wiki?curid=14794", "title": "Integer (computer science)", "text": "Datum of integral data type\nIn computer science, an integer is a datum of integral data type, a data type that represents some range of mathematical integers. Integral data types may be of different sizes and may or may not be allowed to contain negative values. Integers are commonly represented in a computer as a group of binary digits (bits). The size of the grouping varies so the set of integer sizes available varies between different types of computers. Computer hardware nearly always provides a way to represent a processor register or memory address as an integer.\nValue and representation.\nThe \"value\" of an item with an integral type is the mathematical integer that it corresponds to. Integral types may be \"unsigned\" (capable of representing only non-negative integers) or \"signed\" (capable of representing negative integers as well).\nAn integer value is typically specified in the source code of a program as a sequence of digits optionally prefixed with + or \u2212. Some programming languages allow other notations, such as hexadecimal (base 16) or octal (base 8). Some programming languages also permit digit group separators.\nThe \"internal representation\" of this datum is the way the value is stored in the computer's memory. Unlike mathematical integers, a typical datum in a computer has some minimal and maximum possible value.\nThe most common representation of a positive integer is a string of bits, using the binary numeral system. The order of the memory bytes storing the bits varies; see endianness. The \"width\", \"precision\", or \"bitness\" of an integral type is the number of bits in its representation. An integral type with \"n\" bits can encode 2\"n\" numbers; for example an unsigned type typically represents the non-negative values 0 through 2\"n\" \u2212 1. Other encodings of integer values to bit patterns are sometimes used, for example binary-coded decimal or Gray code, or as printed character codes such as ASCII.\nThere are four well-known ways to represent signed numbers in a binary computing system. The most common is two's complement, which allows a signed integral type with \"n\" bits to represent numbers from \u22122(\"n\"\u22121) through 2(\"n\"\u22121) \u2212 1. Two's complement arithmetic is convenient because there is a perfect one-to-one correspondence between representations and values (in particular, no separate +0 and \u22120), and because addition, subtraction and multiplication do not need to distinguish between signed and unsigned types. Other possibilities include offset binary, sign-magnitude, and ones' complement.\nSome computer languages define integer sizes in a machine-independent way; others have varying definitions depending on the underlying processor word size. Not all language implementations define variables of all integer sizes, and defined sizes may not even be distinct in a particular implementation. An integer in one programming language may be a different size in a different language, on a different processor, or in an execution context of different bitness; see .\nSome older computer architectures used decimal representations of integers, stored in binary-coded decimal (BCD) or other format. These values generally require data sizes of 4 bits per decimal digit (sometimes called a nibble), usually with additional bits for a sign. Many modern CPUs provide limited support for decimal integers as an extended datatype, providing instructions for converting such values to and from binary values. Depending on the architecture, decimal integers may have fixed sizes (e.g., 7 decimal digits plus a sign fit into a 32-bit word), or may be variable-length (up to some maximum digit size), typically occupying two digits per byte (octet).\nCommon integral data types.\nDifferent CPUs support different integral data types. Typically, hardware will support both signed and unsigned types, but only a small, fixed set of widths.\nThe table above lists integral type widths that are supported in hardware by common processors. High-level programming languages provide more possibilities. It is common to have a 'double width' integral type that has twice as many bits as the biggest hardware-supported type. Many languages also have \"bit-field\" types (a specified number of bits, usually constrained to be less than the maximum hardware-supported width) and \"range\" types (that can represent only the integers in a specified range).\nSome languages, such as Lisp, Smalltalk, REXX, Haskell, Python, and Raku, support \"arbitrary precision\" integers (also known as \"infinite precision integers\" or \"bignums\"). Other languages that do not support this concept as a top-level construct may have libraries available to represent very large numbers using arrays of smaller variables, such as Java's \n class or Perl's \"codice_1\" package. These use as much of the computer's memory as is necessary to store the numbers; however, a computer has only a finite amount of storage, so they, too, can only represent a finite subset of the mathematical integers. These schemes support very large numbers; for example one kilobyte of memory could be used to store numbers up to 2466 decimal digits long.\nA Boolean type is a type that can represent only two values: 0 and 1, usually identified with \"false\" and \"true\" respectively. This type can be stored in memory using a single bit, but is often given a full byte for convenience of addressing and speed of access.\nA four-bit quantity is known as a \"nibble\" (when eating, being smaller than a \"bite\") or \"nybble\" (being a pun on the form of the word \"byte\"). One nibble corresponds to one digit in hexadecimal and holds one digit or a sign code in binary-coded decimal.\nBytes and octets.\nThe term \"byte\" initially meant 'the smallest addressable unit of memory'. In the past, 5-, 6-, 7-, 8-, and 9-bit bytes have all been used. There have also been computers that could address individual bits ('bit-addressed machine'), or that could only address 16- or 32-bit quantities ('word-addressed machine'). The term \"byte\" was usually not used at all in connection with bit- and word-addressed machines.\nThe term \"octet\" always refers to an 8-bit quantity. It is mostly used in the field of computer networking, where computers with different byte widths might have to communicate.\nIn modern usage \"byte\" almost invariably means eight bits, since all other sizes have fallen into disuse; thus \"byte\" has come to be synonymous with \"octet\".\nWords.\nThe term 'word' is used for a small group of bits that are handled simultaneously by processors of a particular architecture. The size of a word is thus CPU-specific. Many different word sizes have been used, including 6, 8, 12, 16, 18, 24, 32, 36, 39, 40, 48, 60, and 64 bits. Since it is architectural, the size of a \"word\" is usually set by the first CPU in a family, rather than the characteristics of a later compatible CPU. The meanings of terms derived from \"word\", such as \"longword\", \"doubleword\", \"quadword\", and \"halfword\", also vary with the CPU and OS.\nPractically all new desktop processors are capable of using 64-bit words, though embedded processors with 8- and 16-bit word size are still common. The 36-bit word length was common in the early days of computers.\nOne important cause of non-portability of software is the incorrect assumption that all computers have the same word size as the computer used by the programmer. For example, if a programmer using the C language incorrectly declares as int a variable that will be used to store values greater than 215\u22121, the program will fail on computers with 16-bit integers. That variable should have been declared as long, which has at least 32 bits on any computer. Programmers may also incorrectly assume that a pointer can be converted to an integer without loss of information, which may work on (some) 32-bit computers, but fail on 64-bit computers with 64-bit pointers and 32-bit integers. This issue is resolved by C99 in stdint.h in the form of .\nThe \"bitness\" of a program may refer to the word size (or bitness) of the processor on which it runs, or it may refer to the width of a memory address or pointer, which can differ between execution modes or contexts. For example, 64-bit versions of Microsoft Windows support existing 32-bit binaries, and programs compiled for Linux's x32 ABI run in 64-bit mode yet use 32-bit memory addresses.\nStandard integer.\nThe standard integer size is platform-dependent.\nIn C, it is denoted by int and required to be at least 16 bits. Windows and Unix systems have 32-bit ints on both 32-bit and 64-bit architectures.\nShort integer.\nA \"short integer\" can represent a whole number that may take less storage, while having a smaller range, compared with a standard integer on the same machine.\nIn C, it is denoted by short. It is required to be at least 16 bits, and is often smaller than a standard integer, but this is not required. A conforming program can assume that it can safely store values between \u2212(215 \u2212 1) and 215 \u2212 1, but it may not assume that the range is not larger. In Java, a short is \"always\" a 16-bit integer. In the Windows API, the datatype SHORT is defined as a 16-bit signed integer on all machines.\nLong integer.\nA \"long integer\" can represent an integer whose range is greater than or equal to that of a standard integer on the same machine.\nIn C, it is denoted by long. It is required to be at least 32 bits, and may or may not be larger than a standard integer. A conforming program can assume that it can safely store values between \u2212(231 \u2212 1) and 231 \u2212 1, but it may not assume that the range is not larger.\n&lt;templatestyles src=\"Template:Table alignment/tables.css\" /&gt;\nLong long.\nIn the C99 version of the C programming language and the C++11 version of C++, a codice_2 type is supported that has double the minimum capacity of the standard codice_3. This type is not supported by compilers that require C code to be compliant with the previous C++ standard, C++03, because the long long type did not exist in C++03. For an ANSI/ISO compliant compiler, the minimum requirements for the specified ranges, that is, \u2212(263 \u2212 1) to 263 \u2212 1 for signed and 0 to 264 \u2212 1 for unsigned, must be fulfilled; however, extending this range is permitted. This can be an issue when exchanging code and data between platforms, or doing direct hardware access. Thus, there are several sets of headers providing platform independent exact width types. The C standard library provides \"stdint.h\"; this was introduced in C99 and C++11.\nSyntax.\nInteger literals can be written as regular Arabic numerals, consisting of a sequence of digits and with negation indicated by a minus sign before the value. However, most programming languages disallow use of commas or spaces for digit grouping. Examples of integer literals are:\nThere are several alternate methods for writing integer literals in many programming languages:\nExtreme values.\nIn many programming languages, there exist predefined constants representing the least and the greatest values representable with a given integer type. \nNames for these include\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "14795", "revid": "42195518", "url": "https://en.wikipedia.org/wiki?curid=14795", "title": "Infectious disease", "text": ""}
{"id": "14800", "revid": "11096", "url": "https://en.wikipedia.org/wiki?curid=14800", "title": "Icon", "text": "Religious work of art in Christianity\nAn icon (from grc \" \"\" ()\"\u00a0'image, resemblance') is a religious work of art, most commonly a painting, in the cultures of the Eastern Orthodox, Oriental Orthodox, Catholic, and Lutheran churches. The most common subjects include Jesus, Mary, saints, and angels. Although especially associated with portrait-style images concentrating on one or two main figures, the term also covers most of the religious images in a variety of artistic media produced by Eastern Christianity, including narrative scenes, usually from the Bible or the lives of saints.\nIcons are most commonly painted on wood panels with egg tempera, but they may also be cast in metal or carved in stone or embroidered on cloth or done in mosaic or fresco work or printed on paper or metal, etc. Comparable images from Western Christianity may be classified as \"icons\", although \"iconic\" may also be used to describe the static style of a devotional image. In the Greek language, the term for icon painting uses the same word as for \"writing\", and Orthodox sources often translate it into English as \"icon writing\".\nEastern Orthodox tradition holds that the production of Christian images dates back to the very early days of Christianity, and that it has been a continuous tradition since then. Modern academic art history considers that, while images may have existed earlier, the tradition can be traced back only as far as the 3rd century, and that the images which survive from Early Christian art often differ greatly from later ones. The icons of later centuries can be linked, often closely, to images from the 5th century onwards, though very few of these survive. Widespread destruction of images occurred during the Byzantine Iconoclasm of 726\u2013842, although this did settle permanently the question of the appropriateness of images. Since then, icons have had a great continuity of style and subject, far greater than in the icons of the Western church. At the same time there has been change and development.\nHistory.\nEmergence of the icon.\nOrigins in primitive Christianity in the first century.\nPre-Christian religions had produced and used art works. Statues and paintings of various gods and deities were regularly worshiped and venerated. It is unclear when Christians took up such activities. Christian tradition dating from the 8th century identifies Luke the Evangelist as the first icon painter, but this might not reflect historical facts. A general assumption that early Christianity was generally aniconic, opposed to religious imagery in both theory and practice until about 200, has been challenged by Paul Corby Finney's analysis of early Christian writing and material remains (1994). His assumption distinguishes three different sources of attitudes affecting early Christians on the issue: \"first that humans could have a direct vision of God; second that they could not; and, third, that although humans could see God they were best advised not to look, and were strictly forbidden to represent what they had seen\".\nThese derived respectively from Greek and Near Eastern pagan religions, from Ancient Greek philosophy, and from the Jewish tradition and the Old Testament. Of the three, Finney concludes that \"overall, Israel's aversion to sacred images influenced early Christianity considerably less than the Greek philosophical tradition of invisible deity apophatically defined\", so placing less emphasis on the Jewish background of most of the first Christians than most traditional accounts.\nFinney suggests that \"the reasons for the non-appearance of Christian art before 200 have nothing to do with principled aversion to art, with other-worldliness, or with anti-materialism. The truth is simple and mundane: Christians lacked land and capital. Art requires both. As soon as they began to acquire land and capital, Christians began to experiment with their own distinctive forms of art\".\nAside from the legend that Pilate had made an image of Christ, the 4th-century Eusebius of Caesarea, in his \"Church History\", provides a more substantial reference to a \"first\" icon of Jesus. He relates that King Abgar of Edessa (died c.\u200950 CE) sent a letter to Jesus at Jerusalem, asking Jesus to come and heal him of an illness. This version of the Abgar story does not mention an image. A later account found in the Syriac \"Doctrine of Addai\" (c.\u2009400?) mentions a painted image of Jesus in the story. Even later, in the 6th-century account given by Evagrius Scholasticus, the painted image transforms into an image that miraculously appeared on a towel when Christ pressed the cloth to his wet face. Further legends relate that the cloth remained in Edessa until the 10th century, when it was taken by General John Kourkouas to Constantinople. It went missing in 1204 when Crusaders sacked Constantinople, but by then numerous copies had firmly established its iconic type.\nThe 4th-century Christian Aelius Lampridius produced the earliest known written records of Christian images treated like icons (in a pagan or Gnostic context) in his \"Life of Alexander Severus\" (xxix) that formed part of the \"Augustan History\". According to Lampridius, the emperor Alexander Severus (r.\u2009222\u00a0\u2013\u00a0235), himself not a Christian, had kept a domestic chapel for the veneration of images of deified emperors, of portraits of his ancestors, and of Christ, Apollonius, Orpheus and Abraham. Saint Irenaeus, (c.\u2009130\u2013202) in his \"Against Heresies\" (1:25;6) says scornfully of the Gnostic Carpocratians:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;They also possess images, some of them painted, and others formed from different kinds of material; while they maintain that a likeness of Christ was made by Pilate at that time when Jesus lived among them. They crown these images, and set them up along with the images of the philosophers of the world that is to say, with the images of Pythagoras, and Plato, and Aristotle, and the rest. They have also other modes of honouring these images, after the same manner of the Gentiles [pagans].\nOn the other hand, Irenaeus does not speak critically of icons or portraits in a general sense\u2014only of certain gnostic sectarians' use of icons.\nAnother criticism of image veneration appears in the non-canonical 2nd-century Acts of John (generally considered a gnostic work), in which the Apostle John discovers that one of his followers has had a portrait made of him, and is venerating it:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;[John] went into the bedchamber, and saw the portrait of an old man crowned with garlands, and lamps and altars set before it. And he called him and said: Lycomedes, what do you mean by this matter of the portrait? Can it be one of thy gods that is painted here? For I see that you are still living in heathen fashion.\u2014\u200a\nLater in the passage John says, \"But this that you have now done is childish and imperfect: you have drawn a dead likeness of the dead.\"\nAt least some of the hierarchy of the Christian churches still strictly opposed icons in the early 4th century. At the Spanish non-ecumenical Synod of Elvira (c.\u2009305) bishops concluded, \"Pictures are not to be placed in churches, so that they do not become objects of worship and adoration\".\nBishop Epiphanius of Salamis, wrote his letter 51 to John, Bishop of Jerusalem (c.\u2009394) in which he recounted how he tore down an image in a church and admonished the other bishop that such images are \"opposed[...] to our religion\".\nIcons in Eusebius to Philostorgius (425 AD).\nElsewhere in his \"Church History\", Eusebius reports seeing what he took to be portraits of Jesus, Peter and Paul, and also mentions a bronze statue at Banias/Paneas under Mount Hermon, of which he wrote, \"They say that this statue is an image of Jesus\". Further, he relates that locals regarded the image as a memorial of the healing of the woman with an issue of blood by Jesus (Luke 8:43\u201348), because it depicted a standing man wearing a double cloak and with arm outstretched, and a woman kneeling before him with arms reaching out as if in supplication.\nJohn Francis Wilson suggests the possibility that this refers to a pagan bronze statue whose true identity had been forgotten. Some have thought it to represent Aesculapius, the Greek god of healing, but the description of the standing figure and the woman kneeling in supplication precisely matches images found on coins depicting the bearded emperor Hadrian (r.\u2009117\u00a0\u2013\u00a0138) reaching out to a female figure\u2014symbolizing a province\u2014kneeling before him.\nWhen asked by Constantia (Emperor Constantine's half-sister) for an image of Jesus, Eusebius denied the request, replying: \"To depict purely the human form of Christ before its transformation, on the other hand, is to break the commandment of God and to fall into pagan error.\" Hence Jaroslav Pelikan calls Eusebius \"the father of iconoclasm\".\nAfter the emperor Constantine I extended official toleration of Christianity within the Roman Empire in 313, huge numbers of pagans became converts. This period of the Historiography of Christianization of the Roman Empire probably saw the use of Christian images become very widespread among the faithful, though with great differences from pagan habits. Robin Lane Fox states \"By the early fifth century, we know of the ownership of private icons of saints; by c.\u2009480\u2013500, we can be sure that the inside of a saint's shrine would be adorned with images and votive portraits, a practice which had probably begun earlier.\"\nWhen Constantine himself (r.\u2009306\u00a0\u2013\u00a0337) apparently converted to Christianity, the majority of his subjects remained pagans. The Roman Imperial cult of the divinity of the emperor, expressed through the traditional burning of candles and the offering of incense to the emperor's image, was tolerated for a period because it would have been politically dangerous to attempt to suppress it. In the 5th century the courts of justice and municipal buildings of the empire still honoured the portrait of the reigning emperor in this way.\nIn 425 Philostorgius, an allegedly Arian Christian, charged the Orthodox Christians in Constantinople with idolatry because they still honored the image of the emperor Constantine the Great in this way. Dix notes that this occurred more than a century before the first extant reference to a similar honouring of the image of Jesus or of his apostles or saints known today, but that it would seem a natural progression for the image of Christ, the King of Heaven and Earth, to be paid similar veneration as that given to the earthly Roman emperor. However, the Orthodox, Eastern Catholics, Eastern Lutherans, and other groups insist on explicitly distinguishing the veneration of icons from the worship of idols by pagans.&lt;templatestyles src=\"Crossreference/styles.css\" /&gt;\nTheodosius to Justinian.\nAfter adoption of Christianity as the only permissible Roman state religion under Theodosius I, Christian art began to change not only in quality and sophistication, but also in nature. This was in no small part due to Christians being free for the first time to express their faith openly without persecution from the state, in addition to the faith spreading to the non-poor segments of society. Paintings of martyrs and their feats began to appear, and early writers commented on their lifelike effect, one of the elements a few Christian writers criticized in pagan art\u2014the ability to imitate life. The writers mostly criticized pagan works of art for pointing to false gods, thus encouraging idolatry. Statues in the round were avoided as being too close to the principal artistic focus of pagan cult practices, as they have continued to be (with some small-scale exceptions) throughout the history of Eastern Christianity.\nNilus of Sinai (d. c.\u2009430), in his \"Letter to Heliodorus Silentiarius\", records a miracle in which Saint Plato of Ankyra appeared to a Christian in a dream. The saint was recognized because the young man had often seen his portrait. This recognition of a religious apparition from likeness to an image was also a characteristic of pagan pious accounts of appearances of gods to humans, and was a regular \"topos\" in hagiography. One critical recipient of a vision from Saint Demetrius of Thessaloniki apparently specified that the saint resembled the \"more ancient\" images of him\u2014presumably the 7th-century mosaics still in Hagios Demetrios. Another, an African bishop, had been rescued from Arab slavery by a young soldier called Demetrios, who told him to go to his house in Thessaloniki. Having discovered that most young soldiers in the city seemed to be called Demetrios, he gave up and went to the largest church in the city, to find his rescuer on the wall.\nDuring this period the church began to discourage all non-religious human images\u2014the Emperor and donor figures counting as religious. This became largely effective, so that most of the population would only ever see religious images and those of the ruling class. The word \"icon\" referred to any and all images, not just religious ones, but there was barely a need for a separate word for these.\nLuke's portrait of Mary.\nIt is in a context attributed to the 5th century that the first mention of an image of Mary painted from life appears, though earlier paintings on catacomb walls bear resemblance to modern icons of Mary. Theodorus Lector, in his 6th-century \"History of the Church\" 1:1 stated that Eudokia (wife of emperor Theodosius II, d. 460) sent an image of the \"Mother of God\" named Icon of the Hodegetria from Jerusalem to Pulcheria, daughter of Arcadius, the former emperor and father of Theodosius II. The image was specified to have been \"painted by the Apostle Luke.\"\nMargherita Guarducci relates a tradition that the original icon of Mary attributed to Luke, sent by Eudokia to Pulcheria from Palestine, was a large circular icon only of her head. When the icon arrived in Constantinople it was fitted in as the head into a very large rectangular icon of her holding the Christ child and it is this composite icon that became the one historically known as the Hodegetria. She further states another tradition that when the last Latin Emperor of Constantinople, Baldwin II, fled Constantinople in 1261 he took this original circular portion of the icon with him.\nThis remained in the possession of the Angevin dynasty who had it inserted into a much larger image of Mary and the Christ child, which is presently enshrined above the high altar of the Benedictine Abbey church of Montevergine. This icon was subjected to repeated repainting over the subsequent centuries, so that it is difficult to determine what the original image of Mary's face would have looked like. Guarducci states that in 1950 an ancient image of Mary at the Church of Santa Francesca Romana was determined to be a very exact, but reverse mirror image of the original circular icon that was made in the 5th century and brought to Rome, where it has remained until the present.\nIn later tradition the number of icons of Mary attributed to Luke greatly multiplied. The Salus Populi Romani, the Theotokos of Vladimir, the Theotokos Iverskaya of Mount Athos, the Theotokos of Tikhvin, the Theotokos of Smolensk and the Black Madonna of Cz\u0119stochowa are examples, and another is in the cathedral on St Thomas Mount, which is believed to be one of the seven painted by Luke the Evangelist and brought to India by Thomas the Apostle. Ethiopia has at least seven more. Bissera V. Pentcheva concludes, \"The myth [of Luke painting an icon] was invented in order to support the legitimacy of icon veneration during the Iconoclastic controversy\" (8th and 9th centuries, much later than most art historians put it). According to Reformed Baptist pastor John Carpenter, by claiming the existence of a portrait of the Theotokos painted during her lifetime by the evangelist Luke, the iconodules \"fabricated evidence for the apostolic origins and divine approval of images.\"\nIn the period before and during the Iconoclastic Controversy, stories attributing the creation of icons to the New Testament period greatly increased, with several apostles and even Mary herself believed to have acted as the artist or commissioner of images (also embroidered in the case of Mary).\nIconoclast period.\nThere was a continuing opposition to images and their misuse within Christianity from very early times. \"Whenever images threatened to gain undue influence within the church, theologians have sought to strip them of their power\". Further, \"there is no century between the fourth and the eighth in which there is not some evidence of opposition to images even within the Church\". Nonetheless, popular favor for icons guaranteed their continued existence, while no systematic apologia for or against icons, or doctrinal authorization or condemnation of icons yet existed.\nThe use of icons was seriously challenged by Byzantine Imperial authority in the 8th century. Though by this time opposition to images was strongly entrenched in Judaism and Islam, attribution of the impetus toward an iconoclastic movement in Eastern Orthodoxy to Muslims or Jews \"seems to have been highly exaggerated, both by contemporaries and by modern scholars\".\nThough significant in the history of religious doctrine, the Byzantine controversy over images is not seen as of primary importance in Byzantine history; \"[f]ew historians still hold it to have been the greatest issue of the period\".\nThe Iconoclastic period began when images were banned by Emperor Leo III the Isaurian sometime between 726 and 730. Under his son Constantine V, a council forbidding image veneration was held at Hieria near Constantinople in 754. Image veneration was later reinstated by the Empress Regent Irene, under whom another council was held reversing the decisions of the previous iconoclast council and taking its title as Seventh Ecumenical Council. The council anathemized all who hold to iconoclasm, i.e. those who held that veneration of images constitutes idolatry. Then the ban was enforced again by Leo V in 815. Finally, icon veneration was decisively restored by Empress Regent Theodora in 843 at the Council of Constantinople.\nFrom then on all Byzantine coins had a religious image or symbol on the reverse, usually an image of Christ for larger denominations, with the head of the Emperor on the obverse, reinforcing the bond of the state and the divine order.\nThe tradition of (, literally 'not-made-by-hand') accrued to icons that are alleged to have come into existence miraculously, not by a human painter. Such images functioned as powerful relics as well as icons, and their images were naturally seen as authoritative as to the true appearance of the subject: naturally and especially because of the reluctance to accept mere human productions as embodying anything of the divine, a commonplace of Christian deprecation of man-made \"idols\". Like icons believed to be painted directly from the live subject, they therefore acted as important references for other images in the tradition. Beside the developed legend of the \"mandylion\" or Image of Edessa was the tale of the Veil of Veronica, whose very name signifies \"true icon\" or \"true image\", the fear of a \"false image\" remaining strong.\nStylistic developments.\nAlthough there are earlier records of their use, no panel icons earlier than the few from the 6th century preserved at the Greek Orthodox Saint Catherine's Monastery in Egypt survive, as the other examples in Rome have all been drastically over-painted. The surviving evidence for the earliest depictions of Christ, Mary and saints therefore comes from wall-paintings, mosaics and some carvings. They are realistic in appearance, in contrast to the later stylization. They are broadly similar in style, though often much superior in quality, to the mummy portraits done in wax (encaustic) and found at Fayyum in Egypt.\nAs can be judged from such items, the first depictions of Jesus were generic, rather than portrait images, generally representing him as a beardless young man. It was some time before the earliest examples of the long-haired, bearded face that was later to become standardized as the image of Jesus appeared. When they did begin to appear there was still variation. Augustine of Hippo (354\u2013430) said that no one knew the appearance of Jesus or that of Mary. However, Augustine was not a resident of the Holy Land and therefore was not familiar with the local populations and their oral traditions. Gradually, paintings of Jesus took on characteristics of portrait images.\nAt this time the manner of depicting Jesus was not yet uniform, and there was some controversy over which of the two most common icons was to be favored. The first or \"Semitic\" form showed Jesus with short and \"frizzy\" hair; the second showed a bearded Jesus with hair parted in the middle, the manner in which the god Zeus was depicted. Theodorus Lector remarked that of the two, the one with short and frizzy hair was \"more authentic\". To support his assertion, he relates a story (excerpted by John of Damascus) that a pagan commissioned to paint an image of Jesus used the \"Zeus\" form instead of the \"Semitic\" form, and that as punishment his hands withered.\nThough their development was gradual, it is possible to date the full-blown appearance and general ecclesiastical (as opposed to simply popular or local) acceptance of Christian images as venerated and miracle-working objects to the 6th century, when, as Hans Belting writes, \"we first hear of the church's use of religious images\". \"As we reach the second half of the sixth century, we find that images are attracting direct veneration and some of them are credited with the performance of miracles\". Cyril Mango writes, \"In the post-Justinianic period the icon assumes an ever increasing role in popular devotion, and there is a proliferation of miracle stories connected with icons, some of them rather shocking to our eyes\". However, the earlier references by Eusebius and Irenaeus indicate veneration of images and reported miracles associated with them as early as the 2nd century.\nSymbolism.\nIn the icons of Eastern Orthodoxy, and of the early Medieval West, very little room is made for artistic license. Almost everything within the image has a symbolic aspect. Christ, the saints, and the angels all have halos. Angels (and often John the Baptist) have wings because they are messengers. Figures have consistent facial appearances, hold attributes personal to them, and use a few conventional poses. Archangels bear a thin staff and sometimes a mirror.\nColour plays an important role as well. Gold represents the radiance of Heaven; red, divine life. Blue is the colour of human life, white is the Uncreated Light of God, only used for resurrection and transfiguration of Christ. In icons of Jesus and Mary, Jesus wears red undergarment with a blue outer garment (representing God becoming human) and Mary wears a blue undergarment with a red overgarment (representing a human who was granted gifts by God), and thus the doctrine of deification is conveyed by icons. Letters are symbols too. Most icons incorporate some calligraphic text naming the person or event depicted. Even this is often presented in a stylized manner.\nPalladium and miracles.\nThe historical tradition of icons used for purposes other than visual depiction are the Palladium (protective image), the Palladium (classical antiquity), the , and various \"folk\" traditions associated with folk religion. Of these various forms the oldest tradition dates back to before the Christian era among the ancient Greeks. The various \"folk\" traditions are more poorly documented and often are associated with local folk narratives of uncertain origin.\nIn English, since around 1600, the word \"palladium\" has been used figuratively to mean anything believed to provide protection or safety, and in particular in Christian contexts a sacred relic or icon believed to have a protective role in military contexts for a whole city, people or nation. Such beliefs first become prominent in the Eastern Churches in the period after the reign of the Byzantine Emperor Justinian I, and later spread to the Western church. Palladia were processed around the walls of besieged cities and sometimes carried into battle.\nEastern Orthodox teaching.\nThe Eastern Orthodox view of the origin of icons is generally quite different from that of most secular scholars and from some in contemporary Roman Catholic circles: \"The Orthodox Church maintains and teaches that the sacred image has existed from the beginning of Christianity\", L\u00e9onid Ouspensky has written. Accounts that some non-Orthodox writers consider legendary are accepted as history within Eastern Orthodoxy, because they are a part of church tradition. Thus accounts such as that of the miraculous \"image not made by hands\", and the weeping and moving \"Mother of God of the Sign\" of Novgorod are accepted as fact: \"Church Tradition tells us, for example, of the existence of an Icon of the Savior during His lifetime (the 'Icon-Made-Without-Hands') and of Icons of the Most-Holy Theotokos [Mary] immediately after Him.\"\nEastern Orthodoxy further teaches that \"a clear understanding of the importance of Icons\" was part of the church from its very beginning, and has never changed, although explanations of their importance may have developed over time. This is because icon painting is rooted in the theology of the Incarnation (Christ being the of God) which did not change, though its subsequent clarification within the Church occurred over the period of the first seven Ecumenical Councils. Icons also served as tools of edification for the illiterate faithful during most of the history of Christendom. Thus, icons are words in painting; they refer to the history of salvation and to its manifestation in concrete persons. In the Orthodox Church, \"icons have always been understood as a visible gospel, as a testimony to the great things given man by God the incarnate Logos\". In the Council of 860 it was stated that \"all that is uttered in words written in syllables is also proclaimed in the language of colors\".\nEastern Orthodoxy identifies the first instance of an image or icon in the Bible as the creation of man in God's own image (Septuagint Greek ), in Genesis 1:26\u201327. In Exodus, God initially commanded the Israelites not to make any graven images. However, shortly thereafter, God instructed them to create images of cherubim and other similar beings, both in the form of statues and woven into tapestries. Later, when Solomon built the First Temple, he incorporated even more such imagery. Eastern Orthodoxy believe these qualify as icons, in that they were visible images depicting heavenly beings and, in the case of the cherubim, used to indirectly indicate God's presence above the Ark.\nIn the Book of Numbers it is written that God told Moses to make a bronze serpent, \"Nehushtan\", and hold it up, so that anyone looking at the snake would be healed of their snake bites. In John 3, Jesus refers to the same serpent, saying that he must be lifted up in the same way that the serpent was. John of Damascus also regarded the brazen serpent as an icon. Further, Jesus Christ himself is called the \"image of the invisible God\" in Colossians 1:15, and is therefore in one sense an icon. As people are also made in God's images, people are also considered to be living icons, and are therefore \"censed\" along with painted icons during Orthodox prayer services.\nAccording to John of Damascus, anyone who tries to destroy icons \"is the enemy of Christ, the Holy Mother of God and the saints, and is the defender of the Devil and his demons\". This is because the theology behind icons is closely tied to the Incarnational theology of the humanity and divinity of Jesus, so that attacks on icons typically have the effect of undermining or attacking the Incarnation of Jesus himself as elucidated in the Ecumenical Councils.\nBasil of Caesarea, in his writing \"On the Holy Spirit\", says: \"The honor paid to the image passes to the prototype\". He also illustrates the concept by saying, \"If I point to a statue of Caesar and ask you 'Who is that?', your answer would properly be, 'It is Caesar.' When you say such you do not mean that the stone itself is Caesar, but rather, the name and honor you ascribe to the statue passes over to the original, the archetype, Caesar himself.\" This is thus the approach to icons; to kiss an icon of Jesus, in the Eastern Orthodox view, is to show love towards Jesus himself, not mere wood and paint making up the physical substance of the icon. Worship of the icon as somehow entirely separate from its prototype is expressly forbidden by the Seventh Ecumenical Council.\nIcons are often illuminated with a candle or jar of oil with a wick. (Beeswax for candles and olive oil for oil lamps are preferred because they burn very cleanly, although other materials are sometimes used.) The illumination of religious images with lamps or candles is an ancient practice pre-dating Christianity.\nAccording to Fr. Les Bundy, \"The Ecumenical Counciliar dogmatic decrees on icons refer, in fact, to all religious images including three-dimensional statues. Professor Sergios Verkhovskoi, the conservative professor of dogmatics at St. Vladimir\u2019s Seminary forthrightly condemns as heretical anyone who declares statues as unorthodox or in any way canonically inferior to paintings.\" Historically, the Orthodox Church has always approved of veneration of statues, for example, the statue of the Mother of God at Sokolica Monastery in Serbia, the devotional statues of St. Nil Stolbensky, and those of St. Paraskeva.\nIcon painting tradition by region.\nByzantine Empire.\nOf the icon painting tradition that developed in Byzantium, with Constantinople as the chief city, we have only a few icons from the 11th century and none preceding them, in part because of the Iconoclastic reforms during which many were destroyed or lost, and also because of plundering by the Republic of Venice in 1204 during the Fourth Crusade, and finally the Fall of Constantinople in 1453.\nIt was only in the Komnenian period (1081\u20131185) that the cult of the icon became widespread in the Byzantine world, partly on account of the dearth of richer materials (such as mosaics, ivory, and vitreous enamels), but also because an \"iconostasis\" a special screen for icons was introduced then in ecclesiastical practice. The style of the time was severe, hieratic and distant.\nIn the late Comnenian period this severity softened, and emotion, formerly avoided, entered icon painting. Major monuments for this change include the murals at Daphni Monastery (c.\u20091100) and the Church of St. Panteleimon near Skopje (1164). The Theotokos of Vladimir (c.\u20091115) is probably the most representative example of the new trend towards spirituality and emotion.\nThe tendency toward emotionalism in icons continued in the Paleologan period, which began in 1261. Palaiologan art reached its pinnacle in mosaics such as those of Chora Church. In the last half of the 14th century, Palaiologan saints were painted in an exaggerated manner, very slim and in contorted positions \u2013 a style known as the Palaiologan Mannerism, of which is a superb example.\nAfter 1453, the Byzantine tradition was carried on in regions previously influenced by its religion and culture\u2014in the Balkans, Russia, and other Slavic countries, Georgia and Armenia in the Caucasus, and among Eastern Orthodox minorities in the Islamic world. In the Greek-speaking world Crete, ruled by Venice until the mid-17th century, was an important centre of painted icons, as home of the Cretan School, exporting many to Europe.\nCrete.\nCrete was under Venetian control from 1204 and became a thriving center of art with eventually a , or organized painter's guild, the Guild of Saint Luke, on Western lines. Cretan painting was heavily patronized both by Catholics of Venetian territories and by Eastern Orthodox. For ease of transport, Cretan painters specialized in panel paintings, and developed the ability to work in many styles to fit the taste of various patrons. El Greco, who moved to Venice after establishing his reputation in Crete, is the most famous artist of the school, who continued to use many Byzantine conventions in his works. In 1669 the city of Heraklion, on Crete, which at one time boasted at least 120 painters, fell to the Turks. From that time Greek icon painting went into a decline, with a revival attempted in the 20th century by art reformers such as Photis Kontoglou, who emphasized a return to earlier styles.\nRussia.\nRussian icons are typically paintings on wood, often small, though some in churches and monasteries may be as large as a table top. Many religious homes in Russia have icons hanging on the wall in the \u2014the \"red\" corner (see Icon corner). There is a rich history and elaborate religious symbolism associated with icons. In Russian churches, the nave is typically separated from the sanctuary by an \"iconostasis\", a wall of icons.\nThe use and making of icons entered Kievan Rus' following its conversion to Orthodox Christianity from the Eastern Roman (Byzantine) Empire in 988 AD. As a general rule, these icons strictly followed models and formulas hallowed by usage, some of which had originated in Constantinople. As time passed, the Russians\u2014notably Andrei Rublev and Dionisius\u2014widened the vocabulary of iconic types and styles far beyond anything found elsewhere. The personal, improvisatory and creative traditions of Western European religious art are largely lacking in Russia before the 17th century, when Simon Ushakov's painting became strongly influenced by religious paintings and engravings from Protestant as well as Catholic Europe.\nIn the mid-17th century, changes in liturgy and practice instituted by Patriarch Nikon of Moscow resulted in a split in the Russian Orthodox Church. The traditionalists, the persecuted \"Old Ritualists\" or \"Old Believers\", continued the traditional stylization of icons, while the State Church modified its practice. From that time icons began to be painted not only in the traditional stylized and nonrealistic mode, but also in a mixture of Russian stylization and Western European realism, and in a Western European manner very much like that of Catholic religious art of the time. The Stroganov school and the icons from Nevyansk rank among the last important schools of Russian icon-painting.\nRomania.\nIn Romania, icons painted as reversed images behind glass and set in frames were common in the 19th century and are still made. The process is known as reverse glass painting. \"In the Transylvanian countryside, the expensive icons on panels imported from Moldavia, Wallachia, and Mt. Athos were gradually replaced by small, locally produced icons on glass, which were much less expensive and thus accessible to the Transylvanian peasants\".\nSerbia.\nThe earliest historical records about icons in Serbia dates back to the period of Nemanji\u0107 dynasty. One of the notable schools of Serb icons was active in the Bay of Kotor from the 17th century to the 19th century.\nTrojeru\u010dica meaning \"Three-handed Theotokos\" is the most important icon of the Serbian Orthodox Church and main icon of Mount Athos.\nUkraine.\nDuring the period of Kievan Rus, an indigenous school of icon painting developed in the lands of Ukraine, inspired by Byzantine examples. With the rise of Galicia-Volhynia, a local school also developed in the area, influenced in its turn by Kyivan icons. Influence of Galician icon painting spread across the Carpathians, reaching as far as Presov in modern Slovakia. Some icons were painted by monks, but most were created by professional artists. In the 16th century Lviv became the main centre of painting in Ukrainian lands, and by the middle of the next century Orthodox artists achieved prominent positions in the city's painters' guild. Among notable icon painters of the area during that time was Ivan Rutkovych, whose art demonstrated a strong tendency to realism. \nStarting from the early 17th century, icon painting saw a revival in Central and Eastern Ukraine, supported both by the church and by the rising Cossack elite. The strict Byzantine style prevalent in icons of the previous era gave way to the more expressive style of Ukrainian Baroque. Some icons created in the Cossack Hetmanate depict not only religious figures, but also civic rulers such as hetmans, as well as members of their families. By the end of the 18th century icon gradually evolved into painting on biblical motives, as demonstrated in the works of Volodymyr Borovykovsky. A new revival of this art form in Ukraine took place in the early 20th century under the influence of the school of Mykhailo Boychuk, whose style influenced other painters, many of whom were active in the Ukrainian diaspora.\nEgypt and Ethiopia.\nThe Coptic Orthodox Church of Alexandria and Oriental Orthodoxy also have distinctive, living icon painting traditions. Coptic icons have their origin in the Hellenistic art of Egyptian Late Antiquity, as exemplified by the Fayum mummy portraits. Beginning in the 4th century, churches painted their walls and made icons to reflect an authentic expression of their faith.\nAleppo.\nThe Aleppo School was a school of icon-painting, founded by the priest Yusuf al-Musawwir (also known as Joseph the Painter) and active in Aleppo, which was then a part of the Ottoman Empire, between at least 1645 and 1777.\nWestern Christianity.\nAlthough the word \"icon\" is not generally used in Western Christianity, there are religious works of art which were largely patterned on Byzantine works, and equally conventional in composition and depiction. Until the 13th century, icon-like depictions of sacred figures followed Eastern patterns\u2014although very few survive from this early period. Italian examples are in a style known as Italo-Byzantine.\nFrom the 13th century, the Western tradition came slowly to allow the artist far more flexibility, and a more realist approach to the figures. If only because there was a much smaller number of skilled artists, the quantity of works of art, in the sense of panel paintings, was much smaller in the West, and in most Western settings a single diptych as an altarpiece, or in a domestic room, probably stood in place of the larger collections typical of Orthodox \"icon corners\".\nOnly in the 15th century did production of painted works of art begin to approach Eastern levels, supplemented by mass-produced imports from the Cretan School. In this century, the use of icon-like portraits in the West was enormously increased by the introduction of old master prints on paper, mostly woodcuts which were produced in vast numbers (although hardly any survive). They were mostly sold, hand-coloured, by churches, and the smallest sizes (often only an inch high) were affordable even by peasants, who glued or pinned them straight onto a wall.\nDuring the time of the Reformation, the emergence of the Lutheran and the Reformed traditions occurred. Lutherans favored sacred art, including the use of icons (cf. Lutheran art). On the other hand, the Reformed (Calvinists) were generally iconoclastic. At present, icons \"play a role in Lutheran liturgical practice.\" The Lutheran breviary \"\" is illustrated with several icons.\nCatholic view.\nThe Catholic Church accepted the decrees of the iconodule Seventh Ecumenical Council regarding images. There is some minor difference, however, in the Catholic attitude to images from that of the Orthodox. Following Gregory the Great, Catholics emphasize the role of images as the , the \"Bible of the Poor\", from which those who could not read could nonetheless learn.\nCatholics also, however, share the same viewpoint with the Orthodox when it comes to image veneration, believing that whenever approached, sacred images are to be shown reverence. Though using both flat wooden panel and stretched canvas paintings, Catholics traditionally have also favored images in the form of three-dimensional statuary, whereas in the East, statuary is much less widely employed.\nLutheran view.\nIn the Lutheran tradition, \"icons\u2019 functions are meant to express the theological teaching of the church and to be used as a reminder of such teachings.\" Icons are often placed on the home altars of Lutheran households to turn the mind toward God.\nA joint Lutheran\u2013Orthodox statement made in the 7th Plenary of the Lutheran\u2013Orthodox Joint Commission, in July 1993 in Helsinki, reaffirmed the ecumenical council decisions on the nature of Christ and the veneration of images:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;7. As Lutherans and Orthodox we affirm that the teachings of the ecumenical councils are authoritative for our churches. The ecumenical councils maintain the integrity of the teaching of the undivided Church concerning the saving, illuminating/justifying and glorifying acts of God and reject heresies which subvert the saving work of God in Christ. Orthodox and Lutherans, however, have different histories. Lutherans have received the Nicaeno-Constantinopolitan Creed with the addition of the filioque. The Seventh Ecumenical Council, the Second Council of Nicaea in 787, which rejected iconoclasm and restored the veneration of icons in the churches, was not part of the tradition received by the Reformation. Lutherans, however, rejected the iconoclasm of the 16th century, and affirmed the distinction between adoration due to the Triune God alone and all other forms of veneration (CA 21). Through historical research this council has become better known. Nevertheless it does not have the same significance for Lutherans as it does for the Orthodox. Yet, Lutherans and Orthodox are in agreement that the Second Council of Nicaea confirms the christological teaching of the earlier councils and in setting forth the role of images (icons) in the lives of the faithful reaffirms the reality of the incarnation of the eternal Word of God, when it states: \"The more frequently, Christ, Mary, the mother of God, and the saints are seen, the more are those who see them drawn to remember and long for those who serve as models, and to pay these icons the tribute of salutation and respectful veneration. Certainly this is not the full adoration in accordance with our faith, which is properly paid only to the divine nature, but it resembles that given to the figure of the honored and life-giving cross, and also to the holy books of the gospels and to other sacred objects\" (Definition of the Second Council of Nicaea).\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "14801", "revid": "48046997", "url": "https://en.wikipedia.org/wiki?curid=14801", "title": "Icon (programming language)", "text": "Very high-level programming language\nIcon is a very high-level programming language based on the concept of \"goal-directed execution\" in which an expression in code returns \"success\" along with a result, or a \"failure\", indicating that there is no valid result. The success and failure of a given expression is used to direct further processing, whereas conventional languages would typically use Boolean logic written by the programmer to achieve the same ends. Because the logic for basic control structures is often implicit in Icon, common tasks can be completed with less explicit code.\nIcon was designed by Ralph Griswold after leaving Bell Labs where he was a major contributor to the SNOBOL language. SNOBOL was a string-processing language with what would be considered dated syntax by the standards of the early 1970s. After moving to the University of Arizona, he further developed the underlying SNOBOL concepts in SL5, but considered the result to be a failure. This led to the significantly updated Icon, which blends the short but conceptually dense code of SNOBOL-like languages with the more familiar syntax of ALGOL-inspired languages like C or Pascal.\nLike the languages that inspired it, the primary area of use of Icon is managing strings and textual patterns. String operations often fail, for instance, finding \"the\" in \"world\". In most languages, this requires testing and branching to avoid using a non-valid result. In Icon most of these sorts of tests are simply unneeded, reducing the amount of code that must be written. Complex pattern handling can be done in a few lines of terse code, similar to more dedicated languages like Perl but retaining a more function-oriented syntax familiar to users of other ALGOL-like languages.\nIcon is not object-oriented, but an object-oriented extension named Idol was developed in 1996 which eventually became Unicon. It also inspired other languages, with its simple generators being especially influential; Icon's generators were a major inspiration for the Python language.\nHistory.\nSNOBOL.\nThe original SNOBOL effort, retroactively known as SNOBOL1, launched in the fall of 1962 at the Bell Labs Programming Research Studies Department. The effort was a reaction to the frustrations of attempting to use the SCL language for polynomial formula manipulation, symbolic integration and studying Markov chains. SCL, written by the department head Chester Lee, was both slow and had a low-level syntax that resulting in volumes of code for even simple projects. After briefly considering the COMIT language, Ivan Polonsky, Ralph Griswold and David Farber, all members of the six-person department, decided to write their own language to solve these problems.\nThe first versions were running on the IBM 7090 in early 1963, and by the summer had been built out and was being used across Bell. This led almost immediately to SNOBOL2, which added a number of built-in functions, and the ability to link to external assembly language code. It was released in April 1964 and mostly used within Bell, but also saw some use at Project MAC. The introduction of system functions served mostly to indicate the need for user-defined functions, which was the major feature of SNOBOL3, released in July 1964.\nSNOBOL3's introduction corresponded with major changes within the Bell Labs computing department, including the addition of the new GE 645 mainframe which would require a rewrite of SNOBOL. Instead, the team suggested writing a new version that would run on a virtual machine, named SIL for SNOBOL Intermediate Language, allowing it to be easily ported to any sufficiently powerful platform. This proposal was accepted as SNOBOL4 in September 1965. By this time, plans for a significantly improved version of the language emerged in August 1966. Further work on the language continued throughout the rest of the 1960s, notably adding the associative array type in later version, which they referred to as a table.\nSL5 leads to Icon.\nGriswold left Bell Labs to become a professor at the University of Arizona in August 1971. He introduced SNOBOL4 as a research tool at that time. He received grants from the National Science Foundation to continue supporting and evolving SNOBOL.\nAs a language originally developed in the early 1960s, SNOBOL's syntax bears the marks of other early programming languages like FORTRAN and COBOL. In particular, the language is column-dependant, as many of these languages were entered on punch cards where column layout is natural. Additionally, control structures were almost entirely based on branching around code rather than the use of blocks, which were becoming a must-have feature after the introduction of ALGOL 60. By the time he moved to Arizona, the syntax of SNOBOL4 was hopelessly outdated.\nGriswold began the effort of implementing SNOBOL's underlying success/failure concept with traditional flow control structures like if/then. This became SL5, short for \"SNOBOL Language 5\", but the result was unsatisfying. In 1977, he returned to the language to consider a new version. He abandoned the very powerful function system introduced in SL5 with a simpler concept of suspend/resume and developed a new concept for the natural successor to SNOBOL4 with the following principles;\nThe new language was initially known as SNOBOL5, but as it was significantly different from SNOBOL in all but the underlying concept, a new name was ultimately desired. After considering \"s\" as a sort of homage to \"C\", but this was ultimately abandoned due to the problems with typesetting documents using that name. A series of new names were proposed and abandoned; Irving, bard, and \"TL\" for \"The Language\". It was at this time that Xerox PARC began publishing about their work on graphical user interfaces and the term \"icon\" began to enter the computer lexicon. The decision was made to change the name initially to \"icon\" before finally choosing \"Icon\".\nLanguage.\nBasic syntax.\nThe Icon language is derived from the ALGOL-class of structured programming languages, and thus has syntax similar to C or Pascal. Icon is most similar to Pascal, using syntax for assignments, the keyword and similar syntax. On the other hand, Icon uses C-style braces for structuring execution groups, and programs start by running a procedure called .\nIn many ways Icon also shares features with most scripting languages (as well as SNOBOL and SL5, from which they were taken): variables do not have to be declared, types are cast automatically, and numbers can be converted to strings and back automatically. Another feature common to many scripting languages, but not all, is the lack of a line-ending character; in Icon, lines that do not end with a semicolon get ended by an implied semicolon if it makes sense.\nProcedures are the basic building blocks of Icon programs. Although they use Pascal naming, they work more like C functions and can return values; there is no keyword in Icon.\nprocedure doSomething(aString)\n write(aString)\nend\nGoal-directed execution.\nOne of the key concepts in SNOBOL was that its functions returned the \"success\" or \"failure\" as primitives of the language rather than using magic numbers or other techniques.\nFor example, a function that returns the position of a substring within another string is a common routine found in most language runtime systems. In JavaScript to find the position of the word \"World\" within a \"Hello, World!\" program would be accomplished with , which would return 7 in the variable . If one instead asks for the the code will \"fail\", as the search term does not appear in the string. In JavaScript, as in most languages, this will be indicated by returning a magic number, in this case -1.\nIn SNOBOL a failure of this sort returns a special value, . SNOBOL's syntax operates directly on the success or failure of the operation, jumping to labelled sections of the code without having to write a separate test. For instance, the following code prints \"Hello, world!\" five times:\n I = 1\nLOOP OUTPUT = \"Hello, world!\"\n I = I + 1\n LE(I, 5) : S(LOOP)\nEND\nTo perform the loop, the less-than-or-equal operator, , is called on the index variable I, and if it ucceeds, meaning I is less than 5, it branches to the named label and continues.\nIcon retained the concept of flow control based on success or failure but developed the language further. One change was the replacement of the labelled -like branching with block-oriented structures in keeping with the structured programming style that was sweeping the computer industry in the late 1960s. The second was to allow \"failure\" to be passed along the call chain so that entire blocks will succeed or fail as a whole. This is a key concept of the Icon language. Whereas in traditional languages one would have to include code to test the success or failure based on Boolean logic and then branch based on the outcome, such tests and branches are inherent to Icon code and do not have to be explicitly written.\nFor instance, consider this bit of code written in the Java programming language. It calls the function to read a character from a (previously opened) file, assigns the result to the variable , and then s the value of to another file. The result is to copy one file to another. will eventually run out of characters to read from the file, potentially on its very first call, which would leave in an undetermined state and potentially cause to cause a null pointer exception. To avoid this, returns the special value (end-of-file) in this situation, which requires an explicit test to avoid ing it:\nwhile ((a = read()) != EOF) {\n write(a);\nIn contrast, in Icon the function returns a line of text or . is not simply an analog of , as it is explicitly understood by the language to mean \"stop processing\" or \"do the fail case\" depending on the context. The equivalent code in Icon is:\nwhile a := read() do write(a)\nThis means, \"as long as read does not fail, call write, otherwise stop\". There is no need to specify a test against the magic number as in the Java example, this is implicit, and the resulting code is simplified. Because success and failure are passed up through the call chain, one can embed function calls within others and they stop when the nested function call fails. For instance, the code above can be reduced to:\nwhile write(read())\nIn this version, if the call fails, the call fails, and the stops. Icon's branching and looping constructs are all based on the success or failure of the code inside them, not on an arbitrary Boolean test provided by the programmer. performs the block if its \"test\" returns a value, and performs the block or moves to the next line if it returns . Likewise, continues calling its block until it receives a fail. Icon refers to this concept as goal-directed execution.\nIt is important to contrast the concept of success and failure with the concept of an exception; exceptions are unusual situations, not expected outcomes. Fails in Icon are expected outcomes; reaching the end of a file is an expected situation and not an exception. Icon does not have exception handling in the traditional sense, although fail is often used in exception-like situations. For instance, if the file being read does not exist, fails without a special situation being indicated. In traditional language, these \"other conditions\" have no natural way of being indicated; additional magic numbers may be used, but more typically exception handling is used to \"throw\" a value. For instance, to handle a missing file in the Java code, one might see:\ntry {\n while ((a = read()) != EOF) {\n write(a);\n} catch (Exception e) {\n // something else went wrong, use this catch to exit the loop\nThis case needs two comparisons: one for EOF and another for all other errors. Since Java does not allow exceptions to be compared as logic elements, as under Icon, the lengthy syntax must be used instead. Try blocks also impose a performance penalty even if no exception is thrown, a distributed cost that Icon normally avoids.\nIcon uses this same goal-directed mechanism to perform traditional Boolean tests, although with subtle differences. A simple comparison like does not mean, \"if the conditional expression evaluation results in or returns a true value\" as they would under most languages; instead, it means something more like, \"if the conditional expression succeeds and does not fail\". In this case, the operator succeeds if the comparison is true. The calls its clause if the expression succeeds, and either the (if present) or the next line if it fails. The result is similar to the traditional if/then seen in other languages, the performs if is less than . The subtlety is that the same comparison expression can be placed anywhere, for instance:\nwrite(a &lt; b)\nAnother difference is that the operator returns its second argument if it succeeds, which in this example will result in the value of being written if it is larger than , otherwise nothing is written. As this is not a test \"per se\", but an operator that returns a value, they can be strung together allowing things like , a common type of comparison that in most languages must be written as a conjunction of two inequalities like .\nA key aspect of goal-directed execution is that the program may have to rewind to an earlier state if a procedure fails, a task known as \"backtracking\". For instance, consider code that sets a variable to a starting location and then performs operations that may change the value - this is common in string scanning operations for instance, which will advance a cursor through the string as it scans. If the procedure fails, it is important that any subsequent reads of that variable return the original state, not the state as it was being internally manipulated. For this task, Icon has the \"reversible assignment\" operator, , and the \"reversible exchange\", . For instance, consider some code that is attempting to find a pattern string within a larger string:\n (i := 10) &amp;\n (j := (i &lt; find(pattern, inString)))\nThis code begins by moving to 10, the starting location for the search. However, if the fails, the block will fail as a whole, which results in the value of being left at 10 as an undesirable side effect. Replacing with indicates that should be reset to its previous value if the block fails. This provides an analog of atomicity in the execution.\nGenerators.\nExpressions in Icon may return a single value, for instance, will evaluate and return x if the value of x is less than 5, otherwise it will fail and return no value. Icon also includes the concept of procedures that do not \"immediately\" return success or failure, and instead return new values every time they are called. These are known as \"generators\", and are a key part of the Icon language. Within the parlance of Icon, the evaluation of an expression or function produces a \"result sequence\". A result sequence contains all the possible values that can be generated by the expression or function. When the result sequence is exhausted, the expression or function fails.\nIcon allows any procedure to return a single value or multiple values, controlled using the , and keywords. A procedure that lacks any of these keywords returns , which occurs whenever execution runs to the of a procedure. For instance:\nprocedure f(x)\n if x &gt; 0 then {\n return 1\nend\nCalling will return 1, but calling will return . This can lead to non-obvious behavior, for instance, will output nothing because fails and suspends operation of .\nConverting a procedure to be a generator uses the keyword, which means \"return this value, and when called again, start execution at this point\". In this respect it is something like a combination of the concept in C and . For instance:\nprocedure ItoJ(i, j)\n while i &lt;= j do {\n suspend i\n i +:= 1\n fail\nend\ncreates a generator that returns a series of numbers starting at and ending a , and then returns after that. The stops execution and returns the value of without reseting any of the state. When another call is made to the same function, execution picks up at that point with the previous values. In this case, that causes it to perform , loop back to the start of the while block, and then return the next value and suspend again. This continues until fails, at which point it exits the block and calls . This allows iterators to be constructed with ease.\nAnother type of generator-builder is the \"alternator\", which looks and operates like the Boolean operator. For instance:\nif y &lt; (x | 5) then write(\"y=\", y)\nThis appears to say \"if y is smaller than x or 5 then...\", but is actually a short-form for a generator that returns values until it falls off the end of the list. The values of the list are \"injected\" into the operations, in this case, . So in this example, the system first tests y &lt; x, if x is indeed larger than y it returns the value of x, the test passes, and the value of y is written out in the clause. However, if x is not larger than y it fails, and the alternator continues, performing y &lt; 5. If that test passes, y is written. If y is smaller than neither x or 5, the alternator runs out of tests and fails, the fails, and the is not performed. Thus, the value of y will appear on the console if it is smaller than x or 5, thereby fulfilling the purpose of a Boolean . Functions will not be called unless evaluating their parameters succeeds, so this example can be shortened to:\nwrite(\"y=\", (x | 5) &gt; y)\nInternally, the alternator is not simply an and one can also use it to construct arbitrary lists of values. This can be used to iterate over arbitrary values, like:\nevery i := (1|3|4|5|10|11|23) do write(i)\nAs lists of integers are commonly found in many programming contexts, Icon also includes the keyword to construct \"ad hoc\" integer generators:\n every k := i to j do write(k)\nwhich can be shortened:\nevery write(1 to 10)\nIcon is not strongly typed, so the alternator lists can contain different types of items:\nevery i := (1 | \"hello\" | x &lt; 5) do write(i)\nThis writes 1, \"hello\" and maybe 5 depending on the value of x.\nLikewise the \"conjunction operator\", , is used in a fashion similar to a Boolean operator:\nevery x := ItoJ(0,10) &amp; x % 2 == 0 do write(x)\nThis code calls and returns an initial value of 0 which is assigned to x. It then performs the right-hand side of the conjunction, and since does equal 0, it writes out the value. It then calls the generator again which assigns 1 to x, which fails the right-hand-side and prints nothing. The result is a list of every even integer from 0 to 10.\nThe concept of generators is particularly useful and powerful when used with string operations, and is a major underlying basis for Icon's overall design. Consider the operation found in many languages; this function looks for one string within another and returns an index of its location, or a magic number if it is not found. For instance:\ns = \"All the world's a stage. And all the men and women merely players\";\ni = indexOf(\"the\", s);\nwrite(i);\nThis will scan the string , find the first occurrence of \"the\", and return that index, in this case 4. The string, however, contains two instances of the string \"the\", so to return the second example an alternate syntax is used:\nj = indexOf(\"the\", s, i + 1);\nwrite(j);\nThis tells it to scan starting at location 5, so it will not match the first instance we found previously. However, there may not be a second instance of \"the\" -there may not be a first one either- so the return value from has to be checked against the magic number -1 which is used to indicate no matches. A complete routine that prints out the location of every instance is:\ns = \"All the world's a stage. And all the men and women merely players\";\ni = indexOf(\"the\", s);\nwhile i != -1 {\n write(i);\n i = indexOf(\"the\", s, i + 1);\nIn Icon, the equivalent is a generator, so the same results can be created with a single line:\ns := \"All the world's a stage. And all the men and women merely players\"\nevery write(find(\"the\", s))\nOf course there are times where one does want to find a string after some point in input, for instance, if scanning a text file that contains a line number in the first four columns, a space, and then a line of text. Goal-directed execution can be used to skip over the line numbers:\nevery write(5 &lt; find(\"the\", s))\nThe position will only be returned if \"the\" appears after position 5; the comparison will fail otherwise, pass the fail to write, and the write will not occur.\nThe operator is similar to , looping through every item returned by a generator and exiting on failure:\nevery k := i to j do\n write(someFunction(k))\nThere is a key difference between and ; re-evaluates the first result until it fails, whereas fetches the next value from a generator. actually injects values into the function in a fashion similar to blocks under Smalltalk. For instance, the above loop can be re-written this way:\nevery write(someFunction(i to j))\nIn this case, the values from i to j will be injected into and (potentially) write multiple lines of output.\nCollections.\nIcon includes several collection types including lists that can also be used as stacks and queues, tables (also known as maps or dictionaries in other languages), sets and others. Icon refers to these as \"structures\". Collections are inherent generators and can be easily called using the bang syntax. For instance:\nlines := [] # create an empty list\nwhile line := read() do { # loop reading lines from standard input\n push(lines, line) # use stack-like syntax to push the line on the list\nwhile line := pop(lines) do { # loop while lines can be popped off the list\n write(line) # write the line out\nUsing the fail propagation as seen in earlier examples, we can combine the tests and the loops:\nlines := [] # create an empty list\nwhile push(lines, read()) # push until empty\nwhile write(pop(lines)) # write until empty\nBecause the list collection is a generator, this can be further simplified with the bang syntax:\nlines := []\nevery push(lines, !&amp;input)\nevery write(!lines)\nIn this case, the bang in causes Icon to return a line of text one by one from the array and finally fail at the end. is a generator-based analog of that reads a line from standard input, so continues reading lines until the file ends.\nAs Icon is typeless, lists can contain any different types of values:\naCat := [\"muffins\", \"tabby\", 2002, 8]\nThe items can included other structures. To build larger lists, Icon includes the generator; generates a list containing 10 copies of \"word\". Like arrays in other languages, Icon allows items to be looked up by position, e.g., . Array slicing is included, allowing new lists to be created out of the elements of other lists, for instance, produces a new list called aCat that contains \"tabby\" and 2002.\nTables are essentially lists with arbitrary index keys rather than integers:\nsymbols := table(0)\nsymbols[\"there\"] := 1\nsymbols[\"here\"] := 2\nThis code creates a table that will use zero as the default value of any unknown key. It then adds two items into the table, with the keys \"there\" and \"here\", and values 1 and 2.\nSets are also similar to lists but contain only a single member of any given value. Icon includes the to produce the union of two sets, the intersection, and the difference. Icon includes a number of pre-defined \"Cset\"s, a set containing various characters. There are four standard Csets in Icon, , , , and . New Csets can be made by enclosing a string in single quotes, for instance, .\nStrings.\nIn Icon, strings are lists of characters. As a list, they are generators and can thus be iterated over using the bang syntax:\nevery write(!\"Hello, world!\")\nWill print out each character of the string on a separate line.\nSubstrings can be extracted from a string by using a range specification within brackets. A range specification can return a point to a single character, or a slice of the string. Strings can be indexed from either the right or the left. Positions within a string are defined to be between the characters 1A2B3C4 and can be specified from the right \u22123A\u22122B\u22121C0\nFor example,\n\"Wikipedia\"[1] ==&gt; \"W\"\n\"Wikipedia\"[3] ==&gt; \"k\"\n\"Wikipedia\"[0] ==&gt; \"a\"\n\"Wikipedia\"[1:3] ==&gt; \"Wi\"\n\"Wikipedia\"[-2:0] ==&gt; \"ia\"\n\"Wikipedia\"[2+:3] ==&gt; \"iki\"\nWhere the last example shows using a length instead of an ending position\nThe subscripting specification can be used as a lvalue within an expression. This can be used to insert strings into another string or delete parts of a string. For example:\ns := \"abc\"\ns[2] := \"123\"\ns := \"abcdefg\"\ns[3:5] := \"ABCD\"\ns := \"abcdefg\"\ns[3:5] := \"\"\nString scanning.\nA further simplification for handling strings is the \"scanning\" system, invoked with , which calls functions on a string:\ns ? write(find(\"the\"))\nIcon refers to the left-hand-side of the as the \"subject\", and passes it into string functions. Recall the takes two parameters, the search text as parameter one and the string to search in parameter two. Using the second parameter is implicit and does not have to be specified by the programmer. In the common cases when multiple functions are being called on a single string in sequence, this style can significantly reduce the length of the resulting code and improve clarity. Icon function signatures identify the subject parameter in their definitions so the parameter can be hoisted in this fashion.\nThe is not simply a form of syntactic sugar, it also sets up a \"string scanning environment\" for any following string operations. This is based on two internal variables, and ; is simply a pointer to the original string, while is the current position within it, or cursor. Icon's various string manipulation procedures use these two variables so they do not have to be explicitly supplied by the programmer. For example:\ns := \"this is a string\"\ns ? write(\"subject=[\",&amp;subject,\"], pos=[\",&amp;pos,\"]\")\nwould produce:\nsubject=[this is a string], pos=[1]\nBuilt-in and user-defined functions can be used to move around within the string being scanned. All of the built-in functions will default to and to allow the scanning syntax to be used. The following code will write all blank-delimited \"words\" in a string:\ns := \"this is a string\"\ns ? { # Establish string scanning environment\n while not pos(0) do { # Test for end of string\n tab(many(' ')) # Skip past any blanks\n word := tab(upto(' ') | 0) # the next word is up to the next blank -or- the end of the line\n write(word) # write the word\nThere are a number of new functions introduced in this example. returns the current value of . It may not be immediately obvious why one would need this function and not simply use the value of directly; the reason is that is a variable and thus cannot take on the value , which the procedure can. Thus provides a lightweight wrapper on that allows Icon's goal-directed flow control to be easily used without having to provide hand-written Boolean tests against . In this case, the test is \"is &amp;pos zero\", which, in the odd numbering of Icon's string locations, is the end of the line. If it is \"not\" zero, returns , which is inverted with the and the loop continues.\n finds one or more examples of the provided Cset parameter starting at the current . In this case, it is looking for space characters, so the result of this function is the location of the first non-space character after . moves to that location, again with a potential in case, for instance, falls off the end of the string. is essentially the reverse of ; it returns the location immediately prior to its provided Cset, which the example then sets the to with another . Alternation is used to also stop at the end of a line.\nThis example can be made more robust through the use of a more appropriate \"word breaking\" Cset which might include periods, commas and other punctuation, as well as other whitespace characters like tab and non-breaking spaces. That Cset can then be used in and .\nA more complex example demonstrates the integration of generators and string scanning within the language.\nprocedure main()\n s := \"Mon Dec 8\"\n s ? write(Mdate() | \"not a valid date\")\nend\nprocedure Mdate()\n # Define some initial values\n static dates\n static days\n initial {\n days := [\"Mon\",\"Tue\",\"Wed\",\"Thr\",\"Fri\",\"Sat\",\"Sun\"]\n months := [\"Jan\",\"Feb\",\"Mar\",\"Apr\",\"May\",\"Jun\",\n \"Jul\",\"Aug\",\"Sep\",\"Oct\",\"Nov\",\"Dec\"]\n \n every suspend (retval &lt;- tab(match(!days)) || # Match a day\n =\" \" || # Followed by a blank\n tab(match(!months)) || # Followed by the month\n =\" \" || # Followed by a blank\n matchdigits(2) # Followed by at most 2 digits\n (=\" \" | pos(0) ) &amp; # Either a blank or the end of the string\n retval # And finally return the string\n end\nprocedure matchdigits(n)\n suspend (v := tab(many(&amp;digits)) &amp; *v &lt;= n) &amp; v\nend\nCriticisms.\nLaurence Tratt wrote a paper on Icon examining its real-world applications and pointing out a number of areas of concern. Among these were a number of practical decisions that derive from their origins in string processing but do not make as much sense in other areas. Among them:\nThe decision to fail by default at the end of procedures makes sense in the context of generators, but less so in the case of general procedures. Returning to the example noted above, will not output which may be expected. However:\nx := 10\nx := f(-1)\nwrite(x)\nwill result in 10 being printed. This sort of issue is not at all obvious as even in an interactive debugger all the code is invoked yet never picks up the expected value. This could be dismissed as one of those \"gotchas\" that programmers have to be aware of in any language, but Tratt examined a variety of Icon programs and found that the vast majority of procedures are not generators. This means that Icon's default behaviour is only used by a tiny minority of its constructs, yet represents a major source of potential errors in all the others.\nAnother issue is the lack of a Boolean data type and conventional Boolean logic. While the success/fail system works in most cases where the ultimate goal is to check a value, this can still lead to some odd behaviour in seemingly simple code:\nprocedure main()\n if c then {\n write(\"taken\")\nend\nThis program will print \"taken\". The reason is that the test, , does return a value; that value is , the default value for all otherwise uninitiated variables. is a valid value, so succeeds. To test this, one needs to make the test explicit, (or the more idiomatic Icon expression ). Tratt supposed that it detracts from the self-documenting code, having supposed erroneously that it is testing \"is c zero\" or \"does c exist\".\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
