{"id": "19527", "revid": "44434461", "url": "https://en.wikipedia.org/wiki?curid=19527", "title": "Mao Zedong", "text": "Leader of China from 1949 to 1976\nMao Zedong (26December 1893\u00a0\u2013 9September 1976) was a Chinese politician, revolutionary, and political theorist who founded the People's Republic of China (PRC) in 1949 and led the country from its establishment until his death in 1976. Mao served as chairman of the Chinese Communist Party (CCP) from 1943 until his death, and as the party's \"de facto\" leader from 1935. His theories, which he advocated as a Chinese adaptation of Marxism\u2013Leninism, are known as Maoism.\nBorn to a peasant family in Shaoshan, Hunan, Mao studied in Changsha and was influenced by the 1911 Revolution and ideas of Chinese nationalism and anti-imperialism. He was introduced to Marxism while working as a librarian at Peking University, and later participated in the May Fourth Movement of 1919. In 1921, Mao became a founding member of the CCP. After the start of the Chinese Civil War between the Kuomintang (KMT) and CCP, Mao led the failed Autumn Harvest Uprising in Hunan in 1927, and in 1931 founded the Jiangxi Soviet. He helped build the Chinese Red Army, and developed a strategy of guerilla warfare. In 1935, Mao became leader of the CCP during the Long March, a military retreat to the Yan'an Soviet in Shaanxi, where the party began rebuilding its forces. The CCP allied with the KMT in the Second United Front at the start of the Second Sino-Japanese War in 1937, but the civil war resumed after Japan's surrender in 1945. In 1949, Mao's forces defeated the Nationalist government, which withdrew to Taiwan.\nOn 1 October 1949, Mao proclaimed the foundation of the PRC, a one-party state controlled by the CCP. He initiated land redistribution and industrialisation campaigns, suppressed political opponents, intervened in the Korean War, and oversaw the ideological Hundred Flowers and Anti-Rightist Campaigns. From 1958 to 1962, Mao oversaw the Great Leap Forward, a campaign which aimed to rapidly collectivise agriculture and industrialise the country. It failed, and resulted in the Great Chinese Famine. In 1966, Mao launched the Cultural Revolution, which was marked by violent class struggle, destruction of historical artifacts, and Mao's cult of personality. From the late 1950s, Mao's foreign policy was dominated by a political split with the Soviet Union, and in the 1970s he began establishing relations with the United States. In 1976, Mao died of a heart attack. He was initially succeeded by Hua Guofeng, then in 1978 by Deng Xiaoping. The CCP's official evaluation of Mao's legacy both praises him and acknowledges mistakes in his later years.\nMao's policies resulted in a vast number of deaths, with tens of millions of victims of famine, political persecution, prison labour and executions, and his regime has been described as totalitarian. Mao has also been credited with transforming China from a semi-colony to a major world power and advancing literacy, women's rights, basic healthcare, education, and life expectancy. In modern China, he is widely regarded as a national hero who liberated the country from imperialism. He became an ideological leader within the international communist movement, inspiring various Maoist organisations.\nEnglish romanisation of name.\nDuring Mao's lifetime, the English-language media universally rendered his name as Mao Tse-tung, using the Wade\u2013Giles system of transliteration though with the circumflex accent in the syllable \"Ts\u00ea\" dropped. Due to its recognizability, the spelling was used widely, even by the PRC's foreign ministry after Hanyu Pinyin became the PRC's official romanisation system for Mandarin Chinese in 1958; the well-known booklet of Mao's political statements was officially entitled \"Quotations from Chairman Mao Tse-tung\" in English translations. While the pinyin-derived spelling \"Mao Zedong\" is increasingly common, the Wade\u2013Giles-derived spelling \"Mao Tse-tung\" continues to be used in modern publications to some extent.\nEarly life.\nYouth and the Xinhai Revolution: 1893\u20131911.\nMao Zedong was born on 26 December 1893, near Shaoshan village in Hunan, during the Qing dynasty. His father, Mao Yichang, was a formerly impoverished peasant who had become one of the wealthiest farmers in Shaoshan. Growing up in rural Hunan, Mao described his father as a stern disciplinarian, who would beat him and his three siblings, the boys Zemin and Zetan, as well as an adopted sister/cousin, Zejian. Mao's mother, Wen Qimei, was a devout Buddhist who tried to temper her husband's strict attitude. Mao too became a Buddhist, but abandoned this faith in his mid-teenage years. At age 8, Mao was sent to Shaoshan Primary School. Learning the value systems of Confucianism, he later admitted that he did not enjoy the classical Chinese texts preaching Confucian morals, instead favouring classic novels like \"Romance of the Three Kingdoms\" and \"Water Margin\". At age 13, Mao finished primary education, and his father united him in an arranged marriage to the 17-year-old Luo Yixiu, thereby uniting their land-owning families. Mao refused to recognise her as his wife, becoming a fierce critic of arranged marriage and temporarily moving away. Luo was locally disgraced and died of dysentery in 1910 at 20 years old.\nWorking on his father's farm, Mao read voraciously and developed a \"political consciousness\" from Zheng Guanying's booklet which lamented the deterioration of Chinese power and argued for the adoption of representative democracy. Mao also read translations of works by Western authors including Adam Smith, Montesquieu, Jean-Jacques Rousseau, Charles Darwin, and Thomas Huxley.34 Interested in history, Mao was inspired by the military prowess and nationalistic fervour of George Washington and Napoleon Bonaparte. His political views were shaped by Gelaohui-led protests which erupted following a famine in Changsha, the capital of Hunan; Mao supported the protesters' demands, but the armed forces suppressed the dissenters and executed their leaders. The famine spread to Shaoshan, where starving peasants seized his father's grain. He disapproved of their actions as morally wrong, but claimed sympathy for their situation. At age 16, Mao moved to a higher primary school in nearby Dongshan, where he was bullied for his peasant background.\nIn 1911, Mao began middle school in Changsha. Revolutionary sentiment was strong in the city, where there was widespread animosity towards Emperor Puyi's absolute monarchy and many were advocating republicanism. The republicans' figurehead was Sun Yat-sen, an American-educated Christian who led the Tongmenghui society. In Changsha, Mao was influenced by Sun's newspaper, \"The People's Independence\" (\"Minli bao\"), and called for Sun to become president in a school essay. As a symbol of rebellion against the Manchu monarch, Mao and a friend cut off their queue pigtails, a sign of subservience to the emperor.\nInspired by Sun's republicanism, the army rose up across southern China, sparking the Xinhai Revolution. Changsha's governor fled, leaving the city in republican control. Supporting the revolution, Mao joined the rebel army as a private soldier, but was not involved in fighting or combat. The northern provinces remained loyal to the emperor, and hoping to avoid a civil war, Sun\u2014proclaimed \"provisional president\" by his supporters\u2014compromised with the monarchist general Yuan Shikai. The monarchy was abolished, creating the Republic of China, but the monarchist Yuan became president. With the revolution over, Mao resigned from the army in 1912, after six months as a soldier. Around this time, Mao discovered socialism from a newspaper article; proceeding to read pamphlets by Jiang Kanghu, the student founder of the Chinese Socialist Party, Mao remained interested yet unconvinced by the idea.\nFourth Normal School of Changsha: 1912\u20131919.\nOver the next few years, Mao Zedong enrolled in and dropped out of a police academy, a soap-production school, a law school, an economics school, and the government-run Changsha Middle School. Studying independently, he spent much time in Changsha's library, reading core works of classical liberalism such as Adam Smith's \"The Wealth of Nations\" and Montesquieu's \"The Spirit of the Laws\", as well as the works of western scientists and philosophers such as Darwin, Mill, Rousseau, and Spencer. Viewing himself as an intellectual, years later he admitted that at this time he thought himself better than working people. He was inspired by Friedrich Paulsen, a neo-Kantian philosopher and educator whose emphasis on the achievement of a carefully defined goal as the highest value led Mao to believe that strong individuals were not bound by moral codes but should strive for a great goal. His father saw no use in his son's intellectual pursuits, cut off his allowance and forced him to move into a hostel for the destitute.\nMao wanted to become a teacher and enrolled at the Fourth Normal School of Changsha, which soon merged with the First Normal School of Hunan, widely seen as the best in Hunan. Befriending Mao, professor Yang Changji urged him to read a radical newspaper, \"New Youth\" (\"Xin qingnian\"), the creation of his friend Chen Duxiu, a dean at Peking University. Although he was a supporter of Chinese nationalism, Chen argued that China must look to the west to cleanse itself of superstition and autocracy. In his first school year, Mao befriended an older student, Xiao Zisheng; together they went on a walking tour of Hunan, begging and writing literary couplets to obtain food.\nA popular student, in 1915 Mao was elected secretary of the Students' Society. He organised the Association for Student Self-Government and led protests against school rules. Mao published his first article in \"New Youth\" in April 1917, instructing readers to increase their physical strength to serve the revolution. He joined the Society for the Study of Wang Fuzhi (\"Chuan-shan Hs\u00fceh-she\"), a revolutionary group founded by Changsha literati who wished to emulate the philosopher Wang Fuzhi. In spring 1917, he was elected to command the students' volunteer army, set up to defend the school from marauding soldiers. Increasingly interested in the techniques of war, he took a keen interest in World War I, and also began to develop a sense of solidarity with workers. Mao undertook feats of physical endurance with Xiao Zisheng and Cai Hesen, and with other young revolutionaries they formed the Renovation of the People Study Society in April 1918 to debate Chen Duxiu's ideas. Desiring personal and societal transformation, the Society gained 70\u201380 members, many of whom would later join the Communist Party. Mao graduated in June 1919, ranked third in the year.\nEarly revolutionary activity.\nBeijing, anarchism, and Marxism: 1917\u20131919.\nMao moved to Beijing, where his mentor Yang Changji had taken a job at Peking University. Yang thought Mao exceptionally \"intelligent and handsome\", securing him a job as assistant to the university librarian Li Dazhao, who would become an early Chinese Communist. Li authored a series of \"New Youth\" articles on the October Revolution in Russia, during which the Communist Bolshevik Party under the leadership of Vladimir Lenin had seized power. Lenin was an advocate of the socio-political theory of Marxism, first developed by the German sociologists Karl Marx and Friedrich Engels, and Li's articles added Marxism to the doctrines in the Chinese revolutionary movement.\nBecoming \"more and more radical\", Mao was initially influenced by Peter Kropotkin's anarchism, which was the most prominent radical doctrine of the day. Chinese anarchists, such as Cai Yuanpei, Chancellor of Peking University, called for complete social revolution in social relations, family structure, and women's equality, rather than the simple change in the form of government called for by earlier revolutionaries. He joined Li's Study Group and \"developed rapidly toward Marxism\" during the winter of 1919. Paid a low wage, Mao lived in a cramped room with seven other Hunanese students, but believed that Beijing's beauty offered \"vivid and living compensation\". A number of his friends took advantage of the anarchist-organised \"Mouvement Travail-\u00c9tudes\" to study in France, but Mao declined, perhaps because of an inability to learn languages. Mao raised funds for the movement, however.35\nAt the university, Mao was snubbed by other students due to his rural Hunanese accent and lowly position. He joined the university's Philosophy and Journalism Societies and attended lectures and seminars by the likes of Chen Duxiu, Hu Shih, and Qian Xuantong. Mao's time in Beijing ended in the spring of 1919, when he travelled to Shanghai with friends who were preparing to leave for France. He did not return to Shaoshan, where his mother was terminally ill. She died in October 1919 and her husband died in January 1920.\nNew Culture and political protests: 1919\u20131920.\nOn 4 May 1919, students in Beijing gathered at Tiananmen to protest the Chinese government's weak resistance to Japanese expansion in China. Patriots were outraged at the influence given to Japan in the Twenty-One Demands in 1915, the complicity of Duan Qirui's Beiyang government, and the betrayal of China in the Treaty of Versailles, wherein Japan was allowed to receive territories in Shandong which had been surrendered by Germany. These demonstrations ignited the nationwide May Fourth Movement and fuelled the New Culture Movement which blamed China's diplomatic defeats on social and cultural backwardness.\nIn Changsha, Mao had begun teaching history at the Xiuye Primary School and organising protests against the pro-Duan Governor of Hunan Province, Zhang Jingyao, popularly known as \"Zhang the Venomous\" due to his corrupt and violent rule. In late May, Mao co-founded the Hunanese Student Association with He Shuheng and Deng Zhongxia, organising a student strike for June and in July 1919 began production of a weekly radical magazine, \"Xiang River Review\". Using vernacular language that would be understandable to the majority of China's populace, he advocated the need for a \"Great Union of the Popular Masses\", and strengthened trade unions able to wage non-violent revolution. His ideas were not Marxist, but heavily influenced by Kropotkin's concept of .\nZhang banned the Student Association, but Mao continued publishing after assuming editorship of the liberal magazine \"New Hunan\" (\"Xin Hunan\") and authored articles in popular local newspaper \"Ta Kung Pao\". Several of these advocated feminist views, calling for the liberation of women in Chinese society; Mao was influenced by his forced arranged-marriage. In fall 1919, Mao organized a seminar in Changsha studying economic and political issues, as well as ways to unite the people, the feasibility of socialism, and issues regarding Confucianism. During this period, Mao involved himself in political work with manual laborers, setting up night schools and trade unions. In December 1919, Mao helped organise a general strike in Hunan, securing some concessions, but Mao and other student leaders felt threatened by Zhang, and Mao returned to Beijing, visiting the terminally ill Yang Changji. Mao found that his articles had achieved a level of fame among the revolutionary movement, and set about soliciting support in overthrowing Zhang. Coming across newly translated Marxist literature by Thomas Kirkup, Karl Kautsky, and Marx and Engels\u2014notably \"The Communist Manifesto\"\u2014he came under their increasing influence, but was still eclectic in his views.\nMao visited Tianjin, Jinan, and Qufu, before moving to Shanghai, where he worked as a laundryman and met Chen Duxiu, noting that Chen's adoption of Marxism \"deeply impressed me at what was probably a critical period in my life\". In Shanghai, Mao met an old teacher of his, Yi Peiji, a revolutionary and member of the Kuomintang (KMT), or Chinese Nationalist Party, which was gaining increasing support and influence. Yi introduced Mao to General Tan Yankai, a senior KMT member who held the loyalty of troops stationed along the Hunanese border with Guangdong. Tan was plotting to overthrow Zhang, and Mao aided him by organising the Changsha students. In June 1920, Tan led his troops into Changsha, and Zhang fled. In the subsequent reorganisation of the provincial administration, Mao was appointed headmaster of the junior section of the First Normal School. Now receiving a large income, he married Yang Kaihui, daughter of Yang Changji, in the winter of 1920.\nFounding the Chinese Communist Party: 1921\u20131922.\nThe Chinese Communist Party was founded by Chen Duxiu and Li Dazhao in the Shanghai French Concession in 1921 as a study society and informal network. Mao set up a Changsha branch, also establishing a branch of the Socialist Youth Corps and a Cultural Book Society which opened a bookstore to propagate revolutionary literature throughout Hunan. He was involved in the movement for Hunan autonomy, in the hope that a Hunanese constitution would increase civil liberties and make his revolutionary activity easier. When the movement was successful in establishing provincial autonomy under a new warlord, Mao forgot his involvement. By 1921, small Marxist groups existed in Shanghai, Beijing, Changsha, Wuhan, Guangzhou, and Jinan; it was decided to hold a central meeting, which began in Shanghai on 23 July 1921. The first session of the National Congress of the Chinese Communist Party was attended by 13 delegates, Mao included. After the authorities sent a police spy to the congress, the delegates moved to a boat on South Lake near Jiaxing, in Zhejiang, to escape detection. Although Soviet and Comintern delegates attended, the first congress ignored Lenin's advice to accept a temporary alliance between the Communists and the \"bourgeois democrats\" who also advocated national revolution; instead they stuck to the orthodox Marxist belief that only the urban proletariat could lead a socialist revolution.\nMao was party secretary for Hunan stationed in Changsha, and to build the party there he followed a variety of tactics. In August 1921, he founded the Self-Study University, through which readers could gain access to revolutionary literature, housed in the premises of the Society for the Study of Wang Fuzhi, a Qing dynasty Hunanese philosopher who had resisted the Manchus. He joined the YMCA Mass Education Movement to fight illiteracy, though he edited the textbooks to include radical sentiments. He continued organising workers to strike against the administration of Hunan Governor Zhao Hengti. Yet labour issues remained central. The successful and famous Anyuan coal mines strikes (contrary to later Party historians) depended on both \"proletarian\" and \"bourgeois\" strategies. Liu Shaoqi and Li Lisan and Mao not only mobilised the miners, but formed schools and cooperatives and engaged local intellectuals, gentry, military officers, merchants, Red Gang dragon heads and even church clergy. Mao's labour organizing work in the Anyuan mines also involved his wife Yang Kaihui, who worked for women's rights, including literacy and educational issues, in the nearby peasant communities. Although Mao and Yang were not the originators of this political organizing method of combining labor organizing among male workers with a focus on women's rights issues in their communities, they were among the most effective at using this method. Mao's political organizing success in the Anyuan mines resulted in Chen Duxiu inviting him to become a member of the Communist Party's Central Committee.\nMao claimed that he missed the July 1922 Second Congress of the Communist Party in Shanghai because he lost the address. Adopting Lenin's advice, the delegates agreed to an alliance with the \"bourgeois democrats\" of the KMT for the good of the \"national revolution\". Communist Party members joined the KMT, hoping to push its politics leftward.\nMao enthusiastically agreed with this decision, arguing for an alliance across China's socio-economic classes, and eventually rose to become propaganda chief of the KMT. Mao was a vocal anti-imperialist and in his writings he lambasted the governments of Japan, the UK and US, describing the latter as \"the most murderous of hangmen\".\nCollaboration with the Kuomintang: 1922\u20131927.\nAt the 3rd National Congress of the Chinese Communist Party in Shanghai in June 1923, the delegates reaffirmed their commitment to working with the KMT. Supporting this position, Mao was elected to the Party Committee, taking up residence in Shanghai. At the First KMT Congress, held in Guangzhou in early 1924, Mao was elected an alternate member of the KMT Central Executive Committee, and put forward four resolutions to decentralise power to urban and rural bureaus. His enthusiastic support for the KMT earned him the suspicion of Li Li-san, his Hunan comrade.\nIn late 1924, Mao returned to Shaoshan, perhaps to recuperate from an illness. He found that the peasantry were increasingly restless and some had seized land from wealthy landowners to found communes. This convinced him of the revolutionary potential of the peasantry, an idea advocated by the KMT leftists but not the Communists. Mao and many of his colleagues also proposed the end of cooperation with the KMT, which was rejected by the Comintern representative Mikhail Borodin. In the winter of 1925, Mao fled to Guangzhou after his revolutionary activities attracted the attention of Zhao's regional authorities. There, he ran the 6th term of the KMT's Peasant Movement Training Institute from May to September 1926. The Peasant Movement Training Institute under Mao trained cadres and prepared them for militant activity, taking them through military training exercises and getting them to study basic left-wing texts.\nWhen party leader Sun Yat-sen died in May 1925, he was succeeded by Chiang Kai-shek, who moved to marginalise the left-KMT and the CCP. Mao nevertheless supported Chiang's National Revolutionary Army, who embarked on the Northern Expedition attack in 1926 on warlords. In the wake of this expedition, peasants rose up, appropriating the land of the wealthy landowners, who were in many cases killed. Such uprisings angered senior KMT figures, who were themselves landowners, emphasising the growing class and ideological divide within the revolutionary movement.\nIn March 1927, Mao appeared at the Third Plenum of the KMT Central Executive Committee in Wuhan, which sought to strip General Chiang of his power by appointing Wang Jingwei leader. There, Mao played an active role in the discussions regarding the peasant issue, defending a set of \"Regulations for the Repression of Local Bullies and Bad Gentry\", which advocated the death penalty or life imprisonment for anyone found guilty of counter-revolutionary activity, arguing that in a revolutionary situation, \"peaceful methods cannot suffice\". In April 1927, Mao was appointed to the KMT's five-member Central Land Committee, which also included Deng Yanda, Xu Qian, Ku Meng-yu, and Tan Pingshan. Together, the five were tasked with deliberating land reform policies, drafting proposals, and coordinating efforts to implement agrarian change under the Wuhan government.He also urging peasants to refuse to pay rent. Mao led another group to put together a \"Draft Resolution on the Land Question\", which called for the confiscation of land belonging to \"local bullies and bad gentry, corrupt officials, militarists and all counter-revolutionary elements in the villages\". Proceeding to carry out a \"Land Survey\", he stated that anyone owning over 30 \"mou\" (four and a half acres), constituting 13% of the population, were uniformly counter-revolutionary. He accepted that there was great variation in revolutionary enthusiasm across the country, and that a flexible policy of land redistribution was necessary. Presenting his conclusions at the Enlarged Land Committee meeting, many expressed reservations, some believing that it went too far, and others not far enough. Ultimately, his suggestions were only partially implemented.\nCivil War.\nNanchang and Autumn Harvest Uprisings: 1927.\nFresh from the success of the Northern Expedition against the warlords, Chiang turned on the Communists, who then numbered in the tens of thousands across China. Chiang ignored the orders of the Wuhan-based leftist KMT government and marched on Shanghai, a city controlled by Communist militias. As the Communists awaited Chiang's arrival, he loosed the White Terror, massacring with the aid of the Green Gang. In Beijing, 19 leading Communists were killed by Zhang Zuolin. That May, tens of thousands of Communists and those suspected of being communists were killed, and the CCP lost approximately of its members.\nThe CCP continued supporting the leftist KMT government in Wuhan, a position Mao initially supported, but by the time of the CCP's Fifth Congress he had changed his mind, deciding to stake all hope on the peasant militia. The question was rendered moot when the Wuhan government expelled all Communists from the KMT on 15 July. The CCP founded the Workers' and Peasants' Red Army of China, better known as the \"Red Army\", to battle Chiang. A battalion led by General Zhu De was ordered to take the city of Nanchang on 1 August 1927, in what became known as the Nanchang Uprising. They were initially successful, but were forced into retreat after five days, marching south to Shantou, and from there they were driven into the wilderness of Fujian. Mao was appointed commander-in-chief of the Red Army and led four regiments against Changsha in the Autumn Harvest Uprising, in the hope of sparking peasant uprisings across Hunan. On the eve of the attack, Mao composed a poem\u2014the earliest of his to survive\u2014titled \"Changsha\". His plan was to attack the KMT-held city from three directions on 9 September, but the Fourth Regiment deserted to the KMT cause, attacking the Third Regiment. Mao's army made it to Changsha, but could not take it; by 15 September, he accepted defeat and with 1000 survivors marched east to the Jinggang Mountains of Jiangxi.\nBase in Jinggangshan: 1927\u20131928.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\n Revolution is not a dinner party, nor an essay, nor a painting, nor a piece of embroidery; it cannot be so refined, so leisurely and gentle, so temperate, kind, courteous, restrained and magnanimous. A revolution is an insurrection, an act of violence by which one class overthrows another.\n\u2014 Mao, February 1927\nThe CCP Central Committee, hiding in Shanghai, expelled Mao from their ranks and from the Hunan Provincial Committee, as punishment for his \"military opportunism\", for his focus on rural activity, and for being too lenient with \"bad gentry\". The more orthodox Communists especially regarded the peasants as backward and ridiculed Mao's idea of mobilizing them. They nevertheless adopted three policies he had long championed: the immediate formation of workers' councils, the confiscation of all land without exemption, and the rejection of the KMT. Mao's response was to ignore them. He established a base in Jinggangshan City, an area of the Jinggang Mountains, where he united five villages as a self-governing state, and supported the confiscation of land from rich landlords, who were \"re-educated\" and sometimes executed. He ensured that no massacres took place in the region, and pursued a more lenient approach than that advocated by the Central Committee. In addition to land redistribution, Mao promoted literacy and non-hierarchical organizational relationships in Jinggangshan, transforming the area's social and economic life and attracted many local supporters.\nMao proclaimed that \"Even the lame, the deaf and the blind could all come in useful for the revolutionary struggle\", he boosted the army's numbers, incorporating two groups of bandits into his army, building a force of around troops. He laid down rules for his soldiers: prompt obedience to orders, all confiscations were to be turned over to the government, and nothing was to be confiscated from poorer peasants. In doing so, he moulded his men into a disciplined, efficient fighting force.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\n&lt;poem&gt;\nWhen the enemy advances, we retreat.\nWhen the enemy rests, we harass him.\nWhen the enemy avoids a battle, we attack.\nWhen the enemy retreats, we advance.&lt;/poem&gt;\n\u2014 Mao's advice in combating the Kuomintang, 1928\nIn spring 1928, the Central Committee ordered Mao's troops to southern Hunan, hoping to spark peasant uprisings. Mao was skeptical, but complied. They reached Hunan, where they were attacked by the KMT and fled after heavy losses. Meanwhile, KMT troops had invaded Jinggangshan, leaving them without a base. Wandering the countryside, Mao's forces came across a CCP regiment led by General Zhu De and Lin Biao; they united, and attempted to retake Jinggangshan. They were initially successful, but the KMT counter-attacked, and pushed the CCP back; over the next few weeks, they fought an entrenched guerrilla war in the mountains. The Central Committee again ordered Mao to march to south Hunan, but he refused, and remained at his base. Contrastingly, Zhu complied, and led his armies away. Mao's troops fended the KMT off for 25 days while he left the camp at night to find reinforcements. He reunited with the decimated Zhu's army, and together they returned to Jinggangshan and retook the base. There they were joined by a defecting KMT regiment and Peng Dehuai's Fifth Red Army. In the mountainous area they were unable to grow enough crops to feed everyone, leading to food shortages throughout the winter.\nIn 1928, Mao met and married He Zizhen, an 18-year-old revolutionary who would bear him six children.\nJiangxi Soviet Republic of China: 1929\u20131934.\nIn January 1929, Mao and Zhu evacuated the base with 2,000 men and a further 800 provided by Peng, and took their armies south, to the area around Tonggu and Xinfeng in Jiangxi. The evacuation led to a drop in morale, and many troops became disobedient and began thieving; this worried Li Lisan and the Central Committee, who saw Mao's army as \"lumpenproletariat\", that were unable to share in proletariat class consciousness. In keeping with orthodox Marxist thought, Li believed that only the urban proletariat could lead a successful revolution, and saw little need for Mao's peasant guerrillas; he ordered Mao to disband his army into units to be sent out to spread the revolutionary message. Mao replied that while he concurred with Li's theoretical position, he would not disband his army nor abandon his base. Both Li and Mao saw the Chinese Communist Revolution as the key to world revolution, believing that a CCP victory would spark the overthrow of global imperialism and capitalism. In this, they disagreed with the official line of the Soviet government and Comintern. Officials in Moscow desired greater control over the CCP and removed Li from power by calling him to Russia for an inquest into his errors. They replaced him with Soviet-educated Chinese Communists, known as the \"28 Bolsheviks\", two of whom, Bo Gu and Zhang Wentian, took control of the Central Committee. Mao disagreed with the new leadership, believing they grasped little of the Chinese situation, and he soon emerged as their key rival.\nIn February 1930, Mao created the Southwest Jiangxi Provincial Soviet Government in the region under his control. In November, he suffered emotional trauma after his second wife Yang Kaihui and sister were captured and beheaded by KMT general He Jian. Facing internal problems, members of the Jiangxi Soviet accused him of being too moderate, and hence anti-revolutionary. In December, they tried to overthrow Mao, resulting in the Futian incident, during which Mao's loyalists tortured many and executed between 2000 and 3000 dissenters. The CCP Central Committee moved to Jiangxi which it saw as a secure area. In November, it proclaimed Jiangxi to be the Soviet Republic of China, an independent Communist-governed state. Although he was proclaimed Chairman of the Council of People's Commissars, Mao's power was diminished, as his control of the Red Army was allocated to Zhou Enlai. Meanwhile, Mao recovered from tuberculosis.\nThe KMT armies adopted a policy of encirclement and annihilation of the Red armies. Outnumbered, Mao responded with guerrilla tactics influenced by the works of ancient military strategists like Sun Tzu, but Zhou and the new leadership followed a policy of open confrontation and conventional warfare. In doing so, the Red Army successfully defeated the first and second encirclements. Angered at his armies' failure, Chiang Kai-shek personally arrived to lead the operation. He too faced setbacks and retreated to deal with the further Japanese incursions into China. As a result of the KMT's change of focus to the defence of China against Japanese expansionism, the Red Army was able to expand its area of control, eventually encompassing a population of 3 million. Mao proceeded with his land reform program. In November 1931 he announced the start of a \"land verification project\" which was expanded in June 1933. He also orchestrated education programs and implemented measures to increase female political participation. Chiang viewed the Communists as a greater threat than the Japanese and returned to Jiangxi, where he initiated the fifth encirclement campaign, which involved the construction of a concrete and barbed wire \"wall of fire\" around the state, which was accompanied by aerial bombardment, to which Zhou's tactics proved ineffective. Trapped inside, morale among the Red Army dropped as food and medicine became scarce. The leadership decided to evacuate.\nLong March: 1934\u20131935.\nOn 14 October 1934, the Red Army broke through the KMT line on the Jiangxi Soviet's south-west corner at Xinfeng with soldiers and party cadres and embarked on the \"Long March\". In order to make the escape, many of the wounded and the ill, as well as women and children, were left behind, defended by a group of guerrilla fighters whom the KMT massacred. The who escaped headed to southern Hunan, first crossing the Xiang River after heavy fighting, and then the Wu River, in Guizhou where they took Zunyi in January 1935. Temporarily resting in the city, they held a conference; here, Mao was elected to a position of leadership, becoming Chairman of the Politburo, and \"de facto\" leader of both Party and Red Army, in part because his candidacy was supported by Soviet Premier Joseph Stalin. Insisting that they operate as a guerrilla force, he laid out a destination: the Shenshi Soviet in Shaanxi, Northern China, from where the Communists could focus on fighting the Japanese. Mao believed that in focusing on the anti-imperialist struggle, the Communists would earn the trust of the Chinese people, who in turn would renounce the KMT.\nFrom Zunyi, Mao led his troops to Loushan Pass, where they faced armed opposition but successfully crossed the river. Chiang flew into the area to lead his armies against Mao, but the Communists outmanoeuvred him and crossed the Jinsha River. Faced with the more difficult task of crossing the Tatu River, they managed it by fighting a battle over the Luding Bridge in May, taking Luding. In Moukung, Western Sichuan, they encountered the -strong CCP Fourth Front Army of Zhang Guotao (who had marched from the mountain ranges around Ma'anshan), and together proceeded to Maoerhkai and then Gansu. Zhang and Mao disagreed over what to do; the latter wished to proceed to Shaanxi, while Zhang wanted to retreat west to Tibet or Sikkim, far from the KMT threat. It was agreed that they would go their separate ways, with Zhu De joining Zhang. Mao's forces proceeded north, through hundreds of kilometres of grasslands, an area of quagmire where they were attacked by Manchu tribesman and where many soldiers succumbed to famine and disease. Finally reaching Shaanxi, they fought off both the KMT and an Islamic cavalry militia before crossing the Min Mountains and Mount Liupan and reaching the Shenshi Soviet; only 7,000\u20138,000 had survived. The Long March cemented Mao's status as the dominant figure in the party. In November 1935, he was named chairman of the Military Commission. From this point onward, Mao was the CCP's undisputed leader, even though he would not become party chairman until 1943.\nWorld War II.\nMao's troops arrived at the Yan'an Soviet during October 1935 and settled in Bao'an, until spring 1936. While there, they developed links with local communities, redistributed and farmed the land, offered medical treatment, and began literacy programs. Mao now commanded soldiers, boosted by the arrival of He Long's men from Hunan and the armies of Zhu De and Zhang Guotao returned from Tibet. In February 1936, they established the North West Anti-Japanese Red Army University in Yan'an, through which they trained increasing numbers of new recruits. In January 1937, they began the \"anti-Japanese expedition\", that sent groups of guerrilla fighters into Japanese-controlled territory to undertake sporadic attacks. In May 1937, a Communist Conference was held in Yan'an to discuss the situation. Western reporters also arrived in the \"Border Region\" (as the Soviet had been renamed); most notable were Edgar Snow, who used his experiences as a basis for \"Red Star Over China\", and Agnes Smedley, whose accounts brought international attention to Mao's cause.\nOn the Long March, Mao's wife He Zizhen had been injured by a shrapnel wound to the head. She travelled to Moscow for medical treatment; Mao proceeded to divorce her and marry an actress, Jiang Qing. He Zizhen was reportedly \"dispatched to a mental asylum in Moscow to make room\" for Qing. Mao moved into a cave-house and spent much of his time reading, tending his garden and theorising. He came to believe that the Red Army alone was unable to defeat the Japanese, and that a Communist-led \"government of national defence\" should be formed with the KMT and other \"bourgeois nationalist\" elements to achieve this goal. Although despising Chiang Kai-shek as a \"traitor to the nation\", on 5 May, he telegrammed the Military Council of the Nanjing National Government proposing a military alliance, a course of action advocated by Stalin. Although Chiang intended to ignore Mao's message and continue the civil war, he was arrested by one of his own generals, Zhang Xueliang, in Xi'an, leading to the Xi'an Incident; Zhang forced Chiang to discuss the issue with the Communists, resulting in the formation of a United Front with concessions on both sides on 25 December 1937.\nThe Japanese had taken both Shanghai and Nanjing\u2014resulting in the Nanjing Massacre, an atrocity Mao never spoke of all his life\u2014and was pushing the Kuomintang government inland to Chongqing. The Japanese's brutality led to increasing numbers of Chinese joining the fight, and the Red Army grew from to . In August 1938, the Red Army formed the New Fourth Army and the Eighth Route Army, which were nominally under the command of Chiang's National Revolutionary Army. In August 1940, the Red Army initiated the Hundred Regiments Offensive, in which troops attacked the Japanese simultaneously in five provinces. It was a military success that resulted in the death of Japanese, the disruption of railways and the loss of a coal mine. From his base in Yan'an, Mao authored several texts for his troops, including \"Philosophy of Revolution\", which offered an introduction to the Marxist theory of knowledge; \"Protracted Warfare\", which dealt with guerrilla and mobile military tactics; and \"On New Democracy\", which laid forward ideas for China's future.\nIn 1944, the U.S. sent a special diplomatic envoy, called the Dixie Mission, to the Chinese Communist Party. The American soldiers who were sent to the mission were favourably impressed. The party seemed less corrupt, more unified, and more vigorous in its resistance to Japan than the Kuomintang. The soldiers confirmed to their superiors that the party was both strong and popular over a broad area. In the end of the mission, the contacts which the U.S. developed with the Chinese Communist Party led to very little. After the end of World War II, the U.S. continued their diplomatic and military assistance to Chiang Kai-shek and his KMT government forces against the People's Liberation Army (PLA) led by Mao Zedong during the civil war and abandoned the idea of a coalition government which would include the CCP. Likewise, the Soviet Union gave support to Mao by occupying north-eastern China, and secretly giving it to the Chinese communists in March 1946.\nLeadership of China.\nEstablishment of the People's Republic of China.\nIn 1948, the People's Liberation Army starved out the Kuomintang forces occupying Changchun. At least civilians are believed to have perished during the siege, which lasted from June until October. PLA lieutenant colonel Zhang Zhenglu, in his book \"White Snow, Red Blood\", compared it to Hiroshima: \"The casualties were about the same. Hiroshima took nine seconds; Changchun took five months.\" On 21 January 1949, Kuomintang forces suffered great losses in decisive battles against Mao's forces. In the early morning of 10 December 1949, PLA troops laid siege to Chongqing and Chengdu on mainland China, and Chiang Kai-shek fled from the mainland to Taiwan.\nMao proclaimed the establishment of the People's Republic of China from Tiananmen on 1 October 1949, and later that week declared \"The Chinese people have stood up\" (). Mao went to Moscow for talks in the winter of 1949\u201350. Mao initiated the talks which focused on the political and economic revolution in China, foreign policy, railways, naval bases, and Soviet economic and technical aid. The resulting treaty reflected Stalin's dominance and his willingness to help Mao.\nFollowing the Marxist\u2013Leninist theory of vanguardism, Mao believed that only the correct leadership of the Communist Party could advance China into socialism. Conversely, Mao also believed that mass movements and mass criticism were necessary in order to check the bureaucracy.\nKorean War.\nMao pushed the Party to organise campaigns to reform society and extend control. These campaigns were given urgency in October 1950, when the People's Volunteer Army was sent into the Korean War to fight as well as reinforce the armed forces of North Korea, the Korean People's Army, which had been in full retreat. The United States placed a trade embargo on the People's Republic as a result of its involvement in the Korean War, lasting until Richard Nixon's improvements of relations. At least 180,000 Chinese troops died during the war.\nAs the Chairman of the Central Military Commission (CMC), Mao was also the Supreme Commander in Chief of the PLA and the People's Republic and Chairman of the Party. Chinese troops in Korea were under the overall command of then newly installed Premier Zhou Enlai, with General Peng Dehuai as field commander and political commissar.\nSocial reform.\nDuring the land reform campaigns, large numbers of people accused of being \"landlords\" and \"rich peasants\" were beaten to death at mass meetings as land was taken from them and given to poorer peasants, which reduced economic inequality. However, the peasants were now subject to a grain levy/tax, which left them with not enough grain for bare subsistence, once seed grain was set aside. This was further reduced (from 20 kg per month to only 10 kg) to a starvation diet in 1953. One of the main beneficiaries of \"land reform\" were CCP cadres who acquired \"black land\" (untaxed village land) and used their power to dominate the local peasants. In some cases \"middle peasants\" were also arrested, tortured and expropriated, and even children were killed, having been labeled as \"little landlords\". As a result of the campaign, by 1953 agricultural productivity plummeted and famine appeared. In some provinces, like Hubei, whole counties experienced mass starvation, according to reports from work teams sent to the Committee on Land Reform, and millions of people became destitute. Villagers resorted to eating bark, leaves and mud and in some cases sold their children in exchange for food.\nThe Campaign to Suppress Counter-revolutionaries targeted bureaucratic bourgeoisie, such as compradors, merchants and Kuomintang officials who were seen by the party as economic parasites or political enemies. In 1976, the U.S. State Department estimated as many as a million were killed in the land reform, and killed in the counter-revolutionary campaign.\nMao himself claimed that a total of people were killed in attacks on \"counter-revolutionaries\" during the years 1950\u20131952. Because there was a policy to select \"at least one landlord, and usually several, in virtually every village for public execution\", the number of deaths range between 2 million and 5 million. In addition, at least 1.5 million people, perhaps as many as 4 to 6 million, were sent to \"reform through labour\" camps where many perished. Mao defended these killings as necessary for the securing of power.\nThe government is credited with eradicating both consumption and production of opium during the 1950s. Ten million addicts were forced into compulsory treatment, dealers were executed, and opium-producing regions were planted with new crops. Remaining opium production shifted south of the Chinese border into the Golden Triangle region.\nThree-anti and Five-anti Campaigns.\nStarting in 1951, Mao initiated movements to rid urban areas of corruption; the Three-anti and Five-anti Campaigns. Whereas the three-anti campaign was a focused purge of government, industrial and party officials, the five-anti campaign set its sights slightly more broadly, targeting capitalist elements in general. Workers denounced their bosses, spouses turned on their spouses, and children informed on their parents; the victims were often humiliated at struggle sessions, where a targeted person would be verbally and physically abused until they confessed to crimes. Mao insisted that minor offenders be criticised and reformed or sent to labour camps, \"while the worst among them should be shot\". These campaigns took several hundred thousand additional lives, the vast majority via suicide.\nIn Shanghai, suicide by jumping from tall buildings became so commonplace that residents avoided walking on the pavement near skyscrapers for fear that suicides might land on them. Some biographers have pointed out that driving those perceived as enemies to suicide was a common tactic during the Mao-era. In his biography of Mao, Philip Short notes that Mao gave explicit instructions in the Yan'an Rectification Movement that \"no cadre is to be killed\" but in practice allowed security chief Kang Sheng to drive opponents to suicide and that \"this pattern was repeated throughout his leadership of the People's Republic\".\nFive-year plans.\nFollowing the consolidation of power, Mao launched the first five-year plan (1953\u20131958), which emphasised rapid industrial development. Within industry, iron and steel, electric power, coal, heavy engineering, building materials, and basic chemicals were prioritised with the aim of constructing large and highly capital-intensive plants. Many of these plants were built with Soviet assistance and heavy industry grew rapidly. Agriculture, industry and trade were organised as worker cooperatives. This period marked the beginning of China's rapid industrialisation and it resulted in an enormous success.\nDespite being initially sympathetic towards the reformist government of Imre Nagy, Mao feared the \"reactionary restoration\" in Hungary as the Hungarian Revolution of 1956 continued and became more hardline. Mao opposed the withdrawal of Soviet troops by asking Liu Shaoqi to inform the Soviet representatives to use military intervention against \"Western imperialist-backed\" protestors and Nagy's government. However, it was unclear to what degree Mao's stance played a role in Nikita Khrushchev's decision to invade Hungary. It was also unclear if China was forced to conform to the Soviet position due to economic concerns and China's poor power projections compared to the USSR. Despite his disagreements with Moscow's hegemony in the Eastern Bloc, Mao viewed the integrity of the international communist movement as more important than the national autonomy of the countries in the Soviet sphere of influence. The Hungarian crisis also influenced Mao's Hundred Flowers Campaign. Mao decided to soften his stance on Chinese intelligentsia and allow them to express their social dissatisfaction and criticisms of the errors of the government. Mao wanted to use this movement to prevent a similar uprising in China. However, as people in China began to criticize the CCP's policies and Mao's leadership following the Hundred Flowers Campaign, Mao cracked down on the movement he initiated and compared it to the \"counter-revolutionary\" Hungarian Revolution.\nDuring the Hundred Flowers Campaign, Mao indicated his supposed willingness to consider different opinions about how China should be governed. Given the freedom to express themselves, liberal and intellectual Chinese began opposing the Communist Party and questioning its leadership. This was initially tolerated and encouraged. After a few months, Mao's government reversed its policy and persecuted those who had criticised the party, totalling perhaps , as well as those who were merely alleged to have been critical, in what is called the Anti-Rightist Movement. The movement led to the persecution of at least 550,000 people, mostly intellectuals and dissidents. Li Zhisui, Mao's physician, suggested that Mao had initially seen the policy as a way of weakening opposition to him within the party and that he was surprised by the extent of criticism and the fact that it came to be directed at his own leadership.\nMilitary projects.\nUnited States President Dwight D. Eisenhower's threats during the First Taiwan Strait Crisis to use nuclear weapons against military targets in Fujian province prompted Mao to begin China's nuclear program. Under Mao's Two Bombs, One Satellite program, China developed the atomic and hydrogen bombs in record time and launched a satellite a few years after the Soviet Union launched Sputnik.218\nProject 523 is a 1967 military project to find antimalarial medications. It addressed malaria, an important threat in the Vietnam War. Zhou Enlai convinced Mao Zedong to start the mass project \"to keep [the] allies' troops combat-ready\", as the meeting minutes put it. The one for investigating traditional Chinese medicine discovered and led to the development of a class of new antimalarial drugs called artemisinins.\nGreat Leap Forward.\nIn January 1958, Mao launched the Great Leap Forward, to turn China from an agrarian nation to an industrialised one. The relatively small agricultural collectives that had been formed were merged into far larger people's communes, and many peasants were ordered to work on infrastructure projects and on the production of iron and steel. Some private food production was banned, and livestock and farm implements were brought under collective ownership.\nThe effect of the diversion of labour to steel production and infrastructure projects, and cyclical natural disasters led to an approximately 15% drop in grain production in 1959 followed by a further 10% decline in 1960 and no recovery in 1961.\nTo win favour with their superiors and avoid being purged, each layer in the party exaggerated the amount of grain produced under them. Based upon the falsely reported success, party cadres were ordered to requisition a high amount of that fictitious harvest. The result, compounded in some areas by drought and in others by floods, was that farmers were left with little food and many millions starved to death in the Great Chinese Famine. The people of urban areas were given food stamps each month, but the people of rural areas were expected to grow their own crops and give some of the crops back to the government. The death count in rural parts of China surpassed the deaths in the urban centers. The famine was a direct cause of the death of some 30 million Chinese peasants between 1959 and 1962. Many children became malnourished.\nIn late autumn 1958, Mao condemned the practices used during Great Leap Forward such as forcing peasants to do labour without enough food or rest which resulted in epidemics and starvation. He also acknowledged that anti-rightist campaigns were a major cause of \"production at the expense of livelihood.\" He refused to abandon the Great Leap Forward, but he did demand that they be confronted. After the July 1959 clash at Lushan Conference with Peng Dehuai, Mao launched a new anti-rightist campaign along with the radical policies that he previously abandoned. It wasn't until the spring of 1960, that Mao would again express concern about abnormal deaths and other abuses, but he did not move to stop them. Bernstein concludes that the Chairman \"wilfully ignored the lessons of the first radical phase for the sake of achieving extreme ideological and developmental goals\".\nMao stepped down as President of China on 27 April 1959; he retained other top positions such as Chairman of the Communist Party and of the Central Military Commission. The Presidency was transferred to Liu Shaoqi. Mao eventually abandoned the policy in 1962. Liu Shaoqi and Deng Xiaoping rescued the economy by disbanding the people's communes, introducing elements of private control of peasant smallholdings and importing grain from Canada and Australia to mitigate the worst effects of famine.\nAt the Lushan Conference in July/August 1959, several ministers expressed concern that the Great Leap Forward had not proved as successful as planned. The most direct of these was Minister of Defence Peng Dehuai. Following Peng's criticism of the Great Leap Forward, Mao made a purge of Peng and his supporters, stifling criticism of the Great Leap policies. A campaign was launched and resulted in party members and ordinary peasants being sent to prison labour camps. Years later the CCP would conclude that as many as six million people were wrongly punished in the campaign.\nSplit from Soviet Union.\nThe Sino-Soviet split resulted in Nikita Khrushchev's withdrawal of Soviet technical experts and aid from the country. The split concerned the leadership of world communism. The USSR had a network of Communist parties it supported; China now created its own rival network to battle it out. Lorenz M. L\u00fcthi writes: \"The Sino-Soviet split was one of the key events of the Cold War, equal in importance to the construction of the Berlin Wall, the Cuban Missile Crisis, the Second Vietnam War, and Sino-American rapprochement. The split helped to determine the framework of the Second Cold War in general, and influenced the course of the Second Vietnam War in particular.\"\nThe split resulted from Khrushchev's more moderate Soviet leadership after the death of Stalin in March 1953. Only Albania openly sided with China, thereby forming an alliance between the two countries. Warned that the Soviets had nuclear weapons, Mao minimised the threat. Struggle against Soviet revisionism and U.S. imperialism was an important aspect of Mao's attempt to direct the revolution in the right direction.\nIn the late 1950s, Mao wrote reading notes responding to the Soviet Book \"Political Economy: A Textbook\" and essays (\"A Critique of Soviet Economics\") responding to Stalin's \"Economic Problems of Socialism in the USSR.\"51 These texts reflect Mao's views that the USSR was becoming alienated from the masses and distorting socialist development.51\nThird Front.\nAfter the Great Leap Forward, China's leadership slowed the pace of industrialization.3 It invested more on in China's coastal regions and focused on the production of consumer goods.3 Preliminary drafts of the Third Five Year Plan contained no provision for developing large scale industry in China's interior.29 After an April 1964 General Staff report concluded that the concentration of China's industry in its major coastal cities made it vulnerable to attack by foreign powers, Mao argued for the development of basic industry and national defense industry in protected locations in China's interior. Although other key leaders did not initially support the idea, the 2 August 1964 Gulf of Tonkin incident increased fears of a potential invasion by the United States and crystallized support for Mao's industrialization proposal, which came to be known as the Third Front.7 Following the Gulf of Tonkin incident, Mao's own concerns of invasion by the United States increased.100 He wrote to central cadres, \"A war is going to break out. I need to reconsider my actions\" and pushed even harder for the creation of the Third Front.100\nThe secretive Third Front construction involved massive projects including extensive railroad infrastructure like the Chengdu\u2013Kunming line, aerospace industry including satellite launch facilities,218\u2013219 and steel production industry including Panzhihua Iron and Steel.9\nDevelopment of the Third Front slowed in 1966, but accelerated again after the Sino-Soviet border conflict at Zhenbao Island, which increased the perceived risk of Soviet Invasion. Third Front construction again decreased after United States President Richard Nixon's 1972 visit to China and the resulting rapprochement between the United States and China. When Reform and Opening up began after Mao's death, China began to wind down Third Front projects.180 Through distributing infrastructure, state investment, and human talent through the country, the Third Front mitigated regional disparities and ultimately contributed to favorable conditions for later market development.\nCultural Revolution.\nDuring the early 1960s, Mao became concerned with the nature of post-1959 China. He saw that the old ruling elite was replaced by a new one. He was concerned that those in power were becoming estranged from the people they were to serve. Mao believed that a revolution of culture would unseat and unsettle the \"ruling class\" and keep China in a state of \"continuous revolution\" that, theoretically, would serve the interests of the majority, rather than a tiny and privileged elite.\nThe Cultural Revolution led to the destruction of much of China's traditional cultural heritage and the imprisonment of many Chinese citizens, as well as the creation of chaos in the country. Millions of lives were ruined, as the Cultural Revolution pierced into Chinese life. It is estimated that hundreds of thousands of people, perhaps millions, perished in the violence of the Cultural Revolution. This included prominent figures such as Liu Shaoqi.\nIt was during this period that Mao chose Lin Biao to become his successor. Lin was later officially named as Mao's successor. By 1971, a divide between the two men had become apparent. Lin Biao died on 13 September 1971, in a plane crash over the air space of Mongolia, presumably as he fled China, probably anticipating his arrest. The CCP declared that Lin was planning to depose Mao and posthumously expelled Lin from the party. At this time, Mao lost trust in many of the top CCP figures. The highest-ranking Soviet Bloc intelligence defector, Lt. Gen. Ion Mihai Pacepa claimed he had a conversation with Nicolae Ceau\u0219escu, who told him about a plot to kill Mao with the help of Lin Biao organised by the KGB.\nIn 1969, Mao declared the Cultural Revolution to be over. Various historians mark the end of the Cultural Revolution in 1976, following Mao's death and the arrest of the Gang of Four. The Central Committee in 1981 officially declared the Cultural Revolution a \"severe setback\" for the PRC.\nAn estimate of around 400,000 deaths is a widely accepted minimum figure, according to Maurice Meisner. MacFarquhar and Schoenhals assert that in rural China alone some 36\u00a0million people were persecuted, of whom between 750,000 and 1.5\u00a0million were killed, with roughly the same number permanently injured.\nState visits.\nDuring his leadership, Mao traveled outside China on two occasions, both times for state visits to the Soviet Union. In his first visit on 16 December 1949, Mao traveled to celebrate the 70th birthday of Joseph Stalin in Moscow, an event that was also attended by East German deputy chairman of the Council of Ministers Walter Ulbricht and Mongolian general secretary Yumjaagiin Tsedenbal. Mao's second visit took place between 2 and 19 November 1957; highlights included his attendance at the 40th anniversary (Ruby Jubilee) celebrations of the October Revolution (he attended the annual military parade of the Moscow Garrison on Red Square as well as a banquet in the Kremlin) and the International Meeting of Communist and Workers Parties, where he met with other communist leaders.\nDeath and aftermath.\nMao's health declined in his final years, probably aggravated by his chain-smoking. It became a state secret that he suffered from multiple lung and heart ailments during his later years. There are unconfirmed reports that he possibly had Parkinson's disease in addition to amyotrophic lateral sclerosis (ALS), also known as Lou Gehrig's disease. He suffered two major heart attacks, one on May 11 and another on June 26, then a third on 2 September, rendering him as invalid. He died nearly one week later, shortly after midnight on 9 September 1976, at the age of 82. The Communist Party delayed the announcement of his death until 16:00, when a national radio broadcast announced the news and appealed for party unity.\nMao's embalmed body, draped in the CCP flag, lay in state at the Great Hall of the People for one week. One million Chinese filed past to pay their final respects, many displaying sadness, while foreigners watched on television. Mao's official portrait hung on the wall with a banner reading: \"Carry on the cause left by Chairman Mao and carry on the cause of proletarian revolution to the end\". On 17 September, the body was taken in a minibus to the 305 Hospital, where his internal organs were preserved in formaldehyde.\nOn 18 September, guns, sirens, whistles and horns across China were simultaneously blown and a mandatory three-minute silence was observed. Tiananmen Square was packed with millions of people and a military band played \"The Internationale\". Hua Guofeng concluded the service with a 20-minute-long eulogy atop Tiananmen Gate. Despite Mao's request to be cremated, his body was later permanently put on display in the Mausoleum of Mao Zedong, in order for the Chinese nation to pay its respects.\nLegacy.\nMao has been called one of the most important and influential individuals in the 20th century. He has also been described as a political intellect, theorist, military strategist, poet, and visionary. Mao's insurgency strategies continue to be used by insurgents, and his political ideology continues to be embraced by many Communist organisations around the world.\nMao has been credited with his role in ending the previous decades of civil war. He has also been credited with having improved the status of women in China and for improving literacy and education. Mao has been credited for boosting literacy, reducing poverty, a near doubling life expectancy, a near doubling of the population, rapidly developing China's industry and infrastructure, and creating a self-sufficient and self-reliant economy, paving the way for its position as a world power.61\nMao's policies resulted in the deaths of tens of millions of people in China during his tenure, mainly due to starvation, but also through persecution, prison labour in \"laogai\", and mass executions. Mao's China has been described as an autocratic and totalitarian regime responsible for mass repression. Mao has been described as one of the great tyrants of the twentieth century.\nAssessment in China.\nOn 27 June 1981, the CCP Central Committee adopted the \"Resolution on Certain Questions in the History of Our Party since the Founding of the People's Republic of China,\" which assessed the legacy of the Mao era and the CCP's priorities going forward.166 The \"Resolution\" describes setbacks during the period 1957 to 1964 (although it generally affirms this period) and major mistakes beginning in 1965, attributing Mao's errors to individualist tendencies which arose when he departed from the collective view of the leadership.167 Regarding Mao's legacy, the CCP's resolution stated that Mao's contributions to the Chinese Communist Revolution far outweigh his mistakes.445\nIn China, a common expression for summarizing Mao's legacy is that he was 70 percent right and 30 percent wrong.55445253 In December 2013, a poll from the CCP-run tabloid \"Global Times\", stated that roughly 85% of the 1,045 respondents surveyed felt that Mao's achievements outweighed his mistakes.\nOpposition to Mao can lead to censorship or professional repercussions in mainland China, and is often done in private settings. When a video of Bi Fujian, a television host, insulting Mao at a private dinner in 2015 went viral, Bi garnered the support of Weibo users, with 80% of them saying in a poll that Bi should not apologize amidst backlash from state affiliates. Chinese citizens are aware of Mao's mistakes, but many see Mao as a national hero. He is seen as someone who successfully liberated the country from Japanese occupation during the Second Sino-Japanese War and from Western imperialist exploitation dating back to the Opium Wars. Between 2015 and 2018, \"The Washington Post\" interviewed 70 people in China about the Maoist era. A \"sizable proportion\" commented positively on the era's simplicity, attributing to it the \"clear meaning\" of life and minimal inequality; they contended that the \"spiritual life\" was rich. The interviewees simultaneously acknowledged the poor \"material life\" and other negative experiences under Mao.\nOn 25 December 2008, China opened the Mao Zedong Square to visitors in his home town of central Hunan Province to mark the 115th anniversary of his birth.\nFormer CCP official Su Shachi has opined that \"he was a great historical criminal, but he was also a great force for good.\" In a similar vein, journalist Liu Binyan has described Mao as \"both monster and a genius.\" Li Rui, Mao's personal secretary and CCP comrade, opined that \"Mao's way of thinking and governing was terrifying. He put no value on human life. The deaths of others meant nothing to him.\"\nChen Yun remarked \"Had Mao died in 1956, his achievements would have been immortal. Had he died in 1966, he would still have been a great man but flawed. But he died in 1976. Alas, what can one say?\" Deng Xiaoping said \"I should remind you that Chairman Mao dedicated most of his life to China, that he saved the party and the revolution in their most critical moments, that, in short, his contribution was so great that, without him, the Chinese people would have had a much harder time finding the right path out of the darkness. We also shouldn't forget that it was Chairman Mao who combined the teachings of Marx and Lenin with the realities of Chinese history\u2014that it was he who applied those principles, creatively, not only to politics but to philosophy, art, literature, and military strategy.\"\nAssessment in Western world.\nPhilip Short argued that a bit more than half of the millions of deaths under Mao were unintended consequences of famine. Short stated that landlord class were not exterminated as a people due to Mao's belief in redemption through thought reform, and compared Mao with 19th-century Chinese reformers who challenged China's traditional beliefs in the era of China's clashes with Western colonial powers. Short writes that \"Mao's tragedy and his grandeur were that he remained to the end in thrall to his own revolutionary dreams. ... He freed China from the straitjacket of its Confucian past, but the bright Red future he promised turned out to be a sterile purgatory.\"\nAlexander V. Pantsov and Steven I. Levine, in their biography, asserted that Mao was both \"a successful creator and ultimately an evil destroyer\" but also argued that he was a complicated figure who should not be lionised as a saint or reduced to a demon, as he \"indeed tried his best to bring about prosperity and gain international respect for his country.\" They also remarked on Mao's legacy: \"A talented Chinese politician, an historian, a poet and philosopher, an all-powerful dictator and energetic organizer, a skillful diplomat and utopian socialist, the head of the most populous state, resting on his laurels, but at the same time an indefatigable revolutionary who sincerely attempted to refashion the way of life and consciousness of millions of people, a hero of national revolution and a bloody social reformer\u2014this is how Mao goes down in history. The scale of his life was too grand to be reduced to a single meaning.\" Mao's English interpreter Sidney Rittenberg wrote in his memoir that whilst Mao \"was a great leader in history\", he was also \"a great criminal because, not that he wanted to, not that he intended to, but in fact, his wild fantasies led to the deaths of tens of millions of people.\"\nThe United States placed a trade embargo on the People's Republic as a result of its involvement in the Korean War, until Richard Nixon decided that developing relations with the PRC would be useful. The television series \"Biography\" stated: \"[Mao] turned China from a feudal backwater into one of the most powerful countries in the World. ... The Chinese system he overthrew was backward and corrupt; few would argue the fact that he dragged China into the 20th century. But at a cost in human lives that is staggering.\"\nJohn King Fairbank remarked, \"The simple facts of Mao's career seem incredible: in a vast land of 400 million people, at age 28, with a dozen others, to found a party and in the next fifty years to win power, organize, and remold the people and reshape the land\u2014history records no greater achievement. Alexander, Caesar, Charlemagne, all the kings of Europe, Napoleon, Bismarck, Lenin\u2014no predecessor can equal Mao Tse-tung's scope of accomplishment, for no other country was ever so ancient and so big as China.\" In \"China: A New History\", Fairbank and Goldman assessed Mao's legacy: \"Future historians may conclude that Mao's role was to try to destroy the age-old bifurcation of China between a small educated ruling stratum and the vast mass of common people. We do not yet know how far he succeeded. The economy was developing, but it was left to his successors to create a new political structure.\"\nStuart R. Schram said that Mao was an \"Eternal rebel, refusing to be bound by the laws of God or man, nature or Marxism, [who] led his people for three decades in pursuit of a vision initially noble, which turned increasingly into a mirage, and then into a nightmare. Was he a Faust or Prometheus, attempting the impossible for the sake of humanity, or a despot of unbridled ambition, drunk with his own power and his own cleverness?\" Schram also agreed \"with the current Chinese view that Mao's merits outweighed his faults, but it is not easy to put a figure on the positive and negative aspects. How does one weigh, for example, the good fortune of hundreds of millions of peasants in getting land against the execution, in the course of land reform and the 'Campaign against Counter-Revolutionaries,' or in other contexts, of millions, some of whom certainly deserved to die, but others of whom undoubtedly did not? How does one balance the achievements in economic development during the first Five-Year Plan, or during the whole twenty-seven years of Mao's leadership after 1949, against the starvation which came in the wake of the misguided enthusiasm of the Great Leap Forward, or the bloody shambles of the Cultural Revolution?\" Schram added, \"In the last analysis, however, I am more interested in the potential future impact of his thought than in sending Mao as an individual to Heaven or to Hell.\"\nMaurice Meisner assessed Mao's legacy: \"It is the blots on the Maoist record, especially the Great Leap and the Cultural Revolution, that are now most deeply imprinted on our political and historical consciousness. That these adventures were failures colossal in scope, and that they took an enormous human toll, cannot and should not be forgotten. But future historians, without ignoring the failures and the crimes, will surely record the Maoist era in the history of the People's Republic (however else they may judge it) as one of the great modernizing epochs in world history, and one that brought great social and human benefits to the Chinese people.\"\nThird World.\nThe ideology of Maoism has influenced many communists, mainly in the Third World, including revolutionary movements such as Cambodia's Khmer Rouge, Peru's Shining Path, and the Nepalese revolutionary movement. Under the influence of Mao's agrarian socialism and Cultural Revolution, Pol Pot and the Khmer Rouge conceived of his disastrous Year Zero policies which purged the nation of its teachers, artists and intellectuals and emptied its cities, resulting in the Cambodian genocide. The Revolutionary Communist Party, USA, also claims Marxism\u2013Leninism-Maoism as its ideology, as do other communist parties around the world which are part of the Revolutionary Internationalist Movement. China itself has moved sharply away from Maoism since Mao's death, and most people outside of China who describe themselves as Maoist regard the Deng Xiaoping reforms to be a betrayal of Maoism, in line with Mao's view of \"capitalist roaders\" within the CCP. As the Chinese government instituted market economic reforms starting in the late 1970s and as later Chinese leaders took power, less recognition was given to the status of Mao. This accompanied a decline in state recognition of Mao in later years in contrast to previous years when the state organised numerous events and seminars commemorating Mao's 100th birthday. Nevertheless, the Chinese government has never officially repudiated the tactics of Mao. Deng Xiaoping, who was opposed to the Great Leap Forward and the Cultural Revolution, stated that \"when we write about his mistakes we should not exaggerate, for otherwise we shall be discrediting Chairman Mao Zedong and this would mean discrediting our party and state.\"\nThe July 1963 Limited Nuclear Test Ban Treaty increased Chinese concerns over a US-Soviet re-alignment against China and prompted Mao's articulation of the \"Two Intermediate Zones\" concept. Mao viewed Africa and Latin America as the \"First Intermediate Zone\", in which China's status as a non-white power might enable it to compete with and supersede both United States and Soviet Union influence.48 The other intermediate zone was the USA's wealthier allies in Europe.97\nMilitary strategy.\nMao's military writings continue to have a large amount of influence both among those who seek to create an insurgency and those who seek to crush one, especially in manners of guerrilla warfare, at which Mao is popularly regarded as a genius. The Nepali Maoists were highly influenced by Mao's views on protracted war, new democracy, support of masses, permanency of revolution and the Cultural Revolution. Mao's major contribution to the military science is his theory of people's war, with not only guerrilla warfare but more importantly, Mobile Warfare methodologies. Mao had successfully applied Mobile Warfare in the Korean War, and was able to encircle, push back and then halt the UN forces in Korea, despite the clear superiority of UN firepower.\nLiterature.\nMao's poems and writings are frequently cited by both Chinese and non-Chinese. The official Chinese translation of President Barack Obama's inauguration speech used a famous line from one of Mao's poems. In the mid-1990s, Mao's picture began to appear on all new renminbi currency from the People's Republic of China. This was officially instituted as an anti-counterfeiting measure as Mao's face is widely recognised in contrast to the generic figures that appear in older currency. On 13 March 2006, the \"People's Daily\" reported that a member of the Chinese People's Political Consultative Conference proposed to include the portraits of Sun Yat-sen and Deng Xiaoping in the renminbi.\nPublic image.\nMao gave contradicting statements on the subject of personality cults. In 1956, as a response to the Khrushchev Report that criticised Joseph Stalin, Mao stated that personality cults are \"poisonous ideological survivals of the old society\", and reaffirmed China's commitment to collective leadership. At the 1958 party congress in Chengdu, Mao expressed support for the personality cults of people whom he labelled as genuinely worthy figures, not those that expressed \"blind worship\".\nIn 1962, Mao proposed the Socialist Education Movement (SEM) in an attempt to educate the peasants to resist the \"temptations\" of feudalism and the sprouts of capitalism that he saw re-emerging in the countryside from Liu's economic reforms. Large quantities of politicised art were produced and circulated\u2014with Mao at the centre. Numerous posters, badges, and musical compositions referenced Mao in the phrase \"Chairman Mao is the red sun in our hearts\" () and a \"Savior of the people\" ().\nIn October 1966, Mao's \"Quotations from Chairman Mao Tse-tung\", known as the \"Little Red Book\", was published. Party members were encouraged to carry a copy with them, and possession was almost mandatory as a criterion for membership. Over the years, Mao's image became displayed almost everywhere, present in homes, offices and shops. His quotations were typographically emphasised by putting them in boldface or red type in even the most obscure writings. Music from the period emphasised Mao's stature, as did children's rhymes. The phrase \"Long Live Chairman Mao for ten thousand years\" was commonly heard during the era.\nMao also has a presence in China and around the world in popular culture, where his face adorns everything from T-shirts to coffee cups. Mao's granddaughter, Kong Dongmei, defended the phenomenon, stating that \"it shows his influence, that he exists in people's consciousness and has influenced several generations of Chinese people's way of life. Just like Che Guevara's image, his has become a symbol of revolutionary culture.\" Since 1950, over 40 million people have visited Mao's birthplace in Shaoshan, Hunan.\nA 2016 survey by YouGov survey found that 42% of American millennials have never heard of Mao. According to the CIS poll, in 2019 only 21% of Australian millennials were familiar with Mao Zedong. In 2020s China, members of Generation Z are embracing Mao's revolutionary ideas, including violence against the capitalist class, amid rising social inequality, long working hours, and decreasing economic opportunities. As of the early 2020s, surveys conducted on Zhihu frequently rank Mao as one of the greatest and most influential figures in Chinese history.58\nPersonal life and family.\nHaving grown up in Hunan, Mao spoke Mandarin with a marked Hunanese accent. Ross Terrill wrote Mao was a \"son of the soil ... rural and unsophisticated\" in origins, while Clare Hollingworth said that Mao was proud of his \"peasant ways and manners\", having a strong Hunanese accent and providing \"earthy\" comments on sexual matters. Lee Feigon said that Mao's \"earthiness\" meant that he remained connected to \"everyday Chinese life.\"\nSinologist Stuart R. Schram emphasised Mao's ruthlessness but also noted that he showed no sign of taking pleasure in torture or killing in the revolutionary cause. Lee Feigon considered Mao \"draconian and authoritarian\" when threatened but opined that he was not the \"kind of villain that his mentor Stalin was\". Alexander Pantsov and Steven I. Levine wrote that Mao was a \"man of complex moods\", who \"tried his best to bring about prosperity and gain international respect\" for China, being \"neither a saint nor a demon.\" They noted that in early life, he strove to be \"a strong, wilful, and purposeful hero, not bound by any moral chains\", and that he \"passionately desired fame and power\".\nMao learned to speak some English, particularly through Zhang Hanzhi, his English teacher, interpreter and diplomat who later married Qiao Guanhua, Minister of Foreign Affairs and the head of China's UN delegation. His spoken English was limited to a few single words, phrases, and some short sentences. He first chose to systematically learn English in the 1950s, which was very unusual as the main foreign language first taught in Chinese schools at that time was Russian.\nFamily.\nMao had four wives who gave birth to a total of 10 children: Luo Yixiu (1889\u20131910) of Shaoshan, married 1907 to 1910; Yang Kaihui (1901\u20131930) of Changsha, married 1920 to 1927, executed by the KMT in 1930, mother to Mao Anying, Mao Anqing, and Mao Anlong; He Zizhen (1910\u20131984) of Jiangxi, married May 1928 to 1937, mother to 6 children; Jiang Qing (1914\u20131991), married 1939 until Mao's death, mother to Li Na. Mao four siblings: Mao Zemin, Mao Zetan and Mao Zejian. Mao Zemin's son Mao Yuanxin was raised by Mao Zedong's family, and he became Mao Zedong's liaison with the Politburo in 1975.\nMao had a total of ten children, including: Mao Anying (killed in action during the Korean War), Mao Anqing, Mao Anlong (died during the Chinese Civil War), Mao Anhong (left to Mao's younger brother Zetan and then to one of Zetan's guards when he went off to war, was never heard of again), Li Min, and Li Na. Through his ten children, Mao became grandfather to twelve grandchildren, many of whom he never knew. He has many great-grandchildren alive today. One of his granddaughters is businesswoman Kong Dongmei, one of the richest people in China. His grandson Mao Xinyu is a general in the Chinese army.\nWritings and calligraphy.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\n&lt;poem&gt;&lt;/poem&gt;\n&lt;poem&gt;Eagles cleave the air,\nFish glide in the limpid deep;\nUnder freezing skies a million creatures contend in freedom.\nBrooding over this immensity,\nI ask, on this boundless land\nWho rules over man's destiny?&lt;/poem&gt;\n\u2014Excerpt from Mao's poem \"Changsha\", September 1927\nMao was a prolific writer of political and philosophical literature. The main repository of his pre-1949 writings is the Selected Works of Mao Zedong. A fifth volume, which brought the timeline up to 1957, was briefly issued, but subsequently withdrawn from circulation for its perceived ideological errors. There has never been an official \"Complete Works of Mao Zedong\". Mao is the attributed author of \"Quotations from Chairman Mao Tse-tung\", known in the West as the \"Little Red Book\" and in Cultural Revolution China as the \"Red Treasure Book\" (). First published in January 1964, this is a collection of short extracts from his many speeches and articles (most found in the Selected Works), edited by Lin Biao, and ordered topically. \"The Little Red Book\" contains some of Mao's most widely known quotes.\nMao wrote prolifically on political strategy, commentary, and philosophy both before and after he assumed power. Mao was also a skilled Chinese calligrapher with a highly personal style. His calligraphy can be seen today throughout mainland China. His work gave rise to a new form of Chinese calligraphy called \"Mao-style\" or \"Maoti\", which has gained increasing popularity since his death. There exist various competitions specialising in Mao-style calligraphy.\nLiterary works.\nMao's education began with Chinese classical literature. Mao told Edgar Snow in 1936 that he had started the study of the Confucian Analects and the Four Books at a village school when he was eight, but that the books he most enjoyed reading were \"Water Margin\", \"Journey to the West\", the \"Romance of the Three Kingdoms\" and \"Dream of the Red Chamber\". Mao published poems in classical forms starting in his youth and his abilities as a poet contributed to his image in China after he came to power in 1949. His style was influenced by the great Tang dynasty poets Li Bai and Li He.\nSome of his best known poems are \"Changsha\" (1925), \"The Double Ninth\" (October 1929), \"Loushan Pass\" (1935), \"The Long March\" (1935), \"Snow\" (February 1936), \"The PLA Captures Nanjing\" (1949), \"Reply to Li Shuyi\" (11 May 1957), and \"Ode to the Plum Blossom\" (December 1961).\nPortrayal in media.\nMao has been portrayed in film and television numerous times. Some notable actors include: Han Shi, the first actor ever to have portrayed Mao, in a 1978 drama \"Dielianhua\" and later again in a 1980 film \"Cross the Dadu River\"; Gu Yue, who had portrayed Mao 84 times on screen throughout his 27-year career and had won the Best Actor title at the Hundred Flowers Awards in 1990 and 1993; Liu Ye, who played a young Mao in \"The Founding of a Party\" (2011); Tang Guoqiang, who has frequently portrayed Mao in more recent times, in the films \"The Long March\" (1996) and \"The Founding of a Republic\" (2009), and the television series \"Huang Yanpei\" (2010), among others. Mao is a principal character in American composer John Adams' opera \"Nixon in China\" (1987). The Beatles' song \"Revolution\" refers to Mao in the verse \"but if you go carrying pictures of Chairman Mao you ain't going to make it with anyone anyhow...\"; John Lennon expressed regret over including these lines in the song in 1972.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nBibliography.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "19528", "revid": "20468248", "url": "https://en.wikipedia.org/wiki?curid=19528", "title": "Mechanical engineering", "text": "Engineering discipline\nMechanical engineering is the study of physical machines and mechanisms that may involve force and movement. It is an engineering branch that combines engineering physics and mathematics principles with materials science, to design, analyze, manufacture, and maintain mechanical systems. It is one of the oldest and broadest of the engineering branches.\nMechanical engineering requires an understanding of core areas including mechanics, dynamics, thermodynamics, materials science, design, structural analysis, and electricity. In addition to these core principles, mechanical engineers use tools such as computer-aided design (CAD), computer-aided manufacturing (CAM), computer-aided engineering (CAE), and product lifecycle management to design and analyze manufacturing plants, industrial equipment and machinery, heating and cooling systems, transport systems, motor vehicles, aircraft, watercraft, robotics, medical devices, weapons, and others.\nMechanical engineering emerged as a field during the Industrial Revolution in Europe in the 18th century; however, its development can be traced back several thousand years around the world. In the 19th century, developments in physics led to the development of mechanical engineering science. The field has continually evolved to incorporate advancements; today mechanical engineers are pursuing developments in such areas as composites, mechatronics, and nanotechnology. It also overlaps with aerospace engineering, metallurgical engineering, civil engineering, structural engineering, electrical engineering, manufacturing engineering, chemical engineering, industrial engineering, and other engineering disciplines to varying amounts. Mechanical engineers may also work in the field of biomedical engineering, specifically with biomechanics, transport phenomena, biomechatronics, bionanotechnology, and modelling of biological systems.\nHistory.\nThe application of mechanical engineering can be seen in the archives of various ancient and medieval societies. The six classic simple machines were known in the ancient Near East. The wedge and the inclined plane (ramp) were known since prehistoric times. Mesopotamian civilization is credited with the invention of the wheel by several, mainly old sources. However, some recent sources either suggest that it was invented independently in both Mesopotamia and Eastern Europe or credit prehistoric Eastern Europeans with the invention of the wheel The lever mechanism first appeared around 5,000 years ago in the Near East, where it was used in a simple balance scale, and to move large objects in ancient Egyptian technology. The lever was also used in the shadoof water-lifting device, the first crane machine, which appeared in Mesopotamia circa 3000 BC. The earliest evidence of pulleys date back to Mesopotamia in the early 2nd millennium BC.\nThe Saqiyah was developed in the Kingdom of Kush during the 4th century BC. It relied on animal power reducing the tow on the requirement of human energy. Reservoirs in the form of Hafirs were developed in Kush to store water and boost irrigation. Bloomeries and blast furnaces were developed during the seventh century BC in Meroe. Kushite sundials applied mathematics in the form of advanced trigonometry.\nThe earliest practical water-powered machines, the water wheel and watermill, first appeared in the Persian Empire, in what are now Iraq and Iran, by the early 4th century BC. In ancient Greece, the works of Archimedes (287\u2013212 BC) influenced mechanics in the Western tradition. The geared Antikythera mechanisms was an Analog computer invented around the 2nd century BC.\nIn Roman Egypt, Heron of Alexandria (c. 10\u201370 AD) created the first steam-powered device (Aeolipile). In China, Zhang Heng (78\u2013139 AD) improved a water clock and invented a seismometer, and Ma Jun (200\u2013265 AD) invented a chariot with differential gears. The medieval Chinese horologist and engineer Su Song (1020\u20131101 AD) incorporated an escapement mechanism into his astronomical clock tower two centuries before escapement devices were found in medieval European clocks. He also invented the world's first known endless power-transmitting chain drive.\nThe cotton gin was invented in India by the 6th century AD, and the spinning wheel was invented in the Islamic world by the early 11th century, Dual-roller gins appeared in India and China between the 12th and 14th centuries. The worm gear roller gin appeared in the Indian subcontinent during the early Delhi Sultanate era of the 13th to 14th centuries.\nDuring the Islamic Golden Age (7th to 15th century), Muslim inventors made remarkable contributions in the field of mechanical technology. Al-Jazari, who was one of them, wrote his famous \"Book of Knowledge of Ingenious Mechanical Devices\" in 1206 and presented many mechanical designs.\nIn the 17th century, important breakthroughs in the foundations of mechanical engineering occurred in England and the Continent. The Dutch mathematician and physicist Christiaan Huygens invented the pendulum clock in 1657, which was the first reliable timekeeper for almost 300 years, and published a work dedicated to clock designs and the theory behind them. In England, Isaac Newton formulated his laws of motion and developed calculus, which would become the mathematical basis of physics. Newton was reluctant to publish his works for years, but he was finally persuaded to do so by his colleagues, such as Edmond Halley. Gottfried Wilhelm Leibniz, who earlier designed a mechanical calculator, is also credited with developing the calculus during the same time period.\nDuring the early 19th century Industrial Revolution, machine tools were developed in England, Germany, and Scotland. This allowed mechanical engineering to develop as a separate field within engineering. They brought with them manufacturing machines and the engines to power them. The first British professional society of mechanical engineers was formed in 1847 Institution of Mechanical Engineers, thirty years after the civil engineers formed the first such professional society Institution of Civil Engineers. On the European continent, Johann von Zimmermann (1820\u20131901) founded the first factory for grinding machines in Chemnitz, Germany in 1848.\nIn the United States, the American Society of Mechanical Engineers (ASME) was formed in 1880, becoming the third such professional engineering society, after the American Society of Civil Engineers (1852) and the American Institute of Mining Engineers (1871). The first schools in the United States to offer an engineering education were the United States Military Academy in 1817, an institution now known as Norwich University in 1819, and Rensselaer Polytechnic Institute in 1825. Education in mechanical engineering has historically been based on a strong foundation in mathematics and science.\nEducation.\nDegrees in mechanical engineering are offered at various universities worldwide. Mechanical engineering programs typically take four to five years of study depending on the place and university and result in a Bachelor of Engineering (B.Eng. or B.E.), Bachelor of Science (B.Sc. or B.S.), Bachelor of Science Engineering (B.Sc.Eng.), Bachelor of Technology (B.Tech.), Bachelor of Mechanical Engineering (B.M.E.), or Bachelor of Applied Science (B.A.Sc.) degree, in or with emphasis in mechanical engineering. In Spain, Portugal and most of South America, where neither B.S. nor B.Tech. programs have been adopted, the formal name for the degree is \"Mechanical Engineer\", and the course work is based on five or six years of training. In Italy the course work is based on five years of education, and training, but in order to qualify as an Engineer one has to pass a state exam at the end of the course. In Greece, the coursework is based on a five-year curriculum.\nIn the United States, most undergraduate mechanical engineering programs are accredited by the Accreditation Board for Engineering and Technology (ABET) to ensure similar course requirements and standards among universities. The ABET web site lists 302 accredited mechanical engineering programs as of 11 March 2014. Mechanical engineering programs in Canada are accredited by the Canadian Engineering Accreditation Board (CEAB), and most other countries offering engineering degrees have similar accreditation societies.\nIn Australia, mechanical engineering degrees are awarded as Bachelor of Engineering (Mechanical) or similar nomenclature, although there are an increasing number of specialisations. The degree takes four years of full-time study to achieve. To ensure quality in engineering degrees, Engineers Australia accredits engineering degrees awarded by Australian universities in accordance with the global Washington Accord. Before the degree can be awarded, the student must complete at least 3 months of on the job work experience in an engineering firm. Similar systems are also present in South Africa and are overseen by the Engineering Council of South Africa (ECSA).\nIn India, to become an engineer, one needs to have an engineering degree like a B.Tech. or B.E., have a diploma in engineering, or by completing a course in an engineering trade like fitter from the Industrial Training Institute (ITIs) to receive a \"ITI Trade Certificate\" and also pass the All India Trade Test (AITT) with an engineering trade conducted by the National Council of Vocational Training (NCVT) by which one is awarded a \"National Trade Certificate\". A similar system is used in Nepal.\nSome mechanical engineers go on to pursue a postgraduate degree such as a Master of Engineering, Master of Technology, Master of Science, Master of Engineering Management (M.Eng.Mgt. or M.E.M.), a Doctor of Philosophy in engineering (Eng.D. or Ph.D.) or an engineer's degree. The master's and engineer's degrees may or may not include research. The Doctor of Philosophy includes a significant research component and is often viewed as the entry point to academia. The Engineer's degree exists at a few institutions at an intermediate level between the master's degree and the doctorate.\nCoursework.\nStandards set by each country's accreditation society are intended to provide uniformity in fundamental subject material, promote competence among graduating engineers, and to maintain confidence in the engineering profession as a whole. Engineering programs in the U.S., for example, are required by ABET to show that their students can \"work professionally in both thermal and mechanical systems areas.\" The specific courses required to graduate, however, may differ from program to program. Universities and institutes of technology will often combine multiple subjects into a single class or split a subject into multiple classes, depending on the faculty available and the university's major area(s) of research.\nThe fundamental subjects required for mechanical engineering usually include:\nMechanical engineers are also expected to understand and be able to apply basic concepts from chemistry, physics, tribology, chemical engineering, civil engineering, and electrical engineering. All mechanical engineering programs include multiple semesters of mathematical classes including calculus, and advanced mathematical concepts including differential equations, partial differential equations, linear algebra, differential geometry, and statistics, among others.\nIn addition to the core mechanical engineering curriculum, many mechanical engineering programs offer more specialized programs and classes, such as control systems, robotics, transport and logistics, cryogenics, fuel technology, automotive engineering, biomechanics, vibration, optics and others, if a separate department does not exist for these subjects.\nMost mechanical engineering programs also require varying amounts of research or community projects to gain practical problem-solving experience. In the United States it is common for mechanical engineering students to complete one or more internships while studying, though this is not typically mandated by the university. Cooperative education is another option. Research puts demand on study components that feed student's creativity and innovation.\nJob duties.\nMechanical engineers research, design, develop, build, and test mechanical and thermal devices, including tools, engines, and machines.\nMechanical engineers typically do the following:\nMechanical engineers design and oversee the manufacturing of many products ranging from medical devices to new batteries. They also design power-producing machines such as electric generators, internal combustion engines, and steam and gas turbines as well as power-using machines, such as refrigeration and air-conditioning systems.\nLike other engineers, mechanical engineers use computers to help create and analyze designs, run simulations and test how a machine is likely to work.\nLicense and regulation.\nEngineers may seek license by a state, provincial, or national government. The purpose of this process is to ensure that engineers possess the necessary technical knowledge, real-world experience, and knowledge of the local legal system to practice engineering at a professional level. Once certified, the engineer is given the title of Professional Engineer United States, Canada, Japan, South Korea, Bangladesh and South Africa), Chartered Engineer (in the United Kingdom, Ireland, India and Zimbabwe), \"Chartered Professional Engineer\" (in Australia and New Zealand) or \"European Engineer\" (much of the European Union).\nIn the U.S., to become a licensed Professional Engineer (PE), an engineer must pass the comprehensive FE (Fundamentals of Engineering) exam, work a minimum of 4 years as an \"Engineering Intern (EI)\" or \"Engineer-in-Training (EIT)\", and pass the \"Principles and Practice\" or PE (Practicing Engineer or Professional Engineer) exams. The requirements and steps of this process are set forth by the National Council of Examiners for Engineering and Surveying (NCEES), composed of engineering and land surveying licensing boards representing all U.S. states and territories.\nIn Australia (Queensland and Victoria) an engineer must be registered as a Professional Engineer within the State in which they practice, for example Registered Professional Engineer of Queensland or Victoria, RPEQ or RPEV. respectively.\nIn the UK, current graduates require a BEng plus an appropriate master's degree or an integrated MEng degree, a minimum of 4 years post graduate on the job competency development and a peer-reviewed project report to become a Chartered Mechanical Engineer (CEng, MIMechE) through the Institution of Mechanical Engineers. CEng MIMechE can also be obtained via an examination route administered by the City and Guilds of London Institute.\nIn most developed countries, certain engineering tasks, such as the design of bridges, electric power plants, and chemical plants, must be approved by a professional engineer or a chartered engineer. \"Only a licensed engineer, for instance, may prepare, sign, seal and submit engineering plans and drawings to a public authority for approval, or to seal engineering work for public and private clients.\" This requirement can be written into state and provincial legislation, such as in the Canadian provinces, for example the Ontario or Quebec's Engineer Act.\nIn other countries, such as the UK, no such legislation exists; however, practically all certifying bodies maintain a code of ethics independent of legislation, that they expect all members to abide by or risk expulsion.\nSalaries and workforce statistics.\nThe total number of engineers employed in the U.S. in 2015 was roughly 1.6 million. Of these, 278,340 were mechanical engineers (17.28%), the largest discipline by size. In 2012, the median annual income of mechanical engineers in the U.S. workforce was $80,580. The median income was highest when working for the government ($92,030), and lowest in education ($57,090). In 2014, the total number of mechanical engineering jobs was projected to grow 5% over the next decade. As of 2009, the average starting salary was $58,800 with a bachelor's degree.\nSubdisciplines.\nThe field of mechanical engineering can be thought of as a collection of many mechanical engineering science disciplines. Several of these subdisciplines which are typically taught at the undergraduate level are listed below, with a brief explanation and the most common application of each. Some of these subdisciplines are unique to mechanical engineering, while others are a combination of mechanical engineering and one or more other disciplines. Most work that a mechanical engineer does uses skills and techniques from several of these subdisciplines, as well as specialized subdisciplines. Specialized subdisciplines, as used in this article, are more likely to be the subject of graduate studies or on-the-job training than undergraduate research. Several specialized subdisciplines are discussed in this section.\nMechanics.\nMechanics is, in the most general sense, the study of forces and their effect upon matter. Typically, engineering mechanics is used to analyze and predict the acceleration and deformation (both elastic and plastic) of objects under known forces (also called loads) or stresses. Subdisciplines of mechanics include\nMechanical engineers typically use mechanics in the design or analysis phases of engineering. If the engineering project were the design of a vehicle, statics might be employed to design the frame of the vehicle, in order to evaluate where the stresses will be most intense. Dynamics might be used when designing the car's engine, to evaluate the forces in the pistons and cams as the engine cycles. Mechanics of materials might be used to choose appropriate materials for the frame and engine. Fluid mechanics might be used to design a ventilation system for the vehicle (see HVAC), or to design the intake system for the engine.\nMechatronics and robotics.\nMechatronics is a combination of mechanics and electronics. It is an interdisciplinary branch of mechanical engineering, electrical engineering and software engineering that is concerned with integrating electrical and mechanical engineering to create hybrid automation systems. In this way, machines can be automated through the use of electric motors, servo-mechanisms, and other electrical systems in conjunction with special software. A common example of a mechatronics system is a CD-ROM drive. Mechanical systems open and close the drive, spin the CD and move the laser, while an optical system reads the data on the CD and converts it to bits. Integrated software controls the process and communicates the contents of the CD to the computer.\nRobotics is the application of mechatronics to create robots, which are often used in industry to perform tasks that are dangerous, unpleasant, or repetitive. These robots may be of any shape and size, but all are preprogrammed and interact physically with the world. To create a robot, an engineer typically employs kinematics (to determine the robot's range of motion) and mechanics (to determine the stresses within the robot).\nRobots are used extensively in industrial automation engineering. They allow businesses to save money on labor, perform tasks that are either too dangerous or too precise for humans to perform them economically, and to ensure better quality. Many companies employ assembly lines of robots, especially in Automotive Industries and some factories are so robotized that they can run by themselves. Outside the factory, robots have been employed in bomb disposal, space exploration, and many other fields. Robots are also sold for various residential applications, from recreation to domestic applications.\nStructural analysis.\nStructural analysis is the branch of mechanical engineering (and also civil engineering) devoted to examining why and how objects fail and to fix the objects and their performance. Structural failures occur in two general modes: static failure, and fatigue failure. \"Static structural failure\" occurs when, upon being loaded (having a force applied) the object being analyzed either breaks or is deformed plastically, depending on the criterion for failure. \"Fatigue failure\" occurs when an object fails after a number of repeated loading and unloading cycles. Fatigue failure occurs because of imperfections in the object: a microscopic crack on the surface of the object, for instance, will grow slightly with each cycle (propagation) until the crack is large enough to cause ultimate failure.\nFailure is not simply defined as when a part breaks, however; it is defined as when a part does not operate as intended. Some systems, such as the perforated top sections of some plastic bags, are designed to break. If these systems do not break, failure analysis might be employed to determine the cause.\nStructural analysis is often used by mechanical engineers after a failure has occurred, or when designing to prevent failure. Engineers often use online documents and books such as those published by ASM to aid them in determining the type of failure and possible causes.\nOnce theory is applied to a mechanical design, physical testing is often performed to verify calculated results. Structural analysis may be used in an office when designing parts, in the field to analyze failed parts, or in laboratories where parts might undergo controlled failure tests.\nThermodynamics and thermo-science.\nThermodynamics is an applied science used in several branches of engineering, including mechanical and chemical engineering. At its simplest, thermodynamics is the study of energy, its use and transformation through a system. Typically, engineering thermodynamics is concerned with changing energy from one form to another. As an example, automotive engines convert chemical energy (enthalpy) from the fuel into heat, and then into mechanical work that eventually turns the wheels.\nThermodynamics principles are used by mechanical engineers in the fields of heat transfer, thermofluids, and energy conversion. Mechanical engineers use thermo-science to design engines and power plants, heating, ventilation, and air-conditioning (HVAC) systems, heat exchangers, heat sinks, radiators, refrigeration, insulation, and others.\nDesign and drafting.\nDrafting or technical drawing is the means by which mechanical engineers design products and create instructions for manufacturing parts. A technical drawing can be a computer model or hand-drawn schematic showing all the dimensions necessary to manufacture a part, as well as assembly notes, a list of required materials, and other pertinent information. A U.S. mechanical engineer or skilled worker who creates technical drawings may be referred to as a drafter or draftsman. Drafting has historically been a two-dimensional process, but computer-aided design (CAD) programs now allow the designer to create in three dimensions.\nInstructions for manufacturing a part must be fed to the necessary machinery, either manually, through programmed instructions, or through the use of a computer-aided manufacturing (CAM) or combined CAD/CAM program. Optionally, an engineer may also manually manufacture a part using the technical drawings. However, with the advent of computer numerically controlled (CNC) manufacturing, parts can now be fabricated without the need for constant technician input. Manually manufactured parts generally consist of spray coatings, surface finishes, and other processes that cannot economically or practically be done by a machine.\nDrafting is used in nearly every subdiscipline of mechanical engineering, and by many other branches of engineering and architecture. Three-dimensional models created using CAD software are also commonly used in finite element analysis (FEA) and computational fluid dynamics (CFD).\nModern tools.\nComputer aided software suites.\nMany mechanical engineering companies, especially those in industrialized nations, have incorporated computer-aided engineering (CAE) programs into their existing design and analysis processes, including 2D and 3D solid modeling computer-aided design (CAD). This method has many benefits, including easier and more exhaustive visualization of products, the ability to create virtual assemblies of parts, and the ease of use in designing mating interfaces and tolerances.\nOther CAE programs commonly used by mechanical engineers include product lifecycle management (PLM) tools and analysis tools used to perform complex simulations. Analysis tools may be used to predict product response to expected loads, including fatigue life and manufacturability. These tools include finite element analysis (FEA), computational fluid dynamics (CFD), and computer-aided manufacturing (CAM).\nUsing CAE programs, a mechanical design team can quickly and cheaply iterate the design process to develop a product that better meets cost, performance, and other constraints. No physical prototype need be created until the design nears completion, allowing hundreds or thousands of designs to be evaluated, instead of a relative few. In addition, CAE analysis programs can model complicated physical phenomena which cannot be solved by hand, such as viscoelasticity, complex contact between mating parts, or non-Newtonian flows.\nAs mechanical engineering begins to merge with other disciplines, as seen in mechatronics, multidisciplinary design optimization (MDO) is being used with other CAE programs to automate and improve the iterative design process. MDO tools wrap around existing CAE processes, allowing product evaluation to continue even after the analyst goes home for the day. They also use sophisticated optimization algorithms to more intelligently explore possible designs, often finding better, innovative solutions to difficult multidisciplinary design problems.\nOn\u2011demand platforms for external FEA expertise.\nEngineering teams can access external finite\u2011element analysis (FEA) expertise through on\u2011demand platforms. By submitting structured project inputs\u2014such as CAD or FEA input files, load cases, boundary conditions and desired deliverables - users receive instant quotes and connect with pre\u2011qualified simulation engineers. Providers manage the entire workflow remotely, often running simulations on cloud and GPU\u2011based infrastructure to accelerate turnaround, which can be significantly faster than in\u2011house CPU\u2011based systems. This model offers scalability, access to niche simulation domains like CFD or multiphysics, and avoids the delays, licensing burden and overhead of traditional procurement cycles. It is particularly valuable for smaller teams operating under tight deadlines or limited in\u2011house capacity.\nAreas of research.\nMechanical engineers are constantly pushing the boundaries of what is physically possible in order to produce safer, cheaper, and more efficient machines and mechanical systems. Some technologies at the cutting edge of mechanical engineering are listed below (see also exploratory engineering).\nMicro electro-mechanical systems (MEMS).\nMicron-scale mechanical components such as springs, gears, fluidic and heat transfer devices are fabricated from a variety of substrate materials such as silicon, glass and polymers like SU8. Examples of MEMS components are the accelerometers that are used as car airbag sensors, modern cell phones, gyroscopes for precise positioning and microfluidic devices used in biomedical applications.\nFriction stir welding (FSW).\nFriction stir welding, a new type of welding, was discovered in 1991 by The Welding Institute (TWI). The innovative steady state (non-fusion) welding technique joins materials previously un-weldable, including several aluminum alloys. It plays an important role in the future construction of airplanes, potentially replacing rivets. Current uses of this technology to date include welding the seams of the aluminum main Space Shuttle external tank, Orion Crew Vehicle, Boeing Delta II and Delta IV Expendable Launch Vehicles and the SpaceX Falcon 1 rocket, armor plating for amphibious assault ships, and welding the wings and fuselage panels of the new Eclipse 500 aircraft from Eclipse Aviation among an increasingly growing pool of uses.\nComposites.\nComposites or composite materials are a combination of materials which provide different physical characteristics than either material separately. Composite material research within mechanical engineering typically focuses on designing (and, subsequently, finding applications for) stronger or more rigid materials while attempting to reduce weight, susceptibility to corrosion, and other undesirable factors. Carbon fiber reinforced composites, for instance, have been used in such diverse applications as spacecraft and fishing rods.\nMechatronics.\nMechatronics is the synergistic combination of mechanical engineering, electronic engineering, and software engineering. The discipline of mechatronics began as a way to combine mechanical principles with electrical engineering. Mechatronic concepts are used in the majority of electro-mechanical systems. Typical electro-mechanical sensors used in mechatronics are strain gauges, thermocouples, and pressure transducers.\nNanotechnology.\nAt the smallest scales, mechanical engineering becomes nanotechnology\u2014one speculative goal of which is to create a molecular assembler to build molecules and materials via mechanosynthesis. For now that goal remains within exploratory engineering. Areas of current mechanical engineering research in nanotechnology include nanofilters, nanofilms, and nanostructures, among others.\nFinite element analysis.\nFinite Element Analysis is a computational tool used to estimate stress, strain, and deflection of solid bodies. It uses a mesh setup with user-defined sizes to measure physical quantities at a node. The more nodes there are, the higher the precision. This field is not new, as the basis of Finite Element Analysis (FEA) or Finite Element Method (FEM) dates back to 1941. But the evolution of computers has made FEA/FEM a viable option for analysis of structural problems. Many commercial software applications such as NASTRAN, ANSYS, and ABAQUS are widely used in industry for research and the design of components. Some 3D modeling and CAD software packages have added FEA modules. In the recent times, cloud simulation platforms like SimScale are becoming more common.\nOther techniques such as finite difference method (FDM) and finite-volume method (FVM) are employed to solve problems relating heat and mass transfer, fluid flows, fluid surface interaction, etc.\nBiomechanics.\nBiomechanics is the application of mechanical principles to biological systems, such as humans, animals, plants, organs, and cells. Biomechanics also aids in creating prosthetic limbs and artificial organs for humans. Biomechanics is closely related to engineering, because it often uses traditional engineering sciences to analyze biological systems. Some simple applications of Newtonian mechanics and/or materials sciences can supply correct approximations to the mechanics of many biological systems.\nIn the past decade, reverse engineering of materials found in nature such as bone matter has gained funding in academia. The structure of bone matter is optimized for its purpose of bearing a large amount of compressive stress per unit weight. The goal is to replace crude steel with bio-material for structural design.\nOver the past decade the Finite element method (FEM) has also entered the Biomedical sector highlighting further engineering aspects of Biomechanics. FEM has since then established itself as an alternative to in vivo surgical assessment and gained the wide acceptance of academia. The main advantage of Computational Biomechanics lies in its ability to determine the endo-anatomical response of an anatomy, without being subject to ethical restrictions. This has led FE modelling to the point of becoming ubiquitous in several fields of Biomechanics while several projects have even adopted an open source philosophy (e.g. BioSpine).\nComputational fluid dynamics.\nComputational fluid dynamics, usually abbreviated as CFD, is a branch of fluid mechanics that uses numerical methods and algorithms to solve and analyze problems that involve fluid flows. Computers are used to perform the calculations required to simulate the interaction of liquids and gases with surfaces defined by boundary conditions. With high-speed supercomputers, better solutions can be achieved. Ongoing research yields software that improves the accuracy and speed of complex simulation scenarios such as turbulent flows. Initial validation of such software is performed using a wind tunnel with the final validation coming in full-scale testing, e.g. flight tests.\nAcoustical engineering.\nAcoustical engineering is one of many other sub-disciplines of mechanical engineering and is the application of acoustics. Acoustical engineering is the study of Sound and Vibration. These engineers work effectively to reduce noise pollution in mechanical devices and in buildings by soundproofing or removing sources of unwanted noise. The study of acoustics can range from designing a more efficient hearing aid, microphone, headphone, or recording studio to enhancing the sound quality of an orchestra hall. Acoustical engineering also deals with the vibration of different mechanical systems.\nRelated fields.\nManufacturing engineering, aerospace engineering, automotive engineering and marine engineering are grouped with mechanical engineering at times. A bachelor's degree in these areas will typically have a difference of a few specialized classes.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "19529", "revid": "158856", "url": "https://en.wikipedia.org/wiki?curid=19529", "title": "Minister", "text": "Minister may refer to:\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "19530", "revid": "27823944", "url": "https://en.wikipedia.org/wiki?curid=19530", "title": "March 11", "text": "&lt;templatestyles src=\"This date in recent years/styles.css\"/&gt;\nDay of the yearMarch 11 is the day of the year in the Gregorian calendar\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "19531", "revid": "12931457", "url": "https://en.wikipedia.org/wiki?curid=19531", "title": "Monkey Island", "text": "Monkey Island is a series of adventure games. The first four games were produced and published by LucasArts, earlier known as Lucasfilm Games. The fifth was developed by Telltale Games with LucasArts, while the sixth was developed by Terrible Toybox with Lucasfilm Games and Devolver Digital.\nThe games follow the adventures of the hapless Guybrush Threepwood as he struggles to become the most notorious pirate in the Caribbean, defeat the plans of the evil undead pirate LeChuck and win the heart of Governor Elaine Marley. The plots often involve the mysterious Monkey Island and its secrets.\n\"Monkey Island\" was created by Ron Gilbert. Gilbert worked on the first two games before leaving LucasArts. Dave Grossman and Tim Schafer, co-writers of the first two games, had success on other games before they both left LucasArts. The rights to \"Monkey Island\" remained with LucasArts, and the third and fourth games were created without direct involvement from the original writing staff. Grossman was a creative director on the fifth game in the series, which Gilbert was a consultant on the early stages of. Gilbert returned to the series with the sixth game, \"Return to Monkey Island\" (2022), which he co-wrote and co-designed with Grossman.\nBackground.\nRon Gilbert's two main inspirations for the story were Disneyland's Pirates of the Caribbean ride and Tim Powers' book \"On Stranger Tides\". The book was the inspiration for the story and characters, while the ride was the inspiration for the ambiance. Gilbert said in an interview that:\n\"[the POTC Ride] keeps you moving through the adventure but I've always wished I could get off and wander around, learn more about the characters, and find a way onto those pirate ships. So with \"The Secret of Monkey Island\" I wanted to create a game that had the same flavor, but where you could step off the boat and enter that whole storybook world\u201d.\nMedia.\nGames.\n\"The Secret of Monkey Island\".\nThe series debuted in 1990 with \"The Secret of Monkey Island\" on the Amiga, MS-DOS, Atari ST and Macintosh platforms; the game was later ported to FM Towns and Mega-CD (1993). A remake version with updated graphics and new voiceovers was released for PlayStation Network, PC Windows, Xbox Live Arcade and OS X. An iPhone version was also released on July 23, 2009.\nThe game starts off with the main character Guybrush Threepwood stating \"I want to be a pirate!\" To do so, he must prove himself to three old pirate captains. During the perilous pirate trials, he meets the beautiful governor Elaine Marley, with whom he falls in love, unaware that the ghost pirate LeChuck also has his eyes on her. When Elaine is kidnapped, Guybrush procures crew and ship to track LeChuck down, defeat him and rescue his love.\n\"Monkey Island 2: LeChuck's Revenge\".\nThe second game, \"Monkey Island 2: LeChuck's Revenge\" from 1991, was available for fewer platforms; it was only released for PC MS-DOS, Amiga, Macintosh, and later for FM Towns. A Special Edition version, in a similar style as \"The Secret of Monkey Island: Special Edition\", was released in July 2010 for iPhone, iPad, iPod Touch, Mac, PC, PS3 and Xbox 360.\nAs Guybrush, with a treasure chest in hand, and Elaine hang onto ropes in a void, he tells her the story of the game. He has decided to find the greatest of all treasures, that of Big Whoop. Unwittingly he helps revive LeChuck, who is now in zombie form. Guybrush is eventually captured by his nemesis, but escapes with help from Wally and finds the treasure only to find himself dangling from a rope, as depicted at the beginning of the game. As Guybrush concludes his story, his rope breaks and he finds himself facing LeChuck, whom he finally defeats using voodoo. The surrealistic ending is open to a number of interpretations. In the manual of \"The Curse of Monkey Island\", it is stated that Guybrush falls victim to a hex implemented by LeChuck.\n\"The Curse of Monkey Island\".\n\"The Curse of Monkey Island\", the third in the series, was released exclusively for Microsoft Windows on PC in 1997, after a 6-year hiatus. \"The Curse of Monkey Island\" was released at the height of some of the biggest technological advancements in the gaming industry\u2014digital audio, CD-ROM technology, and improved graphics.\n\"Monkey Island I\" and \"II\" were originally released on floppy disks with text dialogue only. Entire conversations between characters would appear as written text, or as captions above their heads.\nThe visuals of the third installment were also an improvement over the original game, using a more modern cel animation style. \"The Curse of Monkey Island\" is the only game in the series to feature this style of animation; subsequent games used three-dimensional polygon animation.\nThreepwood, unwittingly, turns Elaine into a gold statue with a cursed ring, and she is subsequently stolen by pirates. He tracks her down before searching for another ring that can lift the curse. LeChuck appears in a fiery demon form, and is hot on Threepwood\u2019s heels until a stand-off on LeChuck's amusement park ride, Monkey Mountain.\n\"Escape from Monkey Island\".\n\"Escape from Monkey Island\", the fourth installment, was released in 2000 for PC Windows, and in 2001 for Macintosh and PlayStation 2.\nWhen Guybrush Threepwood and Elaine Marley return from their honeymoon, they find that Elaine has been declared officially dead, her mansion is under a destruction order, and her position as governor is up for election. Guybrush investigates and unearths a conspiracy by LeChuck and evil real estate developer Ozzie Mandrill to use a voodoo talisman, \"The Ultimate Insult\", to make all pirates docile in order to turn the Caribbean into a center of tourism.\n\"Tales of Monkey Island\".\n\"Tales of Monkey Island\" is the fifth installment within the series, co-developed by Telltale Games and LucasArts, with a simultaneous release both on WiiWare and PC. Unlike other installments, \"Tales\" is an episodic adventure consisting of five different episodes. The first episode was released on July 7, with the last one released on December 8, 2009.\nDuring a heated battle with his nemesis, the evil pirate LeChuck, Guybrush unwittingly unleashes an insidious pox that rapidly spreads across the Caribbean, turning pirates into zombie-like monsters. The Voodoo Lady sends Guybrush in search of a legendary sea sponge to stem the epidemic, but this seemingly straightforward quest has surprises around every corner.\n\"Return to Monkey Island\".\nWith the purchase of LucasArts by the Walt Disney Company in 2012, the rights to the franchise are now property of Disney. In the second half of 2010s, Disney Interactive ceased the production on gaming and transitioned to a licensing model. Gilbert wrote on Twitter that he was interested in buying the \"Monkey Island\" and \"Maniac Mansion\" properties. Fans of the series launched an online petition asking Disney to sell the franchise to Gilbert; by December 2021, the petition had gathered about 29,000 signatures.\n\"Return to Monkey Island\", the sixth \"Monkey Island\" installment, was released on September 19, 2022, on the Nintendo Switch and Windows, coming to other formats later. It is a collaboration between Gilbert's Terrible Toybox studio and Lucasfilm Games, and published by Devolver Digital. A frame story in the game serves to explain and continue from the ending of \"LeChuck's Revenge\", while the main narrative takes place after the other games in the series. Ron Gilbert has expressed his desire to tell a simple and focused pirate story in the game, while also redefining the adventure game user interface and deepening the greater lore. In addition to Gilbert, Grossman returns as co-writer, with music from veteran series composers Michael Land, Peter McConnell, and Clint Bajakian, and Dominic Armato, Alexandra Boyd, and Denny Delk reprising their roles as Guybrush, Elaine, and Murray. Jess Harnell replaces the retired Earl Boen as the voice of LeChuck.\nOther appearances.\nStan's Used Coffins is referred to in one of the levels of the LucasArts game \"Outlaws\". In \"Indiana Jones and the Infernal Machine\", Guybrush can be accessed as a playable character via a cheat code; in addition, a \"Monkey Island\"-themed secret room can be found in the game's final level. Guybrush also appears in \"\" as a playable skin for Starkiller named \"Guybrush Threepkiller\".\nGuybrush is paid homage in the Naughty Dog video game \"\", where a pirate with major similarities to Guybrush is featured as one of the twelve pirate captains that founded Libertalia. Although he remains unnamed throughout the game, the resemblance is uncanny and his sigil is represented by a monkey. His portrait can be seen in the Libertalia treasury with the other founders and though his name is partly scratched out, the letters still visible spell out the truncated name \"Guy Wood\".\nSeveral elements from the \"Monkey Island\" series appear in \"Sea of Thieves\" as part of its June 2021 \"A Pirate's Life\" update. Developed in collaboration with Disney and primarily themed after \"Pirates of the Caribbean\", multiple references to the characters and locales from the Monkey Island franchise can be found in journals by Kate Capsize scattered around the wreckage of The Headless Monkey during the update's first Tall Tale, accompanied by an original arrangement of the Monkey Island theme. According to the journals, Guybrush and Elaine Threepwood are celebrating their honeymoon somewhere upon the Sea of Thieves, while Kate perished attempting to get revenge on Guybrush for framing her. \nA full \"Monkey Island\"-themed expansion for the game, \"The Legend of Monkey Island\", was released on July 20, 2023 and spread across three monthly episodes. In the story, set between \"Curse\" and \"Escape\", Guybrush and Elaine's honeymoon on the Sea of Thieves is interrupted by LeChuck, who traps them in a dream version of M\u00eal\u00e9e Island where everyone worships Guybrush as a legendary pirate. To stop LeChuck from restoring the legendary Burning Blade and conquering the Sea of Thieves, the Pirate Lord recruits the now-revived Kate Capsize and the player pirates to enter the dreamworld and rescue Guybrush and Elaine.\nIn an update to \"Hitman 3\", a new pirate-themed map was added, which featured an Easter Egg referencing \"Monkey Island\" in the form of a gravestone in the environment reading \"G Threepwood, Mighty Pirate\", a clear reference to Guybrush.\nIn \"\", while completing the 'Fists of Fury' quest in the expansion patch, the protagonist Geralt encounters a man named Mancomb, a reference to a character of the same name in the first game of the series.\nIn the 2006 movie Night at the Museum, Ben Stiller, in the main role of Larry Daley, can be heard whistling the \"Bone Song\" from Monkey Island 2 during his first shift.\nCancelled film.\nShortly after Pixar, a spinout from Lucasfilm, found success with the first \"Toy Story\" film in 1995, there had been a push across Hollywood for more digitally animated films. Lucasfilm's Industrial Light &amp; Magic (ILM), in the midst of transitioning from practical to digital effects, offered its services for producing these films to other studios. One of the first projects they tried to work on was with Universal Pictures to revive the Universal Classic Monsters line with a film called \"Frankenstein and the Wolfman\". While several scripts and preliminary art was produced for this film, shake-ups at Universal due to the financial failure of \"\" led to changes in leadership for the film and ultimately its cancellation.\nDavid Carson, who had been set to direct \"Frankenstein and the Wolfman\" but left after the Universal shake-up, came back to ILM with the idea of an animated film based on the first \"Monkey Island\" game around 2000. With initial support from ILM, Carson worked an initial script with Corey Rosen and Scott Leberecht as to pitch the idea to Amblin Entertainment, the production company owned by Steven Spielberg. Spielberg had told Carson that he had previously told George Lucas that he should have made a \"Monkey Island\" movie years before, and other meetings with Amblin went well to proceed to further screenwriting work. The rest of ILM's story department was brought in to help write, including Steve Purcell, but this team worked separately from the writers that were developing the actual games, creating a disconnect between story the film was going with and the narrative already established in the video game series. As they continued to work out the screenplay, the direction of the film continued to veer further from the video game series, including at one point where Spielberg had suggested the game be about the monkeys on Monkey Island instead of the pirates. According to Carson, the lack of a creative direction at this point led to the film being shelved at ILM.\nDetails about the film were first revealed publicly in 2011 as part of the \"Monkey Island Special Edition Collection\" which included some of the film's concept art, storyboards, and scripts.\nIt had been rumored that Ted Elliott and Terry Rossio had been involved in the writing of the \"Monkey Island\" script which they subsequently used as the basis for the first \"Pirates of the Caribbean\" film. Both Elliott and Rossio had been to ILM and were shown parts of the \"Monkey Island\" script, around the same time they were working on their script for \"Pirates\". When \"Pirates\" was released, many fans of the \"Monkey Island\" series made comparisons of parts of the film to the games, and when news of the cancelled film first arose in 2011, the potential connection of Elliott and Rossio to the \"Monkey Island\" script started. Both Carson and Rossio stated that many of the tropes in both \"Monkey Island\" and \"Pirates\" are based on the classic pirate movies and that there was no direct reuse of the cancelled \"Monkey Island\" film in \"Pirates\".\nThe \"Secret\" of Monkey Island.\nNone of the first five games explicitly reveal the \"Secret of Monkey Island\". The team behind \"Escape from Monkey Island\" attempted to resolve the issue by showing that the Giant Monkey Head was actually the control room of a Giant Monkey Robot. The cut-scene in which the revelation was made is called \"The Real Secret of Monkey Island\".\nGilbert stated that he never told anyone what the true secret of Monkey Island is. In a 2004 interview, Gilbert stated that when the game was originally conceived, it was considered \"too big\", so they split it into three parts. He added that he \"knows what the third [part] is\" and \"how the story's supposed to end\", indicating that he had a definite concept of the \u201csecret\u201d and a conclusive third game.\nThe true nature of the secret is the main focus of \"Return to Monkey Island\", with several characters competing amongst themselves in a race to discover \"the Secret\". The game's conclusion reveals the secret to be a novelty T-shirt earned as a prize at a pirate-themed amusement park, which has acted as the setting for all of Guybrush Threepwood\u2019s previous adventures. Threepwood, as the game's narrator, is intentionally ambiguous as to whether this is the actual secret, even suggesting that the secret means different things to different people, and putting forth the notion that the story of the journey (and the joy of speculating about the secret with others) is more valuable than the reward itself.\nAfter the release of \"Return to Monkey Island\", Gilbert stated in an interview that the true secret (as conceived during development of the first installment of the series) is that Guybrush was, in fact, inside of a pirate-themed amusement park the entire time.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "19532", "revid": "27823944", "url": "https://en.wikipedia.org/wiki?curid=19532", "title": "Cardiff Arms Park", "text": "Sports venue in Cardiff, Wales\nCardiff Arms Park (), also known as The Arms Park, is primarily a rugby union stadium, and also has a bowling green. It is situated in Cardiff, Wales, next to the Millennium Stadium. The Arms Park was host to the British Empire and Commonwealth Games in 1958, and hosted four games in the 1991 Rugby World Cup, including the third-place play-off. The Arms Park also hosted the inaugural Heineken Cup Final of 1995\u201396 and the following year in 1996\u201397.\nThe history of the rugby ground begins with the first stands appearing for spectators in the ground in 1881\u20131882. Originally the Arms Park had a cricket ground to the north and a rugby union stadium to the south. By 1969, the cricket ground had been demolished to make way for the present day rugby ground to the north and a second rugby stadium to the south, called the National Stadium. The National Stadium, which was used by Wales national rugby union team, was officially opened on 7 April 1984, however in 1997 it was demolished to make way for the Millennium Stadium in 1999, which hosted the 1999 Rugby World Cup and became the national stadium of Wales. The rugby ground has remained the home of the semi-professional Cardiff RFC yet the professional Cardiff Blues regional rugby union team moved to the Cardiff City Stadium in 2009, but returned three years later.\nThe site is owned by Cardiff Athletic Club and has been host to many sports, apart from rugby union and cricket; they include athletics, association football, greyhound racing, tennis, British baseball and boxing. The site also has a bowling green to the north of the rugby ground, which is used by Cardiff Athletic Bowls Club, which is the bowls section of the Cardiff Athletic Club. The National Stadium also hosted many music concerts including Michael Jackson, Dire Straits, David Bowie, Bon Jovi, The Rolling Stones and U2.\nHistory.\nEarly history of the site.\nThe Cardiff Arms Park site was originally called the Great Park, a swampy meadow behind the Cardiff Arms Hotel. The hotel was built by Sir Thomas Morgan, during the reign of Charles I. Cardiff Arms Park was named after this hotel. From 1803, the Cardiff Arms Hotel and the Park had become the property of the Bute family. The Arms Park soon became a popular place for sporting events, and by 1848, Cardiff Cricket Club was using the site for its cricket matches. However, by 1878, Cardiff Arms Hotel had been demolished.\nThe 3rd Marquess of Bute stipulated that the ground could only be used for \"recreational purposes\". At that time Cardiff Arms Park had a cricket ground to the north and a rugby union ground to the south. 1881\u20132 saw the first stands for spectators; they held 300 spectators and cost \u00a350. The architect was Archibald Leitch, who also designed Ibrox Stadium and Old Trafford. In 1890, new standing areas were constructed along the entire length of the ground, with additional stands erected in 1896.\n1912 redevelopment.\nBy 1912, the Cardiff Football Ground, as it was then known, had a new south stand and temporary stands on the north, east and west ends of the ground. The south stand was covered, while the north terrace was initially without a roof. The improvements were partly funded by the Welsh Rugby Union (WRU). The opening ceremony took place on 5 October 1912, with a match between Newport RFC and Cardiff RFC. The new ground was opened by Lord Ninian Crichton-Stuart. This new development increased the ground capacity to 43,000 and much improved facilities at the ground compared to the earlier stands.\nIn 1922, The 4th Marquess of Bute sold the entire site and it was bought by the Cardiff Arms Park Company Limited for \u00a330,000. It was then leased to the Cardiff Athletic Club (cricket and rugby sections) for 99 years at a cost of \u00a3200 per annum.\nNorth and South Stand redevelopments.\nDuring 1934 the cricket pavilion had been demolished to make way for the new North Stand which was built on the rugby union ground, costing around \u00a320,000. However, in 1941 the new North Stand and part of the west terracing was badly damaged in the Blitz by the Luftwaffe during the Second World War.\nAt a general meeting of the WRU in June 1953 they made a decision \"That until such time as the facilities at Swansea were improved, all international matches be played at Cardiff\". At the same time, plans were made for a new South Stand which was estimated to cost \u00a360,000; the tender price, however, came out at \u00a390,000, so a compromise was made and it was decided to build a new upper South Stand costing \u00a364,000 instead, with the Cardiff Athletic Club contributing \u00a315,000 and the remainder coming from the WRU. The new South Stand opened in 1956, in time for the 1958 British Empire and Commonwealth Games. This brought the overall capacity of the Arms Park up to 60,000 spectators, of which 12,800 were seated and the remainder standing.\nThe Arms Park hosted the 1958 British Empire and Commonwealth Games, which was used for the athletics events, but this event caused damage to the drainage system, so much so, that other rugby unions (England, Scotland and Ireland) complained after the Games about the state of the pitch. On 4 December 1960, due to torrential rain, the River Taff burst its banks with the Arms Park pitch being left under of water. The Development Committee was set up to resolve these issues on a permanent basis. They looked at various sites in Cardiff, but they all proved to be unsatisfactory. They also could not agree a solution with the Cardiff Athletic Club, so they purchased about of land at Island Farm in Bridgend, which was previously used as a prisoner-of-war camp. It is best known for being the camp where the biggest escape attempt was made by German prisoners of war in Great Britain during the Second World War. Due to problems including transport issues Glamorgan County Council never gave outline planning permission for the proposals and by June 1964 the scheme was abandoned. At that stage, the cricket ground to the north was still being used by Glamorgan County Cricket Club, and the rugby union ground to the south was used by the national Wales team and Cardiff RFC.\nBy 7 October 1966, the first floodlit game was held at Cardiff Arms Park, a game in which Cardiff RFC beat the Barbarians by 12 points to 8.\nNational Stadium redevelopment.\nThe National Stadium, which was previously known as the Welsh National Rugby Ground, was designed by Osborne V Webb &amp; Partners and built by G A Williamson &amp; Associates of Porthcawl and Andrew Scott &amp; Company of Port Talbot. In 1969 construction began on the stadium which replaced the existing rugby ground built in 1881. The stadium was home to the Wales national rugby union team since 1964 and the Wales national football team since 1989. In 1997 the stadium was demolished to make way for the new Millennium Stadium.\nMillennium Stadium.\nThirteen years after the National Stadium had opened in 1984, it was considered too small and did not have the facilities required of the time and it was demolished and a new stadium, the Millennium Stadium, was built in its place (completed to a north\u2013south alignment and opened in June 1999). This would become the fourth redevelopment on the site.\nConstruction involved the demolition of a number of buildings, primarily the existing National Stadium, Wales Empire Pool in Wood Street, Cardiff Empire Telephone Exchange building and the newly built Territorial Auxiliary and Volunteer Reserve building both in Park Street, and the Social Security offices in Westgate Street. The Millennium Stadium is now on roughly two-thirds of the National Stadium, but it no longer uses the Arms Park name. Since 2016, it has been known as the Principality Stadium.\nCurrent site.\nRugby ground.\nOnly the rugby ground and the Cardiff Athletic Bowls Club now use the name Cardiff Arms Park. The rugby ground has two main stands, the North Stand and the South Stand. Both the Stands have terracing below seating. The other stands in the ground are the Westgate Street end Family Stand, which has rows of seating below executive boxes, plus the club shop, and the River Taff end (the Barry Nelmes Suite, named after Barry Nelmes, the former Cardiff RFC captain), which has 26 executive boxes. The rugby ground has two main entrances, the south entrance, and the Gwyn Nicholls Memorial Gates (Angel Hotel entrance), which was unveiled on 26 December 1949 in honour of the Welsh international rugby player Gwyn Nicholls. The Cardiff Athletic Clubhouse is situated in the corner of the ground between the South Stand and the Westgate Street end.\nThe South Stand of the rugby ground formed a complete unit with the North Stand of the National Stadium. Now the same structure of the South Stand of the rugby ground is also physically attached to the North Stand of the Millennium Stadium. This section is known colloquially as Glanmor's Gap, after Glanmor Griffiths, former chair and President of the WRU. This came about because the WRU were unable to secure enough funding to include the North Stand in the Millennium Stadium, and the National Lottery Commission would not provide any additional funds to be used for the construction of a new ground for Cardiff RFC. The Millennium Stadium was therefore built with the old reinforced concrete structure of the National Stadium (North Stand) and the new steel Millennium Stadium structure built around it.\nThere was doubt about the future of the Arms Park after 2010 following the move of the Cardiff Blues to the Cardiff City Stadium. Cardiff RFC Ltd, the company that runs Cardiff Blues and Cardiff RFC, still has a 15-year lease on the Arms Park, but talks are underway to release the rugby club from the terms of the lease, to enable the Millennium Stadium to be redeveloped with a new North Stand and adjoining convention centre. However, it still has the original requirement on the lease, that the land will only be used for \"recreational purposes\", as stipulated by the Bute family. But the Arms Park site is a prime piece of real estate in the centre of Cardiff, which means that it may be difficult to sell the land to property developers. The estimated value of the whole Arms Park site could be at least \u00a325\u00a0million, although with the \"recreational use\" requirement, its actual value could be a lot less than that figure. A decision by Cardiff Athletic Club on the future of the Arms Park has yet to be made. In 2011, the Cardiff Blues regional rugby union team made a \u00a36\u00a0million bid for the Arms Park, later the WRU made an increased bid of \u00a310\u00a0million for the site. Both bids were rejected by the trustees of the Cardiff Athletic Club. However, in 2012 Cardiff Blues announced that they would be making a permanent return to Cardiff Arms Park following declining attendances at the Cardiff City Stadium. During the 2013 off-season, the pitch at the rugby ground was replaced with an all weather 3G (third generation) artificial turf surface from FieldTurf at a cost of \u00a3400,000, intended to prevent any adverse weather conditions from affecting the rugby.\nAn agreement in principle was reached in December 2015 between the landlord of the stadium site (Cardiff Athletic Club) and its tenant (Cardiff Blues) to give the club a 150-year lease on the stadium site. This could see the redevelopment of the Arms Park, including a new 15,000 seater stadium at 90 degrees to the existing stadium costing between \u00a320 million and \u00a330 million and surrounded by new offices and apartments. If the final agreement goes ahead, Cardiff Athletic Club would receive an upfront payment of approximately \u00a38 million. As part of the agreement, the bowls section would have to vacate its current site at the Arms Park and move to a new facility. At present Cardiff Blues pay Cardiff Athletic Club rent of around \u00a3115,000 per annum, however this would nearly double to around \u00a3200,000.\nBowling green.\nCardiff Arms Park is best known as a rugby union stadium, but Cardiff Athletic Bowls Club (CABC) was established in 1923, and ever since then, the club has used the Arms Park as its bowling green. The bowls club is a section of the Cardiff Athletic Club and shares many of the facilities of the Cardiff Arms Park athletics centre.\nThe Les Spence Memorial Gates were erected in memory of the former Cardiff RFU player, who captained the team in 1936\u201337. He was born in 1907 and became chairman of the Cardiff RFU and president of the WRU between 1973 and 1974. He was awarded an MBE and died in 1988.\nThe club has produced two Welsh international bowlers; Mr. C Standfast in 1937 and Mr. B Hawkins who represented Wales in the 1982 World Pairs and captained Wales in 1982 and 1984.\nUsage.\nAssociation football.\nThe Riverside Football Club, founded in 1899, played some matches at the Arms Park until 1910, when they moved to Ninian Park, and later became Cardiff City Football Club.\nOn 31 May 1989, Wales played its first international game against West Germany at the National Stadium in a World Cup qualifying match, which ended goalless. It was also the first ever international football match held in Great Britain that was watched by all-seater spectators.\nThe adjoining Cardiff Rugby Club ground has also been used for Association Football. In July 1995, Ton Pentre played two Intertoto Cup games there, against Heerenveen (Netherlands) and Uniao Leiria (Portugal) as their own ground was not suitable. The Heerenveen game - the first ever soccer match to be played there - kicked off at 6pm on Saturday 1 July 1995 and resulted in the Dutch side winning 7\u20130. The Wales U-21 team have also played a home game there in the late 1990s.\nOn 5 April 2017, the ground was used to host the men's and women's football matches as part of the 2017 Welsh Varsity, between Cardiff University and Swansea University. The women's game finished in a 1-1 draw, while the men's game resulted in a 1-0 win for Swansea.\nAthletics.\nIn 1958, the British Empire and Commonwealth Games were held in Cardiff. The event was (to date) the biggest sporting event ever held in Wales; however, it would not have been possible without the financial support given by the WRU and the Cardiff Athletic Club. Both the opening and closing ceremonies took place at Cardiff Arms Park, plus all the track and field events, on what had been the greyhound track. It would turn out to be the last time that South Africa would participate in the Games until 1994. South Africa withdrew from the Commonwealth Games in 1961.\nBaseball and British baseball.\nBaseball was established early on in Cardiff, and one of the earliest of games to be held at the Arms Park was on 18 May 1918. It was a charity match in aid of the Prisoner of War Fund between Welsh and American teams of the U.S. Beaufort and U.S. Jupiter. British baseball matches have also regularly taken place at the Arms Park and hosted the annual England versus Wales international game every four years. The games are now usually held at Roath Park.\nBoxing.\nThe first boxing contest held at the Arms Park was on 24 January 1914, when Bombardier Billy Wells beat Gaston Pigot by a knockout in the first round of a 20-round contest. Boxing contests were held later on 14 June 1943, 12 August 1944, 4 October 1951 and 10 September 1952.\nAround 25,000 spectators watched international boxing on 1 October 1993, at the National Stadium with a World Boxing Council (WBC) Heavyweight title bout between Lennox Lewis and Frank Bruno. It was the first time that two British-born boxers had fought for the world heavyweight title. Lewis beat Bruno by a technical knockout in the 7th round, in what was called the \"Battle of Britain\". On 30 September 1995, Steve Robinson the World Boxing Organization (WBO) World Featherweight Champion, lost against Prince Naseem Hamed at the rugby ground in 8 rounds.\nCricket.\nIn 1819, Cardiff Cricket Club was formed and by 1848 they had moved to their new home at the Arms Park. Glamorgan County Cricket Club, at the time not a first-class county, played their first match at the ground in June 1869 against Monmouthshire Cricket Club. The county club played their first County Championship match on the ground in 1921, competing there every season (except while first-class cricket was suspended during the Second World War) until their final match on the ground against Somerset in August 1966.\nCardiff Cricket Club played their final game at the ground against Lydney Cricket Club on 17 September 1966. Both Cardiff Cricket Club and Glamorgan then moved to a new ground at Sophia Gardens on the opposite bank of the River Taff to the Arms Park following work on the creation of the national rugby stadium.\nThe first first-class cricket match to be held on the ground was between West of England and East of England, on 20 June 1910. In all more than 240 first-class matches were played on the ground, all but two involving Glamorgan as the home team. Only one List A cricket match was played on the ground, Glamorgan's Gillette Cup fixture against Somerset on 22 May 1963.\nGreyhound racing.\nGreyhound racing took place at the Arms Park for fifty years from 1927 until 1977.\nRugby union.\nIn 1876, the Cardiff RFC was formed and soon after they also used the park. On 12 April 1884, the first international match was played at the ground between Wales and Ireland, when 5,000 people watched Wales beat Ireland by two tries and a drop goal to nil.\nThe Arms Park rugby ground became the permanent home of the Wales national rugby union team in 1964. Later, the National Stadium was also home to the WRU Challenge Cup from 1972 until the match held at the Stadium on 26 April 1997, at a much reduced capacity, between Cardiff RFC and Swansea RFC. Cardiff RFC won the match 33\u201326.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\n\"The game\" (between the Barbarians and the New Zealand All Blacks) \"is one I will never forget and those of us who played in it will never be allowed to forget. It is a match that will live with me forever. People tend only to remember the first four minutes of the game because of the try, but what they forgot is the great deal of good rugby played afterwards, much of which came from the All Blacks. After the success of the 1971 Lions tour, which captured the imagination of the whole country, it was an opportunity to bring a lot of that side together again.\"\nGareth Edwards\nThe National Stadium is best known as the venue for what is considered to be \"the greatest try ever scored\" by Gareth Edwards for the Barbarians against New Zealand in what is also called \"the greatest match ever played\" on 27 January 1973. The final result was a win for the Barbarians. The score, 23\u201311, which translates to 27\u201313 in today's scoring system.\nThe scorers were:\nBarbarians: Tries: Gareth Edwards, Fergus Slattery, John Bevan, J P R Williams; Conversions: Phil Bennett (2); Penalty: Phil Bennett.\nAll Blacks: Tries: Grant Batty (2); Penalty: Joseph Karam.\nThe National Stadium hosted four games in the 1991 Rugby World Cup, including the third-place play-off. The National Stadium was also host to the inaugural Heineken Cup final of 1995\u201396 when Toulouse beat Cardiff RFC by 21\u201318 after extra time, in front of 21,800 spectators. The following final in 1996\u201397 was also held at the National Stadium, this time it was between Brive and Leicester Tigers. Brive won the match 28\u20139, in front of a crowd of 41,664.\nIn 2008, the rugby ground hosted all the games in Pool A of the 2008 IRB Junior World Championship and also the semi-final on 18 June 2008, in which England beat South Africa 26\u201318.\nUntil February 2012, it had been assumed that the last professional rugby union game to take place at the Arms Park was on 17 May 2009, when Edinburgh beat the Cardiff Blues 36\u201314 in a Celtic League match during the 2008\u201309 season.\nHowever, on Tuesday, 7 February 2012, it was confirmed that Cardiff Blues would face Connacht at the Arms Park on Friday, 10 February 2012. The Pro12 League game result was a win for the Cardiff Blues 22\u201315 and attendance of 8,000. The following Tuesday, it was announced that the match against Ulster on Friday, 17 February, would also be at the Arms Park, resulting in a Blues win, 21\u201314 and attendance of 8,600. The agreement signed during 2009 tied Cardiff Blues to a 20-year contract to play a maximum of 18 games per season for a set fee, rather than per match at Cardiff City Stadium. But on 23 February, it was announced that the two Welsh 'derbies' against the Scarlets and the Ospreys would be played at Cardiff City Stadium, rather than the Arms Park, because of Cardiff Blues' anticipation that the attendance figures would far exceed the maximum capacity of 9,000. On 8 May 2012, it was announced that Cardiff Blues would be returning to the Arms Park on a permanent basis after just three years at the Cardiff City Stadium.\nOn 23 May 2014, the rugby ground hosted the final of the 2013\u201314 Amlin Challenge Cup in which Northampton Saints beat Bath 30\u201316.\nCardiff Arms Park hosted matches of the 1991 Rugby World Cup.\nRugby league.\nSouth Wales Scorpions played a Rugby League Championship 1 match against London Skolars at Cardiff Arms Park on Sunday, 27 July 2014 and on Sunday 10 May 2015 at Cardiff Arms Park, South Wales Scorpions took on North Wales Crusaders. The 2015 European Cup match between France and Wales was held at Cardiff Arms Park on Friday on 30 October 2015.\nOn 11 April it was announced Cardiff Arms Park would be the new home ground of the Women's Betfred Super League South team Cardiff Demons. The inaugural league champions will play all home games at the stadium during the 2022 season.\nThe highest attendance for a rugby league game at the Arms Park was recorded on 8 June 1996 during the first Super League season when 6,708 saw St. Helens defeat the Sheffield Eagles 43\u201332. The St Helens team at the time contained Welsh players Anthony Sullivan, Karle Hammond and Keiron Cunningham.\nList of rugby league test matches played at Cardiff Arms Park.\nTennis.\nTennis courts were laid out in the Arms Park for Cardiff Tennis Club until the club moved to Sophia Gardens in 1967. In 2003, the club amalgamated with Lisvane Tennis Club to form Lisvane (CAC) Tennis Club, which is still a section of Cardiff Athletic Club (CAC).\nMusic concerts.\nMajor music concerts were also held at the National Stadium from 1987 until 1996, they included Tina Turner, U2, Michael Jackson, The Rolling Stones, Dire Straits, Bon Jovi and R.E.M. The last music concert was held on 14 July 1996. Jehovah's Witnesses held their annual conventions at the National Stadium.\nSinging tradition.\nThe National Stadium was known primarily as the venue for massed voices singing such hymns as \"Cwm Rhondda\", \"Calon L\u00e2n\", \"Men of Harlech\" and \"Hen Wlad Fy Nhadau\" (\"Land of my Fathers\" \u2013 the national anthem of Wales). The legendary atmosphere including singing of the crowd was said to be worth at least a try or a goal to the home nation. This tradition of singing has now passed on to the Millennium Stadium.\nThe Arms Park has its own choir, called the Cardiff Arms Park Male Choir. It was formed in 1966 as the Cardiff Athletic Club Male Voice Choir, and today performs internationally with a schedule of concerts and tours. In 2000, the choir changed their name to become the Cardiff Arms Park Male Choir.\nReferences.\nInline.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nExternal links.\nrole=\"presentation\" class=\"wikitable succession-box noprint\" style=\"margin:0.5em auto; font-size:small;clear:both;\""}
{"id": "19535", "revid": "36679560", "url": "https://en.wikipedia.org/wiki?curid=19535", "title": "Mikhail Kalashnikov", "text": "Russian firearms designer (1919\u20132013)\nMikhail Timofeyevich Kalashnikov (10November 1919\u00a0\u2013 23December 2013) was a Soviet and Russian lieutenant general, inventor, military engineer, writer, and small arms designer. He is most famous for developing the AK-47 assault rifle and its improvements, the AKM and AK-74, as well as the RPK light machine gun and PK machine gun.\nKalashnikov was, according to himself, a self-taught tinkerer who combined innate mechanical skills with the study of weaponry to design arms that achieved battlefield ubiquity. Even though Kalashnikov felt sorrow at the weapons' uncontrolled distribution, he took pride in his inventions and in their reputation for reliability, emphasizing that his rifle is \"a weapon of defense\" and \"not a weapon for offense\".\nEarly life.\nKalashnikov was born in the village of Kurya, in present-day Altai Krai, Russia, as the seventeenth child of the 19 children of Aleksandra Frolovna Kalashnikova (n\u00e9e Kaverina) and Timofey Aleksandrovich Kalashnikov, who were peasants. In his youth, Mikhail suffered from various illnesses and was on the verge of death at age six. He was attracted to all kinds of machinery, but also wrote poetry, dreaming of becoming a poet. He later went on to write six books and continued to write poetry all of his life. In 1930, his father and most of his family had their properties confiscated and were deported as kulaks to the village of Nizhnyaya Mokhovaya, Tomsk Oblast. After deportation, his family had to combine farming with hunting, and thus Mikhail frequently used his father's rifle in his teens. Kalashnikov continued hunting into his 90s.\nAfter completing seventh grade, Mikhail, with his stepfather's permission, left his family and returned to Kurya, hiking for nearly 1,000\u00a0km. In Kurya, he found a job in mechanics at a tractor station. A party organizer embedded within the factory noticed the man's dexterity and issued him a directive (\"napravlenie\") to work at a nearby weapons design bureau, where he was employed as a tester of fitted stocks in rifles. In 1938, he was conscripted into the Red Army. Because of his engineering skills he was assigned as a tank mechanic, and later became a tank commander. While training, he made his first inventions, which concerned not only tanks, but also small weapons, and was personally awarded a wrist watch by Georgy Zhukov. Kalashnikov served on the T-34s of the 24th Tank Regiment, 12th Tank Division stationed in Stryi before the regiment retreated after the Battle of Brody in June 1941. He was wounded in combat in the Battle of Bryansk in October 1941 and hospitalised until April 1942. In the last few months of being in hospital, he overheard some fellow soldiers bemoaning their current rifles, which were plagued with reliability issues, such as jamming. As he continued to overhear the complaints that the Soviet soldiers had, as soon as he was discharged, he went to work on what would become the famous AK-47 assault rifle.\nSeeing the drawbacks of the standard infantry weapons at the time, he decided to construct a new rifle for the Soviet military. During this time Kalashnikov began designing a submachine gun. Although his first submachine gun design was not accepted into service, his talent as a designer was noticed. From 1942 onwards, Kalashnikov was assigned to the Central Scientific-developmental Firing Range for Rifle Firearms of the Chief Artillery Directorate of the Red Army.\nIn 1944, he designed a gas-operated carbine for the new 7.62\u00d739mm cartridge. This weapon, influenced by the Garand rifle design, lost out to the new Simonov carbine which would eventually be adopted as the SKS; but it became a basis for his entry in an assault rifle competition in 1946. His winning entry, with the designer recorded by the alias \"Mikhtim\" (so named by taking the first letters of his name and patronymic, Mikhail Timofeyevich) became the prototype for the development of a family of prototype rifles. \nThis process culminated in 1947, when he designed the AK-47 (standing for \"Avtomat Kalashnikova model 1947\"). In 1949, the AK became the standard issue assault rifle of the Soviet Army and went on to become Kalashnikov's most famous invention.\nWhile developing his first assault rifles, Kalashnikov competed with two much more experienced weapon designers, Vasily Degtyaryov and Georgy Shpagin, who both accepted the superiority of the AK-47 design. Kalashnikov named Alexandr Zaitsev and Vladimir Deikin as his major collaborators during those years.\nLater career.\nFrom 1949, Mikhail Kalashnikov lived and worked in Izhevsk, Udmurtia. He held a degree of Doctor of Technical Sciences (1971) and was a member of 16 academies.\nOver the course of his career, he evolved the basic design into a weapons family. The AKM (), first brought into service in 1959, was lighter and cheaper to manufacture, owing to the use of a stamped steel receiver (in place of the AK-47's milled steel receiver) and contained detail improvements such as a re-shaped stock and muzzle compensator. From the AKM, he developed a squad automatic weapon variant, known as the RPK ().\nHe also developed the general-purpose PK machine gun (), which used the more powerful 7.62\u00d754mmR cartridge of the Mosin\u2013Nagant rifle. It is cartridge belt-fed, not magazine-fed, as it is intended to provide heavy sustained fire from a tripod mount, or be used as a light, bipod-mounted weapon. The common characteristics of all these weapons are their simple design, ruggedness and ease of maintenance in all operating conditions.\nApproximately 100 million AK-47 assault rifles had been produced by 2009, and about half of them are counterfeit, manufactured at a rate of about a million per year. Izhmash, the official manufacturer of AK-47 in Russia, did not patent the weapon until 1997, and in 2006 accounted for only 10% of the world's production.\nKalashnikov stated that his motivation was always to serve his country, not to earn money. \nDuring a visit to the United States in the early 2000s, Kalashnikov was invited to tour a Virginia holding site for the forthcoming American Wartime Museum. Kalashnikov, a former tank commander, became visibly moved at the sight of his old tank in action, painted with his name in Cyrillic.\nDeath.\nAfter a prolonged illness, Kalashnikov was hospitalized on 17 November 2013, in an Udmurtian medical facility in Izhevsk, the capital of Udmurtia and where he lived. He died 23 December 2013, at age 94 from gastric hemorrhage. In January 2014, a letter that Kalashnikov wrote six months before his death to the leader of the Russian Orthodox Church, Patriarch Kirill, was published by the Russian daily newspaper \"Izvestia\". In the letter, he stated that he was suffering \"spiritual pain\" about whether he was responsible for the deaths caused by the weapons he created. Translated from the published letter he states, \"I keep having the same unsolved question: if my rifle claimed people's lives, then can it be that I... a Christian and an Orthodox believer, was to blame for their deaths?\".\nThe patriarch wrote back, thanked Kalashnikov, and said that he \"was an example of patriotism and a correct attitude toward the country\". Kirill added about the design responsibility for the deaths by the rifle, \"the church has a well-defined position when the weapon is defense of the Motherland, the Church supports its creators and the military, which use it.\"\nHe became one of the first people buried in the Federal Military Memorial Cemetery.\nFamily.\nKalashnikov's father, Timofey Aleksandrovich Kalashnikov (1883\u20131930), was a peasant. He completed two grades of parochial school and could read and write. In 1901, he married Aleksandra Frolovna Kaverina (1884\u20131957), who was illiterate throughout her life. They had 19 children, but only eight survived to adult age; Kalashnikov was born 17th, and was close to death at age six.\nIn 1930, the government labeled Timofey Aleksandrovich a kulak, confiscated his property, and deported him to Siberia, along with most of the family. The eldest three siblings, daughters Agasha (b. 1905) and Anna and son Victor, were already married by 1930, and remained in Kuriya. After her husband's death in 1930, Aleksandra Frolovna married Efrem Kosach, a widower who had three children of his own.\nMikhail Kalashnikov married twice, the first time to Ekaterina Danilovna Astakhova of Altai Krai. He married the second time to Ekaterina Viktorovna Moiseyeva (1921\u20131977). She was an engineer and did much technical drawing work for her husband. They had four children: daughters Nelli (b. 1942), Elena (b. 1948) and Natalya (1953\u20131983), and a son Victor (1942\u20132018). Victor also became a prominent small arms designer.\nKalashnikov's grandson, Igor, ran a German company called Marken Marketing International. The company revamps trademarks and produces merchandise carrying the Kalashnikov name, such as vodka, umbrellas and knives. One of the items is a knife named for the AK-74.\nThe title to the AK-47 trademark belonged to Mikhail Kalashnikov's family until 4 April 2016, when the Kalashnikov Concern won a lawsuit to invalidate the registration of the trademark.\nWeapon designs.\nDuring his career, Kalashnikov designed about 150 models of small weapons. The most famous of them are:\nAwards and tribute.\n\"Incorporates information from the corresponding article in the Russian Wikipedia\"\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "19537", "revid": "27823944", "url": "https://en.wikipedia.org/wiki?curid=19537", "title": "Multi-user dungeon", "text": "Video game genre\nA multi-user dungeon (MUD, ), also known as a multi-user dimension or multi-user domain, is a multiplayer real-time virtual world, usually text-based or storyboarded. MUDs combine elements of role-playing games, hack and slash, player versus player, interactive fiction, and online chat. Players can read or view descriptions of rooms, objects, other players, and non-player characters, and perform actions in the virtual world that are typically also described. Players typically interact with each other and the world by typing commands that resemble a natural language, as well as using a character typically called an avatar.\nTraditional MUDs implement a role-playing video game set in a fantasy world populated by fictional races and monsters, with players choosing classes in order to gain specific skills or powers. The objective of this sort of game is to slay monsters, explore a fantasy world, complete quests, go on adventures, create a story by roleplaying, and advance the created character. Many MUDs were fashioned around the dice-rolling rules of the \"Dungeons &amp; Dragons\" series of games.\nSuch fantasy settings for MUDs are common, while many others have science fiction settings or are based on popular books, movies, animations, periods of history, worlds populated by anthropomorphic animals, and so on. Not all MUDs are games; some are designed for educational purposes, while others are purely chat environments, and the flexible nature of many MUD servers leads to their occasional use in areas ranging from computer science research to geoinformatics to medical informatics to analytical chemistry. MUDs have attracted the interest of academic scholars from many fields, including communications, sociology, law, and economics. At one time, there was interest from the United States military in using them for teleconferencing.\nMost MUDs are run as hobbies and are free to play; some may accept donations or allow players to purchase virtual items, while others charge a monthly subscription fee. MUDs can be accessed via standard telnet clients, or specialized MUD clients, which are designed to improve the user experience. Numerous games are listed at various web portals, such as The Mud Connector.\nThe history of modern massively multiplayer online role-playing games (MMORPGs) like \"EverQuest\" and \"Ultima Online\", and related virtual world genres such as the social virtual worlds exemplified by \"Second Life\", can be traced directly back to the MUD genre. Indeed, before the invention of the term MMORPG, games of this style were simply called graphical MUDs. A number of influential MMORPG designers began as and/or players (such as Raph Koster, Brad McQuaid, Matt Firor, and Brian Green) or were involved with early MUDs (like Mark Jacobs and J. Todd Coleman).\nEarly history.\nOrigins.\n\"Colossal Cave Adventure\", created in 1975 by Will Crowther on a DEC PDP-10 computer, was the first widely played adventure game. The game was significantly expanded in 1976 by Don Woods. Also called \"Adventure\", it contained many D&amp;D features and references, including a computer controlled dungeon master.\nNumerous dungeon crawlers were created on the PLATO system at the University of Illinois and other American universities that used PLATO, beginning in 1975. Among them were \"pedit5\", \"oubliette\", \"moria\", \"avatar\", \"krozair\", \"dungeon\", \"dnd\", \"crypt\", and \"drygulch\". By 1978\u201379, these games were heavily in use on various PLATO systems, and exhibited a marked increase in sophistication in terms of 3D graphics, storytelling, user involvement, team play, and depth of objects and monsters in the dungeons.\nInspired by \"Adventure\", a group of students at MIT in the summer of 1977 wrote a game for the PDP-10 minicomputer; called \"Zork\", it became quite popular on the ARPANET. \"Zork\" was ported, under the filename DUNGEN (\"dungeon\"), to FORTRAN by a programmer working at DEC in 1978.\nIn 1978 Roy Trubshaw, a student at the University of Essex in the UK, started working on a multi-user adventure game in the MACRO-10 assembly language for a DEC PDP-10. He named the game \"MUD\" (\"Multi-User Dungeon\"), in tribute to the \"Dungeon\" variant of \"Zork\", which Trubshaw had greatly enjoyed playing. Trubshaw converted MUD to BCPL (the predecessor of C), before handing over development to Richard Bartle, a fellow student at the University of Essex, in 1980. The game revolved around gaining points till one achieved the Wizard rank, giving the character immortality and special powers over mortals.\nWider access and early derivatives.\n\"MUD\", better known as \"Essex MUD\" and \"MUD1\" in later years, ran on the University of Essex network, and became more widely accessible when a guest account was set up that allowed users on JANET (a British academic X.25 computer network) to connect on weekends and between the hours of 2 AM and 8 AM on weekdays. It became the first Internet multiplayer online role-playing game in 1980 and started the online gaming industry as a whole when the university connected its internal network to ARPANET.\nThe original \"MUD\" game was closed down in late 1987, reportedly under pressure from CompuServe, to whom Richard Bartle had licensed the game. This left \"MIST\", a derivative of \"MUD1\" with similar gameplay, as the only remaining MUD running on the University of Essex network, becoming one of the first of its kind to attain broad popularity. \"MIST\" ran until the machine that hosted it, a PDP-10, was superseded in early 1991.\n1985 saw the origin of a number of projects inspired by the original \"MUD\". These included \"Gods\" by Ben Laurie, a \"MUD1\" clone that included online creation in its endgame, and which became a commercial MUD in 1988; and \"MirrorWorld\", a tolkienesque MUD started by Pip Cordrey who gathered some people on a BBS he ran to create a \"MUD1\" clone that would run on a home computer.\nNeil Newell, an avid \"MUD1\" player, started programming his own MUD called \"SHADES\" during Christmas 1985, because \"MUD1\" was closed down during the holidays. Starting out as a hobby, \"SHADES\" became accessible in the UK as a commercial MUD via British Telecom's Prestel and Micronet networks. A scandal on \"SHADES\" led to the closure of Micronet, as described in Indra Sinha's net-memoir, \"The Cybergypsies\".\nAt the same time, Compunet started a project named \"Multi-User Galaxy Game\" as a science fiction alternative to \"MUD1\", a copy of which they were running on their system at the time. When one of the two programmers left CompuNet, the remaining programmer, Alan Lenton, decided to rewrite the game from scratch and named it \"Federation II\" (at the time no \"Federation I\" existed). The MUD was officially launched in 1989. \"Federation II\" was later picked up by AOL, where it became known simply as \"Federation: Adult Space Fantasy\". \"Federation\" later left AOL to run on its own after AOL began offering unlimited service.\nOther early MUD-like games.\nIn 1978, around the same time Roy Trubshaw wrote \"MUD\", Alan E. Klietz wrote a game called \"Scepter\" (Scepter of Goth), and later called \"Milieu\" using Multi-Pascal on a CDC Cyber 6600 series mainframe which was operated by the Minnesota Educational Computing Consortium. Klietz ported \"Milieu\" to an IBM XT in 1983, naming the new port \"Scepter of Goth\". \"Scepter\" supported 10 to 16 simultaneous users, typically connecting in by modem. It was the first commercial MUD; franchises were sold to a number of locations. \"Scepter\" was first owned and run by GamBit (of Minneapolis, Minnesota), founded by Bob Alberti. GamBit's assets were later sold to Interplay Productions.\nIn 1984, Mark Peterson wrote \"The Realm of Angmar\", beginning as a clone of \"Scepter of Goth\". In 1994, Peterson rewrote \"The Realm of Angmar\", adapting it to MS-DOS (the basis for many dial-in BBS systems), and renamed it \"Swords of Chaos\". For a few years this was a popular form of MUD, hosted on a number of BBS systems, until widespread Internet access eliminated most BBSes.\nIn 1984, Mark Jacobs created and deployed a commercial gaming site, \"Gamers World\". The site featured two games coded and designed by Jacobs, a MUD called \"Aradath\" (which was later renamed, upgraded and ported to GEnie as \"Dragon's Gate\") and a 4X science-fiction game called \"Galaxy\", which was also ported to GEnie. At its peak, the site had about 100 monthly subscribers to both \"Aradath\" and \"Galaxy\". GEnie was shut down in the late 1990s, although \"Dragon's Gate\" was later brought to AOL before it was finally released on its own. Dragon's Gate was closed on February 10, 2007.\nIn the summer of 1980, University of Virginia classmates John Taylor and Kelton Flinn wrote \"Dungeons of Kesmai\", a six player game inspired by \"Dungeons &amp; Dragons\" which used roguelike ASCII graphics. They founded the Kesmai company in 1982 and in 1985 an enhanced version of \"Dungeons of Kesmai\", \"Island of Kesmai\", was launched on CompuServe. Later, its 2-D graphical descendant \"Legends of Kesmai\" was launched on AOL in 1996. The games were retired commercially in 2000.\nThe popularity of MUDs of the University of Essex tradition escalated in the United States during the late 1980s when affordable personal computers with 300 to 2400 bit/s modems enabled role-players to log into multi-line BBSs and online service providers such as CompuServe. During this time it was sometimes said that MUD stands for \"Multi Undergraduate Destroyer\" due to their popularity among college students and the amount of time devoted to them.\n\"\" was published by Yehuda Simmons in 1989. It was the first persistent game world of its kind without the traditional hourly resets and points-based puzzle solving progression systems. Avalon introduced equilibrium and balance (cooldowns), skill-based player vs player combat and concepts such as player-run governments and player housing.\nLater history.\nIn 2004, significant usages of MUDs included \"online gaming, education...socializing\", and religious rituals or other religious activities.\nPopular variants.\nAberMUD.\nThe first popular MUD codebase was AberMUD, written in 1987 by Alan Cox, named after the University of Wales, Aberystwyth. Alan Cox had played the original University of Essex MUD, and the gameplay was heavily influenced by it. AberMUD was initially written in B for a Honeywell L66 mainframe under GCOS3/TSS. In late 1988 it was ported to C, which enabled it to spread rapidly to many Unix platforms upon its release in 1989. AberMUD's popularity resulted in several inspired works, the most notable of which were TinyMUD, LPMud, and DikuMUD.\nTinyMUD.\n\"Monster\" was a multi-user adventure game created by Richard Skrenta for the VAX and written in VMS Pascal. It was publicly released in November 1988. \"Monster\" was disk-based and modifications to the game were immediate. \"Monster\" pioneered the approach of allowing players to build the game world, setting new puzzles or creating dungeons for other players to explore. Monster, which comprised about 60,000 lines of code, had many features which appeared to be designed to allow \"Colossal Cave Adventure\" to work in it. Though there never were many network-accessible Monster servers, it inspired James Aspnes to create a stripped-down version of \"Monster\" which he called TinyMUD.\nTinyMUD, written in C and released in late 1989, spawned a number of descendants, including TinyMUCK and TinyMUSH. TinyMUCK version 2 contained a full programming language named MUF (Multi-User Forth), while MUSH greatly expanded the command interface. To distance itself from the combat-oriented traditional MUDs it was said that the \"D\" in TinyMUD stood for Multi-User \"Domain\" or \"Dimension\"; this, along with the eventual popularity of acronyms other than MUD (such as MUCK, MUSH, MUSE, and so on) for this kind of server, led to the eventual adoption of the term MU* to refer to the TinyMUD family. UberMUD, UnterMUD, and MOO were inspired by TinyMUD but are not direct descendants.\nTinyMUD is also used to refer to the first database run under the TinyMUD codebase, which is also known as TinyMUD Classic; it ran from August 1989 to April 1990, and still comes back up every August during a holiday called Brigadoon Day, a reference to the Scottish village in the musical Brigadoon.\nHourglass.\nThe first version of Hourglass was written by Yehuda Simmons and later Daniel James for \"\" which debuted in 1989 at the last of the London MUD mega Meets aptly named \"Adventure '89\" and initially hosted on the IOWA system. Initially written in ARM assembly language on the Acorn Archimedes 440, in 1994 it made the leap from the venerable Archimedes to Debian Linux on the PC and later Red Hat where, other than shifting to Ubuntu, it has remained ever since. An early version of Hourglass was also ported to the PC, named Vortex, by Ben Maizels in 1992.\nAlthough written specifically for \"Avalon: The Legend Lives\", it went on to spawn a number of games, including \"Avalon: The First Age\", which ran from 1999 to 2014. The now defunct 1996 \"Age of Thrones\" and notably \"Achaea, Dreams of Divine Lands\" started life in Vortex prior to moving to its own Rapture engine. Hourglass continues to be developed as of 2016 and \"Avalon: The Legend Lives\" currently has 2,901,325 written words and 2,248,374 lines of game code (with 2,417,900 instructions). The original game came in at 1\u00a0KB in 1989, compared to 102\u00a0GB in January 2016.\nLPMud.\nIn 1989, LPMud was developed by Lars Pensj\u00f6 (hence the LP in LPMud). Pensj\u00f6 had been an avid player of TinyMUD and AberMUD and wanted to create a world with the flexibility of TinyMUD and the gameplay of AberMUD. In order to accomplish this he wrote what is nowadays known as a virtual machine, which he called the LPMud driver, that ran the C-like LPC programming language used to create the game world. Pensj\u00f6's interest in LPMud eventually waned and development was carried on by others such as J\u00f6rn \"Amylaar\" Rennecke, Felix \"Dworkin\" Croes, Tim \"Beek\" Hollebeek and Lars D\u00fcning. During the early 1990s, LPMud was one of the most popular MUD codebases. Descendants of the original LPMud include MudOS, DGD, SWLPC, FluffOS, and the Pike programming language, the latter the work of long-time LPMud developer Fredrik \"Profezzorn\" H\u00fcbinette.\nDikuMUD.\nIn 1990, the release of DikuMUD, which was inspired by AberMUD, led to a virtual explosion of hack and slash MUDs based upon its code. DikuMUD inspired numerous derivative codebases, including CircleMUD, Merc, ROM, SMAUG, and GodWars. The original Diku team comprised Sebastian Hammer, Tom Madsen, Katja Nyboe, Michael Seifert, and Hans Henrik Staerfeldt. DikuMUD had a key influence on the early evolution of the MMORPG genre, with \"EverQuest\" (created by avid DikuMUD player Brad McQuaid) displaying such Diku-like gameplay that Verant developers were made to issue a sworn statement that no actual DikuMUD code was incorporated.\nSimutronics.\nIn 1987, David Whatley, having previously played \"Scepter of Goth\" and \"Island of Kesmai\", founded Simutronics with Tom and Susan Zelinski. In the same year they demonstrated a prototype of \"GemStone\" to GEnie. After a short-lived instance of \"GemStone II\", \"GemStone III\" was officially launched in February 1990. \"GemStone III\" became available on AOL in September 1995, followed by the release of \"DragonRealms\" in February 1996. By the end of 1997 \"GemStone III\" and \"DragonRealms\" had become the first and second most played games on AOL.\nGameplay.\nThe typical MUD will describe to the player the room or area they are standing in, listing the objects, players and non-player characters (NPCs) in the area, as well as all of the exits. To carry out a task the player would enter a text command such as take apple or attack dragon. Movement around the game environment is generally accomplished by entering the direction (or an abbreviation of it) in which the player wishes to move, for example typing north or just n would cause the player to exit the current area via the path to the north.\nMUD clients are computer applications that make the MUD telnet interface more accessible to users, with features such as syntax highlighting, keyboard macros, and connection assistance. Prominent clients include TinyTalk, TinyFugue, TinTin++, and zMUD.\nStyle.\nWhile there have been many variations in overall focus, gameplay and features in MUDs, some distinct sub-groups have formed that can be used to help categorize different game mechanics, game genres and non-game uses.\nHack and slash MUDs.\nPerhaps the most common approach to game design in MUDs is to loosely emulate the structure of a \"Dungeons &amp; Dragons\" campaign focused more on fighting and advancement than role-playing. When these MUDs restrict player-killing in favor of player versus environment conflict and questing, they are labeled hack and slash MUDs. This may be considered particularly appropriate since, due to the room-based nature of traditional MUDs, ranged combat is typically difficult to implement, resulting in most MUDs equipping characters mainly with close-combat weapons. This style of game was also historically referred to within the MUD genre as \"adventure games\", but video gaming as a whole has developed a meaning of \"adventure game\" that is greatly at odds with this usage.\nPlayer versus player MUDs.\nMost MUDs restrict player versus player combat, often abbreviated as PK (Player Killing). This is accomplished through hard coded restrictions and various forms of social intervention. MUDs without these restrictions are commonly known as PK MUDs. Taking this a step further are MUDs devoted \"solely\" to this sort of conflict, called pure PK MUDs, the first of which was \"Genocide\" in 1992. \"Genocide\"'s ideas were influential in the evolution of player versus player online gaming.\nRoleplaying MUDs.\nRoleplaying MUDs, generally abbreviated as RP MUDs, encourage or enforce that players act out the role of their playing characters at all times. Some RP MUDs provide an immersive gaming environment, while others only provide a virtual world with no game elements. MUDs where roleplay is enforced and the game world is heavily computer-modeled are sometimes known as roleplay intensive MUDs, or RPIMUDs. In many cases, role-playing MUDs attempt to differentiate themselves from hack and slash types, by dropping the \"MUD\" name entirely, and instead using MUX (Multi-User Experience) or MUSH (Multi-User Shared Hallucination).\nSocial MUDs.\nSocial MUDs de-emphasize game elements in favor of an environment designed primarily for socializing. They are differentiated from talkers by retaining elements beyond online chat, typically online creation as a community activity and some element of role-playing. Often such MUDs have broadly defined contingents of socializers and roleplayers. Server software in the TinyMUD family, or MU*, is traditionally used to implement social MUDs.\nTalkers.\nA less-known MUD variant is the talker, a variety of online chat environment typically based on server software like ew-too or NUTS. Most of the early Internet talkers were LPMuds with the majority of the complex game machinery stripped away, leaving just the communication commands. The first Internet talker was \"Cat Chat\" in 1990.\nEducational MUDs.\nTaking advantage of the flexibility of MUD server software, some MUDs are designed for educational purposes rather than gaming or chat. \"MicroMUSE\" is considered by author Lauren P. Burka to have been the first educational MUD, but it can be argued that its evolution into this role was not complete until 1994, which would make the first of many educational MOOs, \"Diversity University\" in 1993, also the first educational MUD. The MUD medium lends itself naturally to constructionist learning pedagogical approaches. The Mud Institute (TMI) was an LPMud opened in February 1992 as a gathering place for people interested in developing LPMud and teaching LPC after it became clear that Lars Pensj\u00f6 had lost interest in the project. TMI focussed on both the LPMud driver and library, the driver evolving into MudOS. The TMI Mudlib was never officially released, but was influential in the development of other libraries.\nGraphical MUDs.\nA graphical MUD is a MUD that uses computer graphics to represent parts of the virtual world and its visitors. A prominent early graphical MUD was \"Habitat\", written by Randy Farmer and Chip Morningstar for Lucasfilm in 1985. Some graphical MUDs require players to download a special client and the game's artwork, while others provide a rich experience by being website-based. Graphical MUDs range from simply enhancing the user interface (e.g. Wolfery provides an option to set the room picture, but otherwise remains a text-based interaction) to simulating 3D worlds with visual spatial relationships and customized avatar appearances (e.g. Ultima Online provides a rich point-and-click experience).\nGames such as \"Meridian 59\", \"EverQuest\", \"Ultima Online\" and \"Dark Age of Camelot\" were routinely called graphical MUDs in their earlier years. \"RuneScape\" was actually originally intended to be a \"text-based\" MUD, but graphics were added very early in development. However, with the increase in computing power and Internet connectivity during the late 1990s, and the shift of online gaming to the mass market, the term \"graphical MUD\" fell out of favor, being replaced by MMORPG (massively multiplayer online role-playing game) a term coined by Richard Garriott in 1997.\nDevelopment.\nWithin a MUD's technical infrastructure, a mudlib (concatenation of \"MUD library\") defines the rules of the in-game world. Examples of mudlibs include Ain Soph Mudlib, CDlib, Discworld Mudlib, Lima Mudlib, LPUniversity Mudlib, MorgenGrauen Mudlib, Nightmare Mudlib, and TMI Mudlib.\nMUDs that include object-oriented programming can add complex features, such as adding elements to the game world and giving users more ways to interact with it, that MUDs without it cannot.\nCommunity.\nMUD history has been preserved primarily through community sites and blogs and not through mainstream sources with journalistic repute. As of the late 1990s, a website called The Mud Connector has served as a central and curated repository for active MUDs. In 1995, \"The Independent\" reported that over 60,000 people regularly played about 600 MUDs, up from 170 MUDs three years prior. \"The Independent\" also noted distinct patterns of socialization within MUD communities.\nIn 2004, MUDs were relatively popular in the United States and mostly text-based.\nSeraphina Brennan of \"Massively\" wrote that the MUD community was \"in decline\" as of 2009.\nPsychology and engagement.\nSherry Turkle developed a theory that the constant use (and in many cases, overuse) of MUDs allows users to develop different personalities in their environments. She uses examples, dating back to the text-based MUDs of the mid-1990s, showing college students who simultaneously live different lives through characters in separate MUDs, up to three at a time, all while doing schoolwork. The students claimed that it was a way to \"shut off\" their own lives for a while and become part of another reality. Turkle claims that this could present a psychological problem of identity for today's youths.\n\"A Story About A Tree\" is a short essay written by Raph Koster regarding the death of a \"LegendMUD\" player named Karyn, raising the subject of inter-human relationships in virtual worlds.\nObservations of MUD-play show styles of play that can be roughly categorized. Achievers focus on concrete measurements of success such as experience points, levels, and wealth; Explorers investigate every nook and cranny of the game, and evaluate different game mechanical options; Socializers devote most of their energy to interacting with other players; and then there are Killers who focus on interacting negatively with other players, if permitted, killing the other characters or otherwise thwarting their play. Few players play only one way; most exhibit a diverse style. According to Richard Bartle, \"People go there as part of a hero's journey\u2014a means of self-discovery\".\nResearch has suggested that various factors combine in MUDs to provide users with a sense of \"presence\" rather than simply communication.\nGrammatical usage and derived terms.\nAs a noun, the word MUD is variously written MUD, Mud, and mud, depending on speaker and context. It is also used as a verb, with to mud meaning to play or interact with a MUD and mudding referring to the act of doing so. A mudder is one who MUDs. Compound words and portmanteaux such as mudlist, mudsex, and mudflation are also regularly coined. Puns on the \"wet dirt\" meaning of \"mud\" are endemic, as with, for example, the names of the ROM (Rivers of MUD), MUCK, MUSH, and CoffeeMUD codebases and the MUD \"Muddy Waters\".\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nBibliography.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "19539", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=19539", "title": "Metric spaces", "text": ""}
{"id": "19540", "revid": "9092818", "url": "https://en.wikipedia.org/wiki?curid=19540", "title": "Mohammed", "text": ""}
{"id": "19541", "revid": "40414428", "url": "https://en.wikipedia.org/wiki?curid=19541", "title": "Muslims", "text": "Adherents of Islam\nMuslims () are people who adhere to Islam, a monotheistic religion belonging to the Abrahamic tradition. They consider the Quran, the foundational religious text of Islam, to be the verbatim word of the God of Abraham (or \"Allah\") as it was revealed to Muhammad, the last Islamic prophet. Alongside the Quran, Muslims also believe in previous revelations, such as the Tawrat (Torah), the Zabur (Psalms), and the Injeel (Gospel). These earlier revelations are associated with Judaism and Christianity, which are regarded by Muslims as earlier versions of Islam. The majority of Muslims also follow the teachings and practices attributed to Muhammad (\"sunnah\") as recorded in traditional accounts (hadith).\nWith an estimated population of almost 2 billion followers, Muslims comprise around 26% of the world's total population. In descending order, the percentage of people who identify as Muslims on each continental landmass stands at: 45% of Africa, 25% of Asia and Oceania collectively, 6% of Europe, and 1% of the Americas. Additionally, in subdivided geographical regions, the figure stands at: 91% of the Middle East\u2013North Africa, 90% of Central Asia, 65% of the Caucasus, 42% of Southeast Asia, 32% of South Asia, and 42% of sub-Saharan Africa.\nWhile there are several Islamic schools and branches, as well as non-denominational Muslims, the two largest denominations are Sunni Islam (87\u201390% of all Muslims) and Shia Islam (10\u201313% of all Muslims). By sheer numbers, South Asia accounts for the largest portion (31%) of the global Muslim population. By country, Indonesia is the largest in the Muslim world, holding around 12% of all Muslims worldwide; with Pakistan having the second largest number of Muslims in the world after Indonesia. Outside the Muslim-majority countries, India and China are home to the largest (11%) and second-largest (2%) Muslim populations, respectively. Due to high Muslim population growth, Islam is the fastest-growing religion in the world. Muslims have experienced persecution of varying severity, especially in China, India, some parts of Africa, and Southeast Asia.\nEtymology.\nThe word \"muslim\" or \"moslem\" is the active participle of the same verb of which \"isl\u0101m\" is a verbal noun, based on the triliteral \"S-L-M\" \"to be whole, intact\". A female adherent is a muslima (; also transliterated as \"muslimah\"). The plural form in Arabic is \"muslim\u016bn\" () or \"muslim\u012bn\" (), and its feminine equivalent is \"muslim\u0101t\" ().\nThe ordinary word in English is \"Muslim\". For most of the 20th century, the preferred spelling in English was \"Moslem\", but this has now fallen into disuse. That spelling and its pronunciation were opposed by many Muslims in English-speaking countries because the \"s\" was often pronounced with a z sound. This made the word more closely match the Arabic triliteral \"\u1e93-l-m\" (), which has negative meanings and includes the Arabic word for \"the oppressor\". In the United States, the Associated Press instructed news outlets to switch to the spelling \"Muslim\" in 1991, making it the most common spelling thereafter. The last major newspaper in the United Kingdom to use the spelling \"Moslem\" was the \"Daily Mail\", which switched to \"Muslim\" in 2004.\nThe word Mosalman, Mussulman or Musulman (, alternatively \"musalm\u0101n\") is a common equivalent for \"Muslim\" used in Central and South Asia. In English it was sometimes spelled Mussulman and has become archaic in usage; however, cognates of this word remain the standard term for \"Muslim\" in various other European languages. Until at least the mid-1960s, many English-language writers used the term Mohammedans or Mahometans. Although such terms were not necessarily intended to be pejorative, Muslims argue that the terms are offensive because they allegedly imply that Muslims worship Muhammad rather than God. Other obsolete terms include \"Muslimite\" and \"Muslimist\". In medieval Europe, Muslims were commonly called Saracens.\nThe Muslim philologist Ibn al-Anbari said:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;a Muslim is a person who has dedicated his worship exclusively to God, for just as we say in Arabic that something is \u2018\"salima\"\u2019 to a person, meaning that it became solely his own, so in the same way \u2018\"Isl\u0101m\"\u2019 means making one's religion and faith God's alone.\nIn several places in the Quran, the word \"muslim\" conveys a universal meaning, beyond the description of the followers of Muhammad, for example:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\"Abraham was not a Jew, nor a Christian, but he was a true Muslim [], and he was not a polytheist.\" \u2013 Quran 3:67 \n\"Then when Jesus perceived their disbelief he said, 'Who will be my helpers of God.' The disciples said 'We will be the helpers of God; we believe in God and bear witness that we are Muslims [].'\" \u2013 Quran 3:52 Quranic studies scholar Mohsen Goudarzi has argued that in the Quran the word \"d\u012bn\" means \"worship\", the \"isl\u0101m\" means \"monotheism\" and the \"muslim\" means \"monotheist\".\nUntil the 8th century, the term \"muslim\" was more inclusive, including anyone who was considered to be submitting to God (e.g. Christians and Jews), and the term \"mu'min\" was instead used to refer to believers in Islam as a distinct religion.\nQualifier.\nTo become a Muslim and to convert to Islam, it is essential to utter the \"Shahada\" in front of Muslim witnesses, one of the Five Pillars of Islam, a declaration of faith and trust that professes that there is only one God \"(Allah)\" and that Muhammad is God's messenger. It is a set statement normally recited in Arabic: \"a\u0161hadu \u02bean-l\u0101 \u02beil\u0101ha \u02beill\u0101-ll\u0101hu wa \u02bea\u0161hadu \u02beanna mu\u0127ammadan ras\u016blu-ll\u0101h\" () \"I testify that there is no god [worthy of worship] except Allah, and Muhammad is the messenger of Allah.\"\nIn Sunni Islam, the shahada has two parts: \"la ilaha illa'llah\" (there is no god but Allah), and \"Muhammadun rasul Allah\" (Muhammad is the messenger of God), which are sometimes referred to as the first \"shahada\" and the second \"shahada\". The first statement of the shahada is also known as the \"tahl\u012bl\".\nIn Shia Islam, the shahada also has a third part, a phrase concerning Ali, the first Shia Imam and the fourth Rashid caliph of Sunni Islam: (), which translates to \"Ali is the \"wali\" of God\".\nIn Quranist Islam, the shahada is the testimony that there is no god but Allah (\"la ilaha illa'llah\").\nThe religious practices of Muslims are enumerated in the Five Pillars of Islam: the declaration of faith (\"shahadah\"), daily prayers (\"salah\"), almsgiving (\"zakat\"), fasting during the month of Ramadan (\"sawm\"), and the pilgrimage to Mecca (\"hajj\") at least once in a lifetime.\nIn Islamic theology.\nThe majority of theological traditions of Islam accept that works do not determine if someone is a Muslim or not. God alone would know about the belief of a person. Fellow Muslims can only accept the personal declaration of faith. Only the Khaw\u0101rij developed an understanding of Muslim identity based mainly on the adherence to liturgical and legal norms.\nWhen asked about one's beliefs, it is recommended to say the \"Istit\u0332h\u0332n\u0101\u02be\", for example, \"\"in-sha'allah\" I am Muslim a believer\" (so God will, I am Muslim), since only God knows the future of a person. Among Asharites, it is also seen as a sign of humility and the individual's longing to improve, because the creature has no assurance of their own state (of belief) until the end of life.\nThe Qur'an describes many prophets and messengers within Judaism and Christianity, and their respective followers, as Muslim. Some of those that were mentioned are: Adam, Noah, Abraham, Ishmael, Jacob, Moses, and Jesus and his apostles are all considered to be Muslims in the Qur'an. The Qur'an states that these men were Muslims because they submitted to God, preached His message and upheld His values, which included praying, charity, fasting and pilgrimage. Thus, in Surah 3:52 of the Qur'an, Jesus' disciples tell him, \"We believe in God; and you be our witness that we are Muslims (\"wa-shahad be anna muslim\u016bn\").\" In Islamic belief, before the Qur'an, God had given the Tawrat (Torah) to the prophets and messengers among the Children of Israel, the Zabur (Psalms) to David and the Injil (Gospel) to Jesus, who are all considered important Muslim prophets.\nDemographics.\nAccording to Pew estimates, as of 2020, Muslims made up about 25.6% of the global population, or roughly 2 billion people. The growth is mainly due to Muslims having a younger average age and higher birth rates\u2014two key drivers of natural population increase. The most populous Muslim-majority country is Indonesia, home to 12.7% of the world's Muslims, followed by Pakistan (11.0%), Bangladesh (9.2%), Nigeria (5.3%) and Egypt (4.9%). About 20% of the world's Muslims live in the Middle East and North Africa. Non-majority India contains 10.9% of the world's Muslims. Arab Muslims form the largest ethnic group among Muslims in the world, followed by Bengalis, and Punjabis.\nOver 87\u201390% of Muslims are Sunni. The second largest sect, Shia, make up 10\u201313%, whereas other movements such as the Ahmadiyya, Quranism, Ibadism, collectively count for 1% per cent. While the majority of the population in the Middle East identify as either Sunni or Shia, a significant number of Muslims identify as non-denominational.\nWith about 1.8 billion followers (2015), almost a quarter of earth's population, Islam is the second-largest and the fastest-growing religion in the world, primarily due to the young age and high fertility rate of Muslims, with Muslims having a rate of 3.1 compared to the world average of 2.5. According to the same study, religious switching has no impact on the Muslim population, since the number of people who embrace Islam and those who leave Islam are roughly equal. According to a 2020 Pew study, about 1% of adults raised Muslim leave the faith, while a similar share convert to Islam, resulting in low levels of religious switching both into and out of Islam.\nAs of 2010, 49 countries in the world had Muslim majorities, in which Muslims comprised more than 50% of the population. In 2010, 74.1% of the world's Muslim population lived in countries where Muslims are in the majority, while 25.9% of the world's Muslim population lived in countries where Muslims are in the minority. A Pew Center study in 2010 found that 3% of the world's Muslim population lives in non-Muslim-majority developed countries. India's Muslim population is the world's largest Muslim-minority population in the world (11% of the world's Muslim population). Followed by Ethiopia (28 million), China (22 million), Russia (16 million) and Tanzania (13 million). Sizeable minorities are also found in the Americas (5.2 million or 0.6%), Australia (714,000 or 1.9%) and parts of Europe (44 million or 6%). According to a 2020 Pew study, 79% of the world's Muslim population live in Muslim-majority countries, while 21% reside in countries where Muslims are a minority.\nA Pew Center study in 2016 found that Muslims have the highest number of adherents under the age of 15 (34% of the total Muslim population) of any major religion, while only 7% are aged 60+ (the smallest percentage of any major religion). According to the same study, Muslims have the highest fertility rates (3.1) of any major religious group. The study also found that Muslims (tied with Hindus) have the lowest average levels of education with an average of 5.6 years of schooling, though both groups have made the largest gains in educational attainment in recent decades among major religions. About 36% of all Muslims have no formal schooling, and Muslims have the lowest average levels of higher education of any major religious group, with only 8% having graduate and post-graduate degrees.\nCulture.\nMuslim culture or Islamic culture are terms used to describe the cultural practices common to Muslims and historically Islamic people. The early forms of Muslim culture, from the Rashidun Caliphate to early Umayyad period, were predominantly Arab, Byzantine, Persian and Levantine. With the rapid expansion of the Arab Islamic empires, Muslim culture has influenced and assimilated much from the Indonesian, Pakistani (Punjabi, Pashtun, Baloch Kashmiri, Sindhi), Hindustani, Bengali, Nigerian, Egyptian, Persian, Turkic, Caucasian, Malay, Somali, Berber, and Moro cultures.\nReferences.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "19542", "revid": "28903366", "url": "https://en.wikipedia.org/wiki?curid=19542", "title": "MUSH", "text": "Text-based online social medium\nIn multiplayer online games, a MUSH (a backronymed variation on MUD most often expanded as Multi-User Shared Hallucination, though Multi-User Shared Hack, Habitat, and Holodeck are also observed) is a text-based online social medium to which multiple users are connected at the same time. MUSHes are often used for online social interaction and role-playing games, although the first forms of MUSH do not appear to be coded specifically to implement gaming activity. MUSH software was originally derived from MUDs; today's two major MUSH variants are descended from TinyMUD, which was fundamentally a social game.\nMUSH has forked over the years and there are now different varieties with different features, although most have strong similarities and one who is fluent in coding one variety can switch to coding for the other with only a little effort. The source code for most widely used MUSH servers is open source and available from its current maintainers.\nA primary feature of MUSH codebases that tends to distinguish it from other multi-user environments is the ability, by default, of any player to extend the world by creating new rooms or objects and specifying their behavior in the MUSH's internal scripting language. \nThe programming language for MUSH, usually referred to as \"MUSHcode\" or \"softcode\" (to distinguish it from \"hardcode\"\u00a0\u2013 the language in which the MUSH server itself is written) was developed by Larry Foard. TinyMUSH started life as a set of enhancements to the original TinyMUD code. \"MUSHcode\" is similar in syntax to Lisp.\nRoleplay.\nTraditionally, roleplay consists of a series of \"poses\". Each character makes a \"pose\"\u00a0\u2013 that is, writes a description of speech, actions, etc. which the character performs. Special commands allow players to print OOC (out of character) messages, distinguished by a prefixed string from IC (in character) action. This medium borrows traits from both improvisational stage acting and writing. Roleplaying is one of the primary activities of MUSHes, along with socializing.\nThere is nothing in the code base that restricts a new MUSH from being a traditional hack-and-slash MUD-style game. However, the earliest uses of MUSH servers were for roleplaying and socializing, and these early trends have largely governed their descendants.\nAdministration.\nAll MUSH servers provide a flag that, when set on a player, bestows the ability to view and modify nearly everything in the game's database. Such players are usually called Wizards, and typically form the basis for the MUSH administration.\nSoftware.\nMaintainers and developers of MUSH servers have traditionally shared ideas with one another, so most MUSH servers include concepts or code developed originally in other servers. There is particular interest in ensuring that common MUSHcode features work similarly across servers.\nPennMUSH, TinyMUSH, TinyMUX and RhostMUSH are all open-source MUSH servers\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "19543", "revid": "25859633", "url": "https://en.wikipedia.org/wiki?curid=19543", "title": "Mathematical Function", "text": ""}
{"id": "19544", "revid": "28481209", "url": "https://en.wikipedia.org/wiki?curid=19544", "title": "Microevolution", "text": "Change in allele frequencies that occurs over time within a population\nMicroevolution is the change in allele frequencies that occurs over time within a population. This change is due to four different processes: mutation, selection (natural and artificial), gene flow and genetic drift. This change happens over a relatively short (in evolutionary terms) amount of time compared to the changes termed macroevolution.\nPopulation genetics is the branch of biology that provides the mathematical structure for the study of the process of microevolution. Ecological genetics concerns itself with observing microevolution in the wild. Typically, observable instances of evolution are examples of microevolution; for example, bacterial strains that have antibiotic resistance.\nMicroevolution provides the raw material for macroevolution.\nDifference from macroevolution.\nMacroevolution is guided by sorting of interspecific variation (\"species selection\"), as opposed to sorting of intraspecific variation in microevolution. Species selection may occur as (a) effect-macroevolution, where organism-level traits (aggregate traits) affect speciation and extinction rates, and (b) strict-sense species selection, where species-level traits (e.g. geographical range) affect speciation and extinction rates. Macroevolution does not produce evolutionary novelties, but it determines their proliferation within the clades in which they evolved, and it adds species-level traits as non-organismic factors of sorting to this process.\nFour processes.\nMutation.\nMutations are changes in the DNA sequence of a cell's genome and are caused by radiation, viruses, transposons and mutagenic chemicals, as well as errors that occur during meiosis or DNA replication. Errors are introduced particularly often in the process of DNA replication, in the polymerization of the second strand. These errors can also be induced by the organism itself, by cellular processes such as hypermutation. Mutations can affect the phenotype of an organism, especially if they occur within the protein coding sequence of a gene. Error rates are usually very low\u20141 error in every 10\u2013100\u00a0million bases\u2014due to the proofreading ability of DNA polymerases. (Without proofreading error rates are a thousandfold higher; because many viruses rely on DNA and RNA polymerases that lack proofreading ability, they experience higher mutation rates.) Processes that increase the rate of changes in DNA are called mutagenic: mutagenic chemicals promote errors in DNA replication, often by interfering with the structure of base-pairing, while UV radiation induces mutations by causing damage to the DNA structure. Chemical damage to DNA occurs naturally as well, and cells use DNA repair mechanisms to repair mismatches and breaks in DNA\u2014nevertheless, the repair sometimes fails to return the DNA to its original sequence.\nIn organisms that use chromosomal crossover to exchange DNA and recombine genes, errors in alignment during meiosis can also cause mutations. Errors in crossover are especially likely when similar sequences cause partner chromosomes to adopt a mistaken alignment making some regions in genomes more prone to mutating in this way. These errors create large structural changes in DNA sequence\u2014duplications, inversions or deletions of entire regions, or the accidental exchanging of whole parts between different chromosomes (called translocation).\nMutation can result in several different types of change in DNA sequences; these can either have no effect, alter the product of a gene, or prevent the gene from functioning. Studies in the fly \"Drosophila melanogaster\" suggest that if a mutation changes a protein produced by a gene, this will probably be harmful, with about 70 percent of these mutations having damaging effects, and the remainder being either neutral or weakly beneficial. Due to the damaging effects that mutations can have on cells, organisms have evolved mechanisms such as DNA repair to remove mutations. Therefore, the optimal mutation rate for a species is a trade-off between costs of a high mutation rate, such as deleterious mutations, and the metabolic costs of maintaining systems to reduce the mutation rate, such as DNA repair enzymes. Viruses that use RNA as their genetic material have rapid mutation rates, which can be an advantage since these viruses will evolve constantly and rapidly, and thus evade the defensive responses of e.g. the human immune system.\nMutations can involve large sections of DNA becoming duplicated, usually through genetic recombination. These duplications are a major source of raw material for evolving new genes, with tens to hundreds of genes duplicated in animal genomes every million years. Most genes belong to larger families of genes of shared ancestry. Novel genes are produced by several methods, commonly through the duplication and mutation of an ancestral gene, or by recombining parts of different genes to form new combinations with new functions.\nHere, domains act as modules, each with a particular and independent function, that can be mixed together to produce genes encoding new proteins with novel properties. For example, the human eye uses four genes to make structures that sense light: three for color vision and one for night vision; all four arose from a single ancestral gene. Another advantage of duplicating a gene (or even an entire genome) is that this increases redundancy; this allows one gene in the pair to acquire a new function while the other copy performs the original function. Other types of mutation occasionally create new genes from previously noncoding DNA.\nSelection.\n\"Selection\" is the process by which heritable traits that make it more likely for an organism to survive and successfully reproduce become more common in a population over successive generations.\nIt is sometimes valuable to distinguish between naturally occurring selection, natural selection, and selection that is a manifestation of choices made by humans, artificial selection. This distinction is rather diffuse. Natural selection is nevertheless the dominant part of selection.\nThe natural genetic variation within a population of organisms means that some individuals will survive more successfully than others in their current environment. Factors which affect reproductive success are also important, an issue which Charles Darwin developed in his ideas on sexual selection.\nNatural selection acts on the phenotype, or the observable characteristics of an organism, but the genetic (heritable) basis of any phenotype which gives a reproductive advantage will become more common in a population (see allele frequency). Over time, this process can result in adaptations that specialize organisms for particular ecological niches and may eventually result in the speciation (the emergence of new species).\nNatural selection is one of the cornerstones of modern biology. The term was introduced by Darwin in his groundbreaking 1859 book \"On the Origin of Species\", in which natural selection was described by analogy to artificial selection, a process by which animals and plants with traits considered desirable by human breeders are systematically favored for reproduction. The concept of natural selection was originally developed in the absence of a valid theory of heredity; at the time of Darwin's writing, nothing was known of modern genetics. The union of traditional Darwinian evolution with subsequent discoveries in classical and molecular genetics is termed the \"modern evolutionary synthesis\". Natural selection remains the primary explanation for adaptive evolution.\nGenetic drift.\nGenetic drift is the change in the relative frequency in which a gene variant (allele) occurs in a population due to random sampling. That is, the alleles in the offspring in the population are a random sample of those in the parents. And chance has a role in determining whether a given individual survives and reproduces. A population's allele frequency is the fraction or percentage of its gene copies compared to the total number of gene alleles that share a particular form.\nGenetic drift is an evolutionary process which leads to changes in allele frequencies over time. It may cause gene variants to disappear completely, and thereby reduce genetic variability. In contrast to natural selection, which makes gene variants more common or less common depending on their reproductive success, the changes due to genetic drift are not driven by environmental or adaptive pressures, and may be beneficial, neutral, or detrimental to reproductive success.\nThe effect of genetic drift is larger in small populations, and smaller in large populations. Vigorous debates wage among scientists over the relative importance of genetic drift compared with natural selection. Ronald Fisher held the view that genetic drift plays at the most a minor role in evolution, and this remained the dominant view for several decades. In 1968 Motoo Kimura rekindled the debate with his neutral theory of molecular evolution which claims that most of the changes in the genetic material are caused by genetic drift. The predictions of neutral theory, based on genetic drift, do not fit recent data on whole genomes well: these data suggest that the frequencies of neutral alleles change primarily due to selection at linked sites, rather than due to genetic drift by means of sampling error.\nGene flow.\nGene flow is the exchange of genes between populations, which are usually of the same species. Examples of gene flow within a species include the migration and then breeding of organisms, or the exchange of pollen. Gene transfer between species includes the formation of hybrid organisms and horizontal gene transfer.\nMigration into or out of a population can change allele frequencies, as well as introducing genetic variation into a population. Immigration may add new genetic material to the established gene pool of a population. Conversely, emigration may remove genetic material. As barriers to reproduction between two diverging populations are required for the populations to become new species, gene flow may slow this process by spreading genetic differences between the populations. Gene flow is hindered by mountain ranges, oceans and deserts or even man-made structures such as the Great Wall of China, which has hindered the flow of plant genes.\nDepending on how far two species have diverged since their most recent common ancestor, it may still be possible for them to produce offspring, as with horses and donkeys mating to produce mules. Such hybrids are generally infertile, due to the two different sets of chromosomes being unable to pair up during meiosis. In this case, closely related species may regularly interbreed, but hybrids will be selected against and the species will remain distinct. However, viable hybrids are occasionally formed and these new species can either have properties intermediate between their parent species, or possess a totally new phenotype. The importance of hybridization in developing new species of animals is unclear, although cases have been seen in many types of animals, with the gray tree frog being a particularly well-studied example.\nHybridization is, however, an important means of speciation in plants, since polyploidy (having more than two copies of each chromosome) is tolerated in plants more readily than in animals. Polyploidy is important in hybrids as it allows reproduction, with the two different sets of chromosomes each being able to pair with an identical partner during meiosis. Polyploid hybrids also have more genetic diversity, which allows them to avoid inbreeding depression in small populations.\nHorizontal gene transfer is the transfer of genetic material from one organism to another organism that is not its offspring; this is most common among bacteria. In medicine, this contributes to the spread of antibiotic resistance, as when one bacteria acquires resistance genes it can rapidly transfer them to other species. Horizontal transfer of genes from bacteria to eukaryotes such as the yeast \"Saccharomyces cerevisiae\" and the adzuki bean beetle \"Callosobruchus chinensis\" may also have occurred. An example of larger-scale transfers are the eukaryotic bdelloid rotifers, which appear to have received a range of genes from bacteria, fungi, and plants. Viruses can also carry DNA between organisms, allowing transfer of genes even across biological domains. Large-scale gene transfer has also occurred between the ancestors of eukaryotic cells and prokaryotes, during the acquisition of chloroplasts and mitochondria.\n\"Gene flow\" is the transfer of alleles from one population to another.\nMigration into or out of a population may be responsible for a marked change in allele frequencies. Immigration may also result in the addition of new genetic variants to the established gene pool of a particular species or population.\nThere are a number of factors that affect the rate of gene flow between different populations. One of the most significant factors is mobility, as greater mobility of an individual tends to give it greater migratory potential. Animals tend to be more mobile than plants, although pollen and seeds may be carried great distances by animals or wind.\nMaintained gene flow between two populations can also lead to a combination of the two gene pools, reducing the genetic variation between the two groups. It is for this reason that gene flow strongly acts against speciation, by recombining the gene pools of the groups, and thus, repairing the developing differences in genetic variation that would have led to full speciation and creation of daughter species.\nFor example, if a species of grass grows on both sides of a highway, pollen is likely to be transported from one side to the other and vice versa. If this pollen is able to fertilise the plant where it ends up and produce viable offspring, then the alleles in the pollen have effectively been able to move from the population on one side of the highway to the other.\nOrigin and extended use of the term.\nOrigin.\nThe term \"microevolution\" was first used by botanist Robert Greenleaf Leavitt in the journal \"Botanical Gazette\" in 1909, addressing what he called the \"mystery\" of how formlessness gives rise to form.\n\"..The production of form from formlessness in the egg-derived individual, the multiplication of parts and the orderly creation of diversity among them, in an actual evolution, of which anyone may ascertain the facts, but of which no one has dissipated the mystery in any significant measure. This microevolution forms an integral part of the grand evolution problem and lies at the base of it, so that we shall have to understand the minor process before we can thoroughly comprehend the more general one...\"\nHowever, Leavitt was using the term to describe what we would now call developmental biology; it was not until Russian Entomologist Yuri Filipchenko used the terms \"macroevolution\" and \"microevolution\" in 1927 in his German language work, \"Variabilit\u00e4t und Variation\", that it attained its modern usage. The term was later brought into the English-speaking world by Filipchenko's student Theodosius Dobzhansky in his book Genetics and the Origin of Species (1937).\nUse in creationism.\nIn young Earth creationism and baraminology a central tenet is that evolution can explain diversity in a limited number of created kinds which can interbreed (which they call \"microevolution\") while the formation of new \"kinds\" (which they call \"macroevolution\") is impossible. This acceptance of \"microevolution\" only within a \"kind\" is also typical of old Earth creationism.\nScientific organizations such as the American Association for the Advancement of Science describe microevolution as small scale change within species, and macroevolution as the formation of new species, but otherwise not being different from microevolution. In macroevolution, an accumulation of microevolutionary changes leads to speciation. The main difference between the two processes is that one occurs within a few generations, whilst the other takes place over thousands of years (i.e. a quantitative difference). Essentially they describe the same process; although evolution beyond the species level results in beginning and ending generations which could not interbreed, the intermediate generations could.\nOpponents to creationism argue that changes in the number of chromosomes can be accounted for by intermediate stages in which a single chromosome divides in generational stages, or multiple chromosomes fuse, and cite the chromosome difference between humans and the other great apes as an example. Creationists insist that since the actual divergence between the other great apes and humans was not observed, the evidence is circumstantial.\nDescribing the fundamental similarity between macro and microevolution in his authoritative textbook \"Evolutionary Biology,\" biologist Douglas Futuyma writes,\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;One of the most important tenets of the theory forged during the Evolutionary Synthesis of the 1930s and 1940s was that \"macroevolutionary\" differences among organisms - those that distinguish higher taxa - arise from the accumulation of the same kinds of genetic differences that are found within species. Opponents of this point of view believed that \"macroevolution\" is qualitatively different from \"microevolution\" within species, and is based on a totally different kind of genetic and developmental patterning... Genetic studies of species differences have decisively disproved [this] claim. \"Differences between species\" in morphology, behavior, and the processes that underlie reproductive isolation all \"have the same genetic properties as variation within species\": they occupy consistent chromosomal positions, they may be polygenic or based on few genes, they may display additive, dominant, or epistatic effects, and they can in some instances be traced to specifiable differences in proteins or DNA nucleotide sequences. \"The degree of reproductive isolation between populations,\" whether prezygotic or postzygotic, \"varies from little or none to complete\". Thus, \"reproductive isolation, like the divergence of any other character, evolves in most cases by the gradual substitution of alleles in populations\".\nContrary to the claims of some antievolution proponents, evolution of life forms beyond the species level (i.e. speciation) has indeed been observed and documented by scientists on numerous occasions. In creation science, creationists accepted speciation as occurring within a \"created kind\" or \"baramin\", but objected to what they called \"third level-macroevolution\" of a new genus or higher rank in taxonomy. There is ambiguity in the ideas as to where to draw a line on \"species\", \"created kinds\", and what events and lineages fall within the rubric of microevolution or macroevolution.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "19545", "revid": "27823944", "url": "https://en.wikipedia.org/wiki?curid=19545", "title": "MySQL", "text": "SQL database engine software\nMySQL () is an open-source relational database management system (RDBMS). Its name is a combination of \"My\", the name of co-founder Michael Widenius's daughter My, and \"SQL\", the acronym for Structured Query Language. A relational database organizes data into one or more data tables in which data may be related to each other; these relations help structure the data. SQL is a language that programmers use to create, modify and extract data from the relational database, as well as control user access to the database. In addition to relational databases and SQL, an RDBMS like MySQL works with an operating system to implement a relational database in a computer's storage system, manages users, allows for network access and facilitates testing database integrity and creation of backups.\nMySQL is free and open-source software under the terms of the GNU General Public License, and is also available under a variety of proprietary licenses. MySQL was owned and sponsored by the Swedish company MySQL AB, which was bought by Sun Microsystems (now Oracle Corporation). In 2010, when Oracle acquired Sun, Widenius forked the open-source MySQL project to create MariaDB.\nMySQL has stand-alone clients that allow users to interact directly with a MySQL database using SQL, but more often, MySQL is used with other programs to implement applications that need relational database capability. MySQL is a component of the LAMP web application software stack (and others), which is an acronym for \"Linux, Apache, MySQL, Perl/PHP/Python\". MySQL is used by many database-driven web applications, including Drupal, Joomla, phpBB, and WordPress. MySQL is also used by many popular websites, including Facebook, Flickr, MediaWiki, Twitter, and YouTube.\nOverview.\nMySQL is written in C and C++. Its SQL parser is written in yacc, but it uses a home-brewed lexical analyzer. MySQL works on many system platforms, including AIX, BSDi, FreeBSD, HP-UX, ArcaOS, eComStation, IBM i, IRIX, Linux, macOS, Microsoft Windows, NetBSD, Novell NetWare, OpenBSD, OpenSolaris, OS/2 Warp, QNX, Oracle Solaris, Symbian, SunOS, SCO OpenServer, SCO UnixWare, Sanos and Tru64. A port of MySQL to OpenVMS also exists.\nThe MySQL server software itself and the client libraries use dual-licensing distribution. They are offered under GPL version 2, or a proprietary license.\nSupport can be obtained from the official manual. Free support additionally is available in different IRC channels and forums. Oracle offers paid support via its MySQL Enterprise products. They differ in the scope of services and in price. Additionally, a number of third party organisations exist to provide support and services.\nMySQL has received positive reviews, and reviewers noticed it \"performs extremely well in the average case\" and that the \"developer interfaces are there, and the documentation (not to mention feedback in the real world via Web sites and the like) is very, very good\". It has also been tested to be a \"fast, stable and true multi-user, multi-threaded SQL database server\".\nHistory.\n&lt;templatestyles src=\"Stack/styles.css\"/&gt;\nMySQL was created by a Swedish company, MySQL AB, founded by Swedes David Axmark and Allan Larsson, along with Finn Michael \"Monty\" Widenius.\nOriginal development of MySQL by Widenius and Axmark began in 1994. The first version of MySQL appeared on 23 May 1995. It was initially created for personal usage from mSQL based on the low-level language ISAM, which the creators considered too slow and inflexible. They created a new SQL interface, while keeping the same API as mSQL. By keeping the API consistent with the mSQL system, many developers were able to use MySQL instead of the (proprietarily licensed) mSQL antecedent.\nMilestones.\nAdditional milestones in MySQL development included:\nRelease history.\nWork on version 6 stopped after the Sun Microsystems acquisition. The MySQL Cluster product uses version 7. The decision was made to jump to version 8 as the next major version number.\nLegal disputes and acquisitions.\nOn 15 June 2001, NuSphere sued MySQL AB, TcX DataKonsult AB and its original authors Michael (\"Monty\") Widenius and David Axmark in U.S. District Court in Boston for \"breach of contract, tortious interference with third party contracts and relationships and unfair competition\".\nIn 2002, MySQL AB sued Progress NuSphere for copyright and trademark infringement in United States district court. NuSphere had allegedly violated MySQL AB's copyright by linking MySQL's GPL'ed code with NuSphere Gemini table without being in compliance with the license. After a preliminary hearing before Judge Patti Saris on 27 February 2002, the parties entered settlement talks and eventually settled. After the hearing, FSF commented that \"Judge Saris made clear that she sees the GNU GPL to be an enforceable and binding license.\"\nIn October 2005, Oracle Corporation acquired Innobase OY, the Finnish company that developed the third-party InnoDB storage engine that allows MySQL to provide such functionality as transactions and foreign keys. After the acquisition, an Oracle press release mentioned that the contracts that make the company's software available to MySQL AB would be due for renewal (and presumably renegotiation) some time in 2006. During the MySQL Users Conference in April 2006, MySQL AB issued a press release that confirmed that MySQL AB and Innobase OY agreed to a \"multi-year\" extension of their licensing agreement.\nIn February 2006, Oracle Corporation acquired Sleepycat Software, makers of the Berkeley DB, a database engine providing the basis for another MySQL storage engine. This had little effect, as Berkeley DB was not widely used, and was dropped (due to lack of use) in MySQL 5.1.12, a pre-GA release of MySQL 5.1 released in October 2006.\nIn January 2008, Sun Microsystems bought MySQL AB for $1 billion.\nIn April 2009, Oracle Corporation entered into an agreement to purchase Sun Microsystems, then owners of MySQL copyright and trademark. Sun's board of directors unanimously approved the deal. It was also approved by Sun's shareholders, and by the U.S. government on 20 August 2009. On 14 December 2009, Oracle pledged to continue to enhance MySQL as it had done for the previous four years.\nA movement against Oracle's acquisition of MySQL AB, to \"Save MySQL\" from Oracle was started by one of the MySQL AB founders, Monty Widenius. The petition of 50,000+ developers and users called upon the European Commission to block approval of the acquisition. At the same time, some Free Software opinion leaders (including Pamela Jones of Groklaw, Jan Wildeboer and Carlo Piana, who also acted as co-counsel in the merger regulation procedure) advocated for the unconditional approval of the merger. As part of the negotiations with the European Commission, Oracle committed that MySQL server will continue until at least 2015 to use the dual-licensing strategy long used by MySQL AB, with proprietary and GPL versions available. The antitrust of the EU had been \"pressuring it to divest MySQL as a condition for approval of the merger\". But the US Department of Justice, at the request of Oracle, pressured the EU to approve the merger unconditionally. The European Commission eventually unconditionally approved Oracle's acquisition of MySQL AB on 21 January 2010.\nIn January 2010, before Oracle's acquisition of MySQL AB, Monty Widenius started a GPL-only fork, MariaDB. MariaDB is based on the same code base as MySQL server 5.5 and aims to maintain compatibility with Oracle-provided versions.\nFeatures.\nMySQL is offered under two different editions: the open source MySQL Community Server and the proprietary Enterprise Server. MySQL Enterprise Server is differentiated by a series of proprietary extensions which install as server plugins, but otherwise shares the version numbering system and is built from the same code base.\nMajor features as available in MySQL 5.6:\nThe developers release minor updates of the MySQL Server approximately every two months. The sources can be obtained from MySQL's website or from MySQL's GitHub repository, both under the GPL license.\nLimitations.\nWhen using some storage engines other than the default of InnoDB, MySQL does not comply with the full SQL standard for some of the implemented functionality, including foreign key references. Check constraints are parsed but ignored by all storage engines before MySQL version 8.0.15.\nUp until MySQL 5.7, triggers are limited to one per action / timing, meaning that at most one trigger can be defined to be executed after an INSERT operation, and one before INSERT on the same table.\nNo triggers can be defined on views.\nBefore MySQL 8.0.28, inbuilt functions like UNIX_TIMESTAMP() would return 0 after 03:14:07 UTC on 19 January 2038. In 2017, an attempt to solve the problem was submitted, but was not used for the final solution that was shipped in 2022.\nDeployment.\nMySQL can be built and installed manually from source code, but it is more commonly installed from a binary package unless special customizations are required. On most Linux distributions, the package management system can download and install MySQL with minimal effort, though further configuration is often required to adjust security and optimization settings.\nThough MySQL began as a low-end alternative to more powerful proprietary databases, it has gradually evolved to support higher-scale needs as well. It is still most commonly used in small to medium scale single-server deployments, either as a component in a LAMP-based web application or as a standalone database server. Much of MySQL's appeal originates in its relative simplicity and ease of use, which is enabled by an ecosystem of open source tools such as phpMyAdmin.\nIn the medium range, MySQL can be scaled by deploying it on more powerful hardware, such as a multi-processor server with gigabytes of memory.\nThere are, however, limits to how far performance can scale on a single server ('scaling up'), so on larger scales, multi-server MySQL ('scaling out') deployments are required to provide improved performance and reliability. A typical high-end configuration can include a powerful source database (formerly known as master database) which handles data write operations and is replicated to multiple replicas (formerly known as slaves) that handle all read operations. The source server continually pushes binlog events to connected replicas so in the event of failure a replica can be promoted to become the new source, minimizing downtime. Further improvements in performance can be achieved by caching the results from database queries in memory using memcached, or breaking down a database into smaller chunks called shards which can be spread across a number of distributed server clusters.\nHigh availability software.\nOracle MySQL offers a high availability solution with a mix of tools including the MySQL router and the MySQL shell. They are based on Group Replication, open source tools.\nMariaDB offers a similar offer in terms of products.\nCloud deployment.\nMySQL can also be run on cloud computing platforms such as Microsoft Azure, Amazon Elastic Compute Cloud, and Oracle Cloud Infrastructure. Some common deployment models for MySQL on the cloud are:\nVirtual machine image.\nIn this implementation, cloud users can upload a machine image of their own with MySQL installed, or use a ready-made machine image with an optimized installation of MySQL on it, such as the one provided by Amazon EC2.\nMySQL as a service.\nSome cloud platforms offer MySQL \"as a service\". In this configuration, application owners do not have to install and maintain the MySQL database on their own. Instead, the database service provider takes responsibility for installing and maintaining the database, and application owners pay according to their usage. Notable cloud-based MySQL services are the Amazon Relational Database Service; Oracle MySQL HeatWave Database Service, Azure Database for MySQL, Rackspace; HP Converged Cloud; Heroku and Jelastic. In this model the database service provider takes responsibility for maintaining the host and database.\nUser interfaces.\nGraphical user interfaces.\nA graphical user interface (GUI) is a type of interface that allows users to interact with electronic devices or programs through graphical icons and visual indicators such as secondary notation, as opposed to text-based interfaces, typed command labels or text navigation.\nThird-party proprietary and free graphical administration applications (or \"front ends\") are available that integrate with MySQL and enable users to work with database structure and data visually.\nMySQL Workbench.\nMySQL Workbench is the integrated environment for MySQL. It was developed by MySQL AB, and enables users to graphically administer MySQL databases and visually design database structures.\nMySQL Workbench is available in three editions, the regular free and open source \"Community Edition\" which may be downloaded from the MySQL website, and the proprietary \"Standard Edition\" which extends and improves the feature set of the Community Edition, and the MySQL Cluster CGE.\nCommand-line interfaces.\nA command-line interface is a means of interacting with a computer program where the user issues commands to the program by typing in successive lines of text (command lines). MySQL ships with many command line tools, from which the main interface is the mysql client.\nMySQL Utilities is a set of utilities designed to perform common maintenance and administrative tasks. Originally included as part of the MySQL Workbench, the utilities are a stand-alone download available from Oracle.\nPercona Toolkit is a cross-platform toolkit for MySQL, developed in Perl. Percona Toolkit can be used to prove replication is working correctly, fix corrupted data, automate repetitive tasks, and speed up servers. Percona Toolkit is included with several Linux distributions such as CentOS and Debian, and packages are available for Fedora and Ubuntu as well. Percona Toolkit was originally developed as Maatkit, but as of late 2011, Maatkit is no longer developed.\nMySQL shell is a tool for interactive use and administration of the MySQL database. It supports JavaScript, Python or SQL modes and it can be used for administration and access purposes.\nApplication programming interfaces.\nMany programming languages with language-specific APIs include libraries for accessing MySQL databases. These include MySQL Connector/Net for .NET/CLI Languages, and the JDBC driver for Java. MySQL offers Connector/C++ for interfacing with C++ in namespace codice_1.\nIn addition, an ODBC interface called MySQL Connector/ODBC allows additional programming languages that support the ODBC interface to communicate with a MySQL database, such as ASP or ColdFusion. The HTSQL\u00a0\u2013 URL-based query method also ships with a MySQL adapter, allowing direct interaction between a MySQL database and any web client via structured URLs. Other drivers exists for languages like Python or Node.js.\nProject forks.\nA variety of MySQL forks exist, including the following:\nCurrent.\nMariaDB.\nMariaDB is a community-developed fork of the MySQL relational database management system intended to remain free under the GNU GPL. The fork has been led by the original developers of MySQL, who forked it due to concerns over its acquisition by Oracle.\nPercona Server for MySQL.\nPercona Server for MySQL, forked by Percona, aims to retain close compatibility to the official MySQL releases. Also included in Percona Server for MySQL is XtraDB, Percona's fork of the InnoDB Storage Engine.\nAbandoned.\nDrizzle.\nDrizzle was a free software/open source relational database management system (DBMS) that was forked from the now-defunct 6.0 development branch of the MySQL DBMS. Like MySQL, Drizzle had a client/server architecture and uses SQL as its primary command language. Drizzle was distributed under version 2 and 3 of the GNU General Public License (GPL) with portions, including the protocol drivers and replication messaging under the BSD license.\nWebScaleSQL.\nWebScaleSQL was a software branch of MySQL 5.6, and was announced on 27 March 2014 by Facebook, Google, LinkedIn and Twitter as a joint effort to provide a centralized development structure for extending MySQL with new features specific to its large-scale deployments, such as building large replicated databases running on server farms. Thus, WebScaleSQL opened a path toward deduplicating the efforts each company had been putting into maintaining its own branch of MySQL, and toward bringing together more developers. By combining the efforts of these companies and incorporating various changes and new features into MySQL, WebScaleSQL aimed at supporting the deployment of MySQL in large-scale environments. The project's source code is licensed under version 2 of the GNU General Public License, and is hosted on GitHub.\nOurDelta.\nThe OurDelta distribution, created by the Australian company Open Query (later acquired by Catalyst IT Australia), had two versions: 5.0, which was based on MySQL, and 5.1, which was based on MariaDB. It included patches developed by Open Query and by other notable members of the MySQL community including Jeremy Cole and Google. Once the patches were incorporated into the MariaDB mainline, OurDelta's objectives were achieved and OurDelta passed on its build and packaging toolchain to Monty Program (now MariaDB Plc).\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nExternal links.\n&lt;templatestyles src=\"Sister-inline/styles.css\"/&gt; Media related to at Wikimedia Commons"}
{"id": "19546", "revid": "194203", "url": "https://en.wikipedia.org/wiki?curid=19546", "title": "MULTICS", "text": ""}
{"id": "19547", "revid": "998182", "url": "https://en.wikipedia.org/wiki?curid=19547", "title": "Modernism", "text": "Cultural and artistic movement\nModernism was an early 20th-century movement in literature, visual arts, performing arts, and music that emphasized experimentation, abstraction, and subjective experience. Philosophy, politics, architecture, and social issues were all aspects of this movement. Modernism centered around beliefs in a \"growing alienation\" from prevailing \"morality, optimism, and convention\" and a desire to change how \"human beings in a society interact and live together\".\nThe modernist movement emerged during the late 19th century in response to significant changes in Western culture, including secularization and the growing influence of science. It is characterized by a self-conscious rejection of tradition and the search for newer means of cultural expression. Modernism was influenced by widespread technological innovation, industrialization, and urbanization, as well as the cultural and geopolitical shifts that occurred after World War I. Artistic movements and techniques associated with modernism include abstract art, literary stream-of-consciousness, cinematic montage, musical atonality and twelve-tonality, modern dance, modernist architecture, and urban planning.\nModernism took a critical stance towards the Enlightenment concept of rationalism. The movement also rejected the concept of absolute originality \u2014 the idea of \"Creatio ex nihilo\" creation out of nothing \u2014 upheld in the 19th century by both realism and Romanticism, replacing it with techniques of collage, reprise, incorporation, rewriting, recapitulation, revision, and parody. Another feature of modernism was reflexivity about artistic and social convention, which led to experimentation highlighting how works of art are made as well as the material from which they are created. Debate about the timeline of modernism continues, with some scholars arguing that it evolved into late modernism or high modernism. Postmodernism, meanwhile, rejects many of the principles of modernism.\nOverview and definition.\nModernism was a cultural movement that impacted the arts as well as the broader \"Zeitgeist\". It is commonly described as a system of thought and behavior marked by self-consciousness or self-reference, prevalent within the avant-garde of various arts and disciplines. It is also often perceived, especially in the West, as a socially progressive movement that affirms the power of human beings to create, improve, and reshape their environment with the aid of practical experimentation, scientific knowledge, or technology. From this perspective, modernism encourages the re-examination of every aspect of existence. Modernists analyze topics to find the ones they believe to be holding back progress, replacing them with new ways of reaching the same end.\nAccording to historian Roger Griffin, modernism can be defined as a broad cultural, social, or political initiative sustained by the ethos of \"the temporality of the new\". Griffin believed that modernism aspired to restore a \"sense of sublime order and purpose to the contemporary world, thereby counteracting the (perceived) erosion of an overarching 'nomos', or 'sacred canopy', under the fragmenting and secularizing impact of modernity\". Therefore, phenomena apparently unrelated to each other such as \"Expressionism, Futurism, Vitalism, Theosophy, Psychoanalysis, Nudism, Eugenics, Utopian town planning and architecture, modern dance, Bolshevism, Organic Nationalism \u2014 and even the cult of self-sacrifice that sustained the Hecatomb of the First World War \u2014 disclose a common cause and psychological matrix in the fight against (perceived) decadence.\" All of them embody bids to access a \"supra-personal experience of reality\" in which individuals believed they could transcend their mortality and eventually that they would cease to be victims of history to instead become its creators.\nReligion was similarly influenced by new scientific, philosophical and political developments of the late 19th and early 20th centuries, and this led to the development of Catholic modernism. T. S. Eliot was influenced by Catholic Modernism.\nWriting in the \"Catholic Encyclopedia\" in 1911, the Jesuit Arthur Vermeersch gave a definition of modernism in the perspective of the Catholic heresiology of his time:\"In general we may say that modernism aims at that radical transformation of human thought in relation to God, man, the world, and life, here and hereafter, which was prepared by Humanism and eighteenth-century philosophy, and solemnly promulgated at the French Revolution.\"\nModernism, Romanticism, Philosophy and Symbol.\nLiterary modernism is often summed up in a line from W. B. Yeats: \"Things fall apart; the centre cannot hold\" (in \"The Second Coming\"). Modernists often search for a metaphysical \"center\" but experience its collapse. (Postmodernism, by way of contrast, celebrates that collapse, exposing the failure of metaphysics, such as Jacques Derrida's deconstruction of metaphysical claims.)\nPhilosophically, the collapse of metaphysics can be traced back to the Scottish philosopher David Hume (1711\u20131776), who argued that one never actually perceives one event causing another; similarly, Hume argued that we never know the self as object, only the self as subject, and we are thus blind to our true natures. Moreover, if we only 'know' through sensory experience\u2014such as sight, touch and feeling\u2014then we cannot 'know' and neither can we make metaphysical claims.\nThus, modernism can be driven emotionally by the desire for metaphysical truths, while understanding their impossibility. Some modernist novels, for instance, feature characters like Marlow in \"Heart of Darkness\" or Nick Carraway in \"The Great Gatsby\" who believe that they have encountered some great truth about nature or character, truths that the novels themselves treat ironically while offering more mundane explanations. Similarly, many poems of Wallace Stevens convey a struggle with the sense of nature's significance, falling under two headings: poems in which the speaker denies that nature has meaning, only for nature to loom up by the end of the poem; and poems in which the speaker claims nature has meaning, only for that meaning to collapse by the end of the poem.\nModernism often rejects nineteenth century realism, \"if\" the latter is understood as focusing on the embodiment of meaning within a naturalistic representation. At the same time, some modernists aim at a more 'real' realism, one that is uncentered. Picasso's protocubist painting, Les Demoiselles d'Avignon of 1907 (see picture above), does not present its subjects from a single point of view (that of a single viewer), but instead presents a flat, two-dimensional picture plane. \"The Poet\" of 1911 is similarly decentered, presenting the body from multiple points of view. As the Peggy Guggenheim Collection website puts it, 'Picasso presents multiple views of each object, as if he had moved around it, and synthesizes them into a single compound image'.\nModernism, with its sense that \"things fall apart,\" can be seen as the apotheosis of romanticism, if romanticism is the (often frustrated) quest for metaphysical truths about character, nature, a higher power and meaning in the world. Modernism often yearns for a romantic or metaphysical center, but later finds its collapse.\nThis distinction between modernism and romanticism extends to their respective treatments of 'symbol'. The romantics at times see an essential relation (the 'ground') between the symbol (or the 'vehicle', in I.A. Richards's terms) and its 'tenor' (its meaning)\u2014for example in Coleridge's description of nature as 'that eternal language which thy God / Utters'. But while some romantics may have perceived nature and its symbols as God's language, for other romantic theorists it remains inscrutable. As Goethe (not himself a romantic) said, \u2018the idea [or meaning] remains eternally and infinitely active and inaccessible in the image\u2019. This was extended in modernist theory which, drawing on its symbolist precursors, often emphasizes the inscrutability and failure of symbol and metaphor. For example, Wallace Stevens seeks and fails to find meaning in nature, even if he at times seems to sense such a meaning. As such, symbolists and modernists at times adopt a mystical approach to suggest a non-rational sense of meaning.\nFor these reasons, modernist metaphors may be unnatural, as for instance in T.S. Eliot's description of an evening 'spread out against the sky / Like a patient etherized upon a table'. Similarly, for many later modernist poets nature is unnaturalized and at times mechanized, as for example in Stephen Oliver's image of the moon busily 'hoisting' itself into consciousness.\nOrigins and early history.\nRomanticism and realism.\nModernism developed out of Romanticism's revolt against the effects of the Industrial Revolution and bourgeois values. Literary scholar Gerald Graff, argues that, \"The ground motive of modernism was criticism of the 19th-century bourgeois social order and its world view; the modernists, carrying the torch of Romanticism.\"\nWhile J. M. W. Turner (1775\u20131851), one of the most notable landscape painters of the 19th century, was a member of the Romantic movement, his pioneering work in the study of light, color, and atmosphere \"anticipated the French Impressionists\" and therefore modernism \"in breaking down conventional formulas of representation; though unlike them, he believed that his works should always express significant historical, mythological, literary, or other narrative themes.\"\nHowever, the modernists were critical of the Romantics' belief that art serves as a window into the nature of reality. They argued that since each viewer interprets art through their own subjective perspective, it can never convey the ultimate metaphysical truth that the Romantics sought. Nonetheless, the modernists did not completely reject the idea of art as a means of understanding the world. To them, it was a tool for challenging and disrupting the viewer's point of view, rather than as a direct means of accessing a higher reality.\nModernism often rejects 19th-century realism when the latter is understood as focusing on the embodiment of meaning within a naturalistic representation. Instead, some modernists aim at a more 'real' realism, one that is uncentered. For instance, Picasso's 1907 Proto-Cubist painting \"Les Demoiselles d'Avignon\" does not present its subjects from a single point of view, instead presenting a flat, two-dimensional picture plane. \"The Poet\" of 1911 is similarly decentered, presenting the body from multiple points of view. As the Peggy Guggenheim Collection comments, \"Picasso presents multiple views of each object, as if he had moved around it, and synthesizes them into a single compound image.\"\nModernism, with its sense that \"things fall apart,\" is often seen as the apotheosis of Romanticism. As August Wilhelm Schlegel, an early German Romantic, described it, while Romanticism searches for metaphysical truths about character, nature, higher power, and meaning in the world, modernism, although yearning for such a metaphysical center, only finds its collapse.\nThe early 19th century.\nIn the context of the Industrial Revolution (~1760\u20131840), influential innovations included steam-powered industrialization, especially the development of railways starting in Britain in the 1830s, and the subsequent advancements in physics, engineering, and architecture they led to. A major 19th-century engineering achievement was the Crystal Palace, the huge cast-iron and plate-glass exhibition hall built for the Great Exhibition of 1851 in London. Glass and iron were used in a similar monumental style in the construction of major railway terminals throughout the city, including King's Cross station (1852) and Paddington Station (1854). These technological advances spread abroad, leading to later structures such as the Brooklyn Bridge (1883) and the Eiffel Tower (1889), the latter of which broke all previous limitations on how tall man-made objects could be. While such engineering feats radically altered the 19th-century urban environment and the daily lives of people, the human experience of time itself was altered with the development of the electric telegraph in 1837, as well as the adoption of \"standard time\" by British railway companies from 1845, a concept which would be adopted throughout the rest of the world over the next fifty years.\nDespite continuing technological advances, the ideas that history and civilization were inherently progressive and that such advances were always good came under increasing attack in the 19th century. Arguments arose that the values of the artist and those of society were not merely different, but in fact oftentimes opposed, and that society's current values were antithetical to further progress; therefore, civilization could not move forward in its present form. Early in the century, the philosopher Schopenhauer (1788\u20131860) (\"The World as Will and Representation\", 1819/20) called into question previous optimism. His ideas had an important influence on later thinkers, including Friedrich Nietzsche (1844\u20131900). Similarly, S\u00f8ren Kierkegaard (1813\u20131855) and Nietzsche120 both later rejected the idea that reality could be understood through a purely objective lens, a rejection that had a significant influence on the development of existentialism and nihilism.\nAround 1850, the Pre-Raphaelite Brotherhood (a group of English poets, painters, and art critics) began to challenge the dominant trends of industrial Victorian England in \"opposition to technical skill without inspiration.\"815 They were influenced by the writings of the art critic John Ruskin (1819\u20131900), who had strong feelings about the role of art in helping to improve the lives of the urban working classes in the rapidly expanding industrial cities of Britain.816 Art critic Clement Greenberg described the Pre-Raphaelite Brotherhood as proto-modernists: \"There the proto-modernists were, of all people, the Pre-Raphaelites (and even before them, as proto-proto-modernists, the German Nazarenes). The Pre-Raphaelites foreshadowed Manet (1832\u20131883), with whom modernist painting most definitely begins. They acted on a dissatisfaction with painting as practiced in their time, holding that its realism wasn't truthful enough.\"\nTwo of the most significant thinkers of the mid-19th century were biologist Charles Darwin (1809\u20131882), author of \"On the Origin of Species through Natural Selection\" (1859), and political scientist Karl Marx (1818\u20131883), author of \"Das Kapital\" (1867). Despite coming from different fields, both of their theories threatened the established order. Darwin's theory of evolution by natural selection undermined religious certainty and the idea of human uniqueness; in particular, the notion that human beings are driven by the same impulses as \"lower animals\" proved to be difficult to reconcile with the idea of an ennobling spirituality. Meanwhile, Marx's arguments that there are fundamental contradictions within the capitalist system and that workers are anything but free led to the formulation of Marxist theory.\nAfrican art had an important influence on modernist art, which was inspired by their interest in abstract depiction.\nThe late 19th century.\nArt historians have suggested various dates as starting points for modernism. Historian William Everdell argued that modernism began in the 1870s when metaphorical (or ontological) continuity began to yield to the discrete with mathematician Richard Dedekind's (1831\u20131916) Dedekind cut and Ludwig Boltzmann's (1844\u20131906) statistical thermodynamics. Everdell also believed modernism in painting began in 1885\u20131886 with post-Impressionist artist Georges Seurat's development of Divisionism, the \"dots\" used to paint \"A Sunday Afternoon on the Island of La Grande Jatte\". On the other hand, visual art critic Clement Greenberg called German philosopher Immanuel Kant (1724\u20131804) \"the first real modernist\", although he also wrote, \"What can be safely called modernism emerged in the middle of the last century\u2014and rather locally, in France, with Charles Baudelaire (1821\u20131867) in literature and Manet in painting, and perhaps with Gustave Flaubert (1821\u20131880), too, in prose fiction. (It was a while later, and not so locally, that modernism appeared in music and architecture).\" The poet Baudelaire's \"Les Fleurs du mal\" (\"The Flowers of Evil\") and the author Flaubert's \"Madame Bovary\" were both published in 1857. Baudelaire's essay \"The Painter of Modern Life\" (1863) inspired young artists to break away from tradition and innovate new ways of portraying their world in art.\nBeginning in the 1860s, two approaches in the arts and letters developed separately in France. The first was Impressionism, a school of painting that initially focused on work done not in studios, but outdoors (\"en plein air\"). Impressionist paintings attempted to convey that human beings do not see objects, but instead see light itself. The school gathered adherents despite internal divisions among its leading practitioners and became increasingly influential. Initially rejected from the most important commercial show of the time, the government-sponsored Paris Salon, the Impressionists organized yearly group exhibitions in commercial venues during the 1870s and 1880s, timing them to coincide with the official Salon. In 1863, the Salon des Refus\u00e9s, created by Emperor Napoleon III, displayed all of the paintings rejected by the Paris Salon. While most were in standard styles, but by inferior artists, the work of Manet attracted attention and opened commercial doors to the movement. The second French school was symbolism, which literary historians see beginning with Charles Baudelaire and including the later poets Arthur Rimbaud (1854\u20131891) with Une Saison en Enfer (\"A Season in Hell\", 1873), Paul Verlaine (1844\u20131896), St\u00e9phane Mallarm\u00e9 (1842\u20131898), and Paul Val\u00e9ry (1871\u20131945). The symbolists \"stressed the priority of suggestion and evocation over direct description and explicit analogy,\" and were especially interested in \"the musical properties of language.\"\nCabaret, which gave birth to so many of the arts of modernism, including the immediate precursors of film, may be said to have begun in France in 1881 with the opening of the Society of Incoherent Arts and the Black Cat in Montmartre.\nThe theories of Sigmund Freud (1856\u20131939), Krafft-Ebing and other sexologists were influential in the early days of modernism. Freud's first major work was \"Studies on Hysteria\" (with Josef Breuer, 1895). Central to Freud's thinking is the idea \"of the primacy of the unconscious mind in mental life\", so that all subjective reality was based on the interactions between basic drives and instincts, through which the outside world was perceived. Freud's description of subjective states involved an unconscious mind full of primal impulses, and counterbalancing self-imposed restrictions derived from social values.538\nThe works of Friedrich Nietzsche (1844\u20131900) were another major precursor of modernism, with a philosophy in which psychological drives, specifically the \"will to power\" (\"Wille zur macht\"), were of central importance: \"Nietzsche often identified life itself with 'will to power', that is, with an instinct for growth and durability.\" Henri Bergson (1859\u20131941), on the other hand, emphasized the difference between scientific, clock time and the direct, subjective human experience of time.131 His work on time and consciousness \"had a great influence on 20th-century novelists\" especially those modernists who used the \"stream of consciousness\" technique, such as Dorothy Richardson, James Joyce, and Virginia Woolf (1882\u20131941). Also important in Bergson's philosophy was the idea of \"\u00e9lan vital\", the life force, which \"brings about the creative evolution of everything.\"132 His philosophy also placed a high value on intuition, though without rejecting the importance of the intellect.132\nImportant literary precursors of modernism included esteemed writers such as Fyodor Dostoevsky (1821\u20131881), whose novels include \"Crime and Punishment\" (1866) and \"The Brothers Karamazov\" (1880); Walt Whitman (1819\u20131892), who published the poetry collection \"Leaves of Grass\" (1855\u20131891); and August Strindberg (1849\u20131912), especially his later plays, including the trilogy \"To Damascus\" 1898\u20131901,\"A Dream Play\" (1902) and \"The Ghost Sonata\" (1907). Henry James has also been suggested as a significant precursor to modernism in works as early as \"The Portrait of a Lady\" (1881).\nModernism emerges.\n1901 to 1930.\nOut of the collision of ideals derived from Romanticism and an attempt to find a way for knowledge to explain that which was as yet unknown, came the first wave of modernist works in the opening decade of the 20th century. Although their authors considered them to be extensions of existing trends in art, these works broke the implicit understanding the general public had of art: that artists were the interpreters and representatives of bourgeois culture and ideas. These \"modernist\" landmarks include the atonal ending of Arnold Schoenberg's Second String Quartet in 1908, the Expressionist paintings of Wassily Kandinsky starting in 1903, and culminating with his first abstract painting and the founding of the Blue Rider group in Munich in 1911, and the rise of fauvism and the inventions of Cubism from the studios of Henri Matisse, Pablo Picasso, Georges Braque, and others, in the years between 1900 and 1910.\nAn important aspect of modernism is how it relates to tradition through its adoption of techniques like reprise, incorporation, rewriting, recapitulation, revision, and parody in new forms. \nT. S. Eliot made significant comments on the relation of the artist to tradition, including: \"[W]e shall often find that not only the best, but the most individual parts of [a poet's] work, may be those in which the dead poets, his ancestors, assert their immortality most vigorously.\" However, the relationship of modernism with tradition was complex, as literary scholar Peter Child's indicates: \"There were paradoxical if not opposed trends towards revolutionary and reactionary positions, fear of the new and delight at the disappearance of the old, nihilism and fanatical enthusiasm, creativity, and despair.\"\nAn example of how modernist art can apply older traditions while also incorporating new techniques can be found within the music of the composer Arnold Schoenberg. On the one hand, he rejected traditional tonal harmony, the hierarchical system of organizing works of music that had guided musical composition for at least a century and a half. Schoenberg believed he had discovered a wholly new way of organizing sound based on the use of twelve-note rows. Yet, while this was indeed a wholly new technique, its origins can be traced back to the work of earlier composers such as Franz Liszt, Richard Wagner, Gustav Mahler, Richard Strauss, and Max Reger.\nIn the world of art, in the first decade of the 20th century, young painters such as Pablo Picasso and Henri Matisse caused much controversy and attracted great criticism with their rejection of traditional perspective as the means of structuring paintings, though the Impressionist Claude Monet had already been innovative in his use of perspective. In 1907, as Picasso was painting , Oskar Kokoschka was writing \"M\u00f6rder, Hoffnung der Frauen\" (\"Murderer, Hope of Women\"), the first Expressionist play (produced with scandal in 1909), and Arnold Schoenberg was composing his String Quartet No.2 in F sharp minor (1908), his first composition without a tonal center.\nA primary influence that led to Cubism was the representation of three-dimensional form in the late works of Paul C\u00e9zanne, which were displayed in a retrospective at the 1907 Salon d'Automne. In Cubist artwork, objects are analyzed, broken up, and reassembled in an abstract form; instead of depicting objects from one viewpoint, the artist depicts the subject from a multitude of viewpoints to represent the subject in a greater context. Cubism was brought to the attention of the general public for the first time in 1911 at the Salon des Ind\u00e9pendants in Paris (held 21 April\u00a0\u2013 13 June). Jean Metzinger, Albert Gleizes, Henri Le Fauconnier, Robert Delaunay, Fernand L\u00e9ger and Roger de La Fresnaye were shown together in Room 41, provoking a 'scandal' out of which Cubism emerged and spread throughout Paris and beyond. Also in 1911, Kandinsky painted \"Bild mit Kreis\" (\"Picture with a Circle\"), which he later called the first abstract painting.167 In 1912, Metzinger and Gleizes wrote the first (and only) major Cubist manifesto, \"Du \"Cubisme\"\", published in time for the Salon de la Section d'Or, the largest Cubist exhibition to date. In 1912 Metzinger painted and exhibited his enchanting \"La Femme au Cheval (Woman with a Horse)\" and \"Danseuse au Caf\u00e9 (Dancer in a Caf\u00e9)\". Albert Gleizes painted and exhibited his \"Les Baigneuses\" (The Bathers) and his monumental \"Le D\u00e9piquage des Moissons\" (Harvest Threshing). This work, along with \"La Ville de Paris\" (\"City of Paris\") by Robert Delaunay, was the largest and most ambitious Cubist painting undertaken during the pre-war Cubist period.\nIn 1905, a group of four German artists, led by Ernst Ludwig Kirchner, formed Die Br\u00fccke (The Bridge) in the city of Dresden. This was arguably the founding organization for the German Expressionist movement, though they did not use the word itself. A few years later, in 1911, a like-minded group of young artists formed Der Blaue Reiter (The Blue Rider) in Munich. The name came from Wassily Kandinsky's \"Der Blaue Reiter\" painting of 1903. Among their members were Kandinsky, Franz Marc, Paul Klee, and August Macke. However, the term \"Expressionism\" did not firmly establish itself until 1913.274 Though initially mainly a German artistic movement, most predominant in painting, poetry and the theater between 1910 and 1930, most precursors of the movement were not German. Furthermore, there have been Expressionist writers of prose fiction, as well as non-German speaking Expressionist writers, and, while the movement had declined in Germany with the rise of Adolf Hitler in the 1930s, there were subsequent Expressionist works.\nExpressionism is notoriously difficult to define, in part because it \"overlapped with other major 'isms' of the modernist period: with Futurism, Vorticism, Cubism, Surrealism and Dada.\" Richard Murphy also comments: \"[The] search for an all-inclusive definition is problematic to the extent that the most challenging Expressionists,\" such as the novelist Franz Kafka, poet Gottfried Benn, and novelist Alfred D\u00f6blin were simultaneously the most vociferous anti-Expressionists.43 What, however, can be said, is that it was a movement that developed in the early 20th century mainly in Germany in reaction to the dehumanizing effect of industrialization and the growth of cities, and that \"one of the central means by which Expressionism identifies itself as an avant-garde movement, and by which it marks its distance to traditions and the cultural institution as a whole is through its relationship to realism and the dominant conventions of representation.\"43 More explicitly: the Expressionists rejected the ideology of realism.43\u201348\nThere was a concentrated Expressionist movement in early 20th-century German theater, of which Georg Kaiser and Ernst Toller were the most famous playwrights. Other notable Expressionist dramatists included Reinhard Sorge, Walter Hasenclever, Hans Henny Jahnn, and Arnolt Bronnen. They looked back to Swedish playwright August Strindberg and German actor and dramatist Frank Wedekind as precursors of their dramaturgical experiments. Oskar Kokoschka's \"Murderer, the Hope of Women\" was the first fully Expressionist work for the theater, which opened on 4 July 1909 in Vienna. The extreme simplification of characters to mythic types, choral effects, declamatory dialog and heightened intensity would become characteristic of later Expressionist plays. The first full-length Expressionist play was \"The Son\" by Walter Hasenclever, which was published in 1914 and first performed in 1916.\nFuturism is another modernist movement. In 1909, the Parisian newspaper \"Le Figaro\" published F. T. Marinetti's first manifesto. Soon afterward, a group of painters (Giacomo Balla, Umberto Boccioni, Carlo Carr\u00e0, Luigi Russolo, and Gino Severini) co-signed the Futurist Manifesto. Modeled on Marx and Engels' famous \"Communist Manifesto\" (1848), such manifestos put forward ideas that were meant to provoke and to gather followers. However, arguments in favor of geometric or purely abstract painting were, at this time, largely confined to \"little magazines\" which had only tiny circulations. Modernist primitivism and pessimism were controversial, and the mainstream in the first decade of the 20th century was still inclined towards a faith in progress and liberal optimism.\nAbstract artists, taking as their examples the Impressionists, as well as Paul C\u00e9zanne (1839\u20131906) and Edvard Munch (1863\u20131944), began with the assumption that color and shape, not the depiction of the natural world, formed the essential characteristics of art. Western art had been, from the Renaissance up to the middle of the 19th century, underpinned by the logic of perspective and an attempt to reproduce an illusion of visible reality. The arts of cultures other than the European had become accessible and showed alternative ways of describing visual experience to the artist. By the end of the 19th century, many artists felt a need to create a new kind of art that encompassed the fundamental changes taking place in technology, science and philosophy. The sources from which individual artists drew their theoretical arguments were diverse and reflected the social and intellectual preoccupations in all areas of Western culture at that time. Wassily Kandinsky, Piet Mondrian, and Kazimir Malevich all believed in redefining art as the arrangement of pure color. The use of photography, which had rendered much of the representational function of visual art obsolete, strongly affected this aspect of modernism.\nModernist architects and designers, such as Frank Lloyd Wright and Le Corbusier, believed that new technology rendered old styles of building obsolete. Le Corbusier thought that buildings should function as \"machines for living in\", analogous to cars, which he saw as machines for traveling in. Just as cars had replaced the horse, so modernist design should reject the old styles and structures inherited from Ancient Greece or the Middle Ages. Following this machine aesthetic, modernist designers typically rejected decorative motifs in design, preferring to emphasize the materials used and pure geometrical forms. The skyscraper is the archetypal modernist building, and the Wainwright Building, a 10-story office building completed in 1891 in St. Louis, Missouri, United States, is among the first skyscrapers in the world. Ludwig Mies van der Rohe's Seagram Building in New York (1956\u20131958) is often regarded as the pinnacle of this modernist high-rise architecture. Many aspects of modernist design persist within the mainstream of contemporary architecture, though previous dogmatism has given way to a more playful use of decoration, historical quotation, and spatial drama.\nIn 1913\u2014which was the year of philosopher Edmund Husserl's \"Ideas\", physicist Niels Bohr's quantized atom, Ezra Pound's founding of imagism, the Armory Show in New York, and in Saint Petersburg the \"first futurist opera\", Mikhail Matyushin's \"Victory over the Sun\"\u2014another Russian composer, Igor Stravinsky, composed \"The Rite of Spring\", a ballet that depicts human sacrifice and has a musical score full of dissonance and primitive rhythm. This caused an uproar on its first performance in Paris. At this time, though modernism was still \"progressive\", it increasingly saw traditional forms and social arrangements as hindering progress and recast the artist as a revolutionary, engaged in overthrowing rather than enlightening society. Also in 1913, a less violent event occurred in France with the publication of the first volume of Marcel Proust's important novel sequence \"\u00c0 la recherche du temps perdu\" (1913\u20131927) (\"In Search of Lost Time\"). This is often presented as an early example of a writer using the stream-of-consciousness technique, but Robert Humphrey comments that Proust \"is concerned only with the reminiscent aspect of consciousness\" and that he \"was deliberately recapturing the past for the purpose of communicating; hence he did not write a stream-of-consciousness novel.\"\nStream of consciousness was an important modernist literary innovation, and it has been suggested that Arthur Schnitzler (1862\u20131931) was the first to make full use of it in his short story \"Leutnant Gustl\" (\"None but the brave\") (1900). Dorothy Richardson was the first English writer to use it, in the early volumes of her novel sequence \"Pilgrimage\" (1915\u20131967). Other modernist novelists that are associated with the use of this narrative technique include James Joyce in \"Ulysses\" (1922) and Italo Svevo in \"La coscienza di Zeno\" (1923).\nHowever, with the coming of the Great War of 1914\u20131918 (World War I) and the Russian Revolution of 1917, the world was drastically changed, and doubt was cast on the beliefs and institutions of the past. The failure of the previous status quo seemed self-evident to a generation that had seen millions die fighting over scraps of earth: before 1914, it had been argued that no one would fight such a war, since the cost was too high. The birth of a machine age, which had made major changes in the conditions of daily life in the 19th century had now radically changed the nature of warfare. The traumatic nature of recent experience altered basic assumptions, and a realistic depiction of life in the arts seemed inadequate when faced with the fantastically surreal nature of trench warfare. The view that mankind was making steady moral progress now seemed ridiculous in the face of the senseless slaughter, described in works such as Erich Maria Remarque's novel \"All Quiet on the Western Front\" (1929). Therefore, modernism's view of reality, which had been a minority taste before the war, became more generally accepted in the 1920s.\nIn literature and visual art, some modernists sought to defy expectations mainly to make their art more vivid or to force the audience to take the trouble to question their own preconceptions. This aspect of modernism has often seemed a reaction to consumer culture, which developed in Europe and North America in the late 19th century. Whereas most manufacturers try to make products that will be marketable by appealing to preferences and prejudices, high modernists reject such consumerist attitudes to undermine conventional thinking. The art critic Clement Greenberg expounded this theory of modernism in his essay \"Avant-Garde and Kitsch\". Greenberg labeled the products of consumer culture \"kitsch\", because their design aimed simply to have maximum appeal, with any difficult features removed. For Greenberg, modernism thus formed a reaction against the development of such examples of modern consumer culture as commercial popular music, Hollywood, and advertising. Greenberg associated this with the revolutionary rejection of capitalism.\nSome modernists saw themselves as part of a revolutionary culture that included political revolution. In Russia after the 1917 Revolution, there was indeed initially a burgeoning of avant-garde cultural activity, which included Russian Futurism. However, others rejected conventional politics as well as artistic conventions, believing that a revolution of political consciousness had greater importance than a change in political structures. But many modernists saw themselves as apolitical. Others, such as T. S. Eliot, rejected mass popular culture from a conservative position. Some even argue that Modernism in literature and art functioned to sustain an elite culture that excluded the majority of the population.\nSurrealism, which originated in the early 1920s, came to be regarded by the public as the most extreme form of modernism, or \"the avant-garde of modernism\". The word \"surrealist\" was coined by Guillaume Apollinaire and first appeared in the preface to his play \"Les Mamelles de Tir\u00e9sias\", which was written in 1903 and first performed in 1917. Major surrealists include Paul \u00c9luard, Robert Desnos, Max Ernst, Hans Arp, Antonin Artaud, Raymond Queneau, Joan Mir\u00f3, and Marcel Duchamp.\nBy 1930, modernism had won a place in the political and artistic establishment, although by this time modernism itself had changed.\nModernism continues: 1930\u20131945.\nModernism continued to evolve during the 1930s. Between 1930 and 1932 composer Arnold Schoenberg worked on \"Moses und Aron\", one of the first operas to make use of the twelve-tone technique, Pablo Picasso painted in 1937 \"Guernica\", his cubist condemnation of fascism, while in 1939 James Joyce pushed the boundaries of the modern novel further with \"Finnegans Wake\". Also by 1930 modernism began to influence mainstream culture, so that, for example, \"The New Yorker\" magazine began publishing work, influenced by modernism, by young writers and humorists like Dorothy Parker, Robert Benchley, E. B. White, S. J. Perelman, and James Thurber, amongst others. Perelman is highly regarded for his humorous short stories that he published in magazines in the 1930s and 1940s, most often in \"The New Yorker\", which are considered to be the first examples of surrealist humor in America. Modern ideas in art also began to appear more frequently in commercials and logos, an early example of which, from 1916, is the famous London Underground logo designed by Edward Johnston.\nOne of the most visible changes of this period was the adoption of new technologies into the daily lives of ordinary people in Western Europe and North America. Electricity, the telephone, the radio, the automobile\u2014and the need to work with them, repair them and live with them\u2014created social change. The kind of disruptive moment that only a few knew in the 1880s became a common occurrence. For example, the speed of communication reserved for the stock brokers of 1890 became part of family life, at least in middle class North America. Associated with urbanization and changing social mores also came smaller families and changed relationships between parents and their children.\nAnother strong influence at this time was Marxism. After the generally primitivistic/irrationalism aspect of pre-World War I modernism (which for many modernists precluded any attachment to merely political solutions) and the neoclassicism of the 1920s (as represented most famously by T. S. Eliot and Igor Stravinsky\u2014which rejected popular solutions to modern problems), the rise of fascism, the Great Depression, and the march to war helped to radicalize a generation. Bertolt Brecht, W. H. Auden, Andr\u00e9 Breton, Louis Aragon, and the philosophers Antonio Gramsci and Walter Benjamin are perhaps the most famous exemplars of this modernist form of Marxism. There were, however, also modernists explicitly of 'the right', including Salvador Dal\u00ed, Wyndham Lewis, T. S. Eliot, Ezra Pound, the Dutch author Menno ter Braak and others.\nSignificant modernist literary works continued to be created in the 1920s and 1930s, including further novels by Marcel Proust, Virginia Woolf, Robert Musil, and Dorothy Richardson. The American modernist dramatist Eugene O'Neill's career began in 1914, but his major works appeared in the 1920s, 1930s and early 1940s. Two other significant modernist dramatists writing in the 1920s and 1930s were Bertolt Brecht and Federico Garc\u00eda Lorca. D. H. Lawrence's \"Lady Chatterley's Lover\" was privately published in 1928, while another important landmark for the history of the modern novel came with the publication of William Faulkner's \"The Sound and the Fury\" in 1929. In the 1930s, in addition to further major works by Faulkner, Samuel Beckett published his first major work, the novel \"Murphy\" (1938). Then in 1939 James Joyce's \"Finnegans Wake\" appeared. This is written in a largely idiosyncratic language, consisting of a mixture of standard English lexical items and neologistic multilingual puns and portmanteau words, which attempts to recreate the experience of sleep and dreams. In poetry T. S. Eliot, E. E. Cummings, and Wallace Stevens were writing from the 1920s until the 1950s. While modernist poetry in English is often viewed as an American phenomenon, with leading exponents including Ezra Pound, T. S. Eliot, Marianne Moore, William Carlos Williams, H.D., and Louis Zukofsky, there were important British modernist poets, including David Jones, Hugh MacDiarmid, Basil Bunting, and W. H. Auden. European modernist poets include Federico Garc\u00eda Lorca, Anna Akhmatova, Constantine Cavafy, and Paul Val\u00e9ry.\nThe modernist movement continued during this period in Soviet Russia. In 1930 composer Dimitri Shostakovich's (1906\u20131975) opera \"The Nose\" was premiered, in which he uses a montage of different styles, including folk music, popular song and atonality. Among his influences was Alban Berg's (1885\u20131935) opera \"Wozzeck\" (1925), which \"had made a tremendous impression on Shostakovich when it was staged in Leningrad.\" However, from 1932 socialist realism began to oust modernism in the Soviet Union, and in 1936 Shostakovich was attacked and forced to withdraw his 4th Symphony. Alban Berg wrote another significant, though incomplete, modernist opera, \"Lulu\", which premiered in 1937. Berg's Violin Concerto was first performed in 1935. Like Shostakovich, other composers faced difficulties in this period.\nIn Germany Arnold Schoenberg (1874\u20131951) was forced to flee to the U.S. when Hitler came to power in 1933, because of his modernist atonal style as well as his Jewish ancestry. His major works from this period are a Violin Concerto, Op. 36 (1934/36), and a Piano Concerto, Op. 42 (1942). Schoenberg also wrote tonal music in this period with the Suite for Strings in G major (1935) and the Chamber Symphony No. 2 in E\u266d minor, Op. 38 (begun in 1906, completed in 1939). During this time Hungarian modernist B\u00e9la Bart\u00f3k (1881\u20131945) produced a number of major works, including \"Music for Strings, Percussion and Celesta\" (1936) and the \"Divertimento for String Orchestra\" (1939), String Quartet No. 5 (1934), and No. 6 (his last, 1939). But he too left for the US in 1940, because of the rise of fascism in Hungary. Igor Stravinsky (1882\u20131971) continued writing in his neoclassical style during the 1930s and 1940s, writing works like the \"Symphony of Psalms\" (1930), Symphony in C (1940), and \"Symphony in Three Movements\" (1945). He also emigrated to the US because of World War II. Olivier Messiaen (1908\u20131992), however, served in the French army during the war and was imprisoned at Stalag VIII-A by the Germans, where he composed his famous \"Quatuor pour la fin du temps\" (\"Quartet for the End of Time\"). The quartet was first performed in January 1941 to an audience of prisoners and prison guards.\nIn painting, during the 1920s and 1930s and the Great Depression, modernism was defined by Surrealism, late Cubism, Bauhaus, De Stijl, Dada, German Expressionism, and modernist and masterful color painters like Henri Matisse and Pierre Bonnard as well as the abstractions of artists like Piet Mondrian and Wassily Kandinsky which characterized the European art scene. In Germany, Max Beckmann, Otto Dix, George Grosz and others politicized their paintings, foreshadowing the coming of World War II, while in America, modernism is seen in the form of American Scene painting and the social realism and Regionalism movements that contained both political and social commentary dominated the art world. Artists like Ben Shahn, Thomas Hart Benton, Grant Wood, George Tooker, John Steuart Curry, Reginald Marsh, and others became prominent. Modernism is defined in Latin America by painters Joaqu\u00edn Torres-Garc\u00eda from Uruguay and Rufino Tamayo from Mexico, while the muralist movement with Diego Rivera, David Siqueiros, Jos\u00e9 Clemente Orozco, Pedro Nel G\u00f3mez and Santiago Mart\u00ednez Delgado, and Symbolist paintings by Frida Kahlo, began a renaissance of the arts for the region, characterized by a freer use of color and an emphasis on political messages.\nDiego Rivera is perhaps best known by the public world for his 1933 mural, \"Man at the Crossroads\", in the lobby of the RCA Building at Rockefeller Center. When his patron Nelson Rockefeller discovered that the mural included a portrait of Vladimir Lenin and other communist imagery, he fired Rivera, and the unfinished work was eventually destroyed by Rockefeller's staff. Frida Kahlo's works are often characterized by their stark portrayals of pain. Kahlo was deeply influenced by indigenous Mexican culture, which is apparent in her paintings' bright colors and dramatic symbolism. Christian and Jewish themes are often depicted in her work as well; she combined elements of the classic religious Mexican tradition, which were often bloody and violent. Frida Kahlo's Symbolist works relate strongly to surrealism and to the magic realism movement in literature.\nPolitical activism was an important piece of David Siqueiros' life, and frequently inspired him to set aside his artistic career. His art was deeply rooted in the Mexican Revolution. The period from the 1920s to the 1950s is known as the Mexican Renaissance, and Siqueiros was active in the attempt to create an art that was at once Mexican and universal. The young Jackson Pollock attended the workshop and helped build floats for the parade.\nDuring the 1930s, radical leftist politics characterized many of the artists connected to surrealism, including Pablo Picasso. On 26 April 1937, during the Spanish Civil War, the Basque town of Gernika was bombed by Nazi Germany's Luftwaffe. The Germans were attacking to support the efforts of Francisco Franco to overthrow the Basque government and the Spanish Republican government. Pablo Picasso painted his mural-sized \"Guernica\" to commemorate the horrors of the bombing.\nDuring the Great Depression of the 1930s and through the years of World War II, American art was characterized by social realism and American Scene painting, in the work of Grant Wood, Edward Hopper, Ben Shahn, Thomas Hart Benton, and several others. \"Nighthawks\" (1942) is a painting by Edward Hopper that portrays people sitting in a downtown diner late at night. It is not only Hopper's most famous painting, but one of the most recognizable in American art. The scene was inspired by a diner in Greenwich Village. Hopper began painting it immediately after the attack on Pearl Harbor. After this event there was a large feeling of gloominess over the country, a feeling that is portrayed in the painting. The urban street is empty outside the diner, and inside none of the three patrons is apparently looking or talking to the others but instead is lost in their own thoughts. This portrayal of modern urban life as empty or lonely is a common theme throughout Hopper's work.\n\"American Gothic\" is a painting by Grant Wood from 1930 portraying a pitchfork-holding farmer and a younger woman in front of a house of Carpenter Gothic style, it is one of the most familiar images in 20th-century American art. Art critics had favorable opinions about the painting; like Gertrude Stein and Christopher Morley, they assumed the painting was meant to be a satire of rural small-town life. It was thus seen as part of the trend towards increasingly critical depictions of rural America, along the lines of Sherwood Anderson's 1919 \"Winesburg, Ohio\", Sinclair Lewis's 1920 \"Main Street\", and Carl Van Vechten's \"The Tattooed Countess\" in literature. However, with the onset of the Great Depression, the painting came to be seen as a depiction of steadfast American pioneer spirit.\nThe situation for artists in Europe during the 1930s deteriorated rapidly as the Nazis' power in Germany and across Eastern Europe increased. \"Degenerate art\" was a term adopted by the Nazi regime in Germany for virtually all modern art. Such art was banned because it was un-German or Jewish Bolshevist in nature, and those identified as degenerate artists were subjected to sanctions. These included being dismissed from teaching positions, being forbidden to exhibit or to sell their art, and in some cases being forbidden to produce art entirely. Degenerate Art was also the title of an exhibition, mounted by the Nazis in Munich in 1937. The climate became so hostile for artists and art associated with modernism and abstraction that many left for the Americas. German artist Max Beckmann and scores of others fled Europe for New York. In New York City a new generation of young and exciting modernist painters led by Arshile Gorky, Willem de Kooning, and others were just beginning to come of age.\nArshile Gorky's portrait of someone who might be Willem de Kooning is an example of the evolution of Abstract Expressionism from the context of figure painting, Cubism and Surrealism. Along with his friends de Kooning and John D. Graham, Gorky created biomorphically shaped and abstracted figurative compositions that by the 1940s evolved into totally abstract paintings. Gorky's work seems to be a careful analysis of memory, emotion and shape, using line and color to express feeling and nature.\nAttacks on early modernism.\nModernism's stress on freedom of expression, experimentation, radicalism, and primitivism disregards conventional expectations. In many art forms this often meant startling and alienating audiences with bizarre and unpredictable effects, as in the strange and disturbing combinations of motifs in Surrealism or the use of extreme dissonance and atonality in modernist music. In literature this often involved the rejection of intelligible plots or characterization in novels, or the creation of poetry that defied clear interpretation. Within the Catholic Church, the specter of Protestantism and Martin Luther was at play in anxieties over modernism and the notion that doctrine develops and changes over time.\nFrom 1932, socialist realism began to oust modernism in the Soviet Union, where it had previously endorsed Russian Futurism and Constructivism, primarily under the homegrown philosophy of Suprematism.\nThe Nazi government of Germany deemed modernism narcissistic and nonsensical, as well as \"Jewish\" (see Antisemitism) and \"Negro\". The Nazis exhibited modernist paintings alongside works by the mentally ill in an exhibition entitled \"Degenerate Art\". Accusations of \"formalism\" could lead to the end of a career, or worse. For this reason, many modernists of the post-war generation felt that they were the most important bulwark against totalitarianism, the \"canary in the coal mine\", whose repression by a government or other group with supposed authority represented a warning that individual liberties were being threatened. Louis A. Sass compared madness, specifically schizophrenia, and modernism in a less fascist manner by noting their shared disjunctive narratives, surreal images, and incoherence.\nAfter 1945.\nWhile \"The Oxford Encyclopedia of British Literature\" states that modernism ended by c. 1939 with regard to British and American literature, \"When (if) modernism petered out and postmodernism began has been contested almost as hotly as when the transition from Victorianism to modernism occurred.\" Clement Greenberg sees modernism ending in the 1930s, with the exception of the visual and performing arts, but with regard to music, Paul Griffiths notes that, while modernism \"seemed to be a spent force\" by the late 1920s, after World War II, \"a new generation of composers\u2014Boulez, Barraqu\u00e9, Babbitt, Nono, Stockhausen, Xenakis\" revived modernism\". In fact, many literary modernists lived into the 1950s and 1960s, though generally they were no longer producing major works. The term \"late modernism\" is also sometimes applied to modernist works published after 1930. Among the modernists (or late modernists) still publishing after 1945 were Wallace Stevens, Gottfried Benn, T. S. Eliot, Anna Akhmatova, William Faulkner, Dorothy Richardson, John Cowper Powys, and Ezra Pound. Basil Bunting, born in 1901, published his most important modernist poem, \"Briggflatts\" in 1965. In addition, Hermann Broch's \"The Death of Virgil\" was published in 1945 and Thomas Mann's \"Doctor Faustus\" in 1947. Samuel Beckett, who died in 1989, has been described as a \"later modernist\". Beckett is a writer with roots in the Expressionist tradition of modernism, who produced works from the 1930s until the 1980s, including \"Molloy\" (1951), \"Waiting for Godot\" (1953), \"Happy Days\" (1961), and \"Rockaby\" (1981). The terms \"minimalist\" and \"post-modernist\" have also been applied to his later works. The poets Charles Olson (1910\u20131970) and J. H. Prynne (born 1936) are among the writers in the second half of the 20th century who have been described as late modernists.\nMore recently, the term \"late modernism\" has been redefined by at least one critic and used to refer to works written after 1945, rather than 1930. With this usage goes the idea that the ideology of modernism was significantly re-shaped by the events of World War II, especially the Holocaust and the dropping of the atom bomb.\nThe post-war period left the capitals of Europe in upheaval, with an urgency to economically and physically rebuild and to politically regroup. In Paris (the former center of European culture and the former capital of the art world), the climate for art was a disaster. Important collectors, dealers, and modernist artists, writers, and poets fled Europe for New York and America. The surrealists and modern artists from every cultural center of Europe had fled the onslaught of the Nazis for safe haven in the United States. Many of those who did not flee perished. A few artists, notably Pablo Picasso, Henri Matisse, and Pierre Bonnard, remained in France and survived.\nThe 1940s in New York City heralded the triumph of American Abstract Expressionism, a modernist movement that combined lessons learned from Henri Matisse, Pablo Picasso, Surrealism, Joan Mir\u00f3, Cubism, Fauvism, and early modernism via great teachers in America like Hans Hofmann and John D. Graham. American artists benefited from the presence of Piet Mondrian, Fernand L\u00e9ger, Max Ernst and the Andr\u00e9 Breton group, Pierre Matisse's gallery, and Peggy Guggenheim's gallery \"The Art of This Century\", as well as other factors.\nParis, moreover, recaptured much of its luster in the 1950s and 1960s as the center of a machine art florescence, with both of the leading machine art sculptors Jean Tinguely and Nicolas Sch\u00f6ffer having moved there to launch their careers\u2014and which florescence, in light of the technocentric character of modern life, may well have a particularly long-lasting influence.\nTheatre of the Absurd.\nThe term \"Theatre of the Absurd\" is applied to plays, written primarily by Europeans, that express the belief that human existence has no meaning or purpose and therefore all communication breaks down. Logical construction and argument gives way to irrational and illogical speech and to its ultimate conclusion, silence. While there are significant precursors, including Alfred Jarry (1873\u20131907), the Theatre of the Absurd is generally seen as beginning in the 1950s with the plays of Samuel Beckett.\nCritic Martin Esslin coined the term in his 1960 essay \"Theatre of the Absurd\". He related these plays based on a broad theme of the absurd, similar to the way Albert Camus uses the term in his 1942 essay, \"The Myth of Sisyphus\". The Absurd in these plays takes the form of man's reaction to a world apparently without meaning, and/or man as a puppet controlled or menaced by invisible outside forces. Though the term is applied to a wide range of plays, some characteristics coincide in many of the plays: broad comedy, often similar to vaudeville, mixed with horrific or tragic images; characters caught in hopeless situations forced to do repetitive or meaningless actions; dialog full of cliches, wordplay, and nonsense; plots that are cyclical or absurdly expansive; either a parody or dismissal of realism and the concept of the \"well-made play\".\nPlaywrights commonly associated with the Theatre of the Absurd include Samuel Beckett (1906\u20131989), Eug\u00e8ne Ionesco (1909\u20131994), Jean Genet (1910\u20131986), Harold Pinter (1930\u20132008), Tom Stoppard (born 1937), Alexander Vvedensky (1904\u20131941), Daniil Kharms (1905\u20131942), Friedrich D\u00fcrrenmatt (1921\u20131990), Alejandro Jodorowsky (born 1929), Fernando Arrabal (born 1932), V\u00e1clav Havel (1936\u20132011) and Edward Albee (1928\u20132016).\nPollock and abstract influences.\nDuring the late 1940s, Jackson Pollock's radical approach to painting revolutionized the potential for all contemporary art that followed him. To some extent, Pollock realized that the journey toward making a work of art was as important as the work of art itself. Like Pablo Picasso's innovative reinventions of painting and sculpture in the early 20th century via Cubism and constructed sculpture, Pollock redefined the way art is made. His move away from easel painting and conventionality was a liberating signal to the artists of his era and to all who came after. Artists realized that Jackson Pollock's process\u2014placing unstretched raw canvas on the floor where it could be attacked from all four sides using artistic and industrial materials; dripping and throwing linear skeins of paint; drawing, staining, and brushing; using imagery and non-imagery\u2014essentially blasted art-making beyond any prior boundary. Abstract Expressionism generally expanded and developed the definitions and possibilities available to artists for the creation of new works of art.\nThe other Abstract Expressionists followed Pollock's breakthrough with new breakthroughs of their own. In a sense the innovations of Jackson Pollock, Willem de Kooning, Franz Kline, Mark Rothko, Philip Guston, Hans Hofmann, Clyfford Still, Barnett Newman, Ad Reinhardt, Robert Motherwell, Peter Voulkos and others opened the floodgates to the diversity and scope of all the art that followed them. Re-readings into abstract art by art historians such as Linda Nochlin, Griselda Pollock and Catherine de Zegher critically show, however, that pioneering women artists who produced major innovations in modern art had been ignored by official accounts of its history.\nInternational figures from British art.\nHenry Moore (1898\u20131986) emerged after World War II as Britain's leading sculptor. He was best known for his semi-abstract monumental bronze sculptures which are located around the world as public works of art. His forms are usually abstractions of the human figure, typically depicting mother-and-child or reclining figures, usually suggestive of the female body, apart from a phase in the 1950s when he sculpted family groups. These sculptures are generally pierced or contain hollow spaces.\nIn the 1950s, Moore began to receive increasingly significant commissions, including a reclining figure for the UNESCO building in Paris in 1958. With many more public works of art, the scale of Moore's sculptures grew significantly. The last three decades of Moore's life continued in a similar vein, with several major retrospectives taking place around the world, notably a prominent exhibition in the summer of 1972 in the grounds of the Forte di Belvedere overlooking Florence. By the end of the 1970s, there were some 40 exhibitions a year featuring his work. On the campus of the University of Chicago in December 1967, 25 years to the minute after the team of physicists led by Enrico Fermi achieved the first controlled, self-sustaining nuclear chain reaction, Moore's \"Nuclear Energy\" was unveiled. Also in Chicago, Moore commemorated science with a large bronze sundial, locally named \"Man Enters the Cosmos\" (1980), which was commissioned to recognize the space exploration program.\nThe \"London School\" of figurative painters, including Francis Bacon (1909\u20131992), Lucian Freud (1922\u20132011), Frank Auerbach (1931-2024), Leon Kossoff (1926-2019), and Michael Andrews (1928\u20131995), have received widespread international recognition.\nFrancis Bacon was an Irish-born British figurative painter known for his bold, graphic and emotionally raw imagery. His painterly but abstracted figures typically appear isolated in glass or steel geometrical cages set against flat, nondescript backgrounds. Bacon began painting during his early 20s but worked only sporadically until his mid-30s. His breakthrough came with the 1944 triptych \"Three Studies for Figures at the Base of a Crucifixion\" which sealed his reputation as a uniquely bleak chronicler of the human condition. His output can be crudely described as consisting of sequences or variations on a single motif; beginning with the 1940s male heads isolated in rooms, the early 1950s screaming popes, and mid to late 1950s animals and lone figures suspended in geometric structures. These were followed by his early 1960s modern variations of the crucifixion in the triptych format. From the mid-1960s to early 1970s, Bacon mainly produced strikingly compassionate portraits of friends. Following the suicide of his lover George Dyer in 1971, his art became more personal, inward-looking, and preoccupied with themes and motifs of death. During his lifetime, Bacon was equally reviled and acclaimed.\nLucian Freud was a German-born British painter, known chiefly for his thickly impastoed portrait and figure paintings, who was widely considered the pre-eminent British artist of his time. His works are noted for their psychological penetration, and for their often discomforting examination of the relationship between artist and model. According to William Grimes of \"The New York Times\", \"Lucien Freud and his contemporaries transformed figure painting in the 20th century. In paintings like \"Girl with a White Dog\" (1951\u20131952), Freud put the pictorial language of traditional European painting in the service of an anti-romantic, confrontational style of portraiture that stripped bare the sitter's social facade. Ordinary people\u2014many of them his friends\u2014stared wide-eyed from the canvas, vulnerable to the artist's ruthless inspection.\"\nAfter Abstract Expressionism.\nIn abstract painting during the 1950s and 1960s, several new directions like hard-edge painting and other forms of geometric abstraction began to appear in artist studios and in radical avant-garde circles as a reaction against the subjectivism of Abstract Expressionism. Clement Greenberg became the voice of post-painterly abstraction when he curated an influential exhibition of new painting that toured important art museums throughout the United States in 1964. Color field painting, hard-edge painting, and lyrical abstraction emerged as radical new directions.\nBy the late 1960s however, postminimalism, process art and Arte Povera also emerged as revolutionary concepts and movements that encompassed both painting and sculpture, via lyrical abstraction and the post-minimalist movement, and in early conceptual art. Process art, as inspired by Pollock enabled artists to experiment with and make use of a diverse encyclopaedia of style, content, material, placement, sense of time, aplastic, and real space. Nancy Graves, Ronald Davis, Howard Hodgkin, Larry Poons, Jannis Kounellis, Brice Marden, Colin McCahon, Bruce Nauman, Richard Tuttle, Alan Saret, Walter Darby Bannard, Lynda Benglis, Dan Christensen, Larry Zox, Ronnie Landfield, Eva Hesse, Keith Sonnier, Richard Serra, Pat Lipsky, Sam Gilliam, Mario Merz and Peter Reginato were some of the younger artists who emerged during the era of late modernism that spawned the heyday of the art of the late 1960s.\nPop art.\nIn 1962, the Sidney Janis Gallery mounted \"The New Realists\", the first major pop art group exhibition in an uptown art gallery in New York City. Janis mounted the exhibition in a 57th Street storefront near his gallery. The show had a great impact on the New York School as well as the greater worldwide art scene. Earlier in England in 1958 the term \"Pop Art\" was used by Lawrence Alloway to describe paintings associated with the consumerism of the post World War II era. This movement rejected Abstract Expressionism and its focus on the hermeneutic and psychological interior in favor of art that depicted material consumer culture, advertising, and the iconography of the mass production age. The early works of David Hockney and the works of Richard Hamilton and Eduardo Paolozzi (who created the ground-breaking \"I was a Rich Man's Plaything\", 1947) are considered seminal examples in the movement. Meanwhile, in the downtown scene in New York's East Village 10th Street galleries, artists were formulating an American version of pop art. Claes Oldenburg had his storefront, and the Green Gallery on 57th Street began to show the works of Tom Wesselmann and James Rosenquist. Later Leo Castelli exhibited the works of other American artists, including those of Andy Warhol and Roy Lichtenstein for most of their careers. There is a connection between the radical works of Marcel Duchamp and Man Ray, the rebellious Dadaists with a sense of humor, and pop artists like Claes Oldenburg, Andy Warhol, and Roy Lichtenstein, whose paintings reproduce the look of Ben-Day dots, a technique used in commercial reproduction.\nMinimalism.\nMinimalism describes movements in various forms of art and design, especially visual art and music, wherein artists intend to expose the essence or identity of a subject through eliminating all nonessential forms, features, or concepts. Minimalism is any design or style wherein the simplest and fewest elements are used to create the maximum effect.\nAs a specific movement in the arts, it is identified with developments in post\u2013World War II Western art, most strongly with American visual arts in the 1960s and early 1970s. Prominent artists associated with this movement include Donald Judd, John McCracken, Agnes Martin, Dan Flavin, Robert Morris, Ronald Bladen, Anne Truitt, and Frank Stella. It derives from the reductive aspects of modernism and is often interpreted as a reaction against Abstract Expressionism and a bridge to Post minimal art practices. By the early 1960s, minimalism emerged as an abstract movement in art (with roots in the geometric abstraction of Kazimir Malevich, the Bauhaus and Piet Mondrian) that rejected the idea of relational and subjective painting, the complexity of Abstract Expressionist surfaces, and the emotional zeitgeist and polemics present in the arena of action painting. Minimalism argued that extreme simplicity could capture all of the sublime representation needed in art. Minimalism is variously construed either as a precursor to postmodernism, or as a postmodern movement itself. In the latter perspective, early Minimalism yielded advanced modernist works, but the movement partially abandoned this direction when some artists like Robert Morris changed direction in favor of the anti-form movement.\nHal Foster, in his essay \"The Crux of Minimalism\", examines the extent to which Donald Judd and Robert Morris both acknowledge and exceed Greenbergian modernism in their published definitions of minimalism. He argues that minimalism is not a \"dead end\" of modernism, but a \"paradigm shift toward postmodern practices that continue to be elaborated today.\"\nMinimal music.\nThe terms have expanded to encompass a movement in music that features such repetition and iteration as those of the compositions of La Monte Young, Terry Riley, Steve Reich, Philip Glass, and John Adams. Minimalist compositions are sometimes known as systems music. The term \"minimal music\" is generally used to describe a style of music that developed in America in the late 1960s and 1970s; and that was initially connected with the composers. The minimalism movement originally involved some composers, and other lesser known pioneers included Pauline Oliveros, Phill Niblock, and Richard Maxfield. In Europe, the music of Louis Andriessen, Karel Goeyvaerts, Michael Nyman, Howard Skempton, Eliane Radigue, Gavin Bryars, Steve Martland, Henryk G\u00f3recki, Arvo P\u00e4rt and John Tavener.\nPostminimalism.\nIn the late 1960s, Robert Pincus-Witten coined the term \"postminimalism\" to describe minimalist-derived art which had content and contextual overtones that minimalism rejected. The term was applied by Pincus-Witten to the work of Eva Hesse, Keith Sonnier, Richard Serra and new work by former minimalists Robert Smithson, Robert Morris, Sol LeWitt, Barry Le Va, and others. Other minimalists, including Donald Judd, Dan Flavin, Carl Andre, Agnes Martin, John McCracken and others, continued to produce late modernist paintings and sculpture for the remainder of their careers.\nSince then, many artists have embraced minimal or post-minimal styles, and the label \"postmodern\" has been attached to them.\nCollage, assemblage, installations.\nRelated to Abstract Expressionism was the emergence of combining manufactured items with artist materials, moving away from previous conventions of painting and sculpture. The work of Robert Rauschenberg exemplifies this trend. His \"combines\" of the 1950s were forerunners of pop art and installation art, and used assemblages of large physical objects, including stuffed animals, birds and commercial photographs. Rauschenberg, Jasper Johns, Larry Rivers, John Chamberlain, Claes Oldenburg, George Segal, Jim Dine, and Edward Kienholz were among important pioneers of both abstraction and pop art. Creating new conventions of art-making, they made acceptable in serious contemporary art circles the radical inclusion in their works of unlikely materials. Another pioneer of collage was Joseph Cornell, whose more intimately scaled works were seen as radical because of both his personal iconography and his use of found objects.\nNeo-Dada.\nIn 1917, Marcel Duchamp submitted a urinal as a sculpture for the inaugural exhibition of the Society of Independent Artists, which was to be staged at the Grand Central Palace in New York. He professed his intent that people look at the urinal as if it were a work of art because he said it was a work of art. This urinal, named \"Fountain\" was signed with the pseudonym \"R. Mutt\". It is also an example of what Duchamp would later call \"readymades\". This and Duchamp's other works are generally labelled as Dada. Duchamp can be seen as a precursor to conceptual art, other famous examples being John Cage's \"4\u203233\u2033\", which is four minutes and thirty three seconds of silence, and Rauschenberg's \"Erased de Kooning Drawing\". Many conceptual works take the position that art is the result of the viewer viewing an object or act as art, not of the intrinsic qualities of the work itself. In choosing \"an ordinary article of life\" and creating \"a new thought for that object\", Duchamp invited onlookers to view \"Fountain\" as a sculpture.\nMarcel Duchamp famously gave up \"art\" in favor of chess. Avant-garde composer David Tudor created a piece, \"Reunion\" (1968), written jointly with Lowell Cross, that features a chess game in which each move triggers a lighting effect or projection. Duchamp and Cage played the game at the work's premier.\nSteven Best and Douglas Kellner identify Rauschenberg and Jasper Johns as part of the transitional phase, influenced by Duchamp, between modernism and postmodernism. Both used images of ordinary objects, or the objects themselves, in their work, while retaining the abstraction and painterly gestures of high modernism.\nPerformance and happenings.\nDuring the late 1950s and 1960s artists with a wide range of interests began to push the boundaries of contemporary art. Yves Klein in France, Carolee Schneemann, Yayoi Kusama, Charlotte Moorman and Yoko Ono in New York City, and Joseph Beuys, Wolf Vostell and Nam June Paik in Germany were pioneers of performance-based works of art. Groups like The Living Theatre with Julian Beck and Judith Malina collaborated with sculptors and painters to create environments, radically changing the relationship between audience and performer, especially in their piece \"Paradise Now\". The Judson Dance Theater, located at the Judson Memorial Church, New York; and the Judson dancers, notably Yvonne Rainer, Trisha Brown, Elaine Summers, Sally Gross, Simonne Forti, Deborah Hay, Lucinda Childs, Steve Paxton and others; collaborated with artists Robert Morris, Robert Whitman, John Cage, Robert Rauschenberg, and engineers like Billy Kl\u00fcver. Park Place Gallery was a center for musical performances by electronic composers Steve Reich, Philip Glass, and other notable performance artists, including Joan Jonas.\nThese performances were intended as works of a new art form combining sculpture, dance, and music or sound, often with audience participation. They were characterized by the reductive philosophies of Minimalism and the spontaneous improvisation and expressivity of Abstract Expressionism. Images of Schneemann's performances of pieces meant to create shock within the audience are occasionally used to illustrate these kinds of art, and she is often photographed while performing her piece \"Interior Scroll\". However, according to modernist philosophy surrounding performance art, it is cross-purposes to publish images of her performing this piece, for performance artists reject publication entirely: the performance itself is the medium. Thus, other media cannot illustrate performance art; performance is momentary, evanescent, and personal, not for capturing; representations of performance art in other media, whether by image, video, narrative or, otherwise, select certain points of view in space or time or otherwise involve the inherent limitations of each medium. The artists deny that recordings illustrate the medium of performance as art.\nDuring the same period, various avant-garde artists created Happenings, mysterious and often spontaneous and unscripted gatherings of artists and their friends and relatives in various specified locations, often incorporating exercises in absurdity, physicality, costuming, spontaneous nudity, and various random or seemingly disconnected acts. Notable creators of happenings included Allan Kaprow\u2014who first used the term in 1958, Claes Oldenburg, Jim Dine, Red Grooms, and Robert Whitman.\nIntermedia and multimedia.\nAnother trend in art associated with postmodernism is the use of a number of different media together. Intermedia is a term coined by Dick Higgins and meant to convey new art forms along the lines of Fluxus, concrete poetry, found objects, performance art, and computer art. Higgins was the publisher of the Something Else Press, a concrete poet married to artist Alison Knowles and an admirer of Marcel Duchamp. Ihab Hassan includes \"Intermedia, the fusion of forms, the confusion of realms,\" in his list of the characteristics of postmodern art. One of the most common forms of multimedia art is the use of videotape and CRT monitors, termed video art. While the theory of combining multiple arts into one art is quite old, and has been revived periodically, the postmodern manifestation is often in combination with performance art, where the dramatic subtext is removed, and what is left is the specific statements of the artist in question or the conceptual statement of their action.\nFluxus.\nFluxus was named and loosely organized in 1962 by George Maciunas (1931\u20131978), a Lithuanian-born American artist. Fluxus traces its beginnings to John Cage's 1957 to 1959 Experimental Composition classes at The New School for Social Research in New York City. Many of his students were artists working in other media with little or no background in music. Cage's students included Fluxus founding members Jackson Mac Low, Al Hansen, George Brecht and Dick Higgins.\nFluxus encouraged a do-it-yourself aesthetic and valued simplicity over complexity. Like Dada before it, Fluxus included a strong current of anti-commercialism and an anti-art sensibility, disparaging the conventional market-driven art world in favor of an artist-centered creative practice. Fluxus artists preferred to work with whatever materials were at hand, and either created their own work or collaborated in the creation process with their colleagues.\nAndreas Huyssen criticizes attempts to claim Fluxus for postmodernism as \"either the master-code of postmodernism or the ultimately unrepresentable art movement\u2014as it were, postmodernism's sublime.\" Instead he sees Fluxus as a major Neo-Dadaist phenomenon within the avant-garde tradition. It did not represent a major advance in the development of artistic strategies, though it did express a rebellion against \"the administered culture of the 1950s, in which a moderate, domesticated modernism served as ideological prop to the Cold War.\"\nAvant-garde popular music.\nModernism had an uneasy relationship with popular forms of music (both in form and aesthetic) while rejecting popular culture. Despite this, Stravinsky used jazz idioms on his pieces like \"Ragtime\" from his 1918 theatrical work \"Histoire du Soldat\" and 1945's \"Ebony Concerto\".\nIn the 1960s, as popular music began to gain cultural importance and question its status as commercial entertainment, musicians began to look to the post-war avant-garde for inspiration. In 1959, music producer Joe Meek recorded \"I Hear a New World\" (1960), which \"Tiny Mix Tapes\"' Jonathan Patrick calls a \"seminal moment in both electronic music and avant-pop history [...] a collection of dreamy pop vignettes, adorned with dubby echoes and tape-warped sonic tendrils\" which would be largely ignored at the time. Other early Avant-pop productions included the Beatles's 1966 song \"Tomorrow Never Knows\", which incorporated techniques from musique concr\u00e8te, avant-garde composition, Indian music, and electro-acoustic sound manipulation into a 3-minute pop format, and the Velvet Underground's integration of La Monte Young's minimalist and drone music ideas, beat poetry, and 1960s pop art.\nLate period.\nThe continuation of Abstract Expressionism, color field painting, lyrical abstraction, geometric abstraction, minimalism, abstract illusionism, process art, pop art, postminimalism, and other late 20th-century modernist movements in both painting and sculpture continued through the first decade of the 21st century and constitute radical new directions in those mediums.\nAt the turn of the 21st century, well-established artists such as Sir Anthony Caro, Lucian Freud, Cy Twombly, Robert Rauschenberg, Jasper Johns, Agnes Martin, Al Held, Ellsworth Kelly, Helen Frankenthaler, Frank Stella, Kenneth Noland, Jules Olitski, Claes Oldenburg, Jim Dine, James Rosenquist, Alex Katz, Philip Pearlstein, and younger artists including Brice Marden, Chuck Close, Sam Gilliam, Isaac Witkin, Sean Scully, Mahirwan Mamtani, Joseph Nechvatal, Elizabeth Murray, Larry Poons, Richard Serra, Walter Darby Bannard, Larry Zox, Ronnie Landfield, Ronald Davis, Dan Christensen, Pat Lipsky, Joel Shapiro, Tom Otterness, Joan Snyder, Ross Bleckner, Archie Rand, Susan Crile, and others continued to produce vital and influential paintings and sculpture.\nModern architecture.\nMany skyscrapers in Hong Kong and Frankfurt have been inspired by Le Corbusier and modernist architecture, and his style is still used as influence for buildings worldwide.\nModernism in Asia.\nThe terms \"modernism\" and \"modernist\", according to scholar William J. Tyler, \"have only recently become part of the standard discourse in English on modern Japanese literature and doubts concerning their authenticity vis-\u00e0-vis Western European modernism remain\". Tyler finds this odd, given \"the decidedly modern prose\" of such \"well-known Japanese writers as Kawabata Yasunari, Nagai Kafu, and Jun'ichir\u014d Tanizaki\". However, \"scholars in the visual and fine arts, architecture, and poetry readily embraced \"modanizumu\" as a key concept for describing and analysing Japanese culture in the 1920s and 1930s\". In 1924, various young Japanese writers, including Kawabata and Riichi Yokomitsu started a literary journal \"Bungei Jidai\" (\"The Artistic Age\"). This journal was \"part of an 'art for art's sake' movement, influenced by European Cubism, Expressionism, Dada, and other modernist styles\".\nJapanese modernist architect Kenz\u014d Tange (1913\u20132005) was one of the most significant architects of the 20th century, combining traditional Japanese styles with modernism, and designing major buildings on five continents. Tange was also an influential patron of the Metabolist movement. He said: \"It was, I believe, around 1959 or at the beginning of the sixties that I began to think about what I was later to call structuralism\", He was influenced from an early age by the Swiss modernist, Le Corbusier, Tange gained international recognition in 1949 when he won the competition for the design of Hiroshima Peace Memorial Park.\nIn China, the \"New Sensationists\" (\u65b0\u611f\u89ba\u6d3e, X\u012bn G\u01cenju\u00e9 P\u00e0i) were a group of writers based in Shanghai who in the 1930s and 1940s, were influenced, to varying degrees, by Western and Japanese modernism. They wrote fiction more concerned with the unconscious and esthetic than with the socioeconomic. Among these writers were Mu Shiying and Shi Zhecun.\nIn India, the Progressive Artists' Group was a group of modern artists, mainly based in Mumbai, India formed in 1947. Though it lacked any particular style, it synthesized Indian art with European and North America influences from the first half of the 20th century, including Post-Impressionism, Cubism and Expressionism.\nModernism in Africa.\nPeter Kalliney suggests that \"Modernist concepts, especially aesthetic autonomy, were fundamental to the literature of decolonization in anglophone Africa.\" In his opinion, Rajat Neogy, Christopher Okigbo, and Wole Soyinka, were among the writers who \"repurposed modernist versions of aesthetic autonomy to declare their freedom from colonial bondage, from systems of racial discrimination, and even from the new postcolonial state\".\nRelationship with postmodernism.\nBy the early 1980s, the postmodern movement in art and architecture began to establish its position through various conceptual and intermedia formats. Postmodernism in music and literature began to take hold earlier. In music, postmodernism is described in one reference work as a \"term introduced in the 1970s\", while in British literature, \"The Oxford Encyclopaedia of British Literature\" sees modernism \"ceding its predominance to postmodernism\" as early as 1939. However, dates are highly debatable, especially as, according to Andreas Huyssen: \"one critic's postmodernism is another critic's modernism.\" This includes those who are critical of the division between the two, see them as two aspects of the same movement, and believe that late modernism continues.\nModernism is an all-encompassing label for a wide variety of cultural movements. Postmodernism is essentially a centralized movement that named itself, based on socio-political theory, although the term is now used in a wider sense to refer to activities from the 20th century onwards which exhibit awareness of and reinterpret the modern.\nPostmodern theory asserts that the attempt to canonize modernism \"after the fact\" is doomed to unresolvable contradictions. And since the crux of postmodernism critiques any claim to a single discernible truth, postmodernism and modernism conflict on the existence of truth. Where modernists approach the issue of \"truth\" with different theories (correspondence, coherence, pragmatist, semantic, etc.), postmodernists approach the issue of truth negatively by disproving the very existence of an accessible truth.\nIn a narrower sense, what was modernist was not necessarily also postmodernist. Those elements of modernism which accentuated the benefits of rationality and socio-technological progress were only modernist. \nModernist reactions against postmodernism include remodernism, which rejects the cynicism and deconstruction of postmodern art in favor of reviving early modernist aesthetic currents.\nCriticism of late modernity.\nAlthough artistic modernism tended to reject capitalist values such as consumerism, 20th century civil society embraced global mass production and the proliferation of cheap and accessible commodities. This period of social development is known as \"late or high modernity\" and originates in advanced Western societies. The German sociologist J\u00fcrgen Habermas, in \"The Theory of Communicative Action\" (1981), developed the first substantive critique of the culture of late modernity. Another important early critique of late modernity is the American sociologist George Ritzer's \"The McDonaldization of Society\" (1993). Ritzer describes how late modernity became saturated with fast food consumer culture. Other authors have demonstrated how modernist devices appeared in popular cinema, and later on in music videos. Modernist design has entered the mainstream of popular culture, as simplified and stylized forms became popular, often associated with dreams of a space age high-tech future.\nIn 2008, Janet Bennett published \"Modernity and Its Critics\" through The Oxford Handbook of Political Theory. Merging of consumer and high -end versions of modernist culture led to a radical transformation of the meaning of \"modernism\". First, it implied that a movement based on the rejection of tradition had become a tradition of its own. Second, it demonstrated that the distinction between elite modernist and mass consumerist culture had lost its precision. Modernism had become so institutionalized that it was now \"post avant-garde\", indicating that it had lost its power as a revolutionary movement. Many have interpreted this transformation as the beginning of the phase that became known as postmodernism. For others, such as art critic Robert Hughes, postmodernism represents an extension of modernism.\n\"Anti-Modern\" or \"Counter-Modern\" movements seek to emphasize holism, connection and spirituality as remedies or antidotes to modernism. Such movements see modernism as reductionist, and therefore subject to an inability to see systemic and emergent effects.\nSome traditionalist artists like Alexander Stoddart reject modernism generally as the product of \"an epoch of false money allied with false culture\".\nIn some fields, the effects of modernism have remained stronger and more persistent than in others. Visual art has made the most complete break with its past. Most major cities have museums devoted to modern art as distinct from post-Renaissance art (c.\u20091400 to c.\u20091900). Examples include the Museum of Modern Art in New York, the Pinakothek der Moderne in Munich, the Tate Modern in London, and the Pompidou Center in Paris. These galleries make no distinction between modernist and postmodernist phases, seeing both as developments within modern art.\nFootnotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "19548", "revid": "27823944", "url": "https://en.wikipedia.org/wiki?curid=19548", "title": "Marshall McLuhan", "text": "Canadian philosopher and communications scholar (1911\u20131980)\nHerbert Marshall McLuhan (, ; July 21, 1911 \u2013 December 31, 1980) was a Canadian philosopher whose work is among the cornerstones of the study of media theory. Raised in Winnipeg, McLuhan studied at the University of Manitoba and the University of Cambridge. He began his teaching career as a professor of English at several universities in the United States and Canada before moving to the University of Toronto in 1946, where he remained for the rest of his life. He is known as \"the father of media studies\".\nMcLuhan coined the expression \"the medium is the message\" (in the first chapter of his \"Understanding Media: The Extensions of Man\"), as well as the term \"global village.\" He predicted the World Wide Web almost 30 years before it was invented. He was a fixture in media discourse in the late 1960s, though his influence began to wane in the early 1970s. In the years following his death, he continued to be a controversial figure in academic circles. However, with the arrival of the Internet and the World Wide Web, interest was renewed in his work and perspectives.\nLife and career.\nMcLuhan was born on July 21, 1911, in Edmonton, Alberta, and was named \"Marshall\" from his maternal grandmother's surname. His brother, Maurice, was born two years later. His parents were both also born in Canada: his mother, Elsie Naomi (n\u00e9e Hall), was a Baptist school teacher who later became an actress; and his father, Herbert Ernest McLuhan, was a Methodist with a real-estate business in Edmonton. When the business failed at the start of World War I, McLuhan's father enlisted in the Canadian Army. After a year of service, he contracted influenza and remained in Canada, away from the front lines. After Herbert's discharge from the army in 1915, the McLuhan family moved to Winnipeg, Manitoba, where Marshall grew up and went to school, attending Kelvin Technical School before enrolling in the University of Manitoba in 1928.\nUndergraduate education.\nAfter studying for one year as an engineering student in Winnipeg, McLuhan changed majors and earned a Bachelor of Arts degree (1933), winning a University Gold Medal in Arts and Sciences. He went on to receive a Master of Arts degree (1934) in English from the University of Manitoba as well. He had long desired to pursue graduate studies in England and was accepted by Trinity Hall, Cambridge, having failed to secure a Rhodes Scholarship to study at Oxford.\nThough having already earned his BA and MA in Manitoba, Cambridge required him to enroll as an undergraduate \"affiliated\" student, with one year's credit towards a three-year bachelor's degree, before entering any doctoral studies. He went up to Cambridge in the autumn of 1934, studied under I. A. Richards and F. R. Leavis, and was influenced by New Criticism. Years afterward, upon reflection, he credited the faculty there with influencing the direction of his later work because of their emphasis on the \"training of perception\", as well as such concepts as Richards' notion of \"feedforward\". These studies formed an important precursor to his later ideas on technological forms. He received the required bachelor's degree from Cambridge in 1936 and entered their graduate program.\nConversion to Catholicism.\nAt the University of Manitoba, McLuhan explored his conflicted relationship with religion and turned to literature to \"gratify his soul's hunger for truth and beauty,\" later referring to this stage as agnosticism. While studying the trivium at Cambridge, he took the first steps toward his eventual conversion to Catholicism in 1937, founded on his reading of G. K. Chesterton. In 1935, he wrote to his mother:Had I not encountered Chesterton I would have remained agnostic for many years at least. Chesterton did not convince me of religious faith, but he prevented my despair from becoming a habit or hardening into misanthropy. He opened my eyes to European culture and encouraged me to know it more closely. He taught me the reasons for all that in me was simply blind anger and misery.At the end of March 1937, McLuhan completed what was a slow but total conversion process, when he was formally received into the Catholic Church. After consulting a minister, his father accepted the decision to convert. His mother, however, felt that his conversion would hurt his career and was inconsolable. McLuhan was devout throughout his life, but his religion remained a private matter. In his personal correspondence and private writings, he sometimes made connections between his religion and the media: for example, he compared satellite technology to the Star of Bethlehem. He had a lifelong interest in the number three (e.g., the trivium, the Trinity) and sometimes said that the Virgin Mary provided intellectual guidance for him.\nEarly career, marriage, and doctorate.\nUnable to find a suitable job in Canada, he went to the United States to take a job as a teaching assistant at the University of Wisconsin\u2013Madison for the 1936\u201337 academic year. From 1937 to 1944, he taught English at Saint Louis University (with an interruption from 1939 to 1940 when he returned to Cambridge). There he taught courses on Shakespeare, eventually tutoring and befriending Walter J. Ong, who would write his doctoral dissertation on a topic that McLuhan had called to his attention, as well as become a well-known authority on communication and technology.\nMcLuhan met Corinne Lewis in St. Louis, a teacher and aspiring actress from Fort Worth, Texas, whom he married on August 4, 1939. They spent 1939\u201340 in Cambridge, where he completed his master's degree (awarded in January 1940) and began to work on his doctoral dissertation on Thomas Nashe and the verbal arts. While the McLuhans were in England, World War II had erupted in Europe. For this reason, he obtained permission to complete and submit his dissertation from the United States, without having to return to Cambridge for an oral defence. In 1940, the McLuhans returned to Saint Louis University, where they started a family as he continued teaching. He was awarded a Doctor of Philosophy degree in December 1943.\nHe next taught at Assumption College in Windsor, Ontario, from 1944 to 1946, then moved to Toronto in 1946 where he joined the faculty of St. Michael's College, a Catholic college of the University of Toronto, where Hugh Kenner would be one of his students. Canadian economist and communications scholar Harold Innis was a university colleague who had a strong influence on his work. McLuhan wrote in 1964: \"I am pleased to think of my own book \"The Gutenberg Galaxy\" as a footnote to the observations of Innis on the subject of the psychic and social consequences, first of writing then of printing.\" Tom Cooper's \"Wisdom Weavers: The Lives and Thought of Harold Innis and Marshall McLuhan\" explores the relationship of Innis and McLuhan in depth.\nLater career and reputation.\nIn the early 1950s, McLuhan began the Communication and Culture seminars at the University of Toronto, funded by the Ford Foundation. As his reputation grew, he received a growing number of offers from other universities. During this period, he published his first major work, \"\" (1951), in which he examines the effect of advertising on society and culture. Throughout the 1950s, he and Edmund Carpenter also produced an important academic journal called \"Explorations\". McLuhan and Carpenter have been characterized as the Toronto School of communication theory, together with Harold Innis, Eric A. Havelock, and Northrop Frye. During this time, McLuhan supervised the doctoral thesis of modernist writer Sheila Watson on the subject of Wyndham Lewis. Hoping to keep him from moving to another institute, the University of Toronto created the Centre for Culture and Technology (CCT) in 1963.\nFrom 1967 to 1968, McLuhan was named the Albert Schweitzer Chair in Humanities at Fordham University in the Bronx. While at Fordham, he was diagnosed with a benign brain tumour, which was treated successfully. He returned to Toronto where he taught at the University of Toronto for the rest of his life and lived in Wychwood Park, a bucolic enclave on a hill overlooking the downtown where Anatol Rapoport was his neighbour.\nIn 1970, he was made a Companion of the Order of Canada. In 1975, the University of Dallas hosted him from April to May, appointing him to the McDermott Chair. Marshall and Corinne McLuhan had six children: Eric, twins Mary and Teresa, Stephanie, Elizabeth, and Michael. The associated costs of a large family eventually drove him to advertising work and accepting frequent consulting and speaking engagements for large corporations, including IBM and AT&amp;T.\nDeath.\nIn September 1979, McLuhan suffered a stroke which affected his ability to speak. The University of Toronto's School of Graduate Studies tried to close his research centre shortly thereafter, but was deterred by substantial protests. McLuhan never fully recovered from the stroke and died in his sleep on December 31, 1980. He is buried at Holy Cross Cemetery in Thornhill, Ontario, Canada.\nEarly works and influences.\nDuring his years at Saint Louis University (1937\u20131944), McLuhan worked concurrently on two projects: his doctoral dissertation and the manuscript that was eventually published in 1951 as a book, titled \"The Mechanical Bride: Folklore of Industrial Man\", which included only a representative selection of the materials that McLuhan had prepared for it.\nMcLuhan's 1942 Cambridge University doctoral dissertation surveys the history of the verbal arts (grammar, logic, and rhetoric\u2014collectively known as the trivium) from the time of Cicero down to the time of Thomas Nashe. In his later publications, McLuhan at times uses the Latin concept of the \"trivium\" to outline an orderly and systematic picture of certain periods in the history of Western culture. McLuhan suggests that the Late Middle Ages, for instance, were characterized by the heavy emphasis on the formal study of logic. The key development that led to the Renaissance was not the rediscovery of ancient texts, but a shift in emphasis from the formal study of logic to rhetoric and grammar. Modern life is characterized by the re-emergence of grammar as its most salient feature\u2014a trend McLuhan felt was exemplified by the New Criticism of Richards and Leavis.\nMcLuhan also began the academic journal \"Explorations\" with anthropologist Edmund \"Ted\" Carpenter. In a letter to Walter Ong, dated 31 May 1953, McLuhan reports that he had received a two-year grant of $43,000 from the Ford Foundation to carry out a communication project at the University of Toronto involving faculty from different disciplines, which led to the creation of the journal.\nIn 1999, Tom Wolfe suggested that a major under-acknowledged influence on McLuhan's work is the Jesuit philosopher Pierre Teilhard de Chardin, whose ideas anticipated those of McLuhan, especially the evolution of the human mind into the \"noosphere.\" In his early book \"The Gutenberg Galaxy\", however, McLuhan warns against whole-heartedly accepting or outright dismissing Teilhard's observations.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;This externalization of our senses creates what de Chardin [\"sic\"] calls the \"noosphere\" or a technological brain for the world. Instead of tending towards a vast Alexandrian library the world has become a computer, an electronic brain, exactly as in an infantile piece of science fiction. And as our senses have gone outside us, Big Brother goes inside. So, unless aware of this dynamic, we shall at once move into a phase of panic terrors, exactly befitting a small world of tribal drums, total interdependence, and super-imposed co-existence.\nIn his private life, McLuhan wrote to friends saying: \"I am not a fan of Pierre Teilhard de Chardin. The idea that anything is better because it comes later is surely borrowed from pre-electronic technologies.\" Further, McLuhan noted to a Catholic collaborator: \"The idea of a Cosmic thrust in one direction\u00a0... is surely one of the lamest semantic fallacies ever bred by the word 'evolution'.\u2026 That development should have any direction at all is inconceivable except to the highly literate community.\"\nSome of McLuhan's main ideas were influenced or prefigured by anthropologists like Edward Sapir and Claude L\u00e9vi-Strauss, arguably with a more complex historical and psychological analysis. The idea of the retribalization of Western society by the far-reaching techniques of communication, the view on the function of the artist in society, and the characterization of means of transportation, like the railroad and the airplane, as means of communication, are prefigured in Sapir's 1933 article on \"Communication\" in the Encyclopaedia of the Social Sciences, while the distinction between \"hot\" and \"cool\" media draws from L\u00e9vi-Strauss' distinction between hot and cold societies.\nMajor works.\n\"The Mechanical Bride\" (1951).\nMcLuhan's first book, ' (1951), is a pioneering study in the field now known as popular culture. In the book, McLuhan turns his attention to analysing and commenting on numerous examples of persuasion in contemporary popular culture. This followed naturally from his earlier work as both dialectic and rhetoric in the classical trivium aimed at persuasion. At this point, his focus shifted dramatically, turning inward to study the influence of communication media independent of their content. His famous aphorism \"the medium is the message\" (elaborated in his ', 1964) calls attention to this intrinsic effect of communications media.\nHis interest in the critical study of popular culture was influenced by the 1933 book \"Culture and Environment\" by F. R. Leavis and Denys Thompson, and the title \"The Mechanical Bride\" is derived from a piece by the Dadaist artist Marcel Duchamp.\n\"The Mechanical Bride\" is composed of 59 short essays that may be read in any order\u2014what he styled the \"mosaic approach\" to writing a book. Each essay begins with a newspaper or magazine article, or an advertisement, followed by McLuhan's analysis thereof. The analyses bear on aesthetic considerations as well as on the implications behind the imagery and text. McLuhan chose these ads and articles not only to draw attention to their symbolism, as well as their implications for the corporate entities who created and disseminated them, but also to mull over what such advertising implies about the wider society at which it is aimed. Roland Barthes's 1957 essay \"Mythologies\", echoes McLuhan's \"Mechanical Bride\", as a series of exhibits of popular mass culture (like advertisements, newspaper articles and photographs) that are analyzed in a semiological way.\n\"The Gutenberg Galaxy\" (1962).\nWritten in 1961 and first published by University of Toronto Press, \"\" (1962) is a pioneering study in the fields of oral culture, print culture, cultural studies, media ecology or media-adequacy.\nThroughout the book, McLuhan makes efforts to reveal how communication technology (i.e., alphabetic writing, the printing press, and the electronic media) affects cognitive organization, which in turn has profound ramifications for social organization:\n[I]f a new technology extends one or more of our senses outside us into the social world, then new ratios among all of our senses will occur in that particular culture. It is comparable to what happens when a new note is added to a melody. And when the sense ratios alter in any culture then what had appeared lucid before may suddenly become opaque, and what had been vague or opaque will become translucent.\nMovable type.\nMcLuhan's episodic history takes the reader from pre-alphabetic, tribal humankind to the electronic age. According to McLuhan, the invention of movable type greatly accelerated, intensified, and ultimately enabled cultural and cognitive changes that had already been taking place since the invention and implementation of the alphabet, by which McLuhan means phonemic orthography. (McLuhan is careful to distinguish the phonetic alphabet from logographic or logogramic writing systems, such as Egyptian hieroglyphs or ideograms.)\nPrint culture, ushered in by the advance in printing during the middle of the 15th century when the Gutenberg press was invented, brought about the cultural predominance of the visual over the aural/oral. Quoting (with approval) an observation on the nature of the printed word from William Ivins' \"Prints and Visual Communication\", McLuhan remarks:\nIn this passage [Ivins] not only notes the ingraining of lineal, sequential habits, but, even more important, points out the visual homogenizing of experience of print culture, and the relegation of auditory and other sensuous complexity to the background.\u2026The technology and social effects of typography incline us to abstain from noting interplay and, as it were, \"formal\" causality, both in our inner and external lives. Print exists by virtue of the static separation of functions and fosters a mentality that gradually resists any but a separative and compartmentalizing or specialist outlook.\nThe main concept of McLuhan's argument (later elaborated upon in \"The Medium Is the Massage\") is that new technologies (such as alphabets, printing presses, and even speech) exert a gravitational effect on cognition, which in turn, affects social organization: print technology changes our perceptual habits\u2014\"visual homogenizing of experience\"\u2014which in turn affects social interactions\u2014\"fosters a mentality that gradually resists all but a\u2026specialist outlook\". According to McLuhan, this advance of print technology contributed to and made possible most of the salient trends in the modern period in the Western world: individualism, democracy, Protestantism, capitalism, and nationalism. For McLuhan, these trends all reverberate with print technology's principle of \"segmentation of actions and functions and principle of visual quantification.\"\nGlobal village.\nIn the early 1960s, McLuhan wrote that the visual, individualistic print culture would soon be brought to an end by what he called \"electronic interdependence\" wherein electronic media replaces visual culture with aural/oral culture. In this new age, humankind would move from individualism and fragmentation to a collective identity, with a \"tribal base.\" McLuhan's coinage for this new social organization is the \"global village\".\nThe term is sometimes described as having negative connotations in \"The Gutenberg Galaxy\", but McLuhan was interested in exploring effects, not making value judgments:\nInstead of tending towards a vast Alexandrian library the world has become a computer, an electronic brain, exactly as an infantile piece of science fiction. And as our senses have gone outside us, Big Brother goes inside. So, unless aware of this dynamic, we shall at once move into a phase of panic terrors, exactly befitting a small world of tribal drums, total interdependence, and superimposed co-existence.\u2026 Terror is the normal state of any oral society, for in it everything affects everything all the time.\u2026In our long striving to recover for the Western world a unity of sensibility and of thought and feeling we have no more been prepared to accept the tribal consequences of such unity than we were ready for the fragmentation of the human psyche by print culture.\nKey to McLuhan's argument is the idea that technology has no \"per se\" moral bent\u2014it is a tool that profoundly shapes an individual's and, by extension, a society's self-conception and realization:\nIs it not obvious that there are always enough moral problems without also taking a moral stand on technological grounds?\u2026Print is the extreme phase of alphabet culture that detribalizes or decollectivizes man in the first instance. Print raises the visual features of alphabet to highest intensity of definition. Thus, print carries the individuating power of the phonetic alphabet much further than manuscript culture could ever do. Print is the technology of individualism. If men decided to modify this visual technology by an electric technology, individualism would also be modified. To raise a moral complaint about this is like cussing a buzz-saw for lopping off fingers. \"But\", someone says, \"we didn't know it would happen.\" Yet even witlessness is not a moral issue. It is a problem, but not a moral problem; and it would be nice to clear away some of the moral fogs that surround our technologies. It would be good for morality.\nThe moral valence of technology's effects on cognition is, for McLuhan, a matter of perspective. For instance, McLuhan contrasts the considerable alarm and revulsion that the growing quantity of books aroused in the latter 17th century with the modern concern for the \"end of the book.\" If there can be no universal moral sentence passed on technology, McLuhan believes that \"there can only be disaster arising from unawareness of the causalities and effects inherent in our technologies\".\nThough the World Wide Web was invented almost 30 years after \"The Gutenberg Galaxy\", and 10 years after his death, McLuhan prophesied the web technology seen today as early as 1962:\nThe next medium, whatever it is\u2014it may be the extension of consciousness\u2014will include television as its content, not as its environment, and will transform television into an art form. A computer as a research and communication instrument could enhance retrieval, obsolesce mass library organization, retrieve the individual's encyclopedic function and flip into a private line to speedily tailored data of a saleable kind.\nFurthermore, McLuhan coined and certainly popularized the usage of the term \"surfing\" to refer to rapid, irregular, and multidirectional movement through a heterogeneous body of documents or knowledge, e.g., statements such as \"Heidegger surf-boards along on the electronic wave as triumphantly as Descartes rode the mechanical wave.\" Paul Levinson's 1999 book \"Digital McLuhan\" explores the ways that McLuhan's work may be understood better through using the lens of the digital revolution.\nMcLuhan frequently quoted Walter Ong's \"Ramus, Method, and the Decay of Dialogue\" (1958), which evidently had prompted McLuhan to write \"The Gutenberg Galaxy\". Ong wrote a highly favourable review of this new book in \"America\". However, Ong later tempered his praise, by describing McLuhan's \"The Gutenberg Galaxy\" as \"a racy survey, indifferent to some scholarly detail, but uniquely valuable in suggesting the sweep and depth of the cultural and psychological changes entailed in the passage from illiteracy to print and beyond.\" McLuhan himself said of the book, \"I'm not concerned to get any kudos out of [\"The Gutenberg Galaxy\"]. It seems to me a book that somebody should have written a century ago. I wish somebody else had written it. It will be a useful prelude to the rewrite of \"Understanding Media\" [the 1960 NAEB report] that I'm doing now.\"\nMcLuhan's \"The Gutenberg Galaxy\" won Canada's highest literary award, the Governor-General's Award for Non-Fiction, in 1962. The chairman of the selection committee was McLuhan's colleague at the University of Toronto and oftentime intellectual sparring partner, Northrop Frye.\n\"Understanding Media\" (1964).\nMcLuhan's best-known work, \"\" (1964), is a seminal study in media theory. Dismayed by the way in which people approach and use new media such as television, McLuhan famously argues that in the modern world \"we live mythically and integrally\u2026but continue to think in the old, fragmented space and time patterns of the pre-electric age.\"\nMcLuhan proposes that media themselves, not the content they carry, should be the focus of study\u2014popularly quoted as \"the medium is the message\". His insight is that a medium affects the society in which it plays a role not by the content it delivers, but by its own characteristics. McLuhan points to the light bulb as a clear demonstration of this. A light bulb does not have content in the way that a newspaper has articles, or a television has programs, but it is a medium that has a social effect; that is, a light bulb enables people to create spaces at night that would otherwise be enveloped by darkness. He describes the light bulb as a medium without any content. McLuhan writes, \"a light bulb creates an environment by its mere presence.\" More controversially, he postulates that content has little effect on society\u2014for example, whether television broadcasts children's shows or violent programming, its effect on society is identical. He notes that all media have characteristics that engage the viewer in different ways; for instance, a passage in a book can be reread at will, but a movie must be screened again in its entirety to study any part of it.\n\"Hot\" and \"cool\" media.\nIn the first part of \"Understanding Media\", McLuhan writes that different media invite different degrees of participation on the part of a person who chooses to consume a medium. Using terminology derived from French anthropologist Claude L\u00e9vi-Strauss's distinction between hot and cold societies, McLuhan argues that a cool medium requires increased involvement due to decreased description, while a hot medium is the opposite, decreasing involvement and increasing description. In other words, a society that appears to be actively participating in streaming content but does not consider the tool's effects is not allowing an \"extension of ourselves\". A movie is thus said to be \"high definition\", demanding a viewer's attention, and a comic book \"low definition\", requiring much more conscious participation by the reader to extract value: \"Any hot medium allows of less participation than a cool one, as a lecture makes for less participation than a seminar, and a book for less than a dialogue.\"\nSome media, such as movies, are \"hot\"\u2014that is, they enhance a single sense, in this case vision, in such a manner that a person does not need to exert much effort to perceive a detailed moving image. Hot media usually, but not always, provide complete involvement with considerable stimulus. In contrast, \"cool\" print may also occupy visual space, using visual senses, but require focus and comprehension to immerse readers. Hot media creation favour analytical precision, quantitative analysis and sequential ordering, as they are usually sequential, linear, and logical. They emphasize one sense (for example, of sight or sound) over the others. For this reason, hot media include film (especially silent films), radio, the lecture, and photography.\nMcLuhan contrasts \"hot\" media with \"cool\"\u2014specifically, television [of the 1960s i.e. small black-and-white screens], which he claims requires more effort from the viewer to determine meaning; and comics, which, due to their minimal presentation of visual detail, require a high degree of effort to fill in details the cartoonist may have intended to portray. Cool media are usually, but not always, those that provide little involvement with substantial stimulus. They require more active participation on the part of the user, including the perception of abstract patterning and simultaneous comprehension of all parts. Therefore, in addition to television, cool media include seminars and cartoons. McLuhan describes the term \"cool media\" as emerging from jazz and popular music used, in this context, to mean \"detached\".\nThis appears to force media into binary categories, but McLuhan's hot and cool exist on a continuum: they are more correctly measured on a scale than as dichotomous terms.\nCritiques of \"Understanding Media\".\nSome theorists have attacked McLuhan's definition and treatment of the word \"medium\" for being too simplistic. Umberto Eco, for instance, contends that McLuhan's medium conflates channels, codes, and messages under the overarching term of the medium, confusing the vehicle, internal code, and content of a given message in his framework.\nIn \"Media Manifestos\", R\u00e9gis Debray also takes issue with McLuhan's envisioning of the medium. Like Eco, he is ill at ease with this reductionist approach, summarizing its ramifications as follows:\n The list of objections could be and has been lengthened indefinitely: confusing technology itself with its use of the media makes of the media an abstract, undifferentiated force and produces its image in an imaginary \"public\" for mass consumption; the magical naivete of supposed causalities turns the media into a catch-all and contagious \"mana\"; apocalyptic millenarianism invents the figure of a \"homo mass-mediaticus\" without ties to historical and social context, and so on.\nFurthermore, when \"Wired\" magazine interviewed him in 1995, Debray said he saw McLuhan \"more as a poet than a historian, a master of intellectual collage rather than a systematic analyst.\u2026 McLuhan overemphasizes the technology behind cultural change at the expense of the usage that the messages and codes make of that technology.\"\nDwight Macdonald, in turn, reproached McLuhan for his focus on television and for his \"aphoristic\" prose style, which he believes leaves \"Understanding Media\" filled with \"contradictions, non-sequiturs, facts that are distorted and facts that are not facts, exaggerations, and chronic rhetorical vagueness.\"\nBrian Winston's \"Misunderstanding Media\", published in 1986, chides McLuhan for what he sees as his technologically deterministic stances. Raymond Williams furthers this point of contention, claiming:\nThe work of McLuhan was a particular culmination of an aesthetic theory which became, negatively, a social theory\u00a0... It is an apparently sophisticated technological determinism which has the significant effect of indicating a social and cultural determinism.\u2026 For if the medium\u2014whether print or television\u2014is the cause, all other causes, all that men ordinarily see as history, are at once reduced to effects.\nDavid Carr wrote that there has been a long line of \"academics who have made a career out of deconstructing McLuhan\u2019s effort to define the modern media ecosystem\", whether it be due to what they see as McLuhan's ignorance of sociohistorical context or the style of his argument.\nWhile some critics have taken issue with McLuhan's writing style and mode of argument, McLuhan himself urged readers to think of his work as \"probes\" or \"mosaics\" offering a toolkit approach to thinking about media. His eclectic writing style has also been praised for its postmodern sensibilities and suitability for virtual space.\n\"The Medium Is the Massage\" (1967).\n\"\", published in 1967, was McLuhan's best seller, \"eventually selling nearly a million copies worldwide.\" Initiated by Quentin Fiore, McLuhan adopted the term \"massage\" to denote the effect each medium has on the human sensorium, taking inventory of the \"effects\" of numerous media in terms of how they \"massage\" the sensorium.\nFiore, at the time a prominent graphic designer and communications consultant, set about composing the visual illustration of these effects which were compiled by Jerome Agel. Near the beginning of the book, Fiore adopted a pattern in which an image demonstrating a media effect was presented with a textual synopsis on the facing page. The reader experiences a repeated shifting of analytic registers\u2014from \"reading\" typographic print to \"scanning\" photographic facsimiles\u2014reinforcing McLuhan's overarching argument in this book: namely, that each medium produces a different \"massage\" or \"effect\" on the human sensorium.\nIn \"The Medium Is the Massage\", McLuhan also rehashed the argument\u2014which first appeared in the Prologue to 1962's \"The Gutenberg Galaxy\"\u2014that all media are \"extensions\" of our human senses, bodies and minds.\nFinally, McLuhan described key points of change in how man has viewed the world and how these views were changed by the adoption of new media. \"The technique of invention was the discovery of the nineteenth [century]\", brought on by the adoption of fixed points of view and perspective by typography, while \"[t]he technique of the suspended judgment is the discovery of the twentieth century,\" brought on by the bard abilities of radio, movies and television.The past went that-a-way. When faced with a totally new situation we tend always to attach ourselves to the objects, to the flavor of the most recent past. We look at the present through a rear-view mirror. We march backward into the future. Suburbia lives imaginatively in Bonanza-land.An audio recording version of McLuhan's famous work was made by Columbia Records. The recording consists of a pastiche of statements made by McLuhan \"interrupted\" by other speakers, including people speaking in various phonations and falsettos, discordant sounds and 1960s incidental music in what could be considered a deliberate attempt to translate the disconnected images seen on TV into an audio format, resulting in the prevention of a connected stream of conscious thought. Various audio recording techniques and statements are used to illustrate the relationship between spoken, literary speech and the characteristics of electronic audio media. McLuhan biographer Philip Marchand called the recording \"the 1967 equivalent of a McLuhan video.\"\"I wouldn't be seen dead with a living work of art.\"\u2014'Old man' speaking\n\"Drop this jiggery-pokery and talk straight turkey.\"\u2014\"Middle-aged man\" speaking\n\"War and Peace in the Global Village\" (1968).\nIn \"War and Peace in the Global Village\", McLuhan used James Joyce's \"Finnegans Wake\", an inspiration for this study of war throughout history, as an indicator as to how war may be conducted in the future.\nJoyce's \"Wake\" is claimed to be a gigantic cryptogram that reveals a cyclic pattern for human history through its Ten Thunders. Each \"thunder\" below is a 100-character portmanteau of other words to create a statement McLuhan likens to an effect that each technology has on the society into which it is introduced. In order to glean the most understanding out of each, the reader must break the portmanteau into separate words (many of these themselves portmanteaus of words taken from multiple languages other than English) and speak them aloud for the spoken effect of each word. There is much dispute over what each portmanteau truly denotes.\nMcLuhan claims that the ten thunders in \"Wake\" represent different stages in the history of man:\n\"From Clich\u00e9 to Archetype\" (1970).\nCollaborating with Canadian poet Wilfred Watson in \"From Clich\u00e9 to Archetype\" (1970), McLuhan approaches the various implications of the verbal clich\u00e9 and of the archetype. One major facet in McLuhan's overall framework introduced in this book that is seldom noticed is the provision of a new term that actually succeeds the global village: the \"global theatre\".\nIn McLuhan's terms, a \"clich\u00e9\" is a \"normal\" action, phrase, etc. which becomes so often used that we are \"anesthetized\" to its effects. McLuhan provides the example of Eug\u00e8ne Ionesco's play \"The Bald Soprano\", whose dialogue consists entirely of phrases Ionesco pulled from an Assimil language book: \"Ionesco originally put all these idiomatic English clich\u00e9s into literary French which presented the English in the most absurd aspect possible.\"\nMcLuhan's \"archetype\" \"is a quoted extension, medium, technology, or environment.\" \"Environment\" would also include the kinds of \"awareness\" and cognitive shifts brought upon people by it, not totally unlike the psychological context Carl Jung described.\nMcLuhan also posits that there is a factor of interplay between the \"clich\u00e9\" and the \"archetype\", or a \"doubleness\":\nAnother theme of the Wake [\"Finnegans Wake\"] that helps in the understanding of the paradoxical shift from clich\u00e9 to archetype is 'past time are pastimes.' The dominant technologies of one age become the games and pastimes of a later age. In the 20th century, the number of 'past times' that are simultaneously available is so vast as to create cultural anarchy. When all the cultures of the world are simultaneously present, the work of the artist in the elucidation of form takes on new scope and new urgency. Most men are pushed into the artist's role. The artist cannot dispense with the principle of 'doubleness' or 'interplay' because this type of hendiadys dialogue is essential to the very structure of consciousness, awareness, and autonomy.\nMcLuhan relates the clich\u00e9-to-archetype process to the Theatre of the Absurd:\nPascal, in the seventeenth century, tells us that the heart has many reasons of which the head knows nothing. The Theater of the Absurd is essentially a communicating to the head of some of the silent languages of the heart which in two or three hundred years it has tried to forget all about. In the seventeenth century world the languages of the heart were pushed down into the unconscious by the dominant print clich\u00e9.\nThe \"languages of the heart\", or what McLuhan otherwise defined as oral culture, were thus made archetype by means of the printing press, and turned into clich\u00e9.\nAccording to McLuhan, the satellite medium encloses the Earth in a man-made environment, which \"ends 'Nature' and turns the globe into a repertory theatre to be programmed.\" All previous environments (book, newspaper, radio, etc.) and their artifacts are retrieved under these conditions (\"past times are pastimes\"). McLuhan thereby meshes this into the term \"global theatre\". This updates his concept of the global village, which, in its own definitions, can be said to be subsumed into the overall condition of the global theatre.\n\"The Global Village\" (1989).\nIn his posthumous book, \"\" (1989), McLuhan, collaborating with Bruce R. Powers, provides a strong conceptual framework for understanding the cultural implications of the technological advances associated with the rise of a worldwide electronic network. This is a major work of McLuhan's as it contains the most extensive elaboration of his concept of \"acoustic space\", and provides a critique of standard 20th-century communication models such as the Shannon\u2013Weaver model.\nMcLuhan distinguishes between the existing worldview of \"visual space\"\u2014a linear, quantitative, classically geometric model\u2014and that of \"acoustic space\"\u2014a holistic, qualitative order with an intricate, paradoxical topology: \"Acoustic Space has the basic character of a sphere whose focus or center is simultaneously everywhere and whose margin is nowhere.\" The transition from \"visual\" to \"acoustic\" \"space\" was not automatic with the advent of the global network, but would have to be a conscious project. The \"universal environment of simultaneous electronic flow\" inherently favors right-brain Acoustic Space, yet we are held back by habits of adhering to a fixed point of view. There are no boundaries to sound. We hear from all directions at once. Yet Acoustic and Visual Space are inseparable. The resonant interval is the invisible borderline between Visual and Acoustic Space. This is like the television camera that the Apollo 8 astronauts focused on the Earth after they had orbited the Moon.\nMcLuhan illustrates how it feels to exist within acoustic space by quoting from the autobiography of Jacques Lusseyran, \"And There Was Light.\" Lusseyran lost his eyesight in a violent accident as a child, and the autobiography describes how a reordering of his sensory life and perception followed:When I came upon the myth of objectivity in certain modern thinkers, it made me angry. So, there was only one world for these people, the same for everyone. And all the other worlds were to be counted as illusions left over from the past. Or why not call them by their name\u2014hallucinations? I had learned to my cost how wrong they were. From my own experience I knew very well that it was enough to take from a man a memory here, an association there, to deprive him of hearing or sight, for the world to undergo immediate transformation, and for another world, entirely different, but entirely coherent, to be born. Another world? Not really. The same world, rather, but seen from a different angle, and counted in entirely new measures. When this happened all the hierarchies they called objective were turned upside down, scattered to the four winds, not even theories but like whims.Reading, writing, and hierarchical ordering are associated with the left brain and visual space, as are the linear concept of time and phonetic literacy. The left brain is the locus of analysis, classification, and rationality. The right brain and acoustic space are the locus of the spatial, tactile, and musical. \"Comprehensive awareness\" results when the two sides of the brain are in true balance. Visual Space is associated with the simplified worldview of Euclidean geometry, the intuitive three dimensions useful for the architecture of buildings and the surveying of land. It is linearly rational and has no grasp of the acoustic. Acoustic Space is multisensory. McLuhan writes about robotism in the context of Japanese Zen Buddhism and how it can offer us new ways of thinking about technology. The Western way of thinking about technology is too related to the left brain, which has a rational and linear focus. What he called robotism might better be called androidism in the wake of \"Blade Runner\" and the novels of Philip K. Dick. Robotism-androidism emerges from the further development of the right brain, creativity and a new relationship to spacetime (most humans are still living in 17th-century classical Newtonian physics spacetime). Robots-androids will have much greater flexibility than humans have had until now, in both mind and body. Robots-androids will teach humanity this new flexibility. And this flexibility of androids (what McLuhan calls robotism) has a strong affinity with Japanese culture and life. McLuhan quotes from Ruth Benedict's \"The Chrysanthemum and the Sword\" an anthropological study of Japanese culture published in 1946:Occidentals cannot easily credit the ability of the Japanese to swing from one behavior to another without psychic cost. Such extreme possibilities are not included in our experience. Yet in Japanese life the contradictions, as they seem to us, are as deeply based in their view of life as our uniformities are in ours.The ability to live in the present and instantly readjust.\nBeyond existing communication models.\n\"All Western scientific models of communication are\u2014like the Shannon\u2013Weaver model\u2014linear, sequential, and logical as a reflection of the late medieval emphasis on the Greek notion of efficient causality.\" McLuhan and Powers criticize the Shannon-Weaver model of communication as emblematic of left-hemisphere bias and linearity, descended from a print-era perversion of Aristotle's notion of efficient causality.\nA third term of \"The Global Village\" that McLuhan and Powers develop at length is The Tetrad. McLuhan had begun development on the Tetrad as early as 1974. The tetrad is an analogical, simultaneous, fourfold pattern of transformation. \"At full maturity the tetrad reveals the metaphoric structure of the artifact as having two figures and two grounds in dynamic and analogical relationship to each other.\" Like the camera focused on the Earth by the Apollo 8 astronauts, the tetrad reveals figure (Moon) and ground (Earth) simultaneously. The right-brain hemisphere thinking is the capability of being in many places at the same time. Electricity is acoustic. It is simultaneously everywhere. The Tetrad, with its fourfold M\u00f6bius topological structure of enhancement, reversal, retrieval and obsolescence, is mobilized by McLuhan and Powers to illuminate the media or technological inventions of cash money, the compass, the computer, the database, the satellite, and the global media network.\nKey concepts.\nTetrad of media effects.\nIn \"Laws of Media\" (1988), published posthumously by his son Eric, McLuhan summarized his ideas about media in a concise tetrad of media effects. The tetrad is a means of examining the effects on society of any technology (i.e., any medium) by dividing its effects into four categories and displaying them simultaneously. McLuhan designed the tetrad as a pedagogical tool, phrasing his laws as questions with which to consider any medium:\nThe laws of the tetrad exist simultaneously, not successively or chronologically, and allow the questioner to explore the \"grammar and syntax\" of the \"language\" of media. McLuhan departs from his mentor Harold Innis in suggesting that a medium \"overheats,\" or reverses into an opposing form, when taken to its extreme.\nVisually, a tetrad can be depicted as four diamonds forming an X, with the name of a medium in the centre. The two diamonds on the left of a tetrad are the \"Enhancement\" and \"Retrieval\" qualities of the medium, both \"Figure\" qualities. The two diamonds on the right of a tetrad are the \"Obsolescence\" and \"Reversal\" qualities, both \"Ground\" qualities.\nUsing the example of radio:\nFigure and ground.\nMcLuhan adapted the Gestalt psychology idea of a \"figure and a ground\", which underpins the meaning of \"the medium is the message.\" He used this concept to explain how a form of communications technology, the medium, or \"figure\", necessarily operates through its context, or \"ground\".\nMcLuhan believed that in order to grasp fully the effect of a new technology, one must examine figure (medium) and ground (context) together, since neither is completely intelligible without the other. McLuhan argued that we must study media in their historical context, particularly in relation to the technologies that preceded them. The present environment, itself made up of the effects of previous technologies, gives rise to new technologies, which, in their turn, further affect society and individuals.\nAll technologies have embedded within them their own assumptions about time and space. The message which the medium conveys can only be understood if the medium and the environment in which the medium is used\u2014and which, simultaneously, it effectively creates\u2014are analysed together. He believed that an examination of the figure-ground relationship can offer a critical commentary on culture and society.\nOpposition between optic and haptic perception.\nIn McLuhan's (and Harley Parker's) work, electric media have an affinity with haptic and hearing perception, while mechanical media have an affinity with visual perception. This opposition between optic and haptic had previously been formulated by art historians Alois Riegl in his 1901 \"Late Roman Art Industry\", and by Erwin Panofsky, in his 1927 \"Perspective as Symbolic Form\".\nIn his \"The Work of Art in the Age of Mechanical Reproduction\" (1935), Walter Benjamin observed how, in perceptions of modern Western culture, from about the 19th century a shift began from the optic toward the haptic. This shift is one of the main recurring topics in McLuhan's work, which McLuhan attributes to the advent of the electronic era.\nLegacy.\nInfluence.\nAfter the publication of \"Understanding Media\", McLuhan received an astonishing amount of publicity, making him perhaps the most-publicized 20th-century English teacher and arguably the most controversial. This publicity began with the work of two California advertising executives, Howard Gossage and Gerald Feigen, who used personal funds to fund their practice of \"genius scouting\". Much enamoured of McLuhan's work, Feigen and Gossage arranged for McLuhan to meet with editors of several major New York magazines in May 1965 at the Lombardy Hotel in New York. Philip Marchand reports that, as a direct consequence of these meetings, McLuhan was offered the use of an office in the headquarters of both \"Time\" and \"Newsweek\" anytime he wanted it.\nIn August 1965, Feigen and Gossage held what they called a \"McLuhan festival\" in the offices of Gossage's advertising agency in San Francisco. During this \"festival\", McLuhan met with advertising executives, members of the mayor's office, and editors from the \"San Francisco Chronicle\" and \"Ramparts\" magazine. More significant was the presence at the festival of Tom Wolfe, who wrote about McLuhan in a subsequent article, \"What If He Is Right?\", published in \"New York\" magazine and Wolfe's own \"The Pump House Gang\". According to Feigen and Gossage, their work had only a moderate effect on McLuhan's eventual celebrity: they claimed that their work only \"probably speeded up the recognition of his genius by about six months.\" In any case, McLuhan soon became a fixture of media discourse. \"Newsweek\" magazine did a cover story on him; articles appeared in \"Life\", \"Harper's\", \"Fortune\", \"Esquire\", and others. Cartoons about him appeared in \"The New Yorker\". In 1969, \"Playboy\" magazine published a lengthy interview with him. In a running gag on the popular sketch comedy \"Rowan &amp; Martin's Laugh-In\", the \"poet\" Henry Gibson would randomly say, \"Marshall McLuhan, what are you doin'?\"\nMcLuhan was credited with coining the phrase \"Turn on, tune in, drop out\" by its popularizer, Timothy Leary, in the 1960s. In a 1988 interview with Neil Strauss, Leary said the slogan was \"given to him\" by McLuhan during a lunch in New York City. Leary said McLuhan \"was very much interested in ideas and marketing, and he started singing something like, 'Psychedelics hit the spot / Five hundred micrograms, that\u2019s a lot,' to the tune of a Pepsi commercial. Then he started going, 'Tune in, turn on, and drop out.'\"\nDuring his lifetime and afterward, McLuhan heavily influenced cultural critics, thinkers, and media theorists such as Neil Postman, Jean Baudrillard, Timothy Leary, Terence McKenna, William Irwin Thompson, Paul Levinson, Douglas Rushkoff, Jaron Lanier, Hugh Kenner, Joey Skaggs and John David Ebert, as well as political leaders such as Pierre Elliott Trudeau and Jerry Brown. Andy Warhol was paraphrasing McLuhan with his now famous \"15 minutes of fame\" quote. When asked in the 1970s for a way to sedate violence in Angola, he suggested a massive spread of TV devices. Douglas Coupland argued that McLuhan \"was conservative, socially, but he never let politics enter his writing or his teaching\".\nPopular culture.\nWoody Allen's Oscar-winning \"Annie Hall\" (1977) featured McLuhan in a cameo as himself. In the film, a pompous academic is arguing with Allen in a cinema queue when McLuhan suddenly appears and silences him, saying, \"You know nothing of my work.\"\nThe character \"Brian O'Blivion\" in David Cronenberg's 1983 film \"Videodrome\" is a \"media oracle\" based on McLuhan.\nIn 1991, McLuhan was named the \"patron saint\" of \"Wired\" magazine and a quote of his appeared on the masthead for the first ten years of its publication.\nMcLuhan's perspective on the cycle of cultural identity inspired Duke Ellington's album \"The Afro-Eurasian Eclipse\".\nHe is mentioned by name in a Peter Gabriel\u2013penned lyric in the song \"Broadway Melody of 1974\", on Genesis's concept album \"The Lamb Lies Down on Broadway\": \"Marshall McLuhan, casual viewin', head buried in the sand.\"\nMcLuhan is jokingly referred to in an episode of \"The Sopranos\" titled \"House Arrest\".\nDespite his death in 1980, someone claiming to be McLuhan posted on a \"Wired\" mailing list in 1996. The information this person provided convinced one \"Wired\" writer that \"if the poster was not McLuhan himself, it was a bot programmed with an eerie command of McLuhan's life and inimitable perspective.\"\nMcLuhan is the subject of the 1993 play \"The Medium\", the first major work by the Saratoga International Theater Institute and director Anne Bogart. The play was revived by SITI Company for a farewell tour in 2022.\nRecognition.\nA new centre known as the McLuhan Program in Culture and Technology, formed soon after his death in 1980, was the successor to McLuhan's Centre for Culture and Technology at the University of Toronto. Since 1994, it was part of the University of Toronto Faculty of Information. In 2008, the centre incorporated in the Coach House Institute, which was subsequently renamed The McLuhan Centre for Culture and Technology. In 2011, at the time of his centenary, the centre established a \"Marshall McLuhan Centenary Fellowship\" program in his honour. The centre closed in 2023. The Canadian Embassy in Manila awards a Marshall McLuhan Fellowship for \"Excellence in Journalism ... that promotes professional, responsible and courageous media.\"\nIn Toronto, Marshall McLuhan Catholic Secondary School is named after him.\nThe media room at Canada House in Berlin is called the Marshall McLuhan Salon. It includes a multimedia information centre and an auditorium, and hosts a permanent exhibition dedicated to McLuhan, based on its collection of film and audio items by and about him.\nIn 2025, McLuhan's childhood home in Winnipeg was turned into a museum.\nBibliography of major works.\nThis is a partial list of works cited in this article.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\nFootnotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nWorks cited.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "19549", "revid": "949717", "url": "https://en.wikipedia.org/wiki?curid=19549", "title": "Masochism", "text": ""}
{"id": "19550", "revid": "44524978", "url": "https://en.wikipedia.org/wiki?curid=19550", "title": "Multiple inheritance", "text": "In software, to have several parent classes\nMultiple inheritance is a feature of some object-oriented computer programming languages in which an object or class can inherit features from more than one parent object or parent class. It is distinct from single inheritance, where an object or class may only inherit from one particular object or class.\nMultiple inheritance has been a controversial issue for many years, with opponents pointing to its increased complexity and ambiguity in situations such as the \"diamond problem\", where it may be ambiguous as to which parent class a particular feature is inherited from if more than one parent class implements said feature. This can be addressed in various ways, including using virtual inheritance. Alternate methods of object composition not based on inheritance such as mixins and traits have also been proposed to address the ambiguity.\nDetails.\nIn object-oriented programming (OOP), \"inheritance\" describes a relationship between two classes in which one class (the \"child\" class) \"subclasses\" (or \"inherits from\" or \"extends\") the \"parent\" class. The child inherits methods and attributes of the parent, allowing for shared functionality. For example, one might create a variable class codice_1 with features such as eating, reproducing, etc.; then define a child class codice_2 that inherits those features without having to explicitly program them, while adding new features like \"chasing mice\".\nMultiple inheritance allows programmers to use more than one totally orthogonal hierarchy simultaneously, such as allowing codice_2 to extend codice_4, codice_5 and codice_1 and access features from within all of those classes.\nImplementations.\nLanguages that support multiple inheritance include: C++, Common Lisp (via Common Lisp Object System (CLOS)), EuLisp (via The EuLisp Object System TELOS), Curl, Dylan, Eiffel, Logtalk, Object REXX, Scala (via use of mixin classes), OCaml, Perl, POP-11, Python, R, Raku, and Tcl (built-in from 8.6 or via Incremental Tcl (Incr Tcl) in earlier versions).\nIBM System Object Model (SOM) runtime supports multiple inheritance, and any programming language targeting SOM can implement new SOM classes inherited from multiple bases.\nSome object-oriented languages, such as Swift, Java, Fortran since its 2003 revision, C#, and Ruby implement \"single inheritance\", although protocols, or \"interfaces,\" provide some of the functionality of true multiple inheritance.\nPHP uses traits classes to inherit specific method implementations. Ruby uses modules to inherit multiple methods.\nThe diamond problem.\nThe \"diamond problem\" (sometimes referred to as the \"Deadly Diamond of Death\") is an ambiguity that arises when two classes B and C inherit from A, and class D inherits from both B and C. If there is a method in A that B and C have overridden, and D does not override it, then which version of the method does D inherit: that of B, or that of C?\nFor example, in the context of GUI software development, a class codice_7 may inherit from both classes codice_8 (for appearance) and codice_9 (for functionality/input handling), and classes codice_8 and codice_9 both inherit from the codice_12 class. Now if the codice_13 method is called for a codice_7 object and there is no such method in the codice_7 class but there is an overridden codice_13 method in codice_8 or codice_9 (or both), which method should be eventually called?\nIt is called the \"diamond problem\" because of the shape of the class inheritance diagram in this situation. In this case, class A is at the top, both B and C separately beneath it, and D joins the two together at the bottom to form a diamond shape.\nMitigation.\nLanguages have different ways of dealing with these problems of repeated inheritance.\nLanguages that allow only single inheritance, where a class can only derive from one base class, do not have the diamond problem. The reason for this is that such languages have at most one implementation of any method at any level in the inheritance chain regardless of the repetition or placement of methods. Typically these languages allow classes to implement multiple protocols, called interfaces in Java. These protocols define methods but do not provide concrete implementations. This strategy has been used by ActionScript, C#, D, Java, Nemerle, Object Pascal, Objective-C, Smalltalk, Swift and PHP. All these languages allow classes to implement multiple protocols.\nMoreover, Ada, C#, Java, Object Pascal, Objective-C, Swift and PHP allow multiple-inheritance of interfaces (called protocols in Objective-C and Swift). Interfaces are like abstract base classes that specify method signatures without implementing any behaviour. (\"Pure\" interfaces such as the ones in Java up to version 7 do not permit any implementation or instance data in the interface.) Nevertheless, even when several interfaces declare the same method signature, as soon as that method is implemented (defined) anywhere in the inheritance chain, it overrides any implementation of that method in the chain above it (in its superclasses). Hence, at any given level in the inheritance chain, there can be at most one implementation of any method. Thus, single-inheritance method implementation does not exhibit the diamond problem even with multiple-inheritance of interfaces. With the introduction of default implementation for interfaces in Java 8 and C# 8, it is still possible to generate a diamond problem, although this will only appear as a compile-time error.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "19551", "revid": "40123752", "url": "https://en.wikipedia.org/wiki?curid=19551", "title": "Materials Science", "text": ""}
{"id": "19552", "revid": "50464812", "url": "https://en.wikipedia.org/wiki?curid=19552", "title": "Media studies", "text": "Field of study that deals with media\n Media studies is a discipline and field of study that deals with the content, history, and effects of various media; in particular, the mass media. Media studies may draw on traditions from both the social sciences and the humanities, but it mostly draws from its core disciplines of mass communication, communication, communication sciences, and communication studies.\nResearchers may also develop and employ theories and methods from disciplines including cultural studies, rhetoric (including digital rhetoric), philosophy, literary theory, psychology, political science, political economy, economics, sociology, anthropology, social theory, art history and criticism, film theory, and information theory.\nOrigin.\nFormer priest and American educator John Culkin was one of the earliest advocates for the implementation of media studies curriculum in schools. He believed students should be capable of scrutinizing mass media, and valued the application of modern communication techniques within the education system. In 1975, Culkin introduced the first media studies M.A. program in the U.S, which has since graduated more than 2,000 students.\nCulkin was also responsible for bringing his colleague and fellow media scholar Marshall McLuhan to Fordham University, and subsequently founding the Center for Understanding Media, which became the New School program. Both educators are recognized as pioneers in the discipline, credited with paving the way for media studies curriculum within the education system. \nGlobal contributions and perspectives on media studies.\nCanada.\nIn his book \"Understanding Media, The Extensions of Man\", media theorist Marshall McLuhan suggested that \"the medium is the message\", and that all human artefacts and technologies are media. His book introduced the usage of terms such as \"media\" into our language along with other precepts, among them \"global village\" and \"Age of Information\". A medium is anything that mediates our interaction with the world or other humans. Given this perspective, media study is not restricted to just media of communications but all forms of technology. Media and their users form an ecosystem, and the study of this ecosystem is known as media ecology. Media ecology also holds that our environment ultimately changes due to technology. Griffin, Ledbetter, and Sparks elaborate on this theory in their book, stating \"...adding smartphones to a family doesn't create a 'family plus smartphones.' The technology changes the family into something different than what it was before.\"\nMcLuhan says that the \"technique of fragmentation that is the essence of machine technology\" shaped the restructuring of human work and association and \"the essence of automation technology is the opposite\". He uses an example of the electric light to make this connection and to explain how \"the medium is the message\". The electric light is pure information and it is a medium without a message, unless it is used to spell out some verbal ad or a name. The characteristic of all media means the \"content\" of any medium is always another medium. For example, the content of writing is speech, the written word is the content of print, and print is the content of the telegraph. The change that the medium or technology introduces into human affairs is the \"message\". If the electric light is used for a Friday night football game or to light up a desk, it could be argued that the content of the electric light is these activities. The fact that it is the medium that shapes and controls the form of human association and action makes it the message. The electric light is overlooked as a communication medium because it does not have any content. It is not until the electric light is used to spell a brand name that it is recognized as a medium. Similar to radio and other mass media, electric light eliminates time and space factors in human association, creating deeper involvement. McLuhan compared the \"content\" to a juicy piece of meat being carried by a burglar to distract the \"watchdog of the mind\". The effect of the medium is made strong because it is given another media \"content\". The content of a movie is a book, play, or maybe even an opera.\nMcLuhan talks about media being \"hot\" or \"cold\" and touches on the principle that distinguishes them from one another. A hot medium (i.e., radio or a movie) extends a single sense in \"high definition\". High definition refers to the state of being well filled with data. A cool medium (i.e., a telephone or television) is considered \"low definition\" because a small amount of data/information is given and has to be filled in. Hot media are low in participation, because they give one most of the information while excluding certain information. Meanwhile, cool media are high in participation, because inclusively provides information but relies on the viewer to fill in the blanks. McLuhan used lecturing as an example for hot media and seminars as an example for low media. Using a hot medium in a hot or cool culture makes a difference.\nIn his book, \"Empire and Communications\", University of Toronto professor Harold Innis highlighted media technologies as a powerful contributor to the rise and collapse of empires. Innis' theory of media bias utilizes historical evidence to argue that a medium will be biased towards either time or space. He claims that this inherent bias will reveal a medium's significance to the development of its civilization. Innis identifies media biased towards time as a medium durable in character like clay, stone, or parchment. Time biased media are heavy and difficult to relocate, which keeps their message centralized and thus maintains economic and social control within the hands of a hierarchical authority structure. He defines media in favor of space as a lighter, more transferable medium like papyrus. Opposite to media in favor of time, Innis explains that the transferable quality of media biased towards space permits civilizations to expand more quickly across vast areas, thus benefiting the growth of sectors like trade. Space biased media influences an empire to decentralize its power and widen its reach of influence. Though these biases are in competition with each other, Innis argued that an empire requires the presence of both time and space biased media to succeed as a lasting civilization.\nFrance.\nOne prominent French media critic is the sociologist Pierre Bourdieu, who wrote books like \"On Television\" (New Press, 1999). Bourdieu asserts that television provides far less autonomy (or freedom) than we think. From his perspective, the market (which creates a hunt for higher advertising revenue) not only imposes uniformity and banality, but also necessitates a form of invisible censorship. For example, television producers often \"pre-interview\" participants in news and public affairs programs to ensure that they will speak in simple, attention-grabbing terms. When the search for viewers leads to an emphasis on the sensational and the spectacular, people with complex or nuanced views are not allowed a hearing.\nBourdieu is also remembered in the discipline for his theory of the habitus. In his written work \"Outline of a Theory of Practice\" (Bourdieu, 1977), Bourdieu claims an audience's preference in media is shaped by their social context. How an individual interprets and engages with their surroundings, or their habitus, is defined by the lasting and transferable elements of character which structure their consumer preferences. Bourdieu explains that, though durable, the habitus is not set in stone; it instead acts as a \"strategy-generating principle\" allowing individuals to navigate new and unfamiliar situations.\nBourdieu expanded on the theory of the habitus, introducing his famous term, cultural capital. According to the French sociologist, cultural capital signifies an individual's socially or culturally valuable skills and knowledge. He claims that these competencies are developed through one's upbringing and access to education resources, and can be unconsciously shaped by their social environment. Bourdieu highlights this accumulation of competencies as a determining factor in one's life chances. One's cultural capital, such as a university degree, can lead them to be offered more opportunities, thus linking the concept to both economic and social capital. Bourdieu explains that it is through the content of the different capitals that the habitus will structure an individual's consumer taste.\nGermany.\nIn Germany, two main branches of media theory or media studies can be identified.\nThe first major branch of media theory has its roots in the humanities and cultural studies, such as film studies (\"Filmwissenschaft\"), theater studies (\"Theaterwissenschaft\"), German language and literature studies (\"Germanistik\"), and Comparative Literature Studies (\"Komparatistik\"). This branch has broadened out substantially since the 1990s, causing a culturally-based media studies (often emphasized more recently through the disciplinary title \"Medienkulturwissenschaft\") in Germany to be developed and established.\nThis plurality of perspectives make it difficult to single out one particular site where the branch of Medienwissenschaft originated. While the Frankfurt-based theatre scholar Hans-Theis Lehmanns' term \"post dramatic theater\" points directly to the increased blending of co-presence and mediatized material in the German theater (and elsewhere) since the 1970s, the field of theater studies from the 1990s onwards at the Freie Universit\u00e4t Berlin, led in particular by Erika Fischer-Lichte, showed particular interest in the ways in which theatricality influenced notions of performativity in aesthetic events. Within the field of Film Studies, again, both Frankfurt and Berlin were dominant in the development of new perspectives on moving image media. Heide Schl\u00fcpman in Frankfurt and Gertrud Koch [de], first in Bochum then in Berlin, were key theorists contributing to an aesthetic theory of the cinema (Schl\u00fcpmann) as dispositif and the moving image as a medium, particularly in the context of illusion (Koch). Many scholars who became known as media scholars in Germany were originally scholars of German, such as Friedrich Kittler, who taught at the Humboldt Universit\u00e4t zu Berlin and completed both his dissertation and habilitation in the context of \"Germanistik\". One of the early publications in this branch of media studies was a volume edited by Helmut Kreuzer entitled \"Literature Studies - Media Studies\" (\"Literaturwissenschaft \u2013 Medienwissenschaft\"), which summarizes the presentations given at the D\u00fcsseldorfer Germanistentag in 1976.\nThe second branch of media studies in Germany is comparable to Communication Studies. Pioneered by Elisabeth Noelle-Neumann in the 1940s, this branch studies mass media, its institutions, and its effects on society and individuals. The German Institute for Media and Communication Policy, founded in 2005 by media scholar Lutz Hachmeister, is one of the few independent research institutions that is dedicated to issues surrounding media and communications policies.\nThe term \"Wissenschaft\" cannot be directly translated to \"studies\", as it invokes both scientific methods and the humanities. Accordingly, German media theory combines philosophy, psychoanalysis, history, and scientific studies with media-specific research.\nPoland.\nAccording to the Zeszyty Prasoznawcze, translated to Press Journals in English, one of the \"architects\" of media studies in Poland is Professor Walery Pisarek. Pisarek spent over 40 years of his career studying how topics such as persuasion, language, and propaganda intersect with media studies and linguistics, specifically in Poland. This focus on linguistics also led to Pisarek's support of the Polish Language Act, a piece of legislation that protected the Polish language and its use while also promoting the Polish culture and history.\nUnited Kingdom.\nMuch research in the field of news media studies has been led by the Reuters Institute for the Study of Journalism. Details of the research projects and results are published in the RISJ annual report. In addition to the research performed at the Reuters Institute, media researchers in the United Kingdom have also used comments from the British press to look at their impression of media studies as a topic for study. Researchers Lucy Bennett and Jenny Kidd found that there was a link between the Conservative party in Britain and the idea that media studies was not an academic field worth studying due to its lack of scientific principles and employability for students.\nStuart Hall, a Jamaican-born social scientist, also contributed to the field of media studies through his writings on cultural studies, separate but similar to media studies. Hall's main viewpoint was that the mainstream media as a whole served the beliefs of the rich and powerful within society, an idea that was heavily influenced by Karl Marx and Antonio Gramsci in his writings. By naming his theory \"cultural studies\", Hall was able to bring in the cultural element of media studies that he felt was often left out by academics in the field.\nUnited States.\nDespite the field normally being called mass communication in American circles, many theories within the realm of media studies have evolved from the United States. Elihu Katz's uses and gratifications theory examines why individuals choose to take in media. At its core, the uses and gratifications theory explores how there is no single reason why people consume the messages that they do. Instead, one person consumes specific media for different reasons than another person may consume the same media. Some possible gratifications include \"companionship\", \"escape\", and \"information\".\nA newer theory from the 2010s comes from danah boyd and Alice Marwick when they studied how media eliminates borders between contexts. In their joint article, they refer to this as part of a process called 'context collapse'. Context collapse refers to how a media platform can flatten multiple audiences into one and allow information intended for one audience to reach another unintended audience. An individual may present themselves to multiple audiences in various ways, but through context collapse, they are put in front of every audience at the same time and must choose which identity to assume.\nIn the United States, there is a rise in research surrounding social media and its use as a media form for communication. As the amount of social media research is on the rise, many researchers are calling on social media corporations to release data about their services to the general public.\nMedia studies in education.\nAustralia.\nMedia is studied as a broad subject in most states in Australia. Media studies in Australia was first developed as an area of study in Victorian universities in the early 1960s, and in secondary schools in the mid 1960s.\nToday, almost all Australian universities teach media studies. According to the Government of Australia's \"Excellence in Research for Australia\" report, the leading universities in the country for media studies (which were ranked well above world standards by the report's scoring methodology) are Monash University, QUT, RMIT, University of Melbourne, University of Queensland, and UTS.\nIn secondary schools, an early film studies course was first introduced as a part of the Victorian junior secondary curriculum during the mid 1960s. By the early 1970s, an expanded media studies course was being taught. The course became part of the senior secondary curriculum (later known as the Victorian Certificate of Education or \"VCE\") in the 1980s. It has since become, and continues to be, a strong component of the VCE. Notable figures in the development of the Victorian secondary school curriculum were the long time Rusden College media teacher Peter Greenaway, Trevor Barr (who authored one of the first media text books \"Reflections of Reality\") and later John Murray (who authored \"The Box in the Corner\", \"In Focus\", and \"10 Lessons in Film Appreciation\").\nToday, Australian states and territories that teach media studies at a secondary level are Australian Capital Territory, Northern Territory, Queensland, South Australia, Victoria, and Western Australia. Media studies does not appear to be taught in the state of New South Wales at a secondary level.\nIn Victoria, the VCE media studies course is structured as: Unit 1 \u2013 Representation, Technologies of Representation, and New Media; Unit 2 \u2013 Media Production, Australian Media Organisations; Unit 3 \u2013 Narrative Texts, Production Planning; and Unit 4 \u2013 Media Process, Social Values, and Media Influence. Media studies also forms a major part of the primary and junior secondary curriculum, and includes areas such as photography, print media, and television.\nVictoria also hosts the peak media teaching body known as ATOM which publishes \"Metro\" and \"Screen Education\" magazines.\nCanada.\nIn Canada, media studies and communication studies are incorporated in the same departments and cover a wide range of approaches (from critical theory and organizations to research-creation and political economy, for example). Over time, research developed to employ theories and methods from cultural studies, philosophy, political economy, gender, sexuality and race theory, management, rhetoric, film theory, sociology, and anthropology. Harold Innis and Marshall McLuhan are famous Canadian scholars for their contributions to the fields of media ecology and political economy in the 20th century. They were both important members of the Toronto School of Communication at the time. More recently, the School of Montreal and its founder James R. Taylor significantly contributed to the field of organizational communication by focusing on the ontological processes of organizations.\nIn 1945 and 1946, Carleton University and the University of Western Ontario (respectively) created journalism specific programs or schools. A journalism specific program was also created at Ryerson in 1950. The first communication programs in Canada were started at Ryerson and Concordia Universities. The Radio and Television Arts program at Ryerson was started in the 1950s, while the Film, Media Studies/Media Arts, and Photography programs also originated from programs started in the 1950s. The Communication studies department at Concordia was created in the late 1960s. Ryerson's Radio and Television, Film, Media and Photography programs were renowned by the mid 1970s, and its programs were being copied by other colleges and universities nationally and internationally. Western University later followed suit, establishing The Faculty of Information and Media Studies. Carleton later expanded upon its school of journalism, introducing the mass communication and media studies program in 1978.\nToday, most universities offer undergraduate degrees in Media and Communication Studies, and many Canadian scholars actively contribute to the field, among which: Brian Massumi (philosophy, cultural studies), Kim Sawchuk (cultural studies, feminist, ageing studies), Carrie Rentschler (feminist theory), and Fran\u00e7ois Cooren (organizational communication).\nChina.\nThere are two universities in China that specialize in media studies. Communication University of China, formerly known as the Beijing Broadcasting Institute, dates back to 1954 and includes media studies. CUC has 15,307 full-time students, including 9,264 undergraduates, 3,512 candidates for doctor and master's degrees, and 16,780 students in programs of continuing education. The other university known for media studies in China is Zhejiang University of Media and Communications (ZUMC) which has campuses in Hangzhou and Tongxiang. Almost 10,000 full-time students are currently studying in over 50 programs at the 13 Colleges and Schools of ZUMC. Both institutions have produced some of China's brightest broadcasting talents for television, as well as leading journalists at magazines and newspapers.\nCzech Republic.\nThere is no university focused on journalism and media studies, but there are seven public universities which have a department of media studies. The three biggest universities are based in Prague (Charles University), Brno (Masaryk University) and Olomouc (Palack\u00fd University). There are another nine private universities and colleges that have a media studies department.\nFrance.\nNumerous French post-secondary institutions offer courses in communications and media studies at both the undergraduate and graduate levels. Media and communications programs at ESCP Business School, Paris Institute of Political Studies, and Grenoble Alpes University center around the study of journalism and other multimedia content, teaching media creation and management strategies.\nGermany.\n\"Medienwissenschaften\" is currently one of the most popular courses of study at universities in Germany, with many applicants mistakenly assuming that studying it will automatically lead to a career in TV or other media. This has led to widespread disillusionment, with students blaming the universities for offering highly theoretical course content. The universities maintain that practical journalistic training is not the aim of the academic studies they offer.\nIndia.\nMedia Studies is a fast growing academic field in India, with several dedicated departments and research institutes. With a view to making the best use of communication facilities for information, publicity, and development, the Government of India in 1962-63 sought the advice of the Ford Foundation/UNESCO team of internationally known mass communication specialists who recommended setting up a national institute for training, teaching, and research in mass communication. Anna University was the first university to start a Master of Science in Electronic Media program. It offers a five-year integrated program and a two-year program in Electronic Media. The Department of Media Sciences was started in January 2002, branching off from the UGC's Educational Multimedia Research Centre (EMMRC). The National Institute of Open Schooling, the world's largest open schooling system, offers Mass Communication as a subject of studies at senior secondary level. All the major universities in the country have mass media and journalism studies departments, including Asian College of Journalism, Chennai, Indian Institute of Mass Communication, New Delhi, Xavier Institute of Communications, O. P. Jindal Global University - Delhi, Mumbai, Parul University, Vadodara, Amity University, Jawaharlal Neheru University, Apeejay Institute of Mass Communications, Brainware University Kolkata, and others. Centre for the Study of Developing Societies (CSDS), Delhi has media studies as an emphasis.\nNetherlands.\nIn the Netherlands, media studies is split into several academic courses, such as (applied) communication sciences, communication and information sciences, communication and media, media and culture or theater, and film and television sciences. While communication sciences focuses on the way people communicate, be it mediated or unmediated, media studies tends to narrow the communication down to just mediated communication.\nCommunication sciences (or a derivative thereof) can be studied at Erasmus University Rotterdam, Radboud University, Tilburg University, University of Amsterdam, University of Groningen, University of Twente, Roosevelt Academy, University of Utrecht, VU University Amsterdam, and Wageningen University and Research Centre.\nMedia studies (or something similar) can be studied at the University of Amsterdam, VU University Amsterdam, Erasmus University Rotterdam, University of Groningen, University of Maastricht, and the University of Utrecht.\nNine Dutch universities collaborate in the overarching Netherlands Research school for Media Studies (RMeS), which acts as a platform for graduate students to build connections within the media studies discipline and to represent Dutch media scholars on an international level.\nNew Zealand.\nMedia studies in New Zealand is a healthy discipline, mainly due to renewed activity in the country's film industry, and is taught at both secondary and tertiary education institutes. Media studies in NZ can be regarded as a singular success, with the subject well-established in the tertiary sector (such as Screen and Media Studies at the University of Waikato; Media Studies, Victoria University of Wellington; Film, Television and Media Studies, University of Auckland; Media Studies, Massey University; Communication Studies, University of Otago).\nDifferent courses can offer students a range of specializations, such as cultural studies, media theory and analysis, practical film-making, journalism, and communications studies. Media studies has been a nationally mandated and very popular subject in secondary (high) schools, taught across three years in a very structured and developmental fashion, with Scholarship in Media Studies available for academically gifted students. According to the New Zealand Ministry of Education Subject Enrollment figures, 229 New Zealand schools offered Media Studies as a subject in 2016, representing more than 14,000 students.\nPakistan.\nIn Pakistan, media studies programs are widely offered. International Islamic University has the oldest department in the country, now called the \"Department of Media and Communication Studies\". Later on, the University of Karachi and the Federal Urdu University of Arts, Science, and Technology established departments of mass communication in 2002. Peshawar University, BZU Multaan, Islamia University Bahwalpur also started communication programs. Now, newly established universities are also offering mass communication programs, in which University of Gujrat emerged as a leading figure. Bahria University, which was established by the Pakistan Navy, is also offering a BS in media studies.\nSwitzerland.\nIn Switzerland, media and communication studies are offered by several higher education institutions, including the International Institute in Geneva, Zurich University of Applied Sciences, University of Lugano, University of Fribourg, and others. The Swiss programs study current trends and strategies used by media corporations, while examining their influence and consequences on modern day society.\nUnited Kingdom.\nIn the United Kingdom, media studies developed in the 1960s from the academic study of English and, more broadly, from literary criticism. The key date, according to Andrew Crisell, is 1959:\nWhen Joseph Trenaman left the BBC's Further Education Unit to become the first holder of the Granada Research Fellowship in Television at Leeds University. Soon after in 1966, the Centre for Mass Communication Research was founded at Leicester University, and degree programs in media studies began to sprout at polytechnics and other universities during the 1970s and 1980s.\nJames Halloran at the University of Leicester is credited for his influence in the development of media studies and communication studies, as the head of the university's Centre for Mass Communication Research and founder of the International Association for Media and Communication Research. Media Studies is now taught all over the UK. It is taught at Key Stages 1\u2013 3, Entry Level, GCSE and at A level; the Scottish Qualifications Authority also offers formal qualifications at a number of different levels. It is offered through a large area of exam boards, including AQA and WJEC.\nAs mentioned earlier, much research in the field of news media studies has been led by the Reuters Institute for the Study of Journalism, which is one of the leaders in news media research for the United Kingdom. The Institute focuses on journalism and news media as topics of study.\nUnited States.\nMass communication, communication studies or simply 'communication' are names that are used far more frequently than \"media studies\" for academic departments in the United States. However, the focus of such programs sometimes excludes certain media\u2014film, book publishing, video games, etc. The title \"media studies\" may be used to designate film studies and rhetorical or critical theory, or it may appear in combinations like \"media studies and communication\" to join two fields or emphasize a different focus. It involves the study of many emerging contemporary media and platforms, with social media growing in popularity in recent years. Broadcast and cable television is no longer the primary form of entertainment, with various screens offering worldwide events and pastimes around the clock. Many institutions within the United States have since changed and revised their media studies programs.\nIn 1999, the MIT Comparative Media Studies program started under the leadership of Henry Jenkins. The program has since grown to include a graduate program; it is MIT's largest humanities major, and, following a 2012 merger with the Writing and Humanistic Studies program, now has a roster of twenty faculty, including Pulitzer Prize-winning author Junot D\u00edaz, science fiction writer Joe Haldeman, games scholar T. L. Taylor, and media scholars William Uricchio (a CMS co-founder), Edward Schiappa, and Heather Hendershot. Now named Comparative Media Studies/Writing, the department places an emphasis on what Jenkins and colleagues have termed \"applied humanities\": it hosts several research groups for civic media, digital humanities, games, computational media, documentary, and mobile design, and these groups are used to provide graduate students with research assistantships to cover the cost of tuition and living expenses. The incorporation of Writing and Humanistic Studies also placed MIT's Science Writing program, Writing Across the Curriculum, and Writing and Communications Center under the same roof.\nIn 2000, the Department of Media Studies was officially established in 2000 at the University of Virginia; the interdisciplinary major has rapidly grown and doubled in size in 2011. This is partly thanks to the acquisition of Professor Siva Vaidhyanathan, a cultural historian and media scholar, as well as the Inaugural Verklin Media Policy and Ethics Conference, endowed by the CEO of Canoe Ventures and UVA alumnus David Verklin.\nUniversity of California, Irvine had professor Mark Poster, who was one of the first and foremost theorists of media culture in the US and boasted a strong Department of Film &amp; Media Studies. University of California, Berkeley has three institutional structures within media studies that take place in the department of Film and Media (formerly Film Studies Program), including famous theorists as Mary Ann Doane and Linda Williams, the Center for New Media, and a long established interdisciplinary program formerly titled Mass Communications, which recently changed its name to Media Studies. This change eliminated any connotations that may have accompanied the term \"mass\" in the former title. Until recently, Radford University in Virginia used the title \"media studies\" for a department that taught practitioner-oriented major concentrations in journalism, advertising, broadcast production, and web design. In 2008, those programs were combined with a previous department of communication (speech and public relations) to create a School of Communication. (A media studies major at Radford still means someone concentrating on journalism, broadcasting, advertising or Web production.)\nBrooklyn College has collaborated with City University of New York to offer graduate studies in television and media since 2015. Currently, the Department of Television and Radio administers an MS in Media Studies, and hosts the Center for the Study of World Television.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "19553", "revid": "43007828", "url": "https://en.wikipedia.org/wiki?curid=19553", "title": "Microprocessor", "text": "Computer processor contained on an integrated-circuit chip\nA microprocessor is a computer processor for which the data processing logic and control is included on a single integrated circuit (IC), or a small number of ICs. The microprocessor contains the arithmetic, logic, and control circuitry required to perform the functions of a computer's central processing unit (CPU). The IC is capable of interpreting and executing program instructions and performing arithmetic operations. The microprocessor is a multipurpose, clock-driven, register-based, digital integrated circuit that accepts binary data as input, processes it according to instructions stored in its memory, and provides results (also in binary form) as output. Microprocessors contain both combinational logic and sequential digital logic, and operate on numbers and symbols represented in the binary number system.\nThe integration of a whole CPU onto a single or a few integrated circuits using very-large-scale integration (VLSI) greatly reduced the cost of processing power. Integrated circuit processors are produced in large numbers by highly automated metal\u2013oxide\u2013semiconductor (MOS) fabrication processes, resulting in a relatively low unit price. Single-chip processors increase reliability because there are fewer electrical connections that can fail. As microprocessor designs improve, the cost of manufacturing a chip (with smaller components built on a semiconductor chip the same size) generally stays the same, according to Rock's law.\nBefore microprocessors, small computers had been built using racks of circuit boards with many medium- and small-scale integrated circuits. These were typically of the TTL type. Microprocessors combined this into one or a few large-scale ICs. While there is disagreement over who deserves credit for the invention of the microprocessor, the first commercially available microprocessor was the Intel 4004, designed by Federico Faggin and introduced in 1971.\nContinued increases in microprocessor capacity have since rendered other forms of computers almost completely obsolete (see history of computing hardware), with one or more microprocessors used in everything from the smallest embedded systems and handheld devices to the largest mainframes and supercomputers.\nA microprocessor is distinct from a microcontroller including a system on a chip. A microprocessor is related but distinct from a digital signal processor, a specialized microprocessor chip, with its architecture optimized for the operational needs of digital signal processing.\nStructure.\nThe complexity of an integrated circuit is bounded by physical limitations on the number of transistors that can be put onto one chip, the number of package terminations that can connect the processor to other parts of the system, the number of interconnections it is possible to make on the chip, and the heat that the chip can dissipate. Advancing technology makes more complex and powerful chips feasible to manufacture.\nA minimal hypothetical microprocessor might include only an arithmetic logic unit (ALU), and a control logic section. The ALU performs addition, subtraction, and operations such as AND or OR. Each operation of the ALU sets one or more flags in a status register, which indicate the results of the last operation (zero value, negative number, overflow, or others). The control logic retrieves instruction codes from memory and initiates the sequence of operations required for the ALU to carry out the instruction. A single operation code might affect many individual data paths, registers, and other elements of the processor.\nAs integrated circuit technology advanced, it was feasible to manufacture more and more complex processors on a single chip. The size of data objects became larger; allowing more transistors on a chip allowed word sizes to increase from 4- and 8-bit words up to today's 64-bit words. Additional features were added to the processor architecture; more on-chip registers sped up programs, and complex instructions could be used to make more compact programs. Floating-point arithmetic, for example, was often not available on 8-bit microprocessors, but had to be carried out in software. Integration of the floating-point unit, first as a separate integrated circuit and then as part of the same microprocessor chip, sped up floating-point calculations.\nOccasionally, physical limitations of integrated circuits made such practices as a bit slice approach necessary. Instead of processing all of a long word on one integrated circuit, multiple circuits in parallel processed subsets of each word. While this required extra logic to handle, for example, carry and overflow within each slice, the result was a system that could handle, for example, 32-bit words using integrated circuits with a capacity for only four\u00a0bits each.\nThe ability to put large numbers of transistors on one chip makes it feasible to integrate memory on the same die as the processor. This CPU cache has the advantage of faster access than off-chip memory and increases the processing speed of the system for many applications. Processor clock frequency has increased more rapidly than external memory speed, so cache memory is necessary if the processor is not to be delayed by slower external memory.\nThe design of some processors has become complicated enough to be difficult to fully test, and this has caused problems at large cloud providers.\nSpecial-purpose designs.\nA microprocessor is a general-purpose processing entity. Several specialized processing devices have followed:\nSpeed and power considerations.\nMicroprocessors can be selected for differing applications based on their word size, which is a measure of their complexity. Longer word sizes allow each clock cycle of a processor to carry out more computation, but correspond to physically larger integrated circuit dies with higher standby and operating power consumption. 4-, 8- or 12-bit processors are widely integrated into microcontrollers operating embedded systems. Where a system is expected to handle larger volumes of data or require a more flexible user interface, 16-, 32- or 64-bit processors are used. An 8- or 16-bit processor may be selected over a 32-bit processor for system on a chip or microcontroller applications that require extremely low-power electronics, or are part of a mixed-signal integrated circuit with noise-sensitive on-chip analog electronics such as high-resolution analog to digital converters, or both.\nSome people say that running 32-bit arithmetic on an 8-bit chip could end up using more power, as the chip must execute software with multiple instructions.\nHowever, others say that modern 8-bit chips are always more power-efficient than 32-bit chips when running equivalent software routines.\nEmbedded applications.\nThousands of items that were traditionally not computer-related include microprocessors. These include household appliances, vehicles (and their accessories), tools and test instruments, toys, light switches/dimmers and electrical circuit breakers, smoke alarms, battery packs, and hi-fi audio/visual components (from DVD players to phonograph turntables). Such products as cellular telephones, DVD video system and HDTV broadcast systems fundamentally require consumer devices with powerful, low-cost, microprocessors. Increasingly stringent pollution control standards effectively require automobile manufacturers to use microprocessor engine management systems to allow optimal control of emissions over the widely varying operating conditions of an automobile. Non-programmable controls would require bulky, or costly implementation to achieve the results possible with a microprocessor.\nA microprocessor control program (embedded software) can be tailored to fit the needs of a product line, allowing upgrades in performance with minimal redesign of the product. Unique features can be implemented in product line's various models at negligible production cost.\nMicroprocessor control of a system can provide control strategies that would be impractical to implement using electromechanical controls or purpose-built electronic controls. For example, an internal combustion engine's control system can adjust ignition timing based on engine speed, load, temperature, and any observed tendency for knocking\u2014allowing the engine to operate on a range of fuel grades.\nHistory.\nThe advent of low-cost computers on integrated circuits has transformed modern society. General-purpose microprocessors in personal computers are used for computation, text editing, multimedia display, and communication over the Internet. Many more microprocessors are part of embedded systems, providing digital control over myriad objects from appliances to automobiles to cellular phones and industrial process control. Microprocessors perform binary operations based on Boolean logic, named after George Boole. The ability to operate computer systems using Boolean logic was first proven in a 1938 thesis by master's student Claude Shannon, who later went on to become a professor. Shannon is considered \"The Father of Information Theory\". In 1951, microprogramming was invented by Maurice Wilkes at the University of Cambridge from the realisation that the central processor could be controlled by a specialised program in a dedicated ROM. Wilkes is also credited with the idea of symbolic labels, macros and subroutine libraries. \nFollowing the development of MOS integrated circuit chips in the early 1960s, MOS chips reached higher transistor density and lower manufacturing costs than bipolar integrated circuits by 1964. MOS chips further increased in complexity at a rate predicted by Moore's law, leading to large-scale integration (LSI) with hundreds of transistors on a single MOS chip by the late 1960s. The application of MOS LSI chips to computing was the basis for the first microprocessors, as engineers began recognizing that a complete computer processor could be contained on several MOS LSI chips. Designers in the late 1960s were striving to integrate the central processing unit (CPU) functions of a computer onto a handful of MOS LSI chips, called microprocessor unit (MPU) chipsets.\nWhile there is disagreement over who invented the microprocessor, the first commercially available microprocessor was the Intel 4004, released as a single MOS LSI chip in 1971. The single-chip microprocessor was made possible with the development of MOS silicon-gate technology (SGT). The earliest MOS transistors had aluminium metal gates, which Italian physicist Federico Faggin replaced with silicon self-aligned gates to develop the first silicon-gate MOS chip at Fairchild Semiconductor in 1968. Faggin later joined Intel and used his silicon-gate MOS technology to develop the 4004, along with Marcian Hoff, Stanley Mazor and Masatoshi Shima in 1971. The 4004 was designed for Busicom, which had earlier proposed a multi-chip design in 1969, before Faggin's team at Intel changed it into a new single-chip design. The 4-bit Intel 4004 was soon followed by the 8-bit Intel 8008 in 1972. The MP944 chipset used in the F-14 Central Air Data Computer in 1970 has also been cited as an early microprocessor, but was not known to the public until declassified in 1998.\nOther embedded uses of 4-bit and 8-bit microprocessors, such as terminals, printers, various kinds of automation etc., followed soon after. Affordable 8-bit microprocessors with 16-bit addressing also led to the first general-purpose microcomputers from the mid-1970s on.\nThe first use of the term \"microprocessor\" is attributed to Viatron Computer Systems describing the custom integrated circuit used in their System 21 small computer system announced in 1968.\nSince the early 1970s, the increase in capacity of microprocessors has followed Moore's law; this originally suggested that the number of components that can be fitted onto a chip doubles every year. With present technology, it is actually every two years, and as a result Moore later changed the period to two years.\nFirst projects.\nThese projects delivered a microprocessor at about the same time: Garrett AiResearch's Central Air Data Computer (CADC) (1970), Texas Instruments' TMS 1802NC (September 1971) and Intel's 4004 (November 1971, based on an earlier 1969 Busicom design). Arguably, Four-Phase Systems AL1 microprocessor was also delivered in 1969.\nFour-Phase Systems AL1 (1969).\nThe Four-Phase Systems AL1 was an 8-bit bit slice chip containing eight registers and an ALU. It was designed by Lee Boysel in 1969. At the time, it formed part of a nine-chip, 24-bit CPU with three AL1s. It was later called a microprocessor when, in response to 1990s litigation by Texas Instruments, Boysel constructed a demonstration system where a single AL1 with a 1969 datestamp formed part of a courtroom demonstration computer system, together with RAM, ROM, and an input-output device. The AL1 wasn't sold individually, but was part of the System IV/70 announced in September 1970 and first delivered in February 1972.\nGarrett AiResearch CADC (1970).\nIn 1968, Garrett AiResearch (who employed designers Ray Holt and Steve Geller) was invited to produce a digital computer to compete with electromechanical systems then under development for the main flight control computer in the US Navy's new F-14 Tomcat fighter. The design was complete by 1970, and used a MOS-based chipset as the core CPU. The design was significantly (approximately 20 times) smaller and much more reliable than the mechanical systems it competed against and was used in all of the early Tomcat models. This system contained \"a 20-bit, pipelined, parallel multi-microprocessor\". The Navy refused to allow publication of the design until 1997. Released in 1998, the documentation on the CADC, and the MP944 chipset, are well known. Ray Holt's autobiographical story of this design and development is presented in the book: The Accidental Engineer.\nRay Holt graduated from California State Polytechnic University, Pomona in 1968, and began his computer design career with the CADC. From its inception, it was shrouded in secrecy until 1998 when at Holt's request, the US Navy allowed the documents into the public domain. Holt has claimed that no one has compared this microprocessor with those that came later. According to Parab et al. (2007), &lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The scientific papers and literature published around 1971 reveal that the MP944 digital processor used for the F-14 Tomcat aircraft of the US Navy qualifies as the first microprocessor. Although interesting, it was not a single-chip processor, as was not the Intel 4004\u00a0\u2013 they both were more like a set of parallel building blocks you could use to make a general-purpose form. It contains a CPU, RAM, ROM, and two other support chips like the Intel 4004. It was made from the same P-channel technology, operated at military specifications and had larger chips\u00a0\u2013 an excellent computer engineering design by any standards. Its design indicates a major advance over Intel, and two year earlier. It actually worked and was flying in the F-14 when the Intel 4004 was announced. It indicates that today's industry theme of converging DSP-microcontroller architectures was started in 1971. This convergence of DSP and microcontroller architectures is known as a digital signal controller.\nGilbert Hyatt (1970).\nIn 1990, American engineer Gilbert Hyatt was awarded U.S. Patent No. 4,942,516, which was based on a 16-bit serial computer he built at his Northridge, California, home in 1969 from boards of bipolar chips after quitting his job at Teledyne in 1968; though the patent had been submitted in December 1970 and prior to Texas Instruments' filings for the TMX 1795 and TMS 0100, Hyatt's invention was never manufactured. This nonetheless led to claims that Hyatt was the inventor of the microprocessor and the payment of substantial royalties through a Philips N.V. subsidiary, until Texas Instruments prevailed in a complex legal battle in 1996, when the U.S. Patent Office overturned key parts of the patent, while allowing Hyatt to keep it. Hyatt said in a 1990 \"Los Angeles Times\" article that his invention would have been created had his prospective investors backed him, and that the venture investors leaked details of his chip to the industry, though he did not elaborate with evidence to support this claim. In the same article, \"The Chip\" author T.R. Reid was quoted as saying that historians may ultimately place Hyatt as a co-inventor of the microprocessor, in the way that Intel's Noyce and TI's Kilby share credit for the invention of the chip in 1958: \"Kilby got the idea first, but Noyce made it practical. The legal ruling finally favored Noyce, but they are considered co-inventors. The same could happen here.\" Hyatt would go on to fight a decades-long legal battle with the state of California over alleged unpaid taxes on his patent's windfall after 1990, which would culminate in a landmark Supreme Court case addressing states' sovereign immunity in \"Franchise Tax Board of California v. Hyatt (2019)\".\nTexas Instruments TMX 1795 (1970\u20131971).\nTexas Instruments developed in 1970\u20131971 a one-chip CPU replacement for the Datapoint 2200 terminal, the TMX 1795 (later TMC 1795). Like Intel's later 8008, it was rejected by customer Datapoint. According to Gary Boone, the TMX 1795 never reached production. Still it reached a prototype state at 1971 February 24. Since it was built to the same specification, its instruction set was very similar to the Intel 8008.\nTexas Instruments TMS 1802NC (1971).\nThe TMS1802NC, announced September 17, 1971, was the first microcontroller and at launch implemented a four-function calculator. The TMS1802NC, despite its designation, was not part of the TMS 1000 series; it was later redesignated as part of the TMS 0100 series, which was used in the TI Datamath calculator. It was marketed as a calculator-on-a-chip and also \"fully programmable\", but this programming had to done during manufacturing. Its chip integrated a CPU with an 11-bit instruction word, 3520 bits (320 instructions) of ROM and 182 bits of RAM.\nPico/General Instrument (1971).\nIn 1971, Pico Electronics and General Instrument (GI) introduced their first collaboration in ICs, a complete single-chip calculator IC for the Monroe/Litton Royal Digital III calculator. This chip could also arguably lay claim to be one of the first microprocessors or microcontrollers having ROM, RAM and a RISC instruction set on-chip. The layout for the four layers of the PMOS process was hand drawn at x500 scale on mylar film, a significant task at the time given the complexity of the chip.\nPico was a spinout by five GI design engineers whose vision was to create single-chip calculator ICs. They had significant previous design experience on multiple calculator chipsets with both GI and Marconi-Elliott. The key team members had originally been tasked by Elliott Automation to create an 8-bit computer in MOS and had helped establish a MOS Research Laboratory in Glenrothes, Scotland in 1967.\nCalculators were becoming the largest single market for semiconductors so Pico and GI went on to have significant success in this burgeoning market. GI continued to innovate in microprocessors and microcontrollers with products including the CP1600, IOB1680 and PIC1650. In 1987, the GI Microelectronics business was spun out into the Microchip PIC microcontroller business.\nIntel 4004 (1971).\nThe Intel 4004 is often (falsely) regarded as the first true microprocessor built on a single chip, priced at US$. The first known advertisement for the 4004 is dated November 15, 1971, and appeared in \"Electronic News\". The microprocessor was designed by a team consisting of Italian engineer Federico Faggin, American engineers Marcian Hoff and Stanley Mazor, and Japanese engineer Masatoshi Shima.\nThe project that produced the 4004 originated in 1969, when Busicom, a Japanese calculator manufacturer, asked Intel to build a chipset for high-performance desktop calculators. Busicom's original design called for a programmable chip set consisting of seven different chips. Three of the chips were to make a special-purpose CPU with its program stored in ROM and its data stored in shift register read-write memory. Ted Hoff, the Intel engineer assigned to evaluate the project, believed the Busicom design could be simplified by using dynamic RAM storage for data, rather than shift register memory, and a more traditional general-purpose CPU architecture. Hoff came up with a four-chip architectural proposal: a ROM chip for storing the programs, a dynamic RAM chip for storing data, a simple I/O device, and a 4-bit central processing unit (CPU). Although not a chip designer, he felt the CPU could be integrated into a single chip, but as he lacked the technical know-how the idea remained just a wish for the time being.\nWhile the architecture and specifications of the MCS-4 came from the interaction of Hoff with Stanley Mazor, a software engineer reporting to him, and with Busicom engineer Masatoshi Shima, during 1969, Mazor and Hoff moved on to other projects. In April 1970, Intel hired Italian engineer Federico Faggin as project leader, a move that ultimately made the single-chip CPU final design a reality (Shima meanwhile designed the Busicom calculator firmware and assisted Faggin during the first six months of the implementation). Faggin, who originally developed the silicon gate technology (SGT) in 1968 at Fairchild Semiconductor and designed the world's first commercial integrated circuit using SGT, the Fairchild 3708, had the correct background to lead the project into what would become the first commercial general purpose microprocessor. Since SGT was his very own invention, Faggin also used it to create his new methodology for random logic design that made it possible to implement a single-chip CPU with the proper speed, power dissipation and cost. The manager of Intel's MOS Design Department was Leslie L. Vad\u00e1sz at the time of the MCS-4 development but Vad\u00e1sz's attention was completely focused on the mainstream business of semiconductor memories so he left the leadership and the management of the MCS-4 project to Faggin, who was ultimately responsible for leading the 4004 project to its realization. Production units of the 4004 were first delivered to Busicom in March 1971 and shipped to other customers in late 1971.\n8-bit designs.\nThe Intel 4004 was followed in 1972 by the Intel 8008, intel's first 8-bit microprocessor. The 8008 was not, however, an extension of the 4004 design, but instead the culmination of a separate design project at Intel, arising from a contract with Computer Terminals Corporation, of San Antonio TX, for a chip for a terminal they were designing, the Datapoint 2200\u2014fundamental aspects of the design came not from Intel but from CTC. In 1968, CTC's Vic Poor and Harry Pyle developed the original design for the instruction set and operation of the processor. In 1969, CTC contracted two companies, Intel and Texas Instruments, to make a single-chip implementation, known as the CTC 1201. In late 1970 or early 1971, TI dropped out being unable to make a reliable part. In 1970, with Intel yet to deliver the part, CTC opted to use their own implementation in the Datapoint 2200, using traditional TTL logic instead (thus the first machine to run \"8008 code\" was not in fact a microprocessor at all and was delivered a year earlier). Intel's version of the 1201 microprocessor arrived in late 1971, but was too late, slow, and required a number of additional support chips. CTC had no interest in using it. CTC had originally contracted Intel for the chip, and would have owed them US$ for their design work. To avoid paying for a chip they did not want (and could not use), CTC released Intel from their contract and allowed them free use of the design. Intel marketed it as the 8008 in April, 1972, as the world's first 8-bit microprocessor. It was the basis for the famous \"Mark-8\" computer kit advertised in the magazine \"Radio-Electronics\" in 1974. This processor had an 8-bit data bus and a 14-bit address bus.\nThe 8008 was the precursor to the successful Intel 8080 (1974), which offered improved performance over the 8008 and required fewer support chips. Federico Faggin conceived and designed it using high voltage N channel MOS. The Zilog Z80 (1976) was also a Faggin design, using low voltage N channel with depletion load and derivative Intel 8-bit processors: all designed with the methodology Faggin created for the 4004. Motorola released the competing 6800 in August 1974, and the similar MOS Technology 6502 was released in 1975 (both designed largely by the same people). The 6502 family rivaled the Z80 in popularity during the 1980s.\nA low overall cost, little packaging, simple computer bus requirements, and sometimes the integration of extra circuitry (e.g. the Z80's built-in memory refresh circuitry) allowed the home computer \"revolution\" to accelerate sharply in the early 1980s. This delivered such inexpensive machines as the Sinclair ZX81, which sold for US$. A variation of the 6502, the MOS Technology 6510 was used in the Commodore 64 and yet another variant, the 8502, powered the Commodore 128.\nThe Western Design Center, Inc (WDC) introduced the CMOS WDC 65C02 in 1982 and licensed the design to several firms. It was used as the CPU in the Apple IIe and IIc personal computers as well as in medical implantable grade pacemakers and defibrillators, automotive, industrial and consumer devices. WDC pioneered the licensing of microprocessor designs, later followed by ARM (32-bit) and other microprocessor intellectual property (IP) providers in the 1990s.\nMotorola introduced the MC6809 in 1978. It was an ambitious and well thought-through 8-bit design that was source compatible with the 6800, and implemented using purely hard-wired logic (subsequent 16-bit microprocessors typically used microcode to some extent, as CISC design requirements were becoming too complex for pure hard-wired logic).\nAnother early 8-bit microprocessor was the Signetics 2650, which enjoyed a brief surge of interest due to its innovative and powerful instruction set architecture.\nA seminal microprocessor in the world of spaceflight was RCA's RCA 1802 (aka CDP1802, RCA COSMAC) (introduced in 1976), which was used on board the \"Galileo\" probe to Jupiter (launched 1989, arrived 1995). RCA COSMAC was the first to implement CMOS technology. The CDP1802 was used because it could be run at very low power, and because a variant was available fabricated using a special production process, silicon on sapphire (SOS), which provided much better protection against cosmic radiation and electrostatic discharge than that of any other processor of the era. Thus, the SOS version of the 1802 was said to be the first radiation-hardened microprocessor.\nThe RCA 1802 had a static design, meaning that the clock frequency could be made arbitrarily low, or even stopped. This let the \"Galileo\" spacecraft use minimum electric power for long uneventful stretches of a voyage. Timers or sensors would awaken the processor in time for important tasks, such as navigation updates, attitude control, data acquisition, and radio communication. Current versions of the Western Design Center 65C02 and 65C816 also have static cores, and thus retain data even when the clock is completely halted.\n12-bit designs.\nThe Intersil 6100 family consisted of a 12-bit microprocessor (the 6100) and a range of peripheral support and memory ICs. The microprocessor recognised the DEC PDP-8 minicomputer instruction set. As such it was sometimes referred to as the CMOS-PDP8. Since it was also produced by Harris Corporation, it was also known as the Harris HM-6100. By virtue of its CMOS technology and associated benefits, the 6100 was being incorporated into some military designs until the early 1980s.\n16-bit designs.\nThe first multi-chip 16-bit microprocessor was the National Semiconductor IMP-16, introduced in early 1973. An 8-bit version of the chipset was introduced in 1974 as the IMP-8.\nOther early multi-chip 16-bit microprocessors include the MCP-1600 that Digital Equipment Corporation (DEC) used in the LSI-11 OEM board set and the packaged PDP-11/03 minicomputer\u2014and the Fairchild Semiconductor MicroFlame 9440, both introduced in 1975\u201376. In late 1974, National introduced the first 16-bit single-chip microprocessor, the National Semiconductor PACE, which was later followed by an NMOS version, the INS8900.\nNext in list is the General Instrument CP1600, released in February 1975, which was used mainly in the Intellivision console.\nAnother early single-chip 16-bit microprocessor was TI's TMS 9900, which was also compatible with their TI-990 line of minicomputers. The 9900 was used in the TI 990/4 minicomputer, the TI-99/4A home computer, and the TM990 line of OEM microcomputer boards. The chip was packaged in a large ceramic 64-pin DIP package, while most 8-bit microprocessors such as the Intel 8080 used the more common, smaller, and less expensive plastic 40-pin DIP. A follow-on chip, the TMS 9980, was designed to compete with the Intel 8080, had the full TI 990 16-bit instruction set, used a plastic 40-pin package, moved data 8\u00a0bits at a time, but could only address 16\u00a0KB. A third chip, the TMS 9995, was a new design. The family later expanded to include the 99105 and 99110.\nThe Western Design Center (WDC) introduced the CMOS 65816 16-bit upgrade of the WDC CMOS 65C02 in 1984. The 65816 16-bit microprocessor was the core of the Apple IIGS and later the Super Nintendo Entertainment System, making it one of the most popular 16-bit designs of all time.\nIntel \"upsized\" their 8080 design into the 16-bit Intel 8086, the first member of the x86 family, which powers most modern PC type computers. Intel introduced the 8086 as a cost-effective way of porting software from the 8080 lines, and succeeded in winning much business on that premise. The 8088, a version of the 8086 that used an 8-bit external data bus, was the microprocessor in the first IBM PC. Intel then released the 80186 and 80188, the 80286 and, in 1985, the 32-bit 80386, cementing their PC market dominance with the processor family's backwards compatibility. The 80186 and 80188 were essentially versions of the 8086 and 8088, enhanced with some onboard peripherals and a few new instructions. Although Intel's 80186 and 80188 were not used in IBM PC type designs, second source versions from NEC, the V20 and V30 frequently were. The 8086 and successors had an innovative but limited method of memory segmentation, while the 80286 introduced a full-featured segmented memory management unit (MMU). The 80386 introduced a flat 32-bit memory model with paged memory management.\nThe 16-bit Intel x86 processors up to and including the 80386 do not include floating-point units (FPUs). Intel introduced the 8087, 80187, 80287 and 80387 math coprocessors to add hardware floating-point and transcendental function capabilities to the 8086 through 80386 CPUs. The 8087 works with the 8086/8088 and 80186/80188, the 80187 works with the 80186 but not the 80188, the 80287 works with the 80286 and the 80387 works with the 80386. The combination of an x86 CPU and an x87 coprocessor forms a single multi-chip microprocessor; the two chips are programmed as a unit using a single integrated instruction set. The 8087 and 80187 coprocessors are connected in parallel with the data and address buses of their parent processor and directly execute instructions intended for them. The 80287 and 80387 coprocessors are interfaced to the CPU through I/O ports in the CPU's address space, this is transparent to the program, which does not need to know about or access these I/O ports directly; the program accesses the coprocessor and its registers through normal instruction opcodes.\n32-bit designs.\n16-bit designs had only been on the market briefly when 32-bit implementations started to appear.\nThe most significant of the 32-bit designs is the Motorola MC68000, introduced in 1979. The 68k, as it was widely known, had 32-bit registers in its programming model but used 16-bit internal data paths, three 16-bit Arithmetic Logic Units, and a 16-bit external data bus (to reduce pin count), and externally supported only 24-bit addresses (internally it worked with full 32\u00a0bit addresses). In PC-based IBM-compatible mainframes the MC68000 internal microcode was modified to emulate the 32-bit System/370 IBM mainframe. Motorola generally described it as a 16-bit processor. The combination of high performance, large (16\u00a0megabytes or 224\u00a0bytes) memory space and fairly low cost made it the most popular CPU design of its class. The Apple Lisa and Macintosh designs made use of the 68000, as did other designs in the mid-1980s, including the Atari ST and Amiga.\nThe world's first single-chip fully 32-bit microprocessor, with 32-bit data paths, 32-bit buses, and 32-bit addresses, was the AT&amp;T Bell Labs BELLMAC-32A, with first samples in 1980, and general production in 1982. After the divestiture of AT&amp;T in 1984, it was renamed the WE 32000 (WE for Western Electric), and had two follow-on generations, the WE 32100 and WE 32200. These microprocessors were used in the AT&amp;T 3B5 and 3B15 minicomputers; in the 3B2, the world's first desktop super microcomputer; in the \"Companion\", the world's first 32-bit laptop computer; and in \"Alexander\", the world's first book-sized super microcomputer, featuring ROM-pack memory cartridges similar to today's gaming consoles. All these systems ran the UNIX System V operating system.\nThe first commercial, single chip, fully 32-bit microprocessor available on the market was the HP FOCUS.\nIntel's first 32-bit microprocessor was the iAPX 432, which was introduced in 1981, but was not a commercial success. It had an advanced capability-based object-oriented architecture, but poor performance compared to contemporary architectures such as Intel's own 80286 (introduced 1982), which was almost four times as fast on typical benchmark tests. However, the results for the iAPX432 was partly due to a rushed and therefore suboptimal Ada compiler.\nMotorola's success with the 68000 led to the MC68010, which added virtual memory support. The MC68020, introduced in 1984 added full 32-bit data and address buses. The 68020 became hugely popular in the Unix supermicrocomputer market, and many small companies (e.g., Altos, Charles River Data Systems, Cromemco) produced desktop-size systems. The MC68030 was introduced next, improving upon the previous design by integrating the MMU into the chip. The continued success led to the MC68040, which included an FPU for better math performance. The 68050 failed to achieve its performance goals and was not released, and the follow-up MC68060 was released into a market saturated by much faster RISC designs. The 68k family faded from use in the early 1990s.\nOther large companies designed the 68020 and follow-ons into embedded equipment. At one point, there were more 68020s in embedded equipment than there were Intel Pentiums in PCs. The ColdFire processor cores are derivatives of the 68020.\nDuring this time (early to mid-1980s), National Semiconductor introduced a very similar 16-bit pinout, 32-bit internal microprocessor called the NS 16032 (later renamed 32016), the full 32-bit version named the NS 32032. Later, National Semiconductor produced the NS 32132, which allowed two CPUs to reside on the same memory bus with built in arbitration. The NS32016/32 outperformed the MC68000/10, but the NS32332\u2014which arrived at approximately the same time as the MC68020\u2014did not have enough performance. The third generation chip, the NS32532, was different. It had about double the performance of the MC68030, which was released around the same time. The appearance of RISC processors like the AM29000 and MC88000 (now both dead) influenced the architecture of the final core, the NS32764. Technically advanced\u2014with a superscalar RISC core, 64-bit bus, and internally overclocked\u2014it could still execute Series 32000 instructions through real-time translation.\nWhen National Semiconductor decided to leave the Unix market, the chip was redesigned into the Swordfish Embedded processor with a set of on-chip peripherals. The chip turned out to be too expensive for the laser printer market and was killed. The design team went to Intel and there designed the Pentium processor, which is very similar to the NS32764 core internally. The big success of the Series 32000 was in the laser printer market, where the NS32CG16 with microcoded BitBlt instructions had very good price/performance and was adopted by large companies like Canon. By the mid-1980s, Sequent introduced the first SMP server-class computer using the NS 32032. This was one of the design's few wins, and it disappeared in the late 1980s. The MIPS R2000 (1984) and R3000 (1989) were highly successful 32-bit RISC microprocessors. They were used in high-end workstations and servers by SGI, among others. Other designs included the Zilog Z80000, which arrived too late to market to stand a chance and disappeared quickly.\nThe ARM first appeared in 1985. This is a RISC processor design, which has since come to dominate the 32-bit embedded systems processor space due in large part to its power efficiency, its licensing model, and its wide selection of system development tools. Semiconductor manufacturers generally license cores and integrate them into their own system on a chip products; only a few such vendors such as Apple are licensed to modify the ARM cores or create their own. Most cell phones include an ARM processor, as do a wide variety of other products. There are microcontroller-oriented ARM cores without virtual memory support, as well as symmetric multiprocessor (SMP) applications processors with virtual memory.\nFrom 1993 to 2003, the 32-bit x86 architectures became increasingly dominant in desktop, laptop, and server markets, and these microprocessors became faster and more capable. Intel had licensed early versions of the architecture to other companies, but declined to license the Pentium, so AMD and Cyrix built later versions of the architecture based on their own designs. During this span, these processors increased in complexity (transistor count) and capability (instructions/second) by at least three orders of magnitude. Intel's Pentium line is probably the most famous and recognizable 32-bit processor model, at least with the public at broad.\n64-bit designs in personal computers.\nWhile 64-bit microprocessor designs have been in use in several markets since the early 1990s (including the Nintendo 64 gaming console in 1996), the early 2000s saw the introduction of 64-bit microprocessors targeted at the PC market.\nWith AMD's introduction of a 64-bit architecture backwards-compatible with x86, x86-64 (also called AMD64), in September 2003, followed by Intel's near fully compatible 64-bit extensions (first called IA-32e or EM64T, later renamed Intel 64), the 64-bit desktop era began. Both versions can run 32-bit legacy applications without any performance penalty as well as new 64-bit software. With operating systems Windows XP x64, Windows Vista x64, Windows 7 x64, Linux, BSD, and macOS that run 64-bit natively, the software is also geared to fully utilize the capabilities of such processors. The move to 64\u00a0bits is more than just an increase in register size from the IA-32 as it also doubles the number of general-purpose registers.\nThe move to 64\u00a0bits by PowerPC had been intended since the architecture's design in the early 90s and was not a major cause of incompatibility. Existing integer registers are extended as are all related data pathways, but, as was the case with IA-32, both floating-point and vector units had been operating at or above 64\u00a0bits for several years. Unlike what happened when IA-32 was extended to x86-64, no new general purpose registers were added in 64-bit PowerPC, so any performance gained when using the 64-bit mode for applications making no use of the larger address space is minimal.\nIn 2011, ARM introduced the new 64-bit ARM architecture.\nRISC.\nIn the mid-1980s to early 1990s, a crop of new high-performance reduced instruction set computer (RISC) microprocessors appeared, influenced by discrete RISC-like CPU designs such as the IBM 801 and others. RISC microprocessors were initially used in special-purpose machines and Unix workstations, but then gained wide acceptance in other roles.\nThe first commercial RISC microprocessor design was released in 1984, by MIPS Computer Systems, the 32-bit R2000 (the R1000 was not released). In 1986, HP released its first system with a PA-RISC CPU. In 1987, in the non-Unix Acorn computers' 32-bit, then cache-less, ARM2-based Acorn Archimedes became the first commercial success using the ARM architecture, then known as Acorn RISC Machine (ARM); first silicon ARM1 in 1985. The R3000 made the design truly practical, and the R4000 introduced the world's first commercially available 64-bit RISC microprocessor. Competing projects would result in the IBM POWER and Sun SPARC architectures. Soon every major vendor was releasing a RISC design, including the AT&amp;T CRISP, AMD 29000, Intel i860 and Intel i960, Motorola 88000, DEC Alpha.\nIn the late 1990s, only two 64-bit RISC architectures were still produced in volume for non-embedded applications: SPARC and Power ISA, but as ARM has become increasingly powerful, in the early 2010s, it became the third RISC architecture in the general computing segment.\nSMP and multi-core design.\nSMP \"symmetric multiprocessing\" is a configuration of two, four, or more CPU's (in pairs) that are typically used in servers, certain workstations and in desktop personal computers, since the 1990s. A multi-core processor is a single CPU that contains more than one microprocessor core.\nThis popular two-socket motherboard from Abit was released in 1999 as the first SMP enabled PC motherboard, the Intel Pentium Pro was the first commercial CPU offered to system builders and enthusiasts. The Abit BP9 supports two Intel Celeron CPU's and when used with a SMP enabled operating system (Windows NT/2000/Linux) many applications obtain much higher performance than a single CPU. The early Celerons are easily overclockable and hobbyists used these relatively inexpensive CPU's clocked as high as 533Mhz - far beyond Intel's specification. After discovering the capacity of these motherboards Intel removed access to the multiplier in later CPU's.\nIn 2001\u00a0IBM released the POWER4 CPU, it was a processor that was developed over five years of research, began in 1996 using a team of 250 researchers. The effort to accomplish the impossible was buttressed by development of and through\u2014remote-collaboration and assigning younger engineers to work with more experienced engineers. The teams work achieved success with the new microprocessor, Power4. It is a two-in-one CPU that more than doubled performance at half the price of the competition, and a major advance in computing. The business magazine \"eWeek\" wrote: \"The newly designed 1GHz Power4 represents a tremendous leap over its predecessor\". An industry analyst, Brad Day of Giga Information Group said: \"\"IBM is getting very aggressive, and this server is a game changer\".\"\nThe Power4 won \"\"Analysts\u2019 Choice Award for Best Workstation/Server Processor of 2001\", and\" it broke notable records, including winning a contest against the best players on the Jeopardy! U.S. television show.\nIntel's codename Yonah CPU's launched on Jan 6, 2006, and were manufactured with two dies packaged on a multi-chip module. In a hotly contested marketplace AMD and others released new versions of multi-core CPU's, AMD's SMP enabled Athlon MP CPU's from the AthlonXP line in 2001, Sun released the Niagara and Niagara 2 with eight-cores, AMD's Athlon X2 was released in June 2007. The companies were engaged in a never-ending race for speed, indeed more demanding software mandated more processing power and faster CPU speeds.\nBy 2012 \"dual and quad-core\" processors became widely used in PCs and laptops, newer processors - similar to the higher cost professional level Intel Xeon's - with additional cores that execute instructions in parallel so software performance typically increases, provided the software is designed to utilize advanced hardware. Operating systems provided support for multiple-cores and SMD CPU's, many software applications including large workload and resource intensive applications - such as 3-D games - are programmed to take advantage of multiple core and multi-CPU systems.\nApple, Intel, and AMD currently lead the market with multiple core desktop and workstation CPU's. Although they frequently leapfrog each other for the lead in the performance tier. Intel retains higher frequencies and thus has the fastest single core performance, while AMD is often the leader in multi-threaded routines due to a more advanced ISA and the process node the CPU's are fabricated on.\nMultiprocessing concepts for multi-core/multi-cpu configurations are related to Amdahl's law.\nMarket statistics.\nIn 1997, about 55% of all CPUs sold in the world were 8-bit microcontrollers, of which over 2\u00a0billion were sold.\nIn 2002, less than 10% of all the CPUs sold in the world were 32-bit or more. Of all the 32-bit CPUs sold, about 2% are used in desktop or laptop personal computers. Most microprocessors are used in embedded control applications such as household appliances, automobiles, and computer peripherals. Taken as a whole, the average price for a microprocessor, microcontroller, or DSP is just over US$.\nIn 2003, about $44\u00a0billion (equivalent to about $ billion in 2024) worth of microprocessors were manufactured and sold. Although about half of that money was spent on CPUs used in desktop or laptop personal computers, those count for only about 2% of all CPUs sold. The quality-adjusted price of laptop microprocessors improved \u221225% to \u221235% per year in 2004\u20132010, and the rate of improvement slowed to \u221215% to \u221225% per year in 2010\u20132013.\nAbout 10\u00a0billion CPUs were manufactured in 2008. Most new CPUs produced each year are embedded.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "19554", "revid": "40123752", "url": "https://en.wikipedia.org/wiki?curid=19554", "title": "Mp3", "text": ""}
{"id": "19555", "revid": "14383484", "url": "https://en.wikipedia.org/wiki?curid=19555", "title": "Molecule", "text": "Electrically neutral group of two or more atoms\nA molecule is a group of two or more atoms that are held together by attractive forces known as chemical bonds; depending on context, the term may or may not include ions that satisfy this criterion. In quantum physics, organic chemistry, and biochemistry, the distinction from ions is dropped and \"molecule\" is often used when referring to polyatomic ions.\nA molecule may be homonuclear, that is, it consists of atoms of one chemical element, e.g. two atoms in the oxygen molecule (O2); or it may be heteronuclear, a chemical compound composed of more than one element, e.g. water (two hydrogen atoms and one oxygen atom; H2O). In the kinetic theory of gases, the term \"molecule\" is often used for any gaseous particle regardless of its composition. This relaxes the requirement that a molecule contains two or more atoms, since the noble gases are individual atoms. Atoms and complexes connected by non-covalent interactions, such as hydrogen bonds or ionic bonds, are typically not considered single molecules.\nConcepts similar to molecules have been discussed since ancient times, but modern investigation into the nature of molecules and their bonds began in the 17th century. Refined over time by scientists such as Robert Boyle, Amedeo Avogadro, Jean Perrin, and Linus Pauling, the study of molecules is today known as molecular physics or molecular chemistry.\nEtymology.\nAccording to Merriam-Webster and the Online Etymology Dictionary, the word \"molecule\" derives from the Latin \"moles\" or small unit of mass. The word is derived from French \"mol\u00e9cule\" (1678), from Neo-Latin \"molecula\", diminutive of Latin \"moles\" \"mass, barrier\". The word, which until the late 18th century was used only in Latin form, became popular after being used in works of philosophy by Descartes.\nHistory.\nThe definition of the molecule has evolved as knowledge of the structure of molecules has increased. Earlier definitions were less precise, defining molecules as the smallest particles of pure chemical substances that still retain their composition and chemical properties. This definition often breaks down since many substances in ordinary experience, such as rocks, salts, and metals, are composed of large crystalline networks of chemically bonded atoms or ions, but are not made of discrete molecules.\nThe modern concept of molecules can be traced back towards pre-scientific and Greek philosophers such as Leucippus and Democritus who argued that all the universe is composed of atoms and voids. Circa 450 BC Empedocles imagined fundamental elements (fire (), earth (), air (), and water ()) and \"forces\" of attraction and repulsion allowing the elements to interact.\nA fifth element, the incorruptible quintessence aether, was considered to be the fundamental building block of the heavenly bodies. The viewpoint of Leucippus and Empedocles, along with the aether, was accepted by Aristotle and passed to medieval and renaissance Europe.\nIn a more concrete manner, however, the concept of aggregates or units of bonded atoms, i.e. \"molecules\", traces its origins to Robert Boyle's 1661 hypothesis, in his famous treatise \"The Sceptical Chymist\", that matter is composed of \"clusters of particles\" and that chemical change results from the rearrangement of the clusters. Boyle argued that matter's basic elements consisted of various sorts and sizes of particles, called \"corpuscles\", which were capable of arranging themselves into groups. In 1789, William Higgins published views on what he called combinations of \"ultimate\" particles, which foreshadowed the concept of valency bonds. If, for example, according to Higgins, the force between the ultimate particle of oxygen and the ultimate particle of nitrogen were 6, then the strength of the force would be divided accordingly, and similarly for the other combinations of ultimate particles.\nAmedeo Avogadro created the word \"molecule\". His 1811 paper \"Essay on Determining the Relative Masses of the Elementary Molecules of Bodies\", he essentially states, i.e. according to Partington's \"A Short History of Chemistry\", that:&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The smallest particles of gases are not necessarily simple atoms, but are made up of a certain number of these atoms united by attraction to form a single molecule.In coordination with these concepts, in 1833 the French chemist Marc Antoine Auguste Gaudin presented a clear account of Avogadro's hypothesis, regarding atomic weights, by making use of \"volume diagrams\", which clearly show both semi-correct molecular geometries, such as a linear water molecule, and correct molecular formulas, such as H2O:\nIn 1917, an unknown American undergraduate chemical engineer named Linus Pauling was learning the Dalton hook-and-eye bonding method, which was the mainstream description of bonds between atoms at the time. Pauling, however, was not satisfied with this method and looked to the newly emerging field of quantum physics for a new method. In 1926, French physicist Jean Perrin received the Nobel Prize in physics for proving, conclusively, the existence of molecules. He did this by calculating the Avogadro constant using three different methods, all involving liquid phase systems. First, he used a gamboge soap-like emulsion, second by doing experimental work on Brownian motion, and third by confirming Einstein's theory of particle rotation in the liquid phase.\nIn 1927, the physicists Fritz London and Walter Heitler applied the new quantum mechanics to the deal with the saturable, nondynamic forces of attraction and repulsion, i.e., exchange forces, of the hydrogen molecule. Their valence bond treatment of this problem, in their joint paper, was a landmark in that it brought chemistry under quantum mechanics. Their work was an influence on Pauling, who had just received his doctorate and visited Heitler and London in Z\u00fcrich on a Guggenheim Fellowship.\nSubsequently, in 1931, building on the work of Heitler and London and on theories found in Lewis' famous article, Pauling published his ground-breaking article \"The Nature of the Chemical Bond\" in which he used quantum mechanics to calculate properties and structures of molecules, such as angles between bonds and rotation about bonds. On these concepts, Pauling developed hybridization theory to account for bonds in molecules such as CH4, in which four sp\u00b3 hybridised orbitals are overlapped by hydrogen's \"1s\" orbital, yielding four sigma (\u03c3) bonds. The four bonds are of the same length and strength, which yields a molecular structure as shown below:\nMolecular science.\nThe science of molecules is called \"molecular chemistry\" or \"molecular physics\", depending on whether the focus is on chemistry or physics. Molecular chemistry deals with the laws governing the interaction between molecules that results in the formation and breakage of chemical bonds, while molecular physics deals with the laws governing their structure and properties. In practice, however, this distinction is vague. In molecular sciences, a molecule consists of a stable system (bound state) composed of two or more atoms. Polyatomic ions may sometimes be usefully thought of as electrically charged molecules. The term \"unstable molecule\" is used for very reactive species, i.e., short-lived assemblies (resonances) of electrons and nuclei, such as radicals, molecular ions, Rydberg molecules, transition states, van der Waals complexes, or systems of colliding atoms as in Bose\u2013Einstein condensate.\nPrevalence.\nMolecules as components of matter are common. They also make up most of the oceans and atmosphere. Most organic substances are molecules. The substances of life are molecules, e.g. proteins, the amino acids of which they are composed, the nucleic acids (DNA and RNA), sugars, carbohydrates, fats, and vitamins. The nutrient minerals are generally ionic compounds, thus they are not molecules, e.g. iron sulfate.\nHowever, the majority of familiar solid substances on Earth are made partly or completely of crystals or ionic compounds, which are not made of molecules. These include all of the minerals that make up the substance of the Earth, sand, clay, pebbles, rocks, boulders, bedrock, the molten interior, and the core of the Earth. All of these contain many chemical bonds, but are \"not\" made of identifiable molecules.\nNo typical molecule can be defined for salts nor for covalent crystals, although these are often composed of repeating unit cells that extend either in a plane, e.g. graphene; or three-dimensionally e.g. diamond, quartz, sodium chloride. The theme of repeated unit-cellular-structure also holds for most metals which are condensed phases with metallic bonding. Thus solid metals are not made of molecules. In glasses, which are solids that exist in a vitreous disordered state, the atoms are held together by chemical bonds with no presence of any definable molecule, nor any of the regularity of repeating unit-cellular-structure that characterizes salts, covalent crystals, and metals.\nBonding.\nMolecules are generally held together by covalent bonding. Several non-metallic elements exist only as molecules in the environment either in compounds or as homonuclear molecules, not as free atoms: for example, hydrogen.\nWhile some people say a metallic crystal can be considered a single giant molecule held together by metallic bonding, others point out that metals behave very differently than molecules.\nCovalent.\nA covalent bond is a chemical bond that involves the sharing of electron pairs between atoms. These electron pairs are termed \"shared pairs\" or \"bonding pairs\", and the stable balance of attractive and repulsive forces between atoms, when they share electrons, is termed \"covalent bonding\".\nIonic.\nIonic bonding is a type of chemical bond that involves the electrostatic attraction between oppositely charged ions, and is the primary interaction occurring in ionic compounds. The ions are atoms that have lost one or more electrons (termed \"cations\") and atoms that have gained one or more electrons (termed \"anions\"). This transfer of electrons is termed \"electrovalence\" in contrast to covalence. In the simplest case, the cation is a metal atom and the anion is a nonmetal atom, but these ions can be of a more complicated nature, e.g. molecular ions like NH4+ or SO42\u2212. At normal temperatures and pressures, ionic bonding mostly creates solids (or occasionally liquids) without separate identifiable molecules, but the vaporization/sublimation of such materials does produce separate molecules where electrons are still transferred fully enough for the bonds to be considered ionic rather than covalent.\nMolecular size.\nMost molecules are far too small to be seen with the naked eye, although molecules of many polymers can reach macroscopic sizes, including biopolymers such as DNA. Molecules commonly used as building blocks for organic synthesis have a dimension of a few angstroms (\u00c5) to several dozen \u00c5, or around one billionth of a meter. Single molecules cannot usually be observed by light (as noted above), but small molecules and even the outlines of individual atoms may be traced in some circumstances by use of an atomic force microscope. Some of the largest molecules are macromolecules or supermolecules.\nThe smallest molecule is the diatomic hydrogen (H2), with a bond length of 0.74 \u00c5.\nEffective molecular radius is the size a molecule displays in solution.\nThe table of permselectivity for different substances contains examples.\nMolecular formulas.\nChemical formula types.\nThe chemical formula for a molecule uses one line of chemical element symbols, numbers, and sometimes also other symbols, such as parentheses, dashes, brackets, and \"plus\" (+) and \"minus\" (\u2212) signs. These are limited to one typographic line of symbols, which may include subscripts and superscripts.\nA compound's empirical formula is a very simple type of chemical formula. It is the simplest integer ratio of the chemical elements that constitute it. For example, water is always composed of a 2:1 ratio of hydrogen to oxygen atoms, and ethanol (ethyl alcohol) is always composed of carbon, hydrogen, and oxygen in a 2:6:1 ratio. However, this does not determine the kind of molecule uniquely\u00a0\u2013 dimethyl ether has the same ratios as ethanol, for instance. Molecules with the same atoms in different arrangements are called isomers. Also carbohydrates, for example, have the same ratio (carbon:hydrogen:oxygen= 1:2:1) (and thus the same empirical formula) but different total numbers of atoms in the molecule.\nThe molecular formula reflects the exact number of atoms that compose the molecule and so characterizes different molecules. However different isomers can have the same atomic composition while being different molecules.\nThe empirical formula is often the same as the molecular formula but not always. For example, the molecule acetylene has molecular formula C2H2, but the simplest integer ratio of elements is CH.\nThe molecular mass can be calculated from the chemical formula and is typically expressed in daltons, which are equal to 1/12 of the mass of a neutral carbon-12 (12C isotope) atom. For network solids, the term formula unit is used in stoichiometric calculations.\nStructural formula.\nFor molecules with a complicated 3-dimensional structure, especially involving atoms bonded to four different substituents, a simple molecular formula or even semi-structural chemical formula may not be enough to completely specify the molecule. In this case, a graphical type of formula called a structural formula may be needed. Structural formulas may in turn be represented with a one-dimensional chemical name, but such chemical nomenclature requires many words and terms which are not part of chemical formulas.\nMolecular geometry.\nMolecules have fixed equilibrium geometries\u2014bond lengths and angles\u2014 about which they continuously oscillate through vibrational and rotational motions. A pure substance is composed of molecules with the same average geometrical structure. The chemical formula and the structure of a molecule are the two important factors that determine its properties, particularly its reactivity. Isomers share a chemical formula but normally have very different properties because of their different structures. Stereoisomers, a particular type of isomer, may have very similar physico-chemical properties and at the same time different biochemical activities.\nMolecular spectroscopy.\nMolecular spectroscopy deals with the response (spectrum) of molecules interacting with probing signals of known energy (or frequency, according to the Planck relation). Molecules have quantized energy levels that can be analyzed by detecting the molecule's energy exchange through absorbance or emission.\nSpectroscopy does not generally refer to diffraction studies where particles such as neutrons, electrons, or high energy X-rays interact with a regular arrangement of molecules (as in a crystal).\nMicrowave spectroscopy commonly measures changes in the rotation of molecules, and can be used to identify molecules in outer space. Infrared spectroscopy measures the vibration of molecules, including stretching, bending or twisting motions. It is commonly used to identify the kinds of bonds or functional groups in molecules. Changes in the arrangements of electrons yield absorption or emission lines in ultraviolet, visible or near infrared light, and result in colour. Nuclear resonance spectroscopy measures the environment of particular nuclei in the molecule, and can be used to characterise the numbers of atoms in different positions in a molecule.\nTheoretical aspects.\nThe study of molecules by molecular physics and theoretical chemistry is largely based on quantum mechanics and is essential for the understanding of the chemical bond. The simplest of molecules is the hydrogen molecule-ion, H2+, and the simplest of all the chemical bonds is the one-electron bond. H2+ is composed of two positively charged protons and one negatively charged electron, which means that the Schr\u00f6dinger equation for the system can be solved more easily due to the lack of electron\u2013electron repulsion. With the development of fast digital computers, approximate solutions for more complicated molecules became possible and are one of the main aspects of computational chemistry.\nWhen trying to define rigorously whether an arrangement of atoms is \"sufficiently stable\" to be considered a molecule, IUPAC suggests that it \"must correspond to a depression on the potential energy surface that is deep enough to confine at least one vibrational state\". This definition does not depend on the nature of the interaction between the atoms, but only on the strength of the interaction. In fact, it includes weakly bound species that would not traditionally be considered molecules, such as the helium dimer, He2, which has one vibrational bound state and is so loosely bound that it is only likely to be observed at very low temperatures.\nWhether or not an arrangement of atoms is \"sufficiently stable\" to be considered a molecule is inherently an operational definition. Philosophically, therefore, a molecule is not a fundamental entity (in contrast, for instance, to an elementary particle); rather, the concept of a molecule is the chemist's way of making a useful statement about the strengths of atomic-scale interactions in the world that we observe.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "19556", "revid": "2846386", "url": "https://en.wikipedia.org/wiki?curid=19556", "title": "Mode (music)", "text": "Type of musical scale and characteristic behaviors\n&lt;score sound=\"1\"&gt;\n \\relative c' {\n \\clef treble \\time 7/4 \\hide Staff.TimeSignature\n c4 d e f g a b c2\n&lt;/score&gt; Diatonic major scale (Ionian mode, I) on C, a \"white note\" scale\n&lt;score sound=\"1\"&gt;\n\\key c \\dorian\n\\override Score.TimeSignature #'stencil = ##f\n\\relative c' { \n \\clef treble \n \\time 7/4 c4^\\markup { Dorian mode, II, on C } d es f g a bes c\n&lt;/score&gt;\n&lt;score sound=\"1\"&gt;\n\\override Score.TimeSignature #'stencil = ##f\n\\key c \\phrygian\n\\relative c' { \n \\clef treble \n \\time 7/4 c4^\\markup { Phrygian mode, III, on C } des es f g aes bes c\n&lt;/score&gt;\n&lt;score sound=\"1\"&gt;\n\\override Score.TimeSignature #'stencil = ##f\n\\key c \\lydian\n\\relative c' { \n \\clef treble \n \\time 7/4 c4^\\markup { Lydian mode, IV, on C } d e fis g a b c\n&lt;/score&gt;\n&lt;score sound=\"1\"&gt;\n\\override Score.TimeSignature #'stencil = ##f\n\\key c \\mixolydian\n\\relative c' { \n \\clef treble \n \\time 7/4 c4^\\markup { Mixolydian mode, V, on C } d e f g a bes c\n&lt;/score&gt;\n&lt;score sound=\"1\"&gt;\n\\override Score.TimeSignature #'stencil = ##f\n\\key c \\aeolian\n\\relative c' { \n \\clef treble \n \\time 7/4 c4^\\markup { Aeolian mode, VI, on C } d es f g aes bes c\n&lt;/score&gt;\n&lt;score sound=\"1\"&gt;\n\\override Score.TimeSignature #'stencil = ##f\n\\key c \\locrian\n\\relative c' { \n \\clef treble \n \\time 7/4 c4^\\markup { Locrian mode, VII, on C } des es f ges aes bes c\n&lt;/score&gt; The modern (diatonic) modes on C\nIn music theory, the term mode or modus is used in a number of distinct senses, depending on context.\nIts most common use may be described as a type of musical scale coupled with a set of characteristic melodic and harmonic behaviors. It is applied to major and minor keys as well as the seven diatonic modes (including the former as Ionian and Aeolian) which are defined by their starting note or tonic. (Olivier Messiaen's modes of limited transposition are strictly a scale type.) Related to the diatonic modes are the eight church modes or Gregorian modes, in which authentic and plagal forms of scales are distinguished by ambitus and tenor or reciting tone. Although both diatonic and Gregorian modes borrow terminology from ancient Greece, the Greek \"tonoi\" do not otherwise resemble their medieval/modern counterparts.\nPreviously, in the Middle Ages the term modus was used to describe intervals, individual notes, and rhythms (see ). Modal rhythm was an essential feature of the modal notation system of the Notre-Dame school at the turn of the 12th century. In the mensural notation that emerged later, modus specifies the subdivision of the \"longa\".\nOutside of Western classical music, \"mode\" is sometimes used to embrace similar concepts such as \"Octoechos\", \"maqam\", \"pathet\" etc. (see below).\nMode as a general concept.\nRegarding the concept of mode as applied to pitch relationships generally, in 2001 Harold S. Powers proposed that \"mode\" has \"a twofold sense\", denoting either a \"particularized scale\" or a \"generalized tune\", or both: &lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nIn 1792, Sir Willam Jones applied the term \"mode\" to the music of \"the Persians and the Hindoos\". As early as 1271, Amerus applied the concept to \"cantilenis organicis\" (lit. \"organic songs\", most probably meaning \"polyphony\"). It is still heavily used with regard to Western polyphony before the onset of the common practice period, as for example \"modale Mehrstimmigkeit\" by Carl Dahlhaus or \"Alte Tonarten\" of the 16th and 17th centuries found by Bernhard Meier.\nThe word encompasses several additional meanings. Authors from the 9th century until the early 18th century (e.g., Guido of Arezzo) sometimes employed the Latin \"modus\" for interval, or for qualities of individual notes. In the theory of late-medieval mensural polyphony (e.g., Franco of Cologne), \"modus\" is a rhythmic relationship between long and short values or a pattern made from them; in mensural music most often theorists applied it to division of longa into 3 or 2 breves.\nModes and scales.\nA musical scale is a series of pitches in a distinct order.\nThe concept of \"mode\" in Western music theory has three successive stages: in Gregorian chant theory, in Renaissance polyphonic theory, and in tonal harmonic music of the common practice period. In all three contexts, \"mode\" incorporates the idea of the diatonic scale, but differs from it by also involving an element of melody type. This concerns particular repertories of short musical figures or groups of tones within a certain scale so that, depending on the point of view, mode takes on the meaning of either a \"particularized scale\" or a \"generalized tune\". Modern musicological practice has extended the concept of mode to earlier musical systems, such as those of Ancient Greek music, Jewish cantillation, and the Byzantine system of \"octoechoi\", as well as to other non-Western types of music.\nBy the early 19th century, the word \"mode\" had taken on an additional meaning, in reference to the difference between major and minor keys, specified as \"major mode\" and \"minor mode\". At the same time, composers were beginning to conceive \"modality\" as something outside of the major/minor system that could be used to evoke religious feelings or to suggest folk-music idioms.\nGreek modes.\nEarly Greek treatises describe three interrelated concepts that are related to the later, medieval idea of \"mode\": (1) scales (or \"systems\"), (2) \"tonos\" \u2013 pl. \"tonoi\" \u2013 (the more usual term used in medieval theory for what later came to be called \"mode\"), and (3) \"harmonia\" (harmony) \u2013 pl. \"harmoniai\" \u2013 this third term subsuming the corresponding \"tonoi\" but not necessarily the converse.\nGreek scales.\n&lt;score sound=\"1\"&gt;\n\\override Score.TimeSignature #'stencil = ##f\n\\relative c' { \n \\clef treble \\time 4/4\n e4^\\markup { Enharmonic genus } feh geses a b ceh deses e\n&lt;/score&gt;\n&lt;score sound=\"1\"&gt;\n\\override Score.TimeSignature #'stencil = ##f\n\\relative c' { \n \\clef treble \\time 4/4\n e4^\\markup { Chromatic genus } f ges a b c des e\n&lt;/score&gt;\n&lt;score sound=\"1\"&gt;\n\\override Score.TimeSignature #'stencil = ##f\n\\relative c' { \n \\clef treble \\time 4/4\n e4^\\markup { Diatonic genus } f g a b c d e\n&lt;/score&gt; The three genera of the Dorian octave species on E\nThe Greek scales in the Aristoxenian tradition were:\nThese names are derived from ancient Greeks' cultural subgroups (Dorians), small regions in central Greece (Locris), and certain Anatolian peoples (Lydia, Phrygia) (not ethnically Greek, but in close contact with them). The association of these ethnic names with the octave species appears to precede Aristoxenus, who criticized their application to the \"tonoi\" by the earlier theorists whom he called the \"Harmonicists\". According to , he felt that their diagrams, which exhibit 28\u00a0consecutive dieses, were\n \"...\u00a0devoid of any musical reality since more than two quarter-tones are never heard in succession.\"\nDepending on the positioning (spacing) of the interposed tones in the tetrachords, three \"genera\" of the seven octave species can be recognized. The diatonic genus (composed of tones and semitones), the chromatic genus (semitones and a minor third), and the enharmonic genus (with a major third and two quarter tones or dieses). The framing interval of the perfect fourth is fixed, while the two internal pitches are movable. Within the basic forms, the intervals of the chromatic and diatonic genera were varied further by three and two \"shades\" (\"chroai\"), respectively.\nIn contrast to the medieval modal system, these scales and their related \"tonoi\" and \"harmoniai\" appear to have had no hierarchical relationships amongst the notes that could establish contrasting points of tension and rest, although the \"mese\" (\"middle note\") might have functioned as some sort of central, returning tone for the melody.\n\"Tonoi\".\nThe term \"tonos\" (pl. \"tonoi\") was used in four senses:\n \"as note, interval, region of the voice, and pitch. We use it of the region of the voice whenever we speak of Dorian, or Phrygian, or Lydian, or any of the other tones\".\nCleonides attributes thirteen \"tonoi\" to Aristoxenus, which represent a progressive transposition of the entire system (or scale) by semitone over the range of an octave between the Hypodorian and the Hypermixolydian. According to Cleonides, Aristoxenus's transpositional \"tonoi\" were named analogously to the octave species, supplemented with new terms to raise the number of degrees from seven to thirteen. However, according to the interpretation of at least three modern authorities, in these transpositional \"tonoi\" the Hypodorian is the lowest, and the Mixolydian next-to-highest \u2013 the reverse of the case of the octave species, with nominal base pitches as follows (descending order):\nPtolemy, in his \"Harmonics\", ii.3\u201311, construed the \"tonoi\" differently, presenting all seven octave species within a fixed octave, through chromatic inflection of the scale degrees (comparable to the modern conception of building all seven modal scales on a single tonic). In Ptolemy's system, therefore there are only seven \"tonoi\". Pythagoras also construed the intervals arithmetically (if somewhat more rigorously, initially allowing for 1:1 = Unison, 2:1 = Octave, 3:2 = Fifth, 4:3 = Fourth and 5:4 = Major Third within the octave). In their diatonic genus, these \"tonoi\" and corresponding \"harmoniai\" correspond with the intervals of the familiar modern major and minor scales. See Pythagorean tuning and Pythagorean interval.\n\"Harmoniai\".\nIn music theory the Greek word \"harmonia\" can signify the enharmonic genus of tetrachord, the seven octave species, or a style of music associated with one of the ethnic types or the \"tonoi\" named by them.\nParticularly in the earliest surviving writings, \"harmonia\" is regarded not as a scale, but as the epitome of the stylised singing of a particular district or people or occupation. When the late-6th-century poet Lasus of Hermione referred to the Aeolian \"harmonia\", for example, he was more likely thinking of a melodic style characteristic of Greeks speaking the Aeolic dialect than of a scale pattern. By the late 5th century BC, these regional types are being described in terms of differences in what is called \"harmonia\" \u2013 a word with several senses, but here referring to the pattern of intervals between the notes sounded by the strings of a lyra or a kithara.\nHowever, there is no reason to suppose that, at this time, these tuning patterns stood in any straightforward and organised relations to one another. It was only around the year 400 that attempts were made by a group of theorists known as the harmonicists to bring these \"harmoniai\" into a single system and to express them as orderly transformations of a single structure. Eratocles was the most prominent of the harmonicists, though his ideas are known only at second hand, through Aristoxenus, from whom we learn they represented the \"harmoniai\" as cyclic reorderings of a given series of intervals within the octave, producing seven octave species. We also learn that Eratocles confined his descriptions to the enharmonic genus.\nPhilosophical \"harmoniai\" in Plato and Aristotle.\nIn the \"Republic\", Plato uses the term inclusively to encompass a particular type of scale, range and register, characteristic rhythmic pattern, textual subject, etc. Plato held that playing music in a particular \"harmonia\" would incline one towards specific behaviors associated with it, and suggested that soldiers should listen to music in Dorian or Phrygian \"harmoniai\" to help harden them but avoid music in Lydian, Mixolydian, or Ionian \"harmoniai\", for fear of being softened. Plato believed that a change in the musical modes of the state would cause a wide-scale social revolution.\nThe philosophical writings of Plato and Aristotle (c.\u2009350 BC) include sections that describe the effect of different \"harmoniai\" on mood and character formation. For example, Aristotle stated in his \"Politics\":\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;But melodies themselves do contain imitations of character. This is perfectly clear, for the \"harmoniai\" have quite distinct natures from one another, so that those who hear them are differently affected and do not respond in the same way to each. To some, such as the one called Mixolydian, they respond with more grief and anxiety, to others, such as the relaxed \"harmoniai\", with more mellowness of mind, and to one another with a special degree of moderation and firmness, Dorian being apparently the only one of the \"harmoniai\" to have this effect, while Phrygian creates ecstatic excitement. These points have been well expressed by those who have thought deeply about this kind of education; for they cull the evidence for what they say from the facts themselves.\nAristotle continues by describing the effects of rhythm, and concludes about the combined effect of rhythm and \"harmonia\" (viii:1340b:10\u201313): &lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nThe word \"ethos\" (\u1f26\u03b8\u03bf\u03c2) in this context means \"moral character\", and Greek ethos theory concerns the ways that music can convey, foster, and even generate ethical states.\n\"Melos\".\nSome treatises also describe \"melic\" composition (\u03bc\u03b5\u03bb\u03bf\u03c0\u03bf\u03b9\u0390\u03b1), \"the employment of the materials subject to harmonic practice with due regard to the requirements of each of the subjects under consideration\" \u2013 which, together with the scales, \"tonoi\", and \"harmoniai\" resemble elements found in medieval modal theory. According to Aristides Quintilianus, melic composition is subdivided into three classes: dithyrambic, nomic, and tragic. These parallel his three classes of rhythmic composition: systaltic, diastaltic and hesychastic. Each of these broad classes of melic composition may contain various subclasses, such as erotic, comic and panegyric, and any composition might be elevating (diastaltic), depressing (systaltic), or soothing (hesychastic).\nAccording to Thomas J. Mathiesen, music as a performing art was called \"melos\", which in its perfect form (\u03bc\u03ad\u03bb\u03bf\u03c2 \u03c4\u03ad\u03bb\u03b5\u03b9\u03bf\u03bd) comprised not only the melody and the text (including its elements of rhythm and diction) but also stylized dance movement. Melic and rhythmic composition (respectively, \u03bc\u03b5\u03bb\u03bf\u03c0\u03bf\u03b9\u0390\u03b1 and \u1fe5\u03c5\u03b8\u03bc\u03bf\u03c0\u03bf\u03b9\u0390\u03b1) were the processes of selecting and applying the various components of melos and rhythm to create a complete work. According to Aristides Quintilianus:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;And we might fairly speak of perfect melos, for it is necessary that melody, rhythm and diction be considered so that the perfection of the song may be produced: in the case of melody, simply a certain sound; in the case of rhythm, a motion of sound; and in the case of diction, the meter. The things contingent to perfect melos are motion-both of sound and body-and also chronoi and the rhythms based on these.\nWestern Church.\nEarly theorists.\nThe oldest medieval treatise regarding modes is \"Musica disciplina\" by Aurelian of R\u00e9\u00f4me (dating from around 850) while Hermannus Contractus was the first to define modes as partitionings of the octave. However, the earliest Western source using the system of eight modes is the Tonary of St Riquier, dated between about 795 and 800.\nTonaries, lists of chant titles grouped by mode, appear in western sources around the turn of the 9th century. The influence of developments in Byzantium, from Jerusalem and Damascus, for instance the works of Saints John of Damascus (d. 749) and Cosmas of Maiouma, are still not fully understood. The eight-fold division of the Latin modal system, in a four-by-two matrix, was certainly of Eastern provenance, originating probably in Syria or even in Jerusalem, and was transmitted from Byzantine sources to Carolingian practice and theory during the 8th century. However, the earlier Greek model for the Carolingian system was probably ordered like the later Byzantine \"okt\u014d\u0113chos\", that is, with the four principal (authentic) modes first, then the four plagals, whereas the Latin modes were always grouped the other way, with the authentics and plagals paired.\nThe 6th-century scholar Boethius had translated Greek music theory treatises by Nicomachus and Ptolemy into Latin. Later authors created confusion by applying mode as described by Boethius to explain plainchant modes, which were a wholly different system. In his \"De institutione musica\", book 4 chapter 15, Boethius, like his Hellenistic sources, twice used the term \"harmonia\" to describe what would likely correspond to the later notion of \"mode\", but also used the word \"modus\" \u2013 probably translating the Greek word \u03c4\u03c1\u03cc\u03c0\u03bf\u03c2 (\"tropos\"), which he also rendered as Latin \"tropus\" \u2013 in connection with the system of transpositions required to produce seven diatonic octave species, so the term was simply a means of describing transposition and had nothing to do with the church modes.\nLater, 9th-century theorists applied Boethius's terms \"tropus\" and \"modus\" (along with \"tonus\") to the system of church modes. The treatise \"De Musica\" (or \"De harmonica institutione\") of Hucbald synthesized the three previously disparate strands of modal theory: chant theory, the Byzantine \"okt\u014d\u0113chos\" and Boethius's account of Hellenistic theory. The late-9th- and early 10th-century compilation known as the \"Alia musica\" imposed the seven octave transpositions, known as \"tropus\" and described by Boethius, onto the eight church modes, but its compilator also mentions the Greek (Byzantine) echoi translated by the Latin term \"sonus\". Thus, the names of the modes became associated with the eight church tones and their modal formulas \u2013 but this medieval interpretation does not fit the concept of the ancient Greek harmonics treatises. The modern understanding of mode does not reflect that it is made of different concepts that do not all fit.\nCarl Dahlhaus lists \"three factors that form the respective starting points for the modal theories of Aurelian of R\u00e9\u00f4me, Hermannus Contractus, and Guido of Arezzo\":\nGregorian modes.\nAccording to Carolingian theorists the eight church modes, or Gregorian modes, can be divided into four pairs, where each pair shares the \"final\" note and the four notes above the final, but they have different intervals concerning the species of the fifth. If the octave is completed by adding three notes above the fifth, the mode is termed \"authentic\", but if the octave is completed by adding three notes below, it is called \"plagal\" (from Greek \u03c0\u03bb\u03ac\u03b3\u03b9\u03bf\u03c2, \"oblique, sideways\"). In both cases, the strict ambitus of the mode is one octave. A melody that remains confined to the mode's ambitus is called \"perfect\"; if it falls short of it, \"imperfect\"; if it exceeds it, \"superfluous\"; and a melody that combines the ambituses of both the plagal and authentic is said to be in a \"mixed mode\".\nAlthough the earlier (Greek) model for the Carolingian system was probably ordered like the Byzantine \"okt\u014d\u0113chos\", with the four authentic modes first, followed by the four plagals, the earliest extant sources for the Latin system are organized in four pairs of authentic and plagal modes sharing the same final: protus authentic/plagal, deuterus authentic/plagal, tritus authentic/plagal, and tetrardus authentic/plagal.\nEach mode has, in addition to its final, a \"reciting tone\", sometimes called the \"dominant\". It is also sometimes called the \"tenor\", from Latin \"tenere\" \"to hold\", meaning the tone around which the melody principally centres. The reciting tones of all authentic modes began a fifth above the final, with those of the plagal modes a third above. However, the reciting tones of modes 3, 4, and 8 rose one step during the 10th and 11th centuries with 3 and 8 moving from B to C (half step) and that of 4 moving from G to A (whole step).\nAfter the reciting tone, every mode is distinguished by scale degrees called \"mediant\" and \"participant\". The mediant is named from its position between the final and reciting tone. In the authentic modes it is the third of the scale, unless that note should happen to be B, in which case C substitutes for it. In the plagal modes, its position is somewhat irregular. The participant is an auxiliary note, generally adjacent to the mediant in authentic modes and, in the plagal forms, coincident with the reciting tone of the corresponding authentic mode (some modes have a second participant).\nOnly one accidental is used commonly in Gregorian chant \u2013 B may be lowered by a half-step to B\u266d. This usually (but not always) occurs in modes V and VI, as well as in the upper tetrachord of IV, and is optional in other modes except III, VII and VIII.\nLater systemizations.\nIn 1547, the Swiss theorist Henricus Glareanus published the \"Dodecachordon\", in which he solidified the concept of the church modes, and added four additional modes: the Aeolian (mode 9), Hypoaeolian (mode 10), Ionian (mode 11), and Hypoionian (mode 12). A little later in the century, the Italian Gioseffo Zarlino at first adopted Glarean's system in 1558, but later (1571 and 1573) revised the numbering and naming conventions in a manner he deemed more logical, resulting in the widespread promulgation of two conflicting systems.\nZarlino's system reassigned the six pairs of authentic\u2013plagal mode numbers to finals in the order of the natural hexachord, C\u2013D\u2013E\u2013F\u2013G\u2013A, and transferred the Greek names as well, so that modes 1 through 8 now became C-authentic to F-plagal, and were now called by the names Dorian to Hypomixolydian. The pair of G modes were numbered 9 and 10 and were named Ionian and Hypoionian, while the pair of A modes retained both the numbers and names (11, Aeolian, and 12 Hypoaeolian) of Glarean's system. While Zarlino's system became popular in France, Italian composers preferred Glarean's scheme because it retained the traditional eight modes, while expanding them. Luzzasco Luzzaschi was an exception in Italy, in that he used Zarlino's new system.\nIn the late-18th and 19th centuries, some chant reformers (notably the editors of the Mechlin, Pustet-Ratisbon (Regensburg), and Rheims-Cambrai Office-Books, collectively referred to as the Cecilian Movement) renumbered the modes once again, this time retaining the original eight mode numbers and Glareanus's modes 9 and 10, but assigning numbers 11 and 12 to the modes on the final B, which they named Locrian and Hypolocrian (even while rejecting their use in chant). The Ionian and Hypoionian modes (on C) become in this system modes 13 and 14.\nGiven the confusion between ancient, medieval, and modern terminology, \"today it is more consistent and practical to use the traditional designation of the modes with numbers one to eight\", using Roman numeral (I\u2013VIII), rather than using the pseudo-Greek naming system. Medieval terms, first used in Carolingian treatises, later in Aquitanian tonaries, are still used by scholars today: the Greek ordinals (\"first\", \"second\", etc.) transliterated into the Latin alphabet protus (\u03c0\u03c1\u1ff6\u03c4\u03bf\u03c2), deuterus (\u03b4\u03b5\u03cd\u03c4\u03b5\u03c1\u03bf\u03c2), tritus (\u03c4\u03c1\u03af\u03c4\u03bf\u03c2), and tetrardus (\u03c4\u03ad\u03c4\u03b1\u03c1\u03c4\u03bf\u03c2). In practice they can be specified as authentic or as plagal like \"protus authentus / plagalis\".\nAffect.\nVarious interpretations of the \"character\" imparted by the different modes have been suggested. Three such interpretations, from Guido of Arezzo (995\u20131050), Adam of Fulda (1445\u20131505), and Juan de Espinosa Medrano (1632\u20131688), follow:\nModern diatonic modes.\nModern Western modes use the same set of notes as the major scale, in the same order, but starting from one of its seven degrees in turn as a tonic, and so present a different sequence of whole and half steps. With the interval sequence of the major scale being W\u2013W\u2013H\u2013W\u2013W\u2013W\u2013H, where \"W\" means a whole tone (whole step) and \"H\" means a semitone (half step), it is thus possible to generate the following modes:\nFor the sake of simplicity, the examples shown above are formed by natural notes (also called \"white notes\", as they can be played using the white keys of a piano keyboard). However, any transposition of each of these scales is a valid example of the corresponding mode. In other words, transposition preserves mode.\nAlthough the names of the modern modes are Greek and some have names used in ancient Greek theory for some of the \"harmoniai\", the names of the modern modes are conventional and do not refer to the sequences of intervals found even in the diatonic genus of the Greek octave species sharing the same name.\nAnalysis.\nEach mode has characteristic intervals and chords that give it its distinctive sound. The following is an analysis of each of the seven modern modes. The examples are provided in a key signature with no sharps or flats (scales composed of natural notes).\nIonian (I).\nThe Ionian mode is the modern major scale. The example composed of natural notes begins on C, and is also known as the C-major scale:\n&lt;score sound=\"1\"&gt;\n\\override Score.TimeSignature #'stencil = ##f\n\\relative c' { \n \\clef treble \n \\time 7/4 c4 d e f g a b c\n&lt;/score&gt; The modern Ionian mode on C\nDorian (II).\nThe Dorian mode is the second mode. The example composed of natural notes begins on D:\n&lt;score sound=\"1\"&gt;\n\\override Score.TimeSignature #'stencil = ##f\n\\relative c' { \n \\clef treble \n \\time 7/4 d4 e f g a b c d\n&lt;/score&gt; The modern Dorian mode on D\nThe Dorian mode is very similar to the modern natural minor scale (see Aeolian mode below). The only difference with respect to the natural minor scale is in the sixth scale degree, which is a major sixth (M6) above the tonic, rather than a minor sixth (m6).\nPhrygian (III).\nThe Phrygian mode is the third mode. The example composed of natural notes starts on E:\n&lt;score sound=\"1\"&gt;\n\\override Score.TimeSignature #'stencil = ##f\n\\relative c' { \n \\clef treble \n \\time 7/4 e4 f g a b c d e\n&lt;/score&gt; The modern Phrygian mode on E\nThe Phrygian mode is very similar to the modern natural minor scale (see Aeolian mode below). The only difference with respect to the natural minor scale is in the second scale degree, which is a minor second (m2) above the tonic, rather than a major second (M2).\nLydian (IV).\nThe Lydian mode is the fourth mode. The example composed of natural notes starts on F:\n&lt;score sound=\"1\"&gt;\n\\override Score.TimeSignature #'stencil = ##f\n\\relative c' { \n \\clef treble \n \\time 7/4 f4 g a b c d e f\n&lt;/score&gt; The modern Lydian mode on F\nThe single tone that differentiates this scale from the major scale (Ionian mode) is its fourth degree, which is an augmented fourth (A4) above the tonic (F), rather than a perfect fourth (P4).\nMixolydian (V).\nThe Mixolydian mode is the fifth mode. The example composed of natural notes begins on G:\n&lt;score sound=\"1\"&gt;\n\\override Score.TimeSignature #'stencil = ##f\n\\relative c\" { \n \\clef treble \n \\time 7/4 g4 a b c d e f g\n&lt;/score&gt; The modern Mixolydian mode on G\nThe single tone that differentiates this scale from the major scale (Ionian mode) is its seventh degree, which is a minor seventh (m7) above the tonic (G), rather than a major seventh (M7). Therefore, the seventh scale degree becomes a subtonic to the tonic because it is now a whole tone lower than the tonic, in contrast to the seventh degree in the major scale, which is a semitone tone lower than the tonic (leading-tone).\nAeolian (VI).\nThe Aeolian mode is the sixth mode. It is also called the natural minor scale. The example composed of natural notes begins on A, and is also known as the A natural-minor scale:\n&lt;score sound=\"1\"&gt;\n\\override Score.TimeSignature #'stencil = ##f\n\\relative c\" { \n \\clef treble \n \\time 7/4 a4 b c d e f g a\n&lt;/score&gt; The modern Aeolian mode on A\nLocrian (VII).\nThe Locrian mode is the seventh mode. The example composed of natural notes begins on B:\n&lt;score sound=\"1\"&gt;\n\\override Score.TimeSignature #'stencil = ##f\n\\relative c\" { \n \\clef treble \n \\time 7/4 b4c d e f g a b\n&lt;/score&gt; The modern Locrian mode on B\nThe distinctive scale degree here is the diminished fifth (d5). This makes the tonic triad diminished, so this mode is the only one in which the chords built on the tonic and dominant scale degrees have their roots separated by a diminished, rather than perfect, fifth. Similarly the tonic seventh chord is half-diminished.\nSummary.\nThe modes can be arranged in the following sequence, which follows the circle of fifths. In this sequence, each mode has one more lowered interval relative to the tonic than the mode preceding it. Thus, taking Lydian as reference, Ionian (major) has a lowered fourth; Mixolydian, a lowered fourth and seventh; Dorian, a lowered fourth, seventh, and third; Aeolian (natural minor), a lowered fourth, seventh, third, and sixth; Phrygian, a lowered fourth, seventh, third, sixth, and second; and Locrian, a lowered fourth, seventh, third, sixth, second, and fifth. Put another way, the augmented fourth of the Lydian mode has been reduced to a perfect fourth in Ionian, the major seventh in Ionian to a minor seventh in Mixolydian, etc.\nThe first three modes are sometimes called major, the next three minor, and the last one diminished (Locrian), according to the quality of their tonic triads. The Locrian mode is traditionally considered theoretical rather than practical because the triad built on the first scale degree is diminished. Because diminished triads are not consonant they do not lend themselves to cadential endings and cannot be tonicized according to traditional practice.\nUsage.\nThe usage and conception of modes or modality today is different from that in early music. As Jim Samson explains: \"Clearly any comparison of medieval and modern modality would recognize that the latter takes place against a background of some three centuries of harmonic tonality, permitting, and in the 19th century requiring, a dialogue between modal and diatonic procedure.\" Indeed, when 19th-century composers revived the modes, they rendered them more strictly than Renaissance composers had, to make their qualities distinct from the prevailing major-minor system. Renaissance composers routinely sharped leading tones at cadences and lowered the fourth in the Lydian mode.\nThe Ionian, or Iastian, mode is another name for the major scale used in much Western music. The Aeolian forms the base of the most common Western minor scale; in modern practice the Aeolian mode is differentiated from the minor by using only the seven notes of the Aeolian mode. By contrast, minor mode compositions of the common practice period frequently raise the seventh scale degree by a semitone to strengthen the cadences, and in conjunction also raise the sixth scale degree by a semitone to avoid the awkward interval of an augmented second. This is particularly true of vocal music.\nTraditional folk music provides countless examples of modal melodies. For example, Irish traditional music makes extensive usage not only of the major and minor (Aeolian) modes, but also the Mixolydian and Dorian modes. Within the context of Irish traditional music, the tunes are most commonly played in the keys of G-Major/A-Dorian/D-Mixolydian/E-Aeolian (minor) and D-Major/E-Dorian/A-Mixolydian/B-Aeolian (minor). Some Irish music is written in A-Major/F#-Aeolian (minor), with B-Dorian and E-Mixolydian tunes not being completely unheard of. Rarer still are Irish tunes in E-Major/F#-Dorian/B-Mixolydian.\nIn some regions of Ireland, such as the west-central coast area of counties Galway and Clare, \"flat\" keys are far more prevalent than in other areas. Instruments will be constructed or pitched accordingly to allow for modal playing in C-Major/D-Dorian/G-Mixolydian or F-Major/G-Dorian/C-Mixolydian/D-Aeolian (minor), with some rare exceptions in Eb-Major/C-minor being played regionally. Some tunes are even composed in Bb-Major, with modulating sections in F-Mixolydian. A-minor is less popularly played in the region, despite the localised prevalence of tunes in C-Major and related modes. Much Flamenco music is in the Phrygian mode, although frequently with the third and seventh degrees raised by a semitone.\nZolt\u00e1n Kod\u00e1ly, Gustav Holst, and Manuel de Falla use modal elements as modifications of a diatonic background, while modality replaces diatonic tonality in the music of Claude Debussy and B\u00e9la Bart\u00f3k.\nOther types.\nWhile the term \"mode\" is still most commonly understood to refer to Ionian, Dorian, Phrygian, Lydian, Mixolydian, Aeolian, or Locrian modes, in modern music theory the word is often applied to scales other than the diatonic. This is seen, for example, in melodic minor scale harmony, which is based on the seven rotations of the ascending melodic minor scale, yielding some interesting scales as shown below. The \"chord\" row lists tetrads that can be built from the pitches in the given mode (in jazz notation, the symbol \u0394 is for a major seventh).\nThe number of possible modes for any intervallic set is dictated by the pattern of intervals in the scale. For scales built of a pattern of intervals that only repeats at the octave (like the diatonic set), the number of modes is equal to the number of notes in the scale. Scales with a recurring interval pattern smaller than an octave, however, have only as many modes as notes within that subdivision: e.g., the diminished scale, which is built of alternating whole and half steps, has only two distinct modes, since all odd-numbered modes are equivalent to the first (starting with a whole step) and all even-numbered modes are equivalent to the second (starting with a half step).\nThe chromatic and whole-tone scales, each containing only steps of uniform size, have only a single mode each, as any rotation of the sequence results in the same sequence. Another general definition excludes these equal-division scales, and defines modal scales as subsets of them: according to Karlheinz Stockhausen, \"If we leave out certain steps of a[n equal-step] scale we get a modal construction\". In \"Messiaen's narrow sense, \"a mode is any scale\" made up from the 'chromatic total,' the twelve tones of the tempered system\".\nReferences.\nFootnotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nBibliography.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nFurther reading.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;"}
{"id": "19559", "revid": "50865928", "url": "https://en.wikipedia.org/wiki?curid=19559", "title": "Mechanics", "text": "Science concerned with physical bodies subjected to forces or displacements\n&lt;templatestyles src=\"Hlist/styles.css\"/&gt;\nMechanics (from grc \" \"\" ()\"\u00a0'of machines') is the area of physics concerned with the relationships between force, matter, and motion among physical objects. Forces applied to objects may result in displacements, which are changes of an object's position relative to its environment.\nTheoretical expositions of this branch of physics have their origins in Ancient Greece, for instance, in the writings of Aristotle and Archimedes (see History of classical mechanics and Timeline of classical mechanics). During the early modern period, scientists such as Galileo Galilei, Johannes Kepler, Christiaan Huygens, and Isaac Newton laid the foundation for what is now known as classical mechanics.\nIn the 20th century the concepts of classical mechanics were challenged by new discoveries, leading to fundamentally new approaches including relativistic mechanics and quantum mechanics.\nHistory.\nAntiquity.\nThe ancient Greek philosophers were among the first to propose that abstract principles govern nature. The main theory of mechanics in antiquity was Aristotelian mechanics, though an alternative theory is exposed in the pseudo-Aristotelian \"Mechanical Problems\", often attributed to one of his successors.\nThere is another tradition that goes back to the ancient Greeks where mathematics is used more extensively to analyze bodies statically or dynamically, an approach that may have been stimulated by prior work of the Pythagorean Archytas. Examples of this tradition include pseudo-Euclid (\"On the Balance\"), Archimedes (\"On the Equilibrium of Planes\", \"On Floating Bodies\"), Hero (\"Mechanica\"), and Pappus (\"Collection\", Book VIII).\nMedieval age.\nIn the Middle Ages, Aristotle's theories were criticized and modified by a number of figures, beginning with John Philoponus in the 6th century. A central problem was that of projectile motion, which was discussed by Hipparchus and Philoponus.\nPersian Islamic polymath Ibn S\u012bn\u0101 published his theory of motion in \"The Book of Healing\" (1020). He said that an impetus is imparted to a projectile by the thrower, and viewed it as persistent, requiring external forces such as air resistance to dissipate it. Ibn Sina made a distinction between 'force' and 'inclination' (called \"mayl\"), and argued that an object gained mayl when the object is in opposition to its natural motion. So he concluded that continuation of motion is attributed to the inclination that is transferred to the object, and that object will be in motion until the mayl is spent. He also claimed that a projectile in a vacuum would not stop unless it is acted upon, consistent with Newton's first law of motion.\nOn the question of a body subject to a constant (uniform) force, the 12th-century Jewish-Arab scholar Hibat Allah Abu'l-Barakat al-Baghdaadi (born Nathanel, Iraqi, of Baghdad) stated that constant force imparts constant acceleration. According to Shlomo Pines, al-Baghdaadi's theory of motion was \"the oldest negation of Aristotle's fundamental dynamic law [namely, that a constant force produces a uniform motion], [and is thus an] anticipation in a vague fashion of the fundamental law of classical mechanics [namely, that a force applied continuously produces acceleration].\"\nInfluenced by earlier writers such as Ibn Sina and al-Baghdaadi, the 14th-century French priest Jean Buridan developed the theory of impetus, which later developed into the modern theories of inertia, velocity, acceleration and momentum. This work and others were developed in 14th-century England by the Oxford Calculators such as Thomas Bradwardine, who studied and formulated various laws regarding falling bodies. The concept that the main properties of a body are uniformly accelerated motion (as of falling bodies) was worked out by the 14th-century Oxford Calculators.\nEarly modern age.\nTwo central figures in the early modern age are Galileo Galilei and Isaac Newton. Galileo's final statement of his mechanics, particularly of falling bodies, is his \"Two New Sciences\" (1638). Newton's 1687 \"Philosophi\u00e6 Naturalis Principia Mathematica\" provided a detailed mathematical account of mechanics, using the newly developed mathematics of calculus and providing the basis of Newtonian mechanics.\nThere is some dispute over the priority of various ideas: Newton's \"Principia\" is certainly the seminal work and has been tremendously influential, and many of the mathematical results therein could not have been stated earlier without the development of the calculus. However, many of the ideas, particularly as they pertain to inertia and falling bodies, had been developed by prior scholars such as Christiaan Huygens and the less-known medieval predecessors. Assigning precise credit is difficult, since scientific language and standards of proof have changed; the ideas of medieval scholars may be regarded either as equivalent to modern statements or merely as preliminary hypotheses similar to them.\nModern age.\nTwo main modern developments in mechanics are general relativity of Einstein, and quantum mechanics, both developed in the 20th century based in part on earlier 19th-century ideas. The development in the modern continuum mechanics, particularly in the areas of elasticity, plasticity, fluid dynamics, electrodynamics, and thermodynamics of deformable media, started in the second half of the 20th century.\nTypes of mechanical bodies.\nThe often-used term \"body\" needs to stand for a wide assortment of objects, including particles, projectiles, spacecraft, stars, parts of machinery, parts of solids, parts of fluids (gases and liquids), etc.\nOther distinctions between the various sub-disciplines of mechanics concern the nature of the bodies being described. Particles are bodies with little (known) internal structure, treated as mathematical points in classical mechanics. Rigid bodies have size and shape, but retain a simplicity close to that of the particle, adding just a few so-called degrees of freedom, such as orientation in space.\nOtherwise, bodies may be semi-rigid, i.e. elastic, or non-rigid, i.e. fluid. These subjects have both classical and quantum divisions of study.\nFor instance, the motion of a spacecraft, regarding its orbit and attitude (rotation), is described by the relativistic theory of classical mechanics, while the analogous movements of an atomic nucleus are described by quantum mechanics.\nSub-disciplines.\nThe following are the three main designations consisting of various subjects that are studied in mechanics.\nNote that there is also the \"theory of fields\" which constitutes a separate discipline in physics, formally treated as distinct from mechanics, whether it be classical fields or quantum fields. But in actual practice, subjects belonging to mechanics and fields are closely interwoven. Thus, for instance, forces that act on particles are frequently derived from fields (electromagnetic or gravitational), and particles generate fields by acting as sources. In fact, in quantum mechanics, particles themselves are fields, as described theoretically by the wave function.\nClassical.\nThe following are described as forming classical mechanics:\nQuantum.\nThe following are categorized as being part of quantum mechanics:\nHistorically, classical mechanics had been around for nearly a quarter millennium before quantum mechanics developed. Classical mechanics originated with Isaac Newton's laws of motion in Philosophi\u00e6 Naturalis Principia Mathematica, developed over the seventeenth century. Quantum mechanics developed later, over the nineteenth century, precipitated by Planck's postulate and Albert Einstein's explanation of the photoelectric effect. Both fields are commonly held to constitute the most certain knowledge that exists about physical nature.\nClassical mechanics has especially often been viewed as a model for other so-called exact sciences. Essential in this respect is the extensive use of mathematics in theories, as well as the decisive role played by experiment in generating and testing them.\nQuantum mechanics is of a bigger scope, as it encompasses classical mechanics as a sub-discipline which applies under certain restricted circumstances. According to the correspondence principle, there is no contradiction or conflict between the two subjects, each simply pertains to specific situations. The correspondence principle states that the behavior of systems described by quantum theories reproduces classical physics in the limit of large quantum numbers, i.e. if quantum mechanics is applied to large systems (for e.g. a baseball), the result would almost be the same if classical mechanics had been applied. Quantum mechanics has superseded classical mechanics at the foundation level and is indispensable for the explanation and prediction of processes at the molecular, atomic, and sub-atomic level. However, for macroscopic processes classical mechanics is able to solve problems which are unmanageably difficult (mainly due to computational limits) in quantum mechanics and hence remains useful and well used.\nModern descriptions of such behavior begin with a careful definition of such quantities as displacement (distance moved), time, velocity, acceleration, mass, and force. Until about 400 years ago, however, motion was explained from a very different point of view. For example, following the ideas of Greek philosopher and scientist Aristotle, scientists reasoned that a cannonball falls down because its natural position is in the Earth; the Sun, the Moon, and the stars travel in circles around the Earth because it is the nature of heavenly objects to travel in perfect circles.\nOften cited as father to modern science, Galileo brought together the ideas of other great thinkers of his time and began to calculate motion in terms of distance travelled from some starting position and the time that it took. He showed that the speed of falling objects increases steadily during the time of their fall. This acceleration is the same for heavy objects as for light ones, provided air friction (air resistance) is discounted. The English mathematician and physicist Isaac Newton improved this analysis by defining force and mass and relating these to acceleration. For objects traveling at speeds close to the speed of light, Newton's laws were superseded by Albert Einstein's theory of relativity. [A sentence illustrating the computational complication of Einstein's theory of relativity.] For atomic and subatomic particles, Newton's laws were superseded by quantum theory. For everyday phenomena, however, Newton's three laws of motion remain the cornerstone of dynamics, which is the study of what causes motion.\nRelativistic.\nAkin to the distinction between quantum and classical mechanics, Albert Einstein's general and special theories of relativity have expanded the scope of Newton and Galileo's formulation of mechanics. The differences between relativistic and Newtonian mechanics become significant and even dominant as the velocity of a body approaches the speed of light. For instance, in Newtonian mechanics, the kinetic energy of a free particle is \"E\" = \"mv\"2, whereas in relativistic mechanics, it is \"E\" = (\"\u03b3\" \u2212 1)\"mc\"2 (where \"\u03b3\" is the Lorentz factor; this formula reduces to the Newtonian expression in the low energy limit).\nFor high-energy processes, quantum mechanics must be adjusted to account for special relativity; this has led to the development of quantum field theory.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "19560", "revid": "205121", "url": "https://en.wikipedia.org/wiki?curid=19560", "title": "Material science", "text": ""}
{"id": "19562", "revid": "93143", "url": "https://en.wikipedia.org/wiki?curid=19562", "title": "Mandelbrot set", "text": "Fractal named after mathematician Benoit Mandelbrot\nThe Mandelbrot set () is a two-dimensional set that is defined in the complex plane as the complex numbers formula_1 for which the function formula_2 does not diverge to infinity when iterated starting at formula_3, i.e., for which the sequence formula_4, formula_5, etc., remains bounded in absolute value.\nThis set was first defined and drawn by Robert W. Brooks and Peter Matelski in 1978, as part of a study of Kleinian groups. Afterwards, in 1980, Benoit Mandelbrot obtained high-quality visualizations of the set while working at IBM's Thomas J. Watson Research Center in Yorktown Heights, New York.\nImages of the Mandelbrot set exhibit an infinitely complicated boundary that reveals progressively ever-finer recursive detail at increasing magnifications; mathematically, the boundary of the Mandelbrot set is a fractal curve. The \"style\" of this recursive detail depends on the region of the set boundary being examined. Mandelbrot set images may be created by sampling the complex numbers and testing, for each sample point formula_1, whether the sequence formula_7 goes to infinity. Treating the real and imaginary parts of formula_1 as image coordinates on the complex plane, pixels may then be colored according to how soon the sequence formula_9 crosses an arbitrarily chosen threshold (the threshold must be at least 2, as \u22122 is the complex number with the largest magnitude within the set, but otherwise the threshold is arbitrary). If formula_1 is held constant and the initial value of formula_11 is varied instead, the corresponding Julia set for the point formula_1 is obtained.\nThe Mandelbrot set is well-known, even outside mathematics, for how it exhibits complex fractal structures when visualized and magnified, despite having a relatively simple definition, and is commonly cited as an example of mathematical beauty.\nHistory.\nThe Mandelbrot set has its origin in complex dynamics, a field first investigated by the French mathematicians Pierre Fatou and Gaston Julia at the beginning of the 20th century. The fractal was first defined and drawn in 1978 by Robert W. Brooks and Peter Matelski as part of a study of Kleinian groups. On 1 March 1980, at IBM's Thomas J. Watson Research Center in Yorktown Heights, New York, Benoit Mandelbrot first visualized the set.\nMandelbrot studied the parameter space of quadratic polynomials in an article that appeared in 1980. The mathematical study of the Mandelbrot set really began with work by the mathematicians Adrien Douady and John H. Hubbard (1985), who established many of its fundamental properties and named the set in honor of Mandelbrot for his influential work in fractal geometry.\nThe mathematicians Heinz-Otto Peitgen and Peter Richter became well known for promoting the set with photographs, books (1986), and an internationally touring exhibit of the German Goethe-Institut (1985).\nThe cover article of the August 1985 \"Scientific American\" introduced the algorithm for computing the Mandelbrot set. The cover was created by Peitgen, Richter and Saupe at the University of Bremen. The Mandelbrot set became prominent in the mid-1980s as a computer-graphics demo, when personal computers became powerful enough to plot and display the set in high resolution.\nThe work of Douady and Hubbard occurred during an increase in interest in complex dynamics and abstract mathematics, and the topological and geometric study of the Mandelbrot set remains a key topic in the field of complex dynamics.\nFormal definition.\nThe Mandelbrot set is the uncountable set of values of \"c\" in the complex plane for which the orbit of the critical point formula_13 under iteration of the quadratic map\nformula_14 \nremains bounded. Thus, a complex number \"c\" is a member of the Mandelbrot set if, when starting with formula_15 and applying the iteration repeatedly, the absolute value of formula_16 remains bounded for all formula_17.\nFor example, for \"c\" = 1, the sequence is 0, 1, 2, 5, 26, ..., which tends to infinity, so 1 is not an element of the Mandelbrot set. On the other hand, for formula_18, the sequence is 0, \u22121, 0, \u22121, 0, ..., which is bounded, so \u22121 does belong to the set.\nThe Mandelbrot set can also be defined as the connectedness locus of the family of quadratic polynomials formula_19, the subset of the space of parameters formula_1 for which the Julia set of the corresponding polynomial forms a connected set. In the same way, the boundary of the Mandelbrot set can be defined as the bifurcation locus of this quadratic family, the subset of parameters near which the dynamic behavior of the polynomial (when it is iterated repeatedly) changes drastically.\nBasic properties.\nThe Mandelbrot set is a compact set, since it is closed and contained in the closed disk of radius 2 centred on zero. A point formula_1 belongs to the Mandelbrot set if and only if formula_22 for all formula_23. In other words, the absolute value of formula_16 must remain at or below 2 for formula_1 to be in the Mandelbrot set, formula_26, and if that absolute value exceeds 2, the sequence will escape to infinity. Since formula_27, it follows that formula_28, establishing that formula_1 will always be in the closed disk of radius 2 around the origin.\nThe intersection of formula_26 with the real axis is the interval formula_31. The parameters along this interval can be put in one-to-one correspondence with those of the real logistic family,\nformula_32\nThe correspondence is given by\nformula_33\nThis gives a correspondence between the entire parameter space of the logistic family and that of the Mandelbrot set.\nDouady and Hubbard showed that the Mandelbrot set is connected. They constructed an explicit conformal isomorphism between the complement of the Mandelbrot set and the complement of the closed unit disk. Mandelbrot had originally conjectured that the Mandelbrot set is disconnected. This conjecture was based on computer pictures generated by programs that are unable to detect the thin filaments connecting different parts of formula_26. Upon further experiments, he revised his conjecture, deciding that formula_26 should be connected. A topological proof of the connectedness was discovered in 2001 by Jeremy Kahn.\nThe dynamical formula for the uniformisation of the complement of the Mandelbrot set, arising from Douady and Hubbard's proof of the connectedness of formula_26, gives rise to external rays of the Mandelbrot set. These rays can be used to study the Mandelbrot set in combinatorial terms and form the backbone of the Yoccoz parapuzzle.\nThe boundary of the Mandelbrot set is the bifurcation locus of the family of quadratic polynomials. In other words, the boundary of the Mandelbrot set is the set of all parameters formula_1 for which the dynamics of the quadratic map formula_38 exhibits sensitive dependence on formula_39 i.e. changes abruptly under arbitrarily small changes of formula_40 It can be constructed as the limit set of a sequence of plane algebraic curves, the \"Mandelbrot curves\", of the general type known as polynomial lemniscates. The Mandelbrot curves are defined by setting formula_41, and then interpreting the set of points formula_42 in the complex plane as a curve in the real Cartesian plane of degree formula_43in \"x\" and \"y\". Each curve formula_17 is the mapping of an initial circle of radius 2 under formula_45. These algebraic curves appear in images of the Mandelbrot set computed using the \"escape time algorithm\" mentioned below.\nOther properties.\nMain cardioid and period bulbs.\nThe \"main cardioid\" is the period 1 continent. It is the region of parameters formula_1 for which the map formula_47 has an attracting fixed point. It consists of all parameters of the form formula_48 for some formula_49 in the open unit disk.\nTo the left of the main cardioid, attached to it at the point formula_50, a circular bulb, the \"period-2 bulb\" is visible. The bulb consists of formula_1 for which formula_52 has an attracting cycle of period 2. It is the filled circle of radius 1/4 centered around \u22121.\nMore generally, for every positive integer formula_53, there are formula_54 circular bulbs tangent to the main cardioid called \"period-q bulbs\" (where formula_55 denotes the Euler phi function), which consist of parameters formula_1 for which formula_52 has an attracting cycle of period formula_58. More specifically, for each primitive formula_58th root of unity formula_60 (where formula_61), there is one period-q bulb called the formula_62 bulb, which is tangent to the main cardioid at the parameter formula_63 and which contains parameters with formula_58-cycles having combinatorial rotation number formula_62. More precisely, the formula_58 periodic Fatou components containing the attracting cycle all touch at a common point (commonly called the \"formula_67-fixed point\"). If we label these components formula_68 in counterclockwise orientation, then formula_52 maps the component formula_70 to the component formula_71.\nThe change of behavior occurring at formula_72 is known as a bifurcation: the attracting fixed point \"collides\" with a repelling period-\"q\" cycle. As we pass through the bifurcation parameter into the formula_73-bulb, the attracting fixed point turns into a repelling fixed point (the formula_67-fixed point), and the period-\"q\" cycle becomes attracting.\nHyperbolic components.\nBulbs that are interior components of the Mandelbrot set in which the maps formula_52 have an attracting periodic cycle are called \"hyperbolic components\".\nIt is conjectured that these are the \"only\" interior regions of formula_26 and that they are dense in formula_26. This problem, known as \"density of hyperbolicity\", is one of the most important open problems in complex dynamics. Hypothetical non-hyperbolic components of the Mandelbrot set are often referred to as \"queer\" or ghost components. For real quadratic polynomials, this question was proved in the 1990s independently by Lyubich and by Graczyk and \u015awi\u0105tek. (Note that hyperbolic components intersecting the real axis correspond exactly to periodic windows in the Feigenbaum diagram. So this result states that such windows exist near every parameter in the diagram.)\nNot every hyperbolic component can be reached by a sequence of direct bifurcations from the main cardioid of the Mandelbrot set. Such a component can be reached by a sequence of direct bifurcations from the main cardioid of a little Mandelbrot copy (see below).\nEach of the hyperbolic components has a \"center\", which is a point \"c\" such that the inner Fatou domain for formula_78 has a super-attracting cycle\u2014that is, that the attraction is infinite. This means that the cycle contains the critical point 0, so that 0 is iterated back to itself after some iterations. Therefore, formula_79 for some \"n\". If we call this polynomial formula_80 (letting it depend on \"c\" instead of \"z\"), we have that formula_81 and that the degree of formula_80 is formula_83. Therefore, constructing the centers of the hyperbolic components is possible by successively solving the equations formula_84. The number of new centers produced in each step is given by Sloane's (sequence in the OEIS).\nLocal connectivity.\nIt is conjectured that the Mandelbrot set is locally connected. This conjecture is known as \"MLC\" (for \"Mandelbrot locally connected\"). By the work of Adrien Douady and John H. Hubbard, this conjecture would result in a simple abstract \"pinched disk\" model of the Mandelbrot set. In particular, it would imply the important \"hyperbolicity conjecture\" mentioned above.\nThe work of Jean-Christophe Yoccoz established local connectivity of the Mandelbrot set at all finitely renormalizable parameters; that is, roughly speaking those contained only in finitely many small Mandelbrot copies. Since then, local connectivity has been proved at many other points of formula_26, but the full conjecture is still open.\nSelf-similarity.\nThe Mandelbrot set is self-similar under magnification in the neighborhoods of the Misiurewicz points. It is also conjectured to be self-similar around generalized Feigenbaum points (e.g., \u22121.401155 or \u22120.1528\u00a0+\u00a01.0397\"i\"), in the sense of converging to a limit set. The Mandelbrot set in general is quasi-self-similar, as small slightly different versions of itself can be found at arbitrarily small scales. These copies of the Mandelbrot set are all slightly different, mostly because of the thin threads connecting them to the main body of the set.\nFurther results.\nThe Hausdorff dimension of the boundary of the Mandelbrot set equals 2 as determined by a result of Mitsuhiro Shishikura. The fact that this is greater by a whole integer than its topological dimension, which is 1, reflects the extreme fractal nature of the Mandelbrot set boundary. Roughly speaking, Shishikura's result states that the Mandelbrot set boundary is so \"wiggly\" that it locally fills space as efficiently as a two-dimensional planar region. Curves with Hausdorff dimension 2, despite being (topologically) 1-dimensional, are oftentimes capable of having nonzero area (more formally, a nonzero planar Lebesgue measure). Whether this is the case for the Mandelbrot set boundary is an unsolved problem.\nIt has been shown that the generalized Mandelbrot set in higher-dimensional hypercomplex number spaces (i.e. when the power formula_67 of the iterated variable formula_11 tends to infinity) is convergent to the unit (formula_67\u22121)-sphere.\nIn the Blum\u2013Shub\u2013Smale model of real computation, the Mandelbrot set is not computable, but its complement is computably enumerable. Many simple objects (e.g., the graph of exponentiation) are also not computable in the BSS model. At present, it is unknown whether the Mandelbrot set is computable in models of real computation based on computable analysis, which correspond more closely to the intuitive notion of \"plotting the set by a computer\". Hertling has shown that the Mandelbrot set is computable in this model if the hyperbolicity conjecture is true.\nRelationship with Julia sets.\nAs a consequence of the definition of the Mandelbrot set, there is a close correspondence between the geometry of the Mandelbrot set at a given point and the structure of the corresponding Julia set. For instance, a value of c belongs to the Mandelbrot set if and only if the corresponding Julia set is connected. Thus, the Mandelbrot set may be seen as a map of the connected Julia sets.\nThis principle is exploited in virtually all deep results on the Mandelbrot set. For example, Shishikura proved that, for a dense set of parameters in the boundary of the Mandelbrot set, the Julia set has Hausdorff dimension two, and then transfers this information to the parameter plane. Similarly, Yoccoz first proved the local connectivity of Julia sets, before establishing it for the Mandelbrot set at the corresponding parameters.\nGeometry.\nFor every rational number formula_73, where \"p\" and \"q\" are coprime, a hyperbolic component of period \"q\" bifurcates from the main cardioid at a point on the edge of the cardioid corresponding to an internal angle of formula_90. The part of the Mandelbrot set connected to the main cardioid at this bifurcation point is called the \"p\"/\"q\"-limb. Computer experiments suggest that the diameter of the limb tends to zero like formula_91. The best current estimate known is the Yoccoz-inequality, which states that the size tends to zero like formula_92.\nA period-\"q\" limb will have formula_93 \"antennae\" at the top of its limb. The period of a given bulb is determined by counting these antennas. The numerator of the rotation number, \"p\", is found by numbering each antenna counterclockwise from the limb from 1 to formula_93 and finding which antenna is the shortest.\nPi in the Mandelbrot set.\nThere are intriguing experiments in the Mandelbrot set that lead to the occurrence of the number formula_95. For a parameter formula_96 with formula_97, verifying that formula_1 is not in the Mandelbrot set means iterating the sequence formula_14 starting with formula_3, until the sequence leaves the disk around formula_101 of any radius formula_102. This is motivated by the (still open) question whether the vertical line at real part formula_103 intersects the Mandelbrot set at points away from the real line. It turns out that the necessary number of iterations, multiplied by formula_104, converges to pi. For example, for \"formula_104\" = 0.0000001, and formula_106, the number of iterations is 31415928 and the product is 3.1415928. This experiment was performed independently by many people in the early 1990s, if not before; for instance by David Boll.\nAnalogous observations have also been made at the parameters formula_107 and formula_108 (with a necessary modification in the latter case). In 2001, Aaron Klebanoff published a (non-conceptual) proof for this phenomenon at formula_108\nIn 2023, Paul Siewert developed, in his Bachelor thesis, a conceptual proof also for the value formula_108, explaining why the number pi occurs (geometrically as half the circumference of the unit circle).\nIn 2025, the three high school students Thies Brockm\u00f6ller, Oscar Scherz, and Nedim Srkalovic extended the theory and the conceptual proof to all the infinitely bifurcation points in the Mandelbrot set.\nFibonacci sequence in the Mandelbrot set.\nThe Mandelbrot Set features a fundamental cardioid shape adorned with numerous bulbs directly attached to it. Understanding the arrangement of these bulbs requires a detailed examination of the Mandelbrot Set's boundary. As one zooms into specific portions with a geometric perspective, precise deducible information about the location within the boundary and the corresponding dynamical behavior for parameters drawn from associated bulbs emerges.\nThe iteration of the quadratic polynomial formula_47, where formula_1\u00a0is a parameter drawn from one of the bulbs attached to the main cardioid within the Mandelbrot Set, gives rise to maps featuring attracting cycles of a specified period formula_58\u00a0and a rotation number formula_114. In this context, the attracting cycle of \u00a0exhibits rotational motion around a central fixed point, completing an average of formula_114\u00a0revolutions at each iteration.\nThe bulbs within the Mandelbrot Set are distinguishable by both their attracting cycles and the geometric features of their structure. Each bulb is characterized by an antenna attached to it, emanating from a junction point and displaying a certain number of spokes indicative of its period. For instance, the formula_116 bulb is identified by its attracting cycle with a rotation number of formula_116. Its distinctive antenna-like structure comprises a junction point from which five spokes emanate. Among these spokes, called the principal spoke is directly attached to the formula_116 bulb, and the 'smallest' non-principal spoke is positioned approximately formula_116 of a turn counterclockwise from the principal spoke, providing a distinctive identification as a formula_116-bulb. This raises the question: how does one discern which among these spokes is the 'smallest'? In the theory of external rays developed by Douady and Hubbard, there are precisely two external rays landing at the root point of a satellite hyperbolic component of the Mandelbrot Set. Each of these rays possesses an external angle that undergoes doubling under the angle doubling map formula_121 formula_122. According to this theorem, when two rays land at the same point, no other rays between them can intersect. Thus, the 'size' of this region is measured by determining the length of the arc between the two angles.\nIf the root point of the main cardioid is the cusp at formula_108, then the main cardioid is the formula_124-bulb. The root point of any other bulb is just the point where this bulb is attached to the main cardioid. This prompts the inquiry: which is the largest bulb between the root points of the formula_124 and formula_126-bulbs? It is clearly the formula_127-bulb. And note that formula_127 is obtained from the previous two fractions by Farey addition, i.e., adding the numerators and adding the denominators\nformula_129 formula_130 formula_131formula_132formula_133\nSimilarly, the largest bulb between the formula_127 and formula_126-bulbs is the formula_116-bulb, again given by Farey addition.\nformula_133 formula_130 formula_131formula_132formula_141\nThe largest bulb between the formula_116 and formula_126-bulb is the formula_144-bulb, while the largest bulb between the formula_116 and formula_127-bulbs is the formula_147-bulb, and so on. The arrangement of bulbs within the Mandelbrot set follows a remarkable pattern governed by the Farey tree, a structure encompassing all rationals between formula_101 and formula_149. This ordering positions the bulbs along the boundary of the main cardioid precisely according to the rational numbers in the unit interval.\nStarting with the formula_127 bulb at the top and progressing towards the formula_126 circle, the sequence unfolds systematically: the largest bulb between formula_126 and formula_127 is formula_116, between formula_127 and formula_116 is formula_147, and so forth. Intriguingly, the denominators of the periods of circular bulbs at sequential scales in the Mandelbrot Set conform to the Fibonacci number sequence, the sequence that is made by adding the previous two terms \u2013 1, 2, 3, 5, 8, 13, 21...\nThe Fibonacci sequence manifests in the number of spiral arms at a unique spot on the Mandelbrot set, mirrored both at the top and bottom. This distinctive location demands the highest number of iterations of \u00a0for a detailed fractal visual, with intricate details repeating as one zooms in.\nImage gallery of a zoom sequence.\nThe boundary of the Mandelbrot set shows more intricate detail the closer one looks or magnifies the image. The following is an example of an image sequence zooming to a selected \"c\" value. The area shown is known as the \"seahorse valley\", which is a region of the Mandelbrot set centred on the point \u22120.75\u00a0+\u00a00.1\"i\".\nThe magnification of the last image relative to the first one is about 1010 to 1. Relating to an ordinary computer monitor, it represents a section of a Mandelbrot set with a diameter of 4 million kilometers.\nThe seahorse \"body\" is composed by 25 \"spokes\" consisting of two groups of 12 \"spokes\" each and one \"spoke\" connecting to the main cardioid. These two groups can be attributed by some metamorphosis to the two \"fingers\" of the \"upper hand\" of the Mandelbrot set; therefore, the number of \"spokes\" increases from one \"seahorse\" to the next by 2; the \"hub\" is a Misiurewicz point. Between the \"upper part of the body\" and the \"tail\", there is a distorted copy of the Mandelbrot set, called a \"satellite\".\nThe islands in the third-to-last step seem to consist of infinitely many parts, as is the case for the corresponding Julia set formula_158. They are connected by tiny structures, so that the whole represents a simply connected set. The tiny structures meet each other at a satellite in the center that is too small to be recognized at this magnification. The value of \"formula_159\" for the corresponding \"formula_158\" is not the image center but, relative to the main body of the Mandelbrot set, has the same position as the center of this image relative to the satellite shown in the 6th step.\nInner structure.\nWhile the Mandelbrot set is typically rendered showing outside boundary detail, structure within the bounded set can also be revealed. For example, while calculating whether or not a given c value is bound or unbound, while it remains bound, the maximum value that this number reaches can be compared to the c value at that location. If the https:// is used, the calculated number would be max:(real^2 + imaginary^2) \u2212 c:(real^2 + imaginary^2). The magnitude of this calculation can be rendered as a value on a gradient.\nThis produces results like the following, gradients with distinct edges and contours as the boundaries are approached. The animations serve to highlight the gradient boundaries.\nGeneralizations.\nMultibrot sets.\nMultibrot sets are bounded sets found in the complex plane for members of the general monic univariate polynomial family of recursions\nformula_161.\nFor an integer \"d\", these sets are connectedness loci for the Julia sets built from the same formula. The full cubic connectedness locus has also been studied; here one considers the two-parameter recursion formula_162, whose two critical points are the complex square roots of the parameter \"k\". A parameter is in the cubic connectedness locus if both critical points are stable. For general families of holomorphic functions, the \"boundary\" of the Mandelbrot set generalizes to the bifurcation locus.\nThe Multibrot set is obtained by varying the value of the exponent \"d\". The article has a video that shows the development from \"d\" = 0 to 7, at which point there are 6 i.e. formula_163 lobes around the perimeter. In general, when \"d\" is a positive integer, the central region in each of these sets is always an epicycloid of formula_163 cusps. A similar development with negative integral exponents results in formula_165 clefts on the inside of a ring, where the main central region of the set is a hypocycloid of formula_165 cusps.\nHigher dimensions.\nThere is no perfect extension of the Mandelbrot set into 3D, because there is no 3D analogue of the complex numbers for it to iterate on. There is an extension of the complex numbers into 4 dimensions, the quaternions, that creates a perfect extension of the Mandelbrot set and the Julia sets into 4 dimensions. These can then be either cross-sectioned or projected into a 3D structure. The quaternion (4-dimensional) Mandelbrot set is simply a solid of revolution of the 2-dimensional Mandelbrot set (in the j-k plane), and is therefore uninteresting to look at. Taking a 3-dimensional cross section at formula_167 results in a solid of revolution of the 2-dimensional Mandelbrot set around the real axis.\nOther non-analytic mappings.\nThe tricorn fractal, also called the Mandelbar set, is the connectedness locus of the anti-holomorphic family formula_168. It was encountered by Milnor in his study of parameter slices of real cubic polynomials. It is not locally connected. This property is inherited by the connectedness locus of real cubic polynomials.\nAnother non-analytic generalization is the Burning Ship fractal, which is obtained by iterating the following:\nformula_169.\nComputer drawings.\nThere exist a multitude of various algorithms for plotting the Mandelbrot set via a computing device. Here, the na\u00efve \"escape time algorithm\" will be shown, since it is the most popular and one of the simplest algorithms. In the escape time algorithm, a repeating calculation is performed for each \"x\", \"y\" point in the plot area and based on the behavior of that calculation, a color is chosen for that pixel.\nThe \"x\" and \"y\" locations of each point are used as starting values in a repeating, or iterating calculation (described in detail below). The result of each iteration is used as the starting values for the next. The values are checked during each iteration to see whether they have reached a critical \"escape\" condition, or \"bailout\". If that condition is reached, the calculation is stopped, the pixel is drawn, and the next \"x\", \"y\" point is examined.\nThe color of each point represents how quickly the values reached the escape point. Often black is used to show values that fail to escape before the iteration limit, and gradually brighter colors are used for points that escape. This gives a visual representation of how many cycles were required before reaching the escape condition.\nTo render such an image, the region of the complex plane we are considering is subdivided into a certain number of pixels. To color any such pixel, let formula_1 be the midpoint of that pixel. Iterate the critical point 0 under formula_52, checking at each step whether the orbit point has a radius larger than 2. When this is the case, formula_1 does not belong to the Mandelbrot set, and color the pixel according to the number of iterations used to find out. Otherwise, keep iterating up to a fixed number of steps, after which we decide that our parameter is \"probably\" in the Mandelbrot set, or at least very close to it, and color the pixel black.\nIn pseudocode, this algorithm would look as follows. The algorithm does not use complex numbers and manually simulates complex-number operations using two real numbers, for those who do not have a complex data type. The program may be simplified if the programming language includes complex-data-type operations.\n for each pixel (Px, Py) on the screen do\n x0 := scaled x coordinate of pixel (scaled to lie in the Mandelbrot X scale (-2.00, 0.47))\n y0 := scaled y coordinate of pixel (scaled to lie in the Mandelbrot Y scale (-1.12, 1.12))\n x := 0.0\n y := 0.0\n iteration := 0\n max_iteration := 1000\n while (x^2 + y^2 \u2264 2^2 AND iteration &lt; max_iteration) do\n xtemp := x^2 - y^2 + x0\n y := 2*x*y + y0\n x := xtemp\n iteration := iteration + 1\n \n color := palette[iteration]\n plot(Px, Py, color)\nHere, relating the pseudocode to formula_1, formula_11 and formula_52:\nand so, as can be seen in the pseudocode in the computation of \"x\" and \"y\":\nTo get colorful images of the set, the assignment of a color to each value of the number of executed iterations can be made using one of a variety of functions (linear, exponential, etc.).\nPython code.\nHere is the code implementing the above algorithm in Python:\nimport numpy as np\nimport matplotlib.pyplot as plt\nx_domain, y_domain = np.linspace(-2, 2, 500), np.linspace(-2, 2, 500)\nbound = 2\nmax_iterations = 50 # any positive integer value\ncolormap = \"nipy_spectral\" # set to any matplotlib valid colormap\nfunc = lambda z, p, c: z**p + c\niteration_array = []\nfor y in y_domain:\n row = []\n for x in x_domain:\n z = 0\n p = 2\n c = complex(x, y)\n for iteration_number in range(max_iterations):\n if abs(z) &gt;= bound:\n row.append(iteration_number)\n break\n else:\n try:\n z = func(z, p, c)\n except (ValueError, ZeroDivisionError):\n z = c\n else:\n row.append(0)\n iteration_array.append(row)\nax = plt.axes()\nax.set_aspect(\"equal\")\ngraph = ax.pcolormesh(x_domain, y_domain, iteration_array, cmap=colormap)\nplt.colorbar(graph)\nplt.xlabel(\"Real-Axis\")\nplt.ylabel(\"Imaginary-Axis\")\nplt.show()\nThe value of codice_1 variable can be modified to generate an image of equivalent multibrot set (formula_181). For example, setting codice_2 produces the associated image.\nReferences in popular culture.\nThe Mandelbrot set is widely considered the most popular fractal, and has been referenced several times in popular culture.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "19564", "revid": "194203", "url": "https://en.wikipedia.org/wiki?curid=19564", "title": "Music critic", "text": ""}
{"id": "19565", "revid": "51031800", "url": "https://en.wikipedia.org/wiki?curid=19565", "title": "Michael Mann", "text": "American filmmaker (born 1943)\nMichael Kenneth Mann (born February 5, 1943) is an American film director, screenwriter, author and producer. Best known for his stylized crime dramas, he has won two Primetime Emmy Awards, as well as earned nominations for four Academy Awards, two Golden Globe Awards, and a BAFTA Award. His most acclaimed works include the films \"Thief\" (1981), \"Manhunter\" (1986), \"The Last of the Mohicans\" (1992), \"Heat\" (1995), \"The Insider\" (1999), \"Ali\" (2001), \"Collateral\" (2004), \"Public Enemies\" (2009), and \"Ferrari\" (2023). He was executive producer on the popular TV series \"Miami Vice\" (1984\u201390), which he adapted into a 2006 feature film.\nEarly life.\nMann was born February 5, 1943, in Chicago, Illinois. He is Jewish and the son of Esther and Jack Mann. His grandfather left the Russian Empire in 1912, and brought his wife and Mann's father over in 1922.\nMann graduated from Amundsen High School, also the alma mater of Bob Fosse. He then studied English literature at the University of Wisconsin\u2013Madison. While a student, he saw Stanley Kubrick's \"Dr. Strangelove\" and fell in love with movies. In an \"LA Weekly\" interview, he described the film's impact on him:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;It said to my whole generation of filmmakers that you could make an individual statement of high integrity and have that film be successfully seen by a mass audience all at the same time. In other words, you didn't have to be making \"Seven Brides for Seven Brothers\" if you wanted to work in the mainstream film industry, or be reduced to niche filmmaking if you wanted to be serious about cinema. So that's what Kubrick meant, aside from the fact that \"Strangelove\" was a revelation.\nCareer.\n1967\u20131978: Rise to prominence.\nMann graduated from the University of Wisconsin with a BA in 1965. He later moved to London in the mid-1960s to go to graduate school in cinema and went on to receive a graduate degree at the London Film School in 1967. He spent seven years in the United Kingdom going to film school and then working on commercials along with contemporaries Alan Parker, Ridley Scott and Adrian Lyne. In 1968, footage he shot of the Paris student revolt for a documentary, \"Insurrection\", aired on NBC's \"First Tuesday\" news program and he developed his '68 experiences into the short film \"Jaunpuri\" which won the Jury Prize at Cannes in 1970.\nMann returned to the United States after divorcing his first wife in 1971. He went on to direct a road trip documentary, \"17 Days Down the Line\" (1972). Three years later, \"Hawaii Five-O\" veteran Robert Lewin gave Mann a shot and a crash course on television writing and story structure. This led to Mann writing four episodes for \"Starsky and Hutch\" between 1975\u20131977 (three in the first season and one in the second), two episodes for \"Bronk\" in 1976, and an episode for \"Gibbsville\" in 1976. Between 1976\u20131978, he wrote four episodes for \"Police Story\" (as well as directed one for the spin-off series \"Police Woman\" in 1977) with cop-turned-novelist Joseph Wambaugh. \"Police Story\" concentrated on the detailed realism of a real cop's life and taught Mann that first-hand research was essential to bring authenticity to his work. \nIn 1976\u20131977, Mann worked on a screenplay originally titled \"The Last Public Enemy\" but later re-titled \"Karpis\", based on Canadian-American criminal Alvin Karpis's autobiography, \"The Alvin Karpis Story\". The film was scheduled to be made at Paramount Pictures for producers Harold Hecht and Robert L. Rosen, and was to be directed by John Frankenheimer (who had previously directed a similar film, \"Birdman of Alcatraz\", for Hecht), but it was never produced. Mann also wrote an early draft of the 1978 film \"Straight Time\", which was based on real-life criminal-turned author Edward Bunker's novel \"No Beast So Fierce\". He then created and wrote the pilot episode for \"Vegas\" (1978\u20131981).\n1978\u20131999: Career breakthrough and acclaim.\nMann's first feature movie was the sports-themed \"Swan Song\" starring David Soul for ABC, which was filmed in April 1978. However, it was only broadcast in February 1980, after his second feature, \"The Jericho Mile\", had been released. \"The Jericho Mile\" was also made for ABC for television broadcast in the United States but was released theatrically in Europe. The movie was filmed on location at the Folsom State Penitentiary, and won an Emmy for Outstanding Writing in a Limited Series or a Special in 1979 and the Directors Guild of America award for Best Director. \nMann's debut feature in cinema as director was \"Thief\" (1981) starring James Caan, a relatively accurate depiction of thieves that operated in New York City and Chicago at that time. Mann used actual former professional burglars to keep the technical scenes as genuine as possible. His next film was \"The Keep\" (1983), a supernatural thriller set in Nazi-occupied Romania. Though it was a commercial flop, the film has since attained cult status amongst fans. \nHis television work in the mid-1980s includes being the executive producer on \"Miami Vice\" (1984\u20131990) and \"Crime Story\" (1986\u20131988). Contrary to popular belief, he was not the creator of these shows, but the executive producer and showrunner, produced by his production company. His production company also produced Paul Michael Glaser's 1986 film \"Band of the Hand.\"\nIn 1986, Mann was the first to bring Thomas Harris' character of serial killer Hannibal Lecter to the screen with \"Manhunter\", his adaptation of the novel \"Red Dragon\", which starred Brian Cox as Hannibal. In an interview on the \"Manhunter\" DVD, star William Petersen comments that because Mann is so focused on his creations, it takes several years for him to complete a film; Petersen believes that this is why Mann does not make films very often. \nIn 1989, he wrote, produced and directed the crime television film \"L.A. Takedown\". He then wrote and produced the three-part miniseries \"\" (1990), and its 1992 follow-up \"Drug Wars II: The Cocaine Cartel\".\nMann gained widespread recognition in 1992 for his film adaptation of James Fenimore Cooper's novel into the epic historical drama \"The Last of the Mohicans\" starring Daniel Day-Lewis. The film is set during the French and Indian War. Film critic Owen Gleiberman of \"Entertainment Weekly\" described Mann's directorial style, writing that \"Mann, at his best, is a master of violence and lyrical anxiety\". Peter Travers of \"Rolling Stone\" praised Mann's directing, writing that \"the action is richly detailed and thrillingly staged.\"\nThis was followed by crime drama \"Heat\" (1995) starring Al Pacino, Robert De Niro, and Val Kilmer. The film, a remake of his TV movie \"L.A. Takedown\", was a critical success with Kenneth Turan of the \"Los Angeles Times\" calling the film a \"sleek, accomplished piece of work, meticulously controlled and completely involving. The dark end of the street doesn't get much more inviting than this.\" Todd McCarthy of \"Variety\" wrote, \"Stunningly made and incisively acted by a large and terrific cast, Michael Mann's ambitious study of the relativity of good and evil stands apart from other films of its type by virtue of its extraordinarily rich characterizations and its thoughtful, deeply melancholy take on modern life.\"\nIn 1999, Mann filmed \"The Insider\" about the \"60 Minutes\" segment about Jeffrey Wigand, a whistleblower in the tobacco industry. Russell Crowe portrayed Wigand, with Pacino playing Lowell Bergman and Christopher Plummer as Mike Wallace. The film showcased Mann's cinematic style and garnered the most critical recognition of his career up to this point. \"The Insider\" was nominated for seven Academy Awards as a result, including a nomination for Mann's direction. Critic Roger Ebert of the \"Chicago Sun-Times\" praised the film writing, \"\"The Insider\" had a greater impact on me than \"All the President's Men\", because you know what? Watergate didn't kill my parents. Cigarettes did.\"\n2001\u2013present.\nWith his next film, \"Ali\" (2001), starring Will Smith, Mann started experimenting with digital cameras. For his action thriller film \"Collateral\", which was released in 2004, Mann cast Tom Cruise against type by giving him the role of a hitman. Mann shot all of the exterior scenes digitally so that he could achieve more depth and detail during the night scenes while shooting most of the interiors on film stock. Jamie Foxx was nominated for an Academy Award for his performance in \"Collateral\". Also in 2004, he produced Martin Scorsese's \"The Aviator\", based on the life of Howard Hughes, which he had developed with Leonardo DiCaprio. \"The Aviator\" was nominated for an Academy Award for Best Picture but lost to \"Million Dollar Baby\". After \"Collateral\", Mann directed the film adaptation of \"Miami Vice\" which he also executive produced. The film starred Colin Farrell as Don Johnson's character James \"Sonny\" Crockett, and Foxx filling Philip Michael Thomas' shoes as Ricardo Tubbs.\nMann directed the 2002 \"Lucky Star\" advertisement for Mercedes-Benz, which took the form of a film trailer for a purported thriller featuring Benicio del Toro. In the fall of 2007, Mann directed two commercials for Nike. The ad campaign \"Leave Nothing\" features football action scenes with former NFL players Shawne Merriman and Steven Jackson, as well as using the score \"Promontory\" from the soundtrack of \"The Last of the Mohicans\". Mann directed the 2008 promotional video for Ferrari's California sports car.\nMann was producer with Peter Berg as director for \"The Kingdom\" and \"Hancock\". \"Hancock\" stars Smith as a hard-drinking superhero who has fallen out of favor with the public and who begins to have a relationship with the wife (Charlize Theron) of a public relations expert (Jason Bateman), who is helping him to repair his image. Mann makes a cameo appearance in the film as an executive. In 2009, Mann wrote and directed \"Public Enemies\" for Universal Pictures, about the Depression-era crime wave, based on Bryan Burrough's nonfiction book, \"Public Enemies: America's Greatest Crime Wave and the Birth of the FBI, 1933\u201334\". It starred Johnny Depp and Christian Bale. Depp played John Dillinger in the film, and Bale played Melvin Purvis, the FBI agent in charge of capturing Dillinger.\nIn 2009, Mann signed a petition calling for the release of film director Roman Polanski, who had been arrested in Switzerland in relation to his 1977 charge for drugging and raping a 13-year-old girl\nIn January 2010, it was reported by \"Variety\" that Mann, alongside David Milch, would serve as co-executive producer of new TV series \"Luck\" starring Dustin Hoffman and Dennis Farina. The series was an hour-long HBO production, and Mann directed the series' pilot. Although initially renewed for a second season after the airing of the pilot, it was eventually cancelled due to the death of three horses during production.\nIn February 2013, it was announced that Mann had been developing an untitled thriller film with screenwriter Morgan Davis Foehl for over a year, for Legendary Pictures. In May 2013, Mann started filming the action thriller, named \"Blackhat\", in Los Angeles, Kuala Lumpur, Hong Kong and Jakarta. The film, starring Chris Hemsworth as a hacker who gets released from prison to pursue a cyberterrorist across the globe, was released in January 2015 by Universal. It received mixed reviews and was a commercial disaster, although several critics included it in their year-end \"best-of\" lists.\nMann directed the first episode of the 2022 crime series \"Tokyo Vice\" for HBO Max, his first directing work since \"Blackhat\". In August the same year, Mann released \"Heat 2,\" a novel he had co-written with Meg Gardiner. The book takes place from 1988 to 2000, covering events that happen before and after the 1995 film. The same month, Mann began shooting \"Ferrari\" starring Adam Driver and Pen\u00e9lope Cruz in Modena. The film premiered at the 80th Venice International Film Festival and was released in the US in December 2023. \"Ferrari\" received generally positive reviews from critics and attained moderate box office success in the United States, while under-performing in overseas box office.\nMann intends for his next film to be Heat 2, which will be distributed by Amazon MGM Studios and United Artists. Leonardo DiCaprio and Christian Bale are currently understood to be playing the two male leads. \nDirectorial style.\nMann's trademarks include powerfully-lit nighttime scenes and unusual scores, such as Tangerine Dream's for \"Thief\" and the new-age score to \"Manhunter\".\nDante Spinotti is a frequent cinematographer of Mann's films. F. X. Feeney describes Mann's body of work in \"DGA Quarterly\" as \"abundantly energetic in its precision and variety\" and \"psychologically layered\".\n\"IndieWire\"'s 2014 retrospective of the director's filmography focused on the intensity of Mann's ongoing interest in \"stories pitting criminals against those who seek to put them behind bars (\"Heat\", \"Public Enemies\", \"Thief\", \"Collateral\", \"Miami Vice\"). His films frequently suggest that in fact, at the top of their respective games, crooks and cops are not so dissimilar as men: they each live and die by their own codes and they each recognize themselves in the other.\"\nMann's films have been noted for their realism when it comes to capturing the sounds of gunfire, with him preferring to use raw audio captured from the scene, rather than a sound mix. Many of his films feature practical effects to produce the action scenes, with actors attending boot camps for weapons handling and firing 'full load' blanks in scenes to accurately represent the sound of live ammunition.\nPersonal life.\nMann's daughter Ami Canaan Mann is also a film director and producer.\nFilmography.\nMann has directed 12 theatrical feature films. His full filmography includes numerous other works.\nAwards and nominations.\nFor his work, he has received nominations from international organizations and juries, including the British Academy of Film and Television Arts, Cannes, and the Academy of Motion Picture Arts and Sciences. As a producer, Mann has twice received nominations for the Academy Award for Best Picture, first for \"The Insider\" and then \"The Aviator\" (2004), which Mann had been hired to direct before the project was transferred to Martin Scorsese.\n\"Total Film\" ranked Mann No. 28 on its 2007 list of the 100 Greatest Directors Ever, and \"Sight and Sound\" ranked him No. 5 on their list of the 10 Best Directors of the Last 25 Years (for the years 1977\u20132002).\nDirected Academy Award performances\nUnder Mann's direction, these actors have received Academy Award nominations for their performances in their respective roles.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nExternal links.\nInterviews"}
{"id": "19566", "revid": "39174407", "url": "https://en.wikipedia.org/wiki?curid=19566", "title": "Main-group element", "text": "Chemical elements in groups 1, 2, 13\u201318\nIn chemistry and atomic physics, the main group is the group of elements (sometimes called the representative elements) whose lightest members are represented by helium, lithium, beryllium, boron, carbon, nitrogen, oxygen, and fluorine as arranged in the periodic table of the elements. The main group includes the elements (except hydrogen, which is sometimes excluded) in groups 1 and 2 (s-block), and groups 13 to 18 (p-block). The s-block elements are primarily characterised by one main oxidation state, and the p-block elements, when they have multiple oxidation states, often have common oxidation states separated by two units. Advances in this area are often described in the journal Main Group Chemistry.\nMain-group elements (with some of the lighter transition metals) are the most abundant elements on Earth, in the Solar System, and in the universe. Group 12 elements are often considered to be transition metals; however, zinc (Zn), cadmium (Cd), and mercury (Hg) share some properties of both groups, and some scientists believe they should be included in the main group.\nOccasionally, even the group 3 elements as well as the lanthanides and actinides have been included, because especially the group 3 elements and many lanthanides are electropositive elements with only one main oxidation state like the group 1 and 2 elements. The position of the actinides is more questionable, but the most common and stable of them, thorium (Th) and uranium (U), are similar to main-group elements as thorium is an electropositive element with only one main oxidation state (+4), and uranium has two main ones separated by two oxidation units (+4 and +6).\nIn older nomenclature, the main-group elements are groups IA and IIA, and groups IIIB to 0 (CAS groups IIIA to VIIIA). Group 12 is labelled as group IIB in both systems. Group 3 is labelled as group IIIA in the older nomenclature (CAS group IIIB).In the Uranium has two main ones separated by two oxidation units (+4 and +6)\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "19567", "revid": "7611264", "url": "https://en.wikipedia.org/wiki?curid=19567", "title": "Microscopy", "text": "Viewing of objects which are too small to be seen with the naked eye\nMicroscopy is the technical field of using microscopes to view subjects too small to be seen with the naked eye (objects that are not within the resolution range of the normal eye). There are three well-known branches of microscopy: optical, electron, and scanning probe microscopy, along with the emerging field of X-ray microscopy.\nOptical microscopy and electron microscopy involve the diffraction, reflection, or refraction of electromagnetic radiation/electron beams interacting with the specimen, and the collection of the scattered radiation or another signal in order to create an image. This process may be carried out by wide-field irradiation of the sample (for example standard light microscopy and transmission electron microscopy) or by scanning a fine beam over the sample (for example confocal laser scanning microscopy and scanning electron microscopy). Scanning probe microscopy involves the interaction of a scanning probe with the surface of the object of interest. The development of microscopy revolutionized biology, gave rise to the field of histology and so remains an essential technique in the life and physical sciences. X-ray microscopy is three-dimensional and non-destructive, allowing for repeated imaging of the same sample for in situ or 4D studies, and providing the ability to \"see inside\" the sample being studied before sacrificing it to higher resolution techniques. A 3D X-ray microscope uses the technique of computed tomography (microCT), rotating the sample 360 degrees and reconstructing the images. CT is typically carried out with a flat panel display. A 3D X-ray microscope employs a range of objectives, e.g., from 4X to 40X, and can also include a flat panel.\nHistory.\nThe field of microscopy (optical microscopy) dates back to at least the 17th-century. Earlier microscopes, single lens magnifying glasses with limited magnification, date at least as far back as the wide spread use of lenses in eyeglasses in the 13th century but more advanced compound microscopes first appeared in Europe around 1620 The earliest practitioners of microscopy include Galileo Galilei, who found in 1610 that he could close focus his telescope to view small objects close up and Cornelis Drebbel, who may have invented the compound microscope around 1620. Antonie van Leeuwenhoek developed a very high magnification simple microscope in the 1670s and is often considered to be the first acknowledged microscopist and microbiologist.\nOptical microscopy.\nOptical or light microscopy involves passing visible light transmitted through or reflected from the sample through a single lens or multiple lenses to allow a magnified view of the sample. The resulting image can be detected directly by the eye, imaged on a photographic plate, or captured digitally. The single lens with its attachments, or the system of lenses and imaging equipment, along with the appropriate lighting equipment, sample stage, and support, makes up the basic light microscope. The most recent development is the digital microscope, which uses a CCD camera to focus on the exhibit of interest. The image is shown on a computer screen, so eye-pieces are unnecessary.\nLimitations.\nLimitations of standard optical microscopy (bright field microscopy) lie in three areas;\nLive cells in particular generally lack sufficient contrast to be studied successfully, since the internal structures of the cell are colorless and transparent. The most common way to increase contrast is to stain the structures with selective dyes, but this often involves killing and fixing the sample. Staining may also introduce artifacts, which are apparent structural details that are caused by the processing of the specimen and are thus not features of the specimen. In general, these techniques make use of differences in the refractive index of cell structures. Bright-field microscopy is comparable to looking through a glass window: one sees not the glass but merely the dirt on the glass. There is a difference, as glass is a denser material, and this creates a difference in phase of the light passing through. The human eye is not sensitive to this difference in phase, but clever optical solutions have been devised to change this difference in phase into a difference in amplitude (light intensity).\nTechniques.\nTo improve specimen contrast or highlight structures in a sample, special techniques must be used. A huge selection of microscopy techniques are available to increase contrast or label a sample.\n&lt;gallery caption=\"Four examples of transillumination techniques used to generate contrast in a sample of tissue paper. 1.559 \u03bcm/pixel.\" align=\"center\"&gt;\nImage:Paper_Micrograph_Bright.png|Bright field illumination, sample contrast comes from absorbance of light in the sample\nImage:Paper_Micrograph_Cross-Polarised.png|Cross-polarized light illumination, sample contrast comes from rotation of polarized light through the sample\nImage:Paper_Micrograph_Dark.png|Dark field illumination, sample contrast comes from light scattered by the sample\nImage:Paper_Micrograph_Phase.png|Phase contrast illumination, sample contrast comes from interference of different path lengths of light through the sample\n&lt;/gallery&gt;\nBright field.\nBright field microscopy is the simplest of all the light microscopy techniques. Sample illumination is via transmitted white light, i.e. illuminated from below and observed from above. Limitations include low contrast of most biological samples and low apparent resolution due to the blur of out-of-focus material. The simplicity of the technique and the minimal sample preparation required are significant advantages.\nOblique illumination.\nThe use of oblique (from the side) illumination gives the image a three-dimensional appearance and can highlight otherwise invisible features. A more recent technique based on this method is \"Hoffmann's modulation contrast\", a system found on inverted microscopes for use in cell culture. Oblique illumination enhances contrast even in clear specimens; however, because light enters off-axis, the position of an object will appear to shift as the focus is changed. This limitation makes techniques like optical sectioning or accurate measurement on the z-axis impossible.\nDark field.\nDark field microscopy is a technique for improving the contrast of unstained, transparent specimens. Dark field illumination uses a carefully aligned light source to minimize the quantity of directly transmitted (unscattered) light entering the image plane, collecting only the light scattered by the sample. Dark field can dramatically improve image contrast \u2013 especially of transparent objects \u2013 while requiring little equipment setup or sample preparation. However, the technique suffers from low light intensity in the final image of many biological samples and continues to be affected by low apparent resolution.\n\"Rheinberg illumination\" is a variant of dark field illumination in which transparent, colored filters are inserted just before the condenser so that light rays at high aperture are differently colored than those at low aperture (i.e., the background to the specimen may be blue while the object appears self-luminous red). Other color combinations are possible, but their effectiveness is quite variable.\nDispersion staining.\nDispersion staining is an optical technique that results in a colored image of a colorless object. This is an optical staining technique and requires no stains or dyes to produce a color effect. There are five different microscope configurations used in the broader technique of dispersion staining. They include brightfield Becke line, oblique, darkfield, phase contrast, and objective stop dispersion staining.\n \"In electron microscopy: Phase-contrast imaging\"\nPhase contrast.\nMore sophisticated techniques will show proportional differences in optical density. Phase contrast is a widely used technique that shows differences in refractive index as difference in contrast. It was developed by the Dutch physicist Frits Zernike in the 1930s (for which he was awarded the Nobel Prize in 1953). The nucleus in a cell for example will show up darkly against the surrounding cytoplasm. Contrast is excellent; however it is not for use with thick objects. Frequently, a halo is formed even around small objects, which obscures detail. The system consists of a circular annulus in the condenser, which produces a cone of light. This cone is superimposed on a similar sized ring within the phase-objective. Every objective has a different size ring, so for every objective another condenser setting has to be chosen. The ring in the objective has special optical properties: it, first of all, reduces the direct light in intensity, but more importantly, it creates an artificial phase difference of about a quarter wavelength. As the physical properties of this direct light have changed, interference with the diffracted light occurs, resulting in the phase contrast image. One disadvantage of phase-contrast microscopy is halo formation (halo-light ring).\nDifferential interference contrast.\nSuperior and much more expensive is the use of interference contrast. Differences in optical density will show up as differences in relief. A nucleus within a cell will actually show up as a globule in the most often used differential interference contrast system according to Georges Nomarski. However, it has to be kept in mind that this is an \"optical effect\", and the relief does not necessarily resemble the true shape. Contrast is very good and the condenser aperture can be used fully open, thereby reducing the depth of field and maximizing resolution.\nThe system consists of a special prism (Nomarski prism, Wollaston prism) in the condenser that splits light in an ordinary and an extraordinary beam. The spatial difference between the two beams is minimal (less than the maximum resolution of the objective). After passage through the specimen, the beams are reunited by a similar prism in the objective.\nIn a homogeneous specimen, there is no difference between the two beams, and no contrast is being generated. However, near a refractive boundary (say a nucleus within the cytoplasm), the difference between the ordinary and the extraordinary beam will generate a relief in the image. Differential interference contrast requires a polarized light source to function; two polarizing filters have to be fitted in the light path, one below the condenser (the polarizer), and the other above the objective (the analyzer).\nNote: In cases where the optical design of a microscope produces an appreciable lateral separation of the two beams we have the case of classical interference microscopy, which does not result in relief images, but can nevertheless be used for the quantitative determination of mass-thicknesses of microscopic objects.\nInterference reflection.\nAn additional technique using interference is interference reflection microscopy (also known as reflected interference contrast, or RIC). It relies on cell adhesion to the slide to produce an interference signal. If there is no cell attached to the glass, there will be no interference.\nInterference reflection microscopy can be obtained by using the same elements used by DIC, but without the prisms. Also, the light that is being detected is reflected and not transmitted as it is when DIC is employed.\nFluorescence.\nWhen certain compounds are illuminated with high energy light, they emit light of a lower frequency. This effect is known as fluorescence. Often specimens show their characteristic autofluorescence image, based on their chemical makeup.\nThis method is of critical importance in the modern life sciences, as it can be extremely sensitive, allowing the detection of single molecules. Many fluorescent dyes can be used to stain structures or chemical compounds. One powerful method is the combination of antibodies coupled to a fluorophore as in immunostaining. Examples of commonly used fluorophores are fluorescein or rhodamine.\nThe antibodies can be tailor-made for a chemical compound. For example, one strategy often in use is the artificial production of proteins, based on the genetic code (DNA). These proteins can then be used to immunize rabbits, forming antibodies which bind to the protein. The antibodies are then coupled chemically to a fluorophore and used to trace the proteins in the cells under study.\nHighly efficient fluorescent proteins such as the green fluorescent protein (GFP) have been developed using the molecular biology technique of gene fusion, a process that links the expression of the fluorescent compound to that of the target protein. This combined fluorescent protein is, in general, non-toxic to the organism and rarely interferes with the function of the protein under study. Genetically modified cells or organisms directly express the fluorescently tagged proteins, which enables the study of the function of the original protein in vivo.\nGrowth of protein crystals results in both protein and salt crystals. Both are colorless and microscopic. Recovery of the protein crystals requires imaging which can be done by the intrinsic fluorescence of the protein or by using transmission microscopy. Both methods require an ultraviolet microscope as proteins absorbs light at 280\u00a0nm. Protein will also fluorescence at approximately 353\u00a0nm when excited with 280\u00a0nm light.\nSince fluorescence emission differs in wavelength (color) from the excitation light, an ideal fluorescent image shows only the structure of interest that was labeled with the fluorescent dye. This high specificity led to the widespread use of fluorescence light microscopy in biomedical research. Different fluorescent dyes can be used to stain different biological structures, which can then be detected simultaneously, while still being specific due to the individual color of the dye.\nTo block the excitation light from reaching the observer or the detector, filter sets of high quality are needed. These typically consist of an excitation filter selecting the range of excitation wavelengths, a dichroic mirror, and an emission filter blocking the excitation light. Most fluorescence microscopes are operated in the Epi-illumination mode (illumination and detection from one side of the sample) to further decrease the amount of excitation light entering the detector.\nSee also:\ntotal internal reflection fluorescence microscope\nNeuroscience\nConfocal.\nConfocal laser scanning microscopy uses a focused laser beam (e.g. 488\u00a0nm) that is scanned across the sample to excite fluorescence in a point-by-point fashion. The emitted light is directed through a pinhole to prevent out-of-focus light from reaching the detector, typically a photomultiplier tube. The image is constructed in a computer, plotting the measured fluorescence intensities according to the position of the excitation laser. Compared to full sample illumination, confocal microscopy gives slightly higher lateral resolution and significantly improves optical sectioning (axial resolution). Confocal microscopy is, therefore, commonly used where 3D structure is important.\nA subclass of confocal microscopes are spinning disc microscopes which are able to scan multiple points simultaneously across the sample. A corresponding disc with pinholes rejects out-of-focus light. The light detector in a spinning disc microscope is a digital camera, typically EM-CCD or sCMOS.\nTwo-photon microscopy.\nA two-photon microscope is also a laser-scanning microscope, but instead of UV, blue or green laser light, a pulsed infrared laser is used for excitation. Only in the tiny focus of the laser is the intensity high enough to generate fluorescence by two-photon excitation, which means that no out-of-focus fluorescence is generated, and no pinhole is necessary to clean up the image. This allows imaging deep in scattering tissue, where a confocal microscope would not be able to collect photons efficiently. Two-photon microscopes with wide-field detection are frequently used for functional imaging, e.g. calcium imaging, in brain tissue. They are marketed as Multiphoton microscopes by several companies, although the gains of using 3-photon instead of 2-photon excitation are marginal.\nSingle plane illumination microscopy and light sheet fluorescence microscopy.\nUsing a plane of light formed by focusing light through a cylindrical lens at a narrow angle or by scanning a line of light in a plane perpendicular to the axis of objective, high resolution optical sections can be taken. Single plane illumination, or light sheet illumination, is also accomplished using beam shaping techniques incorporating multiple-prism beam expanders. The images are captured by CCDs. These variants allow very fast and high signal to noise ratio image capture.\nWide-field multiphoton microscopy.\nWide-field multiphoton microscopy refers to an optical non-linear imaging technique in which a large area of the object is illuminated and imaged without the need for scanning. High intensities are required to induce non-linear optical processes such as two-photon fluorescence or second harmonic generation. In scanning multiphoton microscopes the high intensities are achieved by tightly focusing the light, and the image is obtained by beam scanning. In wide-field multiphoton microscopy the high intensities are best achieved using an optically amplified pulsed laser source to attain a large field of view (~100\u00a0\u03bcm). The image in this case is obtained as a single frame with a CCD camera without the need of scanning, making the technique particularly useful to visualize dynamic processes simultaneously across the object of interest. With wide-field multiphoton microscopy the frame rate can be increased up to a 1000-fold compared to multiphoton scanning microscopy. In scattering tissue, however, image quality rapidly degrades with increasing depth.\nDeconvolution.\nFluorescence microscopy is a powerful technique to show specifically labeled structures within a complex environment and to provide three-dimensional information of biological structures. However, this information is blurred by the fact that, upon illumination, all fluorescently labeled structures emit light, irrespective of whether they are in focus or not. So an image of a certain structure is always blurred by the contribution of light from structures that are out of focus. This phenomenon results in a loss of contrast especially when using objectives with a high resolving power, typically oil immersion objectives with a high numerical aperture.\nHowever, blurring is not caused by random processes, such as light scattering, but can be well defined by the optical properties of the image formation in the microscope imaging system. If one considers a small fluorescent light source (essentially a bright spot), light coming from this spot spreads out further from our perspective as the spot becomes more out of focus. Under ideal conditions, this produces an \"hourglass\" shape of this point source in the third (axial) dimension. This shape is called the point spread function (PSF) of the microscope imaging system. Since any fluorescence image is made up of a large number of such small fluorescent light sources, the image is said to be \"convolved by the point spread function\". The mathematically modeled PSF of a terahertz laser pulsed imaging system is shown on the right.\nThe output of an imaging system can be described using the equation:\nformula_1\nWhere n is the additive noise. Knowing this point spread function means that it is possible to reverse this process to a certain extent by computer-based methods commonly known as deconvolution microscopy. There are various algorithms available for 2D or 3D deconvolution. They can be roughly classified in \"nonrestorative\" and \"restorative\" methods. While the nonrestorative methods can improve contrast by removing out-of-focus light from focal planes, only the restorative methods can actually reassign light to its proper place of origin. Processing fluorescent images in this manner can be an advantage over directly acquiring images without out-of-focus light, such as images from confocal microscopy, because light signals otherwise eliminated become useful information. For 3D deconvolution, one typically provides a series of images taken from different focal planes (called a Z-stack) plus the knowledge of the PSF, which can be derived either experimentally or theoretically from knowing all contributing parameters of the microscope.\nSub-diffraction techniques.\nA multitude of super-resolution microscopy techniques have been developed in recent times which circumvent the diffraction limit.\nThis is mostly achieved by imaging a sufficiently static sample multiple times and either modifying the excitation light or observing stochastic changes in the image. The deconvolution methods described in the previous section, which removes the PSF induced blur and assigns a mathematically 'correct' origin of light, are used, albeit with slightly different understanding of what the value of a pixel mean. Assuming \"most of the time\", one single fluorophore contributes to one single blob on one single taken image, the blobs in the images can be replaced with their calculated position, vastly improving resolution to well below the diffraction limit.\nTo realize such assumption, Knowledge of and chemical control over fluorophore photophysics is at the core of these techniques, by which resolutions of ~20 nanometers are obtained.\nSerial time-encoded amplified microscopy.\nSerial time encoded amplified microscopy (STEAM) is an imaging method that provides ultrafast shutter speed and frame rate, by using optical image amplification to circumvent the fundamental trade-off between sensitivity and speed, and a single-pixel photodetector to eliminate the need for a detector array and readout time limitations The method is at least 1000 times faster than the state-of-the-art CCD and CMOS cameras. Consequently, it is potentially useful for scientific, industrial, and biomedical applications that require high image acquisition rates, including real-time diagnosis and evaluation of shockwaves, microfluidics, MEMS, and laser surgery.\nExtensions.\nMost modern instruments provide simple solutions for micro-photography and image recording electronically. However such capabilities are not always present and the more experienced microscopist may prefer a hand drawn image to a photograph. This is because a microscopist with knowledge of the subject can accurately convert a three-dimensional image into a precise two-dimensional drawing. In a photograph or other image capture system however, only one thin plane is ever in good focus.\nThe creation of accurate micrographs requires a microscopical technique using a monocular eyepiece. It is essential that both eyes are open and that the eye that is not observing down the microscope is instead concentrated on a sheet of paper on the bench besides the microscope. With practice, and without moving the head or eyes, it is possible to accurately trace the observed shapes by simultaneously \"seeing\" the pencil point in the microscopical image.\nOther enhancements.\nMicrospectroscopy:spectroscopy with a microscope\nX-ray.\nAs resolution depends on the wavelength of the light. Electron microscopy has been developed since the 1930s that use electron beams instead of light. Because of the much smaller wavelength of the electron beam, resolution is far higher.\nThough less common, X-ray microscopy has also been developed since the late 1940s. The resolution of X-ray microscopy lies between that of light microscopy and electron microscopy.\nElectron microscopy.\nUntil the invention of sub-diffraction microscopy, the wavelength of the light limited the resolution of traditional microscopy to around 0.2 micrometers. In order to gain higher resolution, the use of an electron beam with a far smaller wavelength is used in electron microscopes.\nElectron microscopes equipped for X-ray spectroscopy can provide qualitative and quantitative elemental analysis. This type of electron microscope, also known as analytical electron microscope, can be a very powerful tool for investigation of nanomaterials.\nScanning probe microscopy.\nThis is a sub-diffraction technique. Examples of scanning probe microscopes are the atomic force microscope (AFM), the scanning tunneling microscope, the photonic force microscope and the recurrence tracking microscope. All such methods use the physical contact of a solid probe tip to scan the surface of an object, which is supposed to be almost flat.\nUltrasonic force.\nUltrasonic force microscopy (UFM) has been developed in order to improve the details and image contrast on \"flat\" areas of interest where AFM images are limited in contrast. The combination of AFM-UFM allows a near field acoustic microscopic image to be generated. The AFM tip is used to detect the ultrasonic waves and overcomes the limitation of wavelength that occurs in acoustic microscopy. By using the elastic changes under the AFM tip, an image of much greater detail than the AFM topography can be generated.\nUltrasonic force microscopy allows the local mapping of elasticity in atomic force microscopy by the application of ultrasonic vibration to the cantilever or sample. To analyze the results of ultrasonic force microscopy in a quantitative fashion, a force-distance curve measurement is done with ultrasonic vibration applied to the cantilever base, and the results are compared with a model of the cantilever dynamics and tip-sample interaction based on the finite-difference technique.\nUltraviolet microscopy.\nUltraviolet microscopes have two main purposes. The first is to use the shorter wavelength of ultraviolet electromagnetic energy to improve the image resolution beyond that of the diffraction limit of standard optical microscopes. This technique is used for non-destructive inspection of devices with very small features such as those found in modern semiconductors. The second application for UV microscopes is contrast enhancement where the response of individual samples is enhanced, relative to their surrounding, due to the interaction of light with the molecules within the sample itself. One example is in the growth of protein crystals. Protein crystals are formed in salt solutions. As salt and protein crystals are both formed in the growth process, and both are commonly transparent to the human eye, they cannot be differentiated with a standard optical microscope. As the tryptophan of protein absorbs light at 280\u00a0nm, imaging with a UV microscope with 280\u00a0nm bandpass filters makes it simple to differentiate between the two types of crystals. The protein crystals appear dark while the salt crystals are transparent.\nInfrared microscopy.\nThe term \"infrared microscopy\" refers to microscopy performed at infrared wavelengths. In the typical instrument configuration, a Fourier Transform Infrared Spectrometer (FTIR) is combined with an optical microscope and an infrared detector. The infrared detector can be a single point detector, a linear array or a 2D focal plane array. FTIR provides the ability to perform chemical analysis via infrared spectroscopy and the microscope and point or array detector enable this chemical analysis to be spatially resolved, i.e. performed at different regions of the sample. As such, the technique is also called infrared microspectroscopy\nAn alternative architecture called Laser Direct Infrared (LDIR) Imaging involves the combination of a tuneable infrared light source and single point detector on a flying objective. This technique is frequently used for infrared chemical imaging, where the image contrast is determined by the response of individual sample regions to particular IR wavelengths selected by the user, usually specific IR absorption bands and associated molecular resonances. A key limitation of conventional infrared microspectroscopy is that the spatial resolution is diffraction-limited. Specifically the spatial resolution is limited to a figure related to the wavelength of the light. For practical IR microscopes, the spatial resolution is limited to 1\u20133x the wavelength, depending on the specific technique and instrument used. For mid-IR wavelengths, this sets a practical spatial resolution limit of ~3-30 \u03bcm.\nIR versions of sub-diffraction microscopy also exist. These include IR Near-field scanning optical microscope (NSOM), photothermal microspectroscopy and atomic force microscope based infrared spectroscopy (AFM-IR), as well as scattering-type Scanning Near-field Optical Microscopy (s-SNOM) &amp; nano-FTIR that provide nanoscale spatial resolution at IR wavelengths.\nDigital holographic microscopy.\nIn digital holographic microscopy (DHM), interfering wave fronts from a coherent (monochromatic) light-source are recorded on a sensor. The image is digitally reconstructed by a computer from the recorded hologram. Besides the ordinary bright field image, a phase shift image is created.\nDHM can operate both in reflection and transmission mode. In reflection mode, the phase shift image provides a relative distance measurement and thus represents a topography map of the reflecting surface. In transmission mode, the phase shift image provides a label-free quantitative measurement of the optical thickness of the specimen. Phase shift images of biological cells are very similar to images of stained cells and have successfully been analyzed by high content analysis software.\nA unique feature of DHM is the ability to adjust focus after the image is recorded, since all focus planes are recorded simultaneously by the hologram. This feature makes it possible to image moving particles in a volume or to rapidly scan a surface. Another attractive feature is The ability of DHM to use low cost optics by correcting optical aberrations by software.\nDigital pathology (virtual microscopy).\nDigital pathology is an image-based information environment enabled by computer technology that allows for the management of information generated from a digital slide. Digital pathology is enabled in part by virtual microscopy, which is the practice of converting glass slides into digital slides that can be viewed, managed, and analyzed.\nLaser microscopy.\nLaser microscopy is a rapidly growing field that uses laser illumination sources in various forms of microscopy. For instance, laser microscopy focused on biological applications uses ultrashort pulse lasers, in a number of techniques labeled as nonlinear microscopy, saturation microscopy, and two-photon excitation microscopy.\nHigh-intensity, short-pulse laboratory x-ray lasers have been under development for several years. When this technology comes to fruition, it will be possible to obtain magnified three-dimensional images of elementary biological structures in the living state at a precisely defined instant. For optimum contrast between water and protein and for best sensitivity and resolution, the laser should be tuned near the nitrogen line at about 0.3 nanometers. Resolution will be limited mainly by the hydrodynamic expansion that occurs while the necessary number of photons is being registered. Thus, while the specimen is destroyed by the exposure, its configuration can be captured before it explodes.\nScientists have been working on practical designs and prototypes for x-ray holographic microscopes, despite the prolonged development of the appropriate laser.\nPhotoacoustic microscopy.\nA microscopy technique relying on the photoacoustic effect, i.e. the generation of (ultra)sound caused by light absorption.\nA focused and intensity modulated laser beam is raster scanned over a sample. The generated (ultra)sound is detected via an ultrasound transducer. Commonly piezoelectric ultrasound transducers are employed.\nThe image contrast is related to the sample's absorption coefficient formula_2. This is in contrast to bright or dark field microscopy, where the image contrast is due to transmittance or scattering. In principle, the contrast of fluorescence microscopy is proportional to the sample's absorption too. However, in fluorescence microscopy the fluorescence quantum yield formula_3 needs to be unequal to zero in order that a signal can be detected. In photoacoustic microscopy, however, every absorbing substance gives a photoacoustic signal formula_4 which is proportional to\nformula_5\nHere formula_6 is the Gr\u00fcneisen coefficient, formula_7 is the laser's photon energy and formula_8 is the sample's band gap energy. Therefore, photoacoustic microscopy seems well suited as a complementary technique to fluorescence microscopy, as a high fluorescence quantum yield leads to high fluorescence signals and a low fluorescence quantum yield leads to high photoacoustic signals.\nNeglecting non-linear effects, the lateral resolution dx is limited by the Abbe diffraction limit:\nformula_9\nwhere formula_10 is the wavelength of the excitation laser and NA is the numerical aperture of the objective lens. The Abbe diffraction limit holds if the incoming wave front is parallel. In reality, however, the laser beam profile is Gaussian. Therefore, in order to the calculate the achievable resolution, formulas for truncated Gaussian beams have to be used.\nAmateur microscopy.\n\"Amateur Microscopy\" is the investigation and observation of biological and non-biological specimens for recreational purposes. Collectors of minerals, insects, seashells, and plants may use microscopes as tools to uncover features that help them classify their collected items. Other amateurs may be interested in observing the life found in pond water and of other samples. Microscopes may also prove useful for the water quality assessment for people that keep a home aquarium. Photographic documentation and drawing of the microscopic images are additional pleasures. There are competitions for photomicrograph art. Participants of this pastime may use commercially prepared microscopic slides or prepare their own slides.\nWhile microscopy is a central tool in the documentation of biological specimens, it is often insufficient to justify the description of a new species based on microscopic investigations alone. Often genetic and biochemical tests are necessary to confirm the discovery of a new species. A laboratory and access to academic literature is a necessity. There is, however, one advantage that amateurs have above professionals: time to explore their surroundings. Often, advanced amateurs team up with professionals to validate their findings and possibly describe new species.\nIn the late 1800s, amateur microscopy became a popular hobby in the United States and Europe. Several 'professional amateurs' were being paid for their sampling trips and microscopic explorations by philanthropists, to keep them amused on the Sunday afternoon (e.g., the diatom specialist A. Grunow, being paid by (among others) a Belgian industrialist). Professor John Phin published \"Practical Hints on the Selection and Use of the Microscope (Second Edition, 1878),\" and was also the editor of the \"American Journal of Microscopy.\"\nExamples of amateur microscopy images:\nApplication in forensic science.\nMicroscopy has applications in the forensic sciences. The microscope can detect, resolve and image the smallest items of evidence, often without any alteration or destruction. The microscope is used to identify and compare fibers, hairs, soils, and dust...etc.\nIn ink markings, blood stains or bullets, no specimen treatment is required and the evidence shows directly from microscopical examination. For traces of particular matter, the sample preparation must be done before microscopical examination occurs.\nLight microscopes are the most use in forensics, using photons to form images, microscopes which are most applicable for examining forensic specimens are as follows:\n1. The compound microscope\n2. The comparison microscope\n3. The stereoscopic microscope\n4. The polarizing microscope\n5. The micro spectrophotometer\nThis diversity of the types of microscopes in forensic applications comes mainly from their magnification ranges, which are (1- 1200X), (50 -30,000X) and (500- 250,000X) for the optical microscopy, SEM and TEM respectively.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "19568", "revid": "7903804", "url": "https://en.wikipedia.org/wiki?curid=19568", "title": "Microscope", "text": "Scientific instrument\nA microscope (from grc \" ' ()\"\u00a0'small' and \" ' ()\"\u00a0'to look (at); examine, inspect') is a laboratory instrument used to examine objects that are too small to be seen by the naked eye. Microscopy is the science of investigating small objects and structures using a microscope. Microscopic means being invisible to the eye unless aided by a microscope.\nThere are many types of microscopes, and they may be grouped in different ways. One way is to describe the method an instrument uses to interact with a sample and produce images, either by sending a beam of light or electrons through a sample in its optical path, by detecting photon emissions from a sample, or by scanning across and a short distance from the surface of a sample using a probe. The most common microscope (and the first to be invented) is the optical microscope, which uses lenses to refract visible light that passed through a thinly sectioned sample to produce an observable image. Other major types of microscopes are the fluorescence microscope, electron microscope (both the transmission electron microscope and the scanning electron microscope) and various types of scanning probe microscopes.\nHistory.\nAlthough objects resembling lenses date back 4,000 years and there are Greek accounts of the optical properties of water-filled spheres (5th century BC) followed by many centuries of writings on optics, the earliest known use of simple microscopes (magnifying glasses) dates back to the widespread use of lenses in eyeglasses in the 13th century. The earliest known examples of compound microscopes, which combine an objective lens near the specimen with an eyepiece to view a real image, appeared in Europe around 1620. The inventor is unknown, even though many claims have been made over the years. Several revolve around the spectacle-making centers in the Netherlands, including claims it was invented in 1590 by Zacharias Janssen (claim made by his son) or Zacharias' father, Hans Martens, or both, claims it was invented by their neighbor and rival spectacle maker, Hans Lippershey (who applied for the first telescope patent in 1608), and claims it was invented by expatriate Cornelis Drebbel, who was noted to have a version in London in 1619. Galileo Galilei (also sometimes cited as compound microscope inventor) seems to have found after 1610 that he could close focus his telescope to view small objects and, after seeing a compound microscope built by Drebbel exhibited in Rome in 1624, built his own improved version. Giovanni Faber coined the name \"microscope\" for the compound microscope Galileo submitted to the in 1625 (Galileo had called it the \"occhiolino\" 'little eye'). Ren\u00e9 Descartes (\"Dioptrique\", 1637) describes microscopes wherein a concave mirror, with its concavity towards the object, is used, in conjunction with a lens, for illuminating the object, which is mounted on a point fixing it at the focus of the mirror.\nRise of modern light microscopes.\nThe first detailed account of the microscopic anatomy of organic tissue based on the use of a microscope did not appear until 1644, in Giambattista Odierna's \"L'occhio della mosca\", or \"The Fly's Eye\".\nThe microscope was still largely a novelty until the 1660s and 1670s when naturalists in Italy, the Netherlands and England began using them to study biology. Italian scientist Marcello Malpighi, called the father of histology by some historians of biology, began his analysis of biological structures with the lungs. The publication in 1665 of Robert Hooke's \"Micrographia\" had a huge impact, largely because of its impressive illustrations. Hooke created tiny lenses of small glass globules made by fusing the ends of threads of spun glass. A significant contribution came from Antonie van Leeuwenhoek who achieved up to 300 times magnification using a simple single lens microscope. He sandwiched a very small glass ball lens between the holes in two metal plates riveted together, and with an adjustable-by-screws needle attached to mount the specimen. Then, Van Leeuwenhoek re-discovered red blood cells (after Jan Swammerdam) and spermatozoa, and helped popularise the use of microscopes to view biological ultrastructure. On 9 October 1676, van Leeuwenhoek reported the discovery of micro-organisms.\nThe performance of a compound light microscope depends on the quality and correct use of the condensor lens system to focus light on the specimen and the objective lens to capture the light from the specimen and form an image. Early instruments were limited until this principle was fully appreciated and developed from the late 19th to very early 20th century, and until electric lamps were available as light sources. In 1893 August K\u00f6hler developed a key principle of sample illumination, K\u00f6hler illumination, which is central to achieving the theoretical limits of resolution for the light microscope. This method of sample illumination produces even lighting and overcomes the limited contrast and resolution imposed by early techniques of sample illumination. Further developments in sample illumination came from the discovery of phase contrast by Frits Zernike in 1953, and differential interference contrast illumination by Georges Nomarski in 1955; both of which allow imaging of unstained, transparent samples.\nElectron microscopes.\nIn the early 20th century a significant alternative to the light microscope was developed, an instrument that uses a beam of electrons rather than light to generate an image. The German physicist, Ernst Ruska, working with electrical engineer Max Knoll, developed the first prototype electron microscope in 1931, a transmission electron microscope (TEM). The transmission electron microscope works on similar principles to an optical microscope but uses electrons in the place of light and electromagnets in the place of glass lenses. Use of electrons, instead of light, allows for much higher resolution.\nDevelopment of the transmission electron microscope was quickly followed in 1935 by the development of the scanning electron microscope by Max Knoll. Although TEMs were being used for research before WWII, and became popular afterwards, the SEM was not commercially available until 1965.\nTransmission electron microscopes became popular following the Second World War. Ernst Ruska, working at Siemens, developed the first commercial transmission electron microscope and, in the 1950s, major scientific conferences on electron microscopy started being held. In 1965, the first commercial scanning electron microscope was developed by Professor Sir Charles Oatley and his postgraduate student Gary Stewart, and marketed by the Cambridge Instrument Company as the \"Stereoscan\".\nOne of the latest discoveries made about using an electron microscope is the ability to identify a virus. Since this microscope produces a visible, clear image of small organelles, in an electron microscope there is no need for reagents to see the virus or harmful cells, resulting in a more efficient way to detect pathogens.\nScanning probe microscopes.\nFrom 1981 to 1983 Gerd Binnig and Heinrich Rohrer worked at IBM in Z\u00fcrich, Switzerland to study the quantum tunnelling phenomenon. They created a practical instrument, a scanning probe microscope from quantum tunnelling theory, that read very small forces exchanged between a probe and the surface of a sample. The probe approaches the surface so closely that electrons can flow continuously between probe and sample, making a current from surface to probe. The microscope was not initially well received due to the complex nature of the underlying theoretical explanations. In 1984 Jerry Tersoff and D.R. Hamann, while at AT&amp;T's Bell Laboratories in Murray Hill, New Jersey began publishing articles that tied theory to the experimental results obtained by the instrument. This was closely followed in 1985 with functioning commercial instruments, and in 1986 with Gerd Binnig, Quate, and Gerber's invention of the atomic force microscope, then Binnig's and Rohrer's Nobel Prize in Physics for the SPM.\nNew types of scanning probe microscope have continued to be developed as the ability to machine ultra-fine probes and tips has advanced.\nFluorescence microscopes.\nThe most recent developments in light microscope largely centre on the rise of fluorescence microscopy in biology. During the last decades of the 20th century, particularly in the post-genomic era, many techniques for fluorescent staining of cellular structures were developed. The main groups of techniques involve targeted chemical staining of particular cell structures, for example, the chemical compound DAPI to label DNA, use of antibodies conjugated to fluorescent reporters, see\nimmunofluorescence, and fluorescent proteins, such as green fluorescent protein. These techniques use these different fluorophores for analysis of cell structure at a molecular level in both live and fixed samples.\nThe rise of fluorescence microscopy drove the development of a major modern microscope design, the confocal microscope. The principle was patented in 1957 by Marvin Minsky, although laser technology limited practical application of the technique. It was not until 1978 when Thomas and Christoph Cremer developed the first practical confocal laser scanning microscope and the technique rapidly gained popularity through the 1980s.\nSuper resolution microscopes.\nMuch current research (in the early 21st century) on optical microscope techniques is focused on development of superresolution analysis of fluorescently labelled samples. Structured illumination can improve resolution by around two to four times and techniques like stimulated emission depletion (STED) microscopy are approaching the resolution of electron microscopes. This occurs because the diffraction limit is occurred from light or excitation, which makes the resolution must be doubled to become super saturated. Stefan Hell was awarded the 2014 Nobel Prize in Chemistry for the development of the STED technique, along with Eric Betzig and William Moerner who adapted fluorescence microscopy for single-molecule visualization.\nX-ray microscopes.\nX-ray microscopes are instruments that use electromagnetic radiation usually in the soft X-ray band to image objects. Technological advances in X-ray lens optics in the early 1970s made the instrument a viable imaging choice. They are often used in tomography (see micro-computed tomography) to produce three dimensional images of objects, including biological materials that have not been chemically fixed. Currently research is being done to improve optics for hard X-rays which have greater penetrating power.\nTypes.\nMicroscopes can be separated into several different classes. One grouping is based on what interacts with the sample to generate the image, i.e., light or photons (optical microscopes), electrons (electron microscopes) or a probe (scanning probe microscopes). Alternatively, microscopes can be classified based on whether they analyze the sample via a scanning point (confocal optical microscopes, scanning electron microscopes and scanning probe microscopes) or analyze the sample all at once (wide field optical microscopes and transmission electron microscopes).\nWide field optical microscopes and transmission electron microscopes both use the theory of lenses (optics for light microscopes and electromagnet lenses for electron microscopes) in order to magnify the image generated by the passage of a wave transmitted through the sample, or reflected by the sample. The waves used are electromagnetic (in optical microscopes) or electron beams (in electron microscopes). Resolution in these microscopes is limited by the wavelength of the radiation used to image the sample, where shorter wavelengths allow for a higher resolution.\nScanning optical and electron microscopes, like the confocal microscope and scanning electron microscope, use lenses to focus a spot of light or electrons onto the sample then analyze the signals generated by the beam interacting with the sample. The point is then scanned over the sample to analyze a rectangular region. Magnification of the image is achieved by displaying the data from scanning a physically small sample area on a relatively large screen. These microscopes have the same resolution limit as wide field optical, probe, and electron microscopes.\nScanning probe microscopes also analyze a single point in the sample and then scan the probe over a rectangular sample region to build up an image. As these microscopes do not use electromagnetic or electron radiation for imaging they are not subject to the same resolution limit as the optical and electron microscopes described above.\nOptical microscope.\nThe most common type of microscope (and the first invented) is the optical microscope. This is an optical instrument containing one or more lenses producing an enlarged image of a sample placed in the focal plane. Optical microscopes have refractive glass (occasionally plastic or quartz), to focus light on the eye or on to another light detector. Mirror-based optical microscopes operate in the same manner. Typical magnification of a light microscope, assuming visible range light, is up to 1,250\u00d7 with a theoretical resolution limit of around 0.250\u00a0micrometres or 250\u00a0nanometres. This limits practical magnification to ~1,500\u00d7. Specialized techniques (e.g., scanning confocal microscopy, Vertico SMI) may exceed this magnification but the resolution is diffraction limited. The use of shorter wavelengths of light, such as ultraviolet, is one way to improve the spatial resolution of the optical microscope, as are devices such as the near-field scanning optical microscope.\nSarfus is a recent optical technique that increases the sensitivity of a standard optical microscope to a point where it is possible to directly visualize nanometric films (down to 0.3\u00a0nanometre) and isolated nano-objects (down to 2\u00a0nm-diameter). The technique is based on the use of non-reflecting substrates for cross-polarized reflected light microscopy.\nUltraviolet light enables the resolution of microscopic features as well as the imaging of samples that are transparent to the eye. Near infrared light can be used to visualize circuitry embedded in bonded silicon devices, since silicon is transparent in this region of wavelengths.\nIn fluorescence microscopy many wavelengths of light ranging from the ultraviolet to the visible can be used to cause samples to fluoresce, which allows viewing by eye or with specifically sensitive cameras.\nPhase-contrast microscopy is an optical microscopic illumination technique in which small phase shifts in the light passing through a transparent specimen are converted into amplitude or contrast changes in the image. The use of phase contrast does not require staining to view the slide. This microscope technique made it possible to study the cell cycle in live cells.\nThe traditional optical microscope has more recently evolved into the digital microscope. In addition to, or instead of, directly viewing the object through the eyepieces, a type of sensor similar to those used in a digital camera is used to obtain an image, which is then displayed on a computer monitor. These sensors may use CMOS or charge-coupled device (CCD) technology, depending on the application.\nDigital microscopy with very low light levels to avoid damage to vulnerable biological samples is available using sensitive photon-counting digital cameras. It has been demonstrated that a light source providing pairs of entangled photons may minimize the risk of damage to the most light-sensitive samples. In this application of ghost imaging to photon-sparse microscopy, the sample is illuminated with infrared photons, each of which is spatially correlated with an entangled partner in the visible band for efficient imaging by a photon-counting camera.\nElectron microscope.\nThe two major types of electron microscopes are transmission electron microscopes (TEMs) and scanning electron microscopes (SEMs). They both have series of electromagnetic and electrostatic lenses to focus a high energy beam of electrons on a sample. In a TEM the electrons pass through the sample, analogous to basic optical microscopy. This requires careful sample preparation, since electrons are scattered strongly by most materials. The samples must also be very thin (below 100\u00a0nm) in order for the electrons to pass through it. Cross-sections of cells stained with osmium and heavy metals reveal clear organelle membranes and proteins such as ribosomes. With a 0.1\u00a0nm level of resolution, detailed views of viruses (20 \u2013 300\u00a0nm) and a strand of DNA (2\u00a0nm in width) can be obtained. In contrast, the SEM has raster coils to scan the surface of bulk objects with a fine electron beam. Therefore, the specimen do not necessarily need to be sectioned, but coating with a nanometric metal or carbon layer may be needed for nonconductive samples. SEM allows fast surface imaging of samples, possibly in thin water vapor to prevent drying.\nScanning probe.\nThe different types of scanning probe microscopes arise from the many different types of interactions that occur when a small probe is scanned over and interacts with a specimen. These interactions or modes can be recorded or mapped as function of location on the surface to form a characterization map. The three most common types of scanning probe microscopes are atomic force microscopes (AFM), near-field scanning optical microscopes (NSOM or SNOM, scanning near-field optical microscopy), and scanning tunneling microscopes (STM). An atomic force microscope has a fine probe, usually of silicon or silicon nitride, attached to a cantilever; the probe is scanned over the surface of the sample, and the forces that cause an interaction between the probe and the surface of the sample are measured and mapped. A near-field scanning optical microscope is similar to an AFM but its probe consists of a light source in an optical fiber covered with a tip that has usually an aperture for the light to pass through. The microscope can capture either transmitted or reflected light to measure very localized optical properties of the surface, commonly of a biological specimen. Scanning tunneling microscopes have a metal tip with a single apical atom; the tip is attached to a tube through which a current flows. The tip is scanned over the surface of a conductive sample until a tunneling current flows; the current is kept constant by computer movement of the tip and an image is formed by the recorded movements of the tip.\nOther types.\nScanning acoustic microscopes use sound waves to measure variations in acoustic impedance. Similar to Sonar in principle, they are used for such jobs as detecting defects in the subsurfaces of materials including those found in integrated circuits. On February 4, 2013, Australian engineers built a \"quantum microscope\" which provides unparalleled precision.\nMobile apps.\nMobile app microscopes can optionally be used as optical microscope when the flashlight is activated. However, mobile app microscopes are harder to use due to visual noise, are often limited to 40x, and the resolution limits of the camera lens itself.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "19570", "revid": "32978398", "url": "https://en.wikipedia.org/wiki?curid=19570", "title": "Midrash", "text": "Traditional Jewish exegesis of Biblical texts\nMidrash (; ; pl. or &lt;templatestyles src=\"Script/styles_hebrew.css\" /&gt;\u05de\u05b4\u05d3\u05b0\u05e8\u05b8\u05e9\u05c1\u05d5\u05b9\u05ea\u200e \"midrashot\") is an expansive Jewish Biblical exegesis using a rabbinic mode of interpretation prominent in the Talmud. The word itself means \"textual interpretation\", \"study\", or \"exegesis\", derived from the root verb (), which means \"resort to, seek, seek with care, enquire, require\".\nMidrash and rabbinic readings \"discern value in texts, words, and letters, as potential revelatory spaces\", writes the Hebrew scholar Wilda Gafney. \"They reimagine dominant narratival readings while crafting new ones to stand alongside\u2014not replace\u2014former readings. Midrash also asks questions of the text; sometimes it provides answers, sometimes it leaves the reader to answer the questions\". Vanessa Lovelace defines midrash as \"a Jewish mode of interpretation that not only engages the words of the text, behind the text, and beyond the text, but also focuses on each letter, and the words left unsaid by each line\".\nAn example of a midrashic interpretation:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\"And God saw all that He had made, and found it very good. And there was evening, and there was morning, the sixth day.\" (Genesis 1:31)\u2014Midrash: \"Rabbi Nahman said in Rabbi Samuel's name: \"Behold, it was very good\" refers to the Good Desire; \"AND behold, it was very good\" refers to the Evil Desire. Can then the Evil Desire be very good? That would be extraordinary! But without the Evil Desire, however, no man would build a house, take a wife and beget children; and thus said Solomon: \"Again, I considered all labour and all excelling in work, that it is a man's rivalry with his neighbour.\" (Kohelet IV, 4)\".\nThe term Midrash is also used of a rabbinic work that interprets Scripture in that manner. Such works contain early interpretations and commentaries on the Written Torah and Oral Torah (spoken law and sermons), as well as non-legalistic rabbinic literature () and occasionally Jewish religious laws (), which usually form a running commentary on specific passages in the Hebrew Scripture (Tanakh).\nThe word \"Midrash\", especially if capitalized, can refer to a specific compilation of these rabbinic writings composed between 400 and 1200 CE. According to Gary Porton and Jacob Neusner, \"midrash\" has three technical meanings:\nEtymology.\nThe Hebrew word \"midrash\" is derived from the root of the verb (), which means \"resort to, seek, seek with care, enquire, require\", forms of which appear frequently in the Bible.\nThe word \"midrash\" occurs twice in the Hebrew Bible: 2 Chronicles 13:22 \"in the \"midrash\" of the prophet Iddo\", and 24:27 \"in the \"midrash\" of the book of the kings\". Both the King James Version (KJV) and English Standard Version (ESV) translate the word as \"story\" in both instances; the Septuagint translates it as (book) in the first, as (writing) in the second. The meaning of the Hebrew word in these contexts is uncertain: it has been interpreted as referring to \"a body of authoritative narratives, or interpretations thereof, concerning historically important figures\" and seems to refer to a \"book\", perhaps even a \"book of interpretation\", which might make its use a foreshadowing of the technical sense that the rabbis later gave to the word.\nSince the early Middle Ages the function of much of midrashic interpretation has been distinguished from that of , straight or direct interpretation aiming at the original literal meaning of a scriptural text.\nAs a genre.\nA definition of \"midrash\" repeatedly quoted by other scholars is that given by Gary G. Porton in 1981: \"a type of literature, oral or written, which stands in direct relationship to a fixed, canonical text, considered to be the authoritative and revealed word of God by the midrashist and his audience, and in which this canonical text is explicitly cited or clearly alluded to\".\nLieve M. Teugels, who would limit midrash to rabbinic literature, offered a definition of midrash as \"rabbinic interpretation of Scripture that bears the lemmatic form\", a definition that, unlike Porton's, has not been adopted by others. While some scholars agree with the limitation of the term \"midrash\" to rabbinic writings, others apply it also to certain Qumran writings, to parts of the New Testament, and of the Hebrew Bible (in particular the superscriptions of the Psalms, Deuteronomy, and Chronicles), and even modern compositions are called midrashim.\nAs method.\nMidrash is now viewed more as method than genre, although the rabbinic midrashim do constitute a distinct literary genre. According to the \"Encyclopaedia Britannica\", \"Midrash was initially a philological method of interpreting the literal meaning of biblical texts. In time it developed into a sophisticated interpretive system that reconciled apparent biblical contradictions, established the scriptural basis of new laws, and enriched biblical content with new meaning. Midrashic creativity reached its peak in the schools of Rabbi Ishmael and Akiba, where two different hermeneutic methods were applied. The first was primarily logically oriented, making inferences based upon similarity of content and analogy. The second rested largely upon textual scrutiny, assuming that words and letters that seem superfluous teach something not openly stated in the text.\"\nMany different exegetical methods are employed to derive deeper meaning from a text. This is not limited to the traditional thirteen textual tools attributed to the Tanna Rabbi Ishmael, which are used in the interpretation of (Jewish law). The presence of words or letters which are seen to be apparently superfluous, and the chronology of events, parallel narratives or what are seen as other textual \"anomalies\" are often used as a springboard for interpretation of segments of Biblical text. In many cases, a handful of lines in the Biblical narrative may become a long philosophical discussion.\nJacob Neusner distinguishes three midrash processes:\nJewish midrashic literature.\nNumerous Jewish midrashim previously preserved in manuscript form have been published in print, including those denominated as smaller or minor midrashim. Bernard H. Mehlman and Seth M. Limmer deprecate this usage, claiming that the term \"minor\" seems judgmental and \"small\" is inappropriate for midrashim, some of which are lengthy. They propose the term \"medieval midrashim\" instead, since the period of their production extended from the twilight of the rabbinic age to the dawn of the Age of Enlightenment.\nGenerally speaking, rabbinic midrashim either focuses on religious law and practice () or interprets the biblical narrative in relation to non-legal ethics or theology, creating homilies and parables based on the text. In the latter case, they are described as .\nHalakhic midrashim.\n\"Midrash halakha\" is the name given to a group of tannaitic expositions on the first five books of the Hebrew Bible. These midrashim, written in Mishnaic Hebrew, clearly distinguish between the Biblical texts that they discuss and the rabbinic interpretation of that text. They often go beyond simple interpretation and derive or support halakha. This work is based on pre-set assumptions about the sacred and divine nature of the text and the belief in the legitimacy that accords with rabbinic interpretation.\nAlthough this material treats the biblical texts as the authoritative word of God, it is clear that not all of the Hebrew Bible was fixed in its wording at this time, as some verses that are cited differ from the Masoretic, and accord with the Septuagint or Samaritan Torah instead.\nOrigins.\nWith the growing canonization of the contents of the Hebrew Bible, both in terms of the books that it contained and the version of the text in them and an acceptance that new texts could not be added, there came a need to produce material that would clearly differentiate between that text and rabbinic interpretation of it. By collecting and compiling these thoughts, they could be presented in a manner that helped to refute claims that they were only human interpretations\u2014the argument being that, by presenting the various collections of different schools of thought, each of which relied upon close study of the text, the growing difference between early biblical law and its later rabbinic interpretation could be reconciled.\nAggadic midrashim.\nMidrashim that seek to explain the non-legal portions of the Hebrew Bible are sometimes referred to as or .\nAggadic discussions of the non-legal parts of scripture are characterized by a much greater freedom of exposition than the halakhic midrashim (midrashim on Jewish law). Aggadic expositors availed themselves of various techniques, including sayings of prominent rabbis. These aggadic explanations could be philosophical or mystical disquisitions concerning angels, demons, paradise, Hell, the messiah, Satan, feasts and fasts, parables, legends, satirical assaults on those who practice idolatry, etc.\nSome of these midrashim entail mystical teachings. The presentation is such that the midrash is a simple lesson to the uninitiated and a direct allusion, or analogy, to a mystical teaching for those educated in this area.\nContemporary Jewish midrash.\nA wealth of literature and artwork has been created in the 20th and 21st centuries by people aspiring to create \"contemporary midrash\". Forms include poetry, prose, Bibliodrama (the acting out of Bible stories), murals, masks, and music, among others. The Institute for Contemporary Midrash was formed to facilitate these reinterpretations of sacred texts. The institute hosted several week-long intensives between 1995 and 2004, and published eight issues of \"Living Text: The Journal of Contemporary Midrash\" from 1997 to 2000.\nContemporary views.\nAccording to Carol Bakhos, recent studies that use literary-critical tools to concentrate on the cultural and literary aspects of midrash have led to a rediscovery of the importance of these texts for finding insights into the rabbinic culture that created them. Midrash is increasingly seen as a literary and cultural construction, responsive to literary means of analysis.\nFrank Kermode has written that midrash is an imaginative way of \"updating, enhancing, augmenting, explaining, and justifying the sacred text\". Because the Tanakh came to be seen as unintelligible or even offensive, midrash could be used as a means of rewriting it in a way that both makes it more acceptable to later ethical standards and conforms more to later notions of plausibility.\nJames L. Kugel, in \"The Bible as It Was\" (Cambridge, Massachusetts: Harvard University Press, 1997), examines a number of early Jewish and Christian texts that comment on, expand, or re-interpret passages from the first five books of the Tanakh between the third century BCE and the second century CE.\nKugel traces how and why biblical interpreters produced new meanings by the use of exegesis on ambiguities, syntactical details, unusual or awkward vocabulary, repetitions, etc. in the text. As an example, Kugel examines the different ways in which the biblical story that God's instructions are not to be found in heaven (Deuteronomy 30:12) has been interpreted. Baruch 3:29-4:1 states that this means that divine wisdom is not available anywhere other than in the Torah. Targum Neophyti (Deuteronomy 30:12) and b. Baba Metzia 59b claim that this text means that Torah is no longer hidden away, but has been given to humans who are then responsible for following it.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "19571", "revid": "38001712", "url": "https://en.wikipedia.org/wiki?curid=19571", "title": "Missouri", "text": "U.S. state\nMissouri (\"see pronunciation\") is a landlocked state in the Midwestern region of the United States. Ranking 21st in land area, it borders Iowa to the north, Illinois, Kentucky and Tennessee to the east, Arkansas to the south and Oklahoma, Kansas, and Nebraska to the west. In the south are the Ozarks, a forested highland, providing timber, minerals, and recreation. At 1.5 billion years old, the St. Francois Mountains are among the oldest in the world. The Missouri River, after which the state is named, flows through the center and into the Mississippi River, which forms the eastern border. With over six million residents, it is the 19th-most populous state of the country. The largest urban areas are St. Louis, Kansas City, Springfield, and Columbia. The capital is Jefferson City.\nHumans have inhabited present-day Missouri for at least 12,000 years. The Mississippian culture, which emerged in the ninth century, built cities with pyramidal and other ceremonial mounds before declining in the 14th century. The Indigenous Osage and Missouria nations inhabited the area when European people arrived in the 17th century. The French incorporated the territory into Louisiana, founding Ste. Genevieve in 1735 and St. Louis in 1764. After a brief period of Spanish rule, the United States acquired Missouri as part of the Louisiana Purchase in 1803. Americans from the Upland South rushed into the new Missouri Territory, taking advantage of its productive agricultural plains; Missouri played a central role in the westward expansion of the United States. Missouri was admitted as a slave state as part of the Missouri Compromise of 1820. As a border state, Missouri's role in the American Civil War was complex, and it was subject to rival governments, raids, and guerilla warfare. After the war, both Greater St. Louis and the Kansas City metropolitan area became large centers of industrialization and business.\nToday the state is divided into 114 counties and the independent city of St. Louis. Missouri has been called the \"Gateway to the West\", the \"Mother of the West\", the \"Cave State\", and the \"Show Me State\". Its culture blends elements of the Midwestern and Southern United States. It is the birthplace of the musical genres ragtime, Kansas City jazz and St. Louis blues. The well-known Kansas City-style barbecue, and the lesser-known St. Louis-style barbecue, can be found across the state and beyond.\nMissouri is a major center of beer brewing and has some of the most permissive alcohol laws in the U.S. It is home to Anheuser-Busch, the world's largest beer producer, and produces Missouri wine, especially in the Missouri Rhineland. Outside the state's major cities, popular tourist destinations include the Lake of the Ozarks, Table Rock Lake and Branson. Some of the largest companies based in the state include Cerner, Express Scripts, Monsanto, Emerson Electric, Edward Jones, H&amp;R Block, Wells Fargo Advisors, Centene Corporation, and O'Reilly Auto Parts. Well-known universities in Missouri include the University of Missouri, Saint Louis University, and Washington University in St. Louis.\nEtymology and pronunciation.\nThe state is named for the Missouri River, which was named after the indigenous Missouria, a Siouan-language tribe. French colonists adapted a form of the Illinois language-name for the people: \"Wimihsoorita\". Their name means 'one who has dugout canoes'.\nThe name \"Missouri\" has several different pronunciations even among its present-day inhabitants, the two most common being and . Further pronunciations also exist in Missouri or elsewhere in the United States, involving the realization of the medial consonant as either or ; the vowel in the second syllable as either or ; and the third syllable as or . Any combination of these phonetic realizations may be observed coming from speakers of American English. In British Received Pronunciation, the preferred variant is , with being a possible alternative.\nDonald M. Lance, a professor of English at the University of Missouri, stated that no pronunciation could be declared correct, nor could any be clearly defined as native or outsider, rural or urban, southern or northern, educated or otherwise. Politicians often employ multiple pronunciations, even during a single speech, to appeal to a greater number of listeners. In informal contexts respellings of the state's name, such as \"Missour-\"ee\"\" or \"Missour-\"uh\"\", are occasionally used to distinguish pronunciations phonetically.\nNicknames.\nThere is no official state nickname. However, Missouri's unofficial nickname is the \"Show Me State\", which appears on its license plates. This phrase has several origins. One is popularly ascribed to a speech by Congressman Willard Vandiver in 1899, who declared that \"I come from a state that raises corn and cotton, cockleburs and Democrats, and frothy eloquence neither convinces nor satisfies me. I'm from Missouri, and you have got to show me.\" This is in keeping with the saying \"I'm from Missouri\", which means \"I'm skeptical of the matter and not easily convinced.\" However, according to researchers, the phrase \"show me\" was already in use before the 1890s. Another one states that it is a reference to Missouri miners who were taken to Leadville, Colorado, to replace striking workers. Since the new miners were unfamiliar with the mining methods, they required frequent instruction. Pit bosses began saying, \"That man is from Missouri. You'll have to show him.\"\nOther nicknames for Missouri include \"The Lead State\", \"The Bullion State\", \"The Ozark State\", \"The Mother of the West\", \"The Iron Mountain State\", and \"Pennsylvania of the West\". It is also known as the \"Cave State\" because there are more than 7,300 recorded caves in the state (second to Tennessee). Perry County is the county with the most caves and the single longest cave.\nThe official state motto is \"Salus Populi Suprema Lex Esto\", Latin for \"Let the welfare of the people be the supreme law.\"\nHistory.\nEarly history.\nArchaeological excavations along river valleys have shown continuous habitation since about 9000 BCE. Beginning before 1000 CE, the people of the Mississippian culture created regional political centers at present-day St. Louis and across the Mississippi River at Cahokia, near present-day Collinsville, Illinois. Their large cities included thousands of individual residences. Still, they are known for their surviving massive earthwork mounds, built for religious, political and social reasons, in platform, ridgetop and conical shapes. Cahokia was the center of a regional trading network that reached from the Great Lakes to the Gulf of Mexico. The civilization declined by 1400 CE, and most descendants left the area long before the arrival of Europeans. St. Louis was at one time known as Mound City by the European Americans because of the numerous surviving prehistoric mounds since lost to urban development. The Mississippian culture left mounds throughout the middle Mississippi and Ohio river valleys, extending into the southeast and the upper river.\nThe land that became the state of Missouri was part of numerous different territories, possessed changing and often indeterminate borders, and had many different Native American and European names between the 1600s and statehood. For much of the first half of the 1700s, the west bank of the Mississippi River that would become Missouri was mostly uninhabited, something of a no man's land that kept peace between the Illinois on the east bank of the Mississippi River and to the North, and the Osage and Missouri Indians of the lower Missouri Valley. In the early 1700s, French traders and missionaries explored the whole of the Mississippi Valley, and named the region \"Louisiana\". Around the same time, a different group of French Canadians established five villages on the east bank of the Mississippi River and identified their settlements as being in le pays des Illinois, \"the country of the Illinois\". When settlers of French Canadian descent began crossing the Mississippi River to establish settlements such as Ste. Genevieve, they continued to identify their settlements as being in the Illinois Country. At the same time, the French settlements on both sides of the Mississippi River were part of the French province of Louisiana. To distinguish the settlements in the Middle Mississippi Valley from French settlements in the lower Mississippi Valley around New Orleans, French officials and inhabitants referred to the Middle Mississippi Valley as La Haute Louisiane, \"The High Louisiana\", or \"Upper Louisiana\".\nThe first European settlers were mostly ethnic French Canadians, who created their first settlement in Missouri at present-day Ste. Genevieve, about south of St. Louis. They had migrated in about 1750 from the Illinois Country. They came from colonial villages on the east side of the Mississippi River, where soils were becoming exhausted and there was insufficient river bottom land for the growing population. The early Missouri settlements included many enslaved Africans and Native Americans, and slave labor was central to both commercial agriculture and the fur trade. Sainte-Genevi\u00e8ve became a thriving agricultural center, producing enough surplus wheat, corn and tobacco to ship tons of grain annually downriver to Lower Louisiana for trade. Grain production in the Illinois Country was critical to the survival of Lower Louisiana and especially the city of New Orleans.\nSt. Louis was founded on February 14, 1764, by French fur traders Gilbert Antoine de St. Maxent, Pierre Lacl\u00e8de, and Auguste Chouteau. From 1764 to 1803, European control of the area west of the Mississippi to the northernmost part of the Missouri River basin, called Louisiana, was assumed by the Spanish as part of the Viceroyalty of New Spain, due to Treaty of Fontainebleau (in order to have Spain join with France in the war against England). The arrival of the Spanish in St. Louis was in September 1767.\nSt. Louis became the center of a regional fur trade with Native American tribes that extended up the Missouri and Mississippi rivers, dominating the regional economy for decades. Trading partners of major firms shipped their furs from St. Louis by river down to New Orleans for export to Europe. They provided a variety of goods to traders for sale and trade with their Native American clients. The fur trade and associated businesses made St. Louis an early financial center and provided the wealth for some to build fine houses and import luxury items. Its location near the confluence of the Illinois River meant it also handled produce from the agricultural areas. River traffic and trade along the Mississippi were integral to the state's economy. As the area's first major city, St. Louis expanded greatly after the invention of the steamboat and the increased river trade.\n19th century.\nPart of the 1803 Louisiana Purchase by the United States, Missouri earned the nickname \"Gateway to the West\" because it served as a significant departure point for expeditions and settlers heading to the West during the 19th century. St. Charles, just west of St. Louis, was the starting point and the return destination of the Lewis and Clark Expedition, which ascended the Missouri River in 1804, to explore the western lands to the Pacific Ocean. For decades, St. Louis was a major supply point for parties of settlers heading west.\nMissouri was historically a Southern state. As many of the early settlers in western and southeastern Missouri migrated from the Upper South including Kentucky, Tennessee, and Virginia, they brought enslaved African Americans as agricultural laborers, and they desired to continue their culture and the institution of slavery. They settled predominantly in 17 counties along the Missouri River, in an area of flatlands that enabled plantation agriculture and became known as \"Little Dixie\".\nThe state was rocked by the 1811\u201312 New Madrid earthquakes. Casualties were few due to the sparse population.\nAdmission as a state in 1821.\nIn 1821, the former Missouri Territory was admitted as a slave state, under the Missouri Compromise, and with a temporary state capital in St. Charles. In 1826, the capital was shifted to its permanent location of Jefferson City, also on the Missouri River.\nOriginally the state's western border was a straight line, defined as the meridian passing through the Kawsmouth, the point where the Kansas River enters the Missouri River. The river has moved since this designation. This line is known as the Osage Boundary. In 1836 the Platte Purchase was added to the northwest corner of the state after purchase of the land from the native tribes, making the Missouri River the border north of the Kansas River. This addition increased the land area of what was already the largest state in the Union at the time (about to Virginia's 65,000 square miles, which then included West Virginia).\nIn the early 1830s, Mormon migrants from northern states and Canada began settling near Independence and areas just north of there. Conflicts over religion and slavery arose between the 'old settlers' (mainly from the South) and the Mormons (mainly from the North). The Mormon War erupted in 1838. By 1839, with the help of an \"Extermination Order\" by Governor Lilburn Boggs, the old settlers forcibly expelled the Mormons from Missouri and confiscated their lands.\nConflicts over slavery exacerbated border tensions among the states and territories. From 1838 to 1839, a border dispute with Iowa over the so-called Honey Lands resulted in both states' calling-up of militias along the border.\nWith increasing migration, from the 1830s to the 1860s, Missouri's population almost doubled with every decade. Most newcomers were American-born and Southern, but many later arrivals were Northern migrants as well as Irish and German immigrants who arrived in the late 1840s and 1850s. As a majority were Catholic, they set up their own religious institutions in the state, which had been mostly Protestant. Many settled in cities, creating a regional and then state network of Catholic churches and schools. 19th-century German immigrants created the wine industry along the Missouri River and the beer industry in St. Louis.\nWhile many German immigrants were strongly anti-slavery, many Irish immigrants living in cities were pro-slavery, fearing that liberating African-American slaves would create a glut of unskilled labor, driving wages down.\nMost Missouri farmers practiced subsistence farming before the American Civil War. The majority of those who held slaves had fewer than five each. Planters, defined by some historians as those holding 20 slaves or more, were concentrated in the counties known as \"Little Dixie\", in the central part of the state along the Missouri River as well as southeastern Missouri. The tensions over slavery chiefly had to do with the future of the state and nation. In 1860, enslaved African Americans made up less than 10% of the state's population of 1,182,012. In order to control the flooding of farmland and low-lying villages along the Mississippi, the state had completed construction of of levees along the river by 1860.\nAmerican Civil War.\nAfter the secession of Southern states began in 1861, the Missouri legislature called for the election of a special convention on secession. This convention voted against secession, but also qualified their support of the Union. In the aftermath of Battle of Fort Sumter Pro-Southern Governor Claiborne F. Jackson ordered the mobilization of several hundred members of the state militia who had gathered in a camp in St. Louis for training. In secret, he also requested Confederate arms and artillery to help take the St. Louis Arsenal. Alarmed at this action, and discovering the Confederate aid, General Nathaniel Lyon struck first, encircling the camp and forcing the state troops to surrender. Lyon directed his soldiers, largely non-English-speaking German immigrants, to march the prisoners through the streets, and this led to riot by pro-secession citizens. While it is disputed how it started, this riot led to violence and Union soldiers killed by St. Louis civilians. The event as a whole, is called the Camp Jackson Affair.\nThese events sharpened the divisions within the state. Governor Jackson appointed Sterling Price, president of the convention on secession, as head of the new Missouri State Guard. In the face of Union General Lyon's rapid advance through the state, Jackson and Price were forced to flee the capital of Jefferson City on June 14, 1861. In Neosho, Missouri, Jackson called the state legislature into session to call for secession. However, the elected legislative body was split between pro-Union and pro-Confederate. As such, few of the pro-unionist attended the session called in Neosho, and the ordinance of secession was quickly adopted. The Confederacy recognized Missouri secession on October 30, 1861.\nWith the elected governor absent from the capital and the legislators largely dispersed, the state convention was reassembled with most of its members present, save twenty who fled south with Jackson's forces. The convention declared all offices vacant and installed Hamilton Gamble as the new governor of Missouri. President Lincoln's administration immediately recognized Gamble's government as the legal Missouri government. The federal government's decision enabled raising pro-Union militia forces for service within the state and volunteer regiments for the Union Army.\nFighting ensued between Union forces and a combined army of General Price's Missouri State Guard and Confederate troops from Arkansas and Texas under General Ben McCulloch. After winning victories at the battle of Wilson's Creek and the siege of Lexington, Missouri and suffering losses elsewhere, the Confederate forces retreated to Arkansas and later Marshall, Texas, in the face of a largely reinforced Union Army.\nThough regular Confederate troops staged some large-scale raids into Missouri, the fighting in the state for the next three years consisted chiefly of guerrilla warfare. \"Citizen soldiers\" or insurgents such as Captain William Quantrill, Frank and Jesse James, the Younger brothers, and William T. Anderson made use of quick, small-unit tactics. Pioneered by the Missouri Partisan Rangers, such insurgencies also arose in portions of the Confederacy occupied by the Union during the Civil War. Historians have portrayed stories of the James brothers' outlaw years as an American \"Robin Hood\" myth. The vigilante activities of the Bald Knobbers of the Ozarks in the 1880s were an unofficial continuation of insurgent mentality long after the official end of the war, and they are a favorite theme in Branson's self-image.\nReconstruction and later 19th century.\nMissouri remained electorally competitive during the Jim Crow era, and did not disenfranchise African Americans, who comprised less than 10% of the state's population from 1870 to 1960. In particular, Missouri never implemented a poll tax as a requirement to vote.\nHowever, Missouri did enact racial segregation. Democratic President Harry S. Truman grew up in Missouri, where segregation was practiced and largely accepted. Truman would later issue Executive Order 9981 in July 1948, prohibiting racial segregation in the armed forces.\n20th century.\nThe Progressive Era (1890s to 1920s) saw numerous prominent leaders from Missouri trying to end corruption and modernize politics, government, and society. Joseph \"Holy Joe\" Folk was a key leader who made a strong appeal to the middle class and rural evangelical Protestants. Folk was elected governor as a progressive reformer and Democrat in the 1904 election. He promoted what he called \"the Missouri Idea\", the concept of Missouri as a leader in public morality through popular control of law and strict enforcement. He successfully conducted antitrust prosecutions, ended free railroad passes for state officials, extended bribery statutes, improved election laws, required formal registration for lobbyists, made racetrack gambling illegal and enforced the Sunday-closing law. He helped enact Progressive legislation, including an initiative and referendum provision, regulation of elections, education, employment and child labor, railroads, food, business, and public utilities. Several efficiency-oriented examiner boards and commissions were established during Folk's administration, including many agricultural boards and the Missouri library commission.\nBetween the Civil War and the end of World War II, Missouri transitioned from a rural southern state to a hybrid industrial-service-agricultural midwestern state as the Midwest rapidly industrialized and expanded into Missouri. The expansion of railroads to the West transformed Kansas City into a major transportation hub within the nation, and led to major Midwestern migration after the war overtaking the state's original Southern population. The growth of the Texas cattle industry along with this increased rail infrastructure and the invention of the refrigerated boxcar also made Kansas City a major meatpacking center, as large cattle drives from Texas brought herds of cattle to Dodge City and other Kansas towns. There, the cattle were loaded onto trains destined for Kansas City, where they were butchered and distributed to the eastern markets. The first half of the 20th century was the height of Kansas City's prominence, and its downtown became a showcase for stylish Art Deco skyscrapers as construction boomed.\nIn 1930, there was a diphtheria epidemic in the area around Springfield, which killed approximately 100 people. Serum was rushed to the area, and medical personnel stopped the epidemic.\nDuring the mid-1950s and 1960s, St. Louis and Kansas City suffered deindustrialization and loss of jobs in railroads and manufacturing, as did other Midwestern industrial cities. St. Charles claims to be the site of the first interstate highway project in 1956. Such highway construction made it easy for middle-class residents to leave the city for newer housing developed in the suburbs, often former farmland where land was available at lower prices. These major cities have gone through decades of readjustment to develop different economies and adjust to demographic changes. Suburban areas have developed separate job markets, both in knowledge industries and services, such as major retail malls.\n21st century.\nIn 2014, Missouri received national attention for the protests and riots that followed the shooting of Michael Brown by a police officer of Ferguson, which led Governor Jay Nixon to call out the Missouri National Guard. A grand jury declined to indict the officer, and the U.S. Department of Justice concluded, after careful investigation, that the police officer legitimately feared for his safety. However, in a separate investigation, the Department of Justice also found that the Ferguson Police Department and the City of Ferguson relied on unconstitutional practices in order to balance the city's budget through racially motivated excessive fines and punishments, that the Ferguson police \"had used excessive and dangerous force and had disproportionately targeted blacks,\" and that the municipal court \"emphasized revenue over public safety, leading to routine breaches of citizens' constitutional guarantees of due process and equal protection under the law.\"\nA series of student protests at the University of Missouri against what the protesters viewed as poor response by the administration to racist incidents on campus began in September 2015.\nOn June 7, 2017, the National Association for the Advancement of Colored People issued a warning to prospective African-American travelers to Missouri. This is the first NAACP warning ever covering an entire state. According to a 2018 report by the Missouri Attorney General's office, for the past 18 years, \"African Americans, Hispanics and other people of color are disproportionately affected by stops, searches and arrests.\" The same report found that the biggest discrepancy was in 2017, when \"black motorists were 85% more likely to be pulled over in traffic stops\".\nIn 2018, the USDA announced its plans to relocate Economic Research Service (ERS) and National Institute of Food &amp; Agriculture (NIFA) to Kansas City. They have since decided on a specific location in downtown Kansas City, Missouri. With the addition of the KC Streetcar project and construction of the Sprint Center Arena, the downtown area in KC has attracted investment in new offices, hotels, and residential complexes. Both Kansas City and St. Louis are undergoing a rebirth in their downtown areas with the addition of the new Power &amp; Light (KC) and Ballpark Village (STL) districts and the renovation of existing historical buildings in each downtown area. The 2019 announcement of an MLS expansion team in St. Louis is driving even more development in the downtown west area of St. Louis. Kansas City has experienced a boom in population, with new developments such as Three Light apartments being centered in Downtown Kansas City, as well as suburban development in the Northland.\nGeography.\nMissouri borders eight different states, a figure equaled only by its neighbor, Tennessee. Missouri is bounded by Iowa on the north; by Illinois, Kentucky, and Tennessee across the Mississippi River on the east; on the south by Arkansas; and by Oklahoma, Kansas, and Nebraska (the last across the Missouri River) on the west. Whereas the northern and southern boundaries are straight lines, the Missouri Bootheel extends south between the St. Francis and the Mississippi rivers. The two largest rivers are the Mississippi (which defines the eastern boundary of the state) and the Missouri River (which flows from west to east through the state), essentially connecting the two largest metros of Kansas City and St. Louis.\nAlthough today it is usually considered part of the Midwest, Missouri was historically seen by many as a border state, chiefly because of the settlement of migrants from the South and its status as a slave state before the Civil War, balanced by the influence of St. Louis. The counties that made up \"Little Dixie\" were those along the Missouri River in the center of the state, settled by Southern migrants who held the greatest concentration of slaves.\nIn 2005, Missouri received 16,695,000 visitors to its national parks and other recreational areas totaling , giving it $7.41\u00a0million in annual revenues, 26.6% of its operating expenditures.\nTopography.\nNorth of, and in some cases just south of, the Missouri River lie the Northern Plains that stretch into Iowa, Nebraska, and Kansas. Here, rolling hills remain from the glaciation that once extended from the Canadian Shield to the Missouri River. Missouri has many large river bluffs along the Mississippi, Missouri, and Meramec Rivers. Southern Missouri rises to the Ozark Mountains, a dissected plateau surrounding the Precambrian igneous St. Francois Mountains. This region also hosts karst topography characterized by high limestone content with the formation of sinkholes and caves.\nThe southeastern part of the state is known as the Missouri Bootheel region, which is part of the Mississippi Alluvial Plain or Mississippi embayment. This region is the lowest, flattest, warmest, and wettest part of the state. It is also among the poorest, as the economy there is mostly agricultural. It is also the most fertile, with cotton and rice crops predominant. The Bootheel was the epicenter of the four New Madrid Earthquakes of 1811 and 1812.\nClimate.\nMissouri generally has a humid continental climate with cool, sometimes cold, winters and hot, humid, and wet summers. In the southern part of the state, particularly in the Bootheel, the climate becomes humid subtropical. Located in the interior United States, Missouri often experiences extreme temperatures. Without high mountains or oceans nearby to moderate temperature, its climate is alternately influenced by air from the cold Arctic and the hot and humid Gulf of Mexico. Missouri's highest recorded temperature is at Warsaw and Union on July 14, 1954, while the lowest recorded temperature is also at Warsaw on February 13, 1905.\nLocated in Tornado Alley, Missouri also receives extreme weather in the form of severe thunderstorms and tornadoes. On May 22, 2011, a massive EF-5 tornado killed 158 people and destroyed roughly one-third of the city of Joplin. The tornado caused an estimated $1\u20133\u00a0billion in damages, killed 159 people and injured more than a thousand. It was the first EF5 to hit the state since 1957 and the deadliest in the U.S. since 1947, making it the seventh deadliest tornado in American history and 27th deadliest in the world. St. Louis and its suburbs also have a history of experiencing particularly severe tornadoes, the most recent one of note being an EF4 that damaged Lambert-St. Louis International Airport on April 22, 2011. One of the worst tornadoes in American history struck St. Louis on May 27, 1896, killing at least 255 people and causing $10\u00a0million in damage (equivalent to $3.9\u00a0billion in 2009 or $ in today's dollars).\nFlora and fauna.\nMissouri is home to diverse flora and fauna, including several endemic species. There is a large amount of fresh water present due to the Mississippi River, Missouri River, Table Rock Lake and Lake of the Ozarks, with numerous smaller tributary rivers, streams, and lakes. North of the Missouri River, the state is primarily rolling hills of the Great Plains, whereas south of the Missouri River, the state is dominated by the Oak-Hickory Central U.S. hardwood forest.\nRecreational and commercial uses of public forests, including grazing, logging, and mining, increased after World WarII. Fishermen, hikers, campers, and others started lobbying to protect forest areas with a \"wilderness character\". During the 1930s and 1940s, Aldo Leopold, Arthur Carhart and Bob Marshall developed a \"wilderness\" policy for the Forest Service. Their efforts bore fruit with the Wilderness Act of 1964, which designated wilderness areas \"where the earth and its community of life are untrammeled by men, where man himself is a visitor and does not remain.\" This included second growth public forests like the Mark Twain National Forest.\nCounties.\nMissouri has 114 counties and one independent city, St. Louis, which is Missouri's most densely populated\u20145,140 people per square mile. The largest counties by population are St. Louis (1,004,125), Jackson (717,204), and St. Charles (406,262). Worth County is the smallest (1,973). The largest counties by size are Texas (1,179 square miles) and Shannon (1,004). Worth County is the smallest (266).\nCities and towns.\nJefferson City is the capital city of Missouri, while the state's five largest cities are Kansas City, St. Louis, Springfield, Columbia, and Independence.\nSt. Louis is the principal city of the largest metropolitan area in Missouri, composed of 17 counties and the independent city of St. Louis; eight of its counties are in Illinois. As of 2022, St. Louis was the 21st-largest metropolitan area in the nation with 2.80\u00a0million people. If ranked using Combined Statistical Area, it is also the 21st-largest with 2.91 million people in 2022. Some of the major cities making up the St. Louis metro area in Missouri are O'Fallon, St. Charles, St. Peters, Florissant, Chesterfield, Wentzville, Wildwood, University City, Ballwin, and Kirkwood.\nKansas City is Missouri's largest city and the principal city of the fourteen-county Kansas City Metropolitan Statistical Area, including five counties in the state of Kansas. As of 2022, it was the 31st-largest metropolitan area in the U.S., with 2.21\u00a0million people. In the Combined Statistical Area in 2022, it ranked 29th with 2.55\u00a0million. Some of the other major cities comprising the Kansas City metro area in Missouri include Independence, Lee's Summit, Blue Springs, Liberty, Raytown, Gladstone, Grandview, and Belton.\nSpringfield is Missouri's third-largest city and the principal city of the Springfield-Branson Metropolitan Area, which has a population of 549,423 and includes seven counties in southwestern Missouri. Branson is a major tourist attraction in the Ozarks in southwest Missouri. Some of the other major cities comprising the Springfield-Branson metro area include Nixa, Ozark, and Republic.\n&lt;templatestyles src=\"Template:Largest_cities/styles.css\" /&gt;\nDemographics.\n&lt;templatestyles src=\"US Census population/styles.css\"/&gt;\nThe United States Census Bureau estimates that the population of Missouri was 6,137,428 on July 1, 2019, a 2.48% increase since the 2010 United States census.\nMissouri had a population of 5,988,927, according to the 2010 census; an increase of 137,525 (2.3 percent) since the year 2010. From 2010 to 2018, this includes a natural increase of 137,564 people since the last census (480,763 births less 343,199 deaths) and an increase of 88,088 people due to net migration into the state. Immigration from outside the United States resulted in a net increase of 50,450 people, and migration within the country produced a net increase of 37,638 people. More than half of Missourians (3,294,936 people, or 55.0%) live within the state's two largest metropolitan areas\u2014St. Louis and Kansas City. The state's population density of 86.9 people per square mile in 2009, was also closer to the national average (86.8 in 2009) than any other state. The top countries of origin for Missouri's immigrants in 2018 were Mexico, China, India, Vietnam and Bosnia and Herzegovina.\nAccording to HUD's 2022 Annual Homeless Assessment Report, there were an estimated 5,992 homeless people in Missouri.\n2020 census.\nThe U.S. census of 2010 found that the population center of the United States is in Texas County, while the 2000 census found the mean population center to be in Phelps County. The center of population of Missouri is in Osage County, in the city of Westphalia.\nIn 2004, the population included 194,000 foreign-born people (3.4 percent of the state population).\nThe five largest ancestry groups in Missouri are: German (27.4 percent), Irish (14.8 percent), English (10.2 percent), American (8.5 percent) and French (3.7 percent).\nGerman Americans are an ancestry group present throughout Missouri. African Americans are a substantial part of the population in St. Louis (56.6% of African Americans in the state lived in St. Louis or St. Louis County as of the 2010 census), Kansas City, Boone County and in the southeastern Bootheel and some parts of the Missouri River Valley, where plantation agriculture was once important. Missouri Creoles of French ancestry are concentrated in the Mississippi River Valley south of St. Louis (see Missouri French). Kansas City is home to large and growing immigrant communities from Latin America esp. Mexico and Colombia, Africa (i.e. Sudan, Somalia and Nigeria), and Southeast Asia including China and the Philippines; and Europe like the former Yugoslavia (see Bosnian American). A notable Cherokee Indian population exists in Missouri, and 30,518 identified as being Native American alone in 2020, while 152,917 did in combination with one or more other races.\nIn 2004, 6.6 percent of the state's population was reported as younger than5, 25.5 percent younger than 18, and 13.5 percent 65 or older. Females were approximately 51.4 percent of the population. 81.3 percent of Missouri residents were high school graduates (more than the national average), and 21.6 percent had a bachelor's degree or higher. 3.4 percent of Missourians were foreign-born, and 5.1 percent reported speaking a language other than English at home.\nIn 2010, there were 2,349,955 households in Missouri, with 2.45 people per household. The homeownership rate was 70.0 percent, and the median value of an owner-occupied housing unit was $137,700. The median household income for 2010 was $46,262, or $24,724 per capita. There was 14.0 percent (1,018,118) of Missourians living below the poverty line in 2010.\nThe mean commute time to work was 23.8 minutes.\nBirth data.\nIn 2011, 28.1% of Missouri's population younger than age1 were minorities.\n\"Note: Births in table do not add up, because Hispanics are counted both by their ethnicity and by their race, giving a higher overall number.\"\nLanguage.\nThe vast majority of people in Missouri speak English. Approximately 5.1% of the population reported speaking a language other than English at home. The Spanish language is spoken in small Latino communities in the St. Louis and Kansas City Metro areas.\nMissouri is home to an endangered dialect of the French language known as Missouri French. Speakers of the dialect, who call themselves \"Cr\u00e9oles\", are descendants of the French pioneers who settled the area then known as the Illinois Country beginning in the late 17th century. It developed in isolation from French speakers in Canada and Louisiana, becoming quite distinct from the varieties of Canadian French and Louisiana French. Once widely spoken throughout the area, Missouri French is now nearly extinct, with only a few elderly speakers able to use it.\nReligion.\n&lt;templatestyles src=\"Pie chart/styles.css\"/&gt;\nAccording to a Pew Research study conducted in 2014, 80% of Missourians identify with a religion. 77% affiliate with Christianity and its various denominations and the other 3% are adherents of non-Christian religions. The remaining 20% have no religion, with 2% specifically identifying as atheists and 3% identifying as agnostics (the other 15% do not identify as \"anything in particular\").\nThe religious demographics of Missouri are as follows:\nThe largest denominations by number of adherents in 2010 were the Southern Baptist Convention with 749,685; the Roman Catholic Church with 724,315; and the United Methodist Church with 226,409.\nAmong the other denominations there are approximately 93,000 Mormons in 253 congregations, 25,000 Jewish adherents in 21 synagogues, 12,000 Muslims in 39 masjids, 7,000 Buddhists in 34 temples, 20,000 Hindus in 17 temples, 2,500 Unitarians in nine congregations, 2,000 of the Bah\u00e1\u02bc\u00ed Faith in 17 temples, five Sikh temples, a Zoroastrian temple, a Jain temple and an uncounted number of neopagans.\nSeveral religious organizations have headquarters in Missouri, including the Lutheran Church\u2013Missouri Synod, which has its headquarters in Kirkwood, as well as the United Pentecostal Church International in Hazelwood, both outside St. Louis.\nIndependence, near Kansas City, is the headquarters for the Community of Christ (formerly the Reorganized Church of Jesus Christ of Latter-day Saints), the Church of Christ (Temple Lot) and the group Remnant Church of Jesus Christ of Latter-day Saints. This area and other parts of Missouri are also of significant religious and historical importance to the Church of Jesus Christ of Latter-day Saints (LDS Church), which maintains several sites and visitor centers.\nSpringfield is the headquarters of the Assemblies of God USA and the Baptist Bible Fellowship International. The General Association of General Baptists has its headquarters in Poplar Bluff. The Unity Church is headquartered in Unity Village. Springfield is particularly known as a Christian center in the state and is considered by some to be a \"buckle\" of the Bible Belt.\nThe Hindu Temple of St. Louis is the largest Hindu Temple in Missouri, serving more than 14,000 Hindus.\nEconomy.\nThe U.S. Department of Commerce's Bureau of Economic Analysis estimated Missouri's gross state product was $422\u00a0billion in 2023. Per capita personal income in 2023 was $61,302, ranking 34th in the nation. Major industries include agriculture, aerospace, transportation equipment, food processing, chemicals, printing/publishing, electrical equipment, light manufacturing, and financial services.\nThe agriculture products of the state are beef, soybeans, pork, dairy products, hay, corn, poultry, sorghum, cotton, rice, and eggs. Missouri is ranked sixth in the nation for the production of hogs and seventh for cattle. Missouri is ranked in the top five states in the nation for production of soy beans, and it is ranked fourth in the nation for the production of rice. In 2001, there were 108,000 farms, the second-largest number in any state after Texas. Missouri actively promotes its rapidly growing wine industry. According to the Missouri Partnership, Missouri's agriculture industry contributes $33\u00a0billion in GDP to Missouri's economy, and generates $88\u00a0billion in sales and more than 378,000 jobs.\nMissouri has vast quantities of limestone. Other resources mined are lead, coal, and crushed stone. Missouri produces the most lead of all the states. Most of the lead mines are in the central eastern portion of the state. Missouri also ranks first or near first in the production of lime, a key ingredient in Portland cement.\nMissouri also has a growing science, agricultural technology, and biotechnology field. Monsanto, formerly one of the largest biotech companies in America, was based in St. Louis until it was acquired by Bayer AG in 2018. It is now part of the Crop Science Division of Bayer Corporation, Bayer's U.S. subsidiary.\nTourism, services, and wholesale/retail trade follow manufacturing in importance; tourism benefits from the many rivers, lakes, caves, and parks throughout the state. In addition to a network of state parks, Missouri is home to Gateway Arch National Park in St. Louis and the Ozark National Scenic Riverways. A much-visited show cave is Meramec Caverns, near Stanton.\nMissouri is the only state in the Union to have two Federal Reserve Banks: one in Kansas City (serving western Missouri, Kansas, Nebraska, Oklahoma, Colorado, northern New Mexico, and Wyoming) and one in St. Louis (serving eastern Missouri, southern Illinois, southern Indiana, western Kentucky, western Tennessee, northern Mississippi, and all of Arkansas).\nThe state's seasonally adjusted unemployment rate in April 2017 was 3.9 percent. In 2017, Missouri became a right-to-work state, but in August 2018, Missouri voters rejected a right-to-work law with 67% to 33%.\nTaxation.\nPersonal income is taxed in ten different earning brackets, ranging from 1.5% to 6.0%. Missouri's sales tax rate for most items is 4.225%, with some additional local levies. More than 2,500 Missouri local governments rely on property taxes levied on real property (real estate) and personal property.\nMost personal property is exempt, except for motorized vehicles. Exempt real estate includes property owned by governments and property used as nonprofit cemeteries, exclusively for religious worship, for schools and colleges, and purely charitable purposes. There is no inheritance tax and limited Missouri estate tax related to federal estate tax collection.\nIn 2017, the Tax Foundation rated Missouri as having the fifth-best corporate tax index, and the 15th-best overall tax climate. Missouri's corporate income tax rate is 6.25%; however, 50% of federal income tax payments may be deducted before computing taxable income, leading to an effective rate of 5.2%.\nEnergy.\nIn 2012, Missouri had roughly 22,000 MW of installed electricity generation capacity. In 2011, 82% of Missouri's electricity was generated by coal. Ten percent was generated from the state's only nuclear power plant, the Callaway Plant in Callaway County, northeast of Jefferson City. Five percent was generated by natural gas. One percent was generated by hydroelectric sources, such as the dams for Truman Lake and Lake of the Ozarks. Missouri has a small but growing amount of wind and solar power\u2014wind capacity increased from 309 MW in 2009 to 459 MW in 2011, while photovoltaics have increased from 0.2 MW to 1.3 MW over the same period. As of 2016, Missouri's solar installations had reached 141 MW.\nOil wells in Missouri produced 120,000 barrels of crude oil in fiscal 2012. There are no oil refineries in Missouri.\nCulture.\nMusic.\nMany well-known musicians were born or have lived in Missouri. These include guitarist and rock pioneer Chuck Berry, singer and actress Josephine Baker, \"Queen of Rock\" Tina Turner, pop singer-songwriter Sheryl Crow, Michael McDonald of the Doobie Brothers, rap producer Metro Boomin, and rappers Nelly, Chingy, and Akon, all of whom are either current or former residents of St. Louis.\nCountry singers from Missouri include Perryville native Chris Janson, New Franklin native Sara Evans, Cantwell native Ferlin Husky, West Plains native Porter Wagoner, Tyler Farr of Garden City, and Mora native Leroy Van Dyke, along with bluegrass musician Rhonda Vincent, a native of Greentop. Rapper Eminem was born in St. Joseph and also lived in Savannah and Kansas City. Ragtime composer Scott Joplin lived in St. Louis and Sedalia. Jazz saxophonist Charlie Parker lived in Kansas City. Rock and Roll singer Steve Walsh of the group Kansas was born in St. Louis and grew up in St. Joseph.\nThe Kansas City Symphony and the St. Louis Symphony Orchestra are the state's major orchestras. The latter is the nation's second-oldest symphony orchestra and achieved prominence in recent years under conductor Leonard Slatkin. Branson is well known for its music theaters, most of which bear the name of a star performer or musical group.\nLiterature.\nMissouri is the native state of Mark Twain. His novels \"The Adventures of Tom Sawyer\" and \"The Adventures of Huckleberry Finn\" are set in his boyhood hometown of Hannibal. Authors Kate Chopin, T. S. Eliot and Tennessee Williams were from St. Louis. Kansas City-born writer William Least Heat-Moon resides in Rocheport. He is best known for \"Blue Highways\", a chronicle of his travels to small towns across America, which was on The New York Times Bestseller list for 42 weeks in 1982\u20131983. Novelist Daniel Woodrell, known for depicting life in the Missouri Ozarks, was born in Springfield and lives in West Plains.\nSports.\nMissouri hosted the 1904 Summer Olympics at St. Louis, the first time the games were hosted in the United States.\nProfessional major league teams:\nFormer professional major league teams:\nHeritage.\nSte. Genevi\u00e8ve National Historical Park, which preserves the story of Missouri's oldest permanent European settlement. The park's historic buildings, like the Amoureux House, showcase rare French Colonial architecture, including a unique \"poteaux-en-terre\" or \"post-in-ground\" construction style.\nGovernment and politics.\nThe Constitution of Missouri, the fourth constitution for the state, was adopted in 1945. It provides for three branches of government: the legislative, judicial, and executive branches. The legislative branch consists of two bodies: the House of Representatives and the Senate. These bodies comprise the Missouri General Assembly.\nThe House of Representatives has 163 members apportioned based on the last decennial census. The Senate consists of 34 members from districts of approximately equal populations. The judicial department comprises the Supreme Court of Missouri, which has seven judges, the Missouri Court of Appeals (an intermediate appellate court divided into three districts), sitting in Kansas City, St. Louis, and Springfield, and 45 Circuit Courts which function as local trial courts. The executive branch is headed by the Governor of Missouri and includes five other statewide elected offices. Following the departure from office of State Auditor Nicole Galloway on January 9, 2023, there are no Democrats holding statewide elected positions in Missouri.\nHarry S Truman (1884\u20131972), the 33rd President of the United States (Democrat, 1945\u20131953), was born in Lamar. He was a judge in Jackson County and then represented the state in the United States Senate for ten years, before being elected vice-president in 1944. He lived in Independence after retiring as president in 1953.\nIn a 2020 study, Missouri was ranked as 48th on the Cost of Voting Index with only Texas and Georgia ranking higher.\nMissouri retains the death penalty. Authorized methods of execution include the gas chamber. Abortion in Missouri is legal as a result of 2024 Missouri Amendment 3.\nFormer status as a political bellwether.\nPrior to 2008, Missouri had been widely regarded as a bellwether in American politics, often making it a swing state. The state had a longer stretch of supporting the winning presidential candidate than any other state, having voted for the winning candidate in every election from 1904 to 2004 with a single exception: 1956 when Democratic candidate Adlai Stevenson of neighboring Illinois lost the election despite carrying Missouri. However, since 2000, Missouri has always voted for the Republican presidential candidate, with the last Democrat winning the state being Bill Clinton in 1996. Missouri voted for John McCain and Mitt Romney over Democrat Barack Obama of neighboring Illinois, despite Obama being elected to the Presidency in both 2008 and 2012. Missouri voted for Mitt Romney by nearly 10% in 2012 and voted for Donald Trump by over 18% in 2016 and 2024, and 15% in 2020.\nOn October 24, 2012, there were 4,190,936 registered voters. At the state level, both Democratic Senator Claire McCaskill and Democratic Governor Jay Nixon were re-elected.\nOn November 3, 2020, there were 4,318,758 registered voters, with 3,026,028 voting (70.1%). By this time, the state had favored more Republican candidates for federal offices. The offices held by Democratic party officials a decade before were subsequently held by Republican Senator Josh Hawley and Republican Governor Mike Parson.\nMissouri's accuracy rate for the last 29 presidential elections is now 89.66%. This percentage is on par with that of Ohio, which has voted for the winner of every presidential election since 1896, except in 1944, 1960 and 2020.\nAlcohol and tobacco laws.\nMissouri has been known for its population's generally \"stalwart, conservative, noncredulous\" attitude toward regulatory regimes, which is one of the origins of the state's unofficial nickname, the \"Show-Me State\". As a result, and combined with the fact that Missouri is one of America's leading alcohol states, regulation of alcohol and tobacco in Missouri is among the most laissez-faire in America. In 2013, the Mercatus Center ranked Missouri third for alcohol freedom and first for tobacco freedom. The state's alcohol laws are notably lax, with no blue laws, low taxes, and broad access to alcohol in locations like drugstores and gas stations. Additionally, Missouri's tobacco laws are equally permissive, including the lowest cigarette excise tax in the nation. Missouri law makes it \"an improper employment practice\" for an employer to refuse to hire, to fire, or otherwise to disadvantage any person because that person lawfully uses alcohol or tobacco products outside of work.\nWith a large German immigrant population and the development of a brewing industry, Missouri always has had among the most permissive alcohol laws in the United States. It has never enacted statewide prohibition. Missouri has no statewide open container law or prohibition on drinking in public, no alcohol-related blue laws, no local option, no precise locations for selling liquor by the package (allowing even drug stores and filling stations to sell any kind of liquor), and no differentiation of laws based on alcohol percentage. State law protects persons from arrest or criminal penalty for public intoxication.\nMissouri law expressly prohibits any jurisdiction from going dry. Missouri law also expressly allows parents and guardians to serve alcohol to their children. The Power &amp; Light District in Kansas City is one of the few places in the United States where a state law explicitly allows persons over 21 to possess and consume open containers of alcohol in the street (as long as the beverage is in a plastic cup).\nMissouri had the lowest cigarette excise taxes in the United States in 2016, at 17 cents per pack, and the state electorate voted in 2002, 2006, 2012, and twice in 2016 to keep it that way. According to the Centers for Disease Control and Prevention, in 2008 Missouri had the fourth highest percentage of adult smokers among U.S. states, at 24.5%. Although federal law prohibits the sale of tobacco to persons under 21, tobacco products can be distributed to persons under 21 by family members on private property.\nNo statewide smoking ban ever has been seriously entertained before the Missouri General Assembly, and in October 2008, a statewide survey by the Missouri Department of Health and Senior Services found that only 27.5% of Missourians support a statewide ban on smoking in all bars and restaurants. Missouri state law permits restaurants seating less than 50 people, bars, bowling alleys, and billiard parlors to decide their own smoking policies, without limitation.\nCannabis laws.\nIn 2014, a Republican-led legislature and Democratic governor Jay Nixon enacted a series of laws to partially decriminalize possession of cannabis by making first-time possession of up to 10 grams no longer punishable with jail time and legalizing CBD oil. In November 2018, 66% of voters approved a constitutional amendment that established a right to medical marijuana and a system for licensing, regulating, and taxing medical marijuana.\nEducation.\nThe Missouri State Board of Education has general authority over all public education in the state of Missouri. It is made up of eight citizens appointed by the governor and confirmed by the Missouri Senate.\nPrimary and secondary schools.\nEducation is compulsory from ages seven to seventeen. It is required that any parent, guardian, or another person with custody of a child between the ages of seven and seventeen, the compulsory attendance age for the district, must ensure the child is enrolled in and regularly attends public, private, parochial school, home school or a combination of schools for the full term of the school year. Compulsory attendance also ends when children complete sixteen credits in high school.\nChildren in Missouri between the ages of five and seven are not required to be enrolled in school. However, if they are enrolled in a public school, their parent, guardian, or custodian must ensure they regularly attend.\nMissouri schools are commonly but not exclusively divided into three tiers of primary and secondary education: elementary school, middle school or junior high school and high school. The public school system includes kindergarten to 12th grade. District territories are often complex in structure. In some cases, elementary, middle, and junior high schools of a single district feed into high schools in another district. As another example, special education and related services for students in the twenty-two school districts of St. Louis County are provided by staff employed by a special school district, a local education agency that serves students county-wide. High school athletics and competitions are governed by the Missouri State High School Activities Association (MSHSAA).\nHomeschooling is legal in Missouri and is an option to meet the compulsory education requirement. It is neither monitored nor regulated by the state's Department of Elementary and Secondary Education.\nAnother gifted school is the Missouri Academy of Science, Mathematics and Computing, which is at the Northwest Missouri State University.\nColleges and universities.\nThe University of Missouri System is Missouri's statewide public university system. The flagship institution and largest university in the state is the University of Missouri in Columbia. The others in the system are University of Missouri\u2013Kansas City, University of Missouri\u2013St. Louis, and Missouri University of Science and Technology in Rolla.\nDuring the late nineteenth and early twentieth century, the state established a series of normal schools in each region of the state, originally named after the geographic districts: Northeast Missouri State University (now Truman State University) (1867), Central Missouri State University (now the University of Central Missouri) (1871), Southeast Missouri State University (1873), Southwest Missouri State University (now Missouri State University) (1905), Northwest Missouri State University (1905), Missouri Western State University (1915), Maryville University (1872) and Missouri Southern State University (1937). Lincoln University and Harris\u2013Stowe State University were established in the mid-nineteenth century and are historically black colleges and universities.\nAmong private institutions Washington University in St. Louis and Saint Louis University are two top ranked schools in the US. There are numerous junior colleges, trade schools, church universities and other private universities in the state. A.T. Still University was the first osteopathic medical school in the world. Hannibal\u2013LaGrange University in Hannibal, Missouri, was one of the first colleges west of the Mississippi (founded 1858 in LaGrange, Missouri, and moved to Hannibal in 1928).\nThe state funds a $3000, renewable merit-based scholarship, Bright Flight, given to the top three percent of Missouri high school graduates who attend a university in-state.\nThe 19th-century border wars between Missouri and Kansas have continued as a sports rivalry between the University of Missouri and University of Kansas. The rivalry was chiefly expressed through football and basketball games between the two universities, but since Missouri left the Big 12 Conference in 2012, the teams no longer regularly play one another. It was the oldest college rivalry west of the Mississippi River and the second-oldest in the nation. Each year when the universities met to play, the game was coined the \"Border War\". Following the game, an exchange occurred where the winner took a historic Indian War Drum, which had been passed back and forth for decades. Though Missouri and Kansas no longer have an annual game after the University of Missouri moved to the Southeastern Conference, rivalry still exists between them.\nTransportation.\nAirports.\nMissouri has two major airport hubs: St. Louis Lambert International Airport and Kansas City International Airport. Southern Missouri has the Springfield\u2013Branson National Airport (SGF) with multiple non-stop destinations. Residents of Mid-Missouri use Columbia Regional Airport (COU) to fly to Chicago (ORD), Dallas (DFW) or Denver (DEN).\nRail.\n&lt;templatestyles src=\"Routemap/styles.css\"/&gt;\nTwo of the nation's three busiest rail centers are in Missouri. Kansas City is a major railroad hub for BNSF Railway, Norfolk Southern Railway, Kansas City Southern Railway, and Union Pacific Railroad, and every class1 railroad serves Missouri. Kansas City is the second-largest freight rail center in the U.S. (but is first in the amount of tonnage handled). Like Kansas City, St. Louis is a major destination for train freight. Springfield remains an operational hub for BNSF Railway.\nAmtrak passenger trains serve Kansas City, La Plata, Jefferson City, St. Louis, Lee's Summit, Independence, Warrensburg, Hermann, Washington, Kirkwood, Sedalia, and Poplar Bluff. A proposed high-speed rail route in Missouri as part of the Chicago Hub Network has received $31\u00a0million in funding.\nThe only urban light rail/subway system operating in Missouri is MetroLink, which connects the city of St. Louis with suburbs in Illinois and St. Louis County. It is one of the largest systems (by track mileage) in the United States. The KC Streetcar in downtown Kansas City opened in May 2016.\nThe Gateway Multimodal Transportation Center in St. Louis is the largest active multi-use transportation center in the state. It is in downtown St. Louis, next to the historic Union Station complex. It serves as a hub center/station for MetroLink, the MetroBus regional bus system, Greyhound, Amtrak, and taxi services.\nIn 2018, a Missouri Hyperloop was proposed to connect St. Louis, Kansas City, and Columbia, reducing travel time across the entire state to around a half hour. The project stalled in December 2023, with the shutdown of the corporate partner Hyperloop One.\nBus.\nMany cities have regular fixed-route systems, and many rural counties have rural public transit services. Greyhound and Trailways provide inter-city bus service in Missouri. Megabus serves St. Louis, but discontinued service to Columbia and Kansas City in 2015.\nRivers.\nThe Mississippi River and Missouri River are commercially navigable over their entire lengths in Missouri. The Missouri was channelized through dredging and jetties, and the Mississippi was given a series of locks and dams to avoid rocks and deepen the river. St. Louis is a major destination for barge traffic on the Mississippi.\nRoads.\nFollowing the passage of Amendment 3 in late 2004, the Missouri Department of Transportation (MoDOT) began its Smoother, Safer, Sooner road-building program with a goal of bringing of highways up to good condition by December 2007. From 2006 to 2011 traffic deaths have decreased annually from 1,257 in 2005, to 1,096 in 2006, to 992 in 2007, to 960 in 2008, to 878 in 2009, to 821 in 2010, to 786 in 2011.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "19572", "revid": "122189", "url": "https://en.wikipedia.org/wiki?curid=19572", "title": "MacOS (Classic)", "text": ""}
{"id": "19574", "revid": "543434", "url": "https://en.wikipedia.org/wiki?curid=19574", "title": "Monitor", "text": "Monitor or monitor may refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "19577", "revid": "40414428", "url": "https://en.wikipedia.org/wiki?curid=19577", "title": "Moses", "text": "Prophet in Abrahamic religions\nIn Abrahamic religions, Moses was the Hebrew prophet who led the Israelites out of slavery in the Exodus from Egypt. He is considered the most important prophet in Judaism and Samaritanism, and one of the most important prophets in Christianity, Islam, the Bah\u00e1\u02bc\u00ed Faith, and other Abrahamic religions. According to the Abrahamic scriptures, God dictated the Mosaic Law to Moses, which he wrote down and which formed part of the Torah.\nAccording to the Book of Exodus, Moses was born in a period when his people, the Israelites, who were an enslaved minority, were increasing in population; consequently, the Egyptian Pharaoh was worried that they might ally themselves with Egypt's enemies. When Pharaoh ordered all newborn Hebrew boys to be killed in order to reduce the population of the Israelites, Moses' Hebrew mother, Jochebed, secretly hid him in the bulrushes along the Nile river. The Pharaoh's daughter discovered the infant there and adopted him as a foundling. Thus, he grew up with the Egyptian royal family. After killing an Egyptian slave-master who was beating a Hebrew, Moses fled across the Red Sea to Midian, where he encountered the Angel of the Lord, speaking to him from within a burning bush on Mount Horeb.\nGod sent Moses back to Egypt to demand the release of the Israelites from slavery. Moses said that he could not speak eloquently, so God allowed Aaron, his elder brother, to become his spokesperson. After the Ten Plagues, Moses led the Exodus of the Israelites out of Egypt and across the Red Sea, after which they based themselves at Mount Sinai, where Moses received the Ten Commandments. After 40 years of wandering in the desert, Moses died on Mount Nebo at the age of 120, within sight of the Promised Land.\nThe majority of scholars see the biblical Moses as a legendary figure, while retaining the possibility that Moses or a Moses-like figure existed in the 13th century BCE. Rabbinic Judaism calculated a lifespan of Moses corresponding to 1391\u20131271 BCE; Jerome suggested 1592 BCE, and James Ussher suggested 1571 BCE as his birth year. Moses has often been portrayed in art, literature, music and film, and he is the subject of works at a number of U.S. government buildings.\nEtymology of name.\nThe Egyptian root ('child of') or \"mose\" has been considered as a possible etymology, arguably an abbreviation of a theophoric name with the god\u2019s name omitted. The suffix mose appears in Egyptian pharaohs\u2019 names like Thutmose ('born of Thoth') and Ramose ('born of Ra'). One of the Egyptian names of Ramesses was , meaning 'born of Ra, beloved of Amon'. Ms by itself also has multiple attestations as an Egyptian personal name in the New Kingdom. Linguist Abraham Yahuda, based on the spelling given in the Tanakh, argues that it combines \"water\" or \"seed\" and \"pond, expanse of water,\" thus yielding the sense of \"child of the Nile\" ().\nThe biblical account of Moses' birth provides him with a folk etymology to explain the ostensible meaning of his name. He is said to have received it from the Pharaoh's daughter: \"he became her son. She named him Moses [, ], saying, 'I drew him out [, ] of the water'.\" This explanation links it to the Semitic root , , meaning \"to draw out\". The eleventh-century Tosafist Isaac b. Asher haLevi noted that the princess names him the active participle 'drawer-out' (, ), not the passive participle 'drawn-out' (, ), in effect prophesying that Moses would draw others out (of Egypt); this has been accepted by some scholars.\nThe Hebrew etymology in the Biblical story may reflect an attempt to cancel out traces of Moses' Egyptian origins. The Egyptian character of his name was recognized as such by ancient Jewish writers like Philo and Josephus. Philo linked Moses' name () to the Egyptian (Coptic) word for 'water' (, ), in reference to his finding in the Nile and the biblical folk etymology. Josephus, in his \"Antiquities of the Jews\", claims that the second element, , meant 'those who are saved'. The problem of how an Egyptian princess (who, according to the Biblical account found in the book of Exodus, gave him the name \"Moses\") could have known Hebrew puzzled medieval Jewish commentators like Abraham ibn Ezra and Hezekiah ben Manoah. Hezekiah suggested she either converted to the Jewish religion or took a tip from Jochebed (Moses' mother). The Egyptian princess who named Moses is not named in the book of Exodus. However, she was known to Josephus as Thermutis (identified as Tharmuth), and some within Jewish tradition have tried to identify her with a \"daughter of Pharaoh\" in 1 Chronicles 4:17 named Bithiah, but others note that this is unlikely since there is no textual indication that this daughter of Pharaoh is the same one who named Moses.\nIbn Ezra gave two possibilities for the name of Moses: he believed that it was either a translation of the Egyptian name instead of a transliteration or that the Pharaoh's daughter was able to speak Hebrew.\nKenneth Kitchen argues that the Hebrew etymology is most likely correct, as the sounds in the Hebrew do not correspond to the pronunciation of Egyptian in the relevant time period.\nBiblical narrative.\nProphet and deliverer of Israel.\nThe Israelites had settled in the Land of Goshen in the time of Joseph and Jacob, but a new Pharaoh arose who oppressed the children of Israel. At this time, Moses was born to his father Amram, son (or descendant) of Kehath the Levite, who entered Egypt with Jacob's household; his mother was Jochebed (also Yocheved), who was kin to Kehath. Moses had one older (by seven years) sister, Miriam, and one older (by three years) brother, Aaron. Pharaoh had commanded that all male Hebrew children born would be drowned in the river Nile, but Moses's mother placed him in an ark and concealed the ark in the bulrushes by the riverbank. He was discovered and adopted by Pharaoh's daughter and raised as an Egyptian. One day, after Moses had reached adulthood, he killed an Egyptian who was beating a Hebrew. To escape Pharaoh's death penalty, Moses fled to Midian (a desert country south of Judah), where he married Zipporah.\nThere, on Mount Horeb, God appeared to Moses as a burning bush, revealed his name as YHWH (probably pronounced Yahweh), and commanded him to return to Egypt and bring his chosen people (Israel) out of bondage and into the Promised Land (Canaan). During the journey, God tried to kill Moses for failing to circumcise his son, but Zipporah saved his life. Moses returned to carry out God's command, but God enabled Pharaoh to refuse, and only after God had subjected Egypt to ten plagues did Pharaoh relent. Moses led the Israelites to the border of Egypt, but God hardened Pharaoh's heart once more so that he could destroy Pharaoh and his army at the Red Sea Crossing as a sign of his power to Israel and the nations.\nAfter defeating the Amalekites in Rephidim, Moses led the Israelites to Mount Sinai, where he was given the Ten Commandments from God, written on stone tablets. However, since Moses remained a long time on the mountain, some of the people feared that he might be dead, so they made a statue of a golden calf and worshipped it as an idol of God, thus disobeying and angering God and Moses. Moses, out of anger, broke the tablets and later ordered the elimination of those who had worshiped the golden statue, which was melted down and fed to the idolaters. God again wrote the Ten Commandments on a new set of tablets. Later at Mount Sinai, Moses and the elders entered into a covenant by which Israel would become the people of YHWH, obeying his laws, and YHWH would be their god. Moses delivered the laws of God to Israel, instituted the priesthood under the sons of Moses's brother Aaron, and destroyed those Israelites who fell away from his worship. In his final act at Sinai, God gave Moses instructions for the Tabernacle, the mobile shrine by which he would travel with Israel to the Promised Land.\nFrom Sinai, Moses led the Israelites to the Desert of Paran on the border of Canaan. From there, he sent twelve spies into the land (Numbers 13\u201314). The spies returned with samples of the land's fertility but warned that its inhabitants were giants. The people were afraid and wanted to return to Egypt, and some rebelled against Moses and against God. Moses told the Israelites they were not worthy to inherit the land and would wander the wilderness for forty years until the generation who refused to enter Canaan died so their children would possess the land. Later on, Korah was punished for leading a revolt against Moses.\nWhen the forty years had passed, Moses led the Israelites east around the Dead Sea to the territories of Edom and Moab. There they escaped the temptation of idolatry, conquered the lands of Og and Sihon in Transjordan, received God's blessing through Balaam the prophet, and massacred the Midianites, who by the end of the Exodus journey had become the enemies of the Israelites due to their notorious role in enticing the Israelites to sin against God. Moses was twice given notice that he would die before entry to the Promised Land: in Numbers 27:13, once he had seen the Promised Land from a viewpoint on Mount Abarim, and again in Numbers 31:1, once battle with the Midianites had been won.\nOn the banks of the Jordan River, in sight of the land, Moses assembled the tribes. After recalling their wanderings, he delivered God's laws by which they must live in the land, sang a song of praise and pronounced a blessing on the people, and passed his authority to Joshua, under whom they would possess the land. Moses then went up Mount Nebo, looked over the Promised Land spread out before him, and died at the age of 120:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;So Moses the servant of the LORD died there in the land of Moab according to the word of the LORD. And He buried him in the valley in the land of Moab, opposite Beth-Peor, but no man knows his burial place to this day. (Deuteronomy 34:5\u20136, Amplified Bible)\nLawgiver of Israel.\nMoses is honored among Jews today as the \"lawgiver of Israel\": he delivered several sets of laws in the course of the Torah. The first is the Covenant Code, the terms of the covenant which God offers to the Israelites at Mount Sinai. Embedded in the covenant are the Decalogue (the Ten Commandments, Exodus 20:1\u201317), as well as the Book of the Covenant (Exodus 20:22\u201323:19). The entire Book of Leviticus constitutes a second body of law, the Book of Numbers begins with yet another set, and the Book of Deuteronomy another.\nMoses has traditionally been regarded as the author of the Torah, the first section of the Hebrew Bible.\nHistoricity.\nScholars hold different opinions on the historicity of Moses. For instance, according to William G. Dever, the modern scholarly consensus is that the biblical person of Moses is largely mythical while also holding that \"a Moses-like figure may have existed somewhere in the southern Transjordan\" in the mid-to-late thirteenth century BCE, and that \"archeology can do nothing\" to prove or confirm either way. According to Solomon Nigosian, there are three prevailing views among biblical scholars: one is that Moses is not a historical figure, another view strives to anchor the decisive role he played in Israelite religion, and a third that argues there are elements of both history and legend from which \"these issues are hotly debated unresolved matters among scholars\". According to Brian Britt, there is divide among scholars when discussing matters on Moses that threatens gridlock. According to the official Torah commentary for Conservative Judaism, it is irrelevant if the historical Moses existed, calling him \"the folkloristic, national hero\".\nJan Assmann argues that it cannot be known if Moses ever lived because there are no traces of him outside tradition. Although the names of Moses and others in the biblical narratives are Egyptian and contain genuine Egyptian elements, no extra-biblical sources point clearly to Moses. No references to Moses appear in any Egyptian sources prior to the fourth century\u00a0BCE, long after he is believed to have lived. No contemporary Egyptian sources mention Moses or the events of Exodus\u2013Deuteronomy, nor has any archaeological evidence been discovered in Egypt or the Sinai wilderness to support the story in which he is the central figure. David Adams Leeming states that Moses is a mythic hero and the central figure in Hebrew mythology.\nThe \"Oxford Companion to the Bible\" states that the historicity of Moses is the most reasonable (albeit not unbiased) assumption to be made about him, as his absence would leave a vacuum that cannot be explained away. \"Oxford Biblical Studies\" states that although few modern scholars are willing to support the traditional view that Moses himself wrote the five books of the Torah, there are certainly those who regard the leadership of Moses as too firmly based in Israel's corporate memory to be dismissed as pious fiction.\nThe story of Moses' discovery follows a familiar motif in ancient Near Eastern mythological accounts of the ruler who rises from humble origins. For example, in the account of the origin of Sargon of Akkad (twenty-third century\u00a0BCE):\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nMoses' story, like those of the other patriarchs, most likely had a substantial oral prehistory (he is mentioned in the Book of Jeremiah and the Book of Isaiah). The earliest mention of him is vague, in the Book of Hosea and his name is apparently ancient, as the tradition found in Exodus gives it a folk etymology. Nevertheless, the Torah was completed by combining older traditional texts with newly-written ones.\nJean-Louis Ska argues that texts such as and , written during the Exile (i.e., in the first half of the sixth century\u00a0BCE), testify to tension between the people of Judah and the returning post-Exilic Jews (the \"g\u00f4l\u00e2\"). Whereas the Jews who had continuously lived in the land based their claim to the land on their descent from Abraham, the texts written by the exiles call God the true father of Israel and regard the Exodus under Moses as the true starting point of Israel's history.\nA theory developed by Cornelis Tiele in 1872, which has proved influential, argued that Yahweh was a Midianite god, introduced to the Israelites by Moses, whose father-in-law Jethro was a Midianite priest. It was to such a Moses that Yahweh reveals his real name, hidden from the Patriarchs who knew him only as El Shaddai. Against this view is the modern consensus that most of the Israelites were native to Palestine. Martin Noth argued that the Pentateuch uses the figure of Moses, originally linked to legends of a Transjordan conquest, as a narrative bracket or late redactional device to weld together four of the five, originally independent, themes of that work. Manfred G\u00f6rg and Rolf Krauss, the latter in a somewhat sensationalist manner, have suggested that the Moses story is a distortion or transmogrification of the historical pharaoh Amenmose (c.\u20091200 BCE), who was dismissed from office and whose name was later simplified to (Mose). Aidan Dodson regards this hypothesis as \"intriguing, but beyond proof\". Rudolf Smend argues that the two details about Moses that were most likely to be historical are his name, of Egyptian origin, and his marriage to a Midianite woman, details which seem unlikely to have been invented by the Israelites; in Smend's view, all other details given in the biblical narrative are too mythically charged to be seen as accurate data.\nThe name King Mesha of Moab has been linked to that of Moses. Mesha also is associated with narratives of an exodus and a conquest, and several motifs in stories about him are shared with the Exodus tale and that regarding Israel's war with Moab (2 Kings 3). Moab rebels against oppression, like Moses, leads his people out of Israel, as Moses does from Egypt, and his first-born son is slaughtered at the wall of Kir-hareseth as the firstborn of Israel are condemned to slaughter in the Exodus story, in what Calvinist theologian Peter Leithart described as \"an infernal Passover that delivers Mesha while wrath burns against his enemies\".\nOther Egyptian figures which have been postulated as candidates for a historical Moses-like figure include the princes Ahmose-ankh and Ramose, who were sons of pharaoh Ahmose I, or a figure associated with the family of pharaoh Thutmose III. Israel Knohl has proposed to identify Moses with Irsu, a Shasu who, according to Papyrus Harris I and the Elephantine Stele, took power in Egypt with the support of \"Asiatics\" (people from the Levant) after the death of Queen Twosret; after coming to power, Irsu and his supporters disrupted Egyptian rituals, \"treating the gods like the people\" and halting offerings to the Egyptian deities. They were eventually defeated and expelled by the new Pharaoh Setnakhte and, while fleeing, they abandoned large quantities of gold and silver they had stolen from the temples.\nOsarseph.\nAn Egyptian version of the tale that crosses over with the Moses story is found in Manetho who, according to the summary in Josephus, wrote that a certain Osarseph, a Heliopolitan priest, became overseer of a band of lepers, when Amenophis, following indications by Amenhotep, son of Hapu, had all the lepers in Egypt quarantined in order to cleanse the land so that he might see the gods. The lepers are bundled into Avaris, the former capital of the Hyksos, where Osarseph prescribes for them everything forbidden in Egypt, while proscribing everything permitted in Egypt. They invite the Hyksos to reinvade Egypt, rule with them for 13 years \u2013 Osarseph then assumes the name Moses \u2013 and are then driven out.\nHellenistic literature.\nNon-biblical writings about Jews, with references to the role of Moses, first appear at the beginning of the Hellenistic period, from 323\u00a0BCE to about 146\u00a0BCE. Shmuel notes that \"a characteristic of this literature is the high honour in which it holds the peoples of the East in general and some specific groups among these peoples\".\nIn addition to the Judeo-Roman or Judeo-Hellenic historians Artapanus, Eupolemus, Josephus, and Philo, a few non-Jewish historians, including Hecataeus of Abdera (quoted by Diodorus Siculus), Alexander Polyhistor, Manetho, Apion, Chaeremon of Alexandria, Tacitus and Porphyry also make reference to him. The extent to which any of these accounts rely on earlier sources is unknown. Moses also appears in other religious texts such as the Mishnah (c.\u00a0200\u00a0CE) and the Midrash (200\u20131200\u00a0CE).\nThe figure of Osarseph in Hellenistic historiography is a renegade Egyptian priest who leads an army of lepers against the pharaoh and is finally expelled from Egypt, changing his name to Moses.\nHecataeus.\nThe earliest reference to Moses in Greek literature occurs in the Egyptian history of Hecataeus of Abdera (fourth century BCE). All that remains of his description of Moses are two references made by Diodorus Siculus, wherein, writes historian Arthur Droge, he \"describes Moses as a wise and courageous leader who left Egypt and colonized Judaea\". Among the many accomplishments described by Hecataeus, Moses had founded cities, established a temple and religious cult, and issued laws:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;After the establishment of settled life in Egypt in early times, which took place, according to the mythical account, in the period of the gods and heroes, the first\u00a0... to persuade the multitudes to use written laws was Mneves, a man not only great of soul but also in his life the most public-spirited of all lawgivers whose names are recorded.\nDroge also points out that this statement by Hecataeus was similar to statements made subsequently by Eupolemus.\nArtapanus.\nThe Jewish historian Artapanus of Alexandria (second century\u00a0BCE) portrayed Moses as a cultural hero, alien to the Pharaonic court. According to theologian John Barclay, the Moses of Artapanus \"clearly bears the destiny of the Jews, and in his personal, cultural and military splendor, brings credit to the whole Jewish people\".\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt; Jealousy of Moses' excellent qualities induced Chenephres to send him with unskilled troops on a military expedition to Ethiopia, where he won great victories. After having built the city of Hermopolis, he taught the people the value of the ibis as a protection against the serpents, making the bird the sacred guardian spirit of the city; then he introduced circumcision. After his return to Memphis, Moses taught the people the value of oxen for agriculture, and the consecration of the same by Moses gave rise to the cult of Apis. Finally, after having escaped another plot by killing the assailant sent by the king, Moses fled to Arabia, where he married the daughter of Raguel [Jethro], the ruler of the district.\nArtapanus relates how Moses returns to Egypt with Aaron and is imprisoned but miraculously escapes through the name of YHWH to lead the Exodus. This account further testifies that all Egyptian temples of Isis thereafter contained a rod, in remembrance of that used for Moses' miracles. He describes Moses as 80 years old, \"tall and ruddy, with long white hair, and dignified\".\nSome historians, however, point out the \"apologetic nature of much of Artapanus' work\", with his addition of extra-biblical details, such as his references to Jethro: the non-Jewish Jethro expresses admiration for Moses' gallantry in helping his daughters and chooses to adopt Moses as his son.\nStrabo.\nStrabo, a Greek historian, geographer, and philosopher, in his \"Geographica\" (c.\u00a024\u00a0CE), wrote in detail about Moses, whom he considered to be an Egyptian who deplored the situation in his homeland, and thereby attracted many followers who respected the deity. He writes, for example, that Moses opposed the picturing of the deity in the form of man or animal and was convinced that the deity was an entity that encompassed everything \u2013 land and sea:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\n35. An Egyptian priest named Moses, who possessed a portion of the country called the Lower Egypt, being dissatisfied with the established institutions there, left it and came to Judaea with a large body of people who worshipped the Divinity. He declared and taught that the Egyptians and Africans entertained erroneous sentiments, in representing the Divinity under the likeness of wild beasts and cattle of the field; that the Greeks also were in error in making images of their gods after the human form. For God [said he] may be this one thing which encompasses us all, land and sea, which we call heaven, or the universe, or the nature of things...\n36. By such doctrine Moses persuaded a large body of right-minded persons to accompany him to the place where Jerusalem now stands.\nIn Strabo's writings of the history of Judaism as he understood it, he describes various stages in its development: from the first stage, including Moses and his direct heirs, to the final stage where \"the Temple of Jerusalem continued to be surrounded by an aura of sanctity\". Strabo's \"positive and unequivocal appreciation of Moses' personality is among the most sympathetic in all ancient literature.\" His portrayal of Moses is said to be similar to the writing of Hecataeus who \"described Moses as a man who excelled in wisdom and courage\".\nEgyptologist Jan Assmann concludes that Strabo was the historian \"who came closest to a construction of Moses' religion as monotheistic and as a pronounced counter-religion.\" It recognized \"only one divine being whom no image can represent\u00a0... [and] the only way to approach this god is to live in virtue and in justice.\"\nTacitus.\nThe Roman historian Tacitus (c. 56\u2013120\u00a0CE) refers to Moses by noting that the Jewish religion was monotheistic and without a clear image. His primary work, wherein he describes Jewish philosophy, is his \"Histories\" (c.\u2009100), where, according to the eighteenth-century translator and Irish dramatist Arthur Murphy, as a result of the Jewish worship of one God, \"pagan mythology fell into contempt\". Tacitus states that, despite various opinions current in his day regarding the Jews' ethnicity, most of his sources are in agreement that there was an Exodus from Egypt. By his account, the Pharaoh Bocchoris, suffering from a plague, banished the Jews in response to an oracle of the god Zeus-Amun.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nIn this version, Moses and the Jews wander through the desert for only six days, capturing the Holy Land on the seventh.\nLonginus.\nThe Septuagint, the Greek version of the Hebrew Bible, impressed the pagan author of the famous classical book of literary criticism, \"On the Sublime\", traditionally attributed to Longinus. The date of composition is unknown, but it is commonly assigned to the late first century CE.\nThe writer quotes Genesis in a \"style which presents the nature of the deity in a manner suitable to his pure and great being\", but he does not mention Moses by name, calling him 'no chance person' () but \"the Lawgiver\" (, thesmothete) of the Jews, a term that puts him on a par with Lycurgus and Minos. Aside from a reference to Cicero, Moses is the only non-Greek writer quoted in the work; contextually he is put on a par with Homer, and he is described \"with far more admiration than even Greek writers who treated Moses with respect, such as Hecataeus and Strabo\".\nJosephus.\nIn Josephus' (37 \u2013 c.\u00a0100 CE) \"Antiquities of the Jews\", Moses is mentioned throughout. For example, Book VIII Ch. IV describes Solomon's Temple, also known as the First Temple, at the time the Ark of the Covenant was first moved into the newly built temple:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;When King Solomon had finished these works, these large and beautiful buildings, and had laid up his donations in the temple, and all this in the interval of seven years, and had given a demonstration of his riches and alacrity therein; ... he also wrote to the rulers and elders of the Hebrews, and ordered all the people to gather themselves together to Jerusalem, both to see the temple which he had built, and to remove the ark of God into it; and when this invitation of the whole body of the people to come to Jerusalem was everywhere carried abroad, ... The Feast of Tabernacles happened to fall at the same time, which was kept by the Hebrews as a most holy and most eminent feast. So they carried the ark and the tabernacle which Moses had pitched, and all the vessels that were for ministration to the sacrifices of God, and removed them to the temple. ... Now the ark contained nothing else but those two tables of stone that preserved the ten commandments, which God spake to Moses in Mount Sinai, and which were engraved upon them\u00a0...\nAccording to Feldman, Josephus also attaches particular significance to Moses' possession of the \"cardinal virtues of wisdom, courage, temperance, and justice\". He also includes piety as an added fifth virtue. In addition, he \"stresses Moses' willingness to undergo toil and his careful avoidance of bribery. Like Plato's philosopher-king, Moses excels as an educator.\"\nNumenius.\nNumenius of Apamea, a Greek philosopher who was a native of Apamea, in Syria, wrote during the latter half of the second century\u00a0CE. Historian Kenneth Guthrie writes that \"Numenius is perhaps the only recognized Greek philosopher who explicitly studied Moses, the prophets, and the life of Jesus\". He describes his background:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Numenius was a man of the world; he was not limited to Greek and Egyptian mysteries, but talked familiarly of the myths of Brahmins and Magi. It is however his knowledge and use of the Hebrew scriptures which distinguished him from other Greek philosophers. He refers to Moses simply as \"the prophet\", exactly as for him Homer is the poet. Plato is described as a Greek Moses.\nJustin Martyr.\nThe Christian saint and religious philosopher Justin Martyr (103\u2013165\u00a0CE) drew the same conclusion as Numenius, according to other experts. Theologian Paul Blackham notes that Justin considered Moses to be \"more trustworthy, profound and truthful because he is \"older\" than the Greek philosophers.\" He quotes him:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;I will begin, then, with our first prophet and lawgiver, Moses\u00a0... that you may know that, of all your teachers, whether sages, poets, historians, philosophers, or lawgivers, by far the oldest, as the Greek histories show us, was Moses, who was our first religious teacher.\nAbrahamic religions.\nJudaism.\nMost of what is known about Moses from the Bible comes from the books of Exodus, Leviticus, Numbers, and Deuteronomy. The majority of scholars consider the compilation of these books to go back to the Persian period, 538\u2013332\u00a0BCE, but based on earlier written and oral traditions. There is a wealth of stories and additional information about Moses in the Jewish apocrypha and in the genre of rabbinical exegesis known as Midrash, as well as in the primary works of the Jewish oral law, the Mishnah and the Talmud. Moses is also given a number of bynames in Jewish tradition. The Midrash identifies Moses as one of seven biblical personalities who were called by various names. Moses' other names were Jekuthiel (by his mother), Heber (by his father), Jered (by Miriam), Avi Zanoah (by Aaron), Avi Gedor (by Kohath), Avi Soco (by his wet-nurse), Shemaiah ben Nethanel (by people of Israel). Moses is also attributed the names Toviah (as a first name), and Levi (as a family name) (Vayikra Rabbah 1:3), Heman, Mechoqeiq (lawgiver), and Ehl Gav Ish (Numbers 12:3). In another exegesis, Moses had ascended to the first heaven until the seventh, even visited Paradise and Hell alive, after he saw the divine vision in Mount Horeb.\nJewish historians who lived at Alexandria, such as Eupolemus, attributed to Moses the feat of having taught the Phoenicians their alphabet, similar to legends of Thoth. Artapanus of Alexandria explicitly identified Moses not only with Thoth/Hermes, but also with the Greek figure Musaeus (whom he called \"the teacher of Orpheus\") and ascribed to him the division of Egypt into 36 districts, each with its own liturgy. He named the princess who adopted Moses as Merris, wife of Pharaoh Chenephres.\nJewish tradition considers Moses to be the greatest prophet who ever lived. Despite his importance, Judaism stresses that Moses was a human being, and is therefore not to be worshipped. Only God is worthy of worship in Judaism.\nTo Orthodox Jews, Moses is called \"Moshe Rabbenu, 'Eved HaShem, Avi haNeviim zya\"a\": \"Our Leader Moshe, Servant of God, Father of all the Prophets (may his merit shield us, amen)\". In the orthodox view, Moses received not only the Torah, but also the revealed (written and oral) and the hidden (the \"'hokhmat nistar\") teachings, which gave Judaism the Zohar of the Rashbi, the Torah of the Ari haQadosh and all that is discussed in the Heavenly Yeshiva between the Ramhal and his masters.\nArising in part from his age of death (120 years, according to Deuteronomy 34:7) and that \"his eye had not dimmed, and his vigor had not diminished\", the phrase \"may you live to 120\" has become a common blessing among Jews (120 is stated as the maximum age for all of Noah's descendants in Genesis 6:3).\nChristianity.\nMoses is mentioned more often in the New Testament than any other Old Testament figure. For Christians, Moses is often a symbol of God's law, as reinforced and expounded on in the teachings of Jesus. New Testament writers often compared Jesus' words and deeds with Moses' to explain Jesus' mission. In Acts 7:39\u201343, 51\u201353, for example, the rejection of Moses by the Jews who worshipped the golden calf is likened to the rejection of Jesus by the Jews that continued in traditional Judaism. Comparisons such as these are examples of the interpretive method known as typology, which holds that early biblical figures can be seen as anticipatory prefigures of Jesus Christ. This method is influential in the theology of many branches of Christianity, including Catholicism and Protestantism.\nMoses also figures in several of Jesus' messages. When he met the Pharisee Nicodemus at night in John 3, he compared Moses' lifting up of the bronze serpent in the wilderness, which any Israelite could look at and be healed, to his own lifting up (by his death and resurrection) for the people to look at and be healed. In John 6, Jesus responded to the people's claim that Moses provided them \"manna\" in the wilderness by saying that it was not Moses, but God, who provided. Calling himself the \"bread of life\", Jesus stated that he was provided to feed God's people.\nMoses, along with Elijah, is presented as meeting with Jesus in all three Synoptic Gospels of the Transfiguration of Jesus in Matthew 17, Mark 9, and Luke 9. In Matthew 23, in what is the first attested use of a phrase referring to this rabbinic usage (the Graeco-Aramaic ), Jesus refers to the scribes and the Pharisees, in a passage critical of them, as having seated themselves \"on the chair of Moses\" (, \"ep\u00ec t\u0113s M\u014d\u00fcs\u00e9\u014ds kath\u00e9dras\")\nHis relevance to modern Christianity has not diminished. Moses is considered to be a saint by several churches; and is commemorated as a prophet in the respective Calendars of Saints of the Eastern Orthodox Church, the Roman Catholic Church, and the Lutheran churches on September 4. In Eastern Orthodox liturgics for September 4, Moses is commemorated as the \"Holy Prophet and God-seer Moses, on Mount Nebo\". The Orthodox Church also commemorates him on the Sunday of the Forefathers, two Sundays before the Nativity. Moses is also commemorated on July 20 with Aaron, Elias (Elijah) and Eliseus (Elisha) and on April 14 with all saint Sinai monks.\nThe Armenian Apostolic Church commemorates him as one of the Holy Forefathers in their Calendar of Saints on July 30.\nMormonism.\nMembers of the Church of Jesus Christ of Latter-day Saints (colloquially called Mormons) generally view Moses in the same way that other Christians do. However, in addition to accepting the biblical account of Moses, Mormons include Selections from the Book of Moses as part of their scriptural canon. This book is believed to be the translated writings of Moses and is included in the Pearl of Great Price.\nLatter-day Saints are also unique in believing that Moses was taken to heaven without having tasted death (translated). In addition, Joseph Smith and Oliver Cowdery stated that on April 3, 1836, Moses appeared to them in the Kirtland Temple (located in Kirtland, Ohio) in a glorified, immortal, physical form and bestowed upon them the \"keys of the gathering of Israel from the four parts of the earth, and the leading of the ten tribes from the land of the north\".\nIslam.\nMoses is mentioned more in the Quran than any other individual and his life is narrated and recounted more than that of any other Islamic prophet. In Islam, Moses is characterized in ways which parallel Muhammad. Like Muhammad, Moses is defined in the Quran as both prophet (\"nabi\") and messenger (\"rasul\"), the latter term indicating that he was one of those prophets who brought a book and law to his people.\nMost of the key events in Moses' life which are narrated in the Bible are to be found dispersed through the different chapters (\"suwar\") of the Quran, with a story about meeting the Quranic figure Khidr which is not found in the Bible.\nIn the Moses' story narrated by the Quran, Jochebed is commanded by God to place Moses in a coffin and cast him on the waters of the Nile, thus abandoning him completely to God's protection. The Pharaoh's wife Asiya, not his daughter, found Moses floating in the waters of the Nile. She convinced the Pharaoh to keep him as their son because they were not blessed with any children.\nThe Quran's account emphasizes Moses' mission to invite the Pharaoh to accept God's divine message as well as give salvation to the Israelites. According to the Quran, Moses encourages the Israelites to enter Canaan, but they are unwilling to fight the Canaanites, fearing certain defeat. Moses responds by pleading to Allah that he and his brother Aaron be separated from the rebellious Israelites, after which the Israelites are made to wander for 40 years.\nOne of the hadith, or traditional narratives about Muhammad's life, describes a meeting in heaven between Moses and Muhammad, which resulted in Muslims observing five daily prayers. Huston Smith says this was \"one of the crucial events in Muhammad's life\".\nAccording to some Islamic tradition, Moses is buried at Maqam El-Nabi Musa, near Jericho.\nBah\u00e1\u02bc\u00ed Faith.\nMoses is one of the most important of God's messengers in the Bah\u00e1\u02bc\u00ed Faith, being designated a Manifestation of God. An epithet of Moses in Bah\u00e1\u02bc\u00ed scriptures is the \"One Who Conversed with God\".\nAccording to the Bah\u00e1\u02bc\u00ed Faith, Bah\u00e1'u'll\u00e1h, the founder of the faith, is the one who spoke to Moses from the burning bush.\n\u02bbAbdu'l-Bah\u00e1 has highlighted the fact that Moses, like Abraham, had none of the makings of a great man of history, but through God's assistance he was able to achieve many great things. He is described as having been \"for a long time a shepherd in the wilderness\", of having had a stammer, and of being \"much hated and detested\" by Pharaoh and the ancient Egyptians of his time. He is said to have been raised in an oppressive household, and to have been known, in Egypt, as a man who had committed murder \u2013 though he had done so in order to prevent an act of cruelty.\nNevertheless, like Abraham, through the assistance of God, he achieved great things and gained renown even beyond the Levant. Chief among these achievements was the freeing of his people, the Hebrews, from bondage in Egypt and leading \"them to the Holy Land\". He is viewed as the one who bestowed on Israel \"the religious and the civil law\" which gave them \"honour among all nations\", and which spread their fame to different parts of the world.\nFurthermore, through the law, Moses is believed to have led the Hebrews \"to the highest possible degree of civilization at that period\". 'Abdul'l-Bah\u00e1 asserts that the ancient Greek philosophers regarded \"the illustrious men of Israel as models of perfection\". Chief among these philosophers, he says, was Socrates who \"visited Syria, and took from the children of Israel the teachings of the Unity of God and of the immortality of the soul\".\nMoses is further seen as paving the way for Bah\u00e1'u'll\u00e1h and his ultimate revelation, and as a teacher of truth, whose teachings were in line with the customs of his time.\nDruze faith.\nMoses is considered an important prophet of God in the Druze faith, being among the seven prophets who appeared in different periods of history.\nLegacy in politics and law.\nIn a metaphorical sense in the Christian tradition, a \"Moses\" has been referred to as the leader who delivers the people from a terrible situation. Among the Presidents of the United States known to have used the symbolism of Moses were Harry S. Truman, Jimmy Carter, Ronald Reagan, Bill Clinton, George W. Bush and Barack Obama, who referred to his supporters as \"the Moses generation\".\nIn subsequent years, theologians linked the Ten Commandments with the formation of early democracy. Scottish theologian William Barclay described them as \"the universal foundation of all things\u00a0... the law without which nationhood is impossible. ... Our society is founded upon it.\" Pope Francis addressed the United States Congress in 2015 stating that all people need to \"keep alive their sense of unity by means of just legislation\u00a0... [and] the figure of Moses leads us directly to God and thus to the transcendent dignity of the human being\".\nIn United States history.\nPilgrims.\nReferences to Moses were used by the Puritans, who relied on the story of Moses to give meaning and hope to the lives of Pilgrims seeking religious and personal freedom in North America. John Carver was the first governor of Plymouth Colony and first signer of the Mayflower Compact, which he wrote in 1620 during the ship \"Mayflower\"'s three-month voyage. He inspired the Pilgrims with a \"sense of earthly grandeur and divine purpose\", notes historian Jon Meacham, and was called the \"Moses of the Pilgrims\". Early American writer James Russell Lowell noted the similarity of the founding of America by the Pilgrims to that of ancient Israel by Moses:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Next to the fugitives whom Moses led out of Egypt, the little shipload of outcasts who landed at Plymouth are destined to influence the future of the world. The spiritual thirst of mankind has for ages been quenched at Hebrew fountains; but the embodiment in human institutions of truths uttered by the Son of Man eighteen centuries ago was to be mainly the work of Puritan thought and Puritan self-devotion. ... If their municipal regulations smack somewhat of Judaism, yet there can be no nobler aim or more practical wisdom than theirs; for it was to make the law of man a living counterpart of the law of God, in their highest conception of it.\nFollowing Carver's death the following year, William Bradford was made governor. He feared that the remaining Pilgrims would not survive the hardships of the new land, with half their people having already died within months of arriving. Bradford evoked the symbol of Moses to the weakened and desperate Pilgrims to help calm them and give them hope: \"Violence will break all. Where is the meek and humble spirit of Moses?\" William G. Dever explains the attitude of the Pilgrims: \"We considered ourselves the 'New Israel', particularly we in America. And for that reason, we knew who we were, what we believed in and valued, and what our 'manifest destiny' was.\"\nFounding Fathers of the United States.\nOn July 4, 1776, immediately after the Declaration of Independence was officially passed, the Continental Congress asked John Adams, Thomas Jefferson, and Benjamin Franklin to design a seal that would clearly represent a symbol for the new United States. They chose the symbol of Moses leading the Israelites to freedom.\nAfter the death of George Washington in 1799, two thirds of his eulogies referred to him as \"America's Moses\", with one orator saying that \"Washington has been the same to us as Moses was to the Children of Israel.\"\nBenjamin Franklin, in 1788, saw the difficulties that some of the newly independent American states were having in forming a government, and proposed that until a new code of laws could be agreed to, they should be governed by \"the laws of Moses\", as contained in the Old Testament. He justified his proposal by explaining that the laws had worked in biblical times: \"The Supreme Being\u00a0... having rescued them from bondage by many miracles, performed by his servant Moses, he personally delivered to that chosen servant, in the presence of the whole nation, a constitution and code of laws for their observance.\"\nJohn Adams, the second president of the United States, stated why he relied on the laws of Moses over Greek philosophy for establishing the United States Constitution: \"As much as I love, esteem, and admire the Greeks, I believe the Hebrews have done more to enlighten and civilize the world. Moses did more than all their legislators and philosophers.\" Swedish historian Hugo Valentin credited Moses as the \"first to proclaim the rights of man\".\nSlavery and civil rights.\nUnderground Railroad conductor and American Civil War veteran Harriet Tubman was nicknamed \"Moses\" due to her various missions in freeing and ferrying escaped enslaved persons to freedom in the free states of the United States.\nHistorian Gladys L. Knight describes how leaders who emerged during and after the period in which slavery was legal often personified the Moses symbol. \"The symbol of Moses was empowering in that it served to amplify a need for freedom.\" Therefore, when Abraham Lincoln was assassinated in 1865 after the passage of the amendment to the Constitution outlawing slavery, Black Americans said they had lost \"their Moses\". Lincoln biographer Charles Carleton Coffin writes, \"The millions whom Abraham Lincoln delivered from slavery will ever liken him to Moses, the deliverer of Israel.\"\nMartin Luther King Jr., a leader of the civil rights movement during the 1960s, was called \"a modern Moses\", and often referred to Moses in his speeches: \"The struggle of Moses, the struggle of his devoted followers as they sought to get out of Egypt. This is something of the story of every people struggling for freedom.\"\nCultural portrayals and references.\nArt.\nMoses often appears in Christian art, and the Pope's private chapel, the Sistine Chapel, has a large sequence of six frescos of the \"life of Moses\" on the southern wall, opposite a set with the \"Life of Christ\". They were painted in 1481\u201382 by a group of mostly Florentine artists including Sandro Botticelli and Pietro Perugino.\nBecause of an ambiguity in the Hebrew word \u05e7\u05b6\u05e8\u05b6\u05df (keren) meaning both horn and ray or beam, in Jerome's Latin Vulgate translation of the Bible Moses' face is described as (\"horned\") when descending from Mount Sinai with the tablets, Moses is usually shown in Western art until the Renaissance with small horns, which at least served as a convenient identifying attribute. In at least some of these depictions, an antisemitic meaning is likely to have been intended, for example on the Hereford Mappa Mundi.\nWith the prophet Elijah, he is a necessary figure in the Transfiguration of Jesus in Christian art, a subject with a long history in Eastern Orthodox art. It appears in the art of the Western Church from the tenth century, and was especially popular between about 1475 and 1535.\nMichelangelo's statue.\nMichelangelo's statue of Moses (1513\u20131515), in the Church of San Pietro in Vincoli, Rome, is one of the most familiar statues in the world. The horns the sculptor included on Moses' head are the result of a mistranslation of the Hebrew Bible into the Latin Vulgate Bible with which Michelangelo was familiar. The Hebrew word taken from \"Exodus\" means either a \"horn\" or an \"irradiation\". Experts at the Archaeological Institute of America show that the term was used when Moses \"returned to his people after seeing as much of the Glory of the Lord as human eye could stand\", and his face \"reflected radiance\". In early Jewish art, moreover, Moses is often \"shown with rays coming out of his head\".\nDepiction on U.S. government buildings.\nMoses is depicted in several U.S. government buildings because of his legacy as a lawgiver. In the Library of Congress stands a large statue of Moses alongside a statue of Paul the Apostle. Moses is one of the twenty-three lawgivers depicted in marble bas-reliefs in the chamber of the U.S. House of Representatives in the United States Capitol. The plaque's overview states: \"Moses (c.\u00a01350\u20131250\u00a0B.C.) Hebrew prophet and lawgiver; transformed a wandering people into a nation; received the Ten Commandments.\"\nThe other 22 figures have their profiles turned to Moses, which is the only forward-facing bas-relief.\nMoses appears eight times in carvings that ring the Supreme Court Great Hall ceiling. His face is presented along with other ancient figures such as Solomon, the Greek god Zeus, and the Roman goddess of wisdom, Minerva. The Supreme Court Building's east pediment depicts Moses holding two tablets. Tablets representing the Ten Commandments can be found carved in the oak courtroom doors, on the support frame of the courtroom's bronze gates, and in the library woodwork. A controversial image is one that sits directly above the Chief Justice of the United States' head. In the center of the Spanish marble carving is a tablet displaying Roman numerals I through X, with some numbers partially hidden.\nCriticism of Moses.\nIn the late eighteenth century, the deist Thomas Paine commented at length on Moses' Laws in \"The Age of Reason\" (1794, 1795, and 1807). Paine considered Moses to be a \"detestable villain\", and cited Numbers 31 as an example of his \"unexampled atrocities\". In the passage, after the Israelite army returned from conquering Midian, Moses orders the killing of the Midianites with the exception of the virgin girls who were to be kept for the Israelites.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Have ye saved all the women alive? behold, these caused the children of Israel, through the counsel of Balaam, to commit trespass against the Lord in the matter of Peor, and there was a plague among the congregation of the Lord. Now, therefore, kill every male among the little ones, and kill every woman that hath known a man by lying with him; but all the women-children, that have not known a man by lying with him, keep alive for yourselves.\u2014\u200a\nRabbi Joel Grossman argued that the story is a \"powerful fable of lust and betrayal\", and that Moses' execution of the women was a symbolic condemnation of those who seek to turn sex and desire to evil purposes. He says that the Midianite women \"used their sexual attractiveness to turn the Israelite men away from [Yahweh] God and toward the worship of Baal Peor [another Canaanite god]\". Rabbi Grossman argues that the genocide of all the Midianite non-virgin women, including those that did not seduce Jewish men, was fair because some of them had sex for \"improper reasons\". Alan Levin, an educational specialist with the Reform movement, has similarly suggested that the story should be taken as a cautionary tale, to \"warn successive generations of Jews to watch their own idolatrous behavior\". Chasam Sofer emphasizes that this war was not fought at Moses' behest, but was commanded by God as an act of revenge against the Midianite women, who, according to the Biblical account, had seduced the Israelites and led them to sin. Linguist Keith Allan remarked: \"God's work or not, this is military behaviour that would be tabooed today and might lead to a war crimes trial.\"\nMoses has also been the subject of much feminist criticism. Womanist Biblical scholar Nyasha Junior has argued that Moses can be the object of feminist inquiry.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "19579", "revid": "31256549", "url": "https://en.wikipedia.org/wiki?curid=19579", "title": "Mississippi River", "text": "Major river in the United States\nThe Mississippi River is the primary river of the largest drainage basin in the United States. It is the second-longest river in the United States, behind only the Missouri. From its traditional source of Lake Itasca in northern Minnesota, it flows generally south for to the Mississippi River Delta in the Gulf of Mexico. With its many tributaries, the Mississippi's watershed drains all or parts of 32 U.S. states and two Canadian provinces between the Rocky and Appalachian mountains. The river either borders or passes through the states of Minnesota, Wisconsin, Iowa, Illinois, Missouri, Kentucky, Tennessee, Arkansas, Mississippi, and Louisiana. The main stem is entirely within the United States; the total drainage basin is , of which only about one percent is in Canada. The Mississippi ranks as the world's tenth-largest river by discharge flow, and the largest in North America.\nNative Americans have lived along the Mississippi River and its tributaries for thousands of years. Many were hunter-gatherers, but some, such as the Mound Builders, formed prolific agricultural and urban civilizations, and some practiced aquaculture. The arrival of Europeans in the 16th century changed the native way of life as first explorers, then settlers, ventured into the basin in increasing numbers. The river served sometimes as a barrier, forming borders for New Spain, New France, and the early United States, and throughout as a vital transportation artery and communications link. In the 19th century, during the height of the ideology of manifest destiny, the Mississippi and several tributaries, most notably its largest, the Ohio and Missouri, formed pathways for the western expansion of the United States. The river also became the subject of American literature, particularly in the writings of Mark Twain.\nFormed from thick layers of the river's silt deposits, the Mississippi embayment, and American Bottom are some of the most fertile regions of the United States; steamboats were widely used in the 19th and early 20th centuries to ship agricultural and industrial goods. During the American Civil War, the Mississippi's final capture by Union forces marked a turning point to victory for the Union. Because of the substantial growth of cities and the larger ships and barges that replaced steamboats, the first decades of the 20th century saw the construction of massive engineering works such as levees, locks and dams, often built in combination. A major focus of this work has been to prevent the lower Mississippi from shifting into the channel of the Atchafalaya River and bypassing New Orleans.\nSince the 20th century, the Mississippi River has also experienced major pollution and environmental problems, most notably elevated nutrient and chemical levels from agricultural runoff, the primary contributor to the Gulf of Mexico dead zone.\nName and significance.\nThe word Mississippi itself comes from , the French rendering of the Anishinaabe (Ojibwe or Algonquin) name for the river, (Great River).\nIn the 18th century, the river was set by the Treaty of Paris as, for the most part, the western border of the new United States. With the Louisiana Purchase and the country's westward expansion, it became a convenient boundary line between the western and eastern halves of the country. This is reflected in the Gateway Arch in St. Louis, which was designed to symbolize the opening of the West, and the focus on the \"Trans-Mississippi\" region in the Trans-Mississippi Exposition.\nRegional landmarks are often classified in relation to the river, such as \"the highest peak east of the Mississippi\" or \"the oldest city west of the Mississippi\". The FCC also uses it as the dividing line for broadcast call-signs, which begin with W to the east and K to the west, overlapping in media markets along the river.\nDue to its size and importance, it has been nicknamed The Mighty Mississippi River or simply The Mighty Mississippi.\nDivisions.\nThe Mississippi River can be divided into three sections: the Upper Mississippi, the river from its headwaters to the confluence with the Missouri River; the Middle Mississippi, which is downriver from the Missouri to the Ohio River; and the Lower Mississippi, which flows from the Ohio to the Gulf of Mexico.\nUpper Mississippi.\nThe Upper Mississippi runs from its headwaters to its confluence with the Missouri River at St. Louis, Missouri. It is divided into two sections:\nThe source of the Upper Mississippi branch is traditionally accepted as Lake Itasca, above sea level in Itasca State Park in Clearwater County, Minnesota. The name \"Itasca\" was chosen to designate the \"true head\" of the Mississippi River as a combination of the last four letters of the Latin word for truth () and the first two letters of the Latin word for head (). However, the lake is in turn fed by a number of smaller streams.\nFrom its origin at Lake Itasca to St. Louis, Missouri, the waterway's flow is moderated by 43 dams. Fourteen of these dams are located above Minneapolis in the headwaters region and serve multiple purposes, including power generation and recreation. The remaining 29 dams, beginning in downtown Minneapolis, all contain locks and were constructed to improve commercial navigation of the upper river. Taken as a whole, these 43 dams significantly shape the geography and influence the ecology of the upper river. Beginning just below Saint Paul, Minnesota, and continuing throughout the upper and lower river, the Mississippi is further controlled by thousands of wing dikes that moderate the river's flow in order to maintain an open navigation channel and prevent the river from eroding its banks.\nThe head of navigation on the Mississippi is the St. Anthony Falls Lock. Before the Coon Rapids Dam in Coon Rapids, Minnesota, was built in 1913, steamboats could occasionally go upstream as far as Saint Cloud, Minnesota, depending on river conditions.\nThe uppermost lock and dam on the Upper Mississippi River is the Upper St. Anthony Falls Lock and Dam in Minneapolis. Above the dam, the river's elevation is . Below the dam, the river's elevation is . This drop is the largest of all the Mississippi River locks and dams. The origin of the dramatic drop is a waterfall preserved adjacent to the lock under an apron of concrete. Saint Anthony Falls is the only true waterfall on the entire Mississippi River. The water elevation continues to drop steeply as it passes through the gorge carved by the waterfall.\nAfter the completion of the St. Anthony Falls Lock and Dam in 1963, the river's head of navigation moved upstream, to the Coon Rapids Dam. However, the Locks were closed in 2015 to control the spread of invasive Asian carp, making Minneapolis once again the site of the head of navigation of the river.\nThe Upper Mississippi has a number of natural and artificial lakes, with its widest point being Lake Winnibigoshish, near Grand Rapids, Minnesota, over across. Lake Onalaska, created by Lock and Dam No. 7, near La Crosse, Wisconsin, is more than wide. Lake Pepin, a natural lake formed behind the delta of the Chippewa River of Wisconsin as it enters the Upper Mississippi, is more than wide.\nBy the time the Upper Mississippi reaches Saint Paul, Minnesota, below Lock and Dam No. 1, it has dropped more than half its original elevation and is above sea level. From St. Paul to St. Louis, Missouri, the river elevation falls much more slowly and is controlled and managed as a series of pools created by 26 locks and dams.\nThe Upper Mississippi River is joined by the Minnesota River at Fort Snelling in the Twin Cities; the St. Croix River near Prescott, Wisconsin; the Cannon River near Red Wing, Minnesota; the Zumbro River at Wabasha, Minnesota; the Black, La Crosse, and Root rivers in La Crosse, Wisconsin; the Wisconsin River at Prairie du Chien, Wisconsin; the Rock River at the Quad Cities; the Iowa River near Wapello, Iowa; the Skunk River south of Burlington, Iowa; and the Des Moines River at Keokuk, Iowa. Other major tributaries of the Upper Mississippi include the Crow River in Minnesota, the Chippewa River in Wisconsin, the Maquoketa River and the Wapsipinicon River in Iowa, and the Illinois River in Illinois.\nThe Upper Mississippi is largely a multi-thread stream with many bars and islands. From its confluence with the St. Croix River downstream to Dubuque, Iowa, the river is entrenched, with high bedrock bluffs lying on either side. The height of these bluffs decreases to the south of Dubuque, though they are still significant through Savanna, Illinois. This topography contrasts strongly with the Lower Mississippi, which is a meandering river in a broad, flat area, only rarely flowing alongside a bluff (as at Vicksburg, Mississippi).\nMiddle Mississippi.\nThe Mississippi River is known as the Middle Mississippi from the Upper Mississippi River's confluence with the Missouri River at St. Louis, Missouri, for to its confluence with the Ohio River at Cairo, Illinois.\nThe Middle Mississippi is relatively free-flowing. From St. Louis to the Ohio River confluence, the Middle Mississippi falls over for an average rate of . At its confluence with the Ohio River, the Middle Mississippi is above sea level. Apart from the Missouri and Meramec rivers of Missouri and the Kaskaskia River of Illinois, no major tributaries enter the Middle Mississippi River.\nLower Mississippi.\nThe Mississippi River is called the Lower Mississippi River from its confluence with the Ohio River to its mouth at the Gulf of Mexico, a distance of about . At the confluence of the Ohio and the Middle Mississippi, the long-term mean discharge of the Ohio at Cairo, Illinois is , while the long-term mean discharge of the Mississippi at Thebes, Illinois (just upriver from Cairo) is . Thus, by volume, the main branch of the Mississippi River system at Cairo can be considered to be the Ohio River (and the Allegheny River further upstream), rather than the Middle Mississippi.\nIn addition to the Ohio River, the major tributaries of the Lower Mississippi River are the White River, flowing in at the White River National Wildlife Refuge in east-central Arkansas; the Arkansas River, joining the Mississippi at Arkansas Post; the Big Black River in Mississippi; and the Yazoo River, meeting the Mississippi at Vicksburg, Mississippi.\nDeliberate water diversion at the Old River Control Structure in Louisiana allows the Atchafalaya River in Louisiana to be a major distributary of the Mississippi River, with 30% of the combined flow of the Mississippi and Red Rivers flowing to the Gulf of Mexico by this route, rather than continuing down the Mississippi's current channel past Baton Rouge and New Orleans on a longer route to the Gulf. Although the Red River was once an additional tributary, its water now flows separately into the Gulf of Mexico through the Atchafalaya River.\nWatershed.\nThe Mississippi River has the world's fourth-largest drainage basin (\"watershed\" or \"catchment\"). The basin covers more than , including all or parts of 32 U.S. states and two Canadian provinces. The drainage basin empties into the Gulf of Mexico, part of the Atlantic Ocean. The total catchment of the Mississippi River covers nearly 40% of the landmass of the continental United States. The highest point within the watershed is also the highest point of the Rocky Mountains, Mount Elbert at .\nIn the United States, the Mississippi River drains the majority of the area between the crest of the Rocky Mountains and the crest of the Appalachian Mountains, except for various regions drained to Hudson Bay by the Red River of the North; to the Atlantic Ocean by the Great Lakes and the Saint Lawrence River; and to the Gulf of Mexico by the Rio Grande, the Alabama and Tombigbee rivers, the Chattahoochee and Appalachicola rivers, and various smaller coastal waterways along the Gulf.\nThe Mississippi River empties into the Gulf of Mexico about downstream from New Orleans. Measurements of the length of the Mississippi from Lake Itasca to the Gulf of Mexico vary somewhat, but the United States Geological Survey's number is . The retention time from Lake Itasca to the Gulf is typically about 90 days; while speed varies along the course of the river, this gives an overall average of around per day, or per hour.\nThe stream gradient of the entire river is 0.01%, a drop of 450 m over 3,766\u00a0km.\nOutflow.\nThe Mississippi River discharges at an annual average rate of between . The Mississippi is the fourteenth largest river in the world by volume. On average, the Mississippi has 8% the flow of the Amazon River,\nwhich moves nearly during wet seasons.\nBefore 1900, the Mississippi River transported an estimated of sediment per year from the interior of the United States to coastal Louisiana and the Gulf of Mexico. During the last two decades, this number was only per year. The reduction in sediment transported down the Mississippi River is the result of engineering modification of the Mississippi, Missouri, and Ohio rivers and their tributaries by dams, meander cutoffs, river-training structures, and bank revetments and soil erosion control programs in the areas drained by them.\nMixing with salt water.\nDenser salt water from the Gulf of Mexico forms a salt wedge along the river bottom near the mouth of the river, while fresh water flows near the surface. In drought years, with less fresh water to push it out, salt water can travel many miles upstream\u2014 in 2022\u2014contaminating drinking water supplies and requiring the use of desalination. The United States Army Corps of Engineers constructed \"saltwater sills\" or \"underwater levees\" to contain this in 1988, 1999, 2012, and 2022. This consists of a large mound of sand spanning the width of the river 55 feet below the surface, allowing fresh water and large cargo ships to pass over.\nFresh river water flowing from the Mississippi into the Gulf of Mexico does not mix into the salt water immediately. The images from NASA's MODIS show a large plume of fresh water, which appears as a dark ribbon against the lighter-blue surrounding waters. These images demonstrate that the plume did not mix with the surrounding sea water immediately. Instead, it stayed intact as it flowed through the Gulf of Mexico, into the Straits of Florida, and entered the Gulf Stream. The Mississippi River water rounded the tip of Florida and traveled up the southeast coast to the latitude of Georgia before finally mixing in so thoroughly with the ocean that it could no longer be detected by MODIS.\nCourse changes.\nOver geologic time, the Mississippi River has experienced numerous large and small changes to its main course, as well as additions, deletions, and other changes among its numerous tributaries, and the lower Mississippi River has used different pathways as its main channel to the Gulf of Mexico across the delta region.\nAs Pangaea began to break up about 95 million years ago, North America passed over a volcanic \"hotspot\" in the Earth's mantle (specifically, the Bermuda hotspot) that was undergoing a period of intense activity. The upwelling of magma from the hotspot forced the further uplift to a height of perhaps 2\u20133\u00a0km of part of the Appalachian-Ouachita range, forming an arch that blocked southbound water flows. The uplifted land quickly eroded and, as North America moved away from the hot spot and as the hotspot's activity declined, the crust beneath the embayment region cooled, contracted and subsided to a depth of 2.6\u00a0km, and around 80 million years ago the Reelfoot Rift formed a trough that was flooded by the Gulf of Mexico. As sea levels dropped, the Mississippi and other rivers extended their courses into the embayment, which gradually became filled with sediment with the Mississippi River at its center.\nThrough a natural process known as avulsion or delta switching, the lower Mississippi River has shifted its final course to the mouth of the Gulf of Mexico every thousand years or so. This occurs because the deposits of silt and sediment begin to clog its channel, raising the river's level and causing it to eventually find a steeper, more direct route to the Gulf of Mexico. The abandoned distributaries diminish in volume and form what are known as bayous. This process has, over the past 5,000 years, caused the coastline of south Louisiana to advance toward the Gulf from . The currently active delta lobe is called the Birdfoot Delta, after its shape, or the Balize Delta, after La Balize, Louisiana, the first French settlement at the mouth of the Mississippi.\nPrehistoric courses.\nThe current form of the Mississippi River basin was largely shaped by the Laurentide Ice Sheet of the most recent Ice Age. The southernmost extent of this enormous glaciation extended well into the present-day United States and Mississippi basin. When the ice sheet began to recede, hundreds of feet of rich sediment were deposited, creating the flat and fertile landscape of the Mississippi Valley. During the melt, giant glacial rivers found drainage paths into the Mississippi watershed, creating such features as the Minnesota River, James River, and Milk River valleys. When the ice sheet completely retreated, many of these \"temporary\" rivers found paths to Hudson Bay or the Arctic Ocean, leaving the Mississippi Basin with many features \"over-sized\" for the existing rivers to have carved in the same time period.\nIce sheets during the Illinoian Stage, about 300,000 to 132,000 years before present, blocked the Mississippi near Rock Island, Illinois, diverting it to its present channel farther to the west, the current western border of Illinois. The Hennepin Canal roughly follows the ancient channel of the Mississippi downstream from Rock Island to Hennepin, Illinois. South of Hennepin, to Alton, Illinois, the current Illinois River follows the ancient channel used by the Mississippi River before the Illinoian Stage.\nTimeline of outflow course changes\nHistoric course changes.\nIn March 1876, the Mississippi suddenly changed course near the settlement of Reverie, Tennessee, leaving a small part of Tipton County, Tennessee, attached to Arkansas and separated from the rest of Tennessee by the new river channel. Since this event was an avulsion, rather than the effect of incremental erosion and deposition, the state line still follows the old channel.\nThe town of Kaskaskia, Illinois once stood on a peninsula at the confluence of the Mississippi and Kaskaskia (Okaw) Rivers. Founded as a French colonial community, it later became the capital of the Illinois Territory and was the first state capital of Illinois until 1819. Beginning in 1844, successive flooding caused the Mississippi River to slowly encroach east. A major flood in 1881 caused it to overtake the lower of the Kaskaskia River, forming a new Mississippi channel and cutting off the town from the rest of the state. Later flooding destroyed most of the remaining town, including the original State House. Today, the remaining island and community of 14 residents is known as an enclave of Illinois and is accessible only from the Missouri side.\nNew Madrid Seismic Zone.\nThe New Madrid Seismic Zone, along the Mississippi River near New Madrid, Missouri, between Memphis and St. Louis, is related to an aulacogen (failed rift) that formed at the same time as the Gulf of Mexico. This area is still quite active seismically. Four great earthquakes in 1811 and 1812, estimated at 8 on the Richter magnitude scale, had tremendous local effects in the then sparsely settled area, and were felt in many other places in the Midwestern and eastern U.S. These earthquakes created Reelfoot Lake in Tennessee from the altered landscape near the river.\nLength.\nWhen measured from its traditional source at Lake Itasca, the Mississippi has a length of . When measured from its longest stream source (most distant source from the sea), Brower's Spring in Montana, the source of the Missouri River, it has a length of , making it the fourth longest river in the world after the Nile, Amazon, and Yangtze. When measured by the largest stream source (by water volume), the Ohio River, by extension the Allegheny River, would be the source, and the Mississippi would begin in Pennsylvania.\nDepth.\nAt its source at Lake Itasca, the Mississippi River is about deep. The average depth of the Mississippi River between Saint Paul and Saint Louis is between deep, the deepest part being Lake Pepin, which averages deep and has a maximum depth of . Between where the Missouri River joins the Mississippi at Saint Louis, Missouri, and Cairo, Illinois, the depth averages . Below Cairo, where the Ohio River joins, the depth averages deep. The deepest part of the river is in New Orleans, where it reaches deep.\nCultural geography.\nState boundaries.\nThe Mississippi River runs through or along 10 states, from Minnesota to Louisiana, and is used to define portions of these states' borders, with Wisconsin, Illinois, Kentucky, Tennessee, and Mississippi along the east side of the river, and Iowa, Missouri, and Arkansas along its west side. Substantial parts of both Minnesota and Louisiana are on either side of the river, although the Mississippi defines part of the boundary of each of these states.\nIn all of these cases, the middle of the riverbed at the time the borders were established was used as the line to define the borders between adjacent states. In various areas, the river has since shifted, but the state borders have not changed, still following the former bed of the Mississippi River as of their establishment, leaving several small isolated areas of one state across the new river channel, contiguous with the adjacent state. Also, due to a meander in the river, a small part of western Kentucky is contiguous with Tennessee but isolated from the rest of its state.\nAll communities along the river.\nNotable communities listed from the source at Lake Itasca to the mouth the Mississippi Delta.\nBridge crossings.\nThe road crossing highest on the Upper Mississippi is a simple steel culvert, through which the river (locally named \"Nicolet Creek\") flows north from Lake Nicolet under \"Wilderness Road\" to the West Arm of Lake Itasca, within Itasca State Park.\nThe earliest bridge across the Mississippi River was built in 1855. It spanned the river in Minneapolis where the current Hennepin Avenue Bridge is located. No highway or railroad tunnels cross under the Mississippi River.\nThe first railroad bridge across the Mississippi was built in 1856. It spanned the river between the Rock Island Arsenal in Illinois and Davenport, Iowa. Steamboat captains of the day, fearful of competition from the railroads, considered the new bridge a hazard to navigation. Two weeks after the bridge opened, the steamboat \"Effie Afton\" rammed part of the bridge, setting it on fire. Legal proceedings ensued, with Abraham Lincoln defending the railroad. The lawsuit went to the Supreme Court of the United States, which ruled in favor of the railroad.\nBelow is a general overview of selected Mississippi bridges that have notable engineering or landmark significance, with their cities or locations. They are sequenced from the Upper Mississippi's source to the Lower Mississippi's mouth.\nNavigation and flood control.\nA clear channel is needed for the barges and other vessels that make the main stem Mississippi one of the great commercial waterways of the world. The task of maintaining a navigation channel is the responsibility of the United States Army Corps of Engineers, which was established in 1802. Earlier projects began as early as 1829 to remove snags, close off secondary channels and excavate rocks and sandbars.\nThe upper backwaters of the Mississippi normally freeze over by December, while the main channel freezes over only in the coldest years, historically as far south as St. Louis.\nA series of 29 locks and dams on the upper Mississippi, most of which were built in the 1930s, is designed primarily to maintain a channel for commercial barge traffic. The lakes formed are also used for recreational boating and fishing. The dams make the river deeper and wider but do not stop it. No flood control is intended. During periods of high flow, the gates, some of which are submersible, are completely opened and the dams simply cease to function. Below St. Louis, the Mississippi is relatively free-flowing, although it is constrained by numerous levees and directed by numerous wing dams. The scope and scale of the levees, built along either side of the river to keep it on its course, has often been compared to the Great Wall of China.\nOn the lower Mississippi, from Baton Rouge to the mouth of the Mississippi, the navigation depth is , allowing container ships and cruise ships to dock at the Port of New Orleans and bulk cargo ships shorter than air draft that fit under the Huey P. Long Bridge to traverse the Mississippi to Baton Rouge. There is a feasibility study to dredge this portion of the river to to allow New Panamax ship depths.\n19th century.\nIn 1829, there were surveys of the two major obstacles on the upper Mississippi, the Des Moines Rapids and the Rock Island Rapids, where the river was shallow and the riverbed was rock. The Des Moines Rapids were about long and just above the mouth of the Des Moines River at Keokuk, Iowa. The Rock Island Rapids were between Rock Island and Moline, Illinois. Both rapids were considered virtually impassable.\nIn 1848, the Illinois and Michigan Canal was built to connect the Mississippi River to Lake Michigan via the Illinois River near Peru, Illinois. The canal allowed shipping between these important waterways. In 1900, the canal was replaced by the Chicago Sanitary and Ship Canal. The second canal, in addition to shipping, also allowed Chicago to address specific health issues (typhoid fever, cholera and other waterborne diseases) by sending its waste down the Illinois and Mississippi river systems rather than polluting its water source of Lake Michigan.\nThe Corps of Engineers recommended the excavation of a channel at the Des Moines Rapids, but work did not begin until after Lieutenant Robert E. Lee endorsed the project in 1837. The Corps later also began excavating the Rock Island Rapids. By 1866, it had become evident that excavation was impractical, and it was decided to build a canal around the Des Moines Rapids. The canal opened in 1877, but the Rock Island Rapids remained an obstacle. In 1878, Congress authorized the Corps to establish a channel to be obtained by building wing dams that direct the river to a narrow channel causing it to cut a deeper channel, by closing secondary channels and by dredging. The channel project was complete when the Moline Lock, which bypassed the Rock Island Rapids, opened in 1907.\nTo improve navigation between St. Paul, Minnesota, and Prairie du Chien, Wisconsin, the Corps constructed several dams on lakes in the headwaters area, including Lake Winnibigoshish and Lake Pokegama. The dams, which were built beginning in the 1880s, stored spring run-off which was released during low water to help maintain channel depth.\n20th century.\nIn 1907, Congress authorized a channel project on the Mississippi River, which was not complete when it was abandoned in the late 1920s in favor of the channel project.\nIn 1913, construction was complete on Lock and Dam No. 19 at Keokuk, Iowa, the first dam below St. Anthony Falls. Built by a private power company (Union Electric Company of St. Louis) to generate electricity (originally for streetcars in St. Louis), the Keokuk dam was one of the largest hydro-electric plants in the world at the time. The dam also eliminated the Des Moines Rapids. Lock and Dam No. 1 was completed in Minneapolis, Minnesota in 1917. Lock and Dam No. 2, near Hastings, Minnesota, was completed in 1930.\nBefore the Great Mississippi Flood of 1927, the Corps's primary strategy was to close off as many side channels as possible to increase the flow in the main river. It was thought that the river's velocity would scour off bottom sediments, deepening the river and decreasing the possibility of flooding. The 1927 flood proved this to be so wrong that communities threatened by the flood began to create their own levee breaks to relieve the force of the rising river.\nThe Rivers and Harbors Act of 1930 authorized the channel project, which called for a navigation channel feet deep and wide to accommodate multiple-barge tows. This was achieved by a series of locks and dams, and by dredging. Twenty-three new locks and dams were built on the upper Mississippi in the 1930s in addition to the three already in existence.\nUntil the 1950s, there was no dam below Lock and Dam 26 at Alton, Illinois. Chain of Rocks Lock (Lock and Dam No. 27), which consists of a low-water dam and an canal, was added in 1953, just below the confluence with the Missouri River, primarily to bypass a series of rock ledges at St. Louis. It also serves to protect the St. Louis city water intakes during times of low water.\nU.S. government scientists determined in the 1950s that the Mississippi River was starting to switch to the Atchafalaya River channel because of its much steeper path to the Gulf of Mexico. Eventually, the Atchafalaya River would capture the Mississippi River and become its main channel to the Gulf of Mexico, leaving New Orleans on a side channel. As a result, the U.S. Congress authorized a project called the Old River Control Structure, which has prevented the Mississippi River from leaving its current channel that drains into the Gulf via New Orleans.\nBecause the large scale of high-energy water flow threatened to damage the structure, an auxiliary flow control station was built adjacent to the standing control station. This $300\u00a0million project was completed in 1986 by the Corps of Engineers. Beginning in the 1970s, the Corps applied hydrological transport models to analyze flood flow and water quality of the Mississippi. Dam 26 at Alton, Illinois, which had structural problems, was replaced by the Mel Price Lock and Dam in 1990. The original Lock and Dam 26 was demolished.\n21st century.\nThe Corps now actively creates and maintains spillways and floodways to divert periodic water surges into backwater channels and lakes, as well as route part of the Mississippi's flow into the Atchafalaya Basin and from there to the Gulf of Mexico, bypassing Baton Rouge and New Orleans. The main structures are the Birds Point-New Madrid Floodway in Missouri; the Old River Control Structure and the Morganza Spillway in Louisiana, which direct excess water down the west and east sides (respectively) of the Atchafalaya River; and the Bonnet Carr\u00e9 Spillway, also in Louisiana, which directs floodwaters to Lake Pontchartrain (see diagram). Some experts blame urban sprawl for increases in both the risk and frequency of flooding on the Mississippi River.\nSome of the pre-1927 strategy remains in use today, with the Corps actively cutting the necks of horseshoe bends, allowing the water to move faster and reducing flood heights.\nHistory.\nApproximately 50,000 years ago, the Central United States was covered by an inland sea, which was drained by the Mississippi and its tributaries into the Gulf of Mexico\u2014creating large floodplains and extending the continent further to the south in the process. The soil in areas such as Louisiana was thereafter found to be very rich.\nNative Americans.\nThe area of the Mississippi River basin was first settled by hunting and gathering Native American peoples and is considered one of the few independent centers of plant domestication in human history. Evidence of early cultivation of sunflower, a goosefoot, a marsh elder and an indigenous squash dates to the 4th millennium BC. The lifestyle gradually became more settled after around 1000\u00a0BC during what is now called the Woodland period, with increasing evidence of shelter construction, pottery, weaving and other practices.\nA network of trade routes referred to as the Hopewell interaction sphere was active along the waterways between about 200 and 500 AD, spreading common cultural practices over the entire area between the Gulf of Mexico and the Great Lakes. A period of more isolated communities followed, and agriculture introduced from Mesoamerica based on the Three Sisters (maize, beans and squash) gradually came to dominate. After around 800 AD there arose an advanced agricultural society today referred to as the Mississippian culture, with evidence of highly stratified complex chiefdoms and large population centers.\nThe most prominent of these, now called Cahokia, was occupied between about 600 and 1400 AD and at its peak numbered between 8,000 and 40,000 inhabitants, larger than London, England of that time. At the time of first contact with Europeans, Cahokia and many other Mississippian cities had dispersed, and archaeological finds attest to increased social stress.\nModern American Indian nations inhabiting the Mississippi basin include Cheyenne, Sioux, Ojibwe, Potawatomi, Ho-Chunk, Meskwaki, Kickapoo, Tamaroa, Moingwena, Quapaw and Chickasaw.\nThe word \"Mississippi\" itself comes from \"Messipi\", the French rendering of the Anishinaabe (Ojibwe or Algonquin) name for the river, \"Misi-ziibi\" (Great River). The Ojibwe called Lake Itasca \"Omashkoozo-zaaga'igan\" (Elk Lake) and the river flowing out of it \"Omashkoozo-ziibi\" (Elk River). After flowing into Lake Bemidji, the Ojibwe called the river \"Bemijigamaag-ziibi\" (River from the Traversing Lake). After flowing into Cass Lake, the name of the river changes to \"Gaa-miskwaawaakokaag-ziibi\" (Red Cedar River) and then out of Lake Winnibigoshish as \"Wiinibiigoonzhish-ziibi\" (Miserable Wretched Dirty Water River), \"Gichi-ziibi\" (Big River) after the confluence with the Leech Lake River, then finally as \"Misi-ziibi\" (Great River) after the confluence with the Crow Wing River. After the expeditions by Giacomo Beltrami and Henry Schoolcraft, the longest stream above the juncture of the Crow Wing River and \"Gichi-ziibi\" was named \"Mississippi River\". The Mississippi River Band of Chippewa Indians, known as the \"Gichi-ziibiwininiwag\", are named after the stretch of the Mississippi River known as the \"Gichi-ziibi\". The Cheyenne, one of the earliest inhabitants of the upper Mississippi River, called it the \"M\u00e1\u02bcxe-\u00e9\u02bcometaa\u02bce\" (Big Greasy River) in the Cheyenne language. The Arapaho name for the river is \"Beesniic\u00ede\". The Pawnee name is \"Kicka\u00e1tit\".\nThe Mississippi was spelled Mississipi or Missisipi during French Louisiana and was also known as the Rivi\u00e8re Saint-Louis.\nEuropean exploration.\nIn 1519 Spanish explorer Alonso \u00c1lvarez de Pineda became the first recorded European to reach the Mississippi River, followed by Hernando de Soto who reached the river on May 8, 1541, and called it \"R\u00edo del Esp\u00edritu Santo\" (\"River of the Holy Spirit\"), in the area of what is now Mississippi. In Spanish, the river is called \"R\u00edo Mississippi\".\nFrench explorers Louis Jolliet and Jacques Marquette began exploring the Mississippi in the 17th century. Marquette traveled with a Sioux Indian who named it \"Ne Tongo\" (\"Big river\" in Sioux language) in 1673. Marquette proposed calling it the \"River of the Immaculate Conception\".\nWhen Louis Jolliet explored the Mississippi Valley in the 17th century, natives guided him to a quicker way to return to French Canada via the Illinois River. When he found the Chicago Portage, he remarked that a canal of \"only half a league\" (less than ) would join the Mississippi and the Great Lakes. In 1848, the continental divide separating the waters of the Great Lakes and the Mississippi Valley was breached by the Illinois and Michigan canal via the Chicago River. This both accelerated the development, and forever changed the ecology of the Mississippi Valley and the Great Lakes.\nIn 1682, Ren\u00e9-Robert Cavelier, Sieur de La Salle and Henri de Tonti claimed the entire Mississippi River valley for France, calling the river \"Colbert River\" after Jean-Baptiste Colbert and the region \"La Louisiane\", for King Louis XIV. On March 2, 1699, Pierre Le Moyne d'Iberville rediscovered the mouth of the Mississippi, following the death of La Salle. The French built the small fort of La Balise there to control passage.\nIn 1718, about upriver, New Orleans was established along the river crescent by Jean-Baptiste Le Moyne, Sieur de Bienville, with construction patterned after the 1711 resettlement on Mobile Bay of Mobile, the capital of French Louisiana at the time.\nIn 1727, \u00c9tienne Perier begins work, using enslaved African laborers, on the first levees on the Mississippi River.\nColonization.\nFollowing Britain's victory in the Seven Years War, the Mississippi became the border between the British and Spanish Empires. The Treaty of Paris (1763) gave Great Britain rights to all land east of the Mississippi and Spain rights to land west of the Mississippi. Spain also ceded Florida to Britain to regain Cuba, which the British occupied during the war. Britain then divided the territory into East and West Florida.\nArticle 8 of the Treaty of Paris (1783) states, \"The navigation of the river Mississippi, from its source to the ocean, shall forever remain free and open to the subjects of Great Britain and the citizens of the United States\". With this treaty, which ended the American Revolutionary War, Britain also ceded West Florida back to Spain to regain the Bahamas, which Spain had occupied during the war. Initial disputes around the ensuing claims of the U.S. and Spain were resolved when Spain was pressured into signing Pinckney's Treaty in 1795. However, in 1800, under duress from Napoleon of France, Spain ceded an undefined portion of West Florida to France in the secret Treaty of San Ildefonso. The United States then secured effective control of the river when it bought the Louisiana Territory from France in the Louisiana Purchase of 1803. This triggered a dispute between Spain and the U.S. on which parts of West Florida Spain had ceded to France in the first place, which would decide which parts of West Florida the U.S. had bought from France in the Louisiana Purchase, versus which were unceded Spanish property. Due to ongoing U.S. colonization creating facts on the ground, and U.S. military actions, Spain ceded both West and East Florida in their entirety to the United States in the Adams\u2013On\u00eds Treaty of 1819.\nThe last serious European challenge to U.S. control of the river came at the conclusion of the War of 1812, when British forces mounted an attack on New Orleans just 15 days after the signing of the Treaty of Ghent. The attack was repulsed by an American army under the command of General Andrew Jackson.\nIn the Treaty of 1818, the U.S. and Great Britain agreed to fix the border running from the Lake of the Woods to the Rocky Mountains along the 49th parallel north. In effect, the U.S. ceded the northwestern extremity of the Mississippi basin to the British in exchange for the southern portion of the Red River basin.\nSo many settlers traveled westward through the Mississippi river basin, as well as settled in it, that Zadok Cramer wrote a guidebook called \"The Navigator\", detailing the features, dangers, and navigable waterways of the area. It was so popular that he updated and expanded it through 12 editions over 25 years.\nThe colonization of the area was barely slowed by the three earthquakes in 1811 and 1812, estimated at 8 on the Richter magnitude scale, that were centered near New Madrid, Missouri.\nSteamboat era.\nMark Twain's book, \"Life on the Mississippi\", covered the steamboat commerce, which took place from 1830 to 1870, before more modern ships replaced the steamer. \"Harper's Weekly\" first published the book as a seven-part serial in 1875. James R. Osgood &amp; Company published the full version, including a passage from the then unfinished \"Adventures of Huckleberry Finn\" and works from other authors, in 1885.\nThe first steamboat to travel the full length of the Lower Mississippi from the Ohio River to New Orleans was the \"New Orleans\" in December 1811. Its maiden voyage occurred during the series of New Madrid earthquakes in 1811\u201312. The Upper Mississippi was treacherous, unpredictable and to make traveling worse, the area was not properly mapped out or surveyed. Until the 1840s, only two trips a year to the Twin Cities landings were made by steamboats, which suggests it was not very profitable. The Secretary of War, Charles M. Conrad in 1851 authorized a scientific study of the river in order to prevent flooding primarily. The report was first published in 1861 under the title, \"Report upon the Physics and Hydraulics of the Mississippi River\" and was the most extensive river study undertaken in the world at that time.\nSteamboat transport remained a viable industry, both in terms of passengers and freight, until the end of the first decade of the 20th century. Among the several Mississippi River system steamboat companies was the noted Anchor Line, which, from 1859 to 1898, operated a luxurious fleet of steamers between St. Louis and New Orleans.\nItalian explorer Giacomo Beltrami wrote about his journey on the \"Virginia\", which was the first steamboat to make it to Fort St. Anthony in Minnesota. He referred to his voyage as a promenade that was once a journey on the Mississippi. The steamboat era changed the economic and political life of the Mississippi, as well as of travel itself. The Mississippi was completely changed by the steamboat era as it transformed into a flourishing tourist trade.\nCivil War.\nControl of the river was a strategic objective of both sides in the American Civil War, forming a part of the U.S. Anaconda Plan. In 1862, Union forces coming down the river successfully cleared Confederate defenses at Island Number 10 and Memphis, Tennessee, while Naval forces coming upriver from the Gulf of Mexico captured New Orleans, Louisiana. One of the last major Confederate strongholds was on the heights overlooking the river at Vicksburg, Mississippi; the Union's Vicksburg Campaign (December 1862 \u2013 July 1863), and the fall of Port Hudson, completed control of the lower Mississippi River. The Union victory ended the Siege of Vicksburg on July 4, 1863, and was pivotal to the Union's final victory of the Civil War.\n20th and 21st centuries.\nThe \"Big Freeze\" of 1918\u201319 blocked river traffic north of Memphis, Tennessee, preventing transportation of coal from southern Illinois. This resulted in widespread shortages, high prices, and rationing of coal in January and February.\nIn the spring of 1927, the river broke out of its banks in 145 places, during the Great Mississippi Flood of 1927 and inundated to a depth of up to .\nIn 1930, Fred Newton was the first person to swim the length of the river, from Minneapolis to New Orleans. The journey took 176 days and covered 1,836 miles.\nIn 1962 and 1963, industrial accidents spilled of soybean oil into the Mississippi and Minnesota rivers. The oil covered the Mississippi River from St. Paul to Lake Pepin, creating an ecological disaster and a demand to control water pollution.\nOn October 20, 1976, the automobile ferry, \"MV George Prince\", was struck by a ship traveling upstream as the ferry attempted to cross from Destrehan, Louisiana, to Luling, Louisiana. Seventy-eight passengers and crew died; only eighteen survived the accident.\nIn 1988, the water level of the Mississippi fell to below zero on the Memphis gauge. The remains of wooden-hulled water craft were exposed in an area of on the bottom of the Mississippi River at West Memphis, Arkansas. They dated to the late 19th to early 20th centuries. The State of Arkansas, the Arkansas Archeological Survey, and the Arkansas Archeological Society responded with a two-month data recovery effort. The fieldwork received national media attention as good news in the middle of a drought.\nThe Great Flood of 1993 was another significant flood, primarily affecting the Mississippi above its confluence with the Ohio River at Cairo, Illinois.\nTwo portions of the Mississippi were designated as American Heritage Rivers in 1997: the lower portion around Louisiana and Tennessee, and the upper portion around Iowa, Illinois, Minnesota, Missouri and Wisconsin. The Nature Conservancy's project called \"America's Rivershed Initiative\" announced a 'report card' assessment of the entire basin in October 2015 and gave the grade of D+. The assessment noted the aging navigation and flood control infrastructure along with multiple environmental problems.\nIn 2002, Slovenian long-distance swimmer Martin Strel swam the entire length of the river, from Minnesota to Louisiana, over the course of 68 days. In 2005, the Source to Sea Expedition paddled the Mississippi and Atchafalaya Rivers to benefit the Audubon Society's Upper Mississippi River Campaign.\nFuture.\nGeologists believe that the lower Mississippi could take a new course to the Gulf. Either of two new routes\u2014through the Atchafalaya Basin or through Lake Pontchartrain\u2014might become the Mississippi's main channel if flood-control structures are overtopped or heavily damaged during a severe flood.\nFailure of the Old River Control Structure, the Morganza Spillway, or nearby levees would likely re-route the main channel of the Mississippi through Louisiana's Atchafalaya Basin and down the Atchafalaya River to reach the Gulf of Mexico south of Morgan City in southern Louisiana. This route provides a more direct path to the Gulf of Mexico than the present Mississippi River channel through Baton Rouge and New Orleans. While the risk of such a diversion is present during any major flood event, such a change has so far been prevented by active human intervention involving the construction, maintenance, and operation of various levees, spillways, and other control structures by the U.S. Army Corps of Engineers.\nThe Old River Control Structure, between the present Mississippi River channel and the Atchafalaya Basin, sits at the normal water elevation and is ordinarily used to divert 30% of the Mississippi flow to the Atchafalaya River. There is a steep drop here away from the Mississippi's main channel into the Atchafalaya Basin. If this facility were to fail during a major flood, there is a strong concern the water would scour and erode the river bottom enough to capture the Mississippi's main channel. The structure was nearly lost during the 1973 flood, but repairs and improvements were made after engineers studied the forces at play. In particular, the Corps of Engineers made many improvements and constructed additional facilities for routing water through the vicinity. These additional facilities give the Corps much more flexibility and potential flow capacity than they had in 1973, which further reduces the risk of a catastrophic failure in this area during other major floods, such as that of 2011.\nBecause the Morganza Spillway is slightly higher and well back from the river, it is normally dry on both sides. Even if it failed at the crest during a severe flood, the floodwaters would have to erode to normal water levels before the Mississippi could permanently jump channel at this location. During the 2011 floods, the Corps of Engineers opened the Morganza Spillway to 1/4 of its capacity to allow of water to flood the Morganza and Atchafalaya floodways and continue directly to the Gulf of Mexico, bypassing Baton Rouge and New Orleans. In addition to reducing the Mississippi River crest downstream, this diversion reduced the chances of a channel change by reducing stress on the other elements of the control system.\nSome geologists have noted that the possibility for course change into the Atchafalaya also exists in the area immediately north of the Old River Control Structure. Army Corps of Engineers geologist Fred Smith once stated, \"The Mississippi wants to go west. 1973 was a forty-year flood. The big one lies out there somewhere\u2014when the structures can't release all the floodwaters and the levee is going to have to give way. That is when the river's going to jump its banks and try to break through.\"\nAnother possible course change for the Mississippi River is a diversion into Lake Pontchartrain near New Orleans. This route is controlled by the Bonnet Carr\u00e9 Spillway, built to reduce flooding in New Orleans. This spillway and an imperfect natural levee about high are all that prevents the Mississippi from taking a new, shorter course through Lake Pontchartrain to the Gulf of Mexico. Diversion of the Mississippi's main channel through Lake Pontchartrain would have consequences similar to an Atchafalaya diversion, but to a lesser extent, since the present river channel would remain in use past Baton Rouge and into the New Orleans area.\nRecreation.\nThe sport of water skiing was invented on the river in a wide region between Minnesota and Wisconsin known as Lake Pepin. Ralph Samuelson of Lake City, Minnesota, created and refined his skiing technique in late June and early July 1922. He later performed the first water ski jump in 1925 and was pulled along at by a Curtiss flying boat later that year.\nThere are seven National Park Service sites along the Mississippi River. The Mississippi National River and Recreation Area is the National Park Service site dedicated to protecting and interpreting the Mississippi River itself. The other six National Park Service sites along the river are (listed from north to south):\nEcology.\nThe Mississippi basin is home to a highly diverse aquatic fauna and has been called the \"mother fauna\" of North American freshwater.\nFish.\nAbout 375 fish species are known from the Mississippi basin, far exceeding other North Hemisphere river basins exclusively within temperate/subtropical regions, except the Yangtze. Within the Mississippi basin, streams that have their source in the Appalachian and Ozark highlands contain especially many species. Among the fish species in the basin are numerous endemics, as well as relicts such as paddlefish, sturgeon, gar and bowfin.\nBecause of its size and high species diversity, the Mississippi basin is often divided into subregions. The Upper Mississippi River alone is home to about 120 fish species, including walleye, sauger, largemouth bass, smallmouth bass, white bass, northern pike, bluegill, crappie, channel catfish, flathead catfish, common shiner, freshwater drum, and shovelnose sturgeon.\nOther fauna.\nA large number of reptiles are native to the river channels and basin, including American alligators, several species of turtle, aquatic amphibians, and cambaridae crayfish, are native to the Mississippi basin.\nIn addition, approximately 40% of the migratory birds in the US use the Mississippi River corridor during the Spring and Fall migrations; 60% of all migratory birds in North America (326 species) use the river basin as their flyway.\nIntroduced species.\nNumerous introduced species are found in the Mississippi and some of these are invasive. Among the introductions are fish such as Asian carp, including the silver carp that have become infamous for out-competing native fish and their potentially dangerous jumping behavior. They have spread throughout much of the basin, even approaching (but not yet invading) the Great Lakes. The Minnesota Department of Natural Resources has designated much of the Mississippi River in the state as infested waters by the exotic species zebra mussels and Eurasian watermilfoil.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "19581", "revid": "7903804", "url": "https://en.wikipedia.org/wiki?curid=19581", "title": "Men in black", "text": "Government agents who supposedly intimidate UFO witnesses\nIn popular culture and UFO conspiracy theories, men in black (MIB) are government agents dressed in dark suits, who question, interrogate, harass, and threaten unidentified flying object (UFO) witnesses to keep them silent about what they have seen. The term is also frequently used to describe mysterious men working for unknown organizations, as well as various branches of government allegedly tasked with protecting government UFO secrets or performing other strange activities. They are typically described as tall men with expressionless faces, slightly pale skin, and usually wearing black suits with black sunglasses. \u201cMen In Black\u201d encounters are very common tales told in American UFO conspiracy theories. \nThe term is generic, as it is used for any unusual, threatening or strangely behaved individual whose appearance on the scene can be linked in some fashion with a UFO sighting. \nStories about men in black inspired the science fiction comedy franchise \"Men in Black\" and an album by the Stranglers.\nFolklore.\nFolklorist James R. Lewis compares accounts of men in black with tales of people encountering Lucifer, and speculates that they can be considered a kind of \"psychological trauma\".\nUfologists.\nMen in black feature prominently in ufology, UFO folklore, and fan fiction. In the 1950s and 1960s, ufologists adopted a conspiratorial mindset and began fearing they would be subject to organized intimidation in retaliation for discovering \"the truth of the UFOs\".\nIn 1947, Harold Dahl claimed a man in a dark suit warned him not to discuss his alleged UFO sighting on Maury Island. In the mid-1950s, ufologist Albert K. Bender claimed he was visited by men in dark suits who threatened and warned him not to continue investigating UFOs. He maintained that the men were secret government agents tasked with suppressing evidence of UFOs. Ufologist John Keel claimed to have had encounters with MIB and referred to them as \"demonic supernaturals\" with \"dark skin and/or 'exotic' facial features\". According to ufologist Jerome Clark, reports of men in black represent \"experiences\" that \"don't seem to have occurred in the world of consensus reality\".\nHistorian Aaron Gulyas wrote: \"During the 1970s, 1980s and 1990s, UFO conspiracy theorists would incorporate the MIB into their increasingly complex and paranoid visions.\"\nKeel has argued that some MIB encounters could be explained as entirely mundane events perpetuated through folklore. In his book \"The Mothman Prophecies\" (1975), he describes a late-night outing in 1967, where he was mistaken for an MIB while searching for a phone to call a tow truck.\nIn his article \"Gray Barker: My Friend, the Myth-Maker\", John C. Sherwood claims that, in the late 1960s, at age 18, he cooperated when Gray Barker urged him to develop a hoax\u2014which Barker subsequently published\u2014about what Barker called \"blackmen\", three mysterious UFO inhabitants who silenced Sherwood's pseudonymous identity, \"Dr. Richard H. Pratt\".\nIn popular culture.\nThe 1976 Blue \u00d6yster Cult song \"E.T.I. (Extra Terrestrial Intelligence)\" contains the line: \"Three men in black said, 'Don't report this.'\" Their 1983 song \"Take Me Away\", about the singer's desire to leave Earth with \"good guy\" aliens, has the line: \"The men in black, their lips are sealed.\"\nIn 1979, British punk rock and new wave rock band The Stranglers recorded a song entitled \"Meninblack\" for their album \"The Raven\", released that year. In 1981, their concept album \"The Gospel According to the Meninblack\" featured alien visitations to Earth.\nJames T. Flocker's 1979 film \"The Alien Encounters\" included Men in Black who harass a UFO investigator portrayed by Augie Tribach.\nThe 1984 film \"The Brother from Another Planet\" features two Men in Black who try to capture the alien hero. One is played by the film's director, John Sayles.\nThe 1995 album \"Masquerade\" by German heavy metal band Running Wild has a song called \"Men in Black\". The song tells about a UFO sighting and the arrival of the Men In Black and the covering up of the sighting.\nThe 1997 science-fiction film \"Men In Black\", starring Will Smith and Tommy Lee Jones, was loosely based on \"The Men in Black\" comic book series created by Lowell Cunningham and Sandy Carruthers. Cunningham got the idea for the comic when he and a friend saw a black van on the street and his friend joked about government \"men in black\". Also in 1997 a more serious take on the subject was seen in a TV movie \"The Shadow Men\".\nThe video game franchise \"Half-Life\" features a character known as the G-Man, widely regarded as being inspired by urban legends associated with the men in black.\nThe Men in Black are featured in the 2000 video game \"Deus Ex\" as agents of Majestic 12. \nIn \"The X-Files\" there are numerous instances of Men In Black references. The episode \"Jose Chung%27s From Outer Space\" has 2 characters, portrayed by Jesse Ventura and Alex Trebek, among many other characters in the television series and movies.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "19582", "revid": "50816438", "url": "https://en.wikipedia.org/wiki?curid=19582", "title": "May 7", "text": "&lt;templatestyles src=\"This date in recent years/styles.css\"/&gt;\nDay of the yearMay 7 is the day of the year in the Gregorian calendar\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "19583", "revid": "36118552", "url": "https://en.wikipedia.org/wiki?curid=19583", "title": "Monomer", "text": "Molecule which reacts with other monomers to form a polymer\nA monomer ( ; \"mono-\", \"one\" + \"-mer\", \"part\") is a molecule that can react together with other monomer molecules to form a larger polymer chain or two- or three-dimensional network in a process called polymerization.&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\n IUPAC definition\n Monomer molecule: A molecule which can undergo polymerization, thereby contributing constitutional units to the essential structure of a macromolecule.\nClassification.\nChemistry classifies monomers by type, and two broad classes based on the type of polymer they form.\nBy type:\nBy type of polymer they form:\nDiffering stoichiometry causes each class to create its respective form of polymer.\nThe polymerization of one kind of monomer gives a homopolymer. Many polymers are copolymers, meaning that they are derived from two different monomers. In the case of condensation polymerizations, the ratio of comonomers is usually 1:1. For example, the formation of many nylons requires equal amounts of a dicarboxylic acid and diamine. In the case of addition polymerizations, the comonomer content is often only a few percent. For example, small amounts of 1-octene monomer are copolymerized with ethylene to give specialized polyethylene.\nBiopolymers.\nThe term \"monomeric protein\" may also be used to describe one of the proteins making up a multiprotein complex.\nNatural monomers.\nSome of the main biopolymers are listed below:\nAmino acids.\nFor \"proteins\", the monomers are amino acids. Polymerization occurs at ribosomes. Usually about 20 types of amino acid monomers are used to produce proteins. Hence proteins are not homopolymers.\nNucleotides.\nFor polynucleic acids (DNA/RNA), the monomers are nucleotides, each of which is made of a pentose sugar, a nitrogenous base and a phosphate group. Nucleotide monomers are found in the cell nucleus. Four types of nucleotide monomers are precursors to DNA and four different nucleotide monomers are precursors to RNA.\nGlucose and related sugars.\nFor carbohydrates, the monomers are monosaccharides. The most abundant natural monomer is glucose, which is linked by glycosidic bonds into the polymers cellulose, starch, and glycogen.\nIsoprene.\nIsoprene is a natural monomer that polymerizes to form a natural rubber, most often \"cis-\"1,4-polyisoprene, but also \"trans-\"1,4-polymer. Synthetic rubbers are often based on butadiene, which is structurally related to isoprene.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "19588", "revid": "28481209", "url": "https://en.wikipedia.org/wiki?curid=19588", "title": "Mitochondrion", "text": "Organelle in eukaryotic cells responsible for respiration\n&lt;templatestyles src=\"Infobox_microanatomy/styles.css\"/&gt;\nA mitochondrion (pl.\u2009mitochondria) is an organelle found in the cells of most eukaryotes, such as animals, plants and fungi. Mitochondria have a double membrane structure and use aerobic respiration to generate adenosine triphosphate (ATP), which is used throughout the cell as a source of chemical energy. They were discovered by Albert von K\u00f6lliker in 1857 in the voluntary muscles of insects. The term \"mitochondrion\", meaning a thread-like granule, was coined by Carl Benda in 1898. The mitochondrion is popularly nicknamed the \"powerhouse of the cell\", a phrase popularized by Philip Siekevitz in a 1957 \"Scientific American\" article of the same name.\nSome cells in some multicellular organisms lack mitochondria (for example, mature mammalian red blood cells). The multicellular animal \"Henneguya salminicola\" is known to have retained mitochondrion-related organelles despite a complete loss of their mitochondrial genome. A large number of unicellular organisms, such as microsporidia, parabasalids and diplomonads, have reduced or transformed their mitochondria into other structures, e.g. hydrogenosomes and mitosomes. The oxymonads \"Monocercomonoides\", \"Streblomastix\", and \"Blattamonas\" completely lost their mitochondria.\nMitochondria are commonly between 0.75 and 3\u00a0\u03bcm2 in cross section, but vary considerably in size and structure. Unless specifically stained, they are not visible. The mitochondrion is composed of compartments that carry out specialized functions. These compartments or regions include the outer membrane, intermembrane space, inner membrane, cristae, and matrix.\nIn addition to supplying cellular energy, mitochondria are involved in other tasks, such as signaling, cellular differentiation, and cell death, as well as maintaining control of the cell cycle and cell growth. Mitochondrial biogenesis is in turn temporally coordinated with these cellular processes.\nMitochondria are implicated in human disorders and conditions such as mitochondrial diseases, cardiac dysfunction, heart failure, and autism.\nThe number of mitochondria in a cell vary widely by organism, tissue, and cell type. A mature red blood cell has no mitochondria, whereas a liver cell can have more than 2000.\nAlthough most of a eukaryotic cell's DNA is contained in the cell nucleus, the mitochondrion has its own genome (\"mitogenome\") that is similar to bacterial genomes. This finding has led to general acceptance of symbiogenesis (endosymbiotic theory) \u2013 that free-living prokaryotic ancestors of modern mitochondria permanently fused with eukaryotic cells in the distant past, evolving such that modern animals, plants, fungi, and other eukaryotes respire to generate cellular energy.\nStructure.\nMitochondria may have a number of different shapes. A mitochondrion contains outer and inner membranes composed of phospholipid bilayers and proteins. The two membranes have different properties. Because of this double-membraned organization, there are five distinct parts to a mitochondrion:\nMitochondria have folding to increase surface area, which in turn increases ATP (adenosine triphosphate) production.\nMitochondria stripped of their outer membrane are called mitoplasts.\nOuter membrane.\nThe outer mitochondrial membrane, which encloses the entire organelle, is 60 to 75 angstroms (\u00c5) thick. It has a protein-to-phospholipid ratio similar to that of the cell membrane (about 1:1 by weight). It contains large numbers of integral membrane proteins called porins. A major trafficking protein is the pore-forming voltage-dependent anion channel (VDAC). The VDAC is the primary transporter of nucleotides, ions and metabolites between the cytosol and the intermembrane space. It is formed as a beta barrel that spans the outer membrane, similar to that in the gram-negative bacterial outer membrane. Larger proteins can enter the mitochondrion if a signaling sequence at their N-terminus binds to a large multisubunit protein called translocase in the outer membrane, which then actively moves them across the membrane. Mitochondrial pro-proteins are imported through specialised translocation complexes.\nThe outer membrane also contains enzymes involved in such diverse activities as the elongation of fatty acids, oxidation of epinephrine, and the degradation of tryptophan. These enzymes include monoamine oxidase, rotenone-insensitive NADH-cytochrome c-reductase, kynurenine hydroxylase and fatty acid Co-A ligase. Disruption of the outer membrane permits proteins in the intermembrane space to leak into the cytosol, leading to cell death. The outer mitochondrial membrane can associate with the endoplasmic reticulum (ER) membrane, in a structure called MAM (mitochondria-associated ER-membrane). This is important in the ER-mitochondria calcium signaling and is involved in the transfer of lipids between the ER and mitochondria. Outside the outer membrane are small (diameter: 60 \u00c5) particles named sub-units of Parson.\nIntermembrane space.\nThe mitochondrial intermembrane space is the space between the outer membrane and the inner membrane. It is also known as perimitochondrial space. Because the outer membrane is freely permeable to small molecules, the concentrations of small molecules, such as ions and sugars, in the intermembrane space is the same as in the cytosol. However, large proteins must have a specific signaling sequence to be transported across the outer membrane, so the protein composition of this space is different from the protein composition of the cytosol. One protein that is localized to the intermembrane space in this way is cytochrome c.\nInner membrane.\nThe inner mitochondrial membrane contains proteins with three types of functions:\nIt contains more than 151 different polypeptides, and has a very high protein-to-phospholipid ratio (more than 3:1 by weight, which is about 1\u00a0protein for 15\u00a0phospholipids). The inner membrane is home to around 1/5 of the total protein in a mitochondrion. Additionally, the inner membrane is rich in an unusual phospholipid, cardiolipin. This phospholipid was originally discovered in cow hearts in 1942, and is usually characteristic of mitochondrial and bacterial plasma membranes. Cardiolipin contains four fatty acids rather than two, and may help to make the inner membrane impermeable, and its disruption can lead to multiple clinical disorders including neurological disorders and cancer. Unlike the outer membrane, the inner membrane does not contain porins, and is highly impermeable to all molecules. Almost all ions and molecules require special membrane transporters to enter or exit the matrix. Proteins are ferried into the matrix via the translocase of the inner membrane (TIM) complex or via OXA1L. In addition, there is a membrane potential across the inner membrane, formed by the action of the enzymes of the electron transport chain. Inner membrane fusion is mediated by the inner membrane protein OPA1.\nCristae.\nThe inner mitochondrial membrane is compartmentalized into numerous folds called cristae, which expand the surface area of the inner mitochondrial membrane, enhancing its ability to produce ATP. For typical liver mitochondria, the area of the inner membrane is about five times as large as that of the outer membrane. This ratio is variable and mitochondria from cells that have a greater demand for ATP, such as muscle cells, contain even more cristae. Mitochondria within the same cell can have substantially different crista-density, with the ones that are required to produce more energy having much more crista-membrane surface. These folds are studded with small round bodies known as F1 particles or oxysomes.\nMatrix.\nThe matrix is the space enclosed by the inner membrane. It contains about 2/3 of the total proteins in a mitochondrion. The matrix is important in the production of ATP with the aid of the ATP synthase contained in the inner membrane. The matrix contains a highly concentrated mixture of hundreds of enzymes, special mitochondrial ribosomes, tRNA, and several copies of the mitochondrial DNA genome. Of the enzymes, the major functions include oxidation of pyruvate and fatty acids, and the citric acid cycle. The DNA molecules are packaged into nucleoids by proteins, one of which is TFAM.\nFunction.\nThe most prominent roles of mitochondria are to produce the energy currency of the cell, ATP (i.e., phosphorylation of ADP), through respiration and to regulate cellular metabolism. The central set of reactions involved in ATP production are collectively known as the citric acid cycle, or the Krebs cycle, and oxidative phosphorylation. However, the mitochondrion has many other functions in addition to the production of ATP.\nEnergy conversion.\nA dominant role for the mitochondria is the production of ATP, as reflected by the large number of proteins in the inner membrane for this task. This is done by oxidizing the major products of glucose: pyruvate, and NADH, which are produced in the cytosol. This type of cellular respiration, known as aerobic respiration, is dependent on the presence of oxygen. When oxygen is limited, the glycolytic products will be metabolized by anaerobic fermentation, a process that is independent of the mitochondria. The production of ATP from glucose and oxygen has an approximately 13-times higher yield during aerobic respiration compared to fermentation. Plant mitochondria can also produce a limited amount of ATP either by breaking the sugar produced during photosynthesis or without oxygen by using the alternate substrate nitrite. ATP crosses out through the inner membrane with the help of a specific protein, and across the outer membrane via porins. After conversion of ATP to ADP by dephosphorylation that releases energy, ADP returns via the same route.\nPyruvate and the citric acid cycle.\nPyruvate molecules produced by glycolysis are actively transported across the inner mitochondrial membrane, and into the matrix where they can either be oxidized and combined with coenzyme A to form CO2, acetyl-CoA, and NADH, or they can be carboxylated (by pyruvate carboxylase) to form oxaloacetate. This latter reaction \"fills up\" the amount of oxaloacetate in the citric acid cycle and is therefore an anaplerotic reaction, increasing the cycle's capacity to metabolize acetyl-CoA when the tissue's energy needs (e.g., in muscle) are suddenly increased by activity.\nIn the citric acid cycle, all the intermediates (e.g. citrate, iso-citrate, alpha-ketoglutarate, succinate, fumarate, malate and oxaloacetate) are regenerated during each turn of the cycle. Adding more of any of these intermediates to the mitochondrion therefore means that the additional amount is retained within the cycle, increasing all the other intermediates as one is converted into the other. Hence, the addition of any one of them to the cycle has an anaplerotic effect, and its removal has a cataplerotic effect. These anaplerotic and cataplerotic reactions will, during the course of the cycle, increase or decrease the amount of oxaloacetate available to combine with acetyl-CoA to form citric acid. This in turn increases or decreases the rate of ATP production by the mitochondrion, and thus the availability of ATP to the cell.\nAcetyl-CoA, on the other hand, derived from pyruvate oxidation, or from the beta-oxidation of fatty acids, is the only fuel to enter the citric acid cycle. With each turn of the cycle one molecule of acetyl-CoA is consumed for every molecule of oxaloacetate present in the mitochondrial matrix, and is never regenerated. It is the oxidation of the acetate portion of acetyl-CoA that produces CO2 and water, with the energy thus released captured in the form of ATP.\nIn the liver, the carboxylation of cytosolic pyruvate into intra-mitochondrial oxaloacetate is an early step in the gluconeogenic pathway, which converts lactate and de-aminated alanine into glucose, under the influence of high levels of glucagon and/or epinephrine in the blood. Here, the addition of oxaloacetate to the mitochondrion does not have a net anaplerotic effect, as another citric acid cycle intermediate (malate) is immediately removed from the mitochondrion to be converted to cytosolic oxaloacetate, and ultimately to glucose, in a process that is almost the reverse of glycolysis.\nThe enzymes of the citric acid cycle are located in the mitochondrial matrix, with the exception of succinate dehydrogenase, which is bound to the inner mitochondrial membrane as part of Complex II. The citric acid cycle oxidizes the acetyl-CoA to carbon dioxide, and, in the process, produces reduced cofactors (three molecules of NADH and one molecule of FADH2) that are a source of electrons for the electron transport chain, and a molecule of GTP (which is readily converted to an ATP).\nO2 and NADH: energy-releasing reactions.\nThe electrons from NADH and FADH2 are transferred to oxygen (O2) and hydrogen (protons) in several steps via an electron transport chain. NADH and FADH2 molecules are produced within the matrix via the citric acid cycle and in the cytoplasm by glycolysis. Reducing equivalents from the cytoplasm can be imported via the malate-aspartate shuttle system of antiporter proteins or fed into the electron transport chain using a glycerol phosphate shuttle.\nThe major energy-releasing reactions that make the mitochondrion the \"powerhouse of the cell\" occur at protein complexes I, III and IV in the inner mitochondrial membrane (NADH dehydrogenase (ubiquinone), cytochrome c reductase, and cytochrome c oxidase). At complex IV, O2 reacts with the reduced form of iron in cytochrome c:\n\u0394rGo' = -218 kJ/mol\nreleasing a lot of free energy from the reactants without breaking bonds of an organic fuel. The free energy put in to remove an electron from Fe2+ is released at complex III when Fe3+ of cytochrome c reacts to oxidize ubiquinol (QH2):\n\u0394rGo' = -30 kJ/mol\nThe ubiquinone (Q) generated reacts, in complex I, with NADH:\n\u0394rGo' = -81 kJ/mol\nWhile the reactions are controlled by an electron transport chain, free electrons are not amongst the reactants or products in the three reactions shown and therefore do not affect the free energy released, which is used to pump protons (H+) into the intermembrane space. This process is efficient, but a small percentage of electrons may prematurely reduce oxygen, forming reactive oxygen species such as superoxide. This can cause oxidative stress in the mitochondria and may contribute to the decline in mitochondrial function associated with aging.\nAs the proton concentration increases in the intermembrane space, a strong electrochemical gradient is established across the inner membrane. The protons can return to the matrix through the ATP synthase complex, and their potential energy is used to synthesize ATP from ADP and inorganic phosphate (Pi). This process is called chemiosmosis, and was first described by Peter Mitchell, who was awarded the 1978 Nobel Prize in Chemistry for his work. Later, part of the 1997 Nobel Prize in Chemistry was awarded to Paul D. Boyer and John E. Walker for their clarification of the working mechanism of ATP synthase.\nHeat production.\nUnder certain conditions, protons can re-enter the mitochondrial matrix without contributing to ATP synthesis. This process is known as \"proton leak\" or mitochondrial uncoupling and is due to the facilitated diffusion of protons into the matrix. The process results in the unharnessed potential energy of the proton electrochemical gradient being released as heat. The process is mediated by a proton channel called thermogenin, or UCP1. Thermogenin is primarily found in brown adipose tissue, or brown fat, and is responsible for non-shivering thermogenesis. Brown adipose tissue is found in mammals, and is at its highest levels in early life and in hibernating animals. In humans, brown adipose tissue is present at birth and decreases with age.\nMitochondrial fatty acid synthesis.\nMitochondrial fatty acid synthesis (mtFAS) is essential for cellular respiration and mitochondrial biogenesis. In response to mitochondrial acetyl-CoA availability, mtFAS builds acyl chains on the 4'-phosphopantetheine group of the matrix-soluble scaffold protein ACP (holo-ACP), producing acyl-ACP species with varying chain lengths of at least eight carbons.\nAmong these, octanoyl-ACP (C8) serves as the precursor for lipoic acid biosynthesis. Since lipoic acid is a cofactor for key mitochondrial enzyme complexes, including the pyruvate dehydrogenase complex (PDC), \u03b1-ketoglutarate dehydrogenase complex (OGDC), 2-oxoadipate dehydrogenase complex (OADHC), branched-chain \u03b1-ketoacid dehydrogenase complex (BCKDC), and the glycine cleavage system (GCS), mtFAS significantly influences energy metabolism.\nIn contrast, longer-chain acyl-ACPs (C12\u2013C18) allosterically activate the network of LYRM proteins, which comprises at least 12 members in humans and regulates mitochondrial translation, iron-sulfur cluster biogenesis, and the assembly of electron transport chain complexes. MtFAS and ACP thus coordinate the activation of mitochondrial respiration in response to substrate availability. This enables cells to increase their oxidative capacity when substrates are abundant and prevents the electron transport chain from running empty and inducing the formation of reactive oxygen species (ROS) under substrate-limited conditions.\nMtFAS is also thought to play a role as a mediator in intracellular signaling due to its influence on the levels of bioactive lipids, such as lysophospholipids and sphingolipids.\nUptake, storage and release of calcium ions.\nThe concentrations of free calcium in the cell can regulate an array of reactions and is important for signal transduction in the cell. Mitochondria can transiently store calcium, a contributing process for the cell's homeostasis of calcium.\n Their ability to rapidly take in calcium for later release makes them good \"cytosolic buffers\" for calcium. The endoplasmic reticulum (ER) is the most significant storage site of calcium, and there is a significant interplay between the mitochondrion and ER with regard to calcium. The calcium is taken up into the matrix by the mitochondrial calcium uniporter on the inner mitochondrial membrane. It is primarily driven by the mitochondrial membrane potential. Release of this calcium back into the cell's interior can occur via a sodium-calcium exchange protein or via \"calcium-induced-calcium-release\" pathways. This can initiate calcium spikes or calcium waves with large changes in the membrane potential. These can activate a series of second messenger system proteins that can coordinate processes such as neurotransmitter release in nerve cells and release of hormones in endocrine cells.\nCa2+ influx to the mitochondrial matrix has recently been implicated as a mechanism to regulate respiratory bioenergetics by allowing the electrochemical potential across the membrane to transiently \"pulse\" from \u0394\u03a8-dominated to pH-dominated, facilitating a reduction of oxidative stress. In neurons, concomitant increases in cytosolic and mitochondrial calcium act to synchronize neuronal activity with mitochondrial energy metabolism. Mitochondrial matrix calcium levels can reach the tens of micromolar levels, which is necessary for the activation of isocitrate dehydrogenase, one of the key regulatory enzymes of the Krebs cycle.\nCellular proliferation regulation.\nThe relationship between cellular proliferation and mitochondria has been investigated. Tumor cells require ample ATP to synthesize bioactive compounds such as lipids, proteins, and nucleotides for rapid proliferation. The majority of ATP in tumor cells is generated via the oxidative phosphorylation pathway (OxPhos). Interference with OxPhos cause cell cycle arrest suggesting that mitochondria play a role in cell proliferation. Mitochondrial ATP production is also vital for cell division and differentiation in infection in addition to basic functions in the cell including the regulation of cell volume, solute concentration, and cellular architecture. ATP levels differ at various stages of the cell cycle suggesting that there is a relationship between the abundance of ATP and the cell's ability to enter a new cell cycle. ATP's role in the basic functions of the cell make the cell cycle sensitive to changes in the availability of mitochondrial derived ATP. The variation in ATP levels at different stages of the cell cycle support the hypothesis that mitochondria play an important role in cell cycle regulation. Although the specific mechanisms between mitochondria and the cell cycle regulation is not well understood, studies have shown that low energy cell cycle checkpoints monitor the energy capability before committing to another round of cell division.\nProgrammed cell death and innate immunity.\nProgrammed cell death (PCD) is crucial for various physiological functions, including organ development and cellular homeostasis. It serves as an intrinsic mechanism to prevent malignant transformation and plays a fundamental role in immunity by aiding in antiviral defense, pathogen elimination, inflammation, and immune cell recruitment.\nMitochondria have long been recognized for their central role in the intrinsic pathway of apoptosis, a form of PCD. In recent decades, they have also been identified as a signalling hub for much of the innate immune system. The endosymbiotic origin of mitochondria distinguishes them from other cellular components, and the exposure of mitochondrial elements to the cytosol can trigger the same pathways as infection markers. These pathways lead to apoptosis, autophagy, or the induction of proinflammatory genes.\nMitochondria contribute to apoptosis by releasing cytochrome \"c\", which directly induces the formation of apoptosomes. Additionally, they are a source of various damage-associated molecular patterns (DAMPs). These DAMPs are often recognised by the same pattern-recognition receptors (PRRs) that respond to pathogen-associated molecular patterns (PAMPs) during infections. For example, mitochondrial mtDNA resembles bacterial DNA due to its lack of CpG methylation and can be detected by Toll-like receptor 9 and cGAS. Double-stranded RNA (dsRNA), produced due to bidirectional mitochondrial transcription, can activate viral sensing pathways through RIG-I-like receptors. Additionally, the \"N\"-formylation of mitochondrial proteins, similar to that of bacterial proteins, can be recognized by formyl peptide receptors.\nNormally, these mitochondrial components are sequestered from the rest of the cell but are released following mitochondrial membrane permeabilization during apoptosis or passively after mitochondrial damage. However, mitochondria also play an active role in innate immunity, releasing mtDNA in response to metabolic cues. Mitochondria are also the localization site for immune and apoptosis regulatory proteins, such as BAX, MAVS (located on the outer membrane), and NLRX1 (found in the matrix). These proteins are modulated by the mitochondrial metabolic status and mitochondrial dynamics.\nDonation.\nSome cells donate mitochondria to other cells. Such donations occur in multiple cell types, in organisms such as yeast, molluscs, and rodents. Mitochondrial donation was first observed in 2006. As of 2025,[ [update]] it had not been observed in humans \"in vivo\". Donations may occur to help damaged cells, trigger tissue repair or the immune system, or to power distressed cells.\nResearchers cultured human mitochondria-free lung cancer cells with stem cells. The stem cells ejected mitochondria, which were absorbed by the lung cells. The lung cells then recovered their ability to divide and metabolize glucose. Mitochondria were then detected moving among lung, heart, brain, fat, bone, and other cells. Research has not identified how a cell indicates that it needs mitochondrial assistance or how other cells read those indicators.\nVarious purposes have been observed to explain such donations. These include:\nExtracellular mitochondria use multiple modes of transport:\nAdditional functions.\nMitochondria play a central role in many other metabolic tasks, such as:\nSome mitochondrial functions are performed only in specific types of cells. For example, mitochondria in liver cells contain enzymes that allow them to detoxify ammonia, a waste product of protein metabolism. A mutation in the genes regulating any of these functions can result in mitochondrial diseases.\nMitochondrial proteins (proteins transcribed from mitochondrial DNA) vary depending on the tissue and the species. In humans, 615 distinct types of proteins have been identified from cardiac mitochondria, whereas in rats, 940 proteins have been reported. The mitochondrial proteome is thought to be dynamically regulated.\nOrganization and distribution.\nMitochondria (or related structures) are found in all eukaryotes (except the Oxymonad \"Monocercomonoides\"). Although commonly depicted as bean-like structures they form a highly dynamic network in the majority of cells where they constantly undergo fission and fusion. The population of all the mitochondria of a given cell constitutes the chondriome. Mitochondria vary in number and location according to cell type. A single mitochondrion is often found in unicellular organisms, while human liver cells have about 1000\u20132000 mitochondria per cell, making up 1/5 of the cell volume. The mitochondrial content of otherwise similar cells can vary substantially in size and membrane potential, with differences arising from sources including uneven partitioning at cell division, leading to extrinsic differences in ATP levels and downstream cellular processes. The mitochondria can be found nestled between myofibrils of muscle or wrapped around the sperm flagellum. Often, they form a complex 3D branching network inside the cell with the cytoskeleton. The association with the cytoskeleton determines mitochondrial shape, which can affect the function as well: different structures of the mitochondrial network may afford the population a variety of physical, chemical, and signalling advantages or disadvantages. Mitochondria in cells are always distributed along microtubules and the distribution of these organelles is also correlated with the endoplasmic reticulum. Recent evidence suggests that vimentin, one of the components of the cytoskeleton, is also critical to the association with the cytoskeleton.\nMitochondria-associated ER membrane (MAM).\nThe mitochondria-associated ER membrane (MAM) is another structural element that is increasingly recognized for its critical role in cellular physiology and homeostasis. Once considered a technical snag in cell fractionation techniques, the alleged ER vesicle contaminants that invariably appeared in the mitochondrial fraction have been re-identified as membranous structures derived from the MAM\u2014the interface between mitochondria and the ER. Physical coupling between these two organelles had previously been observed in electron micrographs and has more recently been probed with fluorescence microscopy. Such studies estimate that at the MAM, which may comprise up to 20% of the mitochondrial outer membrane, the ER and mitochondria are separated by a mere 10\u201325\u00a0nm and held together by protein tethering complexes.\nPurified MAM from subcellular fractionation is enriched in enzymes involved in phospholipid exchange, in addition to channels associated with Ca2+ signaling. These hints of a prominent role for the MAM in the regulation of cellular lipid stores and signal transduction have been borne out, with significant implications for mitochondrial-associated cellular phenomena, as discussed below. Not only has the MAM provided insight into the mechanistic basis underlying such physiological processes as intrinsic apoptosis and the propagation of calcium signaling, but it also favors a more refined view of the mitochondria. Though often seen as static, isolated 'powerhouses' hijacked for cellular metabolism through an ancient endosymbiotic event, the evolution of the MAM underscores the extent to which mitochondria have been integrated into overall cellular physiology, with intimate physical and functional coupling to the endomembrane system.\nPhospholipid transfer.\nThe MAM is enriched in enzymes involved in lipid biosynthesis, such as phosphatidylserine synthase on the ER face and phosphatidylserine decarboxylase on the mitochondrial face. Because mitochondria are dynamic organelles constantly undergoing fission and fusion events, they require a constant and well-regulated supply of phospholipids for membrane integrity. But mitochondria are not only a destination for the phospholipids they finish synthesis of; rather, this organelle also plays a role in inter-organelle trafficking of the intermediates and products of phospholipid biosynthetic pathways, ceramide and cholesterol metabolism, and glycosphingolipid anabolism.\nSuch trafficking capacity depends on the MAM, which has been shown to facilitate transfer of lipid intermediates between organelles. In contrast to the standard vesicular mechanism of lipid transfer, evidence indicates that the physical proximity of the ER and mitochondrial membranes at the MAM allows for lipid flipping between opposed bilayers. Despite this unusual and seemingly energetically unfavorable mechanism, such transport does not require ATP. Instead, in yeast, it has been shown to be dependent on a multiprotein tethering structure termed the ER-mitochondria encounter structure, or ERMES, although it remains unclear whether this structure directly mediates lipid transfer or is required to keep the membranes in sufficiently close proximity to lower the energy barrier for lipid flipping.\nThe MAM may also be part of the secretory pathway, in addition to its role in intracellular lipid trafficking. In particular, the MAM appears to be an intermediate destination between the rough ER and the Golgi in the pathway that leads to very-low-density lipoprotein, or VLDL, assembly and secretion. The MAM thus serves as a critical metabolic and trafficking hub in lipid metabolism.\nCalcium signaling.\nA critical role for the ER in calcium signaling was acknowledged before such a role for the mitochondria was widely accepted, in part because the low affinity of Ca2+ channels localized to the outer mitochondrial membrane seemed to contradict this organelle's purported responsiveness to changes in intracellular Ca2+ flux. But the presence of the MAM resolves this apparent contradiction: the close physical association between the two organelles results in Ca2+ microdomains at contact points that facilitate efficient Ca2+ transmission from the ER to the mitochondria. Transmission occurs in response to so-called \"Ca2+ puffs\" generated by spontaneous clustering and activation of IP3R, a canonical ER membrane Ca2+ channel.\nThe fate of these puffs\u2014in particular, whether they remain restricted to isolated locales or integrated into Ca2+ waves for propagation throughout the cell\u2014is determined in large part by MAM dynamics. Although reuptake of Ca2+ by the ER (concomitant with its release) modulates the intensity of the puffs, thus insulating mitochondria to a certain degree from high Ca2+ exposure, the MAM often serves as a firewall that essentially buffers Ca2+ puffs by acting as a sink into which free ions released into the cytosol can be funneled. This Ca2+ tunneling occurs through the low-affinity Ca2+ receptor VDAC1, which recently has been shown to be physically tethered to the IP3R clusters on the ER membrane and enriched at the MAM. The ability of mitochondria to serve as a Ca2+ sink is a result of the electrochemical gradient generated during oxidative phosphorylation, which makes tunneling of the cation an exergonic process. Normal, mild calcium influx from cytosol into the mitochondrial matrix causes transient depolarization that is corrected by pumping out protons.\nBut transmission of Ca2+ is not unidirectional; rather, it is a two-way street. The properties of the Ca2+ pump SERCA and the channel IP3R present on the ER membrane facilitate feedback regulation coordinated by MAM function. In particular, the clearance of Ca2+ by the MAM allows for spatio-temporal patterning of Ca2+ signaling because Ca2+ alters IP3R activity in a biphasic manner. SERCA is likewise affected by mitochondrial feedback: uptake of Ca2+ by the MAM stimulates ATP production, thus providing energy that enables SERCA to reload the ER with Ca2+ for continued Ca2+ efflux at the MAM. Thus, the MAM is not a passive buffer for Ca2+ puffs; rather it helps modulate further Ca2+ signaling through feedback loops that affect ER dynamics.\nRegulating ER release of Ca2+ at the MAM is especially critical because only a certain window of Ca2+ uptake sustains the mitochondria, and consequently the cell, at homeostasis. Sufficient intraorganelle Ca2+ signaling is required to stimulate metabolism by activating dehydrogenase enzymes critical to flux through the citric acid cycle. However, once Ca2+ signaling in the mitochondria passes a certain threshold, it stimulates the intrinsic pathway of apoptosis in part by collapsing the mitochondrial membrane potential required for metabolism. Studies examining the role of pro- and anti-apoptotic factors support this model; for example, the anti-apoptotic factor Bcl-2 has been shown to interact with IP3Rs to reduce Ca2+ filling of the ER, leading to reduced efflux at the MAM and preventing collapse of the mitochondrial membrane potential post-apoptotic stimuli. Given the need for such fine regulation of Ca2+ signaling, it is perhaps unsurprising that dysregulated mitochondrial Ca2+ has been implicated in several neurodegenerative diseases, while the catalogue of tumor suppressors includes a few that are enriched at the MAM.\nMolecular basis for tethering.\nRecent advances in the identification of the tethers between the mitochondrial and ER membranes suggest that the scaffolding function of the molecular elements involved is secondary to other, non-structural functions. In yeast, ERMES, a multiprotein complex of interacting ER- and mitochondrial-resident membrane proteins, is required for lipid transfer at the MAM and exemplifies this principle. One of its components, for example, is also a constituent of the protein complex required for insertion of transmembrane beta-barrel proteins into the lipid bilayer. However, a homologue of the ERMES complex has not yet been identified in mammalian cells. Other proteins implicated in scaffolding likewise have functions independent of structural tethering at the MAM; for example, ER-resident and mitochondrial-resident mitofusins form heterocomplexes that regulate the number of inter-organelle contact sites, although mitofusins were first identified for their role in fission and fusion events between individual mitochondria. Glucose-related protein 75 (grp75) is another dual-function protein. In addition to the matrix pool of grp75, a portion serves as a chaperone that physically links the mitochondrial and ER Ca2+ channels VDAC and IP3R for efficient Ca2+ transmission at the MAM. Another potential tether is Sigma-1R, a non-opioid receptor whose stabilization of ER-resident IP3R may preserve communication at the MAM during the metabolic stress response.\nPerspective.\nThe MAM is a critical signaling, metabolic, and trafficking hub in the cell that allows for the integration of ER and mitochondrial physiology. Coupling between these organelles is not simply structural but functional as well and critical for overall cellular physiology and homeostasis. The MAM thus offers a perspective on mitochondria that diverges from the traditional view of this organelle as a static, isolated unit appropriated for its metabolic capacity by the cell. Instead, this mitochondrial-ER interface emphasizes the integration of the mitochondria, the product of an endosymbiotic event, into diverse cellular processes. Recently it has also been shown, that mitochondria and MAM-s in neurons are anchored to specialised intercellular communication sites (so called somatic-junctions). Microglial processes monitor and protect neuronal functions at these sites, and MAM-s are supposed to have an important role in this type of cellular quality-control.\nOrigin and evolution.\nThere are two hypotheses about the origin of mitochondria: endosymbiotic and autogenous. The endosymbiotic hypothesis suggests that mitochondria were originally prokaryotic cells, capable of implementing oxidative mechanisms that were not possible for eukaryotic cells; they became endosymbionts living inside the eukaryote. In the autogenous hypothesis, mitochondria were born by splitting off a portion of DNA from the nucleus of the eukaryotic cell at the time of divergence with the prokaryotes; this DNA portion would have been enclosed by membranes, which could not be crossed by proteins. Since mitochondria have many features in common with bacteria, the endosymbiotic hypothesis is the more widely accepted of the two accounts.\nA mitochondrion contains DNA, which is organized as several copies of a single, usually circular chromosome. This mitochondrial chromosome contains genes for redox proteins, such as those of the respiratory chain. The CoRR hypothesis proposes that this co-location is required for redox regulation. The mitochondrial genome codes for some RNAs of ribosomes, and the 22\u00a0tRNAs necessary for the translation of mRNAs into protein. The circular structure is also found in prokaryotes. The proto-mitochondrion was probably closely related to the order \"Rickettsiales\", which is in class Alphaproteobactera of phylum Pseudomonadota. However, the exact relationship of the ancestor of mitochondria to the alphaproteobacteria and whether the mitochondrion was formed at the same time or after the nucleus, remains controversial. For example, it has been suggested that the SAR11 clade of bacteria shares a relatively recent common ancestor with the mitochondria, while phylogenomic analyses indicate that mitochondria evolved from a Pseudomonadota lineage that is closely related to or a member of alphaproteobacteria. Some papers describe mitochondria as sister to the alphaproteobacteria, together forming the sister the marineproteo1 group, together forming the sister to Magnetococcidae.\nThe ribosomes coded for by the mitochondrial DNA are similar to those from bacteria in size and structure. They closely resemble the bacterial 70S ribosome and not the 80S cytoplasmic ribosomes, which are coded for by nuclear DNA.\nThe endosymbiotic relationship of mitochondria with their host cells was popularized by Lynn Margulis. The endosymbiotic theory suggests that mitochondria descended from aerobic bacteria that somehow survived endocytosis by another cell, and became incorporated into the cytoplasm. The ability of these bacteria to conduct respiration in host cells that had relied on glycolysis and fermentation would have provided a considerable evolutionary advantage. This symbiotic relationship probably developed 1.7 to 2 billion years ago.\nA few groups of unicellular eukaryotes have only vestigial mitochondria or derived structures: The microsporidians, metamonads, and archamoebae. These groups appear as the most primitive eukaryotes on phylogenetic trees constructed using rRNA information, which once suggested that they appeared before the origin of mitochondria. However, this is now known to be an artifact of \"long-branch attraction\": They are derived groups and retain genes or organelles derived from mitochondria (e.\u00a0g., mitosomes and hydrogenosomes). Hydrogenosomes, mitosomes, and related organelles as found in some loricifera (e.\u00a0g. \"Spinoloricus\") and myxozoa (e.\u00a0g. \"Henneguya zschokkei\") are together classified as MROs, mitochondrion-related organelles.\n\"Monocercomonoides\" and other oxymonads appear to have lost their mitochondria completely and at least some of the mitochondrial functions seem to be carried out by cytoplasmic proteins now.\nMitochondrial genetics.\nMitochondria contain their own genome. The human mitochondrial genome is a circular double-stranded DNA molecule of about 16\u00a0kilobases. It encodes 37 genes: 13 for subunits of respiratory complexes I, III, IV and V, 22 for mitochondrial tRNA (for the 20 standard amino acids, plus an extra gene for leucine and serine), and 2 for rRNA (12S and 16S rRNA). One mitochondrion can contain two to ten copies of its DNA. One of the two mitochondrial DNA (mtDNA) strands has a disproportionately higher ratio of the heavier nucleotides adenine and guanine, and this is termed the heavy strand (or H strand), whereas the other strand is termed the light strand (or L strand). The weight difference allows the two strands to be separated by centrifugation. mtDNA has one long non-coding stretch known as the non-coding region (NCR), which contains the heavy strand promoter (HSP) and light strand promoter (LSP) for RNA transcription, the origin of replication for the H strand (OriH) localized on the L strand, three conserved sequence boxes (CSBs 1\u20133), and a termination-associated sequence (TAS). The origin of replication for the L strand (OriL) is localized on the H strand 11,000 bp downstream of OriH, located within a cluster of genes coding for tRNA.\nAs in prokaryotes, there is a very high proportion of coding DNA and an absence of repeats. Mitochondrial genes are transcribed as multigenic transcripts, which are cleaved and polyadenylated to yield mature mRNAs. Most proteins necessary for mitochondrial function are encoded by genes in the cell nucleus and the corresponding proteins are imported into the mitochondrion. The exact number of genes encoded by the nucleus and the mitochondrial genome differs between species. Most mitochondrial genomes are circular. In general, mitochondrial DNA lacks introns, as is the case in the human mitochondrial genome; however, introns have been observed in some eukaryotic mitochondrial DNA, such as that of yeast and protists, including \"Dictyostelium discoideum\". Between protein-coding regions, tRNAs are present. Mitochondrial tRNA genes have different sequences from the nuclear tRNAs, but lookalikes of mitochondrial tRNAs have been found in the nuclear chromosomes with high sequence similarity.\nIn animals, the mitochondrial genome is typically a single circular chromosome that is approximately 16 kb long and has 37 genes. The genes, while highly conserved, may vary in location. Curiously, this pattern is not found in the human body louse (\"Pediculus humanus\"). Instead, this mitochondrial genome is arranged in 18 minicircular chromosomes, each of which is 3\u20134 kb long and has one to three genes. This pattern is also found in other sucking lice, but not in chewing lice. Recombination has been shown to occur between the minichromosomes.\nHuman population genetic studies.\nThe near-absence of genetic recombination in mitochondrial DNA makes it a useful source of information for studying population genetics and evolutionary biology. Because all the mitochondrial DNA is inherited as a single unit, or haplotype, the relationships between mitochondrial DNA from different individuals can be represented as a gene tree. Patterns in these gene trees can be used to infer the evolutionary history of populations. The classic example of this is in human evolutionary genetics, where the molecular clock can be used to provide a recent date for mitochondrial Eve. This is often interpreted as strong support for a recent modern human expansion out of Africa. Another human example is the sequencing of mitochondrial DNA from Neanderthal bones. The relatively large evolutionary distance between the mitochondrial DNA sequences of Neanderthals and living humans has been interpreted as evidence for the lack of interbreeding between Neanderthals and modern humans.\nHowever, mitochondrial DNA reflects only the history of the females in a population. This can be partially overcome by the use of paternal genetic sequences, such as the non-recombining region of the Y-chromosome.\nRecent measurements of the molecular clock for mitochondrial DNA reported a value of 1 mutation every 7884 years dating back to the most recent common ancestor of humans and apes, which is consistent with estimates of mutation rates of autosomal DNA (10\u22128 per base per generation).\nAlternative genetic code.\nWhile slight variations on the standard genetic code had been predicted earlier, none was discovered until 1979, when researchers studying human mitochondrial genes determined that they used an alternative code. Nonetheless, the mitochondria of many other eukaryotes, including most plants, use the standard code. Many slight variants have been discovered since, including various alternative mitochondrial codes. Further, the AUA, AUC, and AUU codons are all allowable start codons.\nSome of these differences should be regarded as pseudo-changes in the genetic code due to the phenomenon of RNA editing, which is common in mitochondria. In higher plants, it was thought that CGG encoded for tryptophan and not arginine; however, the codon in the processed RNA was discovered to be the UGG codon, consistent with the standard genetic code for tryptophan. Of note, the arthropod mitochondrial genetic code has undergone parallel evolution within a phylum, with some organisms uniquely translating AGG to lysine.\nReplication and inheritance.\nMitochondria divide by mitochondrial fission, a form of binary fission that is also done by bacteria although the process is tightly regulated by the host eukaryotic cell and involves communication between and contact with several other organelles. The regulation of this division differs between eukaryotes. In many single-celled eukaryotes, their growth and division are linked to the cell cycle. For example, a single mitochondrion may divide synchronously with the nucleus. This division and segregation process must be tightly controlled so that each daughter cell receives at least one mitochondrion. In other eukaryotes (in mammals for example), mitochondria may replicate their DNA and divide mainly in response to the energy needs of the cell, rather than in phase with the cell cycle. When the energy needs of a cell are high, mitochondria grow and divide. When energy use is low, mitochondria are destroyed or become inactive. In such examples mitochondria are apparently randomly distributed to the daughter cells during the division of the cytoplasm. Mitochondrial dynamics, the balance between mitochondrial fusion and fission, is an important factor in pathologies associated with several disease conditions.\nThe hypothesis of mitochondrial binary fission has relied on the visualization by fluorescence microscopy and conventional transmission electron microscopy (TEM). The resolution of fluorescence microscopy (\u2248200\u00a0nm) is insufficient to distinguish structural details, such as double mitochondrial membrane in mitochondrial division or even to distinguish individual mitochondria when several are close together. Conventional TEM has also some technical limitations in verifying mitochondrial division. Cryo-electron tomography was recently used to visualize mitochondrial division in frozen hydrated intact cells. It revealed that mitochondria divide by budding.\nAn individual's mitochondrial genes are inherited only from the mother, with rare exceptions. In humans, when an egg cell is fertilized by a sperm, the mitochondria, and therefore the mitochondrial DNA, usually come from the egg only. The sperm's mitochondria enter the egg, but do not contribute genetic information to the embryo. Instead, paternal mitochondria are marked with ubiquitin to select them for later destruction inside the embryo. The egg cell contains relatively few mitochondria, but these mitochondria divide to populate the cells of the adult organism. This mode is seen in most organisms, including the majority of animals. However, mitochondria in some species can sometimes be inherited paternally. This is the norm among certain coniferous plants, although not in pine trees and yews. For Mytilids, paternal inheritance only occurs within males of the species. It has been suggested that it occurs at a very low level in humans.\nUniparental inheritance leads to little opportunity for genetic recombination between different lineages of mitochondria, although a single mitochondrion can contain 2\u201310 copies of its DNA. What recombination does take place maintains genetic integrity rather than maintaining diversity. However, there are studies showing evidence of recombination in mitochondrial DNA. It is clear that the enzymes necessary for recombination are present in mammalian cells. Further, evidence suggests that animal mitochondria can undergo recombination. The data are more controversial in humans, although indirect evidence of recombination exists.\nEntities undergoing uniparental inheritance and with little to no recombination may be expected to be subject to Muller's ratchet, the accumulation of deleterious mutations until functionality is lost. Animal populations of mitochondria avoid this buildup through a developmental process known as the mtDNA bottleneck. The bottleneck exploits stochastic processes in the cell to increase the cell-to-cell variability in mutant load as an organism develops: a single egg cell with some proportion of mutant mtDNA thus produces an embryo where different cells have different mutant loads. Cell-level selection may then act to remove those cells with more mutant mtDNA, leading to a stabilization or reduction in mutant load between generations. The mechanism underlying the bottleneck is debated, with a recent mathematical and experimental metastudy providing evidence for a combination of random partitioning of mtDNAs at cell divisions and random turnover of mtDNA molecules within the cell.\nDNA repair.\nMitochondria can repair oxidative DNA damage by mechanisms analogous to those occurring in the cell nucleus. The proteins employed in mtDNA repair are encoded by nuclear genes, and are translocated to the mitochondria. The DNA repair pathways in mammalian mitochondria include base excision repair, double-strand break repair, direct reversal and mismatch repair. Alternatively, DNA damage may be bypassed, rather than repaired, by translesion synthesis.\nOf the several DNA repair process in mitochondria, the base excision repair pathway has been most comprehensively studied. Base excision repair is carried out by a sequence of enzyme-catalyzed steps that include recognition and excision of a damaged DNA base, removal of the resulting abasic site, end processing, gap filling and ligation. A common damage in mtDNA that is repaired by base excision repair is 8-oxoguanine produced by oxidation of guanine.\nDouble-strand breaks can be repaired by homologous recombinational repair in both mammalian mtDNA and plant mtDNA. Double-strand breaks in mtDNA can also be repaired by microhomology-mediated end joining. Although there is evidence for the repair processes of direct reversal and mismatch repair in mtDNA, these processes are not well characterized.\nLack of mitochondrial DNA.\nSome organisms have lost mitochondrial DNA altogether. In these cases, genes encoded by the mitochondrial DNA have been lost or transferred to the nucleus. \"Cryptosporidium\" have mitochondria that lack any DNA, presumably because all their genes have been lost or transferred. In \"Cryptosporidium\", the mitochondria have an altered ATP generation system that renders the parasite resistant to many classical mitochondrial inhibitors such as cyanide, azide, and atovaquone. Mitochondria that lack their own DNA have been found in a marine parasitic dinoflagellate from the genus \"Amoebophrya\". This microorganism, \"A. cerati\", has functional mitochondria that lack a genome. In related species, the mitochondrial genome still has three genes, but in \"A. cerati\" only a single mitochondrial gene \u2014 the cytochrome c oxidase I gene (\"cox1\") \u2014 is found, and it has migrated to the genome of the nucleus.\nDysfunction and disease.\nMitochondrial diseases.\nDamage and subsequent dysfunction in mitochondria is an important factor in a range of human diseases due to their influence in cell metabolism. Mitochondrial disorders often present as neurological disorders, including autism. They can also manifest as myopathy, diabetes, multiple endocrinopathy, and a variety of other systemic disorders. Diseases caused by mutation in the mtDNA include Kearns\u2013Sayre syndrome, MELAS syndrome and Leber's hereditary optic neuropathy. In the vast majority of cases, these diseases are transmitted by a female to her children, as the zygote derives its mitochondria and hence its mtDNA from the ovum. Diseases such as Kearns-Sayre syndrome, Pearson syndrome, and progressive external ophthalmoplegia are thought to be due to large-scale mtDNA rearrangements, whereas other diseases such as MELAS syndrome, Leber's hereditary optic neuropathy, MERRF syndrome, and others are due to point mutations in mtDNA.\nIt has also been reported that drug tolerant cancer cells have an increased number and size of mitochondria which suggested an increase in mitochondrial biogenesis. A 2022 study in \"Nature Nanotechnology\" has reported that cancer cells can hijack the mitochondria from immune cells via physical tunneling nanotubes.\nIn other diseases, defects in nuclear genes lead to dysfunction of mitochondrial proteins. This is the case in Friedreich's ataxia, hereditary spastic paraplegia, and Wilson's disease. These diseases are inherited in a dominance relationship, as applies to most other genetic diseases. A variety of disorders can be caused by nuclear mutations of oxidative phosphorylation enzymes, such as coenzyme Q10 deficiency and Barth syndrome. Environmental influences may interact with hereditary predispositions and cause mitochondrial disease. For example, there may be a link between pesticide exposure and the later onset of Parkinson's disease. Other pathologies with etiology involving mitochondrial dysfunction include schizophrenia, bipolar disorder, dementia, Alzheimer's disease, Parkinson's disease, epilepsy, stroke, cardiovascular disease, myalgic encephalomyelitis/chronic fatigue syndrome (ME/CFS), retinitis pigmentosa, and diabetes mellitus.\nMitochondria-mediated oxidative stress plays a role in cardiomyopathy in type 2 diabetics. Increased fatty acid delivery to the heart increases fatty acid uptake by cardiomyocytes, resulting in increased fatty acid oxidation in these cells. This process increases the reducing equivalents available to the electron transport chain of the mitochondria, ultimately increasing reactive oxygen species (ROS) production. ROS increases uncoupling proteins (UCPs) and potentiate proton leakage through the adenine nucleotide translocator (ANT), the combination of which uncouples the mitochondria. Uncoupling then increases oxygen consumption by the mitochondria, compounding the increase in fatty acid oxidation. This creates a vicious cycle of uncoupling; furthermore, even though oxygen consumption increases, ATP synthesis does not increase proportionally because the mitochondria are uncoupled. Less ATP availability ultimately results in an energy deficit presenting as reduced cardiac efficiency and contractile dysfunction. To compound the problem, impaired sarcoplasmic reticulum calcium release and reduced mitochondrial reuptake limits peak cytosolic levels of the important signaling ion during muscle contraction. Decreased intra-mitochondrial calcium concentration increases dehydrogenase activation and ATP synthesis. So in addition to lower ATP synthesis due to fatty acid oxidation, ATP synthesis is impaired by poor calcium signaling as well, causing cardiac problems for diabetics.\nMitochondria also modulate processes such as testicular somatic cell development, spermatogonial stem cell differentiation, luminal acidification, testosterone production in testes, and more. Thus, dysfunction of mitochondria in spermatozoa can be a cause for infertility.\nIn efforts to combat mitochondrial disease, mitochondrial replacement therapy (MRT) has been developed. This form of in vitro fertilization uses donor mitochondria, which avoids the transmission of diseases caused by mutations of mitochondrial DNA. However, this therapy is still being researched and can introduce genetic modification, as well as safety concerns. These diseases are rare but can be extremely debilitating and progressive diseases, thus posing complex ethical questions for public policy.\nRelationships to aging.\nThere may be some leakage of the electrons transferred in the respiratory chain to form reactive oxygen species. This was thought to result in significant oxidative stress in the mitochondria with high mutation rates of mitochondrial DNA. Hypothesized links between aging and oxidative stress are not new and were proposed in 1956, which was later refined into the mitochondrial free radical theory of aging. A vicious cycle was thought to occur, as oxidative stress leads to mitochondrial DNA mutations, which can lead to enzymatic abnormalities and further oxidative stress.\nA number of changes can occur to mitochondria during the aging process. Tissues from elderly humans show a decrease in enzymatic activity of the proteins of the respiratory chain. However, mutated mtDNA can only be found in about 0.2% of very old cells. Large deletions in the mitochondrial genome have been hypothesized to lead to high levels of oxidative stress and neuronal death in Parkinson's disease. Mitochondrial dysfunction has also been shown to occur in amyotrophic lateral sclerosis.\nSince mitochondria cover a pivotal role in the ovarian function, by providing ATP necessary for the development from germinal vesicle to mature oocyte, a decreased mitochondria function can lead to inflammation, resulting in premature ovarian failure and accelerated ovarian aging. The resulting dysfunction is then reflected in quantitative (such as mtDNA copy number and mtDNA deletions), qualitative (such as mutations and strand breaks) and oxidative damage (such as dysfunctional mitochondria due to ROS), which are not only relevant in ovarian aging, but perturb oocyte-cumulus crosstalk in the ovary, are linked to genetic disorders (such as Fragile X) and can interfere with embryo selection.\nHistory.\nThe first observations of intracellular structures that probably represented mitochondria were published in 1857, by the physiologist Albert von Kolliker. Richard Altmann, in 1890, established them as cell organelles and called them \"bioblasts\". In 1898, Carl Benda coined the term \"mitochondria\" from the Greek , , \"thread\", and , , \"granule\". Leonor Michaelis discovered that Janus green can be used as a supravital stain for mitochondria in 1900. In 1904, Friedrich Meves made the first recorded observation of mitochondria in plants in cells of the white waterlily, \"Nymphaea alba,\" and in 1908, along with Claudius Regaud, suggested that they contain proteins and lipids. Benjamin F. Kingsbury, in 1912, first related them with cell respiration, but almost exclusively based on morphological observations. In 1913, Otto Heinrich Warburg linked respiration to particles which he had obtained from extracts of guinea-pig liver and which he called \"grana\". Warburg and Heinrich Otto Wieland, who had also postulated a similar particle mechanism, disagreed on the chemical nature of the respiration. It was not until 1925, when David Keilin discovered cytochromes, that the respiratory chain was described.\nIn 1939, experiments using minced muscle cells demonstrated that cellular respiration using one oxygen molecule can form four adenosine triphosphate (ATP) molecules, and in 1941, the concept of the phosphate bonds of ATP being a form of energy in cellular metabolism was developed by Fritz Albert Lipmann. In the following years, the mechanism behind cellular respiration was further elaborated, although its link to the mitochondria was not known. The introduction of tissue fractionation by Albert Claude allowed mitochondria to be isolated from other cell fractions and biochemical analysis to be conducted on them alone. In 1946, he concluded that cytochrome oxidase and other enzymes responsible for the respiratory chain were isolated to the mitochondria. Eugene Kennedy and Albert Lehninger discovered in 1948 that mitochondria are the site of oxidative phosphorylation in eukaryotes. Over time, the fractionation method was further developed, improving the quality of the mitochondria isolated, and other elements of cell respiration were determined to occur in the mitochondria.\nThe first high-resolution electron micrographs appeared in 1952, replacing the Janus Green stains as the preferred way to visualize mitochondria. This led to a more detailed analysis of the structure of the mitochondria, including confirmation that they were surrounded by a membrane. It also showed a second membrane inside the mitochondria that folded up in ridges dividing up the inner chamber and that the size and shape of the mitochondria varied from cell to cell.\nThe popular term \"powerhouse of the cell\" was coined by Philip Siekevitz in 1957.\nIn 1967, it was discovered that mitochondria contained ribosomes. In 1968, methods were developed for mapping the mitochondrial genes, with the genetic and physical map of yeast mitochondrial DNA completed in 1976. In November 2024, Researchers from the United States have discovered that mitochondria divide into two distinct forms when cells are starved, this could help explain and describe how cancers thrive in hostile conditions.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nGeneral"}
{"id": "19589", "revid": "44217690", "url": "https://en.wikipedia.org/wiki?curid=19589", "title": "Minimax", "text": "Decision rule used for minimizing the possible loss for a worst case scenario\nMinimax (sometimes Minmax, MM or saddle point) is a decision rule used in artificial intelligence, decision theory, combinatorial game theory, statistics, and philosophy for \"minimizing\" the possible loss for a worst case (\"max\"imum loss) scenario. When dealing with gains, it is referred to as \"maximin\" \u2013 to maximize the minimum gain. Originally formulated for several-player zero-sum game theory, covering both the cases where players take alternate moves and those where they make simultaneous moves, it has also been extended to more complex games and to general decision-making in the presence of uncertainty.\nGame theory.\nIn general games.\nThe maximin value is the highest value that the player can be sure to get without knowing the actions of the other players; equivalently, it is the lowest value the other players can force the player to receive when they know the player's action. Its formal definition is:\nformula_1\nWhere:\nCalculating the maximin value of a player is done in a worst-case approach: for each possible action of the player, we check all possible actions of the other players and determine the worst possible combination of actions \u2013 the one that gives player i the smallest value. Then, we determine which action player i can take in order to make sure that this smallest value is the highest possible.\nFor example, consider the following game for two players, where the first player (\"row player\") may choose any of three moves, labelled T, M, or B, and the second player (\"column player\") may choose either of two moves, L or R. The result of the combination of both moves is expressed in a payoff table:\nformula_6\n(where the first number in each of the cell is the pay-out of the row player and the second number is the pay-out of the column player).\nFor the sake of example, we consider only pure strategies. Check each player in turn:\nIf both players play their respective maximin strategies formula_10, the payoff vector is formula_11.\nThe minimax value of a player is the smallest value that the other players can force the player to receive, without knowing the player's actions; equivalently, it is the largest value the player can be sure to get when they \"know\" the actions of the other players. Its formal definition is:\nformula_12\nThe definition is very similar to that of the maximin value \u2013 only the order of the maximum and minimum operators is inverse. In the above example:\nFor every player i, the maximin is at most the minimax:\nformula_15\nIntuitively, in maximin the maximization comes after the minimization, so player i tries to maximize their value before knowing what the others will do; in minimax the maximization comes before the minimization, so player i is in a much better position \u2013 they maximize their value knowing what the others did.\nAnother way to understand the \"notation\" is by reading from right to left: When we write\nformula_16\nthe initial set of outcomes formula_17 depends on both formula_18 and formula_19 We first \"marginalize away\" formula_20 from formula_21, by maximizing over formula_18 (for every possible value of formula_23) to yield a set of marginal outcomes formula_24 which depends only on formula_19 We then minimize over formula_26 over these outcomes. (Conversely for maximin.)\nAlthough it is always the case that formula_27 and formula_28 the payoff vector resulting from both players playing their minimax strategies, formula_29 in the case of formula_30 or formula_31 in the case of formula_32 cannot similarly be ranked against the payoff vector formula_33 resulting from both players playing their maximin strategy.\nIn zero-sum games.\nIn two-player zero-sum games, the minimax solution is the same as the Nash equilibrium.\nIn the context of zero-sum games, the minimax theorem is equivalent to:\nFor every two-person zero-sum game with finitely many strategies, there exists a value V and a mixed strategy for each player, such that\n(a) Given Player\u00a02's strategy, the best payoff possible for Player\u00a01 is V, and\n(b) Given Player\u00a01's strategy, the best payoff possible for Player 2 is \u2212V.\nEquivalently, Player\u00a01's strategy guarantees them a payoff of V regardless of Player\u00a02's strategy, and similarly Player\u00a02 can guarantee themselves a payoff of \u2212V. The name \"minimax\" arises because each player minimizes the maximum payoff possible for the other \u2013 since the game is zero-sum, they also minimize their own maximum loss (i.e., maximize their minimum payoff).\nSee also example of a game without a value.\nExample.\nThe following example of a zero-sum game, where A and B make simultaneous moves, illustrates \"maximin\" solutions. Suppose each player has three choices and consider the payoff matrix for A displayed on the table (\"Payoff matrix for player\u00a0A\"). Assume the payoff matrix for B is the same matrix with the signs reversed (i.e., if the choices are A1 and B1 then B pays\u00a03 to A). Then, the maximin choice for A is A2 since the worst possible result is then having to pay\u00a01, while the simple maximin choice for B is B2 since the worst possible result is then no payment. However, this solution is not stable, since if B believes A will choose A2 then B will choose B1 to gain\u00a01; then if A believes B will choose B1 then A will choose A1 to gain\u00a03; and then B will choose B2; and eventually both players will realize the difficulty of making a choice. So a more stable strategy is needed.\nSome choices are \"dominated\" by others and can be eliminated: A will not choose A3 since either A1 or A2 will produce a better result, no matter what B chooses; B will not choose B3 since some mixtures of B1 and B2 will produce a better result, no matter what A chooses.\nPlayer A can avoid having to make an expected payment of more than by choosing A1 with probability and A2 with probability : The expected payoff for A would be \u202f 3 \u00d7 \u2212 1 \u00d7 \n \u202f in case B chose B1 and \u202f \u22122 \u00d7 + 0 \u00d7 \n \u202f in case B chose B2. Similarly, B can ensure an expected gain of at least , no matter what A chooses, by using a randomized strategy of choosing B1 with probability and B2 with probability . These mixed minimax strategies cannot be improved and are now stable.\nMaximin.\nFrequently, in game theory, maximin is distinct from minimax. Minimax is used in zero-sum games to denote minimizing the opponent's maximum payoff. In a zero-sum game, this is identical to minimizing one's own maximum loss, and to maximizing one's own minimum gain.\n\"Maximin\" is a term commonly used for non-zero-sum games to describe the strategy which maximizes one's own minimum payoff. In non-zero-sum games, this is not generally the same as minimizing the opponent's maximum gain, nor the same as the Nash equilibrium strategy.\nIn repeated games.\nThe minimax values are very important in the theory of repeated games. One of the central theorems in this theory, the folk theorem, relies on the minimax values.\nCombinatorial game theory.\nIn combinatorial game theory, there is a minimax algorithm for game solutions.\nA simple version of the minimax \"algorithm\", stated below, deals with games such as tic-tac-toe, where each player can win, lose, or draw. If player\u00a0A \"can\" win in one move, their best move is that winning move. If player\u00a0B knows that one move will lead to the situation where player\u00a0A \"can\" win in one move, while another move will lead to the situation where player\u00a0A can, at best, draw, then player\u00a0B's best move is the one leading to a draw. Late in the game, it's easy to see what the \"best\" move is. The minimax algorithm helps find the best move, by working backwards from the end of the game. At each step it assumes that player\u00a0A is trying to maximize the chances of A winning, while on the next turn player B is trying to minimize the chances of A winning (i.e., to maximize B's own chances of winning).\nMinimax algorithm with alternate moves.\nA minimax algorithm is a recursive algorithm for choosing the next move in an n-player game, usually a two-player game. A value is associated with each position or state of the game. This value is computed by means of a position evaluation function and it indicates how good it would be for a player to reach that position. The player then makes the move that maximizes the minimum value of the position resulting from the opponent's possible following moves. If it is A's turn to move, A gives a value to each of their legal moves.\nA possible allocation method consists in assigning a certain win for A as +1 and for B as \u22121. This leads to combinatorial game theory as developed by John H. Conway. An alternative is using a rule that if the result of a move is an immediate win for A, it is assigned positive infinity and if it is an immediate win for B, negative infinity. The value to A of any other move is the maximum of the values resulting from each of B's possible replies. For this reason, A is called the \"maximizing player\" and B is called the \"minimizing player\", hence the name \"minimax algorithm\". The above algorithm will assign a value of positive or negative infinity to any position since the value of every position will be the value of some final winning or losing position. Often this is generally only possible at the very end of complicated games such as chess or go, since it is not computationally feasible to look ahead as far as the completion of the game, except towards the end, and instead, positions are given finite values as estimates of the degree of belief that they will lead to a win for one player or another.\nThis can be extended if we can supply a heuristic evaluation function which gives values to non-final game states without considering all possible following complete sequences. We can then limit the minimax algorithm to look only at a certain number of moves ahead. This number is called the \"look-ahead\", measured in \"plies\". For example, the chess computer Deep Blue (the first one to beat a reigning world champion, Garry Kasparov at that time) looked ahead at least 12\u00a0plies, then applied a heuristic evaluation function.\nThe algorithm can be thought of as exploring the nodes of a \"game tree\". The \"effective branching factor\" of the tree is the average number of children of each node (i.e., the average number of legal moves in a position). The number of nodes to be explored usually increases exponentially with the number of plies (it is less than exponential if evaluating forced moves or repeated positions). The number of nodes to be explored for the analysis of a game is therefore approximately the branching factor raised to the power of the number of plies. It is therefore impractical to completely analyze games such as chess using the minimax algorithm.\nThe performance of the na\u00efve minimax algorithm may be improved dramatically, without affecting the result, by the use of alpha\u2013beta pruning. Other heuristic pruning methods can also be used, but not all of them are guaranteed to give the same result as the unpruned search.\nA na\u00efve minimax algorithm may be trivially modified to additionally return an entire Principal Variation along with a minimax score.\nPseudocode.\nThe pseudocode for the depth-limited minimax algorithm is given below.\n function minimax(node, depth, maximizingPlayer) is\n if depth = 0 or node is a terminal node then\n return the heuristic value of node\n if maximizingPlayer then\n value := \u2212\u221e\n for each child of node do\n value := max(value, minimax(child, depth \u2212 1, FALSE))\n return value\n else \"(* minimizing player *)\"\n value := +\u221e\n for each child of node do\n value := min(value, minimax(child, depth \u2212 1, TRUE))\n return value\n \"(* Initial call *)\"\n minimax(origin, depth, TRUE)\nThe minimax function returns a heuristic value for leaf nodes (terminal nodes and nodes at the maximum search depth). Non-leaf nodes inherit their value from a descendant leaf node. The heuristic value is a score measuring the favorability of the node for the maximizing player. Hence nodes resulting in a favorable outcome, such as a win, for the maximizing player have higher scores than nodes more favorable for the minimizing player. The heuristic value for terminal (game ending) leaf nodes are scores corresponding to win, loss, or draw, for the maximizing player. For non terminal leaf nodes at the maximum search depth, an evaluation function estimates a heuristic value for the node. The quality of this estimate and the search depth determine the quality and accuracy of the final minimax result.\nMinimax treats the two players (the maximizing player and the minimizing player) separately in its code. Based on the observation that formula_34 minimax may often be simplified into the negamax algorithm.\nExample.\nSuppose the game being played only has a maximum of two possible moves per player each turn. The algorithm generates the tree on the right, where the circles represent the moves of the player running the algorithm (\"maximizing player\"), and squares represent the moves of the opponent (\"minimizing player\"). Because of the limitation of computation resources, as explained above, the tree is limited to a \"look-ahead\" of 4\u00a0moves.\nThe algorithm evaluates each \"leaf node\" using a heuristic evaluation function, obtaining the values shown. The moves where the \"maximizing player\" wins are assigned with positive infinity, while the moves that lead to a win of the \"minimizing player\" are assigned with negative infinity. At level\u00a03, the algorithm will choose, for each node, the smallest of the \"child node\" values, and assign it to that same node (e.g. the node on the left will choose the minimum between \"10\" and \"+\u221e\", therefore assigning the value \"10\" to itself). The next step, in level\u00a02, consists of choosing for each node the largest of the \"child node\" values. Once again, the values are assigned to each \"parent node\". The algorithm continues evaluating the maximum and minimum values of the child nodes alternately until it reaches the \"root node\", where it chooses the move with the largest value (represented in the figure with a blue arrow). This is the move that the player should make in order to \"minimize\" the \"maximum\" possible loss.\nFor individual decisions.\nIn the face of uncertainty.\nMinimax theory has been extended to decisions where there is no other player, but where the consequences of decisions depend on unknown facts. For example, deciding to prospect for minerals entails a cost, which will be wasted if the minerals are not present, but will bring major rewards if they are. One approach is to treat this as a game against \"nature\" (see move by nature), and using a similar mindset as Murphy's law or resistentialism, take an approach which minimizes the maximum expected loss, using the same techniques as in the two-person zero-sum games.\nIn addition, expectiminimax trees have been developed, for two-player games in which chance (for example, dice) is a factor.\nCriterion in statistical decision theory.\nIn classical statistical decision theory, we have an estimator formula_35 that is used to estimate a parameter formula_36 We also assume a risk function formula_37 usually specified as the integral of a loss function. In this framework, formula_38 is called minimax if it satisfies\n formula_39\nAn alternative criterion in the decision theoretic framework is the Bayes estimator in the presence of a prior distribution formula_40 An estimator is Bayes if it minimizes the \"average\" risk\n formula_41\nNon-probabilistic decision theory.\nA key feature of minimax decision making is being non-probabilistic: in contrast to decisions using expected value or expected utility, it makes no assumptions about the probabilities of various outcomes, just scenario analysis of what the possible outcomes are. It is thus robust to changes in the assumptions, in contrast to these other decision techniques. Various extensions of this non-probabilistic approach exist, notably minimax regret and Info-gap decision theory.\nFurther, minimax only requires ordinal measurement (that outcomes be compared and ranked), not \"interval\" measurements (that outcomes include \"how much better or worse\"), and returns ordinal data, using only the modeled outcomes: the conclusion of a minimax analysis is: \"this strategy is minimax, as the worst case is (outcome), which is less bad than any other strategy\". Compare to expected value analysis, whose conclusion is of the form: \"This strategy yields Minimax thus can be used on ordinal data, and can be more transparent.\nMinimax.\nThe concept of \"lesser evil\" voting (LEV) can be seen as a form of the minimax strategy where voters, when faced with two or more candidates, choose the one they perceive as the least harmful or the \"lesser evil.\" To do so, \"voting should not be viewed as a form of personal self-expression or moral judgement directed in retaliation towards major party candidates who fail to reflect our values, or of a corrupt system designed to limit choices to those acceptable to corporate elites,\" but rather as an opportunity to reduce harm or loss.\nMaximin in philosophy.\nIn philosophy, the term \"maximin\" is often used in the context of John Rawls's \"A Theory of Justice,\" where he refers to it in the context of The Difference Principle. Rawls defined this principle as the rule which states that social and economic inequalities should be arranged so that \"they are to be of the greatest benefit to the least-advantaged members of society\".\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt; \nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "19590", "revid": "196446", "url": "https://en.wikipedia.org/wiki?curid=19590", "title": "Minnesota", "text": "U.S. state\nMinnesota ( ) is a state in the Upper Midwestern region of the United States. It is bordered by the Canadian provinces of Manitoba and Ontario to the north and east and by the U.S. states of Wisconsin to the east, Iowa to the south, and North Dakota and South Dakota to the west. The northeast corner has a water boundary with Michigan. It is the 12th-largest U.S. state in area and the 22nd-most populous, with about 5.8 million residents. Minnesota is known as the \"Land of 10,000 Lakes\"; it has 14,420 bodies of fresh water covering at least ten acres each. Roughly a third of the state is forested. Much of the remainder is prairie and farmland. More than 60% of Minnesotans (about 3.71 million) live in the Minneapolis\u2013Saint Paul metropolitan area, known as the \"Twin Cities\", which is Minnesota's main political, economic, and cultural hub and the 16th-largest metropolitan area in the U.S. Other minor metropolitan and micropolitan statistical areas include Duluth, Mankato, Moorhead, Rochester, and St. Cloud.\nMinnesota, which derives its name from the Dakota language, has been inhabited by various Native Americans since the Woodland period of the 11th century BCE. Between roughly 200 and 500 CE, two areas of the indigenous Hopewell tradition emerged: the Laurel complex in the north, and Trempealeau Hopewell in the Mississippi River Valley in the south. The Upper Mississippian culture, consisting of the Oneota people and other Siouan speakers, emerged around 1000 CE and lasted through the arrival of Europeans in the 17th century. French explorers and missionaries were the earliest Europeans to enter the region, encountering the Dakota, Ojibwe, and various Anishinaabe tribes. Much of what is now Minnesota formed part of the vast French holding of Louisiana, which the United States purchased in 1803. After several territorial reorganizations, the Minnesota Territory was admitted to the Union as the 32nd state in 1858. Minnesota's official motto, (\"The Star of the North\"), is the only state motto in French. This phrase was adopted shortly after statehood and reflects both the state's early French explorers and its position as the northernmost state in the contiguous U.S.\nAs part of the American frontier, Minnesota attracted settlers and homesteaders from across the country. Its growth was initially based on timber, agriculture, and railroad construction. Into the early 20th century, European immigrants arrived in significant numbers, particularly from Scandinavia, Germany, and Central Europe. Many were linked to the failed revolutions of 1848, which partly influenced the state's development as a center of labor and social activism. Minnesota's rapid industrialization and urbanization precipitated major social, economic, and political changes in the late 19th and early 20th centuries; the state was at the forefront of labor rights, women's suffrage, and political reform. Consequently, Minnesota is relatively unique among Midwestern states in being a reliable base for the Democratic Party, having voted for every Democratic presidential nominee since 1976, longer than any other U.S. state.\nSince the late 20th century, Minnesota's economy has diversified away from traditional industries such as agriculture and resource extraction to services, finance, and health care. Minnesota ranks highly among national averages in terms of life expectancy, healthcare standards, and education, and above average in income per capita. Minnesota is home to 11 federally recognized Native American reservations (seven Ojibwe, four Dakota), and its culture, demographics, and religious landscape reflect Scandinavian and German influence. This heritage continues to affect the state's racial demographics, making it one of the country's least diverse states, but in recent decades, Minnesota has become more multicultural, due to both larger domestic migration and immigration from Latin America, Asia, the Horn of Africa, and the Middle East. The state has the nation's largest population of Somali Americans and second-largest Hmong community.\nEtymology.\nThe word \"Minnesota\" comes from the Dakota name for the Minnesota River, which got its name from one of two words in Dakota: \"\", which means \"clear blue water\", or \"\", which means \"cloudy water\". Early explorers interpreted the Dakota name for the Minnesota River in different ways, and four spellings of the state's name were considered before settling on \"Minnesota\" in 1849, when the Territory of Minnesota was formed. Dakota people demonstrated the name to early settlers by dropping milk into water and calling it \"\".\nMany places in the state have similar Dakota names, such as Minnehaha Falls (\"curling water\" or waterfall), Minneiska (\"white water\"), Minneota (\"much water\"), Minnetonka (\"big water\"), Minnetrista (\"crooked water\"), and Minneapolis, a hybrid word combining Dakota \"\" (\"water\") and \"-\" (Greek for \"city\"). The state seal features the phrase (\"the land where the water reflects the skies\"), the Dakota name for the larger region.\nHistory.\nWhen Europeans arrived in North America, the Dakota people lived in what is now Minnesota. The first Europeans to enter the region were French voyageurs, fur traders who arrived in the 17th century. They used the Grand Portage to access trapping and trading areas further into Minnesota. The Anishinaabe (also known as Ojibwe or Chippewa) were migrating into Minnesota, causing tensions with the Dakota people, and dislocated the Mdewakanton from their homelands along Mille Lacs Lake. Explorers such as Daniel Greysolon, Sieur du Lhut, Father Louis Hennepin, Jonathan Carver, Henry Schoolcraft, and Joseph Nicollet mapped the state.\nThe region was part of Spanish Louisiana from 1762 to 1802. The portion of the state east of the Mississippi River became part of the United States at the end of the American Revolutionary War, when the Second Treaty of Paris was signed. Land west of the Mississippi was acquired with the Louisiana Purchase, though the Hudson's Bay Company disputed the Red River Valley until the Treaty of 1818, when the border on the 49th parallel was agreed upon.\nIn 1805, Zebulon Pike bargained with Native Americans to acquire land at the confluence of the Minnesota and Mississippi rivers to create a military reservation. The construction of Fort Snelling followed between 1819 and 1825. Its soldiers built a grist mill and a sawmill at Saint Anthony Falls, which were harbingers of the water-powered industries around which Minneapolis later grew. Meanwhile, squatters, government officials, and others had settled near the fort; in 1839 the army forced them off military lands, and most moved downriver, just outside the military reservation, to the area that became St. Paul.\nMinnesota was part of several territorial organizations between acquisition and statehood. From 1812 to 1821 it was part of the Territory of Missouri that corresponded with much of the Louisiana Purchase. It was briefly an unorganized territory (1821\u20131834) and was later consolidated with Wisconsin, Iowa and half the Dakotas to form the short-lived Territory of Michigan (1834\u20131836). From 1836 to 1848, Minnesota and Iowa were part of the Territory of Wisconsin. From 1838 to 1846, Minnesota west of the Mississippi River was part of the Territory of Iowa. Minnesota east of the Mississippi was part of Wisconsin until 1848.\nWhen Iowa gained statehood, western Minnesota was in an Unorganized Territory again. Minnesota Territory was formed on March 3, 1849. The first territorial legislature, held on September 2, 1849, was dominated by men of New England ancestry. Thousands of pioneers had come to create farms and cut timber. Minnesota became the 32nd U.S. state on May 11, 1858. The founding population was so overwhelmingly of New England origins that the state was dubbed \"the New England of the West\".\nTreaties between the U.S. government and the eastern Dakota and Ojibwe gradually forced the natives off their lands and onto reservations. As conditions deteriorated for the eastern Dakota, tensions rose, leading to the Dakota War of 1862. The conflict was ignited when four young Dakota men, searching for food, killed a family of white settlers on August 17. That night, a faction of Little Crow's eastern Dakota decided to try to drive all settlers out of the Minnesota River valley. In the weeks that followed, Dakota warriors killed hundreds of settlers, causing thousands to flee the area. The six-week war ended with the defeat of the eastern Dakota and 2,000 in custody, who were eventually exiled to the Crow Creek Reservation by the Great Sioux Reservation in Dakota Territory. The remaining 4,500 to 5,000 Dakota mostly fled the state into Rupert's Land. As many as 800 settlers were killed during the war.\nMinnesota Governor Alexander Ramsey subsequently declared that \"the Sioux Indians of Minnesota must be exterminated or driven forever beyond the borders of the state\" and placed a bounty of $25/scalp on the heads of the eastern Dakota men. Over 1,600 eastern Dakota women, children, and elderly walked from the Lower Sioux Agency to Fort Snelling to be held until the spring thaw allowed riverboats to take them out of Minnesota to Crow Creek Indian Reservation. William Crooks, commander of 6th Minnesota, had a palisade erected around the encampment on Pike Island, just below the fort, to protect native people from the soldiers and settlers. Conditions there were poor and between 125 and 300 died of disease. Around 400 Dakota men were tried after the war. 303 were sentenced to death, but Abraham Lincoln reviewed the convictions and approved 39 of the death sentences. In December 1862, 38 of them were hanged.\nIn early 1863, Ramsey resigned as governor to become the Federal Indian Commissioner. His successor, Governor Henry Swift, raised the bounty to $200/scalp. A total of $325 was paid out to four people collecting bounties, including for Little Crow who was killed in July 1863. Upon becoming Indian Commissioner, Ramsey set out to get Ojibwe lands too. In 1863 he negotiated the Treaty of Old Crossing, whereby the Ojibwe ceded all their land in northern Minnesota and moved to reservations.\nLogging, farming, and railroads were mainstays of Minnesota's early economy. The sawmills at Saint Anthony Falls and logging centers of Pine City, Marine on St. Croix, Stillwater, and Winona processed vast quantities of timber. These cities were on rivers that were ideal for transportation. St. Anthony Falls was later tapped to provide power for flour mills. Innovations by Minneapolis millers led to the production of Minnesota \"patent\" flour, which commanded almost double the price of \"bakers'\" or \"clear\" flour which it replaced. By 1900, Minnesota mills, led by Pillsbury, Northwestern, and the Washburn-Crosby Company, an ancestor of General Mills, were grinding 14.1% of the nation's grain.\nThe state's iron-mining industry was established with the discovery of iron in the Vermilion and Mesabi ranges in the 1880s, followed by the Cuyuna Range in the early 1900s. The ore went by rail to Duluth and Two Harbors for ship transport east via the Great Lakes.\nIndustrial development and the rise of manufacturing caused the population to shift gradually from rural areas to cities during the early 20th century. Nevertheless, farming remained prevalent. Minnesota's economy was hit hard by the Great Depression, resulting in lower prices for farmers, layoffs among iron miners, and labor unrest. Compounding the adversity, western Minnesota and the Dakotas were hit by drought from 1931 to 1935. New Deal programs provided some economic turnaround. The Civilian Conservation Corps and other programs around the state established some jobs for Indians on their reservations, and the Indian Reorganization Act of 1934 provided the tribes with a mechanism of self-government. This gave Natives a greater voice within the state and promoted more respect for tribal customs because religious ceremonies and native languages were no longer suppressed.\nAfter World War II, industrial development quickened. New technology increased farm productivity through automation of feedlots for hogs and cattle, machine milking at dairy farms, and raising chickens in large buildings. Planting became more specialized, with hybridization of corn and wheat, and farm machinery such as tractors and combines became the norm. University of Minnesota professor Norman Borlaug contributed to these developments as part of the Green Revolution. Increased mobility enabled more specialized jobs.\nMinnesota became a center of technology after World War II. Engineering Research Associates was formed in 1946 to develop computers for the United States Navy. It later merged with Remington Rand, and then became Sperry Rand. William Norris left Sperry in 1957 to form Control Data Corporation (CDC). Cray Research was formed when Seymour Cray left CDC to form his own company. Medical device maker Medtronic also started business in the Twin Cities in 1949. The nonprofit Mayo Clinic, which was founded in 1864 in Rochester, grew to become one of the country's leading medical systems, and, by the 21st century, Minnesota's largest private employer.\nIn 1957, the legislature created a planning commission for the Twin Cities metropolitan area, which became the Metropolitan Council in 1967. In 1971, under Governor Wendell Anderson, a series of legislation called the \"Minnesota Miracle\" led to a broad reform in financing of Minnesota public schools and local governments that created a fairer distribution in taxation and education. Two postwar Minnesota governors, former dentist Rudy Perpich and former professional wrestler Jesse Ventura, attracted national attention for their unconventional manner, but both enjoyed some popularity within the state. After a period of mostly divided government during the 21st century, the DFL (Democratic\u2013Farmer\u2013Labor Party) gained control of all three branches of Minnesota's government and passed significant reforms in the 2023 legislative session, moving the state in a progressive direction.\nGeography.\nMinnesota is the second northernmost U.S. state (after Alaska) and northernmost contiguous state, as the isolated Northwest Angle in Lake of the Woods County is the only part of the 48 contiguous states north of the 49th parallel. The state is part of the U.S. region known as the Upper Midwest and part of North America's Great Lakes region. It shares a Lake Superior water border with Michigan and a land and water border with Wisconsin to the east. Iowa is to the south, North Dakota and South Dakota are to the west, and the Canadian provinces of Ontario and Manitoba are to the north. With , or approximately 2.25% of the United States, Minnesota is the 12th-largest state.\nGeology.\nMinnesota has some of the earth's oldest rocks, gneisses that are about 3.6billion years old (80% as old as the planet). About 2.7billion years ago basaltic lava poured out of cracks in the floor of the primordial ocean; the remains of this volcanic rock formed the Canadian Shield in northeast Minnesota. The roots of these volcanic mountains and the action of Precambrian seas formed the Iron Range of northern Minnesota. Since a period of volcanism 1.1billion years ago, Minnesota's geological activity has been more subdued, with no volcanism or mountain formation, but with repeated incursions of the sea, which left behind multiple strata of sedimentary rock.\nIn more recent times, massive ice sheets at least one kilometer thick ravaged the state's landscape and sculpted its terrain. The Wisconsin glaciation left 12,000 years ago. These glaciers covered all of Minnesota except the far southeast, an area characterized by steep hills and streams that cut into the bedrock. This area is known as the Driftless Zone for its absence of glacial drift. Much of the remainder of the state has 50 feet (15m) or more of glacial till left behind as the last glaciers retreated. Gigantic Lake Agassiz formed in the northwest 13,000 years ago. Its flatbed now is the fertile Red River valley, and its outflow, glacial River Warren, carved the valley of the Minnesota River and the Upper Mississippi downstream from Fort Snelling. Minnesota is geologically quiet today; it experiences earthquakes infrequently, most of them minor.\nThe state's high point is Eagle Mountain at 2,301 feet (701m), which is only away from the low point of 601 feet (183m) at the shore of Lake Superior. Notwithstanding dramatic local differences in elevation, much of the state is a gently rolling peneplain.\nTwo major drainage divides meet in Minnesota's northeast in rural Hibbing, forming a triple watershed. Precipitation can follow the Mississippi River south to the Gulf of Mexico, the Saint Lawrence Seaway east to the Atlantic Ocean, or the Hudson Bay watershed to the Arctic Ocean.\nThe state's nickname \"Land of 10,000 Lakes\" is apt, as there are 11,842 Minnesota lakes over in size. Minnesota's portion of Lake Superior is the largest (at ) and deepest (at ) body of water in the state. Minnesota has 6,564 natural rivers and streams that cumulatively flow for . The Mississippi River begins its journey from its headwaters at Lake Itasca and crosses the Iowa border downstream. It is joined by the Minnesota River at Fort Snelling, by the St. Croix River near Hastings, by the Chippewa River at Wabasha, and by many smaller streams. The Red River drains the northwest part of the state northward toward Canada's Hudson Bay. Approximately of wetlands are within Minnesota's borders, the most of any state outside Alaska.\nFlora and fauna.\nMinnesota has four ecological provinces: prairie parkland, in the southwestern and western parts of the state; the eastern broadleaf forest (Big Woods) in the southeast, extending in a narrowing strip to the state's northwestern part, where it transitions into tallgrass aspen parkland; and the northern Laurentian mixed forest, a transitional forest between the northern boreal forest and the broadleaf forests to the south. These northern forests are a vast wilderness of pine and spruce trees mixed with patchy stands of birch and poplar.\nMuch of Minnesota's northern forest has undergone logging, leaving only a few patches of old growth forest today in areas such as the Chippewa National Forest and the Superior National Forest, where the Boundary Waters Canoe Area Wilderness has some of unlogged land. Although logging continues, regrowth and replanting keep about a third of the state forested. Nearly all Minnesota's prairies and oak savannas have been fragmented by farming, grazing, logging, and suburban development.\nWhile loss of habitat has affected native animals such as the pine marten, elk, woodland caribou, and bison, others like whitetail deer and bobcat thrive. Minnesota has the nation's largest population of timber wolves outside Alaska, and supports healthy populations of black bears, moose, and gophers. Located on the Mississippi Flyway, Minnesota hosts migratory waterfowl such as geese and ducks, and game birds such as grouse, pheasants, and turkeys. It is home to birds of prey, including the largest number of breeding pairs of bald eagles in the lower 48 states as of 2007, red-tailed hawks, and snowy owls. Hawk Ridge is one of the premier birdwatching sites in North America. The lakes teem with sport fish such as walleye, bass, muskellunge, and northern pike, while brook, brown, and rainbow trout populate streams in the southeast and northeast.\nClimate.\nMinnesota experiences temperature extremes characteristic of its continental climate, with cold winters and hot summers. The lowest temperature recorded was at Tower on February 2, 1996. The highest was at Moorhead on July 6, 1936. Meteorological events include rain, snow, blizzards, thunderstorms, hail, derechos, tornadoes, and high-velocity straight-line winds. The growing season varies from 90 days in the far northeast to 160 days in southeast Minnesota near the Mississippi River. Average temperatures range from . Average summer dewpoints range from about in the south to about in the north. Average annual precipitation ranges from . Droughts occur every 10 to 50 years.\nMinnesota has been affected by climate change and warmed over the past few years. Rising temperatures have affected natural habitats and many species that live in them. For example, the lakes' water is warming, which affects fish populations: trout, a cold-water fish, is losing its habitat, while the habitat of bass, a warm-water fish, is growing.\nProtected lands.\nMinnesota's first state park, Itasca State Park, was established in 1891, and is the source of the Mississippi River. Today Minnesota has 72 state parks and recreation areas, 58 state forests covering about four million acres (16,000km2), and numerous state wildlife preserves, all managed by the Minnesota Department of Natural Resources. The Chippewa and Superior national forests comprise . The Superior National Forest in the northeast contains the Boundary Waters Canoe Area Wilderness, which encompasses over a million acres (4,000km2) and a thousand lakes. To its west is Voyageurs National Park. The Mississippi National River and Recreation Area (MNRRA) is a corridor along the Mississippi River through the Minneapolis\u2013St. Paul Metropolitan Area connecting a variety of sites of historic, cultural, and geologic interest.\nCities and towns.\nSaint Paul, in east-central Minnesota along the banks of the Mississippi River, has been Minnesota's capital city since 1849, first as capital of the Territory of Minnesota, and then as the state capital since 1858.\nSaint Paul is adjacent to Minnesota's most populous city, Minneapolis; they and their suburbs are collectively known as the Twin Cities metropolitan area, the country's 16th-largest metropolitan area and home to about 55% of the state's population. The remainder of the state is known as \"Greater Minnesota\" or \"Outstate Minnesota\".\nThe state has 17 cities with populations above 50,000 as of the 2020 census. In descending order of population, they are Minneapolis, Saint Paul, Rochester, Duluth, Bloomington, Brooklyn Park, Plymouth, Saint Cloud, Woodbury, Eagan, Maple Grove, Coon Rapids, Eden Prairie, Minnetonka, Burnsville, Apple Valley, Blaine, and Lakeville. Of these, only Rochester, Duluth, and Saint Cloud are outside the Twin Cities metropolitan area.\nMinnesota's population continues to grow, primarily in the urban centers. The populations of metropolitan Sherburne and Scott counties doubled between 1980 and 2000, while 40 of the state's 87 counties lost residents over the same period.\n&lt;templatestyles src=\"Template:Largest_cities/styles.css\" /&gt;\nThe United States Navy has recognized\nmultiple Minnesota communities.\nDemographics.\nOverview.\n&lt;templatestyles src=\"US Census population/styles.css\"/&gt;\nAccording to the United States Census Bureau and the Minnesota State Demographic Center, Minnesota had a population of about 5.7 million in 2020, making it the 22nd-most populous U.S. state. Its fertility rate in 2021 was slightly below the replacement rate at 1.75, but the state has seen growth over the past century through more births than deaths, and significant immigration. A destination for European immigrants in the late 19th and early 20th centuries, primarily from Scandinavia, Germany, and Ireland, it now attracts people from Latin America, primarily Mexico; East Africa, particularly Somalis and Ethiopians; and South and Southeast Asia, especially Hmong, Vietnamese, and Indians. The state has a diverse population in terms of age, birthplace, ancestry, and socioeconomic status, with a well-educated populace and a median household income around $77,000.\nRace and ethnicity.\nMinnesota's racial demographics have significantly diversified since its early settlement period. As of 2020, according to U.S. census data, the white population had fallen to 77.5% from over 98% in the early to mid-20th century. Concurrently, other racial populations have markedly increased. The Black population has risen to 7%, the Asian population to 5.3%, and those identifying as two or more races to 6.1%.\nIn the 2017 American Community Survey, 5.1% of Minnesota's population were of Hispanic or Latino origin (of any race): Mexican (3.5%), Puerto Rican (0.2%), Cuban (0.1%), and other Hispanic or Latino origin (1.2%). The ancestry groups claimed by more than 5% of the population were German (33.8%), Norwegian (15.3%), Irish (10.5%), Swedish (8.1%), and English (5.4%). Minnesota has the country's largest Somali population, and the largest Hmong population per capita. Minnesota also has the largest Norwegian American and Swedish American populations.\nImmigration.\nSince the 1960s, Minnesota's immigrant population has been shaped by its status as a major area for refugee resettlement. As of 2018, Minnesota had the largest refugee population per capita of any state, with 2% of the country's population but 13% of its refugees. The largest groups of refugees over the past decades have been Hmongs, Somalis, Ethiopians, and Vietnamese; other major refugee groups that have recently been settling in Minnesota include Burmese, Liberians, Ecuadorians, Congolese, Russians, and Ukrainians. Minnesota also receives large numbers of non-refugee immigrants, primarily from Mexico, India, China, Korea, and Canada.\nReligion.\nMinnesota's religious landscape is also diverse, having evolved significantly over its history. The area's first Christian influence came from Catholic missionaries in the 17th and 18th centuries. 19th-century European settlers, especially Scandinavians, established Protestant denominations, particularly Lutheranism. Catholicism also continued to be significant due to Irish immigrants, and the Archdiocese of Saint Paul and Minneapolis serves a substantial Catholic community. The 20th and 21st centuries witnessed growth in other Christian denominations and non-Christian religions due to further immigration, leading to the establishment of Buddhist, Hmong folk religion, Muslim, and Hindu communities, as well as a sizable Jewish community. A growing number of people identify as non-religious, in line with national trends. As of 2014, 74% of Minnesotans identified as Christian, 5% belonged to non-Christian faiths, and 20% identified as religiously unaffiliated, according to the Pew Research Center.\nLanguages.\nMinnesota does not have an official language, although English is dominant, spoken by about 90% of residents. Other languages spoken include Spanish, Somali, Hmong, Vietnamese, Chinese, Russian, Arabic, Amharic, and Karen.\nEconomy.\nOnce primarily a producer of raw materials, Minnesota's economy has transformed to emphasize finished products and services. Perhaps the most significant characteristic of the economy is its diversity; the relative outputs of its business sectors closely match the United States as a whole. Minnesota's economy had a gross domestic product of $383billion in 2019, with 33 of the United States' top 1,000 publicly traded companies by revenue headquartered in Minnesota, including Target, UnitedHealth Group, 3M, General Mills, U.S. Bancorp, Ameriprise, Hormel, Land O' Lakes, SuperValu, Best Buy, and Valspar. Private companies based in Minnesota include Cargill, the largest privately owned company in the United States, and Carlson Companies, the parent company of Radisson Hotels.\nMinnesota's per capita personal income in 2019 was $58,834, the thirteenth-highest in the nation. Its 2019 median household income was $74,593, ranking thirteenth in the U.S. and fifth among the 36 states not on the Atlantic coast.\nIndustry and commerce.\nMinnesota's earliest industries were fur trading and agriculture. Minneapolis grew around the flour mills powered by St. Anthony Falls. Although less than 1% of the population is now employed in the agricultural sector, it remains a major part of the state's economy, ranking sixth in the nation in the value of products sold. The state is the nation's largest producer of sugar beets, sweet corn, peas for processing, and farm-raised turkeys. Minnesota is also a large producer of corn and soybeans, and has the most food cooperatives per capita in the United States. Forestry remains strong, including logging, pulpwood processing and paper production, and forest products manufacturing. Minnesota was famous for its soft-ore mines, which produced a significant portion of the world's iron ore for more than a century. Although the high-grade ore is now depleted, taconite mining continues, using processes developed locally to save the industry. In 2016 the state produced 60% of the country's usable iron ore. The mining boom created the port of Duluth, which continues to be important for shipping ore, coal, and agricultural products. The manufacturing sector now includes technology and biomedical firms, in addition to the older food processors and heavy industry. The nation's first indoor shopping mall was Edina's Southdale Center, and its largest is Bloomington's Mall of America. Minnesota is one of 45 U.S. states with its own lottery; its games include multi-jurisdiction draws and in-house draws.\nLargest employers.\nAs of 2025, Minnesota's largest employers were:\nEnergy use and production.\nMinnesota produces ethanol fuel and is the first to mandate its use, a 10% mix (E10). In 2019 there were more than 411 service stations supplying E85 fuel, comprising 85% ethanol and 15% gasoline. A 2% biodiesel blend has been required in diesel fuel since 2005. Minnesota is ranked in the top ten for wind energy production. The state gets nearly one-fifth of all its electrical energy from wind.\nXcel Energy is the state's largest utility and is headquartered in the state; it is one of five investor-owned utilities. There are also a number of municipal utilities. There are also 44 electric distribution cooperatives serving retail electric consumers throughout the state.\nState taxes.\nMinnesota has a progressive income tax structure; the four brackets of state income tax rates are 5.35%, 7.05%, 7.85%, and 9.85%. As of 2008 Minnesota was ranked 12th in the nation in per capita total state and local taxes. In 2008 Minnesotans paid 10.2% of their income in state and local taxes; the U.S. average was 9.7%. The state sales tax in Minnesota is 6.875%, but clothing, prescription drug medications and food items for home consumption are exempt. The state legislature may allow municipalities to institute local sales taxes and special local taxes, such as the 0.5% supplemental sales tax in Minneapolis. Excise taxes are levied on alcohol, tobacco, and motor fuel. The state imposes a use tax on items purchased elsewhere but used within Minnesota. Owners of real property in Minnesota pay property tax to their county, municipality, school district, and special taxing districts.\nCulture.\nFine and performing arts.\nMinnesota's leading fine art museums include the Minneapolis Institute of Art, the Walker Art Center, the Frederick R. Weisman Art Museum, and The Museum of Russian Art (TMORA). All are in Minneapolis. The Minnesota Orchestra and the Saint Paul Chamber Orchestra are prominent full-time professional musical ensembles who perform concerts and offer educational programs to the Twin Cities' community. The world-renowned Guthrie Theater moved into a new Minneapolis facility in 2006, boasting three stages and overlooking the Mississippi River. Attendance at theatrical, musical, and comedy events in the area is strong. In the United States, Minneapolis's number of theater companies ranks behind only New York City's, and about 2.3million theater tickets were sold in the Twin Cities annually as of 2006. The Minnesota Fringe Festival in Minneapolis is an annual celebration of theatre, dance, improvisation, puppetry, kids' shows, visual art, and musicals with more than 800 performances over 11 days. It is the country's largest non-juried performing arts festival.\nLiterature.\nThe rigors and rewards of pioneer life on the prairie are the subject of \"Giants in the Earth\" by Ole Rolvaag and the \"Little House\" series of children's books by Laura Ingalls Wilder. Small-town life is portrayed grimly by Sinclair Lewis in the novel \"Main Street\", and more gently and affectionately by Garrison Keillor in his tales of Lake Wobegon. St. Paul native F. Scott Fitzgerald writes of the social insecurities and aspirations of the young city in stories such as \"Winter Dreams\" and \"The Ice Palace\" (published in \"Flappers and Philosophers\"). Henry Wadsworth Longfellow's epic poem \"The Song of Hiawatha\" was inspired by Minnesota and names of many of the state's places and bodies of water. Minnesota native Bob Dylan won the 2016 Nobel Prize in Literature. Science fiction writer Marissa Lingen lives here.\nEntertainment.\nMinnesota musicians include Prince, Bob Dylan, Eddie Cochran, The Andrews Sisters, The Castaways, The Trashmen, Soul Asylum, David Ellefson, Chad Smith, John Wozniak, H\u00fcsker D\u00fc, Semisonic, The Replacements, Owl City, Holly Henry, Motion City Soundtrack, Atmosphere, and Dessa. Minnesotans helped shape the history of music through popular American culture: the Andrews Sisters' \"Boogie Woogie Bugle Boy\" was an iconic tune of World War II, while the Trashmen's \"Surfin' Bird\" and Bob Dylan epitomize two sides of the 1960s. In the 1980s, influential hit radio groups and musicians included Prince, The Original 7ven, Jimmy Jam &amp; Terry Lewis, The Jets, Lipps Inc., and Information Society.\nMinnesotans have also made significant contributions to comedy, theater, media, and film. The comic strip \"Peanuts\" was created by St. Paul native Charles M. Schulz. A Prairie Home Companion which first aired in 1974, became a long-running comedy radio show on National Public Radio. A cult sci-fi cable TV show, \"Mystery Science Theater 3000\", was created by Joel Hodgson in Hopkins, and Minneapolis, MN. Another popular comedy staple developed in the 1990s, \"The Daily Show\", was originated through Lizz Winstead and Madeleine Smithberg.\nJoel and Ethan Coen, Terry Gilliam, Bill Pohlad, and Mike Todd contributed to the art of filmmaking as writers, directors, and producers. Notable actors from Minnesota include Loni Anderson, Richard Dean Anderson, James Arness, Jessica Biel, Rachael Leigh Cook, Julia Duffy, Mike Farrell, Judy Garland, Peter Graves, Josh Hartnett, Garrett Hedlund, Tippi Hedren, Jessica Lange, Kelly Lynch, E.G. Marshall, Laura Osnes, Melissa Peterman, Chris Pratt, Marion Ross, Jane Russell, Winona Ryder, Seann William Scott, Kevin Sorbo, Lea Thompson, Vince Vaughn, Jesse Ventura, James Hong, and Steve Zahn.\nPopular culture.\nStereotypical traits of Minnesotans include \"Minnesota nice\", Lutheranism, a strong sense of community and shared culture, and a distinctive brand of North Central American English sprinkled with Scandinavian expressions. Potlucks, usually with a variety of hotdishes, are popular small-town church activities. A small segment of the Scandinavian population attend a traditional lutefisk dinner to celebrate Christmas. Life in Minnesota has also been depicted or used as a backdrop, in movies such as \"Fargo\", \"Grumpy Old Men\", \"Grumpier Old Men\", \"Juno\", \"Drop Dead Gorgeous\", \"Young Adult\", \"A Serious Man\", \"New in Town\", \"Rio\", \"The Mighty Ducks films,\" and in famous television series like \"Little House on the Prairie\", \"The Mary Tyler Moore Show\", \"The Golden Girls\", \"Coach\", \"The Rocky and Bullwinkle Show\", \"How I Met Your Mother\" and \"Fargo\". Major movies shot on location in Minnesota include \"That Was Then... This Is Now\", \"Purple Rain\", \"Airport\", \"Beautiful Girls\", \"North Country\", \"Untamed Heart\", \"Feeling Minnesota\", \"Jingle All The Way\", \"A Simple Plan\".\nThe Minnesota State Fair, advertised as \"The Great Minnesota Get-Together\", is an icon of state culture. In a state of 5.5million people, there were more than 1.8million visitors to the fair in 2014, setting a new attendance record. The fair covers the variety of Minnesota life, including fine art, science, agriculture, food preparation, 4-H displays, music, the midway, and corporate merchandising. It is known for its displays of seed art, butter sculptures of dairy princesses, the birthing barn, and the \"fattest pig\" competition. In September 1927, John Philip Sousa and his band gave the premiere performance of \"The Minnesota March\" at the fair before a grandstand crowd of 12,000. One can also find dozens of varieties of food on a stick, such as Pronto Pups, cheese curds, and deep-fried candy bars. On a smaller scale, many of these attractions are offered at numerous county fairs.\nOther large annual festivals include the Saint Paul Winter Carnival, the Minnesota Renaissance Festival, Minneapolis' Aquatennial and Mill City Music Festival, Moondance Jam in Walker, the Judy Garland Festival in Grand Rapids, the Eelpout Festival on Leech Lake, and the WE Fest in Detroit Lakes.\nHealth.\nMinnesotans have low rates of premature death, infant mortality, cardiovascular disease, and occupational fatalities. They have long life expectancies, and high rates of health insurance and regular exercise. These and other measures have led two groups to rank Minnesota as the healthiest state in the nation; however, in one of these rankings, Minnesota descended from first to sixth in the nation between 2005 and 2009 because of low levels of public health funding and the prevalence of binge drinking. While overall health indicators are strong, Minnesota does have significant health disparities in minority populations.\nOn October 1, 2007, the Freedom to Breathe Act took effect, outlawing smoking in restaurants and bars in Minnesota.\nThe Minnesota Department of Health is the primary state health agency responsible for public policy and regulation. Medical care in the state is provided by a comprehensive network of hospitals and clinics operated by a number of large providers including Allina Hospitals &amp; Clinics, CentraCare Health System, Essentia Health, HealthPartners, M Health Fairview and the Mayo Clinic Health System. There are two teaching hospitals and medical schools in Minnesota. The University of Minnesota Medical School is a high-rated teaching institution that has made a number of breakthroughs in treatment, and its research activities contribute significantly to the state's growing biotechnology industry. The Mayo Clinic, a world-renowned hospital based in Rochester, was founded by William Worrall Mayo, an immigrant from England.\n\"U.S. News &amp; World Report\"'s 2020\u201321 survey ranked 4,554 hospitals in the country in 12 specialized fields of care, and placed the Mayo Clinic in the top four in most fields. The hospital ranked first on the best hospitals honor roll. The only specialty where it fell outside the top ten was ophthalmology. The Mayo Clinic and the University of Minnesota are partners in the Minnesota Partnership for Biotechnology and Medical Genomics, a state-funded program that conducts research into cancer, Alzheimer's disease, heart health, obesity, and other areas.\nEducation.\nOne of the first acts of the Minnesota Legislature when it opened in 1858 was the creation of a normal school in Winona. Minnesota's commitment to education has contributed to a literate and well-educated populace. In 2009, according to the U.S. Census Bureau, Minnesota had the second-highest proportion of high school graduates, with 91.5% of people 25 and older holding a high school diploma, and the tenth-highest proportion of people with bachelor's degrees. In 2015, Minneapolis was named the nation's \"Most Literate City\", while St. Paul placed fourth, according to a major annual survey. In a 2013 study conducted by the National Center for Educational Statistics comparing the performance of eighth-grade students internationally in math and science, Minnesota ranked eighth in the world and third in the United States, behind Massachusetts and Vermont. In 2014, Minnesota students earned the tenth-highest average composite score in the nation on the ACT exam. In 2013, nationwide in per-student public education spending, Minnesota ranked 21st. While Minnesota has chosen not to implement school vouchers, it is home to the first charter school.\nThe state supports a network of public universities and colleges, including 37 institutions in the Minnesota State Colleges and Universities System, and five major campuses of the University of Minnesota system. It is also home to more than 20 private colleges and universities, six of which rank among the nation's top 100 liberal arts colleges, according to \"U.S. News &amp; World Report\".\nTransportation.\nTransportation in Minnesota is overseen by the Minnesota Department of Transportation (MnDOT) at the state level and by regional and local governments at the local level. Principal transportation corridors radiate from the Twin Cities metropolitan area and along interstate corridors in Greater Minnesota. The major Interstate highways are Interstate35 (I-35), I-90, and I-94, with I-35 and I-94 connecting the Minneapolis\u2013St. Paul area, and I-90 traveling east\u2013west along the southern edge of the state. In 2006, a constitutional amendment was passed that required sales and use taxes on motor vehicles to fund transportation, with at least 40% dedicated to public transit. There are nearly two dozen rail corridors in Minnesota, most of which go through Minneapolis\u2013St. Paul or Duluth. There is water transportation along the Mississippi River system and from the ports of Lake Superior.\nMinnesota's principal airport is Minneapolis\u2013St. Paul International Airport (MSP), a major passenger and freight hub for Delta Air Lines and Sun Country Airlines. Most other domestic carriers serve the airport. Large commercial jet service is provided at Duluth and Rochester, with scheduled commuter service to four smaller cities via Delta Connection carriers SkyWest Airlines, Compass Airlines, and Endeavor Air.\nPublic transit services are available in the regional urban centers in Minnesota including Metro Transit in the Twin Cities, opt-out suburban operators Minnesota Valley Transit Authority, SouthWest Transit, Plymouth Metrolink, Maple Grove Transit and others. In Greater Minnesota transit services are provided by city systems such as Duluth Transit Authority, Mankato Transit System, MATBUS (Fargo-Moorhead), Rochester Public Transit, Saint Cloud Metro Bus, Winona Public Transit and others. Dial-a-Ride service is available for persons with disabilities in a majority of Minnesota counties.\nIn addition to bus services, Amtrak's daily \"Empire Builder\" (Chicago\u2013Seattle/Portland) train runs through Minnesota, calling at the Saint Paul Union Depot and five other stations. Intercity bus providers include Jefferson Lines, Greyhound, and Megabus. Local public transit is provided by bus networks in the larger cities and by two rail services. The Northstar Line commuter rail service runs from Big Lake to the Target Field station in downtown Minneapolis. From there, light rail runs to Saint Paul Union Depot on the Green Line, and to the MSP airport and the Mall of America via the Blue Line.\nLaw and government.\nMinnesota is governed pursuant to the Minnesota Constitution, which was adopted on October 13, 1857, roughly one year before statehood. Like all U.S. states and the federal government, Minnesota has a republican system of political representation with power divided into three branches: executive, legislative, and judicial. The state constitution includes a bill of rights that reaffirms many of the same rights and freedoms as its federal counterpart, with some protected more strongly and explicitly.\nExecutive.\nThe executive branch is led by Minnesota's governor, currently Tim Walz, a DFLer who took office on January 7, 2019. Walz was also Kamala Harris's running mate in the 2024 United States presidential election. As chief executive, the governor appoints the heads of state agencies and is responsible for faithful execution of the law. As commander-in-chief of the state's armed forces, the governor also has command and control over the Minnesota National Guard. A cabinet consisting of the lieutenant governor and the heads of Minnesota's 22 state agencies consults and assists the governor in the business of state government.\nAside from the governor and lieutenant governor, who are elected on a joint ticket, Minnesotans separately elect three other constitutional officers: a secretary of state, an attorney general, and a state auditor. These five \"executive officers\" together constitute the Executive Council, which has certain statutory responsibilities in matters of state finance, emergency management, and public lands administration.\nConstitutional officeholders:\nLegislature.\nThe Minnesota Legislature is a bicameral body consisting of the Senate and the House of Representatives. The state has 67 districts, each with about 60,000 people. Each district has one senator and two representatives, each senatorial district being divided into \"A\" and \"B\" sections for members of the House. Senators serve for four years and representatives for two years.\nSince 2023, both the House and Senate have had a slim DFL majority.\nJudiciary.\nMinnesota's court system has three levels. Most cases start in the district courts, which are courts of general jurisdiction. There are 279 district court judgeships in ten judicial districts. Appeals from the trial courts and challenges to certain governmental decisions are heard by the Minnesota Court of Appeals, consisting of 19 judges who typically sit in three-judge panels. The seven-justice Minnesota Supreme Court hears all appeals from the tax court, the workers' compensation court of appeals, first-degree murder convictions, and discretionary appeals from the court of appeals; it also has original jurisdiction over election disputes.\nTwo specialized courts within administrative agencies have been established: the workers' compensation court of appeals, and the tax court, which deals with non-criminal tax cases.\nSupreme Court Justices\nAssociate Justices\nRegional.\nIn addition to the city and county levels of government found in the United States, Minnesota has other entities that provide governmental oversight and planning. Regional development commissions (RDCs) provide technical assistance to local governments in the broad multi-county areas of the state. Along with this Metropolitan Planning Organizations (MPOs), such as the Metropolitan Council, provide planning and oversight of land use actions in metropolitan areas. Many lakes and rivers are overseen by watershed districts and soil and water conservation districts.\nFederal.\nMinnesota's United States senators are Democrats Amy Klobuchar and Tina Smith. The state has eight congressional districts; they are represented by Brad Finstad (1st district; R), Angie Craig (2nd; DFL), Kelly Morrison (3rd; DFL), Betty McCollum (4th; DFL), Ilhan Omar (5th; DFL), Tom Emmer (6th; R), Michelle Fischbach (7th; R), and Pete Stauber (8th; R).\nFederal court cases are heard in the United States District Court for the District of Minnesota, in Minneapolis, St. Paul, Duluth, and Fergus Falls. Appeals are heard by the Eighth Circuit Court of Appeals in St. Louis, Missouri and St. Paul.\nTribal.\nThe State of Minnesota was created by the United States federal government in the traditional and cultural range of lands occupied by the Dakota and Anishinaabe peoples as well as other Native American groups. After many years of unequal treaties and forced resettlement by the state and federal government, the tribes re-organized into sovereign tribal governments. Today, the tribal governments are divided into 11 semi-autonomous reservations that negotiate with the U.S. and the state on a bilateral basis:\nFour Dakota Mdewakanton communities:\nSeven Anishinaabe reservations:\nThe first six of the Anishinaabe bands compose the Minnesota Chippewa Tribe, the collective federally recognized tribal government of the Bois Forte, Fond du Lac, Grand Portage, Leech Lake, Mille Lacs, and White Earth reservations.\nPolitics.\nMinnesota is known for a politically active citizenry, and populism has been a long-standing force among the state's political parties. Minnesota has a consistently high voter turnout. In the 2008 U.S. presidential election, 78.2% of eligible Minnesotans voted\u00a0\u2013 the highest percentage of any U.S. state\u00a0\u2013 versus the national average of 61.2%. That figure was surpassed in 2020, when 79.96% of registered voters participated in the general election. Voters can register on election day at their polling places with evidence of residency.\nHubert Humphrey brought national attention to the state with his address at the 1948 Democratic National Convention. Minnesotans have consistently cast their Electoral College votes for Democratic presidential candidates since 1976, longer than any other state. Minnesota is the only state in the nation that did not vote for Ronald Reagan in either of his presidential campaigns. Minnesota has voted for the Democratic nominee in every presidential election since 1960, with the exception of 1972, when the state was won by Republican Richard Nixon.\nBoth the Democratic and Republican parties have major-party status in Minnesota, but its state-level Democratic party has a different name, officially known as the Minnesota Democratic\u2013Farmer\u2013Labor Party (DFL). It was formed out of a 1944 alliance of the Minnesota Democratic and Farmer\u2013Labor parties.\nThe state has had active third-party movements. The Reform Party, now the Independence Party, was able to elect former mayor of Brooklyn Park and professional wrestler Jesse Ventura to the governorship in 1998. The Independence Party has received enough support to keep major-party status. The Green Party, while no longer having major-party status, has a large presence in municipal government, notably in Minneapolis and Duluth, where it competes directly with the DFL party for local offices. Major-party status in Minnesota (which grants state funding for elections) is reserved for parties whose candidates receive five percent or more of the vote in any statewide election (e.g., governor, secretary of state, U.S. president).\nThe state's U.S. Senate seats was split in the early 1990s and in the 108th and 109th Congresses, Minnesota's congressional delegation was split, with four representatives and one senator from each party. In the 2006 mid-term election, Democrats were elected to all state offices, except governor and lieutenant governor, where Republicans Tim Pawlenty and Carol Molnau narrowly won reelection. The DFL posted double-digit gains in both houses of the legislature, elected Amy Klobuchar to the U.S. Senate, and increased the party's U.S. House caucus by one. Keith Ellison (DFL) was elected as the first African American U.S. Representative from Minnesota, as well as the first Muslim elected to Congress nationwide. In 2008, DFLer and former comedian and radio talk show host Al Franken defeated incumbent Republican Norm Coleman in the U.S. Senate race by 312 votes out of three million cast.\nIn the 2010 election, Republicans took control of both chambers of the Minnesota legislature for the first time in 38 years and, with Mark Dayton's election, the DFL party took the governor's office for the first time in 20 years. Two years later, the DFL regained control of both houses, and with Dayton in office, the party had same-party control of both the legislative and executive branches for the first time since 1990. Two years later, the Republicans regained control of the Minnesota House, and in 2016, the GOP also regained control of the State Senate.\nIn 2018, the DFL retook control of the Minnesota House, while electing DFLer Tim Walz as Governor.\nIn a 2020 study, Minnesota was ranked as the 15th easiest state for citizens to vote in.\nMedia.\nThe Twin Cities area is the fifteenth largest media market in the United States, as ranked by Nielsen Media Research. The state's other top markets are Fargo\u2013Moorhead (118th nationally), Duluth\u2013Superior (137th), Rochester\u2013Mason City\u2013Austin (152nd), and Mankato (200th).\nBroadcast television in Minnesota and the Upper Midwest started on April 27, 1948, when KSTP-TV began broadcasting. Hubbard Broadcasting, which owns KSTP, is now the only locally owned television company in Minnesota. Twin Cities CBS station WCCO-TV and FOX station KMSP-TV are owned-and-operated by their respective networks. There are 39 analog broadcast stations and 23 digital channels broadcast over Minnesota.\nThe four largest daily newspapers are the \"Star Tribune\" in Minneapolis, the \"Pioneer Press\" in Saint Paul, the \"Duluth News Tribune\" in Duluth, and the \"Post-Bulletin\" in Rochester. \"The Minnesota Daily\" is the largest student-run newspaper in the U.S. Sites offering daily news on the Web include \"The UpTake\", \"MinnPost\", the Twin Cities \"Daily Planet\", business news site \"Finance and Commerce\" and Washington D.C.\u2013based \"Minnesota Independent\". Weekly and monthly publications such as \"Minnesota Monthly\" are available.\nTwo of the largest public radio networks, Minnesota Public Radio (MPR) and Public Radio International (PRI), are based in the state. MPR has the largest audience of any regional public radio network in the nation, broadcasting on 46 radio stations as of 2019. PRI weekly provides more than 400 hours of programming to almost 800 affiliates. The state's oldest radio station, KUOM-AM, was launched in 1922 and is among the 10-oldest radio stations in the United States. The University of Minnesota-owned station is still on the air, and since 1993 broadcasts a college rock format.\nSports, recreation and tourism.\nMinnesota has an active program of organized amateur and professional sports. Tourism has become an important industry, especially in the Lake region. In the North Country, what had been an industrial area focused on mining and timber has largely been transformed into a vacation destination. Popular interest in the environment and environmentalism, added to traditional interests in hunting and fishing, has attracted a large urban audience within driving range.\nOrganized sports.\nMinnesota has professional men's teams in all major sports.\nThe Minnesota Vikings have played in the National Football League since their admission as an expansion franchise in 1961. They played in Metropolitan Stadium from 1961 through 1981 and in the Hubert H. Humphrey Metrodome from 1982 until its demolition after the 2013 season for the construction of the team's new home, U.S. Bank Stadium. The Vikings' current stadium hosted Super Bowl LII in February 2018. Super Bowl XXVI was played in the Metrodome in 1992. The Vikings have advanced to the Super Bowl Super Bowl IV, Super Bowl VIII, Super Bowl IX, and Super Bowl XI, losing all four games to their AFC/AFL opponent.\nThe Minnesota Twins have played in the Major League Baseball in the Twin Cities since 1961. The Twins began play as the original Washington Senators, a founding member of the American League in 1901, relocating to Minnesota in 1961. The Twins won the 1987 and 1991 World Series in seven-game matches where the home team was victorious in all games. The Twins also advanced to the 1965 World Series, where they lost to the Los Angeles Dodgers in seven games. The team has played at Target Field since 2010.\nThe Minneapolis Lakers of the National Basketball Association played in the Minneapolis Auditorium from 1947 to 1960, after which they relocated to Los Angeles. The Minnesota Timberwolves joined the NBA in 1989, and have played in Target Center since 1990.\nThe National Hockey League's Minnesota Wild play in St. Paul's Grand Casino Arena, and reached 300 consecutive sold-out games on January 16, 2008. Previously, the Minnesota North Stars competed in NHL from 1967 to 1993, which played in and lost the 1981 and 1991 Stanley Cup Finals.\nMinnesota United FC joined Major League Soccer as an expansion team in 2017, having played in the lower-division North American Soccer League from 2010 to 2016. The team plays at Allianz Field in St. Paul. Previous professional soccer teams have included the Minnesota Kicks, which played at Metropolitan Stadium from 1976 to 1981, and the Minnesota Strikers from 1984 to 1988.\nMinnesota also has minor-league professional sports teams. The Minnesota Swarm of the National Lacrosse League played at the Xcel Energy Center until the team moved to Georgia in 2015. The St. Paul Saints, who play at CHS Field in St. Paul, are the Triple-A minor league affiliate of the Minnesota Twins.\nProfessional women's sports include the Minnesota Lynx of the Women's National Basketball Association, winners of the 2011, 2013, 2015, and 2017 WNBA Championships, Minnesota Aurora FC of the United Soccer League W-League, the Minnesota Vixen of the Independent Women's Football League, the Minnesota Valkyrie of the Legends Football League, the Minnesota Frost of the Professional Women's Hockey League, and the Minnesota Whitecaps of the National Women's Hockey League.\nThe Twin Cities campus of the University of Minnesota is a National Collegiate Athletic Association (NCAA) Division I school competing in the Big Ten Conference. Four additional schools in the state compete in NCAA Division I ice hockey: the University of Minnesota Duluth; Minnesota State University, Mankato; St. Cloud State University and Bemidji State University. There are nine NCAA Division II colleges in the Northern Sun Intercollegiate Conference, and twenty NCAA Division III colleges in the Minnesota Intercollegiate Athletic Conference and Upper Midwest Athletic Conference.\nMinneapolis has hosted the NCAA Men's Division I Basketball Championship in 1951, 1992, 2001, and 2019.\nThe Hazeltine National Golf Club has hosted the U.S. Open, U.S. Women's Open, U.S. Senior Open and PGA Championship. The course also hosted the Ryder Cup in the fall of 2016, when it became one of two courses in the U.S. to host all major golf competitions. The Ryder Cup is scheduled to return in 2028.\nInterlachen Country Club has hosted the U.S. Open, U.S. Women's Open, and Solheim Cup.\nWinter Olympic Games medalists from the state include twelve of the twenty members of the gold medal 1980 ice hockey team (coached by Minnesota native Herb Brooks) and the bronze medalist U.S. men's curling team in the 2006 Winter Olympics, as well as the gold medal-winning team from Duluth at the 2018 Winter Olympics. Swimmer Tom Malchow won an Olympic gold medal in the 2000 Summer games and a silver medal in 1996.\nGrandma's Marathon is run every summer along the scenic North Shore of Lake Superior, and the Twin Cities Marathon winds around lakes and the Mississippi River during the peak of the fall color season. Farther north, Eveleth is the location of the United States Hockey Hall of Fame.\nOutdoor recreation.\nMinnesotans participate in high levels of physical activity, and many of these activities are outdoors. The strong interest of Minnesotans in environmentalism has been attributed to the popularity of these pursuits.\nIn the warmer months, these activities often involve water. Weekend and longer trips to family cabins on Minnesota's numerous lakes are a way of life for many residents. Activities include water sports such as water skiing, which originated in the state, boating, canoeing, and fishing. More than 36% of Minnesotans fish, second only to Alaska.\nFishing does not cease when the lakes freeze; ice fishing has been around since the arrival of early Scandinavian immigrants. Minnesotans have learned to embrace their long, harsh winters in ice sports such as skating, hockey, curling, and broomball, and snow sports such as cross-country skiing, alpine skiing, luge, snowshoeing, and snowmobiling. Minnesota is the only U.S. state where bandy is played.\nState and national forests and the 72 state parks are used year-round for hunting, camping, and hiking. There are almost of snowmobile trails statewide. Minnesota has more miles of bike trails than any other state, and a growing network of hiking trails, including the Superior Hiking Trail in the northeast. Many hiking and bike trails are used for cross-country skiing during the winter.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "19591", "revid": "50993363", "url": "https://en.wikipedia.org/wiki?curid=19591", "title": "Missouri River", "text": "Major river in central United States\nThe Missouri River is a river in the Central and Mountain West regions of the United States. The nation's longest, it rises in the eastern Centennial Mountains of the Bitterroot Range of the Rocky Mountains of southwestern Montana, then flows east and south for before entering the Mississippi River north of St. Louis, Missouri. The river drains semi-arid watershed of more than 500,000 square miles (1,300,000\u00a0km2), which includes parts of ten U.S. states and two Canadian provinces. Although a tributary of the Mississippi, the Missouri River is slightly longer and carries a comparable volume of water, though a fellow tributary (Ohio River) carries more water. When combined with the lower Mississippi River, it forms the world's fourth-longest river system.\nFor over 12,000 years, people have depended on the Missouri River and its tributaries as a source of sustenance and transportation. More than ten major groups of Native Americans populated the watershed, with most leading a nomadic lifestyle and dependent on enormous bison herds that roamed through the Great Plains. The first Europeans encountered the river in the late seventeenth century, and the region passed through Spanish and French hands before becoming part of the United States through the Louisiana Purchase.\nThe Missouri River was one of the main routes for the westward expansion of the United States during the 19th century. The growth of the fur trade in the early 19th century laid much of the groundwork as trappers explored the region and blazed trails. Pioneers headed west \"en masse\" beginning in the 1830s, first by covered wagon, then by the growing numbers of steamboats that entered service on the river. Conflict between settlers and Native Americans in the watershed led to some of the most longstanding violence of the American Indian Wars.\nDuring the 20th century, the Missouri River basin was extensively developed for irrigation, flood control, and the generation of hydroelectric power. Fifteen dams impound the main stem of the river, with hundreds more on tributaries. The Missouri River's reservoirs include the largest, second-largest, and fourth-largest artificial lakes in the United States by surface area: Lake Sakakawea, Lake Oahe, and Fort Peck Lake. Meanders have been cut off and the river channelized to improve navigation, reducing its length by almost from pre-development times. Although the lower Missouri valley is now a populous and highly productive agricultural and industrial region, heavy development has taken its toll on wildlife and fish populations as well as water quality.\nCourse.\nFrom the Rocky Mountains, three streams rise to form the headwaters of the Missouri River:\nThe Missouri River officially starts at the confluence of the Jefferson and Madison in Missouri Headwaters State Park near Three Forks, Montana, and is joined by the Gallatin a mile (1.6\u00a0km) downstream. It then passes through Canyon Ferry Lake, a reservoir west of the Big Belt Mountains. Issuing from the mountains near Cascade, the river flows northeast to the city of Great Falls, where it drops over the Great Falls of the Missouri, a series of five substantial waterfalls. It then winds east through a scenic region of canyons and badlands known as the Missouri Breaks, receiving the Marias River from the west then widening into the Fort Peck Lake reservoir a few miles above the confluence with the Musselshell River. Farther on, the river passes through the Fort Peck Dam, and immediately downstream, the Milk River joins from the north.\nFlowing eastward through the plains of eastern Montana, the Missouri receives the Poplar River from the north before crossing into North Dakota where the Yellowstone River, its greatest tributary by volume, joins from the southwest. At the confluence, the Yellowstone is actually the larger river.\nThe Missouri then meanders east past Williston and into Lake Sakakawea, the reservoir formed by Garrison Dam. Below the dam the Missouri receives the Knife River from the west and flows south to Bismarck, the capital of North Dakota, where the Heart River joins from the west. It slows into the Lake Oahe reservoir just before the Cannonball River confluence. While it continues south, eventually reaching Oahe Dam in South Dakota, the Grand, Moreau and Cheyenne Rivers all join the Missouri from the west.\nThe Missouri makes a bend to the southeast as it winds through the Great Plains, receiving the Niobrara River and many smaller tributaries from the southwest. It then proceeds to form the boundary of South Dakota and Nebraska and is joined by the James River from the north. At Sioux City the Big Sioux River comes in from the north, after which the Missouri forms the Iowa\u2013Nebraska boundary. It flows south to the city of Omaha where it receives its longest tributary, the Platte River, from the west. Downstream, it begins to define the border between the states of Nebraska and Missouri, then flows between the states of Missouri and Kansas. The Missouri swings east at Kansas City, where the Kansas River enters from the west, and so on into north-central Missouri. To the east of Kansas City, the Missouri receives, on the left side, the Grand River. It passes south of Columbia and receives the Osage and Gasconade Rivers from the south downstream of Jefferson City. The river then rounds the northern side of St.\u00a0Louis to join the Mississippi River on the border between Missouri and Illinois.\nWatershed.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\nThere is only one river with a personality, a sense of humor, and a woman's caprice; a river that goes traveling sidewise, that interferes in politics, rearranges geography, and dabbles in real estate; a river that plays hide and seek with you today and tomorrow follows you around like a pet dog with a dynamite cracker tied to his tail. That river is the Missouri.\u2014 George Fitch\nThe Missouri River's drainage basin spans ,\nencompassing nearly one-sixth of the area of the United States or just over five percent of the continent of North America. Comparable to the size of the Canadian province of Quebec, the watershed covers most of the central Great Plains, stretching from the Rocky Mountains in the west to the Mississippi River Valley in the east and from the southern extreme of western Canada to the border of the Arkansas River watershed. Compared with the Mississippi River above their confluence, the Missouri is twice as long\nand drains an area three times as large.\nThe Missouri accounts for 45\u00a0percent of the annual flow of the Mississippi past St. Louis, and as much as 70\u00a0percent in certain droughts.\nIn 1990, the Missouri River watershed was home to about 12\u00a0million people. This included the entire population of the U.S. state of Nebraska, parts of the U.S. states of Colorado, Iowa, Kansas, Minnesota, Missouri, Montana, North Dakota, South Dakota, and Wyoming, and small southern portions of the Canadian provinces of Alberta and Saskatchewan. The watershed's largest city is Denver, Colorado, with a population of more than six hundred thousand. Denver is the main city of the Front Range Urban Corridor whose cities had a combined population of over four million in 2005, making it the largest metropolitan area in the Missouri River basin. Other major population centers \u2013 mostly in the watershed's southeastern portion \u2013 include Omaha, Nebraska, north of the confluence of the Missouri and Platte Rivers; Kansas City, Missouri \u2013 Kansas City, Kansas, at the confluence of the Missouri with the Kansas River; and the St. Louis metropolitan area, south of the Missouri River just below the latter's mouth, on the Mississippi. In contrast, the northwestern part of the watershed is sparsely populated. However, many northwestern cities, such as Billings, Montana, are among the fastest growing in the Missouri basin.\nWith more than under the plow, the Missouri River watershed includes roughly one-fourth of all the agricultural land in the United States, providing more than a third of the country's wheat, flax, barley, and oats. However, only of farmland in the basin is irrigated. A further of the basin is devoted to the raising of livestock, mainly cattle. Forested areas of the watershed, mostly second-growth, total about . Urban areas, on the other hand, comprise less than of land. Most built-up areas are along the main stem and a few major tributaries, including the Platte and Yellowstone Rivers.\nElevation in the watershed varies from just over at the Missouri's mouth to the summit of Mount Lincoln in central Colorado. The river drops from Brower's Spring, the farthest source. Although the plains of the watershed have extremely little local vertical relief, the land rises about 10 feet per mile (1.9 m/km) from east to west. The elevation is less than at the eastern border of the watershed, but is over above sea level in many places at the base of the Rockies.\nThe Missouri's drainage basin has highly variable weather and rainfall patterns, Overall, the watershed is defined by a continental climate with warm, wet summers and harsh, cold winters. Most of the watershed receives an average of of precipitation each year. However, the westernmost portions of the basin in the Rockies as well as southeastern regions in Missouri may receive as much as . The vast majority of precipitation occurs in summer in most of the lower and middle basin, although the upper basin is known for short-lived but intense summer thunderstorms such as the one which produced the 1972 Black Hills flood through Rapid City, South Dakota. Winter temperatures in the northern and western portions of the basin typically drop to or lower every winter with extremes as low as , while summer highs occasionally exceed in all areas except the higher elevations of Montana, Wyoming and Colorado. Extreme maxima \u2014 almost all prior to 1960 \u2014 have exceeded in all US states in the basin.\nAs one of the continent's most significant river systems, the Missouri's drainage basin borders on many other major watersheds of the United States and Canada. The Continental Divide, running along the spine of the Rocky Mountains, forms most of the western border of the Missouri watershed. The Clark Fork and Snake River, both part of the Columbia River basin, drain the area west of the Rockies in Montana, Idaho and western Wyoming. The Columbia, Missouri and Colorado River watersheds meet at Three Waters Mountain in Wyoming's Wind River Range. South of there, the Missouri basin is bordered on the west by the drainage of the Green River, a tributary of the Colorado, then on the south by the mainstem of the Colorado. Both the Colorado and Columbia Rivers flow to the Pacific Ocean. However, a large endorheic drainage called the Great Divide Basin exists between the Missouri and Green watersheds in western Wyoming. This area is sometimes counted as part of the Missouri River watershed, even though its waters do not flow to either side of the Continental Divide.\nTo the north, the much lower Laurentian Divide separates the Missouri River watershed from those of the Oldman River, a tributary of the South Saskatchewan River, as well as the Souris, Sheyenne, and smaller tributaries of the Red River of the North. All of these streams are part of Canada's Nelson River drainage basin, which empties into Hudson Bay. There are also several large endorheic basins between the Missouri and Nelson watersheds in southern Alberta and Saskatchewan. The Minnesota and Des Moines Rivers, tributaries of the upper Mississippi, drain most of the area bordering the eastern side of the Missouri River basin. Finally, on the south, the Ozark Mountains and other low divides through central Missouri, Kansas and Colorado separate the Missouri watershed from those of the White River and Arkansas River, also tributaries of the Mississippi River.\nMajor tributaries.\nOver 95 significant tributaries and hundreds of smaller ones feed the Missouri River, with most of the larger ones coming in as the river draws close to the mouth. Most rivers and streams in the Missouri River basin flow from west to east, following the incline of the Great Plains; however, some eastern tributaries such as the James, Big Sioux and Grand River systems flow from north to south.\nThe Missouri's largest tributaries by runoff are the Yellowstone in Montana and Wyoming, the Platte in Wyoming, Colorado, and Nebraska, and the Kansas\u2013Republican/Smoky Hill and Osage in Kansas and Missouri. Each of these tributaries drains an area greater than or has an average discharge greater than . The Yellowstone River has the highest discharge, even though the Platte is longer and drains a larger area. In fact, the Yellowstone's flow is about \u2013 accounting for sixteen percent of total runoff in the Missouri basin and nearly double that of the Platte. On the other end of the scale is the tiny Roe River in Montana, which at long is one of the world's shortest rivers.\nThe table on the right lists the ten longest tributaries of the Missouri, along with their respective catchment areas and flows. Length is measured to the hydrologic source, regardless of naming convention. The main stem of the Kansas River, for example, is long. However, including the longest headwaters tributaries, the Republican River and the Arikaree River, brings the total length to . Similar naming issues are encountered with the Platte River, whose longest tributary, the North Platte River, is more than twice as long as its mainstream.\nThe Missouri's headwaters above Three Forks extend much farther upstream than the main stem. Measured to the farthest source at Brower's Spring, the Jefferson River is long. Thus measured to its highest headwaters, the Missouri River stretches for . When combined with the lower Mississippi, the Missouri and its headwaters form part of the fourth-longest river system in the world, at .\nDischarge.\nBy discharge, the Missouri is the ninth largest river of the United States, after the Mississippi, St. Lawrence, Ohio, Columbia, Niagara, Yukon, Detroit, and St. Clair. The latter two, however, are sometimes considered part of a strait between Lake Huron and Lake Erie. Among rivers of North America as a whole, the Missouri is thirteenth largest, after the Mississippi, Mackenzie, St. Lawrence, Ohio, Columbia, Niagara, Yukon, Detroit, St. Clair, Fraser, Slave, and Koksoak.\nAs the Missouri drains a predominantly semi-arid region, its discharge is much lower and more variable than other North American rivers of comparable length. Before the construction of dams, the river flooded twice each year \u2013 once in the \"April Rise\" or \"Spring Fresh\", with the melting of snow on the plains of the watershed, and in the \"June Rise\", caused by snowmelt and summer rainstorms in the Rocky Mountains. The latter was far more destructive, with the river increasing to over ten times its normal discharge in some years. The Missouri's discharge is affected by over 17,000 reservoirs with an aggregate capacity of some . By providing flood control, the reservoirs dramatically reduce peak flows and increase low flows. Evaporation from reservoirs significantly reduces the river's runoff, causing an annual loss of over from mainstem reservoirs alone.\nThe United States Geological Survey operates fifty-one stream gauges along the Missouri River. The river's average discharge at Bismarck, from the mouth, is . This is from a drainage area of , or 35% of the total river basin. At Kansas City, from the mouth, the river's average flow is . The river here drains about , representing about 91% of the entire basin.\nThe lowermost gage with a period of record greater than fifty years is at Hermann, Missouri \u2013 upstream of the mouth of the Missouri \u2013 where the average annual flow was from 1897 to 2010. About , or 98.7% of the watershed, lies above Hermann. The highest annual mean was in 1993, and the lowest was in 2006. Extremes of the flow vary even further. The largest discharge ever recorded was over on July 31, 1993, during a historic flood. The lowest, a mere \u2013 caused by the formation of an ice dam \u2013 was measured on December 23, 1963.\nGeology.\nThe Rocky Mountains of southwestern Montana at the headwaters of the Missouri River first rose in the Laramide Orogeny, a mountain-building episode that occurred from around 70 to 45\u00a0million years ago (the end of the Mesozoic through the early Cenozoic). This orogeny uplifted Cretaceous rocks along the western side of the Western Interior Seaway, a vast shallow sea that stretched from the Arctic Ocean to the Gulf of Mexico, and deposited the sediments that now underlie much of the drainage basin of the Missouri River.\nThis Laramide uplift caused the sea to retreat and laid the framework for a vast drainage system of rivers flowing from the Rocky and Appalachian Mountains, the predecessor of the modern-day Mississippi watershed. The Laramide Orogeny is essential to modern Missouri River hydrology, as snow and ice melt from the Rockies provide the majority of the flow in the Missouri and its tributaries.\nThe Missouri and many of its tributaries cross the Great Plains, flowing over or cutting into the Ogallala Group and older mid-Cenozoic sedimentary rocks. The lowest major Cenozoic unit, the White River Formation, was deposited between roughly 35 and 29\u00a0million years ago and consists of claystone, sandstone, limestone, and conglomerate. Channel sandstones and finer-grained overbank deposits of the fluvial Arikaree Group were deposited between 29 and 19\u00a0million years ago. The Miocene-age Ogallala and the slightly younger Pliocene-age Broadwater Formation deposited atop the Arikaree Group, and are formed from material eroded off of the Rocky Mountains during a time of increased generation of topographic relief; these formations stretch from the Rocky Mountains nearly to the Iowa border and give the Great Plains much of their gentle but persistent eastward tilt, and also constitute a major aquifer.\nImmediately before the Quaternary Ice Age, the Missouri River was likely split into three segments: an upper portion that drained northwards into Hudson Bay,\nand middle and lower sections that flowed eastward down the regional slope.\nAs the Earth plunged into the Ice Age, a pre-Illinoian (or possibly the Illinoian) glaciation diverted the Missouri River southeastward toward its present confluence with the Mississippi and caused it to integrate into a single river system that cuts across the regional slope. In western Montana, the Missouri River is thought to have once flowed north then east around the Bear Paw Mountains. Sapphires are found in some spots along the river in western Montana. Advances of the continental ice sheets diverted the river and its tributaries, causing them to pool up into large temporary lakes such as Glacial Lakes Great Falls, Musselshell and others. As the lakes rose, the water in them often spilled across adjacent local drainage divides, creating now-abandoned channels and coulees including the Shonkin Sag, long. When the glaciers retreated, the Missouri flowed in a new course along the south side of the Bearpaws, and the lower part of the Milk River tributary took over the original main channel.\nThe Missouri's nickname, the \"Big Muddy\", was inspired by its enormous loads of sediment or silt \u2013 some of the largest of any North American river. In its pre-development state, the river transported some per year. The construction of dams and levees has drastically reduced this to in the present day. Much of this sediment is derived from the river's floodplain, also called the meander belt; every time the river changed course, it would erode tons of soil and rocks from its banks. However, damming and channeling the river has kept it from reaching its natural sediment sources along most of its course. Reservoirs along the Missouri trap roughly of sediment each year. Despite this, the river still transports more than half the total silt that empties into the Gulf of Mexico; the Mississippi River Delta, formed by sediment deposits at the mouth of the Mississippi, constitutes a majority of sediments carried by the Missouri.\nFirst people.\nArchaeological evidence, especially in Missouri, suggests that human beings first inhabited the watershed of the Missouri River between 10,000 and 12,000 years ago at the end of the Pleistocene. During the end of the last glacial period, large migration of humans were taking place, such as those via the Bering land bridge between the Americas and Eurasia. Over centuries, the Missouri River formed one of these main migration paths. Most migratory groups that passed through the area eventually settled in the Ohio Valley and the lower Mississippi River Valley, but many, including the Mound builders, stayed along the Missouri, becoming the ancestors of the later Indigenous peoples of the Great Plains.\nIndigenous peoples of North America who have lived along the Missouri have historically had access to ample food, water, and shelter. Many migratory animals naturally inhabit the plains area. Before they were hunted by colonists and Native Americans, these animals, such as the buffalo, provided meat, clothing, and other everyday items; there were also great riparian areas in the river's floodplain that provided habitat for herbs and other staple foods. No written records from the tribes and peoples of the pre-European contact period exist because they did not yet use writing. According to the writings of early colonists, some of the major tribes along the Missouri River included the Otoe, Missouria, Omaha, Ponca, Dakota, Lakota, Arikara, Hidatsa, Mandan, Assiniboine, Gros Ventres and Blackfeet.\nIn this pre-colonial and early-colonial era, the Missouri river was used as a path of trade and transport, and the river and its tributaries often formed territorial boundaries. Most of the Indigenous peoples in the region at that time had semi-nomadic cultures, with many tribes maintaining different summer and winter camps. However, the center of Native American wealth and trade lay along the Missouri River in the Dakotas region on its great bend south. A large cluster of walled Mandan, Hidatsa and Arikara villages situated on bluffs and islands of the river was home to thousands, and later served as a market and trading post used by early French and British explorers and fur traders. Following the introduction of horses to Missouri River tribes, possibly from feral European-introduced populations, Natives' way of life changed dramatically. The use of the horse allowed them to travel greater distances, and thus facilitated hunting, communications, warfare, the Siouxoan genocide and expulsion of many tribes, and the abundance of trade.\nOnce, tens of millions of American bison (commonly called buffalo), one of the keystone species of the Great Plains and the Ohio Valley, roamed the plains of the Missouri River basin. Most Native American nations in the basin relied heavily on the bison as a food source, and their hides and bones served to create other household items. In time, the species came to benefit from the indigenous peoples' periodic controlled burnings of the grasslands surrounding the Missouri to clear out old and dead growth. The large bison population of the region gave rise to the term \"great bison belt\", an area of rich annual grasslands that extended from Alaska to Mexico along the eastern flank of the Continental Divide. However, after the arrival of Europeans in North America, both the bison and the Native Americans saw a rapid decline in population. Massive over-hunting for sport by colonists eliminated bison populations east of the Mississippi River by 1833 and reduced the numbers in the Missouri basin to a mere few hundred. Foreign diseases brought by settlers, such as smallpox, raged across the land, decimating Native American populations. Left without their primary source of sustenance, many of the remaining indigenous people were forced onto resettlement areas and reservations, often at gunpoint.\nEarly European explorers.\nIn May 1673, the French-Canadian explorer Louis Jolliet and the French explorer Jacques Marquette left the settlement of St. Ignace on Lake Huron and traveled down the Wisconsin and Mississippi Rivers, aiming to reach the Pacific Ocean. In late June, Jolliet and Marquette became the first documented European discoverers of the Missouri River, which according to their journals was in full flood. \"I never saw anything more terrific,\" Jolliet wrote, \"a tangle of entire trees from the mouth of the Pekistanoui [Missouri] with such impetuosity that one could not attempt to cross it without great danger. The commotion was such that the water was made muddy by it and could not clear itself.\" They recorded \"Pekitanoui\" or \"Pekistanoui\" as the local name for the Missouri. However, the party never explored the Missouri beyond its mouth, nor did they linger in the area. In addition, they later learned that the Mississippi drained into the Gulf of Mexico and not the Pacific as they had originally presumed; the expedition turned back about short of the Gulf at the confluence of the Arkansas River with the Mississippi.\nIn 1682, France expanded its territorial claims in North America to include land on the western side of the Mississippi River, which included the lower portion of the Missouri. However, the Missouri itself remained formally unexplored until \u00c9tienne de Veniard, Sieur de Bourgmont commanded an expedition in 1714 that reached at least as far as the mouth of the Platte River. It is unclear exactly how far Bourgmont traveled beyond there; he described the blond-haired Mandans in his journals, so it is likely he reached as far as their villages in present-day North Dakota. Later that year, Bourgmont published \"The Route To Be Taken To Ascend The Missouri River\", the first known document to use the name \"Missouri River\"; many of the names he gave to tributaries, mostly from the native tribes that lived along them, are still in use today. The expedition's discoveries eventually found their way to cartographer Guillaume Delisle, who used the information to create a map of the lower Missouri. In 1718, Jean-Baptiste Le Moyne, Sieur de Bienville requested that the French government bestow upon Bourgmont the Cross of St. Louis because of his \"outstanding service to France\".\nBourgmont had in fact been in trouble with the French colonial authorities since 1706, when he deserted his post as commandant of Fort Detroit after poorly handling an attack by the Ottawa that resulted in thirty-one deaths. However, his reputation was enhanced in 1720 when the Pawnee \u2013 who had earlier been befriended by Bourgmont \u2013 massacred the Spanish Villasur expedition near present-day Columbus, Nebraska, on the Missouri River, temporarily ending Spanish encroachment on French Louisiana.\nBourgmont established Fort Orleans, the first European settlement of any kind on the Missouri River, near present-day Brunswick, Missouri, in 1723. The following year Bourgmont led an expedition to enlist Comanche support against the Spanish, who continued to show interest in taking over the Missouri. In 1725 Bourgmont brought the chiefs of several Missouri River tribes to visit France. There he was raised to the rank of nobility and did not accompany the chiefs back to North America. Fort Orleans was either abandoned or its small contingent massacred by Native Americans in 1726.\nThe French and Indian War erupted when territorial disputes between France and Great Britain in North America reached a head in 1754. By 1763, France's army in North America had been defeated by a combined British-American force and was forced to sue for peace. In the Treaty of Paris, France ceded its Canadian possessions to the British, gaining Louisiana from the Spanish in return.\nInitially, the Spanish did not extensively explore the Missouri and let French traders continue their activities under license. However, this ended after news of incursions by trappers working for the Hudson's Bay Company in the upper Missouri River watershed was brought back following an expedition by Jacques D'Eglise in the early 1790s. In 1795 the Spanish chartered the Company of Discoverers and Explorers of the Missouri, popularly referred to as the \"Missouri Company\", and offered a reward for the first person to reach the Pacific Ocean via the Missouri. In 1794 and 1795 expeditions led by Jean-Baptiste Truteau and Antoine Simon Lecuyer de la Jonch\u0161re did not even make it as far north as the Mandan villages in central North Dakota.\nArguably the most successful of the Missouri Company expeditions was that of James MacKay and John Evans. The two set out along the Missouri, and established Fort Charles about south of present-day Sioux City as a winter camp in 1795. At the Mandan villages in North Dakota, they forcefully expelled several British traders, and while talking to the populace they pinpointed the location of the Yellowstone River, which was called \"Roche Jaune\" (\"Yellow Rock\") by the French. Although MacKay and Evans failed to accomplish their original goal of reaching the Pacific, they did create the first accurate map of the upper Missouri River.\nIn 1795, the young United States and Spain signed Pinckney's Treaty, which recognized American rights to navigate the Mississippi River and store goods for export in New Orleans. Three years later, Spain revoked the treaty and in 1800 secretly returned Louisiana to Napoleonic France in the Third Treaty of San Ildefonso. This transfer was so secret that the Spanish continued to administer the territory. In 1801, Spain restored rights to use the Mississippi and New Orleans to the United States.\nFearing that the cutoffs could occur again, President Thomas Jefferson proposed to buy the port of New Orleans from France for $10\u00a0million. Instead, faced with a debt crisis, Napoleon offered to sell the entirety of Louisiana, including the Missouri River, for $15\u00a0million \u2013 amounting to less than 3\u00a2 per acre. The deal was signed in 1803, doubling the size of the United States with the acquisition of the Louisiana Territory.\nIn 1803, Jefferson instructed Meriwether Lewis to explore the Missouri and search for a water route to the Pacific Ocean. By then, it had been discovered that the Columbia River system, which drains into the Pacific, had a similar latitude as the headwaters of the Missouri River, and it was widely believed that a connection or short portage existed between the two. However, Spain balked at the takeover, citing that they had never formally returned Louisiana to the French. Spanish authorities warned Lewis not to take the journey and forbade him from seeing the MacKay and Evans map of the Missouri, although Lewis eventually managed to gain access to it.\nMeriwether Lewis and William Clark began their famed expedition in 1804 with a party of thirty-three people in three boats. Although they became the first Europeans to travel the entire length of the Missouri and reach the Pacific Ocean via the Columbia, they found no trace of the Northwest Passage. The maps made by Lewis and Clark, especially those of the Pacific Northwest region, provided a foundation for future explorers and emigrants. They also negotiated relations with numerous Native American tribes and wrote extensive reports on the climate, ecology and geology of the region. Many present-day names of geographic features in the upper Missouri basin originated from their expedition.\nAmerican frontier.\nFur trade.\nAs early as the 18th century, fur trappers entered the extreme northern basin of the Missouri River in the hopes of finding populations of beaver and river otter, the sale of whose pelts drove the thriving North American fur trade. They came from many different places \u2013 some from the Canadian fur corporations at Hudson Bay, some from the Pacific Northwest (\"see also\": Maritime fur trade), and some from the midwestern United States. Most did not stay in the area for long, as they failed to find significant resources.\nThe first glowing reports of country rich with thousands of game animals came in 1806 when Meriwether Lewis and William Clark returned from their two-year expedition. Their journals described lands amply stocked with thousands of buffalo, beaver, and river otter; and also an abundant population of sea otters on the Pacific Northwest coast. In 1807, explorer Manuel Lisa organized an expedition which would lead to the explosive growth of the fur trade in the upper Missouri River country. Lisa and his crew traveled up the Missouri and Yellowstone Rivers, trading manufactured items in return for furs from local Native American tribes, and established a fort at the confluence of the Yellowstone and a tributary, the Bighorn, in southern Montana. Although the business started small, it quickly grew into a thriving trade.\nLisa's men started construction of Fort Raymond, which sat on a bluff overlooking the confluence of the Yellowstone and Bighorn, in the fall of 1807. The fort would serve primarily as a trading post for bartering with the Native Americans for furs. This method was unlike that of the Pacific Northwest fur trade, which involved trappers hired by the various fur enterprises, namely Hudson's Bay. Fort Raymond was later replaced by Fort Lisa at the confluence of the Missouri and Yellowstone in North Dakota; a second fort also called Fort Lisa was built downstream on the Missouri River in Nebraska. In 1809 the St. Louis Missouri Fur Company was founded by Lisa in conjunction with William Clark and Pierre Choteau, among others. In 1828, the American Fur Company founded Fort Union at the confluence of the Missouri and Yellowstone Rivers. Fort Union gradually became the main headquarters for the fur trade in the upper Missouri basin.\nFur trapping activities in the early 19th century encompassed nearly all of the Rocky Mountains on both the eastern and western slopes. Trappers of the Hudson's Bay Company, St. Louis Missouri Fur Company, American Fur Company, Rocky Mountain Fur Company, North West Company and other outfits worked thousands of streams in the Missouri watershed as well as the neighboring Columbia, Colorado, Arkansas, and Saskatchewan river systems. During this period, the trappers, also called mountain men, blazed trails through the wilderness that would later form the paths pioneers and settlers would travel by into the West. Transport of the thousands of beaver pelts required ships, providing one of the first large motives for river transport on the Missouri to start.\nAs the 1830s drew to a close, the fur industry slowly began to die as silk replaced beaver fur as a desirable clothing item. By this time, also, the beaver population of streams in the Rocky Mountains had been decimated by intense hunting. Furthermore, frequent Native American attacks on trading posts made it dangerous for employees of the fur companies. In some regions, the industry continued well into the 1840s, but in others such as the Platte River valley, declines of the beaver population contributed to an earlier demise. The fur trade finally disappeared in the Great Plains around 1850, with the primary center of industry shifting to the Mississippi Valley and central Canada. Despite the demise of the once-prosperous trade, however, its legacy led to the opening of the American West and a flood of settlers, farmers, ranchers, adventurers, hopefuls, financially bereft, and entrepreneurs took their place.\nSettlers and pioneers.\nThe river roughly defined the American frontier in the 19th century, particularly downstream from Kansas City, where it takes a sharp eastern turn into the heart of the state of Missouri, an area known as the Boonslick. As first area settled by Europeans along the river it was largely populated by slave-owning southerners following the Boone's Lick Road. The major trails for the opening of the American West all have their starting points on the river, including the California, Mormon, Oregon, and Santa Fe trails. The first westward leg of the Pony Express was a ferry across the Missouri at St. Joseph, Missouri. Similarly, most emigrants arrived at the eastern terminus of the First transcontinental railroad via a ferry ride across the Missouri between Council Bluffs, Iowa, and Omaha. The Hannibal Bridge became the first bridge to cross the Missouri River in 1869, and its location was a major reason why Kansas City became the largest city on the river upstream from its mouth at St. Louis.\nTrue to the then-ideal of Manifest Destiny, over 500,000 people set out from the river town of Independence, Missouri, to their various destinations in the American West from the 1830s to the 1860s. These people had many reasons to embark on this strenuous year-long journey \u2013 economic crisis, and later gold strikes including the California Gold Rush, for example. For most, the route took them up the Missouri to Omaha, Nebraska, where they would set out along the Platte River, which flows from the Rocky Mountains in Wyoming and Colorado eastward through the Great Plains. An early expedition led by Robert Stuart from 1812 to 1813 proved the Platte impossible to navigate by the dugout canoes they used, let alone the large sidewheelers and sternwheelers that would later ply the Missouri in increasing numbers. One explorer remarked that the Platte was \"too thick to drink, too thin to plow\". Nevertheless, the Platte provided an abundant and reliable source of water for the pioneers as they headed west. Covered wagons, popularly referred to as \"prairie schooners\", provided the primary means of transport until the beginning of regular boat service on the river in the 1850s.\nDuring the 1860s, gold strikes in Montana, Colorado, Wyoming, and northern Utah attracted another wave of hopefuls to the region. Although some freight was hauled overland, most transport to and from the gold fields was done through the Missouri and Kansas Rivers, as well as the Snake River in western Wyoming and the Bear River in Utah, Idaho, and Wyoming. It is estimated that of the passengers and freight hauled from the Midwest to Montana, over 80\u00a0percent were transported by boat, a journey that took 150 days in the upstream direction. A route more directly west into Colorado lay along the Kansas River and its tributary the Republican River as well as pair of smaller Colorado streams, Big Sandy Creek and the South Platte River, to near Denver. The gold rushes precipitated the decline of the Bozeman Trail as a popular emigration route, as it passed through land held by often-hostile Native Americans. Safer paths were blazed to the Great Salt Lake near Corinne, Utah, during the gold rush period, which led to the large-scale settlement of the Rocky Mountains region and eastern Great Basin.\nAs settlers expanded their holdings into the Great Plains, they ran into land conflicts with Native American tribes. This resulted in frequent raids, massacres and armed conflicts, leading to the federal government creating multiple treaties with the Plains tribes, which generally involved establishing borders and reserving lands for the indigenous. As with many other treaties between the U.S. and Native Americans, they were soon broken, leading to huge wars. Over 1,000 battles, big and small, were fought between the U.S. military and Native Americans before the tribes were forced out of their land onto reservations.\nConflicts between natives and settlers over the opening of the Bozeman Trail in the Dakotas, Wyoming and Montana led to Red Cloud's War, in which the Lakota and Cheyenne fought against the U.S. Army. The fighting resulted in a complete Native American victory. In 1868, the Treaty of Fort Laramie was signed, which \"guaranteed\" the use of the Black Hills, Powder River Country and other regions surrounding the northern Missouri River to Native Americans without white intervention. The Missouri River was also a significant landmark as it divides northeastern Kansas from western Missouri; pro-slavery forces from Missouri would cross the river into Kansas and spark mayhem during Bleeding Kansas, leading to continued tension and hostility even today between Kansas and Missouri. Another significant military engagement on the Missouri River during this period was the 1861 Battle of Boonville, which did not affect Native Americans but rather was a turning point in the American Civil War that allowed the Union to seize control of transport on the river, discouraging the state of Missouri from joining the Confederacy.\nHowever, the peace and freedom of the Native Americans did not last for long. The Great Sioux War of 1876\u201377 was sparked when American miners discovered gold in the Black Hills of western South Dakota and eastern Wyoming. These lands were originally set aside for Native American use by the Treaty of Fort Laramie. When the settlers intruded onto the lands, they were attacked by Native Americans. U.S. troops were sent to the area to protect the miners, and drive out the natives from the new settlements. During this bloody period, both the Native Americans and the U.S. military won victories in major battles, resulting in the loss of nearly a thousand lives. The war eventually ended in an American victory, and the Black Hills were opened to settlement. Native Americans of that region were relocated to reservations in Wyoming and southeastern Montana.\nDam-building era.\nIn the late 19th and early 20th centuries, a great number of dams were built along the course of the Missouri, transforming 35\u00a0percent of the river into a chain of reservoirs. River development was stimulated by a variety of factors, first by growing demand for electricity in the rural northwestern parts of the basin, and by floods and droughts that plagued rapidly growing agricultural and urban areas along the lower Missouri River. Small, privately owned hydroelectric projects have existed since the 1890s, but the large flood-control and storage dams that characterize the middle reaches of the river today were not constructed until the 1950s.\nBetween 1890 and 1940, five dams were built in the vicinity of Great Falls to generate power from the Great Falls of the Missouri, a chain of giant waterfalls formed by the river in its path through western Montana. Black Eagle Dam, built in 1891 on Black Eagle Falls, was the first dam of the Missouri. Replaced in 1926 with a more modern structure, the dam was little more than a small weir atop Black Eagle Falls, diverting part of the Missouri's flow into the Black Eagle power plant. The largest of the five dams, Ryan Dam, was built in 1913. The dam lies directly above the Big Falls, the largest waterfall of the Missouri.\nIn the same period, several private establishments \u2013 most notably the Montana Power Company \u2013 began to develop the Missouri River above Great Falls and below Helena for power generation. A small run-of-the river structure completed in 1898 near the present site of Canyon Ferry Dam became the second dam built on the Missouri. This rock-filled timber crib dam generated seven and a half megawatts of electricity for Helena and the surrounding countryside. The nearby steel Hauser Dam was finished in 1907, but failed in 1908 because of structural deficiencies, causing catastrophic flooding all the way downstream past Craig. At Great Falls, a section of the Black Eagle Dam was dynamited to save nearby factories from inundation. Hauser was rebuilt in 1910 as a concrete gravity structure, and stands to this day.\nHolter Dam, about downstream of Helena, was the third hydroelectric dam built on this stretch of the Missouri River. When completed in 1918 by the Montana Power Company and the United Missouri River Power Company, its reservoir flooded the Gates of the Mountains, a limestone canyon which Meriwether Lewis described as \"the most remarkable clifts that we have yet seen ... the tow[er]ing and projecting rocks in many places seem ready to tumble on us.\" In 1949, the U.S. Bureau of Reclamation (USBR) began construction on the modern Canyon Ferry Dam to provide flood control to the Great Falls area. By 1954, the rising waters of Canyon Ferry Lake submerged the old 1898 dam, whose powerhouse still stands underwater about upstream of the present-day dam.\n[\u202fThe Missouri's temperament was as\u202f] \"uncertain as the actions of a jury or the state of a woman's mind\".\nThe Missouri basin suffered a series of catastrophic floods around the turn of the 20th century, most notably in 1844, 1881, and 1926\u20131927. In 1940, as part of the Great Depression-era New Deal, the U.S. Army Corps of Engineers (USACE) completed Fort Peck Dam in Montana. Construction of this massive public works project provided jobs for more than 50,000\u00a0laborers during the Depression and was a major step in providing flood control to the lower half of the Missouri River. However, Fort Peck only controls runoff from 11\u00a0percent of the Missouri River watershed, and had little effect on a severe snowmelt flood that struck the lower basin three years later. This event was particularly destructive as it submerged manufacturing plants in Omaha and Kansas City, greatly delaying shipments of military supplies in World War II.\nFlooding damages on the Mississippi\u2013Missouri river system were one of the primary reasons for which Congress passed the Flood Control Act of 1944, opening the way for the USACE to develop the Missouri on a massive scale. The 1944 act authorized the Pick\u2013Sloan Missouri Basin Program (Pick\u2013Sloan Plan), which was a composite of two widely varying proposals. The Pick plan, with an emphasis on flood control and hydroelectric power, called for the construction of large storage dams along the main stem of the Missouri. The Sloan plan, which stressed the development of local irrigation, included provisions for roughly 85\u00a0smaller dams on tributaries.\nIn the early stages of Pick\u2013Sloan development, tentative plans were made to build a low dam on the Missouri at Riverdale, North Dakota, and 27 smaller dams on the Yellowstone River and its tributaries. This was met with controversy from inhabitants of the Yellowstone basin, and eventually the USBR proposed a solution: to greatly increase the size of the proposed dam at Riverdale \u2013 today's Garrison Dam, thus replacing the storage that would have been provided by the Yellowstone dams. Because of this decision, the Yellowstone is now the longest free-flowing river in the contiguous United States. In the 1950s, construction commenced on the five mainstem dams \u2013 Garrison, Oahe, Big Bend, Fort Randall, and Gavins Point \u2013 proposed under the Pick-Sloan Plan. Along with Fort Peck, which was integrated as a unit of the Pick-Sloan Plan in the 1940s, these dams now form the Missouri River Mainstem System.\nThe flooding of lands along the Missouri River heavily impacted Native American groups whose reservations included fertile bottomlands and floodplains, especially in the arid Dakotas where it was some of the only good farmland they had. These consequences were pronounced in North Dakota's Fort Berthold Indian Reservation, where of land was taken by the construction of Garrison Dam. The Mandan, Hidatsa and Arikara / Sanish tribes sued the federal government on the basis of the 1851 Treaty of Fort Laramie which provided that reservation land could not be taken without the consent of both the tribes and Congress. After a lengthy legal battle the tribes were coerced in 1947 to accept a $5.1\u00a0million ($55\u00a0million today) settlement for the land, just $33\u00a0per acre. In 1949 this was increased to $12.6\u00a0million. The tribes were even denied the right to use the reservoir shore \"for grazing, hunting, fishing, and other purposes\".\nThe six dams of the Mainstem System, chiefly Fort Peck, Garrison, and Oahe, are among the largest dams in the world by volume; their sprawling reservoirs also rank among the biggest of the nation. Holding up to in total, the six reservoirs can store more than three years' worth of the river's flow as measured below Gavins Point, the lowermost dam. This capacity makes it the largest reservoir system in the United States and one of the largest in North America. In addition to storing irrigation water, the system also includes an annual flood-control reservation of . Mainstem power plants generate about 9.3\u00a0billion KWh annually \u2013 equal to a constant output of almost 1,100 megawatts. Along with nearly 100 smaller dams on tributaries, namely the Bighorn, Platte, Kansas, and Osage Rivers, the system provides irrigation water to nearly of land.\nThe table at left lists statistics of all fifteen dams on the Missouri River, ordered downstream. Many of the run-of-the-river power generation dams on the Missouri (marked in yellow) form very small impoundments which may or may not have been given names; those unnamed are left blank. All dams are on the upper half of the river above Sioux City; the lower river is uninterrupted due to its longstanding use as a shipping channel.\nNavigation.\n[\u202fMissouri River shipping\u202f] \"never achieved its expectations. Even under the very best of circumstances, it was never a huge industry\".\nBoat travel on the Missouri began with the wood-framed canoes and bull boats that Native Americans used for thousands of years before the colonization of the Great Plains introduced larger craft to the river. The first steamboat on the Missouri was the \"Independence\", which started running between St. Louis and Keytesville, Missouri, around 1819. By the 1830s, large mail and freight-carrying vessels were running regularly between Kansas City and St. Louis, and many traveled even farther upstream. A handful, such as the \"Western Engineer\" and the \"Yellowstone\", could make it up the river as far as eastern Montana.\nDuring the early 19th century, at the height of the fur trade, steamboats and keelboats travelled nearly the whole length of the Missouri from Montana's rugged Missouri Breaks to the mouth, carrying beaver and buffalo furs to and from the areas the trappers frequented. This resulted in the development of the Missouri River mackinaw, which specialized in carrying furs. Since these boats could only travel downriver, they were dismantled and sold for lumber upon their arrival at St. Louis.\nWater transport increased through the 1850s with multiple craft ferrying pioneers, emigrants and miners; many of these runs were from St. Louis or Independence to near Omaha. There, most of these people would set out overland along the large but shallow and unnavigable Platte River, which pioneers described as \"a mile wide and an inch deep\" and \"the most magnificent and useless of rivers\". Steamboat navigation peaked in 1858 with over 130 boats operating full-time on the Missouri, with many more smaller vessels. Many of the earlier vessels were built on the Ohio River before being transferred to the Missouri. Side-wheeler steamboats were preferred over the larger sternwheelers used on the Mississippi and Ohio because of their greater maneuverability.\nThe industry's success, however, did not guarantee safety. In the early decades before man controlled the river's flow, its sketchy rises and falls and its massive amounts of sediment, which prevented a clear view of the bottom, wrecked some 300 vessels. Because of the dangers of navigating the Missouri River, the average ship's lifespan was only about four years. The development of the Transcontinental and Northern Pacific Railroads marked the beginning of the end of steamboat commerce on the Missouri. Outcompeted by trains, the number of boats slowly dwindled, until there was almost nothing left by the 1890s. Transport of agricultural and mining products by barge, however, saw a revival in the early twentieth century.\nPassage to Sioux City.\nSince the beginning of the 20th century, the Missouri River has been extensively engineered for water transport purposes, and about 32\u00a0percent of the river now flows through artificially straightened channels. In 1912, the USACE was authorized to maintain the Missouri to a depth of from the Port of Kansas City to the mouth, a distance of . This was accomplished by constructing levees and wing dams to direct the river's flow into a straight, narrow channel and prevent sedimentation. In 1925, the USACE began a project to widen the river's navigation channel to ; two years later, they began dredging a deep-water channel from Kansas City to Sioux City. These modifications have reduced the river's length from some in the late 19th century to in the present day.\nConstruction of dams on the Missouri under the Pick-Sloan Plan in the mid-twentieth century was the final step in aiding navigation. The large reservoirs of the Mainstem System help provide a dependable flow to maintain the navigation channel year-round, and are capable of halting most of the river's annual freshets. However, high and low water cycles of the Missouri \u2013 notably the protracted early-21st-century drought in the Missouri River basin and historic floods in 1993 and 2011 \u2013 are difficult for even the massive Mainstem System reservoirs to control.\nIn 1945, the USACE began the Missouri River Bank Stabilization and Navigation Project, which would permanently increase the river's navigation channel to a width of and a depth of . During work that continues to this day, the navigation channel from Sioux City to St. Louis has been controlled by building rock dikes to direct the river's flow and scour out sediments, sealing and cutting off meanders and side channels, and dredging the riverbed. However, the Missouri has often resisted the efforts of the USACE to control its depth. In 2006, the U.S. Coast Guard stated that commercial barge tows ran aground in the Missouri River because the navigation channel had been severely silted. The USACE was blamed for failing to maintain the channel to the minimum depth.\nIn 1929, the Missouri River Navigation Commission estimated the amount of goods shipped on the river annually at 15\u00a0million tons (13.6\u00a0million metric tons), providing widespread consensus for the creation of a navigation channel. However, shipping traffic has since been far lower than expected \u2013 shipments of commodities including produce, manufactured items, lumber, and oil averaged only 683,000\u00a0tons (616,000\u00a0t) per year from 1994 to 2006.\nBy tonnage of transported material, Missouri is by far the largest user of the river accounting for 83\u00a0percent of river traffic, while Kansas has 12\u00a0percent, Nebraska three\u00a0percent and Iowa two\u00a0percent. Almost all of the barge traffic on the Missouri River ships sand and gravel dredged from the lower of the river; the remaining portion of the shipping channel now sees little to no use by commercial vessels.\nFor navigation purposes, the Missouri River is divided into two main sections. The Upper Missouri River is north of Gavins Point Dam, the last hydroelectric dam of fifteen on the river, just upstream from Sioux City, Iowa. The Lower Missouri River is the of river below Gavins Point until it meets the Mississippi just above St. Louis. The Lower Missouri River has no hydroelectric dams or locks but it has a plethora of wing dams that enable barge traffic by directing the flow of the river into a , channel. These wing dams have been put in place by and are maintained by the U.S. Army Corps of Engineers, and there are no plans to construct any locks to replace these wing dams on the Missouri River.\nTraffic decline.\nTonnage of goods shipped by barges on the Missouri River has seen a serious decline from the 1960s to the present. In the 1960s, the USACE predicted an increase to per year by 2000, but instead the opposite has happened. The amount of goods plunged from in 1977 to just in 2000. One of the largest drops has been in agricultural products, especially wheat. Part of the reason is that irrigated land along the Missouri has only been developed to a fraction of its potential. In 2006, barges on the Missouri hauled only of products which is equal to the \"daily\" freight traffic on the Mississippi.\nDrought conditions in the early 21st century and competition from other modes of transport \u2013 mainly railroads \u2013 are the primary reason for decreasing river traffic on the Missouri. The USACE's failure to consistently maintain the navigation channel has also hampered the industry. Efforts are being made to revive the shipping industry on the Missouri River, because of the efficiency and cheapness of river transport to haul agricultural products, and the overcrowding of alternative transportation routes. Solutions such as expanding the navigation channel and releasing more water from reservoirs during the peak of the navigation season are under consideration.\nDrought conditions lifted in 2010, in which about were barged on the Missouri, representing the first significant increase in shipments since 2000. However, flooding in 2011 closed record stretches of the river to boat traffic \u2013 \"wash[ing] away hopes for a bounce-back year\".\nThere are no lock and dams on the lower Missouri River, but there are plenty of wing dams that jettie out into the river and make it harder for barges to navigate. In contrast, the upper Mississippi has 29 locks and dams and averaged 61.3\u00a0million tons of cargo annually from 2008 to 2011, and its locks are closed in the winter.\nEcology.\nNatural history.\nHistorically, the thousands of square miles that comprised the floodplain of the Missouri River supported a wide range of plant and animal species. Biodiversity generally increased proceeding downstream from the cold, subalpine headwaters in Montana to the temperate, moist climate of Missouri. Today, the river's riparian zone consists primarily of cottonwoods, willows and sycamores, with several other types of trees such as maple and ash. Average tree height generally increases farther from the riverbanks for a limited distance, as land next to the river is vulnerable to soil erosion during floods. Because of its large sediment concentrations, the Missouri does not support many aquatic invertebrates. However, the basin supports about 300 species of birds and 150 species of fish, some of which are endangered such as the pallid sturgeon. The Missouri's aquatic and riparian habitats also support several species of mammals, such as minks, river otters, beavers, muskrats, and raccoons.\nThe World Wide Fund For Nature divides the Missouri River watershed into three freshwater ecoregions: the Upper Missouri, Lower Missouri and Central Prairie. The Upper Missouri, roughly encompassing the area within Montana, Wyoming, southern Alberta and Saskatchewan, and North Dakota, comprises mainly semiarid shrub-steppe grasslands with sparse biodiversity because of Ice Age glaciations. There are no known endemic species within the region. Except for the headwaters in the Rockies, there is little precipitation in this part of the watershed. The Middle Missouri ecoregion, extending through Colorado, southwestern Minnesota, northern Kansas, Nebraska, and parts of Wyoming and Iowa, has greater rainfall and is characterized by temperate forests and grasslands. Plant life is more diverse in the Middle Missouri, which is also home to about twice as many animal species. Finally, the Central Prairie ecoregion is situated on the lower part of the Missouri, encompassing all or parts of Missouri, Kansas, Oklahoma and Arkansas. Despite large seasonal temperature fluctuations, this region has the greatest diversity of plants and animals of the three. Thirteen species of crayfish are endemic to the lower Missouri.\nHuman impacts.\nSince river commerce and industrial development began in the 1800s, human activity has severely polluted the Missouri and degraded its water quality. Most of the river's floodplain habitat is long gone, replaced by irrigated agricultural land. Development of the floodplain has led to increasing numbers of people and infrastructure within areas at high risk of inundation. Levees have been constructed along more than a third of the river to keep floodwater within the channel, but with the consequences of faster stream velocity and a resulting increase of peak flows in downstream areas. Fertilizer runoff, which causes elevated levels of nitrogen and other nutrients, is a major problem along the Missouri River, especially in Iowa and Missouri. This form of pollution also affects the upper Mississippi, Illinois and Ohio Rivers. Low oxygen levels in rivers and the vast Gulf of Mexico dead zone at the end of the Mississippi Delta are both results of high nutrient concentrations in the Missouri and other tributaries of the Mississippi.\nChannelization of the lower Missouri waters has made the river narrower, deeper and less accessible to riparian flora and fauna. Many dams and bank stabilization projects have been built to help convert of Missouri River floodplain to agricultural land. Channel control has reduced the volume of sediment transported downstream by the river and eliminated critical habitat for fish, birds and amphibians. By the early 21st century, declines in populations of native species prompted the U.S. Fish and Wildlife Service to issue a biological opinion recommending restoration of river habitats for federally endangered bird and fish species.\nThe USACE began work on ecosystem restoration projects along the lower Missouri River in the early 21st century. Because of the low use of the shipping channel in the lower Missouri maintained by the USACE, it is now considered feasible to remove some of the levees, dikes, and wing dams that constrict the river's flow, thus allowing it to naturally restore its banks. By 2001, there were of riverside floodplain undergoing active restoration.\nRestoration projects have re-mobilized some of the sediments that had been trapped behind bank stabilization structures, prompting concerns of exacerbated nutrient and sediment pollution locally and downstream in the northern Gulf of Mexico. A 2010 National Research Council report assessed the roles of sediment in the Missouri River, evaluating current habitat restoration strategies and alternative ways to manage sediment. The report found that a better understanding of sediment processes in the Missouri River, including the creation of a \"sediment budget\" \u2013 an accounting of sediment transport, erosion, and deposition volumes for the length of the Missouri River \u2013 would provide a foundation for projects to improve water quality standards and protect endangered species.\nNational Wild and Scenic River.\nSeveral sections of the Missouri River were added to the National Wild and Scenic Rivers System from Fort Benton to Robinson Bridge, Gavins Point Dam to Ponca State Park and Fort Randall Dam to Lewis and Clark Lake. A total of of the river were designated including of wild river and of scenic river in Montana. of the river is listed as recreational under the National Wild and Scenic Rivers System.\nTourism and recreation.\nWith over of open water, the six reservoirs of the Missouri River Mainstem System provide some of the main recreational areas within the basin. Visitation has increased from 10\u00a0million visitor-hours in the mid-1960s to over 60\u00a0million visitor-hours in 1990. Development of visitor facilities was spurred by the Federal Water Project Recreation Act of 1965, which required the USACE to build and maintain boat ramps, campgrounds and other public facilities along major reservoirs. Recreational use of Missouri River reservoirs is estimated to contribute $85\u2013100\u00a0million to the regional economy each year.\nThe Lewis and Clark National Historic Trail, some long, follows nearly the entire Missouri River from its mouth to its source, retracing the route of the Lewis and Clark Expedition. Extending from Wood River, Illinois, in the east, to Astoria, Oregon, in the west, it also follows portions of the Mississippi and Columbia Rivers. The trail, which spans through eleven U.S. states, is maintained by various federal and state government agencies; it passes through some 100\u00a0historic sites, notably archaeological locations including the Knife River Indian Villages National Historic Site.\nParts of the river itself are designated for recreational or preservational use. The Missouri National Recreational River consists of portions of the Missouri downstream from Fort Randall and Gavins Point Dams that total . These reaches exhibit islands, meanders, sandbars, underwater rocks, riffles, snags, and other once-common features of the lower river that have now disappeared under reservoirs or have been destroyed by channeling. About forty-five steamboat wrecks are scattered along these reaches of the river.\nDownstream from Great Falls, Montana, about of the river course through a rugged series of canyons and badlands known as the Missouri Breaks. This part of the river, designated a U.S. National Wild and Scenic River in 1976, flows within the Upper Missouri Breaks National Monument, a preserve comprising steep cliffs, deep gorges, arid plains, badlands, archaeological sites, and whitewater rapids on the Missouri itself. The preserve includes a wide variety of plant and animal life; recreational activities include boating, rafting, hiking and wildlife observation.\nIn north-central Montana, some along over of the Missouri River, centering on Fort Peck Lake, comprise the Charles M. Russell National Wildlife Refuge. The wildlife refuge consists of a native northern Great Plains ecosystem that has not been heavily affected by human development, except for the construction of Fort Peck Dam. Although there are few designated trails, the whole preserve is open to hiking and camping.\nMany U.S. national parks, such as Glacier National Park, Rocky Mountain National Park, Yellowstone National Park and Badlands National Park are, at least partially, in the watershed. Parts of other rivers in the basin are set aside for preservation and recreational use \u2013 notably the Niobrara National Scenic River, which is a protected stretch of the Niobrara River, one of the Missouri's longest tributaries. The Missouri flows through or past many National Historic Landmarks, which include Three Forks of the Missouri, Fort Benton, Montana, Big Hidatsa Village Site, Fort Atkinson, Nebraska and Arrow Rock Historic District.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nWorks cited.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "19592", "revid": "194203", "url": "https://en.wikipedia.org/wiki?curid=19592", "title": "Microsoft Corporation", "text": ""}
