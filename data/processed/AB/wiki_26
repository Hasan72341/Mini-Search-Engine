{"id": "13224", "revid": "35681511", "url": "https://en.wikipedia.org/wiki?curid=13224", "title": "History of Germany", "text": "The concept of Germany as a distinct region in Central Europe can be traced to Julius Caesar, who referred to the unconquered area east of the Rhine as \"Germania\", thus distinguishing it from Gaul. The victory of the Germanic tribes in the Battle of the Teutoburg Forest (AD 9) prevented annexation by the Roman Empire, although the Roman provinces of Germania Superior and Germania Inferior were established along the Rhine. Following the Fall of the Western Roman Empire, the Franks conquered the other West Germanic tribes. When the Frankish Empire was divided among Charles the Great's heirs in 843, the eastern part became East Francia, and later Kingdom of Germany. In 962, Otto I became the first Holy Roman Emperor of the Holy Roman Empire, the medieval German state.\nDuring the High Middle Ages, the Hanseatic League, dominated by German port cities, established itself along the Baltic and North Seas. The development of a crusading element within German Christendom led to the Northern Crusades and the establishment of the State of the Teutonic Order along the Southern Baltic coast in what would later become Prussia. In the Investiture Controversy, the German Emperors resisted Catholic Church authority. In the Late Middle Ages, the regional dukes, princes, and bishops gained power at the expense of the emperors. Martin Luther led the Protestant Reformation within the Catholic Church after 1517, as the northern and eastern states became Protestant, while most of the southern and western states remained Catholic. The Thirty Years' War, a civil war from 1618 to 1648 brought tremendous destruction to the Holy Roman Empire. The estates of the empire attained great autonomy in the Peace of Westphalia, the most important being Austria, Prussia, Bavaria and Saxony. With the Napoleonic Wars, feudalism fell away and the Holy Roman Empire was dissolved in 1806. Napoleon established the Confederation of the Rhine as a German puppet state, but after the French defeat, the German Confederation was established under Austrian presidency. The German revolutions of 1848\u20131849 failed but the Industrial Revolution modernized the German economy, leading to rapid urban growth and the emergence of the socialist movement. Prussia, with its capital Berlin, grew in power. German universities became world-class centers for science and humanities, while music and art flourished. The unification of Germany was achieved under the leadership of the Chancellor Otto von Bismarck with the formation of the German Empire in 1871. The new \"Reichstag\", an elected parliament, had only a limited role in the imperial government. Germany joined the other powers in colonial expansion in Africa and the Pacific.\nBy 1900, Germany was the dominant power on the European continent and its rapidly expanding industry had surpassed Britain's while provoking it in a naval arms race. Germany led the Central Powers in World War I, but was defeated, partly occupied, forced to pay war reparations, and stripped of its colonies and significant territory along its borders. The German Revolution of 1918\u20131919 ended the German Empire with the abdication of Wilhelm II in 1918 and established the Weimar Republic, an ultimately unstable parliamentary democracy. In January 1933, Adolf Hitler, leader of the Nazi Party, used the economic hardships of the Great Depression along with popular resentment over the terms imposed on Germany at the end of World War I to establish a totalitarian regime. This Nazi Germany made racism, especially antisemitism, a central tenet of its policies, and became increasingly aggressive with its territorial demands, threatening war if they were not met. Germany quickly remilitarized, annexed its German-speaking neighbors and invaded Poland, triggering World War II. During the war, the Nazis established a systematic genocide program known as the Holocaust which killed 11 million people, including 6 million Jews (representing 2/3rds of the European Jewish population). By 1944, the German Army was pushed back on all fronts until finally collapsing in May 1945. Under occupation by the Allies, denazification efforts took place, large populations under former German-occupied territories were displaced, German territories were split up by the victorious powers and in the east annexed by Poland and the Soviet Union. Germany spent the entirety of the Cold War era divided into the NATO-aligned West Germany and Warsaw Pact-aligned East Germany. Germans also fled from Communist areas into West Germany, which experienced rapid economic expansion, and became the dominant economy in Western Europe.\nIn 1989, the Berlin Wall was opened, the Eastern Bloc collapsed, and East and West Germany were reunited in 1990. The Franco-German friendship became the basis for the political integration of Western Europe in the European Union. In 1998\u20131999, Germany was one of the founding countries of the eurozone. Germany remains one of the economic powerhouses of Europe, contributing about 1/4 of the eurozone's annual gross domestic product. In the early 2010s, Germany played a critical role in trying to resolve the escalating euro crisis, especially concerning Greece and other Southern European nations. In 2015, Germany faced the European migrant crisis as the main receiver of asylum seekers from Syria and other troubled regions. Germany opposed Russia's 2022 invasion of Ukraine and decided to strengthen its armed forces.\nPrehistory.\nPaleolithic and Neolithic ages.\nPre-human apes such as Danuvius guggenmosi, who were present in Germany over 11 million years ago, are theorized to be among the earliest apes to walk on two legs prior to other species and genera such as Australopithecus. The discovery of the Homo heidelbergensis mandible in 1907 affirms archaic human presence in Germany by at least 600,000 years ago, so stone tools were dated as far back as 1.33 million years ago. The oldest complete set of hunting weapons ever found anywhere in the world was excavated from a coal mine in Sch\u00f6ningen, Lower Saxony. Between 1994 and 1998, eight 380,000-year-old wooden javelins between in length were eventually unearthed.\nOne of the oldest buildings in the world and one of the oldest pieces of art was found in Bilzingsleben.\nIn 1856, the fossilized bones of an extinct human species were salvaged from a limestone grotto in the Neander valley near D\u00fcsseldorf, North Rhine-Westphalia. The archaic nature of the fossils, now known to be around 40,000 years old, was recognized and the characteristics published in the first-ever paleoanthropologic species description in 1858 by Hermann Schaaffhausen. The species was named \"Homo neanderthalensis\", Neanderthal man in 1864.\nThe oldest traces of homo sapiens in Germany were found in the cave Ilsenh\u00f6hle in Ranis, where up to 47,500-year-old remains were discovered, among the oldest in Europe. The remains of Paleolithic early modern human occupation uncovered and documented in several caves in the Swabian Jura include various mammoth ivory sculptures that rank among the oldest uncontested works of art and several flutes, made of bird bone and mammoth ivory that are confirmed to be the oldest musical instruments ever found. The 41,000-year-old L\u00f6wenmensch figurine represents the oldest uncontested figurative work of art and the 40,000-year-old Venus of Hohle Fels has been asserted as the oldest uncontested object of human figurative art ever discovered. These artefacts are attributed to the Aurignacian culture.\nBetween 12,900 and 11,700 years ago, north-central Germany was part of the Ahrensburg culture (named for Ahrensburg).\nThe first groups of early farmers different from the indigenous hunter-gatherers to migrate into Europe came from a population in western Anatolia at the beginning of the Neolithic period between 10,000 and 8,000 years ago.\nCentral Germany was one of the primary areas of the Linear Pottery culture (c.\u20095500 BC\u00a0\u2013 c.\u20094500 BC), which was partially contemporary with the Erteb\u00f8lle culture (c.\u20095300 BC\u00a0\u2013 c.\u20093950 BC) of Denmark and northern Germany. The construction of the Central European Neolithic circular enclosures falls in this time period with the best known and oldest being the Goseck circle, constructed c.\u20094900 BC. Afterwards, Germany was part of the R\u00f6ssen culture, Michelsberg culture and Funnelbeaker culture (c.\u20094600 BC\u00a0\u2013 c.\u20092800 BC). The oldest traces for the use of wheel and wagon ever found are located at a northern German Funnelbeaker culture site and date to around 3400 BC.\nBronze Age.\nThe settlers of the Corded Ware culture (c.\u20092900 BC\u00a0\u2013 c.\u20092350 BC), that had spread all over the fertile plains of Central Europe during the Late Neolithic were of Indo-European ancestry. The Indo-Europeans had, via mass-migration, arrived into the heartland of Europe around 4,500 years ago.\nBy the late Bronze Age, the Urnfield culture (c.\u20091300 BC\u00a0\u2013 c.\u2009750 BC) had replaced the Bell Beaker, Unetice and Tumulus cultures in central Europe, whilst the Nordic Bronze Age had developed in Scandinavia and northern Germany. The name 'Urnfield' comes from the custom of cremating the dead and placing their ashes in urns, which were then buried in fields. The first usage of the name occurred in publications over grave sites in southern Germany in the late 19th century. Over much of Europe, the Urnfield culture followed the Tumulus culture and was succeeded by the Hallstatt culture. The Italic peoples, including the Latins, from which the Romans emerged, come from the Urnfield culture of central Europe.\nIron Age.\nThe Hallstatt culture, which had developed from the Urnfield culture, was the predominant Western and Central European culture from the 12th to 8th centuries BC and during the early Iron Age (8th to 6th centuries BC). It was followed by the La T\u00e8ne culture (5th to 1st centuries BC).\nThe people who had adopted these cultural characteristics in central and southern Germany are regarded as Celts. How and if the Celts are related to the Urnfield culture remains disputed. However, Celtic cultural centres developed in central Europe during the late Bronze Age (c.\u20091200 BC until 700 BC). Some, like the Heuneburg, the oldest city north of the Alps, grew to become important cultural centres of the Iron Age in Central Europe, that maintained trade routes to the Mediterranean. In the 5th century BC the Greek historian Herodotus mentioned a Celtic city at the Danube \u2013 \"Pyrene\", that historians attribute to the Heuneburg. Beginning around 700 BC (or later), Germanic peoples (Germanic tribes) from southern Scandinavia and northern Germany expanded south and gradually replaced the Celtic peoples in Central Europe.\nEarly history: Germanic tribes, Roman conquests, and the Migration Period.\nEarly migrations, the Suebi and the Roman Republic.\nThe ethnogenesis of the Germanic tribes remains debated. However, for author Averil Cameron \"it is obvious that a steady process\" occurred during the Nordic Bronze Age, or at the latest during the Pre-Roman Iron Age (Jastorf culture). From their homes in southern Scandinavia and northern Germany the tribes began expanding south, east and west during the 1st century BC, and came into contact with the Celtic tribes of Gaul, as well as with Iranic, Baltic, and Slavic cultures in Central/Eastern Europe.\nFactual and detailed knowledge about the early history of the Germanic tribes is rare. Researchers have to be content with the recordings of the tribes' affairs with the Romans, linguistic conclusions, archaeological discoveries and the rather new yet auspicious results of archaeogenetic study. In the mid-1st century BC, Republican Roman statesman Julius Caesar erected the first known bridges across the Rhine during his campaign in Gaul and led a military contingent across and into the territories of the local Germanic tribes. After several days and having made no contact with Germanic troops (who had retreated inland) Caesar returned to the west of the river. By 60 BC, the Suebi tribe under chieftain Ariovistus, had conquered lands of the Gallic Aedui tribe to the west of the Rhine. Consequent plans to populate the region with Germanic settlers from the east were vehemently opposed by Caesar, who had already launched his ambitious campaign to subjugate all Gaul. Julius Caesar defeated the Suebi forces in 58 BC in the Battle of Vosges and forced Ariovistus to retreat across the Rhine.\nRoman settlement of the Rhine.\nAugustus, first Roman emperor, considered conquest beyond the Rhine and the Danube not only regular foreign policy but also necessary to counter Germanic incursions into a still rebellious Gaul. Forts and commercial centers were established along the rivers. Some tribes, such as the Ubii consequently allied with Rome and readily adopted advanced Roman culture. During the 1st century CE Roman legions conducted extended campaigns into Germania magna, the area north of the Upper Danube and east of the Rhine, attempting to subdue the various tribes. Roman ideas of administration, the imposition of taxes and a legal framework were frustrated by the total absence of an infrastructure. Germanicus's campaigns, for example, were almost exclusively characterized by frequent massacres of villagers and indiscriminate pillaging. The tribes, however maintained their elusive identities. A coalition of tribes under the Cherusci chieftain Arminius, who was familiar with Roman tactical doctrines, defeated a large Roman force in the Battle of the Teutoburg Forest. Consequently, Rome resolved to permanently establish the Rhine/Danube border and refrain from further territorial advance into Germania. By AD 100 the frontier along the Rhine and the Danube and the Limes Germanicus was firmly established. Several Germanic tribes lived under Roman rule south and west of the border, as described in Tacitus's \"Germania\". Austria formed the regular provinces of Noricum and Raetia. The provinces Germania Inferior (with the capital situated at Colonia Claudia Ara Agrippinensium, modern Cologne) and Germania Superior (with its capital at Mogontiacum, modern Mainz), were formally established in 85 AD, after long campaigns as lasting military control was confined to the lands surrounding the rivers. Christianity was introduced to Roman controlled western Germania before the Middle Ages, with Christian religious structures such as the Aula Palatina of Trier built during the reign of Constantine I (r.\u2009306\u00a0\u2013\u00a0337).\nMigration Period and decline of the Western Roman Empire.\nRome's Third Century Crisis coincided with the emergence of a number of large West Germanic tribes: the Alamanni, Franks, Bavarii, Chatti, Saxons, Frisii, Sicambri, and Thuringii. By the 3rd century the Germanic speaking peoples began to migrate beyond the \"limes\" and the Danube frontier. Several large tribes \u2013 the Visigoths, Ostrogoths, Vandals, Burgundians, Lombards, Saxons and Franks \u2013 migrated and played their part in the decline of the Roman Empire and the transformation of the old Western Roman Empire. By the end of the 4th century the Huns invaded eastern and central Europe, establishing the Hunnic Empire. The event triggered the Migration Period. Hunnic hegemony over a vast territory in central and eastern Europe lasted until the death of Attila's son Dengizich in 469. Another pivotal moment in the Migration Period was the Crossing of the Rhine in December of 406 by a large group of tribes including Vandals, Alans and Suebi who settled permanently within the crumbling Western Roman Empire.\nStem duchies and marches.\nStem duchies () in Germany refer to the traditional territory of the various Germanic tribes. The concept of such duchies survived especially in the areas which by the 9th century would constitute East Francia, which included the Duchy of Bavaria, the Duchy of Swabia, the Duchy of Saxony, the Duchy of Franconia and the Duchy of Thuringia, unlike further west the County of Burgundy or Lorraine in Middle Francia.\nThe Salian emperors (reigned 1027\u20131125) retained the stem duchies as the major divisions of Germany, but they became increasingly obsolete during the early high-medieval period under the Hohenstaufen, and Frederick Barbarossa finally abolished them in 1180 in favour of more numerous territorial duchies.\nSuccessive kings of Germany founded a series of border counties or marches in the east and the north. These included Lusatia, the North March (which would become Brandenburg and the heart of the future Prussia), and the Billung March. In the south, the marches included Carniola, Styria, and the March of Austria that would become Austria.\nMiddle Ages.\nFrankish Empire.\nThe Western Roman Empire fell in 476 with the deposition of Romulus Augustus by the Germanic \"foederati\" leader Odoacer, who became the first King of Italy. Afterwards, the Franks, like other post-Roman Western Europeans, emerged as a tribal confederacy in the Middle Rhine-Weser region, among the territory soon to be called Austrasia (the \"eastern land\"), the northeastern portion of the future Kingdom of the Merovingian Franks. As a whole, Austrasia comprised parts of present-day France, Germany, Belgium, Luxembourg and the Netherlands. Unlike the Alamanni to their south in Swabia, they absorbed large swaths of former Roman territory as they spread west into Gaul, beginning in 250. Clovis I of the Merovingian dynasty conquered northern Gaul in 486 and in the Battle of Tolbiac in 496 the Alemanni tribe in Swabia, which eventually became the Duchy of Swabia.\nBy 500, Clovis had united all the Frankish tribes, ruled all of Gaul and was proclaimed \"King of the Franks\" between 509 and 511. Clovis, unlike most Germanic rulers of the time, was baptized directly into Roman Catholicism instead of Arianism. His successors would cooperate closely with papal missionaries, among them Saint Boniface. After the death of Clovis in 511, his four sons partitioned his kingdom including Austrasia. Authority over Austrasia passed back and forth from autonomy to royal subjugation, as successive Merovingian kings alternately united and subdivided the Frankish lands.\nDuring the 5th and 6th centuries the Merovingian kings conquered the Thuringii (531 to 532), the Kingdom of the Burgundians and the principality of Metz and defeated the Danes, the Saxons and the Visigoths. King Chlothar I (558 to 561) ruled the greater part of what is now Germany and undertook military expeditions into Saxony, while the South-east of what is modern Germany remained under the influence of the Ostrogoths. Saxons controlled the area from the northern sea board to the Harz Mountains and the Eichsfeld in the south.\nThe Merovingians placed the various regions of their Frankish Empire under the control of semi-autonomous dukes \u2013 either Franks or local rulers, and followed imperial Roman strategic traditions of social and political integration of the newly conquered territories. While allowed to preserve their own legal systems, the conquered Germanic tribes were pressured to abandon the Arian Christian faith.\nIn 718 Charles Martel waged war against the Saxons in support of the Neustrians. In 743 his son Carloman in his role as Mayor of the Palace renewed the war against the Saxons, who had allied with and aided the duke Odilo of Bavaria. The Catholic Franks, who by 750 controlled a vast territory in Gaul, north-western Germany, Swabia, Burgundy and western Switzerland, that included the alpine passes allied with the Curia in Rome against the Lombards, who posed a permanent threat to the Holy See. Pressed by Liutprand, King of the Lombards, a Papal envoy for help had already been sent to the de facto ruler Charles Martel after his victory in 732 over the forces of the Umayyad Caliphate at the Battle of Tours, however a lasting and mutually beneficial alliance would only materialize after Charles' death under his successor Duke of the Franks, Pepin the Short.\nIn 751 Pippin III, Mayor of the Palace under the Merovingian king, himself assumed the title of king and was anointed by the Church. Pope Stephen II bestowed him the hereditary title of \"Patricius Romanorum\" as protector of Rome and St. Peter in response to the Donation of Pepin, that guaranteed the sovereignty of the Papal States. Charles the Great (who ruled the Franks from 774 to 814) launched a decades-long military campaign against the Franks' heathen rivals, the Saxons and the Avars. The campaigns and insurrections of the Saxon Wars lasted from 772 to 804. The Franks eventually overwhelmed the Saxons and Avars, forcibly converted the people to Christianity, and annexed their lands to the Carolingian Empire.\nFoundation of the Holy Roman Empire.\nAfter the death of Frankish king Pepin the Short in 768, his oldest son \"Charlemagne\" (\"Charles the Great\") consolidated his power over and expanded the Kingdom. Charlemagne ended 200 years of Royal Lombard rule with the Siege of Pavia, and in 774 he installed himself as King of the Lombards. Loyal Frankish nobles replaced the old Lombard aristocracy following a rebellion in 776. The next 30 years of his reign were spent ruthlessly strengthening his power in Francia and on the conquest of the Slavs and Pannonian Avars in the east and all tribes, such as the Saxons and the Bavarians. On Christmas Day, 800 AD, Charlemagne was crowned \"Imperator Romanorum\" (Emperor of the Romans) in Rome by Pope Leo III.\nFighting among Charlemagne's three grandsons over the continuation of the custom of partible inheritance or the introduction of primogeniture caused the Carolingian empire to be partitioned into three parts by the Treaty of Verdun of 843. Louis the German received the Eastern portion of the kingdom, East Francia, all lands east of the Rhine river and to the north of Italy. This encompassed the territories of the German stem duchies \u2013 Franks, Saxons, Swabians, and Bavarians \u2013 that were united in a federation under the first non-Frankish king Henry the Fowler, who ruled from 919 to 936. The royal court permanently moved in between a series of strongholds, called \"Kaiserpfalzen\", that developed into economic and cultural centers. Aachen Palace played a central role, as the local Palatine Chapel served as the official site for all royal coronation ceremonies during the entire medieval period until 1531.\nOttonian dynasty.\nIn 936, Otto I was crowned German king at Aachen, in 961 \"King of Italy\" in Pavia and crowned emperor by Pope John XII in Rome in 962. The tradition of the German King as protector of the Kingdom of Italy and the Latin Church resulted in the term Holy Roman Empire in the 12th century. The name that was to be identified with Germany continued in official usage, with the extension \"Nationis Germanic\u00e6 (of the German nation)\" added after the last imperial coronation in Rome in 1452, until its dissolution in 1806. Otto strengthened the royal authority by re-asserting the old Carolingian rights over ecclesiastical appointments. Otto wrested from the nobles the powers of appointment of the bishops and abbots, who controlled large land holdings. Additionally, Otto revived the old Carolingian program of appointing missionaries in the border lands. Otto continued to support celibacy for the higher clergy, so ecclesiastical appointments never became hereditary. By granting lands to the abbots and bishops he appointed, Otto actually turned these bishops into \"princes of the Empire\" (\"Reichsf\u00fcrsten\"). In this way, Otto was able to establish a national church. Outside threats to the kingdom were contained with the decisive defeat of the Hungarian Magyars at the Battle of Lechfeld in 955. The Slavs between the Elbe and the Oder rivers were also subjugated. Otto marched on Rome and drove John XII from the papal throne and for years controlled the election of the pope, setting a firm precedent for imperial control of the papacy for years to come.\nOtto I was followed on the throne by his son Otto II (955\u2013983), emperor 973\u2013983, Otto II's wife Theophanu (955\u2013991), regent 983\u2013991, his own wife Adelaide of Italy (931\u2013999), regent 991\u2013995, and his grandson Otto III (980\u20131002), emperor 996\u20131002. Otto III died childless and was succeeded by his second cousin Henry II, who likewise died childless as the last emperor of the Ottonian dynasty.\nSalian dynasty.\nHenry II was succeeded by Conrad II, a great-great-grandson of Otto I and the first emperor of the Salian dynasty. During the reign of Conrad II's son, Henry III (1039 to 1056), the empire supported the Cluniac reforms of the Church, the Peace of God, prohibition of simony (the purchase of clerical offices), and required celibacy of priests. Imperial authority over the Pope reached its peak. However, Rome reacted with the creation of the College of Cardinals and Pope Gregory VII's series of clerical reforms. Pope Gregory insisted in his \"Dictatus Papae\" on absolute papal authority over appointments to ecclesiastical offices. The subsequent conflict in which emperor Henry IV was compelled to submit to the Pope at Canossa in 1077, after having been excommunicated came to be known as the Investiture Controversy. In 1122, a temporary reconciliation was reached between Henry V and the Pope with the Concordat of Worms. With the conclusion of the dispute the Roman church and the papacy regained supreme control over all religious affairs. Consequently, the imperial Ottonian church system (\"Reichskirche\") declined. It also ended the royal/imperial tradition of appointing selected powerful clerical leaders to counter the Imperial secular princes.\nBetween 1095 and 1291 the various campaigns of the crusades to the Holy Land took place. Germans followed the movement as early as the People\u2019s Crusade, joining the army of Peter the Hermit. Knightly religious orders were established, including the Knights Templar, the Knights of St John (Knights Hospitaller), and the Teutonic Order.\nThe term \"sacrum imperium\" (Holy Empire) was first used officially by Friedrich I in 1157, but the words \"Sacrum Romanum Imperium\", Holy Roman Empire, were only combined in July 1180 and would never consistently appear on official documents from 1254 onwards.\nHanseatic League.\nThe Hanseatic League was a commercial and defensive alliance of the merchant guilds of towns and cities in northern and central Europe that dominated marine trade in the Baltic Sea, the North Sea and along the connected navigable rivers during part of the High and the Late Middle Ages (12th to 15th centuries). Each of the affiliated cities retained the legal system of its sovereign and, with the exception of the Free imperial cities, had only a limited degree of political autonomy. Beginning with an agreement of the cities of L\u00fcbeck and Hamburg, guilds cooperated in order to strengthen and combine their economic assets, like securing trading routes and tax privileges, to control prices and better protect and market their local commodities. Important centers of commerce within the empire, such as Cologne on the Rhine river and Bremen on the North Sea joined the union, which resulted in greater diplomatic esteem. Recognized by the various regional princes for the great economic potential, favorable charters for, often exclusive, commercial operations were granted. During its zenith the alliance maintained trading posts and \"kontors\" in virtually all cities between London and Edinburgh in the west to Novgorod in the east and Bergen in Norway. By the late 14th century the powerful league enforced its interests with military means, if necessary. This culminated in a war with the sovereign Kingdom of Denmark from 1361 to 1370. Principal city of the Hanseatic League remained L\u00fcbeck, where in 1356 the first general diet was held and its official structure was announced. The league declined after 1450 due to a number of factors, such as the 15th-century crisis, the territorial lords' shifting policies towards greater commercial control, the silver crisis and marginalization in the wider Eurasian trade network, among others.\nEastward expansion.\nThe \"Ostsiedlung\" (lit. Eastern settlement) is the term for a process of largely uncoordinated immigration and chartering of settlement structures by ethnic Germans into territories, already inhabited by Slavs and Balts east of the Saale and Elbe rivers, such as modern Poland and Silesia and to the south into Bohemia, modern Hungary and Romania during the High Middle Ages from the 11th to the 14th century. The primary purpose of the early imperial military campaigns into the lands to the east during the 10th and 11th century, was to punish and subjugate the local heathen tribes. Conquered territories were mostly lost after the troops had retreated, but eventually were incorporated into the empire as marches, fortified borderlands with garrisoned troops in strongholds and castles, who were to ensure military control and enforce the exaction of tributes. Contemporary sources do not support the idea of policies or plans for the organized settlement of civilians.\nEmperor Lothair II re-established feudal sovereignty over Poland, Denmark and Bohemia from 1135 and appointed margraves to turn the borderlands into hereditary fiefs and install a civilian administration. There is no discernible chronology of the immigration process as it took place in many individual efforts and stages, often even encouraged by the Slavic regional lords. However, the new communities were subjected to German law and customs. Total numbers of settlers were generally rather low and, depending on who held a numerical majority, populations usually assimilated into each other. In many regions only enclaves would persist, like Hermannstadt, founded by the Transylvanian Saxons in the medieval Hungarian Kingdom (today in Romania) who were called on by Geza II to repopulate the area as part of the \"Ostsiedlung\", having arrived there and founding the city in 1147 [Saxons called these parts of Transylvania \"Altland\" to distinguish them from later immigrant Saxon settlements established in about 1220 by the Teutonic Order].\nIn 1230, the Catholic monastic order of the Teutonic Knights launched the Prussian Crusade. The campaign, that was supported by the forces of Polish duke Konrad I of Masovia, initially intended to Christianize the Baltic Old Prussians, succeeded primarily in the conquest of large territories. The order, emboldened by imperial approval, quickly resolved to establish an independent state, without the consent of duke Konrad. Recognizing only papal authority and based on a solid economy, the order steadily expanded the Teutonic state during the following 150 years, engaging in several land disputes with its neighbors. Permanent conflicts with the Kingdom of Poland, the Grand Duchy of Lithuania, and the Novgorod Republic, eventually led to military defeat and containment by the mid-15th century. The last Grand Master Albert of Brandenburg converted to Lutheranism in 1525 and turned the remaining lands of the order into the secular Duchy of Prussia.\nChurch and state.\nHenry V, great-grandson of Conrad II, who had overthrown his father Henry IV became Holy Roman Emperor in 1111. Hoping to gain greater control over the church inside the Empire, Henry V appointed Adalbert of Saarbr\u00fccken as the powerful archbishop of Mainz in the same year. Adalbert began to assert the powers of the Church against secular authorities, that is, the Emperor. This precipitated the \"Crisis of 1111\" as yet another chapter of the long-term Investiture Controversy. In 1137, the prince-electors turned back to the Hohenstaufen family for a candidate, Conrad III. Conrad tried to divest his rival Henry the Proud of his two duchies\u2014Bavaria and Saxony\u2014that led to war in southern Germany as the empire was divided into two powerful factions. The faction of the \"Welfs\" or \"Guelphs\" (in Italian) supported the House of Welf of Henry the Proud, which was the ruling dynasty in the Duchy of Bavaria. The rival faction of the \"Waiblings\" or \"Ghibellines\" (in Italian) pledged allegiance to the Swabian House of Hohenstaufen. During this early period, the Welfs generally maintained ecclesiastical independence under the papacy and political particularism (the focus on ducal interests against the central imperial authority). The Waiblings, on the other hand, championed strict control of the church and a strong central imperial government.\nDuring the reign of the Hohenstaufen emperor Frederick I (Barbarossa), an accommodation was reached in 1156 between the two factions. The Duchy of Bavaria was returned to Henry the Proud's son Henry the Lion, duke of Saxony, who represented the Guelph party. However, the Margraviate of Austria was separated from Bavaria and turned into the independent Duchy of Austria by virtue of the Privilegium Minus in 1156.\nHaving become wealthy through trade, the confident cities of Northern Italy, supported by the Pope, increasingly opposed Barbarossa's claim of feudal rule \"(Honor Imperii)\" over Italy. The cities united in the Lombard League and finally defeated Barbarossa in the Battle of Legnano in 1176. The following year a reconciliation was reached between the emperor and Pope Alexander III in the Treaty of Venice. The 1183 Peace of Constance eventually settled that the Italian cities remained loyal to the empire but were granted local jurisdiction and full regal rights in their territories.\nIn 1180, Henry the Lion was outlawed, Saxony was divided, and Bavaria was given to Otto of Wittelsbach, who founded the Wittelsbach dynasty, which was to rule Bavaria until 1918.\nFrom 1184 to 1186, the empire under Frederick I Barbarossa reached its cultural peak with the \"Diet of Pentecost\" held at Mainz and the marriage of his son Henry in Milan to the Norman princess Constance of Sicily. The power of the feudal lords was undermined by the appointment of ministerials (unfree servants of the Emperor) as officials. Chivalry and the court life flowered, as expressed in the scholastic philosophy of Albertus Magnus and the literature of Wolfram von Eschenbach.\nBetween 1212 and 1250, Frederick II established a modern, professionally administered state from his base in Sicily. He resumed the conquest of Italy, leading to further conflict with the Papacy. In the Empire, extensive sovereign powers were granted to ecclesiastical and secular princes, leading to the rise of independent territorial states. The struggle with the Pope sapped the Empire's strength, as Frederick II was excommunicated three times. After his death, the Hohenstaufen dynasty fell, followed by an https:// during which there was no Emperor (1250\u20131273). This interregnum came to an end with the election of a small Swabian count, Rudolf of Habsburg, as emperor.\nThe failure of negotiations between Emperor Louis IV and the papacy led to the 1338 Declaration at Rhense by six princes of the Imperial Estate to the effect that election by all or the majority of the electors automatically conferred the royal title and rule over the empire, without papal confirmation. As result, the monarch was no longer subject to papal approbation and became increasingly dependent on the favour of the electors. Between 1346 and 1378 Emperor Charles IV of Luxembourg, king of Bohemia, sought to restore imperial authority. The 1356 decree of the Golden Bull stipulated that all future emperors were to be chosen by a college of only seven \u2013 four secular and three clerical \u2013 electors. The secular electors were the King of Bohemia, the Count Palatine of the Rhine, the Duke of Saxony, and the Margrave of Brandenburg, the clerical electors were the Archbishops of Mainz, Trier, and Cologne.\nBetween 1347 and 1351 Germany and almost the entire European continent were consumed by the most severe outbreak of the Black Death pandemic. Estimated to have caused the abrupt death of 30 to 60% of Europe's population, it led to widespread social and economic disruption and deep religious disaffection and fanaticism. Minority groups, and Jews in particular were blamed, singled out and attacked. As a consequence, many Jews fled and resettled in Eastern Europe.\nTowns and cities.\nTotal population estimates of the German territories range around 5 to 6 million by the end of Henry III's reign in 1056 and about 7 to 8 million after Friedrich Barbarossa's rule in 1190. The vast majority were farmers, typically in a state of serfdom under feudal lords and monasteries. Towns gradually emerged and in the 12th century many new cities were founded along the trading routes and near imperial strongholds and castles. The towns were subjected to the municipal legal system. Cities such as Cologne, that had acquired the status of Imperial Free Cities, were no longer answerable to the local landlords or bishops, but immediate subjects of the Emperor and enjoyed greater commercial and legal liberties. The towns were ruled by a council of the \u2013 usually mercantile \u2013 elite, the patricians. Craftsmen formed craft guilds, governed by strict rules, which sought to obtain control of the towns; a few were open to women. Society had diversified, but was divided into sharply demarcated classes of the clergy, physicians, merchants, various guilds of artisans, unskilled day labourers and peasants. Full citizenship was not available to paupers. Political tensions arose from issues of taxation, public spending, regulation of business, and market supervision, as well as the limits of corporate autonomy.\nCologne's central location on the Rhine river placed it at the intersection of the major trade routes between east and west and was the basis of Cologne's growth. The economic structures of medieval and early modern Cologne were characterized by the city's status as a major harbor and transport hub upon the Rhine. It was the seat of an archbishop, under whose patronage the vast Cologne Cathedral was built since 1240. The cathedral houses sacred Christian relics and it has since become a well known pilgrimage destination. By 1288 the city had secured its independence from the archbishop (who relocated to Bonn), and was ruled by its burghers.\nLearning and culture.\nBenedictine abbess Hildegard von Bingen wrote several influential theological, botanical, and medicinal texts, as well as letters, liturgical songs, poems, and arguably the oldest surviving morality play, \"Ordo Virtutum\", while supervising brilliant miniature Illuminations. About 100 years later, Walther von der Vogelweide became the most celebrated of the Minnes\u00e4nger, who were Middle High German lyric poets.\nAround 1439, Johannes Gutenberg of Mainz, used movable type printing and issued the Gutenberg Bible. He was the global inventor of the printing press, thereby starting the Printing Revolution. Cheap printed books and pamphlets played central roles for the spread of the Reformation and the Scientific Revolution.\nAround the transition from the 15th to the 16th century, Albrecht D\u00fcrer from Nuremberg established his reputation across Europe as painter, printmaker, mathematician, engraver, and theorist when he was still in his twenties and secured his reputation as one of the most important figures of the Northern Renaissance.\nEarly modern Germany.\nSocial changes.\nThe early-modern European society gradually developed after the disasters of the 14th century as religious obedience and political loyalties declined in the wake of the Great Plague, the schism of the Church and prolonged dynastic wars. The rise of the cities and the emergence of the new burgher class eroded the societal, legal and economic order of feudalism.\nThe commercial enterprises of the mercantile elites in the quickly developing cities in South Germany (such as Augsburg and Nuremberg), with the most prominent families being the Gossembrots, Fuggers (the wealthiest family in Europe during the fifteenth and sixteenth centuries), Welsers, Hochstetters, Imholts, generated unprecedented financial means. As financiers to both the leading ecclesiastical and secular rulers, these families fundamentally influenced the political affairs in the empire during the fifteenth and sixteenth century. The increasingly money based economy also provoked social discontent among knights and peasants and predatory \"robber knights\" became common.\nFrom 1438 the Habsburg dynasty, who had acquired control in the south-eastern empire over the Duchy of Austria, Bohemia and Hungary after the death of King Louis II in 1526, managed to permanently occupy the position of the Holy Roman Emperor until 1806 (with the exception of the years between 1742 and 1745).\nSome Europe-wide revolutions were born in the Empire: the combination of the first modern postal system established by Maximilian (with the management under the Taxis family) with the printing system invented by Gutenberg produced a communication revolution \u2013 the Empire's decentralized nature made censorship difficult and this combined with the new communication system to facilitate free expression, thus elevating cultural life. The system also helped the authorities to disseminate orders and policies, boosted the Empire's coherence in general, and helped reformers like Luther to broadcast their views and communicate with each other effectively, thus contributing to the religious Reformation.\nMaximilian's military reforms, especially his development of the Landsknechte, caused a military revolution that broke the back of the knight class and spread all over Europe shortly after his death.\nImperial reform.\nDuring his reign from 1493 to 1519, Maximilian I, in a combined effort with the Estates (who sometimes acted as opponents and sometimes as cooperators to him), his officials and his humanists, reformed the empire. A dual system of Supreme Courts (the \"Reichskammergericht\" and the \"Reichshofrat\") was established (with the \"Reichshofrat\" playing a more efficient role during the Early Modern period), together with the formalized Reception of Roman Law; the Imperial Diet (\"Reichstag\") became the all-important political forum and the supreme legal and constitutional institution, which would act as a guarantee for the preservation of the Empire in the long run; a Permanent Land Piece (\"Ewiger Landfriede\") was declared in 1495 with regional leagues and unions providing the supporting structure, together with the creation of the \"Reichskreise\" (\"Imperial Circles\", which would serve the purpose of organize imperial armies, collect taxes and enforce orders of the imperial institutions); the Imperial and Court Chanceries were combined to become the decisive government institution; the Landsknechte that Maximilian created became a form of imperial army; a national political culture began to emerge; and the German language began to attain an unified form. The political structure remained incomplete and piecemeal though, mainly due to the failure of the Common Penny (an imperial tax) that the Estates resisted. Through many compromises between emperor and estates though, a flexible, future-oriented problem-solving mechanism for the Empire was formed, together with a monarchy through which the emperor shared power with the Estates. Whether the Reform also equated to a (successful or unsuccessful) nation building process remains a debate.\nThe addition \"Nationis Germanic\u00e6\" (of German Nation) to the emperor's title appeared first in the 15th century: in a 1486 law decreed by Frederick III and in 1512 in reference to the Imperial Diet in Cologne by Maximilian I. In 1525, the Heilbronn reform plan \u2013 the most advanced document of the German Peasants' War (\"Deutscher Bauernkrieg\") \u2013 referred to the \"Reich\" as \"von Teutscher Nation\" (of German nation). During the fifteen century, the term \"German nation\" had witness a rise in use due to the growth of a \"community of interests\". The Estates also increasingly distinguished between their German Reich and the wider, \"universal\" Reich.\nProtestant Reformation.\nIn order to manage their ever growing expenses, the Renaissance Popes of the 15th and early 16th century promoted the excessive sale of indulgences and offices and titles of the Roman Curia.\nIn 1517, the monk Martin Luther published a pamphlet with 95 Theses that he posted in the town square of Wittenberg and handed copies of to feudal lords. Whether he nailed them to a church door at Wittenberg remains unclear. The list detailed 95 assertions, he argued, represented corrupt practice of the Christian faith and misconduct within the Catholic Church. Although perhaps not Luther's chief concern, he received popular support for his condemnation of the sale of indulgences and clerical offices, the pope's and higher clergy's abuse of power and his doubts of the very idea of the institution of the Church and the papacy.\nThe Protestant Reformation was the first successful challenge to the Catholic Church and began in 1521 as Luther was outlawed at the Diet of Worms after his refusal to repent. The ideas of the reformation spread rapidly, as the new technology of the modern printing press ensured cheap mass copies and distribution of the theses and helped by the Emperor Charles V's wars with France and the Turks. Hiding in the Wartburg Castle, Luther translated the Bible into German, thereby greatly contributing to the establishment of the modern German language. This is highlighted by the fact that Luther spoke only a local dialect of minor importance during that time. After the publication of his Bible, his dialect suppressed others and constitutes to a great extent what is now modern German. With the protestation of the Lutheran princes at the Imperial Diet of Speyer in 1529 and the acceptance and adoption of the Lutheran Augsburg Confession by the Lutheran princes beginning in 1530, the separate Lutheran church was established.\nThe German Peasants' War, which began in the southwest in Alsace and Swabia and spread further east into Franconia, Thuringia and Austria, was a series of economic and religious revolts of the rural lower classes, encouraged by the rhetoric of various radical religious reformers and Anabaptists against the ruling feudal lords. Although occasionally assisted by war-experienced noblemen like G\u00f6tz von Berlichingen and Florian Geyer (in Franconia) and the theologian Thomas M\u00fcntzer (in Thuringia), the peasant forces lacked military structure, skill, logistics and equipment and as many as 100,000 insurgents were eventually defeated and massacred by the territorial princes.\nThe Catholic Counter-Reformation, initiated in 1545 at the Council of Trent was spearheaded by the scholarly religious Jesuit order, that was founded just five years prior by several clerics around Ignatius of Loyola. Its intent was to challenge and contain the Protestant Reformation via apologetic and polemical writings and decrees, ecclesiastical reconfiguration, wars and imperial political maneuverings. In 1547, emperor Charles V defeated the Schmalkaldic League, a military alliance of Protestant rulers. The 1555 Peace of Augsburg decreed the recognition of the Lutheran Faith and religious division of the empire. It also stipulated the ruler's right to determine the official confession in his principality (\"Cuius regio, eius religio\"). The Counter-Reformation eventually failed to reintegrate the central and northern German Lutheran states. In 1608/1609 the Protestant Union and the Catholic League were formed.\nThirty Years' War, 1618\u20131648.\nThe 1618 to 1648 Thirty Years' War, that took place almost exclusively in the Holy Roman Empire has its origins, which remain widely debated, in the unsolved and recurring conflicts of the Catholic and Protestant factions. The Catholic emperor Ferdinand II attempted to achieve the religious and political unity of the empire, while the opposing Protestant Union forces were determined to defend their religious rights. The religious motive served as the universal justification for the various territorial and foreign princes, who over the course of several stages joined either of the two warring parties in order to gain land and power.\nThe conflict was sparked by the revolt of the Protestant nobility of Bohemia against emperor Matthias' succession policies. After imperial triumph at the Battle of White Mountain and a short-lived peace, the war grew to become a political European conflict by the intervention of King Christian IV of Denmark from 1625 to 1630, Gustavus Adolphus of Sweden from 1630 to 1648 and France under Cardinal Richelieu from 1635 to 1648. The conflict increasingly evolved into a struggle between the French House of Bourbon and the House of Habsburg for predominance in Europe, for which the central German territories of the empire served as the battleground.\nThe war ranks among the most catastrophic in history as three decades of constant warfare and destruction had left the land devastated. Marauding armies incessantly pillaged the countryside, seized and levied heavy taxes on cities and indiscriminately plundered the food stocks of the peasantry. There were also the countless bands of murderous outlaws, sick, homeless, disrupted people and invalid soldiery. Overall social and economic disruption caused a dramatic decline in population as a result of pandemic murder and random rape and killings, endemic infectious diseases, crop failures, famine, declining birth rates, wanton burglary, witch-hunts and the emigration of terrified people. Estimates vary between a 38% drop from 16 million people in 1618 to 10 million by 1650 and a mere 20% drop from 20 million to 16 million. The Altmark and W\u00fcrttemberg regions were especially hard hit, where it took generations to fully recover.\nThe war was the last major religious struggle in mainland Europe and ended in 1648 with the Peace of Westphalia. It resulted in increased autonomy for the constituent states of the Holy Roman Empire, limiting the power of the emperor. Most of Alsace was ceded to France, Western Pomerania and Bremen-Verden were given to Sweden as Imperial fiefs, and the Netherlands officially left the Empire.\nCulture and literacy.\nThe population of Germany reached about twenty million people by the mid-16th century, the great majority of whom were peasant farmers.\nThe Protestant Reformation was a triumph for literacy and the new printing press. Luther's translation of the Bible into High German (the New Testament was published in 1522; the Old Testament was published in parts and completed in 1534) was a decisive impulse for the increase of literacy in early modern Germany, and stimulated printing and distribution of religious books and pamphlets. From 1517 onward religious pamphlets flooded Germany and much of Europe. The Reformation instigated a media revolution as by 1530 over 10,000 individual works are published with a total of ten million copies. Luther strengthened his attacks on Rome by depicting a \"good\" against \"bad\" church. It soon became clear that print could be used for propaganda in the Reformation for particular agendas. Reform writers used pre-Reformation styles, clich\u00e9s, and stereotypes and changed items as needed for their own purposes. Especially effective were Luther's \"Small Catechism\", for use of parents teaching their children, and \"Larger Catechism,\" for pastors. Using the German vernacular they expressed the Apostles' Creed in simpler, more personal, Trinitarian language. Illustrations in the newly translated Bible and in many tracts popularized Luther's ideas. Lucas Cranach the Elder, the painter patronized by the electors of Wittenberg, was a close friend of Luther, and illustrated Luther's theology for a popular audience. He dramatized Luther's views on the relationship between the Old and New Testaments, while remaining mindful of Luther's careful distinctions about proper and improper uses of visual imagery.\nLuther's translation of the Bible into High German was also decisive for the German language and its evolution from Early New High German to Modern Standard German. The publication of Luther's Bible was a decisive moment in the spread of literacy in early modern Germany, and promoted the development of non-local forms of language and exposed all speakers to forms of German from outside their own area.\nScience.\nNotable late fifteenth to early eighteenth-century polymaths include: Johannes Trithemius, one of the founders of modern cryptography, steganography, as well as bibliography and literary studies as branches of knowledge; Conrad Celtes, the first and foremost German cartographic writer and \"the greatest lyric genius and certainly the greatest organizer and popularizer of German Humanism\"; Athanasius Kircher, described by Fletcher as \"a founder figure of various disciplines\u2014of geology (certainly vulcanology), musicology (as a surveyor of musical forms), museum curatorship, Coptology, to name a few\u2014and might be claimed today as the first theorist of gravity and a long-term originator of the moving pictures (with his magic lantern shows). Through his many enthusiasms, moreover, he was the conduit of others' pursuits in the rapidly widening horizon of knowledge that marks the later Renaissance.\"; and Gottfried Wilhelm Leibniz, one of the greatest, if not the greatest \"Universal genius\", of all time.\nCartography developed strongly, with the center being Nuremberg, at the beginning of the sixteenth century. Martin Waldseem\u00fcller and Matthias Ringmann's \"Universalis Cosmographia\" and the 1513 edition of \"Geography\" marked the climax of a cartography revolution. The emperor himself dabbled in cartography.\nIn 1515, Johannes Stabius (court astronomer under Maximilian I), Albrecht D\u00fcrer and the astronomer produced the first planispheres of both the southern and northern hemispheres, also the first printed celestial maps. These maps prompted the revival of interest in the field of uranometry throughout Europe.\nAstronomer Johannes Kepler from Weil der Stadt was one of the pioneering minds of empirical and rational research. Through rigorous application of the principles of the Scientific method he construed his laws of planetary motion. His ideas influenced contemporary Italian scientist Galileo Galilei and provided fundamental mechanical principles for Isaac Newton's theory of universal gravitation.\nColonies.\nGerman Colonies in the Americas existed because the Free Imperial Cities of Augsburg and Nuremberg got colonial rights in the Province of Venezuela or North of South America in return for debts owed by the Holy Roman Empire Charles V, who was also King of Spain. In 1528, Charles V issued a charter by which the Welser family possessed the rights to explore, rule and colonize the area, also with the motivation of searching for the legendary golden city of El Dorado. Their principal colony was Klein-Venedig. A never realized colonial project was Hanauish-Indies intended by Friedrich Casimir, Count of Hanau-Lichtenberg as a fief of the Dutch West India Company. The project failed due to a lack of funds and the outbreak of the Franco-Dutch War in 1672.\n1648\u20131815.\nRise of Prussia.\nWhen Albert Frederick, Duke of Prussia died in 1618 without male heirs, John Sigismund was granted the right of succession to the Duchy of Prussia, then still a Polish fief since the time of the Partitioning of Prussia in 1466. From then onwards the Duchy of Prussia was in personal union with the Margraviate of Brandenburg. Frederick William, ruler of Brandenburg-Prussia since 1640 and later called the Great Elector, acquired East Pomerania via the Peace of Westphalia in 1648. He reorganized his loose and scattered territories and managed to throw off the vassalage of Prussia under the Kingdom of Poland during the Second Northern War. In order to address the demographic problem of Prussia's largely rural population of about three million, he attracted the immigration and settlement of French Huguenots in urban areas. Many became craftsmen and entrepreneurs. King Frederick William I, known as the \"Soldier King\", who reigned from 1713 to 1740, established the structures for the highly centralized Prussian state and raised a professional army, that was to play a central role. He also successfully operated a command economy that some historians consider mercantilist.\nThe total population of Germany (in its 1914 territorial extent) grew from 16 million in 1700 to 17 million in 1750 and reached 24 million in 1800. The 18th-century economy noticeably profited from widespread practical application of the scientific method as greater yields, a more reliable agricultural production, and the introduction of hygienic standards positively affected the birth rate \u2013 death rate balance.\nWars.\nLouis XIV of France waged a series of successful wars in order to extend the French territory. He occupied Lorraine (1670) and annexed the remainder of Alsace (1678\u20131681) that included the free imperial city of Stra\u00dfburg. At the start of the Nine Years' War, he also invaded the Electorate of the Palatinate (1688\u20131697). Louis established a number of courts whose sole function was to reinterpret historic decrees and treaties, the Treaties of Nijmegen (1678) and the Peace of Westphalia (1648) in particular in favor of his policies of conquest. He considered the conclusions of these courts, the \"Chambres de r\u00e9union\" as sufficient justification for his annexations. Louis' forces operated inside the Holy Roman Empire largely unopposed, because all available imperial contingents fought in Austria in the Great Turkish War. The Grand Alliance of 1689 took up arms against France and countered any further military advances of Louis. The conflict ended in 1697 as both parties agreed to peace talks after either side had realized that a total victory was financially unattainable. The Treaty of Ryswick provided for the return of the Lorraine and Luxembourg to the empire and the abandoning of French claims to the Palatinate.\nAfter the last-minute relief of Vienna from a siege and the imminent seizure by a Turkish force in 1683, the combined troops of the Holy League, that had been founded the following year, embarked on the military containment of the Ottoman Empire and reconquered Hungary in 1687. The Papal States, the Holy Roman Empire, the Polish\u2013Lithuanian Commonwealth, the Republic of Venice and since 1686 Russia, had joined the league under the leadership of Pope Innocent XI. Prince Eugene of Savoy, who served under emperor Leopold I, took supreme command in 1697 and decisively defeated the Ottomans in a series of spectacular battles and\nmanoeuvres. The 1699 Treaty of Karlowitz marked the end of the Great Turkish War and Prince Eugene continued his service for the Habsburg monarchy as president of the War Council. He effectively ended Turkish rule over most of the territorial states in the Balkans during the Austro-Turkish War of 1716\u20131718. The Treaty of Passarowitz left Austria to freely establish royal domains in Serbia and the Banat and maintain hegemony in Southeast Europe, on which the future Austrian Empire was based.\nEnlightened absolutism.\nFrederick II \"the Great\" is best known for his military genius and unique utilisation of the highly organized army to make Prussia one of the great powers in Europe as well as escaping from almost certain national disaster at the last minute. He was also an artist, author and philosopher, who conceived and promoted the concept of enlightened absolutism.\nAustrian empress Maria Theresa succeeded in bringing about a favorable conclusion for her in the 1740 to 1748 war for recognition of her succession to the throne. However, Silesia was permanently lost to Prussia as a consequence of the Silesian Wars and the Seven Years' War. The 1763 Treaty of Hubertusburg ruled that Austria and Saxony had to relinquish all claims to Silesia. Prussia, that had nearly doubled its territory was eventually recognized as a great European power with the consequence that the politics of the following century were fundamentally influenced by German dualism, the rivalry of Austria and Prussia for supremacy in Central Europe.\nThe concept of enlightened absolutism, although rejected by the nobility and citizenry, was advocated in Prussia and Austria and implemented since 1763. Prussian king Frederick II defended the idea in an essay and argued that the benevolent monarch simply is the \"first servant of the state\", who effects his absolute political power for the benefit of the population as a whole. A number of legal reforms (e.g. the abolition of torture and the emancipation of the rural population and the Jews), the reorganization of the Prussian Academy of Sciences, the introduction of compulsory education for boys and girls and promotion of religious tolerance, among others, caused rapid social and economic development.\nDuring 1772 to 1795 Prussia instigated the partitions of Poland by occupying the western territories of the former Polish\u2013Lithuanian Commonwealth. Austria and Russia resolved to acquire the remaining lands with the effect that Poland ceased to exist as a sovereign state until 1918.\nSmaller states.\nThe smaller German states were overshadowed by Prussia and Austria. Bavaria had a rural economy. Saxony was in economically good shape, although numerous wars had taken their toll. During the time when Prussia rose rapidly within Germany, Saxony was distracted by foreign affairs. The House of Wettin concentrated on acquiring and then holding on to the Polish throne which was ultimately unsuccessful.\nMany of the smaller states of Germany were run by bishops, who in reality were from powerful noble families and showed scant interest in religion. While none of the later ecclesial rulers reached the outstanding reputation of Mainz' Johann Philipp von Sch\u00f6nborn or M\u00fcnster's Christoph Bernhard von Galen, some of them promoted Enlightenment like the benevolent and progressive Franz Ludwig von Erthal in W\u00fcrzburg and Bamberg.\nIn Hesse-Kassel, the Landgrave Frederick II, ruled from 1760 to 1785 as an enlightened despot, and raised money by renting soldiers (called \"Hessians\") to Great Britain to help fight the American Revolutionary War. He combined Enlightenment ideas with Christian values, cameralist plans for central control of the economy, and a militaristic approach toward diplomacy.\nHanover did not have to support a lavish court\u2014its rulers were also kings of England and resided in London. George III, elector (ruler) from 1760 to 1820, never once visited Hanover. The local nobility who ran the country opened the University of G\u00f6ttingen in 1737; it soon became a world-class intellectual center. Baden sported perhaps the best government of the smaller states. Karl Friedrich ruled for 73 years and was an enthusiast for the Enlightenment; he abolished serfdom in 1783.\nThe smaller states failed to form coalitions with each other, and were eventually overwhelmed by Prussia who swallowed up many of them between 1807 and 1871.\nSocial changes.\nPrussia underwent major social change between the mid-17th and mid-18th centuries as the nobility declined as the traditional aristocracy struggled to compete with the rising merchant class, which developed into a new Bourgeoisie middle class, while the emancipation of the serfs granted the rural peasantry land purchasing rights and freedom of movement, and a series of agrarian reforms in northwestern Germany abolished feudal obligations and divided up feudal land, giving rise to wealthier peasants and paved the way for a more efficient rural economy.\nEnlightenment.\nDuring the mid-18th century, the recognition and application of Enlightenment cultural, intellectual and spiritual ideals and standards, led to a flourishing of art, music, philosophy, science and literature. The philosopher Christian Wolff was a pioneering author in a vast number of fields of Enlightenment rationality, and established German as the prevailing language of philosophical reasoning, scholarly instruction and research.\nIn 1685, Margrave Frederick William of Prussia issued the Edict of Potsdam within a week after French king Louis XIV's Edict of Fontainebleau, that decreed the abolishment of the 1598 concession to free religious practice for Protestants. Frederick William offered his \"co-religionists, who are oppressed and assailed for the sake of the Holy Gospel and its pure doctrine...a secure and free refuge in all Our Lands\". Around 20,000 Huguenot refugees arrived in an immediate wave and settled in the cities, 40% in Berlin, the ducal residence alone. The French Lyceum in Berlin was established in 1689 and the French language had by the end of the 17th century replaced Latin to be spoken universally in international diplomacy. The nobility and the educated middle-class of Prussia and the various German states increasingly used the French language in public conversation in combination with universal cultivated manners. Like no other German state, Prussia had access to and the skill set for the application of pan-European Enlightenment ideas to develop more rational political and administrative institutions. The princes of Saxony carried out a comprehensive series of fundamental fiscal, administrative, judicial, educational, cultural and general economic reforms. The reforms were aided by the country's strong urban structure and influential commercial groups, who modernized pre-1789 Saxony along the lines of classic Enlightenment principles.\nJohann Gottfried von Herder broke new ground in philosophy and poetry, as a leader of the Sturm und Drang movement of proto-Romanticism. Weimar Classicism (\"Weimarer Klassik\") was a cultural and literary movement based in Weimar that sought to establish a new humanism by synthesizing Romantic, classical, and Enlightenment ideas. The movement, from 1772 until 1805, involved Herder as well as polymath Johann Wolfgang von Goethe and Friedrich Schiller, a poet and historian. Herder argued that every folk had its own particular identity, which was expressed in its language and culture. This legitimized the promotion of German language and culture and helped shape the development of German nationalism. Schiller's plays expressed the restless spirit of his generation, depicting the hero's struggle against social pressures and the force of destiny.\nGerman music, sponsored by the upper classes, came of age under composers Johann Sebastian Bach, Joseph Haydn, and Wolfgang Amadeus Mozart.\nK\u00f6nigsberg philosopher Immanuel Kant tried to reconcile rationalism and religious belief, individual freedom, and political authority. Kant's work contained basic tensions that would continue to shape German thought \u2013 and indeed all of European philosophy \u2013 well into the 20th century. The ideas of the Enlightenment and their implementation received general approval and recognition as principal cause for widespread cultural progress.\nFrench Revolution, 1789\u20131815.\nGerman reaction to the French Revolution was mixed at first. German intellectuals celebrated the outbreak, hoping to see the triumph of Reason and The Enlightenment. The royal courts in Vienna and Berlin denounced the overthrow of the king and the threatened spread of notions of liberty, equality, and fraternity. By 1793, the execution of the French king and the onset of the Terror disillusioned the Bildungsb\u00fcrgertum (educated middle classes). Reformers said the solution was to have faith in the ability of Germans to reform their laws and institutions in peaceful fashion.\nEurope was racked by two decades of war revolving around France's efforts to spread its revolutionary ideals, and the opposition of reactionary royalty. War broke out in 1792 as Austria and Prussia invaded France, but were defeated at the Battle of Valmy (1792). The German lands saw armies marching back and forth, bringing devastation (albeit on a far lower scale than the Thirty Years' War, almost two centuries before), but also bringing new ideas of liberty and civil rights for the people. Prussia and Austria ended their failed wars with France but (with Russia) partitioned Poland among themselves in 1793 and 1795.\nFrench consulate suzerainty.\nFrance took control of the Rhineland, imposed French-style reforms, abolished feudalism, established constitutions, promoted freedom of religion, emancipated Jews, opened the bureaucracy to ordinary citizens of talent, and forced the nobility to share power with the rising middle class. Napoleon created the Kingdom of Westphalia as a model state. These reforms proved largely permanent and modernized the western parts of Germany. When the French tried to impose the French language, German opposition grew in intensity. A Second Coalition of Britain, Russia, and Austria then attacked France but failed. Napoleon established direct or indirect control over most of western Europe, including the German states apart from Prussia and Austria. The old Holy Roman Empire was little more than a farce; Napoleon simply abolished it in 1806 while forming new countries under his control. In Germany Napoleon set up the \"Confederation of the Rhine\", comprising most of the German states except Prussia and Austria.\nImperial French suzerainty.\nUnder Frederick William II's weak rule (1786\u20131797) Prussia had undergone a serious economic, political and military decline. His successor king Frederick William III tried to remain neutral during the War of the Third Coalition and French emperor Napoleon's dissolution of the Holy Roman Empire and reorganisation of the German principalities. Induced by the queen and a pro-war party Frederick William joined the Fourth Coalition in October 1806. Napoleon easily defeated the Prussian army at the Battle of Jena and occupied Berlin. Prussia lost its recently acquired territories in western Germany, its army was reduced to 42,000 men, no trade with Britain was allowed and Berlin had to pay Paris high reparations and fund the French army of occupation. Saxony changed sides to support Napoleon and joined the Confederation of the Rhine. Ruler Frederick Augustus I was rewarded with the title of king and given a part of Poland taken from Prussia, which became known as the Duchy of Warsaw.\nAfter Napoleon's military fiasco in Russia in 1812, Prussia allied with Russia in the Sixth Coalition. A series of battles followed and Austria joined the alliance. Napoleon was decisively defeated in the Battle of Leipzig in late 1813. The German states of the Confederation of the Rhine defected to the Coalition against Napoleon, who rejected any peace terms. Coalition forces invaded France in early 1814, Paris fell and in April Napoleon surrendered. Prussia as one of the winners at the Congress of Vienna, gained extensive territory.\n1815\u20131871.\nOverview.\nIn 1815, continental Europe was in a state of overall turbulence and exhaustion, as a consequence of the French Revolutionary and Napoleonic Wars. The liberal spirit of the Enlightenment and Revolutionary era diverged toward Romanticism. The victorious members of the Coalition had negotiated a new peaceful balance of powers in Vienna and agreed to maintain a stable German heartland that keeps French imperialism at bay. However, the idea of reforming the defunct Holy Roman Empire was discarded. Napoleon's reorganization of the German states was continued and the remaining princes were allowed to keep their titles. In 1813, in return for guarantees from the Allies that the sovereignty and integrity of the Southern German states (Baden, W\u00fcrttemberg, and Bavaria) would be preserved, they broke with France.\nGerman Confederation.\nDuring the 1815 Congress of Vienna the 39 former states of the \"Confederation of the Rhine\" joined the German Confederation, a loose agreement for mutual defense. Attempts at economic integration and customs coordination were frustrated by repressive anti-national policies. Great Britain approved of the union, convinced that a stable, peaceful entity in central Europe could discourage aggressive moves by France or Russia. Most historians, however, concluded, that the Confederation was weak and ineffective and an obstacle to German nationalism. The union was undermined by the creation of the Zollverein in 1834, the 1848 revolutions, the rivalry between Prussia and Austria and was finally dissolved in the wake of the Austro-Prussian War of 1866, to be replaced by the North German Confederation during the same year.\nSociety and economy.\nIncreasingly after 1815, a centralized Prussian government based in Berlin took over the powers of the nobles, which in terms of control over the peasantry had been almost absolute. To help the nobility avoid indebtedness, Berlin set up a credit institution to provide capital loans in 1809, and extended the loan network to peasants in 1849. When the German Empire was established in 1871, the Junker nobility controlled the army and the navy, the bureaucracy, and the royal court; they generally set governmental policies.\nPopulation.\nBetween 1815 and 1865 the population of the German Confederation (excluding Austria) grew around 60% from 21 million to 34 million. Simultaneously the Demographic Transition took place as the high birth rates and high death rates of the pre-industrial country shifted to low birth and death rates of the fast-growing industrialized urban economic and agricultural system. Increased agricultural productivity secured a steady food supply, as famines and epidemics declined. This allowed people to marry earlier, and have more children. The high birthrate was offset by a very high rate of infant mortality and after 1840, large-scale emigration to the United States. Emigration totaled at 480,000 in the 1840s, 1,200,000 in the 1850s, and at 780,000 in the 1860s. The upper and middle classes first practiced birth control, soon to be universally adopted.\nIndustrialization.\nIn 1800, Germany's social structure was poorly suited to entrepreneurship or economic development. Domination by France during the French Revolution (1790s to 1815), however, produced important institutional reforms, that included the abolition of feudal restrictions on the sale of large landed estates, the reduction of the power of the guilds in the cities, and the introduction of a new, more efficient commercial law. The idea that these reforms were beneficial for Industrialization is a subject of debate among historians.\nIn the early 19th century the Industrial Revolution was in full swing in Britain, France, and Belgium. The various small federal states in Germany developed only slowly and autonomously as competition was strong. Early investments for the railway network during the 1830s came almost exclusively from private hands. Without a central regulatory agency, construction projects were quickly realized. Actual industrialization only took off after 1850 in the wake of the railroad construction. The textile industry grew rapidly, profiting from the elimination of tariff barriers by the Zollverein. During the second half of the 19th century German industry grew exponentially and by 1900, Germany was an industrial world leader along with Britain and the United States.\nUrbanization.\nIn 1800, the population was predominantly rural, as only 10% lived in communities of 5,000 or more people, and only 2% lived in cities of more than 100,000 people. After 1815, the urban population grew rapidly, due to the influx of young people from the rural areas. Berlin grew from 172,000 in 1800, to 826,000 inhabitants in 1870, Hamburg from 130,000 to 290,000, Munich from 40,000 to 269,000 and Dresden from 60,000 to 177,000.\nRailways.\nThe initial stage of economic development came with the railroad revolution in the 1840s, which opened up new markets for local products, created a pool of middle managers, increased the demand for engineers, architects and skilled machinists and stimulated investments in coal and iron. Political disunity among three dozen states and a pervasive conservatism made it difficult to build railways in the 1830s. However, by the 1840s, trunk lines did link the major cities; each German state was responsible for the lines within its own borders. Economist Friedrich List summed up the advantages to be derived from the development of the railway system in 1841:\nLacking a technological base at first, engineering and hardware was imported from Britain. In many cities, the new railway shops were the centres of technological awareness and training, so that by 1850, Germany was self-sufficient in meeting the demands of railroad construction, and the railways were a major impetus for the growth of the new steel industry. Observers found that even as late as 1890, their engineering was inferior to Britain. However, German unification in 1870 stimulated consolidation, nationalisation into state-owned companies, and further rapid growth. Unlike the situation in France, the goal was the support of industrialisation. Eventually numerous lines criss-crossed the Ruhr area and other industrial centers and provided good connections to the major ports of Hamburg and Bremen. By 1880, 9,400 locomotives pulled 43,000 passengers and 30,000 tons of freight a day.\nNewspapers and magazines.\nWhile there existed no national newspaper the many states issued a great variety of printed media, although they rarely exceeded regional significance. In a typical town existed one or two outlets, urban centers, such as Berlin and Leipzig had dozens. The audience was limited to a few per cent of male adults, chiefly from the aristocratic and upper middle class. Liberal publishers outnumbered conservative ones by a wide margin. Foreign governments bribed editors to guarantee a favorable image. Censorship was strict, and the imperial government issued the political news that was supposed to be published. After 1871, strict press laws were enforced by Bismarck to contain the Socialists and hostile editors. Editors focused on political commentary, culture, the arts, high culture and the popular serialized novels. Magazines were politically more influential and attracted intellectual authors.\nScience and culture during the 18th and 19th century.\n19th-century artists and intellectuals were greatly inspired by the ideas of the French Revolution and the great poets and writers Johann Wolfgang von Goethe, Gotthold Ephraim Lessing and Friedrich Schiller. The Sturm und Drang romantic movement was embraced and emotion was given free expression in reaction to the perceived rationalism of the Enlightenment. Philosophical principles and methods were revolutionized by Immanuel Kant's paradigm shift. Ludwig van Beethoven was the most influential composer of the period from classical to Romantic music. His use of tonal architecture in such a way as to allow significant expansion of musical forms and structures was immediately recognized as bringing a new dimension to music. His later piano music and string quartets, especially, showed the way to a completely unexplored musical universe, and influenced Franz Schubert and Robert Schumann. In opera, a new Romantic atmosphere combining supernatural terror and melodramatic plot in a folkloric context was first successfully achieved by Carl Maria von Weber and perfected by Richard Wagner in his Ring Cycle. The Brothers Grimm collected folk stories into the popular Grimm's Fairy Tales and are ranked among the founding fathers of German studies inasmuch as they initiated the work on the Deutsches W\u00f6rterbuch (\"The German Dictionary\"), the most comprehensive work on the German language.\nUniversity professors developed international reputations, especially in subjects from the humanities such as history and philology, which brought a new historical perspective to the study of political history, theology, philosophy, language, and literature. With Georg Wilhelm Friedrich Hegel, Friedrich Wilhelm Joseph Schelling, Arthur Schopenhauer, Friedrich Nietzsche, Max Weber, Karl Marx and Friedrich Engels in philosophy, Friedrich Schleiermacher in theology and Leopold von Ranke in history, German scholars became famous. The University of Berlin, founded in 1810, became the world's leading university. Von Ranke, for example, professionalized history and set the world standard for historiography. By the 1830s mathematics, physics, chemistry, and biology had emerged with world class science, led by Alexander von Humboldt in natural science and Carl Friedrich Gauss in mathematics. Young intellectuals often turned to politics, but their support for the failed revolution of 1848 forced many into exile.\nReligion.\nTwo main developments reshaped religion in Germany. Across the land, there was a movement to unite the larger Lutheran and the smaller Reformed Protestant churches. The churches themselves brought this about in Baden, Nassau, and Bavaria. However, in Prussia King Frederick William III was determined to handle unification entirely on his own terms, without consultation. His goal was to unify the Protestant churches, and to impose a single standardized liturgy, organization, and even architecture. The long-term goal was to have fully centralized royal control of all the Protestant churches. In a series of proclamations over several decades the \"Church of the Prussian Union\" was formed, bringing together the more numerous Lutherans, and the less numerous Reformed Protestants. The government of Prussia now had full control over church affairs, with the king himself recognized as the leading bishop. Opposition to unification came from the \"Old Lutherans\" in Silesia who clung tightly to the theological and liturgical forms they had followed since the days of Luther. The government attempted to crack down on them, so they went underground. Tens of thousands migrated, to South Australia, and especially to the United States, where they formed the Missouri Synod, which is still in operation as a conservative denomination. Finally in 1845 a new king Frederick William IV offered a general amnesty and allowed the Old Lutherans to form a separate church association with only nominal government control.\nFrom the religious point of view of the typical Catholic or Protestant, major changes were underway in terms of a much more personalized religiosity that focused on the individual more than the church or the ceremony. The rationalism of the late 19th century faded away, and there was a new emphasis on the psychology and feeling of the individual, especially in terms of contemplating sinfulness, redemption, and the mysteries and the revelations of Christianity. Pietistic revivals were common among Protestants. Among, Catholics there was a sharp increase in popular pilgrimages. In 1844 alone, half a million pilgrims made a pilgrimage to the city of Trier in the Rhineland to view the Seamless robe of Jesus, said to be the robe that Jesus wore on the way to his crucifixion. Catholic bishops in Germany had historically been largely independent of Rome, but now the Vatican exerted increasing control, a new \"ultramontanism\" of Catholics highly loyal to Rome. A heated controversy erupted in 1837\u20131838 in the largely Catholic Rhineland over the religious education of children of mixed marriages, where the mother was Catholic and the father Protestant. The government passed laws to require that these children always be raised as Protestants, contrary to Napoleonic law that had previously prevailed and allowed the parents to make the decision. The government put the Catholic Archbishop under house arrest. In 1840, the new King Frederick William IV sought reconciliation and defused the controversy by agreeing to most of the Catholic demands. However Catholic memories remained deep and led to a sense that Catholics always needed to stick together in the face of a hostile government.\nPolitics of restoration and revolution.\nAfter Napoleon.\nAfter the fall of Napoleon, Europe's statesmen convened in Vienna in 1815 for the reorganisation of European affairs, under the leadership of the Austrian Prince Metternich. The political principles agreed upon at this Congress of Vienna included the restoration, legitimacy and solidarity of rulers for the repression of revolutionary and nationalist ideas.\nThe German Confederation () was founded, a loose union of 39 states (35 ruling princes and 4 free cities) under Austrian leadership, with a Federal Diet () meeting in Frankfurt am Main. It was a loose coalition that failed to satisfy most nationalists. The member states largely went their own way, and Austria had its own interests.\nIn 1819, a student radical assassinated the reactionary playwright August von Kotzebue, who had scoffed at liberal student organisations. In one of the few major actions of the German Confederation, Prince Metternich called a conference that issued the repressive Carlsbad Decrees, designed to suppress liberal agitation against the conservative governments of the German states. The Decrees terminated the fast-fading nationalist fraternities (), removed liberal university professors, and expanded the censorship of the press. The decrees began the \"persecution of the demagogues\", which was directed against individuals who were accused of spreading revolutionary and nationalist ideas. Among the persecuted were the poet Ernst Moritz Arndt, the publisher Johann Joseph G\u00f6rres and the \"Father of Gymnastics\" Ludwig Jahn.\nIn 1834, the Zollverein was established, a customs union between Prussia and most other German states, but excluding Austria. As industrialisation developed, the need for a unified German state with a uniform currency, legal system, and government became more and more obvious.\n1848.\nGrowing discontent with the political and social order imposed by the Congress of Vienna led to the outbreak, in 1848, of the March Revolution in the German states. In May the German National Assembly (the Frankfurt Parliament) met in Frankfurt to draw up a national German constitution.\nBut the 1848 revolution turned out to be unsuccessful: King Frederick William IV of Prussia refused the imperial crown, the Frankfurt parliament was dissolved, the ruling princes repressed the risings by military force, and the German Confederation was re-established by 1850. Many leaders went into exile, including a number who went to the United States and became a political force there.\n1850s.\nThe 1850s were a period of extreme political reaction. Dissent was vigorously suppressed, and many Germans emigrated to America following the collapse of the 1848 uprisings. Frederick William IV became extremely depressed and melancholic during this period, and was surrounded by men who advocated clericalism and absolute divine monarchy. The Prussian people once again lost interest in politics. Prussia not only expanded its territory but began to industrialize rapidly, while maintaining a strong agricultural base.\nBismarck takes charge (1862\u20131866).\nIn 1857, the Prussian king Frederick William IV suffered a stroke and his brother William served as regent until 1861 when he became King William I. Although conservative, William was very pragmatic. His most significant accomplishment was the naming of Otto von Bismarck as Prussian minister president in 1862. The cooperation of Bismarck, Defense Minister Albrecht von Roon, and Field Marshal Helmut von Moltke set the stage for the military victories over Denmark, Austria, and France that led to the unification of Germany.\nIn 1863\u20131864, disputes between Prussia and Denmark over Schleswig, which was not part of the German Confederation, and which Danish nationalists wanted to incorporate into the Danish kingdom escalated. The conflict led to the Second War of Schleswig in 1864. Prussia, joined by Austria, easily defeated Denmark and occupied Jutland. The Danes were forced to cede both the Duchy of Schleswig and the Duchy of Holstein to Austria and Prussia. The subsequent management of the two duchies led to tensions between Austria and Prussia. Austria wanted the duchies to become an independent entity within the German Confederation, while Prussia intended to annex Austria. The disagreement served as a pretext for the Seven Weeks War between Austria and Prussia that broke out in June 1866. In July, the two armies clashed at Sadowa-K\u00f6niggr\u00e4tz (Bohemia) in an enormous battle involving half a million men. Prussian superior logistics and the then-modern breech-loading needle guns' superiority over the slow muzzle-loading rifles of the Austrians proved to be essential for Prussia's victory. The battle had also decided the struggle for hegemony in Germany and Bismarck was deliberately lenient with a defeated Austria that would play only a subpordinate role in future German affairs.\nNorth German Confederation, 1866\u20131871.\nAfter the Seven Weeks War, the German Confederation was dissolved and the North German Federation (German \"Norddeutscher Bund\") was established under the leadership of Prussia. Austria was excluded and its immense influence over Germany finally came to an end. The North German Federation was a transitional organisation that existed from 1867 to 1871, between the dissolution of the German Confederation and the founding of the German Empire.\nGerman Empire, 1871\u20131918.\nOverview.\nChancellor Otto von Bismarck determined the political course of the German Empire until 1890. He fostered alliances in Europe to contain France on the one hand and aspired to consolidate Germany's influence in Europe on the other. His principal domestic policies focused on the suppression of socialism and the reduction of the strong influence of the Roman Catholic Church on its adherents. He issued both the Anti-Socialist Laws and a set of social laws, including universal health care, pension plans and other social security programs, that were intended to win socialists over to the government's side. His Kulturkampf policies were vehemently resisted by Catholics, who organized political opposition in the Center Party (Zentrum). German industrial and economic power had grown to match Britain by 1900.\nIn 1888, the young and ambitious Kaiser Wilhelm II became emperor. He rejected advice from experienced politicians and ordered Bismarck's resignation in 1890. He opposed Bismarck's carefully considered foreign policy and was determined to pursue colonialist policies, as Britain and France had been doing for centuries. The Kaiser promoted the active colonization of Africa and Asia for the lands that were not already colonies of other European powers. The Kaiser took a mostly unilateral approach in Europe only allied with the Austro-Hungarian Empire, and embarked on a dangerous naval arms race with Britain. His aggressive and ill-considered policies greatly contributed to the situation in which the assassination of the Austrian-Hungarian crown prince would spark World War I.\nBismarck era.\nBismarck was the dominant personality not just in Germany but in all of Europe and indeed the entire diplomatic world 1870\u20131890. Historians continue to debate his goals. Lothar Gall and Ernst Engelberg consider Bismarck was a future-oriented modernizer. In sharp contrast, Jonathan Steinberg decided he was basically a traditional Prussian whose highest priorities were to reinforce the monarchy, the Army, and the social and economic dominance of his own Junker class, thereby being responsible for a tragic history after his removal in 1890.\nThe new empire.\nIn 1868, the Spanish queen Isabella II was deposed in the Glorious Revolution, leaving the country's throne vacant. When Prussia suggested the Hohenzollern candidate, Prince Leopold as successor, France vehemently objected. The matter evolved into a diplomatic scandal and in July 1870, France resolved to end it in a full-scale war. The conflict was quickly decided as Prussia, joined by forces of a pan-German alliance never gave up the tactical initiative. A series of victories in north-eastern France followed and another French army group was simultaneously encircled at Metz. A few weeks later, the French army contingent under Emperor Napoleon III's personal command was finally forced to capitulate in the fortress of Sedan. Napoleon was taken prisoner and a provisional government hastily proclaimed in Paris. The new government resolved to fight on and tried to reorganize the remaining armies while the Germans settled down to besiege Paris. The starving city surrendered in January 1871 and Jules Favre signed the surrender at Versailles. France was forced to pay indemnities of 5\u00a0billion francs and cede Alsace-Lorraine to Germany. This conclusion left the French national psyche deeply humiliated and further aggravated the French\u2013German enmity.\nDuring the Siege of Paris, the German princes assembled in the Hall of Mirrors of the Palace of Versailles on 18 January 1871 and announced the establishment of the German Empire and proclaimed the Prussian King Wilhelm I as German Emperor. The act unified all ethnic German states with the exception of Austria in the Little German solution of a federal economic, political and administrative unit. Bismarck was appointed to serve as Chancellor.\nA federal empire.\nThe new empire was a federal union of 25 states that varied considerably in size, demography, constitution, economy, culture, religion and socio-political development. However, even Prussia itself, which accounted for two-thirds of the territory as well as of the population, had emerged from the empire's periphery as a newcomer. It also faced colossal cultural and economic internal divisions. The Prussian provinces of Westphalia and the Rhineland for example had been under French control during the previous decades. The local people, who had benefited from the liberal, civil reforms, that were derived from the ideas of the French Revolution, had only little in common with predominantly rural communities in authoritarian and disjointed Junker estates of Pommerania.\nThe inhabitants of the smaller territorial lands, especially in central and southern Germany greatly rejected the Prussianized concept of the nation and preferred to associate such terms with their individual home state. The Hanseatic port cities of Hamburg, Bremen and L\u00fcbeck ranked among the most ferocious opponents of the \"so-called contract with Prussia\". As advocates of free trade, they objected to Prussian ideas of economic integration and refused to sign the renewed Zollverein (Custom Union) treaties until 1888. The Hanseatic merchants' overseas economic success corresponded with their globalist mindset. The citizens of Hamburg, whom Bismark characterized as \"extremely irritating\" and the German ambassador in London as \"the worst Germans we have\", were particularly appalled by Prussian militarism and its unopposed growing influence.\nThe Prusso-German authorities were aware of necessary integration concepts as the results and the 52% voter turnout of the first imperial elections had clearly demonstrated. Historians increasingly argue, that the nation-state was \"forged through empire\". National identity was expressed in bombastic imperial stone iconography and was to be achieved as an imperial people, with \"an emperor as head of state and it was to develop imperial ambitions\" \u2013 domestic, European and global.\nBismarck's domestic policies as Chancellor of Germany were based on his effort to universally adopt the idea of the Protestant Prussian state and achieve the clear separation of church and state in all imperial principalities. In the Kulturkampf (lit.: culture struggle) from 1871 to 1878, he tried to minimize the influence of the Roman Catholic Church and its political arm, the Catholic Centre Party, via secularization of all education and introduction of civil marriage, but without success. The Kulturkampf antagonised many Protestants as well as Catholics and was eventually abandoned. The millions of non-German imperial subjects, like the Polish, Danish and French minorities, were left with no choice but to endure discrimination or accept the policies of Germanisation.\nA three-class system: Aristocracy, middle class, and working class.\nThe new Empire provided attractive top level career opportunities for the national nobility in the various branches of the consular and civil services and the army. As a consequence the aristocratic near total control of the civil sector guaranteed a dominant voice in the decision making in the universities and the churches. The 1914 German diplomatic corps consisted of 8 princes, 29 counts, 20 barons, 54 representants of the lower nobility and a mere 11 commoners. These commoners were indiscriminately recruited from elite industrialist and banking families. The consular corps employed numerous commoners, that however, occupied positions of little to no executive power. The Prussian tradition to reserve the highest military ranks for young aristocrats was adopted and the new constitution put all military affairs under the direct control of the Emperor and beyond control of the Reichstag. With its large corps of reserve officers across Germany, the military strengthened its role as \"The estate which upheld the nation\", and historian Hans-Ulrich Wehler added: \"\"it became an almost separate, self-perpetuating caste\".\"\nPower increasingly was centralized among the 7000 aristocrats, who resided in the national capital of Berlin and neighboring Potsdam. Berlin's rapidly increasing rich middle-class copied the aristocracy and tried to marry into it. A peerage could permanently boost a rich industrial family into the upper reaches of the establishment. However, the process tended to work in the other direction as the nobility became industrialists. For example, 221 of the 243 mines in Silesia were owned by nobles or by the King of Prussia himself.\nThe middle class in the cities grew exponentially, although it never acquired the powerful parliamentary representation and legislative rights as in France, Britain or the United States. The Association of German Women's Organizations or BDF was established in 1894 to encompass the proliferating women's organizations that had emerged since the 1860s. From the beginning the BDF was a bourgeois organization, its members working toward equality with men in such areas as education, financial opportunities, and political life. Working-class women were not welcome and were organized by the Socialists.\nThe rise of the Socialist Workers' Party (later known as the Social Democratic Party of Germany, SPD), aimed to peacefully establish a socialist order through the transformation of the existing political and social conditions. From 1878, Bismarck tried to oppose the growing social democratic movement by outlawing the party's organisation, its assemblies and most of its newspapers. Nonetheless, the Social Democrats grew stronger and Bismarck initiated his social welfare program in 1883 in order to appease the working class.\nBismarck built on a tradition of welfare programs in Prussia and Saxony that began as early as the 1840s. In the 1880s he introduced old age pensions, accident insurance, medical care, and unemployment insurance that formed the basis of the modern European welfare state. His paternalistic programs won the support of German industry because its goals were to win the support of the working classes for the Empire and reduce the outflow of immigrants to America, where wages were higher but welfare did not exist. Bismarck further won the support of both industry and skilled workers by his high tariff policies, which protected profits and wages from American competition, although they alienated the liberal intellectuals who wanted free trade.\nKulturkampf.\nBismarck would not tolerate any power outside Germany\u2014as in Rome\u2014having a say in domestic affairs. He launched the Kulturkampf (\"culture war\") against the power of the pope and the Catholic Church in 1873, but only in the state of Prussia. This gained strong support from German liberals, who saw the Catholic Church as the bastion of reaction and their greatest enemy. The Catholic element, in turn, saw in the National-Liberals the worst enemy and formed the Center Party.\nCatholics, although nearly a third of the national population, were seldom allowed to hold major positions in the Imperial government, or the Prussian government. After 1871, there was a systematic purge of the remaining Catholics; in the powerful interior ministry, which handled all police affairs, the only Catholic was a messenger boy. Jews were likewise heavily discriminated against.\nMost of the Kulturkampf was fought out in Prussia, but Imperial Germany passed the Pulpit Law which made it a crime for any cleric to discuss public issues in a way that displeased the government. Nearly all Catholic bishops, clergy, and laymen rejected the legality of the new laws and defiantly faced the increasingly heavy penalties and imprisonments imposed by Bismarck's government. Historian Anthony Steinhoff reports the casualty totals:\nAs of 1878, only three of eight Prussian dioceses still had bishops, some 1,125 of 4,600 parishes were vacant, and nearly 1,800 priests ended up in jail or in exile\u00a0... Finally, between 1872 and 1878, numerous Catholic newspapers were confiscated, Catholic associations and assemblies were dissolved, and Catholic civil servants were dismissed merely on the pretence of having Ultramontane sympathies.\nBismarck underestimated the resolve of the Catholic Church and did not foresee the extremes that this struggle would attain. The Catholic Church denounced the harsh new laws as anti-Catholic and mustered the support of its rank and file voters across Germany. In the following elections, the Center Party won a quarter of the seats in the Imperial Diet. The conflict ended after 1879 because Pope Pius IX died in 1878 and Bismarck broke with the Liberals to put his main emphasis on tariffs, foreign policy, and attacking socialists. Bismarck negotiated with the conciliatory new pope Leo XIII. Peace was restored, the bishops returned and the jailed clerics were released. Laws were toned down or taken back, but the laws concerning education, civil registry of marriages and religious disaffiliation remained in place. The Center Party gained strength and became an ally of Bismarck, especially when he attacked socialism.\nHistorians have cited the campaign against the Catholic church, as well as a similar campaign against the Social Democratic Party, as leaving a lasting influence on the German consciousness, whereby national unity can be encouraged by excluding or persecuting a minority. This strategy, later referred to as \"negative integration\", set a tone of either being loyal to the government or an enemy of the state, which directly influenced German nationalist sentiment and the later Nazi movement.\nForeign policies and relations.\nChancellor Bismarck's imperial foreign policy basically aimed at security and the prevention of a Franco-Russian alliance, in order to avoid a likely Two-front war. The League of Three Emperors was signed in 1873 by Russia, Austria, and Germany. It stated that republicanism and socialism were common enemies and that the three powers would discuss any matters concerning foreign policy. Bismarck needed good relations with Russia in order to keep France isolated. Russia fought a victorious war against the Ottoman Empire from 1877 to 1878 and attempted to establish the Principality of Bulgaria, that was strongly opposed by France and Britain in particular, as they were long concerned with the preservation of the Ottoman Empire and Russian containment at the Bosphorus Strait and the Black Sea. Germany hosted the Congress of Berlin in 1878, where a more moderate peace settlement was agreed upon.\nIn 1879, Germany formed the Dual Alliance with Austria-Hungary, an agreement of mutual military assistance in the case of an attack from Russia, which was not satisfied with the agreement of the Congress of Berlin. The establishment of the Dual Alliance led Russia to take a more conciliatory stance and in 1887, the so-called Reinsurance Treaty was signed between Germany and Russia. In it, the two powers agreed on mutual military support in the case that France attacked Germany or an Austrian attack on Russia. Russia turned its attention eastward to Asia and remained largely inactive in European politics for the next 25 years. In 1882, Italy, seeking supporters for its interests in North Africa against France's colonial policy, joined the Dual Alliance, which became the Triple Alliance. In return for German and Austrian support, Italy committed itself to assisting Germany in the case of a French attack.\nBismarck had always argued that the acquisition of overseas colonies was impractical and the burden of administration and maintenance would outweigh the benefits. Eventually, Bismarck gave way, and a number of colonies were established in Africa (Togo, the Cameroons, German South-West Africa, and German East Africa) and in Oceania (German New Guinea, the Bismarck Archipelago, and the Marshall Islands). Consequently, Bismarck initiated the Berlin Conference of 1885, a formal meeting of the European colonial powers, who sought to \"established international guidelines for the acquisition of African territory\" (see Colonisation of Africa). Its outcome, the \"General Act of the Berlin Conference\", can be seen as the formalisation of the \"Scramble for Africa\" and \"New Imperialism\".\nWilhelminian Era (1888\u20131918).\nWilhelm II.\nEmperor William I died in 1888. His son Frederick III, open for a more liberal political course, reigned only for ninety-nine days, as he was stricken with throat cancer and died three months after his coronation. His son Wilhelm II followed him on the throne at the age of 29. Wilhelm rejected the liberal ideas of his parents and embarked on a conservative autocratic rule. He early on decided to replace the political elite and in March 1890 he forced chancellor Bismarck into retirement. Following his principle of \"Personal Regiment\", Wilhelm was determined to exercise maximum influence on all government affairs.\nAlliances and diplomacy.\nThe young Kaiser Wilhelm set out to apply his imperialist ideas of \"Weltpolitik\" (, \"world politics\"), as he envisaged a gratuitously aggressive political course to increase the empire's influence in and control over the world. After the removal of Bismarck, foreign policies were tackled with by the Kaiser and the Federal Foreign Office under Friedrich von Holstein. Wilhelm's increasingly erratic and reckless conduct was unmistakably related to character deficits and the lack of diplomatic skills. The foreign office's rather sketchy assessment of the current situation and its recommendations for the empire's most suitable course of action were:\nFirst a long-term coalition between France and Russia had to fall apart, secondly, Russia and Britain would never get together, and finally, Britain would eventually seek an alliance with Russia.\nSubsequently, Wilhelm refused to renew the Reinsurance Treaty with Russia. Russia promptly formed a closer relationship with France in the Dual Alliance of 1894, as both countries were concerned about the novel disagreeability of Germany. Furthermore, Anglo\u2013German relations provided, from a British point of view, no basis for any consensus as the Kaiser refused to divert from his, although somewhat peculiarly desperate and anachronistic, aggressive imperial engagement and the naval arms race in particular. Holstein's analysis proved to be mistaken on every point and Wilhelm failed too, as he did not adopt a nuanced political dialogue. Germany was left gradually isolated and dependent on the Triple Alliance, with Austria-Hungary and Italy. This agreement was hampered by differences between Austria and Italy and in 1915 Italy left the alliance.\nIn 1897, Admiral Alfred von Tirpitz, state secretary of the German Imperial Naval Office devised his initially rather practical, yet nonetheless ambitious plan to build a sizeable naval force. Although basically posing only an indirect threat as a Fleet in being, Tirpitz theorized, that its mere existence would force Great Britain, dependent on unrestricted movement on the seas, to agree to diplomatic compromises. Tirpitz started the program of warship construction in 1898 and enjoyed the full support of Kaiser Wilhelm. Wilhelm entertained less rational ideas on the fleet, that circled around his romantic childhood dream to have a \"fleet of [his] own some day\" and his obsessive adherence to direct his policies along the line of Alfred Thayer Mahan's work The Influence of Sea Power upon History. In exchange for the eastern African island of Zanzibar, Germany had bargained the island of Heligoland in the German Bight with Britain in 1890, and converted the island into a naval base and installed immense coastal defense batteries. Britain considered the imperial German endeavours to be a dangerous infringement on the century-old delicate balance of global affairs and trade on the seas under British control. The British, however, resolved to keep up the naval arms race and introduced the highly advanced new \"Dreadnought\" battleship concept in 1907. Germany quickly adopted the concept and by 1910 the arms race again escalated.\nIn the First Moroccan Crisis of 1905, Germany nearly clashed with Britain and France when the latter attempted to establish a protectorate over Morocco. Kaiser Wilhelm II was upset at having not been informed about French intentions, and declared their support for Moroccan independence. William II made a highly provocative speech regarding this. The following year, a conference was held in which all of the European powers except Austria-Hungary (by now little more than a German satellite) sided with France. A compromise was brokered by the United States where the French relinquished some, but not all, control over Morocco.\nThe Second Moroccan Crisis of 1911 saw another dispute over Morocco erupt when France tried to suppress a revolt there. Germany, still smarting from the previous quarrel, agreed to a settlement whereby the French ceded some territory in central Africa in exchange for Germany's renouncing any right to intervene in Moroccan affairs. This confirmed French control over Morocco, which became a full protectorate of that country in 1912.\nEconomy.\nBy 1890, the economy continued to industrialize and grow on an even higher rate than during the previous two decades and increased dramatically in the years leading up to World War I. Growth rates for the individual branches and sectors often varied considerably, and periodical figures provided by the \"Kaiserliches Statistisches Amt\" (\"Imperial Statistical Bureau) are often disputed or just assessments. Classification and naming of internationally traded commodities and exported goods was still in progress and the structure of production and export had changed during four decades. Published documents provide numbers such as: The proportion of goods manufactured by the modern industry was approximately 25% in 1900, while the proportion of consumer related products in manufactured exports stood at 40%. Reasonably exact are the figures for the entire industrial production between 1870 and 1914, which increased about 500%.\nHistorian J. A. Perkins argued that more important than Bismarck's new tariff on imported grain was the introduction of the sugar beet as a main crop. Farmers quickly abandoned traditional, inefficient practices in favor of modern methods, including the use of artificial fertilizers and mechanical tools. Intensive methodical farming of sugar and other root crops made Germany the most efficient agricultural producer in Europe by 1914. Even so, farms were usually small in size and women did much of the field work. An unintended consequence was the increased dependence on migratory, especially foreign, labor.\nThe basics of the modern chemical research laboratory layout and the introduction of essential equipment and instruments such as Bunsen burners, the Petri dish, the Erlenmeyer flask, task-oriented working principles and team research originated in 19th-century Germany and France. The organisation of knowledge acquisition was further refined by laboratory integration in research institutes of the universities and the industries. Germany acquired the leading role in the world's chemical industry by the late 19th century through strictly organized methodology. In 1913, the German chemical industry produced almost 90 per cent of the global supply of dyestuffs and sold about 80 per cent of its production abroad.\nGermany became Europe's leading steel-producing nation in the 1890s, thanks in large part to the protection from American and British competition afforded by tariffs and cartels. The leading firm was \"Friedrich Krupp AG Hoesch-Krupp\", run by the Krupp family. The merger of several major firms into the \"Vereinigte Stahlwerke\" (United Steel Works) in 1926 was modeled on the U.S. Steel corporation in the United States. The new company emphasized rationalization of management structures and modernization of the technology; it employed a multi-divisional structure and used return on investment as its measure of success. By 1913, American and German exports dominated the world steel market, as Britain slipped to third place.\nIn machinery, iron and steel, and other industries, German firms avoided cut-throat competition and instead relied on trade associations. Germany was a world leader because of its prevailing \"corporatist mentality\", its strong bureaucratic tradition, and the encouragement of the government. These associations regulate competition and allowed small firms to function in the shadow of much larger companies.\nColonies.\nBy the 1890s, German colonial expansion in Asia and the Pacific (Kiauchau in China, the Marianas, the Caroline Islands, Samoa) led to frictions with Britain, Russia, Japan and the United States. The construction of the Baghdad Railway, financed by German banks, was designed to eventually connect Germany with the Turkish Empire and the Persian Gulf, but it also collided with British and Russian geopolitical interests.\nThe largest colonial enterprises were in Africa. The harsh treatment of the Nama and Herero in what is now Namibia in Africa in 1906\u20131907 led to charges of genocide against the Germans. Historians are examining the links and precedents between the Herero and Nama genocide and the Holocaust of the 1940s.\nOther claimed territories of the German Colonial Empire are: Bear Island (occupied in 1899), Togo-Hinterlands, German Somali Coast, Katanga Territories, Pondoland (failed attempt by Emil Nagel), Nyassaland (Mozambique), Southwestern Madagascar, Santa Lucia Bay (South Africa) (failed attempt in 1884), and the Farasan Islands.\nWorld War I.\nCauses.\nEthnic demands for nation states upset the balance between the empires that dominated Europe, leading to World War I, which started in August 1914. Germany stood behind its ally Austria in a confrontation with Serbia, but Serbia was under the protection of Russia, which was allied to France. Germany was the leader of the Central Powers, which included Austria-Hungary, the Ottoman Empire, and later Bulgaria; arrayed against them were the Allies, consisting chiefly of Russia, France, Britain, and in 1915 Italy.\nIn explaining why neutral Britain went to war with Germany, author Paul M. Kennedy recognized it was critical for war that Germany become economically more powerful than Britain, but he downplays the disputes over economic trade imperialism, the Baghdad Railway, confrontations in Central and Eastern Europe, high-charged political rhetoric and domestic pressure-groups. Germany's reliance time and again on sheer power, while Britain increasingly appealed to moral sensibilities, played a role, especially in seeing the invasion of Belgium as a necessary military tactic or a profound moral crime. The German invasion of Belgium was not important because the British decision had already been made and the British were more concerned with the fate of France. Kennedy argues that by far the main reason was London's fear that a repeat of 1870\u00a0\u2013 when Prussia and the German states smashed France\u00a0\u2013 would mean that Germany, with a powerful army and navy, would control the English Channel and northwest France. British policy makers insisted that would be a catastrophe for British security.\nWestern Front.\nIn the west, Germany sought a quick victory by encircling Paris using the Schlieffen Plan. This plan failed due to unexpectedly strong Belgian resistance, Berlin's diversion of troops, and very stiff French resistance during the First Battle of the Marne, north of Paris. The Western Front became an extremely bloody battleground of trench warfare. The stalemate lasted from 1914 until early 1918, with ferocious battles that moved forces a few hundred yards at best for thousands of casualties along a line that stretched from the North Sea to the Swiss border. The British imposed a tight naval blockade in the North Sea which lasted until 1919, sharply reducing Germany's overseas access to raw materials and foodstuffs. Food scarcity became a serious problem by 1917. The United States joined with the Allies in April 1917. The entry of the United States into the war \u2013 following Germany's declaration of unrestricted submarine warfare \u2013 marked a decisive turning-point against Germany.\nTotal casualties on the Western Front were 3,528,610 killed and 7,745,920 wounded.\nEastern Front.\nMore wide open was the fighting on the Eastern Front. In the east, Germany managed to score decisive victories against the Russian army, including the trapping and destruction of large parts of the Russian 2nd army at the Battle of Tannenberg, followed by huge Austrian and German successes. Although the Russians enjoyed some success during the Brusilov offensive, capturing significant amounts of Austro-Hungarian territory, the eventual breakdown of Russian forces \u2013 exacerbated by internal turmoil caused by the 1917 Russian Revolution \u2013 led to the Treaty of Brest-Litovsk the Bolsheviks were forced to sign on 3 March 1918 as Russia withdrew from the war. It gave Germany control of Eastern Europe. Spencer Tucker says, \"The German General Staff had formulated extraordinarily harsh terms that shocked even the German negotiator.\" When Germany later complained that the Treaty of Versailles of 1919 was too harsh on them, the Allies responded that it was more benign than Brest-Litovsk.\n1918.\nBy defeating Russia in 1917, Germany was able to transfer hundreds of thousands of combat troops from the east to the Western Front, giving it a numerical advantage over the Allies. By retraining the soldiers in new storm-trooper tactics, the Germans hoped to break the stalemate on the Battlefield and win a decisive victory before the American army could arrive in force. However, the spring offensives all failed, as the Allies fell back and regrouped, and the Germans lacked the reserves necessary to consolidate their gains. In the summer, with the Americans arriving at 10,000 a day, and the German reserves exhausted, it was only a matter of time before multiple Allied offenses destroyed the German army.\nHomefront.\nAlthough war was not expected in 1914, Germany rapidly mobilized its civilian economy for the war effort, the economy was handicapped by the British blockade that cut off food supplies.\nSteadily conditions deteriorated rapidly on the home front, with severe food shortages reported in all urban areas. Causes involved the transfer of many farmers and food workers into the military, an overburdened railroad system, shortages of coal, and especially the British blockade that cut off imports from abroad. The winter of 1916\u20131917 was known as the \"turnip winter\", because that vegetable, usually fed to livestock, was used by people as a substitute for potatoes and meat, which were increasingly scarce. Thousands of soup kitchens were opened to feed the hungry people, who grumbled that the farmers were keeping the food for themselves. Even the army had to cut the rations for soldiers. Morale of both civilians and soldiers continued to sink. According to historian William H. McNeill:\nBy 1917, after three years of war, the various groups and bureaucratic hierarchies which had been operating more or less independently of one another in peacetime (and not infrequently had worked at cross purposes) were subordinated to one (and perhaps the most effective) of their number: the General Staff. Military officers controlled civilian government officials, the staffs of banks, cartels, firms, and factories, engineers and scientists, workingmen, farmers-indeed almost every element in German society; and all efforts were directed in theory and in large degree also in practice to forwarding the war effort.\n1918 was the year of the deadly 1918 Spanish Flu pandemic which struck hard at a population weakened by years of malnutrition.\nRevolution 1918\u20131919.\nIn October 1918, General Ludendorff, who wanted to protect the reputation of the Imperial Army by placing responsibility for the capitulation on the democratic parties and the Imperial Reichstag, pushed for the government to be democratised. A new chancellor was appointed, members of the Reichstag's majority parties were brought into the cabinet for the first time and the constitution modified. The moves did not, however, satisfy either the Allies or the majority of German citizens.\nThe German revolution of 1918\u20131919 began on 3 November with a sailor's mutiny at Kiel which spread rapidly and all but bloodlessly across Germany. Within a week, workers' and soldiers' councils were in control of government and military institutions across most of the Reich. On 9 November, Germany was declared a republic. The following day, the Council of the People's Deputies, formed from members of Germany's two main socialist parties, began acting as the provisional government. By the end of the month, all of Germany's ruling monarchs, including Emperor Wilhelm II, who had fled to exile in the Netherlands, had been forced to abdicate.\nIn early January 1919, the Spartacist uprising led by the newly founded Communist Party of Germany attempted to take power in Berlin, but it was quashed by government and Freikorps troops. Into the spring there were additional violently suppressed efforts to push the revolution further in the direction of a council republic, such as the short-lived local soviet republics, notably in Bavaria (Munich). They too were put down with considerable loss of life.\nThe revolution's end is generally set at 11 August 1919, the day the Weimar Constitution was signed following its adoption by the popularly elected Weimar National Assembly, Even though the widespread violence largely ended in 1919, the revolution remained in many ways incomplete. A large number of its opponents had been left in positions of power in the military and the Reich administration, and it failed to resolve the fracture in the Left between moderate socialists and communists. The Weimar Republic as a result was beset from the beginning by opponents from both the Left and \u2013 to a greater degree \u2013 the Right.\nWeimar Republic, 1918\u20131933.\nOverview.\nUnder the peace terms of the Treaty of Versailles, Germany's first democracy began its fourteen-year life facing territorial losses, reparations to the victors of World War I and stringent limitations on its military. Political violence from those on the Right who wanted a return to the monarchy and those on the Left who wanted a soviet-style regime repeatedly threatened the moderate socialist government through 1923. Ongoing issues with state finances, impacted by war debt and the funding of striking workers in the Ruhr, fuelled the hyperinflation of 1923 that impoverished many Germans and left them bitter enemies of the Republic. A period of relative political and economic stability that lasted until the onset of the Great Depression in 1929 was followed by the rapid growth of parties on the extremes \u2013 the Communists on the Left and the Nazis on the Right \u2013 that left the Reichstag (parliament) all but unable to function. In quick succession, four chancellors tried and failed to govern by decree before President Hindenburg named Adolf Hitler chancellor in 1933. In only a few months he had turned the Republic into a Nazi dictatorship.\nTreaty of Versailles.\nThe Armistice of 11 November 1918 ended the fighting in World War I, and on 28 June 1919 Germany reluctantly signed the peace terms laid out in the Treaty of Versailles. Germany had to renounce sovereignty over its colonies and in Europe lost 65,000\u00a0km2 (25,000 sq mi) or about 13% of its former territory \u2013 including 48% of its iron and 10% of its coal resources \u2013 along with 7 million people, or 12% of its population. Allied troops occupied the Rhineland, and it along with an area stretching 50 kilometres east of the Rhine were demilitarized. The German army was limited to no more than 100,000 men with 4,000 officers and no general staff; the navy could have at most 15,000 men and 1,500 officers. Germany was prohibited from having an air force, submarines or dreadnoughts. A large number of its ships and all of its air-related armaments were to be surrendered. The most contentious article of the treaty, the so-called War Guilt Clause (Article 231), stated that Germany accepted responsibility for the loss and damage from the war caused to the Allies, and therefore had to pay reparations for the damage caused to the Allied Powers.\nThe treaty was reviled as a dictated rather than a negotiated peace. Philipp Scheidemann, the Social Democratic minister president of Germany, said to the Weimar National Assembly on 12 May 1919, \"What hand should not wither that puts this fetter on itself and on us?\"\nThe early years.\nThe Weimar Constitution established a federal semi-presidential republic with a chancellor dependent on the confidence of the Reichstag (parliament), a strong president who had considerable powers to govern by decree, and a substantial set of individual rights. The Social Democrat Friedrich Ebert was the Republic's first president.\nThe Left accused the Social Democrats of betraying the ideals of the labour movement because of their alliance with the old elites in the military and administration, and the Right held the supporters of the Republic responsible for Germany's defeat in the war. In early 1920, the right-wing Kapp Putsch, backed by units of the paramilitary Freikorps, briefly took control of the government in Berlin, but the putsch quickly collapsed due to a general strike and passive resistance by civil servants. In the putsch's wake, workers in the industrial Ruhr district, where dissatisfaction with the lack of nationalisation of key industries was particularly high, rose up and attempted to take control of the region. Reichswehr and Freikorps units suppressed the Ruhr uprising with the loss of over 1,000 lives. The unstable political conditions of the period were reflected in the Reichstag election of 1920, in which the centre-left Weimar Coalition, which until then had held a three-quarters majority, lost 125 seats to parties on both the Left and Right.\nPolitical violence continued at a high level through 1923. A right-wing extremist group assassinated former finance minister Matthias Erzberger in August 1921 and Walther Rathenau, the Jewish foreign minister, in June 1922. 1923 saw the communist-led takeover attempt known as the German October, the right-wing K\u00fcstrin Putsch and Adolf Hitler's Beer Hall Putsch.\nGermany was the first state to establish diplomatic relations with the new Soviet Union in the 1922 Treaty of Rapallo. In October 1925, Germany, France, Belgium, Britain and Italy signed the Treaty of Locarno, which recognised Germany's borders with France and Belgium but left its eastern borders open to negotiations. The treaty paved the way for Germany's admission to the League of Nations in 1926.\nIn May 1921 the Allied Powers set Germany's reparations liability under the terms of the Treaty of Versailles at 132 billion Reichsmarks, to be paid either in gold or commodities such as iron, steel and coal. After a series of German defaults, French and Belgian troops occupied the Ruhr in January 1923. The German government responded with a policy of passive resistance. It underwrote the costs of idled factories and mines and paid the workers who were on strike. Unable to meet the enormous costs by any other means, it resorted to printing money. Along with the debts the state had incurred during the war, it was one of the major causes of the 1923 peak in Germany's post-war hyperinflation. The passive resistance was called off in September 1923, and the occupation ended in August 1925, following an agreement (the Dawes Plan) to restructure Germany's reparations. In November 1923 the government introduced a new currency, the Rentenmark (later the Reichsmark). Together with other measures, it quickly stopped the hyperinflation, but many Germans who lost their life savings became bitter enemies of the Weimar Republic and supporters of the anti-democratic Right. During the following six years the economic situation improved. In 1928 Germany's industrial production surpassed the pre-war level of 1913.\nIn 1925, following the death in office of President Ebert, conservative Field Marshal Paul von Hindenburg was elected to replace him. His presidency, coming after a campaign that emphasised nationalism and Hindenburg's ties to the fallen German Empire, was the beginning of a significant shift to the right in German politics.\nEconomic collapse and end of the Republic, 1929\u20131933.\nThe Wall Street crash of 1929 marked the beginning of the worldwide Great Depression, which hit Germany as hard as any nation. In 1931 several major banks failed, and by early 1932 the number of unemployed had soared to more than six million. In the Reichstag election of September 1930, the Communist Party of Germany (KPD) gained 23 seats, while the National Socialist German Workers' Party (NSDAP, Nazi Party), until then a minor far-right party, increased its share by 95 seats, becoming Germany's second largest party behind the Social Democrats. The Nazis were particularly successful among Protestants, unemployed young voters, the lower middle class in the cities and the rural population. It was weakest in Catholic areas and in large cities. The shift to the political extremes made the unstable coalition system by which every Weimar chancellor had governed increasingly unworkable. The last years of the Weimar Republic were marred by even more systemic political instability than previous years, and political violence increased. Four chancellors (Heinrich Br\u00fcning, Franz von Papen, Kurt von Schleicher and, from 30 January to 23 March 1933, Adolf Hitler) governed through presidential decree rather than parliamentary consultation. It effectively rendered the Reichstag powerless as a means of enforcing constitutional checks and balances.\nHindenburg was re-elected president in 1932, out-polling Hitler by almost 6 million votes in the second round. The Nazi Party became the largest party in the Reichstag following the election of July 1932. It received 37% of the vote, with the SPD second (22%) and the Communist KPD third at 14%. The Nazis dropped to 33% after another election four months later, but they remained the largest party. The splintered Reichstag was still unable to form a stable coalition. On 30 January 1933, seeing no other viable option and pressured by former chancellor Franz von Papen and other conservatives, President Hindenburg appointed Hitler chancellor.\nScience and culture in 19th and 20th century.\nThe Weimar years saw a flowering of German science and high culture, before the Nazi regime resulted in a decline in the scientific and cultural life in Germany and forced many renowned scientists and writers to flee.\nGerman recipients dominated the Nobel prizes in science. Germany dominated the world of physics before 1933, led by Hermann von Helmholtz, Wilhelm Conrad R\u00f6ntgen, Albert Einstein, Otto Hahn, Max Planck and Werner Heisenberg. Chemistry likewise was dominated by German professors and researchers at the great chemical companies such as BASF and Bayer and persons like Justus von Liebig, Fritz Haber and Emil Fischer. Theoretical mathematicians Georg Cantor in the 19th century and David Hilbert in the 20th century. Karl Benz, the inventor of the automobile, and Rudolf Diesel were pivotal figures of engineering, and Wernher von Braun, rocket engineer. Ferdinand Cohn, Robert Koch and Rudolph Virchow were three key figures in microbiology.\nAmong the most important German writers were Thomas Mann, Hermann Hesse and Bertolt Brecht. The reactionary historian Oswald Spengler wrote \"The Decline of the West\" (1918\u20131923) on the inevitable decay of Western Civilization, and influenced intellectuals in Germany such as Martin Heidegger, Max Scheler, and the Frankfurt School, as well as intellectuals around the world.\nAfter 1933, Nazi proponents of \"Aryan physics\", led by the Nobel Prize-winners Johannes Stark and Philipp Lenard, attacked Einstein's theory of relativity as a degenerate example of Jewish materialism in the realm of science. Many scientists and humanists emigrated; Einstein moved permanently to the U.S. but some of the others returned after 1945.\nNazi Germany, 1933\u20131945.\nThe Nazi regime suppressed labor unions and strikes, leading to prosperity which gave the Nazi Party popularity, with only minor, isolated and subsequently unsuccessful cases of resistance among the German population over their rule. The Gestapo (secret police) destroyed the political opposition and persecuted the Jews, trying to force them into exile. The Party took control of the courts, local government, and all civic organizations except the Christian churches. All expressions of public opinion were controlled by the propaganda ministry, which used film, mass rallies, and Hitler's hypnotic speaking. The Nazi state idolized Hitler as its F\u00fchrer (leader), putting all powers in his hands. Nazi propaganda centered on Hitler and created the \"Hitler Myth\"\u2014that Hitler was all-wise and that any mistakes or failures by others would be corrected when brought to his attention. In fact Hitler had a narrow range of interests and decision making was diffused among overlapping, feuding power centers; on some issues he was passive, simply assenting to pressures from whoever had his ear. All top officials reported to Hitler and followed his basic policies, but they had considerable autonomy on a daily basis.\nEstablishment of the Nazi regime.\nTo secure a \"Reichstag\" majority for his party, Hitler called for new elections. After the 27 February 1933 Reichstag fire, Hitler swiftly blamed an alleged Communist uprising, and convinced President Hindenburg to approve the Reichstag Fire Decree, rescinding civil liberties. Four thousand communists were arrested and Communist agitation was banned. Communists and Socialists were brought into hastily prepared Nazi concentration camps, where they were at the mercy of the Gestapo, the newly established secret police force. Communist \"Reichstag\" deputies were taken into \"protective custody\".\nDespite the terror and unprecedented propaganda, the last free General Elections of 5 March 1933, while resulting in 43.9% failed to give the Nazis their desired majority. Together with the German National People's Party (DNVP), however, he was able to form a slim majority government. On 23 March 1933, the Enabling Act marked the beginning of Nazi Germany, allowing Hitler and his cabinet to enact laws on their own without the President or the Reichstag. The Enabling Act formed the basis for the dictatorship and the dissolution of the L\u00e4nder. Trade unions and all political parties other than the Nazi Party were suppressed. A centralised totalitarian state was established, no longer based on the liberal Weimar constitution. Germany withdrew from the League of Nations shortly thereafter. The coalition parliament was rigged by defining the absence of arrested and murdered deputies as voluntary and therefore cause for their exclusion as wilful absentees. The Centre Party was voluntarily dissolved in a \"quid pro quo\" with the Pope under the \"anti-communist\" Pope Pius XI for the \"Reichskonkordat\"; and by these manoeuvres Hitler achieved movement of these Catholic voters into the Nazi Party, and a long-awaited international diplomatic acceptance of his regime. The Nazis gained a larger share of their vote in Protestant areas than in Catholic areas. The Communist Party was proscribed in April 1933.\nHitler used the SS and Gestapo to purge the entire SA leadership\u2014along with a number of Hitler's political adversaries in the Night of the Long Knives from 30 June to 2 July 1934. As a reward, the SS became an independent organisation under the command of the \"Reichsf\u00fchrer-SS\" Heinrich Himmler. Upon Hindenburg's death on 2 August 1934, Hitler's cabinet passed a law proclaiming the presidency to be vacant and transferred the role and powers of the head of state to Hitler.\nAntisemitism and the Holocaust.\nThe Nazi regime was particularly hostile towards Jews, who became the target of unending antisemitic propaganda attacks. The Nazis attempted to convince the German people to view and treat Jews as \"subhumans\" and immediately after the 1933 federal elections the Nazis imposed a nationwide boycott of Jewish businesses. In March 1933 the first Nazi concentration camp was established at Dachau and from 1933 to 1935 the Nazi regime consolidated their power. The Law for the Restoration of the Professional Civil Service forced all Jewish civil servants to retire from the legal profession and the civil service. The Nuremberg Laws banned sexual relations between Jews and Germans and only those of German or related blood were eligible to be considered citizens; the remainder were classed as state subjects, without citizenship rights. This stripped Jews, Romani and others of their legal rights. Jews continued to suffer persecution under the Nazi regime, exemplified by the Kristallnacht pogrom of 1938, and about half of Germany's 500,000 Jews fled the country before 1939, after which escape became almost impossible.\nIn 1941, the Nazi leadership decided to implement a plan that they called the \"Final Solution\" which came to be known as the Holocaust. Under the plan, Jews and other \"lesser races\" along with political opponents from Germany as well as occupied countries were systematically murdered at murder sites, and starting in 1942, at extermination camps. Between 1941 and 1945 Jews, Gypsies, Slavs, communists, homosexuals, the mentally and physically disabled and members of other groups were targeted and methodically murdered \u2013 the origin of the word \"genocide\". In total approximately 11 million people were killed during the Holocaust.\nMilitary.\nIn 1935, Hitler officially re-established the Luftwaffe (air force) and reintroduced universal military service, in breach of the Treaty of Versailles; Britain, France and Italy formally protested. Hitler had the officers swear their personal allegiance to him. In 1936, German troops marched into the demilitarised Rhineland. As the territory was part of Germany, the British and French governments did not feel that attempting to enforce the treaty was worth the risk of war. The move strengthened Hitler's standing in Germany. His reputation swelled further with the 1936 Summer Olympics in Berlin, and proved another great propaganda success for the regime as orchestrated by master propagandist Joseph Goebbels.\nForeign policy.\nHitler's diplomatic strategy in the 1930s was to make seemingly reasonable demands, threatening war if they were not met. When opponents tried to appease him, he accepted the gains that were offered, then went to the next target. That aggressive strategy worked as Germany pulled out of the League of Nations, rejected the Versailles Treaty and began to re-arm, won back the Saar, remilitarized the Rhineland, formed an alliance with Mussolini's Italy, sent massive military aid to Franco in the Spanish Civil War, annexed Austria, took over Czechoslovakia after the British and French \"appeasement\" of the Munich Agreement, formed a peace pact with Joseph Stalin's Soviet Union, and finally invaded Poland. Britain and France declared war on Germany and World War II in Europe began.\nHaving established a \"Rome-Berlin axis\" with Benito Mussolini, and signing the Anti-Comintern Pact with Japan\u00a0\u2013 which was joined by Italy a year later in 1937\u00a0\u2013 Hitler felt able to take the offensive in foreign policy. On 12 March 1938, German troops marched into Austria, where an attempted Nazi coup had been unsuccessful in 1934. When Austrian-born Hitler entered Vienna, he was greeted by loud cheers and Austrians voted in favour of the annexation of their country. After Austria, Hitler turned to Czechoslovakia, where the Sudeten German minority was demanding equal rights and self-government. At the Munich Conference of September 1938, Hitler, Mussolini, British Prime Minister Neville Chamberlain and French Prime Minister \u00c9douard Daladier agreed upon the cession of Sudeten territory to the German Reich by Czechoslovakia. Hitler thereupon declared that all of German Reich's territorial claims had been fulfilled. However, hardly six months after the Munich Agreement Hitler used the smoldering quarrel between Slovaks and Czechs as a pretext for taking over the rest of Czechoslovakia. He then secured the return of Memel from Lithuania to Germany. Chamberlain was forced to acknowledge that his policy of appeasement towards Hitler had failed.\nWorld War II.\nAt first Germany was successful in its military operations. In less than three months (April \u2013 June 1940), Germany conquered Denmark, Norway, the Low Countries, and France. The unexpectedly swift defeat of France resulted in an upswing in Hitler's popularity and an upsurge in war fever. Hitler made peace overtures to the new British leader Winston Churchill in July 1940, but Churchill remained dogged in his defiance with major help from US president Franklin D. Roosevelt. Hitler's bombing campaign against Britain (September 1940 \u2013 May 1941) failed. Some 43,000 British civilians were killed and 139,000 wounded in the Blitz; much of London was destroyed. Germany's armed forces invaded the Soviet Union in June 1941 swept forward until they reached the gates of Moscow. The Einsatzgruppen (Nazi mobile death squads) executed all Soviet Jews that it located, while the Germans went to Jewish households and forced the families into concentration camps for labor or to extermination camps for death.\nThe tide began to turn in December 1941, when the invasion of the Soviet Union hit determined resistance in the Battle of Moscow and Hitler declared war on the United States in the wake of the Japanese Pearl Harbor attack. After surrender in North Africa and losing the Battle of Stalingrad in 1942\u20131943, the Germans were forced into the defensive. By late 1944, the United States, Canada, France, and Great Britain were closing in on Germany in the West, while the Soviets were victoriously advancing in the East.\nIn 1944\u20131945, Soviet forces completely or partially liberated Romania, Bulgaria, Hungary, Yugoslavia, Poland, Czechoslovakia, Austria, Denmark, and Norway. Nazi Germany collapsed as Berlin was taken by the Soviet Union's Red Army in a fight to the death on the city streets. 2,000,000 Soviet troops took part in the assault, and they faced 750,000 German troops. 78,000\u2013305,000 Soviets were killed, while 325,000 German civilians and soldiers were killed. Hitler committed suicide on 30 April 1945. The final German Instrument of Surrender was signed on 8 May 1945, marking the end of Nazi Germany.\nBy September 1945, Nazi Germany and its Axis partners (mainly Italy and Japan) had all been defeated, chiefly by the forces of the Soviet Union, the United States, and Britain. Much of Europe lay in ruins, over 60 million people worldwide had been killed (most of them civilians), including approximately 6 million Jews and 11 million non-Jews in what became known as the Holocaust. World War II destroyed Germany's political and economic infrastructure, caused its partition, considerable loss of territory (especially in the East), and historical legacy of guilt and shame.\nGermany during the Cold War, 1945\u20131990.\nAs a consequence of the defeat of Nazi Germany in 1945 and the onset of the Cold War in 1947, the country's territory was shrunk and split between the two global blocs in the East and West, a period known as the division of Germany. Millions of refugees from Central and Eastern Europe moved west, most of them to West Germany. Two countries emerged: West Germany was a parliamentary democracy, a NATO member, a founding member of what since became the European Union as one of the world's largest economies and under allied military control until 1955, while East Germany was a totalitarian Communist dictatorship controlled by the Soviet Union as a satellite of Moscow. With the collapse of Communism in Europe in 1989, reunion followed.\nNo one doubted Germany's economic and engineering prowess; the question was how long bitter memories of the war would cause Europeans to distrust Germany, and whether Germany could demonstrate it had rejected totalitarianism and militarism and embraced democracy and human rights.\nExpulsion.\nAt the Potsdam Conference, Germany was divided into four military occupation zones by the Allies and did not regain independence until 1949. The provinces east of the Oder and Neisse rivers (the Oder-Neisse line) were transferred to Poland and Soviet Russia (Kaliningrad oblast) while Saarland separated from Germany to become a French protectorate on 17 December 1947 (joined West Germany on 1 January 1957), pending a final peace conference with Germany, which eventually never took place. Most of the remaining German population was expelled. Around 6.7 million Germans living in \"west-shifted\" Poland, mostly within previously German lands, and the 3 million in German-settled regions of Czechoslovakia were deported west.\nPost-war chaos.\nThe total of German war dead was 8% to 10% out of a prewar population of 69,000,000, or between 5.5 million and 7 million people. This included 4.5 million in the military, and between 1 and 2 million civilians. There was chaos as 11 million foreign workers and POWs left, while soldiers returned home and more than 14 million displaced German-speaking refugees from both the eastern provinces and East-Central and Eastern Europe were expelled from their native land and came to the western German lands, often foreign to them. During the Cold War, the West German government estimated a death toll of 2.2 million civilians due to the flight and expulsion of Germans and through forced labour in the Soviet Union. This figure remained unchallenged until the 1990s, when some historians put the death toll at 500,000\u2013600,000 confirmed deaths. In 2006, the German government reaffirmed its position that 2.0\u20132.5 million deaths occurred.\nDenazification removed, imprisoned, or executed most top officials of the old regime, but most middle and lower ranks of civilian officialdom were not seriously affected. In accordance with the Allied agreement made at the Yalta Conference, millions of POWs were used as forced labor by the Soviet Union and other European countries.\nIn the East, the Soviets crushed dissent and imposed another police state, often employing ex-Nazis in the dreaded Stasi. The Soviets extracted about 23% of the East German GNP for reparations, while in the West reparations were a minor factor.\nIn 1945\u20131946 housing and food conditions were bad, as the disruption of transport, markets, and finances slowed a return to normal. In the West, bombing had destroyed the fourth of the housing stock, and over 10 million refugees from the east had crowded in, most living in camps. Food production in 1946\u20131948 was only two-thirds of the prewar level, while grain and meat shipments \u2013 which usually supplied 25% of the food \u2013 no longer arrived from the East. Furthermore, the end of the war brought the end of large shipments of food seized from occupied nations that had sustained Germany during the war. Coal production was down 60%, which had cascading negative effects on railroads, heavy industry, and heating. Industrial production fell more than half and reached prewar levels only at the end of 1949.\nAllied economic policy originally was one of industrial disarmament plus building the agricultural sector. In the western sectors, most of the industrial plants had minimal bomb damage and the Allies dismantled 5% of the industrial plants for reparations.\nHowever, deindustrialization became impractical and the U.S. instead called for a strong industrial base in Germany so it could stimulate European economic recovery. The U.S. shipped food in 1945\u20131947 and made a $600 million loan in 1947 to rebuild German industry. By May 1946 the removal of machinery had ended, thanks to lobbying by the U.S. Army. The Truman administration finally realised that economic recovery in Europe could not go forward without the reconstruction of the German industrial base on which it had previously been dependent. Washington decided that an \"orderly, prosperous Europe requires the economic contributions of a stable and productive Germany\".\nIn 1945, the occupying powers took over all newspapers in Germany and purged them of Nazi influence. The American occupation headquarters, the Office of Military Government, United States (OMGUS) began its own newspaper based in Munich, \"Die Neue Zeitung.\" It was edited by German and Jewish \u00e9migr\u00e9s who fled to the United States before the war. Its mission was to encourage democracy by exposing Germans to how American culture operated. The paper was filled with details on American sports, politics, business, Hollywood, and fashions, as well as international affairs.\nEast Germany.\nOn 7 October 1949, the Soviet zone became the \"Deutsche Demokratische Republik\" \u2013 \"DDR\" (\"German Democratic Republic\" \u2013 \"GDR\", simply often \"East Germany\"), under control of the Socialist Unity Party. Neither country had a significant army until the 1950s, but East Germany built the Stasi into a powerful secret police that infiltrated every aspect of its society.\nEast Germany was an Eastern bloc state under political and military control of the Soviet Union through her occupation forces and the Warsaw Treaty. Political power was solely executed by leading members (\"Politburo\") of the communist-controlled Socialist Unity Party (SED). A Soviet-style command economy was set up; later the GDR became the most advanced Comecon state. While East German propaganda was based on the benefits of the GDR's social programs and the alleged constant threat of a West German invasion, many of her citizens looked to the West for political freedoms and economic prosperity.\nWalter Ulbricht was the party boss from 1950 to 1971. In 1933, Ulbricht had fled to Moscow, where he served as a Comintern agent loyal to Stalin. As World War II was ending, Stalin assigned him the job of designing the postwar German system that would centralize all power in the Communist Party. Ulbricht became deputy prime minister in 1949 and secretary (chief executive) of the Socialist Unity (Communist) party in 1950. Some 2.6 million people had fled East Germany by 1961 when he built the Berlin Wall to stop them \u2013 shooting those who attempted it. What the GDR called the \"Anti-Fascist Protective Wall\" was a major embarrassment for the program during the Cold War, but it did stabilize East Germany and postpone its collapse. Ulbricht lost power in 1971, but was kept on as a nominal head of state. He was replaced because he failed to solve growing national crises, such as the worsening economy in 1969\u20131970, the fear of another popular uprising as had occurred in 1953, and the disgruntlement between Moscow and Berlin caused by Ulbricht's d\u00e9tente policies toward the West.\nThe transition to Erich Honecker (General Secretary from 1971 to 1989) led to a change in the direction of national policy and efforts by the Politburo to pay closer attention to the grievances of the proletariat. Honecker's plans were not successful, however, with the dissent growing among East Germany's population.\nIn 1989, the socialist regime collapsed after 40 years, despite its omnipresent secret police, the Stasi. The main reasons for its collapse included severe economic problems and growing emigration towards the West.\nEast Germany's culture was shaped by Communism and particularly Stalinism. It was characterized by East German psychoanalyst Hans-Joachim Maaz in 1990 as having produced a \"Congested Feeling\" among Germans in the East as a result of Communist policies criminalizing personal expression that deviates from government approved ideals, and through the enforcement of Communist principals by physical force and intellectual repression by government agencies, particularly the Stasi. Critics of the East German state have claimed that the state's commitment to communism was a hollow and cynical tool of a ruling elite. This argument has been challenged by some scholars who claim that the Party was committed to the advance of scientific knowledge, economic development, and social progress. However, the vast majority regarded the state's Communist ideals to be nothing more than a deceptive method for government control.\nAccording to German historian J\u00fcrgen Kocka (2010):\n\"Conceptualizing the GDR as a dictatorship has become widely accepted, while the meaning of the concept dictatorship varies. Massive evidence has been collected that proves the repressive, undemocratic, illiberal, nonpluralistic character of the GDR regime and its ruling party.\"\nWest Germany (Bonn Republic).\nOn 23 May 1949, the three western occupation zones (American, British, and French) were combined into the Federal Republic of Germany (FRG, West Germany). The government was formed under Chancellor Konrad Adenauer and his conservative CDU/CSU coalition. The CDU/CSU was in power during most of the period since 1949. The capital was Bonn until it was moved to Berlin in 1990. In 1990, FRG absorbed East Germany and gained full sovereignty over Berlin. At all points West Germany was much larger and richer than East Germany, which became a dictatorship under the control of the Communist Party and was closely monitored by Moscow. Germany, especially Berlin, was a cockpit of the Cold War, with NATO and the Warsaw Pact assembling major military forces in west and east. However, there was never any combat.\nEconomic miracle.\nWest Germany enjoyed prolonged economic growth beginning in the early 1950s (\"Wirtschaftswunder\" or \"Economic Miracle\"). Industrial production doubled from 1950 to 1957, and gross national product grew at a rate of 9 or 10% per year, providing the engine for economic growth of all of Western Europe. Labor unions supported the new policies with postponed wage increases, minimized strikes, support for technological modernization, and a policy of co-determination (\"Mitbestimmung\"), which involved a satisfactory grievance resolution system as well as requiring representation of workers on the boards of large corporations. The recovery was accelerated by the currency reform of June 1948, U.S. gifts of $1.4 billion as part of the Marshall Plan, the breaking down of old trade barriers and traditional practices, and the opening of the global market. West Germany gained legitimacy and respect, as it shed the horrible reputation Germany had gained under the Nazis.\nWest Germany played a central role in the creation of European cooperation; it joined NATO in 1955 and was a founding member of the European Economic Community in 1958.\n1948 currency reform.\nThe most dramatic and successful policy event was the currency reform of 1948. Since the 1930s, prices and wages had been controlled, but money had been plentiful. That meant that people had accumulated large paper assets, and that official prices and wages did not reflect reality, as the black market dominated the economy and more than half of all transactions were taking place unofficially. On 21 June 1948, the Western Allies withdrew the old currency and replaced it with the new Deutsche Mark at the rate of 1 new per 10 old. This wiped out 90% of government and private debt, as well as private savings. Prices were decontrolled, and labor unions agreed to accept a 15% wage increase, despite the 25% rise in prices. The result was that prices of German export products held steady, while profits and earnings from exports soared and were poured back into the economy. The currency reforms were simultaneous with the $1.4 billion in Marshall Plan money coming in from the United States, which was used primarily for investment.\nIn addition, the Marshall Plan forced German companies, as well as those in all of Western Europe, to modernize their business practices and take account of the international market. Marshall Plan funding helped overcome bottlenecks in the surging economy caused by remaining controls (which were removed in 1949), and Marshall Plan business reforms opened up a greatly expanded market for German exports. Overnight, consumer goods appeared in the stores, because they could be sold for realistic prices, emphasizing to Germans that their economy had turned a corner.\nThe success of the currency reform angered the Soviets, who cut off all road, rail, and canal links between the western zones and West Berlin. This was the Berlin Blockade, which lasted from 24 June 1948 to 12 May 1949. In response, the U.S. and Britain launched an airlift of food and coal and distributed the new currency in West Berlin as well. The city thereby became economically integrated into West Germany. Until the mid-1960s, it served as \"America's Berlin\", symbolizing the United States' commitment to defending its freedom, which John F. Kennedy underscored during his visit in June 1963.\nAdenauer.\nKonrad Adenauer was the dominant leader in West Germany. He was the first chancellor (top official) of the FRG and until his death was the founder and leader of the Christian Democratic Union (CDU), a coalition of conservatives, ordoliberals, and adherents of Protestant and Catholic social teaching that dominated West Germany politics for most of its history. During his chancellorship, the West Germany economy grew quickly, and West Germany established friendly relations with France, participated in the emerging European Union, established the country's armed forces (the \"Bundeswehr\"), and became a pillar of NATO as well as firm ally of the United States. Adenauer's government also commenced the long process of reconciliation with the Jews and Israel after the Holocaust.\nErhard.\nLudwig Erhard was in charge of economic policy as economics director for the British and American occupation zones and was Adenauer's long-time economics minister. Erhard's decision to lift many price controls in 1948 (despite opposition from both the social democratic opposition and Allied authorities), plus his advocacy of free markets, helped set the Federal Republic on its strong growth from wartime devastation. Norbert Walter, a former chief economist at Deutsche Bank, argues that \"Germany owes its rapid economic advance after World War II to the system of the Social Market Economy, established by Ludwig Erhard.\" Erhard was politically less successful when he served as the CDU Chancellor from 1963 until 1966. Erhard followed the concept of a social market economy, and was in close touch with professional economists. Erhard viewed the market itself as social and supported only a minimum of welfare legislation. However, Erhard suffered a series of decisive defeats in his effort to create a free, competitive economy in 1957; he had to compromise on such key issues as the anti-cartel legislation. Thereafter, the West German economy evolved into a conventional west European welfare state.\nMeanwhile, in adopting the Godesberg Program in 1959, the Social Democratic Party of Germany (SPD) largely abandoned Marxism ideas and embraced the concept of the market economy and the welfare state. Instead it now sought to move beyond its old working class base to appeal the full spectrum of potential voters, including the middle class and professionals. Labor unions cooperated increasingly with industry, achieving labor representation on corporate boards and increases in wages and benefits.\nGrand coalition.\nIn 1966, Erhard lost support and Kurt Kiesinger was elected as Chancellor by a new CDU/CSU-SPD alliance combining the two largest parties. Social democratic (SPD) leader Willy Brandt was Deputy Federal Chancellor and Foreign Minister. The 1966\u20131969 Grand Coalition reduced tensions with the Soviet bloc nations and establishing diplomatic relations with Czechoslovakia, Romania and Yugoslavia.\nGuest workers.\nWith a booming economy short of unskilled workers, especially after the Berlin Wall cut off the steady flow of East Germans, the FRG negotiated migration agreements with Italy (1955), Spain (1960), Greece (1960), and Turkey (1961) that brought in hundreds of thousands of temporary guest workers, called \"Gastarbeiter\". In 1968, the FRG signed a guest worker agreement with Yugoslavia that employed additional guest workers. \"Gastarbeiter\" were young men who were paid full-scale wages and benefits, but were expected to return home in a few years.\nThe agreement with Turkey ended in 1973 but few workers returned because there were few good jobs in Turkey. By 2010 there were about 4 million people of Turkish descent in Germany. The generation born in Germany attended German schools, but had a poor command of either German or Turkish, and had either low-skilled jobs or were unemployed.\nBrandt and Ostpolitik.\nWilly Brandt was the leader of the Social Democratic Party in 1964\u20131987 and West German Chancellor in 1969\u20131974. Under his leadership, the German government sought to reduce tensions with the Soviet Union and improve relations with the German Democratic Republic, a policy known as the \"Ostpolitik\". Relations between the two German states had been icy at best, with propaganda barrages in each direction. The heavy outflow of talent from East Germany prompted the building of the Berlin Wall in 1961, which worsened Cold War tensions and prevented East Germans from travel. Although anxious to relieve serious hardships for divided families and to reduce friction, Brandt's \"Ostpolitik\" was intent on holding to its concept of \"two German states in one German nation\".\n\"Ostpolitik\" was opposed by the conservative elements in Germany, but won Brandt an international reputation and the Nobel Peace Prize in 1971. In September 1973, both West and East Germany were admitted to the United Nations. The two countries exchanged permanent representatives in 1974, and, in 1987, East Germany's leader Erich Honecker paid an official state visit to West Germany.\nEconomic crisis of 1970s.\nAfter 1973, Germany was hard hit by a worldwide economic crisis, soaring oil prices, and stubbornly high unemployment, which jumped from 300,000 in 1973 to 1.1 million in 1975. The Ruhr region was hardest hit, as its easy-to-reach coal mines petered out, and expensive German coal was no longer competitive. Likewise the Ruhr steel industry went into sharp decline, as its prices were undercut by lower-cost suppliers such as Japan. The welfare system provided a safety net for the large number of unemployed workers, and many factories reduced their labor force and began to concentrate on high-profit specialty items. After 1990 the Ruhr moved into service industries and high technology. Cleaning up the heavy air and water pollution became a major industry in its own right. Meanwhile, formerly rural Bavaria became a high-tech center of industry.\nA spy scandal forced Brandt to step down as Chancellor while remaining as party leader. He was replaced by Helmut Schmidt (b. 1918), of the SPD, who served as Chancellor in 1974\u20131982. Schmidt continued the \"Ostpolitik\" with less enthusiasm. He had a PhD in economics and was more interested in domestic issues, such as reducing inflation. The debt grew rapidly as he borrowed to cover the cost of the ever more expensive welfare state. After 1979, foreign policy issues grew central as the Cold War turned hot again. The German peace movement mobilized hundreds of thousands of demonstrators to protest against American deployment in Europe of new medium-range ballistic missiles. Schmidt supported the deployment but was opposed by the left wing of the SPD and by Brandt.\nThe pro-business Free Democratic Party (FDP) had been in coalition with the SPD, but now it changed direction. Led by Finance Minister Otto Graf Lambsdorff the FDP adopted the market-oriented \"Kiel Theses\" in 1977; it rejected the Keynesian emphasis on consumer demand, and proposed to reduce social welfare spending, and try to introduce policies to stimulate production and facilitate jobs. Lambsdorff argued that the result would be economic growth, which would itself solve both the social problems and the financial problems. As a consequence, the FDP switched allegiance to the CDU and Schmidt lost his parliamentary majority in 1982. For the only time in West Germany's history, the government fell on a vote of no confidence.\nKohl.\nHelmut Kohl brought the conservatives back to power with a CDU/CSU-FDP coalition in 1982, and served as Chancellor until 1998. He orchestrated reunification with the approval of all the Four Powers from World War II, who still had a voice in German affairs. He lost in the left's biggest landslide victory in 1998, and was succeeded by the SPD's Gerhard Schr\u00f6der.\nReunification.\nDuring the summer of 1989, rapid changes known as \"peaceful revolution\" or \"Die Wende\" took place in East Germany, which quickly led to German reunification. Growing numbers of East Germans emigrated to West Germany, many via Hungary after Hungary's reformist government opened its borders.\nThe opening of the Iron Curtain between Austria and Hungary at the Pan-European Picnic in August 1989 then triggered a chain reaction, at the end of which there was no longer a GDR and the Eastern Bloc had disintegrated. Otto von Habsburg's idea developed the greatest mass exodus since the construction of the Berlin Wall and it was shown that the USSR and the rulers of the Eastern European satellite states were not ready to keep the Iron Curtain effective. This made their loss of power visible and clear that the GDR no longer received effective support from the other communist Eastern Bloc countries. Thousands of East Germans then tried to reach the West by staging sit-ins at West German diplomatic facilities in other East European capitals, most notably in Prague. The exodus generated demands within East Germany for political change, and mass demonstrations in several cities continued to grow.\nUnable to stop the growing civil unrest, Erich Honecker was forced to resign in October, and on 9 November, East German authorities unexpectedly allowed East German citizens to enter West Berlin and West Germany. Hundreds of thousands of people took advantage of the opportunity; new crossing points were opened in the Berlin Wall and along the border with West Germany. This led to the acceleration of the process of reforms in East Germany that ended with the dissolution of East Germany and the German reunification that came into force on 3 October 1990.\nFederal Republic of Germany, 1990\u2013present.\nThe SPD/Green coalition won the 1998 elections and SPD leader Gerhard Schr\u00f6der positioned himself as a centrist \"Third Way\" candidate in the mold of U.K. Prime Minister Tony Blair and U.S. President Bill Clinton. Schr\u00f6der proposed Agenda 2010, a significant downsizing of the welfare state with five goals: tax cuts; labor market deregulation, especially relaxing rules protecting workers from dismissal and setting up Hartz concept job training; modernizing the welfare state by reducing entitlements; decreasing bureaucratic obstacles for small businesses; and providing new low-interest loans to local governments.\nOn 26 December 2004 during Boxing Day celebration, nearly 540 Germans died and many more thousands of Germans went missing due to the Indian Ocean tsunami from Indonesian earthquake while vacationing in Southern Thailand.\nIn 2005, after the SPD lost to the Christian Democratic Union (CDU) in North Rhine-Westphalia, Gerhard Schr\u00f6der announced he would call federal elections \"as soon as possible\". A motion of confidence was subsequently defeated after Schr\u00f6der urged members not to vote for his government to trigger new elections. In response, a grouping of left-wing SPD dissidents and the neo-communist Party of Democratic Socialism agreed to run on a joint ticket in the general election, with Schr\u00f6der's rival Oskar Lafontaine leading the new group.\nIn the 2005 elections, Angela Merkel became the first female chancellor. In 2009 the German government approved a \u20ac50\u00a0billion stimulus plan. Among the major German political projects of the early 21st century are the advancement of European integration, the energy transition () for a sustainable energy supply, the debt brake for balanced budgets, measures to increase the fertility rate (pronatalism), and high-tech strategies for the transition of the German economy, summarised as Industry 4.0.\nFrom 2005 to 2009 and 2013 to 2021, Germany was ruled by a grand coalition led by the CDU's Angela Merkel as chancellor. From 2009 to 2013, Merkel headed a centre-right government of the CDU/CSU and FDP.\nTogether with France, Italy, Netherlands, and other EU member nations, Germany has played the leading role in the European Union. Germany (especially under Chancellor Helmut Kohl) was one of the main supporters of admitting many East European countries to the EU. Germany is at the forefront of European states seeking to exploit the momentum of monetary union to advance the creation of a more unified and capable European political, defence and security apparatus. German Chancellor Schr\u00f6der expressed an interest in a permanent seat for Germany in the UN Security Council, identifying France, Russia, and Japan as countries that explicitly backed Germany's bid. Germany formally adopted the Euro on 1 January 1999 after permanently fixing the Deutsche Mark rate on 31 December 1998.\nSince 1990, German Bundeswehr has participated in a number of peacekeeping and disaster relief operations abroad. Since 2002, German troops formed part of the International Security Assistance Force in the War in Afghanistan, resulting in the first German casualties in combat missions since World War II.\nIn light of the worldwide Great Recession that began in 2008, Germany did not experience as much economic hardship as other European nations. Germany later sponsored a massive financial rescue in the wake of the Eurozone crisis which affected the German economy.\nFollowing the 2011 earthquake and tsunami in Japan, which led to the Fukushima nuclear disaster, German public opinion turned sharply against nuclear power in Germany, which at the time produced a fourth of the electricity supply. In response Merkel announced plans to close down the nuclear power plants over the following decade, and a commitment to rely more heavily on wind and other alternative energy sources, in addition to coal and natural gas.\nGermany was affected by the European migrant crisis in 2015 as it became the final destination of choice for many asylum seekers from Africa and the Middle East entering the EU. The country took in over a million refugees and migrants and developed a quota system which redistributed migrants around its federal states based on their tax income and existing population density. The decision by Merkel to authorize unrestricted entry led to heavy criticism in Germany as well as within Europe. This was a major factor in the rise of the far-right party Alternative for Germany which entered the Bundestag in the 2017 federal election.\nGerman government response to the COVID-19 pandemic (2020-22).\nIn January 2020, Germany confirmed the first case of novel coronavirus, originating from Wuhan, China. In March 2020, Germany went on national lockdown, which greatly impacted the German economy, healthcare system, and society, and was also commended for being an effective model for instituting methods of curbing infections and deaths, but lost this status by the end of the year due to rising number of cases, hospitalizations, and deaths. In December 2020, COVID-19 vaccines began to be administered in Germany. Unfortunately, from June 2021 to the end of March 2022, Germany saw a new surge of huge COVID-19 infection wave, fueled by the highly transmissible Deltacron hybrid variant, which is combined of Delta and Omicron mutations. However, Germany has suffered from a recombination event of Deltacron, which was caused by vaccine shortages in the first quarter. As of May 2022, Germany has reported 140,292 COVID-19-related deaths, the fifth highest mortality toll (behind Russia, the United Kingdom, Italy, and France), out of 2 million deaths in Europe.\nCOVID-19 measures in Germany were relaxed in March 2022. Mask obligation has been lifted, except for facilities such as hospitals, nursing homes, and public vehicles.\nPost-COVID period (Since 2022).\nOn 8 December 2021 just three months after Germany's centre-left Social Democrats (SPD) narrowly won the federal election, ending 16 years of conservative-led rule under Angela Merkel, Social Democrat Olaf Scholz was sworn in as Germany's new chancellor. He formed a coalition government with the Green Party and the liberal Free Democrats.\nIn February 2022, Frank-Walter Steinmeier was elected for a second five-year term as Germany's president. Although largely ceremonial post, he has been seen as a symbol of consensus and continuity.\nAfter Russia's Feb. 24 invasion of Ukraine in 2022, Germany's previous foreign policy towards Russia (traditional Ostpolitik) has been severely criticized for having been too credulous and soft. Following concerns from the 2022 Russian invasion of Ukraine, Germany announced a major shift in policy, pledging a \u20ac100 billion special fund for the Bundeswehr\u00a0\u2013 to remedy years of underinvestment\u00a0\u2013 along with raising the budget to above 2% GDP.\nAs of April 2023, over 1.06 million refugees from Ukraine were recorded in Germany.\nAs of December 2023, Germany is the fourth largest economy in the world after the United States, China and Japan and the largest economy in Europe. It is the third largest export nation in the world.\nIn February 2025, CDU/CSU, the conservatives, won Germany's 2025 federal election, becoming the biggest group in the parliament. However, far-right Alternative for Germany, AfD, doubled its support to became the second biggest political party in parliament with 20.8% of the vote. SPD, the Social Democrats, had its worst performance in decades with 16.4% of the vote.\nOn 6 May 2025, Friedrich Merz was sworn in as Germany's next chancellor by President Frank-Walter Steinmeier. Merz formed a coalition with his Christian Democrats, its sister party the Christian Social Union, and the Social Democrats.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nWorks cited.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nFurther reading.\nSurveys.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nMedieval.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nReformation.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nEarly Modern to 1815.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\n1815\u20131890.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\n1890\u20131933.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nNazi era.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nSince 1945.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nGDR.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nHistoriography.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "13225", "revid": "43066271", "url": "https://en.wikipedia.org/wiki?curid=13225", "title": "Hades", "text": "God of the underworld in Greek mythology\nHades (; , , later ), in the ancient Greek religion and mythology, is the god of the dead and riches and the King of the underworld, with which his name became synonymous. Hades was the eldest son of Cronus and Rhea, although this also made him the last son to be regurgitated by his father. He and his brothers, Zeus and Poseidon, defeated, overthrew, and replaced their father's generation of gods, the Titans, and claimed joint sovereignty over the cosmos. Hades received the underworld, Zeus the sky, and Poseidon the sea, with the solid earth, which was long the domain of Gaia, available to all three concurrently. In artistic depictions, Hades is typically portrayed holding a bident\nand wearing his helm with Cerberus, the three-headed guard-dog of the underworld, standing at his side.\nRoman-era mythographers eventually equated the Etruscan god Aita,\nand the Roman gods Dis Pater and Orcus, with Hades, and merged all these figures into Pluto, a Latinisation of Plouton (), itself a euphemistic title (meaning \"the rich one\") often given to Hades.\nName.\nThe origin of Hades's name is uncertain but has generally been seen as meaning \"the unseen one\" since antiquity. An extensive section of Plato's dialogue \"Cratylus\" is devoted to the etymology of the god's name, in which Socrates is arguing for a folk etymology not from \"unseen\" but from \"his knowledge (\"eidenai\") of all noble things\". Modern linguists have proposed the Proto-Greek form *\"Awides\" (\"unseen\"). The earliest attested form is \"A\u1e2fd\u0113s\" (), which lacks the proposed digamma. Martin Litchfield West argues instead for an original meaning of \"the one who presides over meeting up\" from the universality of death.\nIn Homeric and Ionic Greek, he was known as \"\u00c1\u00efd\u0113s\". Other poetic variations of the name include \"A\u00efd\u014dne\u00fas\" () and the inflected forms \"\u00c1\u00efdos\" (, gen.), \"\u00c1\u00efdi\" (, dat.), and \"\u00c1\u00efda\" (, acc.), whose reconstructed nominative case *\"\u00c1\u00efs\" () is, however, not attested. The name as it came to be known in classical times was \"H\u00e1id\u0113s\" (). Later the iota became silent, then a subscript marking (), and finally omitted entirely ().\nPerhaps from fear of pronouncing his name, around the 5th century BC, the Greeks started referring to Hades as Plouton ( \"Plo\u00fat\u014dn\", ), with a root meaning \"wealthy\", considering that from the abode below (i.e., the soil) come riches (e.g., fertile crops, metals and so on). Plouton became the Roman god who both rules the underworld and distributed riches from below. This deity was a mixture of the Greek god Hades and the Eleusinian icon Ploutos, and from this he also received a priestess, which was not previously practiced in Greece. More elaborate names of the same genre were \"Ploutod\u00f3t\u0113s\" (, ) or \"Ploutodot\u1e17r\" (, ), meaning \"giver of wealth\".\nEpithets of Hades include \"Agesander\" (, ) and \"Agesilaos\" (, ), both from \"\u00e1g\u014d\" (, \"lead\", \"carry\" or \"fetch\") and \"an\u1e17r\" (, \"man\") or \"laos\" (, \"men\" or \"people\"), describing Hades as the god who carries away all. Nicander uses the form \"Hegesilaus\" (, ).\nHe was also referred to as \"Zeus katachthonios\" (\u0396\u03b5\u1f7a\u03c2 \u03ba\u03b1\u03c4\u03b1\u03c7\u03b8\u03cc\u03bd\u03b9\u03bf\u03c2, ), meaning \"the Zeus of the underworld\", by those avoiding his actual name, as he had complete control over the underworld.\nMythology.\nEarly years.\nIn Greek mythology, Hades, the god of the Greek underworld, was the first-born son of the Titans Cronus and Rhea. He had three older sisters, Hestia, Demeter, and Hera, as well as a younger brother, Poseidon, all of whom had been swallowed whole by their father as soon as they were born. Zeus was the youngest child and through the machinations of their mother, Rhea, he was the only one that had escaped this fate. Upon reaching adulthood, Zeus managed to force his father to disgorge his siblings. After their release, the six younger gods, along with allies they managed to gather, challenged the elder gods for power in the Titanomachy, a divine war. Armed with the helm of invisibility forged for him by the Cyclopes, Hades with his siblings and other divine allies defeated the Titans and became rulers in their place. The war lasted for ten years and ended with the victory of the younger gods. Following their victory, according to a single famous passage in the \"Iliad\" (\"Book XV\", ln.187\u201393), Hades and his two brothers, Poseidon and Zeus, drew lots for realms to rule. Zeus received the sky, Poseidon received the seas, and Hades received the underworld, the unseen realm to which the souls of the dead go upon leaving the world as well as any and all things beneath the earth.\nHades obtained his wife and queen, Persephone, through abduction at the behest of Zeus. This myth is the most important one Hades takes part in; it also connected the Eleusinian Mysteries with the Olympian pantheon, particularly as represented in the \"Homeric Hymn to Demeter\", which is the oldest story of the abduction, most likely dating back to the beginning of the 6th century BC. Helios told the grieving Demeter that Hades was not an unworthy groom or son-in-law given his status among the gods, as her own brother and king on his own right:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;But, Goddess, give up your strong grief; let go\nof your infinite anger. Hades isn't an unsuitable\nson-in-law among the gods: Lord of the Many Dead,\nyour own brother from the same seed. As for honor,\nhe won the third share back when the division was made\nand now lives among those whom he was allotted to rule.\"\u2014\u200a\nKing of the underworld.\nDespite modern connotations of death as evil, Hades was actually more altruistically inclined in mythology. Hades was portrayed as passive and never portrayed negatively; his role was often maintaining relative balance. That said, he was also depicted as cold and stern, and he held all of his subjects equally accountable to his laws. Any other individual aspects of his personality are not given, as Greeks refrained from giving him much thought to avoid attracting his attention.\nHades ruled the dead, assisted by others over whom he had complete authority. The House of Hades was described as full of \"guests\", though he rarely left the underworld. He cared little about what happened in the world above, as his primary attention was ensuring none of his subjects ever left his domain.\nHe strictly forbade his subjects to leave his domain and would become quite enraged when anyone tried to leave, or if someone tried to steal the souls from his realm. His wrath was equally terrible for anyone who tried to cheat death or otherwise crossed him, as Sisyphus and Pirithous found out to their sorrow. While usually indifferent to his subjects, Hades was very focused on the punishment of these two people; particularly Pirithous, as he entered the underworld in an attempt to steal Persephone for himself, and consequently was forced onto the \"Chair of Forgetfulness\". Another myth is about the Greek god Asclepius who was originally a demigod, son of Apollo and Coronis, a Thessalian princess. During his lifetime, he became a famous and talented physician, who eventually was able to bring the dead back to life. Feeling cheated, Hades persuaded Zeus to kill him with a thunderbolt. After his death, Asclepius was brought to Olympus where he became a god. Hades was only depicted outside of the underworld once in myth, and even that is believed to have been an instance where he had just left the gates of the underworld, which was when Heracles shot him with an arrow as Hades was attempting to defend the city of Pylos. After he was shot, however, he traveled to Olympus to heal. Besides Heracles, the only other living people who ventured to the underworld were also heroes: Odysseus, Aeneas (accompanied by the Sibyl), Orpheus, to whom Hades showed uncharacteristic mercy at Persephone's urging, who was moved by Orpheus's music, Theseus with Pirithous, and, in a late romance, Psyche. None of them were pleased with what they witnessed in the realm of the dead. In particular, the Greek war hero Achilles, whom Odysseus conjured with a blood libation, said:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;&lt;poem&gt;O shining Odysseus, never try to console me for dying.\nI would rather follow the plow as thrall to another\nman, one with no land allotted to him and not much to live on,\nthan be a king over all the perished dead.&lt;/poem&gt;\u2014\u200a\nAbduction of Persephone.\nThe consort of Hades was Persephone, daughter of Zeus and Demeter. Persephone did not submit to Hades willingly, but was abducted by him while picking flowers in the fields of Nysa (her father, Zeus, had previously given Persephone to Hades, to be his wife, as is stated in the first lines of the \"Homeric Hymn to Demeter\"). In protest of his act, Demeter cast a curse on the land and there was a great famine; though, one by one, the gods came to request she lift it, lest mankind perish and cause the gods to be deprived of their receiving gifts and sacrifices, Demeter asserted that the earth would remain barren until she saw her daughter again. Zeus then sends for his son, Hermes, and instructs him to go down to the underworld in hopes that he may be able to convince Hades to allow Persephone to return to Earth, so that Demeter might see Persephone and cause the famine to stop. Hermes obeys and goes down to Hades's realm, wherein he finds Hades seated upon a couch, Persephone seated next to him. Hermes relays Zeus's message, and Hades complies, saying, \n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Go now, Persephone, to your dark-robed mother, go, and feel kindly in your heart towards me: be not so exceedingly cast down; for I shall be no unfitting husband for you among the deathless gods, that am own brother to father Zeus. And while you are here, you shall rule all that lives and moves and shall have the greatest rights among the deathless gods: those who defraud you and do not appease your power with offerings, reverently performing rites and paying fit gifts, shall be punished for evermore.\u2014\u200a\nAfterwards, Hades readies his chariot, but not before he secretly gives Persephone a pomegranate seed to eat; Hermes takes the reins, and he and Persephone make their way to the Earth above, coming to a halt in front of Demeter's temple at Eleusis, where the goddess has been waiting. Demeter and Persephone run towards each other and embrace one another, happy that they are reunited. Demeter, however, suspects that Persephone may have eaten food while down in the underworld, and so she questions Persephone, saying:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;My child, tell me, surely you have not tasted any food while you were below? Speak out and hide nothing, but let us both know. For if you have not, you shall come back from loathly Hades and live with me and your father, the dark-clouded son of Cronos and be honored by all the deathless gods; but if you have tasted food, you must go back again beneath the secret places of the earth, there to dwell a third part of the seasons every year: yet for the two parts you shall be with me and the other deathless gods. But when the earth shall bloom with the fragrant flowers of spring in every kind, then from the realm of darkness and gloom thou shalt come up once more to be a wonder for gods and mortal men. And now tell me how he rapt you away to the realm of darkness and gloom, and by what trick did the strong Host of Many beguile you?\u2014\u200a\nPersephone does admit that she ate the food of the dead, as she tells Demeter that Hades gave her a pomegranate seed and forced her to eat it. Persephone's eating the pomegranate seed binds her to Hades and the underworld, much to the dismay of Demeter. Zeus, however, had previously proposed a compromise, to which all parties had agreed: of the year, Persephone would spend one third with her husband.\nIt is during this time, when Persephone is down in the underworld with her husband, that winter falls upon the earth, \"an aspect of sadness and mourning.\"\nVisitors in the underworld.\nThe hero Orpheus once descended into the underworld in search of his late wife Eurydice, who died when a snake bit her. So lovely was the music he played that it charmed even Hades (as well as his wife Persephone), who allowed him to take Eurydice to the land of the living, as long as he did not look back at her on his way out.\nIn another story, Theseus and Pirithous pledged to kidnap and marry daughters of Zeus. Theseus chose Helen and together they kidnapped her and decided to hold onto her until she was old enough to marry. Pirithous chose Persephone. They left Helen with Theseus's mother, Aethra, and traveled to the underworld. Hades knew of their plan to capture his wife, so he pretended to offer them hospitality and set a feast; as soon as the pair sat down, snakes coiled around their feet and held them there. Theseus was eventually rescued by Heracles but Pirithous was either trapped as punishment for daring to seek the wife of a god for his own or killed by Cerberus, depending on the version of the story.\nSisyphus was a mortal king from Corinth who was punished in Tartarus for revealing to the river god Asopus the whereabouts of his daughter Aegina after Zeus abducted her, and for trying to cheat death as well. Zeus, angry at Sisyphus for revealing the secret, sent Thanatos to Sisyphus, but he cleverly cast Death into his own bonds, and as a result no one could die until Ares freed Thanatos and delivered Sisyphus to him. But still, Sisyphus ordered his wife Merope not to perform any funeral rites for him and what else was accustomed as tribute to the underworld gods before he was brought to Hades. After some time that Merope had not offered proper honours, Hades learnt of this, and allowed Sisyphus to return to the world of the living so that he could punish his wife, with the understanding that he would return afterwards. Sisyphus, however, never returned as promised until years later, when he died of old age. Hades punished Sisyphus by making him roll a boulder up a hill in the underworld; but every time he reached the top, the boulder would roll down again and again. In another version, it is Persephone who lets him out.\nHeracles's final labour was to capture Cerberus. First, Heracles went to Eleusis to be initiated into the Eleusinian Mysteries. He did this to absolve himself of guilt for killing the centaurs and to learn how to enter and exit the underworld alive. He found the entrance to the underworld at Taenarum. Athena and Hermes helped him through and back from Hades. Heracles asked Hades for permission to take Cerberus. Hades agreed as long as Heracles did not harm Cerberus. When Heracles dragged the dog out of Hades, he passed through the cavern Acherusia.\nIn the myth of Admetus and Alcestis, after Alcestis chose to die in place of her husband Admetus in order to save him, Heracles brought her back from the dead by fighting and defeating Hades. In other versions, like Euripides's play \"Alcestis\", Heracles fought Thanatos instead. At another time, Heracles sieged the town of Pylos and during the fight he wounded Hades, who had sided with the Pylians. In great pain, Hades went to Olympus to be healed by the physician of the gods, Paean.\nLovers of Hades.\nLeuce was the most beautiful of the nymphs and a daughter of Oceanus. Hades fell in love with her and abducted her to the underworld. She lived out the span of her life in his realm, and when she died, the god sought consolation by creating a suitable memorial of their love: in the Elysian Fields where the pious spend their afterlife, he brought a white tree into existence. It was this tree with which Heracles crowned himself to celebrate his return from the underworld.\nMinthe was a nymph of the river Cocytus who became Hades's mistress. A jealous Persephone trampled the nymph under her foot, transforming her into garden mint in the process. According to a scholiast on Nicander, Hades turned his dead lover into the mint herb after Persephone tore her into pieces for sleeping with him. In another version, Hades had kept Minthe as his mistress before he married Persephone, and set her aside afterwards. Minthe boasted of being more beautiful than Persephone, and that Hades would soon take her back. In anger over the hubris directed toward her daughter, Demeter trampled Minthe and turned her into mint.\nTheophile was a girl who claimed that Hades loved her and that she was better than Persephone.\nOther works.\nOnce, when a plague hit Aonia, a region in Boeotia, the people consulted an oracle, and the god replied to them that they needed to make an appeal to the gods of the Underworld and sacrifice two willing young maidens to appease the anger of Hades and Persephone. The girls that were chosen were Menippe and Metioche, the daughters of Orion, who solemnly offered their lives in order to save their countrymen. After invoking the chthonic deities three times, they took their own lives with the shuttles of their looms. Hades and Persephone then took pity in both of them, and transformed their corpses into comets.\nIn some versions Hades is considered the master of the goddesses of Fate, not his brother Zeus and the god who designates the end and origin of all things and orders the alternation of birth and destruction, the arbiter of life and death. This relationship is very clear in Roman epics like Statius's \"Thebaid\", where they are mentioned taking souls to be judged by Hades and inflicting severe punishments or in Claudian's \"De raptu Proserpinae\" where they appear begging their master not to release the Titans and saying everything they do is for him, after Hades threatens Zeus to release the Titans against him if he does not give him a wife.\nHades is considered the father of the Furies in some versions, but the mother's identity varies. in Virgil's \"Aeneid\" their mother is the night goddess Nyx and in the \"Orphic Hymns\" their mother is Persephone by Hades. One of the rare occasions when he appears interacting with them is in Statius's \"Thebaid\", when Hades orders Tisiphone to punish humans for having invaded the underworld. He is said to hate Alecto, even though she is one of his children.\nIn contrast to many of his other classical representations the satirical author Lucian of Samosata presents Hades in a more positive and even comic way. In his \"Dialogues of the Dead\", he is represented trying to solve problems of some famous mythological figures and one of the most outstanding dialogues is with Protesilaus, one of the Greek heroes killed in the Trojan War. In this conversation Protesilaus asks him to be reunited with his (still living) lover, and brings up as example that Hades did the same for Admetus and Alcestis, Orpheus and Eurydice, and that he himself also knows what being in love is like. Hades is skeptical, but Persephone manages to persuade him.\nAccording to Hesiod, when the monstrous Typhon attacked the Olympian gods, Hades is said to have trembled in fear in the underworld while Zeus fought Typhon above.\nIn one of Plato's dialogues, Socrates talks about Hades as a figure capable of making everyone fall by his enchantments and that is why no one ever leaves the underworld, including the sirens.\nCult and epithets.\nHades, as the god of the dead, was a fearsome figure to those still living; in no hurry to meet him, they were reluctant to swear oaths in his name, and averted their faces when sacrificing to him. Since to many, simply to say the word \"Hades\" was frightening, euphemisms were pressed into use. Since precious minerals come from under the earth (i.e., the \"underworld\" ruled by Hades), he was considered to have control of these as well, and as such the Greeks referred to him as \u03a0\u03bb\u03bf\u03cd\u03c4\u03c9\u03bd (Greek \"Plouton\"; Latin PLVTO, \"Pluto\", \"the rich one\"). This title is derived from the word \"Ploutos\" (, ). Sophocles explained the notion of referring to Hades as \"Plouton\" with these words: \"the gloomy Hades enriches himself with our sighs and our tears.\" In addition, he was called Clymenus (, \"Kl\u00fdmenos\", 'infamous', ), Polydegmon (, \"Polyd\u00e9gmon\", 'host of many', ), and perhaps Eubuleus (, \"Euboule\u00fas\", 'good counsel', ), all of them euphemisms for a name that was unsafe to pronounce, which evolved into epithets.\nHe spent most of the time in his dark realm. Formidable in battle, he proved his ferocity in the famous Titanomachy, the battle of the Olympians versus the Titans, which established the rule of Zeus.\nFeared and loathed, Hades embodied the inexorable finality of death: \"Why do we loathe Hades more than any god, if not because he is so adamantine and unyielding?\" The rhetorical question is Agamemnon's. Hades was not, however, an evil god, for although he was stern, cruel, and unpitying, he was still just. Hades ruled the underworld and was therefore most often associated with death and feared by men, but he was not Death itself \u2014 it is Thanatos, son of Nyx and Erebus, who is the actual personification of death, although Euripides's play \"Alkestis\" states fairly clearly that Thanatos and Hades were one and the same deity, and gives an interesting description of Hades as being dark-cloaked and winged.\nWhen the Greeks propitiated Hades, they banged their hands on the ground to be sure he would hear them. Black animals, such as sheep, were sacrificed to him. While some suggest the very vehemence of the rejection of human sacrifice expressed in myth might imply an unspoken memory of some distant past, there is no direct evidence of such a turn. The blood from all chthonic sacrifices including those to propitiate Hades dripped into a pit or cleft in the ground. The person who offered the sacrifice had to avert his face.\nOne ancient source says that he possessed the Cap of invisibility. His chariot, drawn by four black horses, made for a fearsome and impressive sight. These beasts were variously named as, according to Claudian: Orphnaeus, Aethon, Nycteus and Alastor while other authors listed also: Nonius, Ametheus, Abastor, Abetor and Metheus. His other ordinary attributes were the narcissus and cypress plants, the Key of Hades and Cerberus, the three-headed dog. In certain portraits, snakes also appeared to be attributed to Hades as he was occasionally portrayed to be either holding them or accompanied by them. This is believed to hold significance as in certain classical sources Hades ravished Kore in the guise of a snake, who went on to give birth to Zagreus-Dionysus. While bearing the name 'Zeus', Zeus Olympios, the great king of the gods, noticeably differs from the Zeus Meilichios, a decidedly chthonian character, often portrayed as a snake, and as seen beforehand, they cannot be different manifestations of the same god, in fact whenever 'another Zeus' is mentioned, this always refers to Hades. Zeus Meilichios and Zeus Eubouleus are often referred to as being alternate names for Hades.\nThe philosopher Heraclitus, unifying opposites, declared that Hades and Dionysus, the very essence of indestructible life \"(zo\u00eb)\", are the same god. Among other evidence, Karl Ker\u00e9nyi notes in his book that the Homeric Hymn To Demeter, votive marble images and epithets all link Hades to being Dionysus. He also notes that the grieving goddess Demeter refused to drink wine, as she states that it would be against \"themis\" for her to drink wine, which is the gift of Dionysus, after Persephone's abduction, because of this association; indicating that Hades may in fact have been a \"cover name\" for the underworld Dionysus. He suggests that this dual identity may have been familiar to those who came into contact with the Mysteries. Dionysus also shared several epithets with Hades such as \"Chthonios\" (\"the subterranean\"), \"Eubouleus\" (\"Good Counselor\"), and \"Euclius\" (\"glorious\" or \"renowned\") .\nEvidence for a cult connection is quite extensive, particularly in southern Italy, especially when considering the death symbolism included in Dionysian worship; statues of Dionysus found in the Ploutonion at Eleusis gives further evidence as the statue bears a striking resemblance to the statue of Eubouleus also known as the youthful depiction of the Lord of the underworld. The statue of Eubouleus is described as being radiant but disclosing a strange inner darkness.\nBoth Hades and Dionysus were associated with a divine tripartite deity with Zeus. The Orphics in particular believed that Zeus and Hades were the same deity and portrayed them as such. This nature and aspect of Hades and Zeus displayed in the Orphic stories is the explanation for why both Hades and Zeus are considered to be the father of Orphic Dionysus-Zagreus. Orphics also described Zagreus as the son of Hades, while also regarding Zagreus as an aspect of Dionysus. The role of unifying Hades, Zeus and Dionysus as a single tripartite god was used to represent the birth, death and resurrection of a deity and to unify the 'shining' realm of Zeus and the dark realm of Hades that lay beneath the Earth.\nAmong the other appellations under which Hades or Pluto is generally known, are the following:\n\"In Greek:\"\n\"In Latin or Etruscan:\"\n\"In Egypt:\"\nArtistic representations.\nHades was depicted infrequently in artwork, as well as mythology, because the Greeks were so afraid of him. His artistic representations, which are generally found in Archaic pottery, are not even concretely thought of as the deity; however at this point in time it is heavily believed that the figures illustrated are indeed Hades. He was later presented in the classical arts in the depictions of the Rape of Persephone. Within these illustrations, Hades was often young, yet he was also shown as varying ages in other works. Due to this lack of depictions, there were not very strict guidelines when representing the deity. On pottery, he has a dark beard and is presented as a stately figure on an \"ebony throne.\" His attributes in art include a bident (less commonly, a scepter), a helm, cornucopias, roosters, and a key. They key plays a doubly symbolic role in that it represents his control over the underworld and acts as a reminder that the gates of the underworld were always locked so that souls could not leave. Even if the doors were open, Cerberus, the three-headed guard dog of the underworld, ensured that, while all souls were allowed to enter into the underworld freely, none could ever escape. Cerberus is a very integral symbol of Hades so much so that when Cerberus is depicted, the depiction very rarely portrays him without Hades. Sometimes, artists painted Hades as looking away from the other gods, as he was disliked by them as well as humans.\nAs Pluto, he was regarded in a more positive light. He holds a cornucopia, representing the gifts he bestows upon people as well as fertility, which he becomes connected to. \nRealm of Hades.\nIn older Greek myths, the realm of Hades is the misty and gloomy abode of the dead (also called Erebus) where all mortals go when they die. Very few mortals could leave Hades once they entered. The exceptions, Heracles and Theseus, are heroic. Even Odysseus in his \"Nekyia\" (\"Odyssey\", xi) calls up the spirits of the departed, rather than descend to them. Later Greek philosophy introduced the idea that all mortals are judged after death and are either rewarded or cursed.\nThere were several sections of the realm of Hades, including Elysium, the Asphodel Meadows, and Tartarus. The mythographer Apollodorus, describes Tartarus as \"a gloomy place in Hades as far distant from Earth, as Earth is distant from the sky.\" Greek mythographers were not perfectly consistent about the geography of the afterlife. A contrasting myth of the afterlife concerns the Garden of the Hesperides, often identified with the Isles of the Blessed, where the blessed heroes may dwell.\nIn Roman mythology, the entrance to the underworld located at Avernus, a crater near Cumae, was the route Aeneas used to descend to the realm of the dead. By synecdoche, \"Avernus\" could be substituted for the underworld as a whole. The \"di inferi\" were a collective of underworld divinities.\nFor Hellenes, the deceased entered the underworld by crossing the Styx, ferried across by Charon (kair'-on), who charged an \"obolus,\" a small coin for passage placed in the mouth of the deceased by pious relatives. Paupers and the friendless gathered for a hundred years on the near shore according to Book VI of Vergil's Aeneid. Greeks offered propitiatory libations to prevent the deceased from returning to the upper world to \"haunt\" those who had not given them a proper burial. The far side of the river was guarded by Cerberus, the three-headed dog defeated by Heracles (Roman Hercules). Passing beyond Cerberus, the shades of the departed entered the land of the dead to be judged.\nThe five rivers of the realm of Hades, and their symbolic meanings, are Acheron (the river of sorrow, or woe), Cocytus (lamentation), Phlegethon (fire), Lethe (oblivion), and Styx (hate), the river upon which even the gods swore and in which Achilles was dipped to render him invincible. The Styx forms the boundary between the upper and lower worlds. See also Eridanos.\nThe first region of Hades comprises the Fields of Asphodel, described in \"Odyssey\" xi, where the shades of heroes wander despondently among lesser spirits, who twitter around them like bats. Only libations of blood offered to them in the world of the living can reawaken in them for a time the sensations of humanity.\nBeyond lay Erebus, which could be taken for a euphonym of Hades, whose own name was dread. There were two pools, that of Lethe, where the common souls flocked to erase all memory, and the pool of Mnemosyne (\"memory\"), where the initiates of the Mysteries drank instead. In the forecourt of the palace of Hades and Persephone sit the three judges of the underworld: Minos, Rhadamanthus, and Aeacus. There at the trivium sacred to Hecate, where three roads meet, souls are judged, returned to the Fields of Asphodel if they are neither virtuous nor evil, sent by the road to Tartarus if they are impious or evil, or sent to Elysium (Islands of the Blessed) with the \"blameless\" heroes.\nIn the Sibylline oracles, a curious hodgepodge of Greco-Roman and Judaeo-Christian elements, Hades again appears as the abode of the dead, and by way of folk etymology, it even derives \"Hades\" from the name Adam (the first man), saying it is because he was the first to enter there. Owing to its appearance in the New Testament of the Bible, Hades also has a distinct meaning in Christianity.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nBibliography.\nAncient.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nModern.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "13236", "revid": "38702144", "url": "https://en.wikipedia.org/wiki?curid=13236", "title": "GNU Hurd", "text": "Operating system kernel designed as a replacement for Unix\nGNU Hurd is a collection of microkernel servers written as part of GNU, for the GNU Mach microkernel. It has been under development since 1990 by the GNU Project of the Free Software Foundation, designed as a replacement for the Unix kernel, and released as free software under the GNU General Public License. When the Linux kernel proved to be a viable solution, development of GNU Hurd slowed, at times alternating between stasis and renewed activity and interest.\nThe Hurd's design consists of a set of protocols and server processes (or daemons, in Unix terminology) that run on the GNU Mach microkernel. The Hurd aims to surpass the Unix kernel in functionality, security, and stability, while remaining largely compatible with it. The GNU Project chose the multiserver microkernel for the operating system, due to perceived advantages over the traditional Unix monolithic kernel architecture, a view that had been advocated by some developers in the 1980s.\nName and logo.\nIn December 1991 the primary architect of the Hurd described the name as a mutually recursive acronym:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;It's time [to] explain the meaning of \"Hurd\". \"Hurd\" stands for \"Hird of Unix-Replacing Daemons\". And, then, \"Hird\" stands for \"Hurd of Interfaces Representing Depth\". We have here, to my knowledge, the first software to be named by a pair of mutually recursive acronyms.\u2014\u200a\nAs both \"hurd\" and \"hird\" are homophones of the English word \"herd\", the full name \"GNU Hurd\" is also a play on the words \"herd of gnus\", reflecting how the kernel works.\nThe logo is called the \"Hurd boxes\" and it also reflects on architecture. The logo is a graph where nodes represent the Hurd kernel's servers and directed edges are IPC messages.\nDevelopment history.\nRichard Stallman founded the GNU Project in September 1983 with an aim to create a free GNU operating system. Initially the components required for kernel development were written: editors, shell, compiler, debugger etc. By 1989, the GPL came into being and the only major component missing was the kernel.\nDevelopment on the Hurd began in 1990 after an abandoned kernel attempt in 1986, based on the research TRIX operating system developed by Professor Steve Ward and his group at MIT's Laboratory for Computer Science (LCS). According to Thomas Bushnell, the initial Hurd architect, their early plan was to adapt the 4.4BSD-Lite kernel and, in hindsight, \"It is now perfectly obvious to me that this would have succeeded splendidly and the world would be a very different place today.\" In 1987 Richard Stallman proposed using the Mach microkernel developed by Richard Rashid at Carnegie Mellon University. Work on this was delayed for three years due to uncertainty over whether CMU would release the Mach code under a suitable license.\nWith the release of the Linux kernel in 1991, the primary user of GNU's userland components soon became operating systems based on the Linux kernel (Linux distributions), prompting the coining of the term \"GNU/Linux\".\nDevelopment of the Hurd has proceeded slowly. Despite an optimistic announcement by Stallman in 2002 predicting a release of GNU/Hurd later that year, the Hurd is still not considered suitable for production environments. Development in general has not met expectations, and there are still a significant number of bugs and missing features. This has resulted in a poorer product than many, including Stallman, had expected. In 2010, after twenty years under development, Stallman said that he was \"not very optimistic about the GNU Hurd. It makes some progress, but to be really superior it would require solving a lot of deep problems\", but added that \"finishing it is not crucial\" for the GNU system because a free kernel already existed (Linux), and completing Hurd would not address the main remaining problem for a free operating system: device support.\nThe Debian project, among others, have worked on the Hurd project to produce binary distributions of Hurd-based GNU operating systems for IBM PC compatible systems.\nAfter years of stagnation, development picked up again in 2015 and 2016, with four releases during these two years, but no more until 2025, when a new version was released.\nOn August 20, 2015, amid the Google Summer of Code, it was announced that GNU Guix had been ported to GNU Hurd.\nArchitecture.\nUnlike most Unix-like kernels, the Hurd uses a server\u2013client architecture, built on a microkernel that is responsible for providing the most basic kernel services \u2013 coordinating access to the hardware: the CPU (through process management and scheduling), RAM (via memory management), and other various input/output devices (via I/O scheduling) for sound, graphics, mass storage, etc. In theory, the microkernel design would allow for all device drivers to be built as servers working in user space, but today most drivers of this kind are still contained in the GNU Mach kernel space.\nAccording to Hurd developers, the main advantage of microkernel-based design is the ability to extend the system: developing a new module would not require in depth knowledge of the rest of the kernel, and a bug in one module would not crash the entire system. Hurd provides a concept of \"translators\", a framework of modules used to extend a file system functionality.\nFrom early on, the Hurd was developed to use GNU Mach as the microkernel. This was a technical decision made by Richard Stallman, who thought it would speed up the work by saving a large part of it. He has admitted that he was wrong about that. Other Unix-like systems working on the Mach microkernel include OSF/1, Lites, and MkLinux. macOS and NeXTSTEP use hybrid kernels based on Mach.\nOther microkernels.\nFrom 2004 onward, various efforts were launched to port the Hurd to more modern microkernels. The L4 microkernel was the original choice in 2004, but progress slowed to a halt. Nevertheless, during 2005, Hurd developer Neal Walfield finished the initial memory management framework for the L4/Hurd port, and Marcus Brinkmann ported essential parts of glibc; namely, getting the process startup code working, allowing programs to run, thus allowing the first user programs (trivial ones such as the hello world program) in C to run.\nSince 2005, Brinkmann and Walfield started researching Coyotos as a new kernel for HURD. In 2006, Brinkmann met with Jonathan Shapiro (a primary architect of the Coyotos Operating System) to aid in and discuss the use of the Coyotos kernel for GNU/Hurd. In further discussion HURD developers realised that Coyotos (as well as other similar kernels) are not suitable for HURD.\nIn 2007, Hurd developers Neal Walfield and Marcus Brinkmann gave a critique of the Hurd architecture, known as \"the critique\", and a proposal for how a future system may be designed, known as \"the position paper\". In 2008, Neal Walfield began working on the Viengoos microkernel as a modern native kernel for HURD. As of 2009[ [update]], development on Viengoos is paused due to Walfield lacking time to work on it.\nIn the meantime, others have continued working on the Mach variant of Hurd.\nUnix extensions.\nA number of traditional Unix concepts are replaced or extended in the Hurd.\nUnder Unix, every running program has an associated user id, which normally corresponds to the user that started the process. This id largely dictates the actions permitted to the program. No outside process can change the user id of a running program. A Hurd process, on the other hand, runs under a \"set\" of user ids, which can contain multiple ids, one, or none. A sufficiently privileged process can add and remove ids to another process. For example, there is a password server that will hand out ids in return for a correct login password.\nRegarding the file system, a suitable program can be designated as a \"translator\" for a single file or a whole directory hierarchy. Every access to the translated file, or files below a hierarchy in the second case, is in fact handled by the program. For example, a file translator may simply redirect read and write operations to another file, like a Unix symbolic link. The effect of Unix \"mounting\" is achieved by setting up a filesystem translator (using the \"settrans\" command). Translators can also be used to provide services to the user. For example, the ftpfs translator allows a user to encapsulate remote FTP sites within a directory. Then, standard tools such as ls, cp, and rm can be used to manipulate files on the remote system. Even more powerful translators are ones such as UnionFS, which allows a user to unify multiple directories into one; thus listing the unified directory reveals the contents of all the directories.\nThe Hurd requires a multiboot-compliant boot loader, such as GRUB.\nArchitecture of the servers.\nAccording to the Debian documentation, there are 24 servers (18 core servers and 6 file system servers) named as follows:\nThe ext2 filesystem translator. It receives disk blocks from the microkernel and gives files and directories to the applications.\nThe translator for the ISO 9660 filesystem. Translates blocks of a CD or DVD to files and directories for the applications.\nSee Network File System.\n File Transfer Protocol filesystem translator.\nThe storage translator.\nFilesystem servers.\nThe servers collectively implement the POSIX API, with each server implementing a part of the interface. For instance, the various filesystem servers each implement the filesystem calls. The storage server will work as a wrapping layer, similar to the block layer of Linux. The equivalent of VFS of Linux is achieved by libdiskfs and libpager libraries.\nGNU distributions running Hurd.\nHurd-based GNU distributions include:\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "13237", "revid": "36767729", "url": "https://en.wikipedia.org/wiki?curid=13237", "title": "HugoPrize", "text": ""}
{"id": "13238", "revid": "43252809", "url": "https://en.wikipedia.org/wiki?curid=13238", "title": "Hate Crime", "text": ""}
{"id": "13239", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=13239", "title": "Hobbits", "text": ""}
{"id": "13240", "revid": "50862944", "url": "https://en.wikipedia.org/wiki?curid=13240", "title": "Hollywood cycles", "text": "In the classic era of the cinema of the United States (1930 \u2013 1945) genres matured. A \"cycle\" occurs when a large amount of films consisting of specific features are produced in a certain period of time, and following the success of films with similar topics. While most would recognize many of the genres as Westerns, gangsters, musicals, etc., often the cycles were significantly more specific. A cycle is different from a genre or a subgenre, because a cycle focuses on a timeframe, while the other two can be used at different times. Hollywood studios created my cycles to attract viewers in the 20th century, and succeed at the box office. Major Hollywood studios have made profits from film cycles because viewers are interest on films with the same theme or topic.\nIn the 1960s, successful examples of Hollywood cycles include cycles of youth revolution films, protest films, campus revolt films and youth rebellion films. However, in the 1980s, some films commercially failed, including Conan the Barbarian, The Thing and Footloose, because they did not meet the expectations.\nInstead of \"romantic comedy\", a cycle might be described as the \"Boy-meets-girl-boy-loses-girl-boy-gets-girl\" cycle.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "13243", "revid": "14926857", "url": "https://en.wikipedia.org/wiki?curid=13243", "title": "HDTV", "text": ""}
{"id": "13247", "revid": "36767729", "url": "https://en.wikipedia.org/wiki?curid=13247", "title": "HistoricalMaterialism", "text": ""}
{"id": "13249", "revid": "33145", "url": "https://en.wikipedia.org/wiki?curid=13249", "title": "Hylobatidae", "text": ""}
{"id": "13250", "revid": "27015025", "url": "https://en.wikipedia.org/wiki?curid=13250", "title": "Health care reform", "text": "Governmental policy\nHealth care reform is for the most part governmental policy that affects health care delivery in a given place. Health care reform typically attempts to:\nFrameworks for health care reform.\nWhile final performance goals are largely agreed upon, different frameworks suggest different intermediate goals, such as equity, productivity, safety, innovation, and choice.\nControl knobs theory.\nIn \"Getting Health Reform Right: A Guide to Improving Performance and Equity,\" Marc Roberts, William Hsiao, Peter Berman, and Michael Reich of the Harvard T.H. Chan School of Public Health aim to provide decision-makers with tools and frameworks for health care system reform. They propose five \"control knobs\" of health reform: financing, payment, organization, regulation, and behavior. These control knobs refer to the \"mechanisms and processes that reformers can adjust to improve system performance\". The authors selected these control knobs as representative of the most important factors upon which a policymaker can act to determine health system outcomes.\nTheir method emphasizes the importance of \"identifying goals explicitly, diagnosing causes of poor performance systematically, and devising reforms that will produce real changes in performance\". The authors view health care systems as a means to an end. Accordingly, the authors advocate for three intrinsic performance goals of the health system that can be adjusted through the control knobs. These goals include:\nThe authors also propose three intermediate performance measures, which are useful in determining the performance of system goals, but are not final objectives. These include:\nThe five proposed control knobs represent the mechanisms and processes that policy-makers can use to design effective health care reforms. These control knobs are not only the most important elements of a healthcare system, but they also represent the aspect that can be deliberately adjusted by reforms to affect change. The five control knobs are:\nLimitations.\nThe five control knobs of health care reform are not designed to work in isolation; health care reform may require the adjustment of more than one knob or of multiple knobs simultaneously. Further, there is no agreed-upon order of turning control knobs to achieve specific reforms or outcomes. Health care reform varies by setting and reforms from one context may not necessarily apply in another. The knobs interact with cultural and structural factors that are not illustrated within this framework, but which have an important effect on health care reform in a given context. Rather than a prescriptive proposal of recommendations, the framework allows users to adapt their analysis and actions based on cultural context and relevance of interventions.\nReduction of health care fraud.\nOne key component to healthcare reform is the reduction of healthcare fraud and abuse. In the U.S. and the EU, it is estimated that as much as 10 percent of all healthcare transactions and expenditures may be fraudulent.\nComparison between countries.\nAs evidenced by the large variety of different healthcare systems seen across the world, there are several different pathways that a country could take when thinking about reform. In comparison to the UK, physicians in Germany have more bargaining power through professional organizations (i.e., Medical association); this ability to negotiate affects reform efforts. Germany makes use of sickness funds, which citizens are obliged to join but are able to opt out if they have a very high income (Belien 87). The Netherlands used a similar system but the financial threshold for opting out was lower (Belien 89). The Swiss, on the other hand use more of a privately based health insurance system where citizens are risk-rated by age and sex, among other factors (Belien 90).\nBy country.\nUnited States.\nIn the United States, the debate regarding health care reform includes questions of a right to health care, access, fairness, sustainability, quality and amounts spent by government. The mixed public-private health care system in the United States is the most expensive in the world, with health care costing more per person than in any other nation, and a greater portion of gross domestic product (GDP) is spent on it than in any other United Nations member state except for East Timor (Timor-Leste).\nHawaii and Massachusetts.\nBoth Hawaii and Massachusetts have implemented some incremental reforms in health care, but neither state has complete coverage of its citizens. For example, data from the Kaiser Family Foundation shows that 5% of Massachusetts and 8% of Hawaii residents are uninsured. To date, The U.S. Uniform Law Commission, sponsored by the National Conference of Commissioners on Uniform State Laws has not submitted a uniform act or model legislation regarding health care insurance or health care reform.\nUnited Kingdom.\nHealthcare was reformed in 1948 after the Second World War, broadly along the lines of the 1942 Beveridge Report, with the creation of the National Health Service or NHS. It was originally established as part of a wider reform of social services and funded by a system of National Insurance, though receipt of healthcare was never contingent upon making contributions towards the National Insurance Fund. Private health care was not abolished but had to compete with the NHS. About 15% of all spending on health in the UK is still privately funded but this includes the patient contributions towards NHS provided prescription drugs, so private sector healthcare in the UK is quite small. As part of a wider reform of social provision it was originally thought that the focus would be as much about the prevention of ill-health as it was about curing disease. The NHS for example would distribute baby formula milk fortified with vitamins and minerals in an effort to improve the health of children born in the post war years as well as other supplements such as cod liver oil and malt. Many of the common childhood diseases such as measles, mumps, and chicken pox were mostly eradicated with a national program of vaccinations.\nThe NHS has been through many reforms since 1974. The Conservative Thatcher administrations attempted to bring competition into the NHS by developing a supplier/buyer role between hospitals as suppliers and health authorities as buyers. This necessitated the detailed costing of activities, something which the NHS had never had to do in such detail, and some felt was unnecessary. The Labour Party generally opposed these changes, although after the party became New Labour, the Blair government retained elements of competition and even extended it, allowing private health care providers to bid for NHS work. Some treatment and diagnostic centres are now run by private enterprise and funded under contract. However, the extent of this privatisation of NHS work is still small, though remains controversial. The administration committed more money to the NHS raising it to almost the same level of funding as the European average and as a result, there was large expansion and modernisation programme and waiting times improved.\nThe government of Gordon Brown proposed new reforms for care in England. One is to take the NHS back more towards health prevention by tackling issues that are known to cause long term ill health. The biggest of these is obesity and related diseases such as diabetes and cardio-vascular disease. The second reform is to make the NHS a more personal service, and it is negotiating with doctors to provide more services at times more convenient to the patient, such as in the evenings and at weekends. This personal service idea would introduce regular health check-ups so that the population is screened more regularly. Doctors will give more advice on ill-health prevention (for example encouraging and assisting patients to control their weight, diet, exercise more, cease smoking etc.) and so tackle problems before they become more serious. Waiting times, which fell considerably under Blair (median wait time is about 6 weeks for elective non-urgent surgery) are also in focus. A target was set from December 2008, to ensure that no person waits longer than 18 weeks from the date that a patient is referred to the hospital to the time of the operation or treatment. This 18-week period thus includes the time to arrange a first appointment, the time for any investigations or tests to determine the cause of the problem and how it should be treated. An NHS Constitution was published which lays out the legal rights of patients as well as promises (not legally enforceable) the NHS strives to keep in England.\nGermany.\nNumerous healthcare reforms in Germany were legislative interventions to stabilise the public health insurance since 1983. 9 out of 10 citizens are publicly insured, only 8% privately. Health care in Germany, including its industry and all services, is one of the largest sectors of the German economy. The total expenditure in health economics of Germany was about 287.3 billion euro in 2010, equivalent to 11.6 percent of the gross domestic product (GDP) this year and about 3,510 euro per capita. Direct inpatient and outpatient care equal just about a quarter of the entire expenditure - depending on the perspective. Expenditure on pharmaceutical drugs is almost twice the amount of those for the entire hospital sector. Pharmaceutical drug expenditure grew by an annual average of 4.1% between 2004 and 2010.\nThese developments have caused numerous healthcare reforms since the 1980s. An actual example of 2010 and 2011: First time since 2004 the drug expenditure fell from 30.2 billion euro in 2010, to 29.1 billion Euro in 2011, i. e. minus 1.1 billion Euro or minus 3.6%. That was caused by restructuring the Social Security Code: manufacturer discount 16% instead of 6%, price moratorium, increasing discount contracts, increasing discount by wholesale trade and pharmacies.\nThe Netherlands.\nThe Netherlands has introduced a new system of health care insurance based on risk equalization through a risk equalization pool. In this way, a compulsory insurance package is available to all citizens at affordable cost without the need for the insured to be assessed for risk by the insurance company. Furthermore, health insurers are now willing to take on high risk individuals because they receive compensation for the higher risks.\nA 2008 article in the journal Health Affairs suggested that the Dutch health system, which combines mandatory universal coverage with competing private health plans, could serve as a model for reform in the US.\nRussia.\nFollowing the collapse of the Soviet Union, Russia embarked on a series of reforms intending to deliver better healthcare by compulsory medical insurance with privately owned providers in addition to the state run institutions. According to the OECD none of 1991-93 reforms worked out as planned and the reforms had in many respects made the system worse. Russia has more physicians, hospitals, and healthcare workers than almost any other country in the world on a per capita basis, but since the collapse of the Soviet Union, the health of the Russian population has declined considerably as a result of social, economic, and lifestyle changes. However, after Putin became president in 2000 there was significant growth in spending for public healthcare and in 2006 it exceed the pre-1991 level in real terms. Also life expectancy increased from 1991 to 1993 levels, infant mortality rate dropped from 18.1 in 1995 to 8.4 in 2008. Russian Prime Minister Vladimir Putin announced a large-scale health care reform in 2011 and pledged to allocate more than 300 billion rubles ($10 billion) in the next few years to improve health care in the country.\nTaiwan.\nTaiwan changed its healthcare system in 1995 to a National Health Insurance model similar to the US Medicare system for seniors. As a result, the 40% of Taiwanese people who had previously been uninsured are now covered. It is said to deliver universal coverage with free choice of doctors and hospitals and no waiting lists. Polls in 2005 are reported to have shown that 72.5% of Taiwanese are happy with the system, and when they are unhappy, it's with the cost of premiums (equivalent to less than US$20 a month).\nEmployers and the self-employed are legally bound to pay National Health Insurance (NHI) premiums which are similar to social security contributions in other countries. However, the NHI is a pay-as-you-go system. The aim is for the premium income to pay costs. The system is also subsidized by a tobacco tax surcharge and contributions from the national lottery.\nSee also.\nTopics on status quo in health care.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReform.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "13251", "revid": "194203", "url": "https://en.wikipedia.org/wiki?curid=13251", "title": "Horse-breaking", "text": ""}
{"id": "13253", "revid": "29463730", "url": "https://en.wikipedia.org/wiki?curid=13253", "title": "Henry Mayhew", "text": "British writer and activist (1812\u20131887)\nHenry Mayhew (25 November 1812 \u2013 25 July 1887) was an English journalist, playwright, and advocate of reform. He was one of the co-founders of the satirical magazine \"Punch\" in 1841, and was the magazine's joint editor, with Mark Lemon, in its early days. He is also known for his work as a social researcher, publishing an extensive series of newspaper articles in the \"Morning Chronicle\" that was later compiled into the three-volume book \"London Labour and the London Poor\" (1851), a groundbreaking and influential survey of the city's poor.\nBiography.\nEarly life.\nHe was born in London, the thirteenth of 17 children to Joshua Mayhew. He was educated at Westminster School before running away from his studies to the sea. He then served with the East India Company as a midshipman on a ship bound for Calcutta. He returned after several years, in 1829, becoming a trainee lawyer in Wales. He left this career to become a freelance journalist. He contributed to \"The Thief\", a readers' digest, followed quickly by founding a weekly comic journal \u2013 \"Figaro in London\" (1831\u20131839). Mayhew reputedly fled his creditors and holed up at the Erwood Inn, a small public house in the village of Erwood, south of Builth Wells in Wales.\nParis and writing.\nIn 1835, Mayhew found himself in a state of debt and, along with a fellow writer, escaped to Paris to avoid his creditors. He spent his time writing and in the company of other writers including William Thackeray and Douglas Jerrold. Mayhew spent over 10 years in Paris, returning to England in the 1850s, whereupon he was involved in several literary adventures, mostly the writing of plays. Two of his plays \u2013 \"The\" \"Wandering Minstrel\" (1834) and \"But, However\" (1842) \u2013 were successful, whilst his early work \"Figaro in London\" was less successful.\n\"Punch\" magazine.\nOn 17 July 1841, Mayhew cofounded \"Punch \"magazine. At its founding, the magazine was jointly edited by Mayhew and Mark Lemon. The two men hired a group of writers and illustrators to aid them. These included Douglas Jerrold, Angus Reach, John Leech, Richard Doyle, and Shirley Brooks. Initially, the magazine was subtitled \"The London Charivari\", referencing the satirical humour magazine published in France under the title \"Le Charivari\" (a work Mayhew read often whilst in Paris). Reflecting their satirical and humorous intent, the two editors took for their name and masthead the anarchic glove puppet Mr. Punch.\n\"Punch\" was an unexpected success, selling about 6,000 copies a week in the early years. However, sales of as many as 10,000 issues a week were required to cover all costs of the magazine. In December 1842, the magazine was sold to Bradbury and Evans; Mayhew resigned as joint editor, and he continued at the magazine as \"suggestor in chief\" with Mark Lemon reappointed as editor. Mayhew eventually severed his connection with the magazine, writing his last article in February 1845. His brother Horace stayed on the board of Punch until his own death.\nThe \"Punch\" years gave Mayhew the opportunity to meet talented illustrators whom he later employed to work from daguerreotypes on \"London Labour and the London Poor\". Following \"Punch\", Mayhew launched \"Iron Times\", a railway magazine. However, this venture lost Mayhew so much money that he was forced to appear in a court of bankruptcy in 1846.\nFormative work.\nIn 1842, Mayhew contributed to the pioneering \"Illustrated London News\". By this time, he had become reasonably secure financially, had settled his debts, and married Jane Jerrold, the daughter of his friend Douglas Jerrold. She lived until 1880.\n\"London Labour and the London Poor\".\nThe articles comprising \"London Labour and the London Poor\" were initially collected into three volumes in 1851; the 1861 edition included a fourth volume, co-written with Bracebridge Hemyng, John Binny, and Andrew Halliday, on the lives of prostitutes, thieves, and beggars. This extra volume took a more general and statistical approach to its subject than volumes one to three.\nMayhew wrote in volume one: \"I shall consider the whole of the metropolitan poor under three separate phases, according as they \"will\" work, they \"can't\" work, and they \"won't\" work\". He interviewed everyone \u2013 beggars, street-entertainers (such as Punch and Judy men), market traders, prostitutes, labourers, sweatshop workers, even down to the \"mudlarks\" who searched the stinking mud on the banks of the River Thames for wood, metal, rope, and coal from passing ships, and the \"pure-finders\" who gathered dog faeces to sell to tanners. He described their clothes, how and where they lived, their entertainments and customs, and made detailed estimates of the numbers and incomes of those practising each trade. The books show how marginal and precarious many people's lives were, in what, at that time, was the richest city in the world.\nMayhew's richly detailed descriptions give an impression of what the street markets of his day were like. An example from volume one:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The pavement and the road are crowded with purchasers and street-sellers. The housewife in her thick shawl, with the market-basket on her arm, walks slowly on, stopping now to look at the stall of caps, and now to cheapen a bunch of greens. Little boys, holding three or four onions in their hand, creep between the people, wriggling their way through every interstice, and asking for custom in whining tones, as if seeking charity. Then the tumult of the thousand different cries of the eager dealers, all shouting at the top of their voices, at one and the same time, is almost bewildering. \"So-old again,\" roars one. \"Chestnuts all'ot, a penny a score,\" bawls another. \"An 'aypenny a skin, blacking,\" squeaks a boy. \"Buy, buy, buy, buy, buy\u2013 bu-u-uy!\" cries the butcher. \"Half-quire of paper for a penny,\" bellows the street stationer. \"An 'aypenny a lot ing-uns.\" \u201cTwopence a pound grapes.\" \u201cThree a penny Yarmouth bloaters.\" \u201cWho'll buy a bonnet for fourpence?\" \u201cPick 'em out cheap here! three pair for a halfpenny, bootlaces.\" \u201cNow's your time! beautiful whelks, a penny a lot.\" \u201cHere's ha'p\u2018orths,\" shouts the perambulating confectioner. \"Come and look at 'em! here's toasters!\" bellows one with a Yarmouth bloater stuck on a toasting fork. \"Penny a lot, fine russets,\" calls the apple woman: and so the Babel goes on.\nSome of the London street traders did not like the way Mayhew wrote about them. In spring/summer 1851, they established a Street Trader's Protection Association to guard themselves against the journalist.\nFamily.\nMayhew was the grandfather of Audrey Mayhew Allen (b. 1870), an author of a number of children's stories published in various periodicals, and of \"Gladys in Grammarland\", an imitation of Lewis Carroll's \"Wonderland\" books.\nInfluence.\nMayhew's work was embraced by and was an influence on the Christian Socialists, such as Thomas Hughes, Charles Kingsley, and F. D. Maurice. Radicals also published sizeable excerpts from the reports in the \"Northern Star\", the \"Red Republican\", and other newspapers. The often sympathetic investigations, with their immediacy and unswerving eye for detail, offered unprecedented insights into the condition of the Victorian poor. Alongside the earlier work of Edwin Chadwick, they are also speculated as a decisive influence on the thinking of Charles Dickens\nMayhew's work inspired the script of director Christine Edzard's 1990 film \"The Fool\". Mayhew has appeared as a character in television and radio histories of Victorian London; he was played by Timothy West in the documentary \"London\" (2004), and David Haig in the Afternoon Play \"A Chaos of Wealth and Want\" (2010). In the 2012 novel \"Dodger\" by Terry Pratchett, Mayhew and his wife appear as fictionalised versions of themselves, and he is mentioned in the dedication.\nPublications, plays and public speeches: a select list.\nAlthough Mayhew is most remembered for his works of non-fiction, he also authored many plays, farces, novels, public speeches (many of which have been transcribed and subsequently published) alongside his numerous works of non-fiction and newspaper articles. \nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "13255", "revid": "7903804", "url": "https://en.wikipedia.org/wiki?curid=13255", "title": "Hydrogen", "text": "element with atomic number 1 (H)\nHydrogen is a chemical element; it has the symbolH and atomic number1. It is the lightest and most abundant chemical element in the universe, constituting about 75% of all normal matter. Under standard conditions, hydrogen is a gas of diatomic molecules with the formula, called dihydrogen, or sometimes hydrogen gas, molecular hydrogen, or simply hydrogen. Dihydrogen is colorless, odorless, non-toxic, and highly combustible. Stars, including the Sun, mainly consist of hydrogen in a plasma state, while on Earth, hydrogen is found as the gas (dihydrogen) and in molecules, such as in water and organic compounds. The most common isotope of hydrogen, 1H, consists of one proton, one electron, and no neutrons.\nHydrogen gas was first produced artificially in the 17thcentury by the reaction of acids with metals. Henry Cavendish, in1766\u20131781, identified hydrogen gas as a distinct substance and discovered its property of producing water when burned: this is the origin of hydrogen's name, which means 'water-former' (from , and ). Understanding the colors of light absorbed and emitted by hydrogen was a crucial part of the development of quantum mechanics.\nHydrogen, typically nonmetallic except under extreme pressure, readily forms covalent bonds with most nonmetals, contributing to the formation of compounds like water and various organic substances. Its role is crucial in acid\u2013base reactions, which mainly involve proton exchange among soluble molecules. In ionic compounds, hydrogen can take the form of either a negatively-charged anion, where it is known as hydride, or as a positively-charged cation, , called a proton. Although tightly bonded to water molecules, protons strongly affect the behavior of aqueous solutions, as reflected in the importance of pH. Hydride, on the other hand, is rarely observed because it tends to deprotonate solvents, yielding.\nIn the early universe, neutral hydrogen atoms formed about 370,000 years after the Big Bang as the universe expanded and plasma had cooled enough for electrons to remain bound to protons. After stars began to form, most of the hydrogen in the intergalactic medium was re-ionized.\nNearly all hydrogen production is done by transforming fossil fuels, particularly steam reforming of natural gas. It can also be produced from water or saline by electrolysis, but this process is more expensive. Its main industrial uses include fossil fuel processing and ammonia production for fertilizer. Emerging uses for hydrogen include the use of fuel cells to generate electricity.\n&lt;templatestyles src=\"Template:TOC limit/styles.css\" /&gt;\nProperties.\nAtomic hydrogen.\nElectron energy levels.\nThe ground state energy level of the electron in a hydrogen atom is \u221213.6electronvolts(eV), equivalent to an ultraviolet photon of roughly 91nanometers wavelength. The energy levels of hydrogen are referred to by consecutive quantum numbers, with formula_1 being the ground state. The hydrogen spectral series corresponds to emission of light due to transitions from higher to lower energy levels. Each energy level is further split by spin interactions between the electron and proton into four hyperfine levels.\nHigh-precision values for the hydrogen atom energy levels are required for definitions of physical constants. Quantum calculations have identified nine contributions to the energy levels. The eigenvalue from the Dirac equation is the largest contribution. Other terms include relativistic recoil, the self-energy, and the vacuum polarization terms.\nIsotopes.\nHydrogen has three naturally-occurring isotopes, denoted 1H, 2H and3H. Other, highly-unstable nuclides(4H to 7H) have been synthesized in laboratories but not observed in nature.\n1H is the most common hydrogen isotope, with an abundance of &gt;99.98%. Because the nucleus of this isotope consists of only a single proton, it is given the descriptive but rarely used formal name \"protium\". It is the only stable isotope with no neutrons (&lt;templatestyles src=\"Crossreference/styles.css\" /&gt;).\n2H, the other stable hydrogen isotope, is known as deuterium and contains one proton and one neutron in the nucleus. Nearly all deuterium nuclei in the universe are thought to have been produced in Big Bang nucleosynthesis, and have endured since then.24.2 Deuterium is not radioactive, and is not a significant toxicity hazard. Water enriched in molecules that include deuterium instead of normal hydrogen is called heavy water. Deuterium and its compounds are used as a non-radioactive label in chemical experiments and in solvents for 1H-NMR spectroscopy. Heavy water is used as a neutron moderator and coolant for nuclear reactors. Deuterium is also a potential fuel for commercial nuclear fusion.\n3H is known as tritium and contains one proton and two neutrons in its nucleus. It is radioactive, decaying into helium-3 through beta decay with a half-life of 12.32years. It is radioactive enough to be used in luminous paint to enhance the visibility of data displays, such as for painting the hands and dial-markers of watches. The watch glass prevents the small amount of radiation from escaping the case. Small amounts of tritium are produced naturally by cosmic rays striking atmospheric gases; tritium has also been released in nuclear weapons tests. It is used in nuclear fusion, as a tracer in isotope geochemistry, and in specialized self-powered lighting devices. Tritium has also been used in chemical and biological labeling experiments as a radiolabel.\nUnique among the elements, distinct names are assigned to hydrogen's isotopes in common use. During the early study of radioactivity, heavy radioisotopes were given their own names, but these are mostly no longer used. The symbols D andT (instead of 2H and 3H) are sometimes used for deuterium and tritium, but the symbolP was already used for phosphorus and thus was not available for protium. In its nomenclatural guidelines, the International Union of Pure and Applied Chemistry(IUPAC) allows any of D, T, 2H, and 3H to be used, though 2H and 3H are preferred.\nAntihydrogen (H) is the antimatter counterpart to hydrogen. It consists of an with a positron. The exotic atom muonium (symbol Mu), composed of an antimuon and an electron, is the analogue of hydrogen; IUPACnomenclature incorporates such hypothetical compounds as muonium chloride(MuCl) and sodium muonide(NaMu), analogous to hydrogen chloride and sodium hydride respectively.\nDihydrogen.\nUnder standard conditions, hydrogen is a gas of diatomic molecules with the formula, officially called \"dihydrogen\", but also called \"molecular hydrogen\", or simply hydrogen. Dihydrogen is a colorless, odorless, flammable gas.\nCombustion.\nHydrogen gas is highly flammable, reacting with oxygen in air to produce liquid water:\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\nThe amount of heat released per mole of hydrogen is (kJ), or (MJ) for a mass.\nHydrogen gas forms explosive mixtures with air in concentrations from and with chlorine at . The hydrogen autoignition temperature, the temperature of spontaneous ignition in air, is . In a high-pressure hydrogen leak, the shock wave from the leak itself can heat air to the autoignition temperature, leading to flaming and possibly explosion.\nHydrogen flames emit faint blue and ultraviolet light. Flame detectors are used to detect hydrogen fires as they are nearly invisible to the naked eye in daylight.\nSpin isomers.\nMolecular exists as two nuclear isomers that differ in the spin states of their nuclei. In the ' form, the spins of the two nuclei are parallel, forming a spin triplet state having a total molecular spin formula_2; in the ' form the spins are and form a spin singlet state having spin formula_3. The equilibrium ratio of ortho- to para-hydrogen depends on temperature. At room temperature or warmer, equilibrium hydrogen gas contains about 25% of the para form and 75% of the ortho form. The ortho form is an excited state, having higher energy than the para form by , and it converts to the para form over the course of several minutes when cooled to low temperature. The thermal properties of these isomers differ because each has distinct rotational quantum states.\nThe ortho-to-para ratio in is an important consideration in the liquefaction and storage of liquid hydrogen: the conversion from ortho to para is exothermic, and produces sufficient heat to evaporate most of the liquid if the conversion to does not occur during the cooling process. Catalysts for the ortho-para , such as ferric oxide and activated carbon compounds, are therefore used during hydrogen cooling to avoid this loss of liquid.\nPhases.\nLiquid hydrogen can exist at temperatures below hydrogen's critical point of . However, for it to be in a fully liquid state at atmospheric pressure, H2 needs to be cooled to . Hydrogen was liquefied by James Dewar in1898 by using regenerative cooling and his invention, the vacuum flask.\nLiquid hydrogen becomes solid hydrogen at standard pressure below hydrogen's melting point of . Distinct solid phases exist, known as PhaseI through PhaseV, each exhibiting a characteristic molecular arrangement. Liquid and solid phases can exist in combination at the triple point; this mixture is known as slush hydrogen.\nMetallic hydrogen, a phase obtained at extremely high pressures (in excess of ), is an electrical conductor. It is believed to exist deep within giant planets like Jupiter.\nWhen ionized, hydrogen becomes a plasma. This is the form in which hydrogen exists within stars.\nHistory.\n18th century.\nIn 1671, Irish scientist Robert Boyle discovered and described the reaction between iron filings and dilute acids, which results in the production of hydrogen gas.\nBoyle did not note that the gas was flammable, but hydrogen would play a key role in overturning the phlogiston theory of combustion.\nIn 1766, Henry Cavendish was the first to recognize hydrogen gas as a discrete substance, by naming the gas from a metal-acid reaction \"inflammable air\". He speculated that \"inflammable air\" was in fact identical to the hypothetical substance \"phlogiston\" and further finding in1781 that the gas produces water when burned. He is usually given credit for the discovery of hydrogen as an element.\nIn 1783, identified the element that came to be known as hydrogen when he and reproduced Cavendish's finding that water is produced when hydrogen is burned. produced hydrogen for his experiments on mass conservation by treating metallic iron with a stream of water through an incandescent iron tube heated in a fire. Anaerobic oxidation of iron by the protons of water at high temperature can be schematically represented by the set of following reactions:\nMany metals react similarly with water, leading to the production of hydrogen. In some situations, this H2-producing process is problematic, for instance in the case of zirconium cladding on nuclear fuel rods.\n19th century.\nBy 1806 hydrogen was used to fill balloons.\n built the first engine, an internal combustion engine powered by a mixture of hydrogen and oxygen, in1806. Edward Daniel Clarke invented the hydrogen gas blowpipe in1819. The 's lamp and limelight were invented in1823. Hydrogen was liquefied for the first time by James Dewar in1898 by using regenerative cooling and his invention, the vacuum flask. He produced solid hydrogen the next year.\nOne of the first quantum effects to be explicitly noticed, although not understood at the time, was James Clerk Maxwell's observation that the specific heat capacity of unaccountably departs from that of a diatomic gas below room temperature, and begins to increasingly resemble that of a monatomic gas at cryogenic temperatures. According to quantum theory, this behavior arises from the spacing of the (quantized) rotational energy levels, which are particularly wide-spaced in because of its low mass. These widely-spaced levels inhibit equal partition of heat energy into rotational motion in hydrogen at low temperatures. Diatomic gases composed of heavier atoms do not have such widely spaced levels and do not exhibit the same effect.\n20th century.\nThe existence of the hydride anion was suggested by GilbertN. Lewis in1916 for group1 and group2 salt-like compounds. In1920, electrolyzed molten lithium hydride(LiH), producing a stoichiometric quantity of hydrogen at the anode.\nBecause of its simple atomic structure, consisting only of a proton and an electron, the hydrogen atom, together with the spectrum of light produced from it or absorbed by it, has been central to the development of the theory of atomic structure. The energy levels of hydrogen can be calculated fairly accurately using the model of the atom, in which the electron \"orbits\" the proton, like how Earth orbits the Sun. However, the electron and proton are held together by electrostatic attraction, while planets and celestial objects are held by gravity. Due to the discretization of angular momentum postulated in early quantum mechanics by , the electron in the model can only occupy certain allowed distances from the proton, and therefore only certain allowed energies.\nHydrogen's unique position as the only neutral atom for which the equation can be directly solved, has significantly contributed to the understanding of quantum mechanics through the exploration of its energetics. Furthermore, study of the corresponding simplicity of the hydrogen molecule and the corresponding cation, , brought understanding of the nature of the chemical bond, which followed shortly after the quantum mechanical treatment of the hydrogen atom had been developed in the mid-1920s.\nHydrogen-lifted airship.\nBecause has only 7% the density of air, it was once widely used as a lifting gas in balloons and airships. The first hydrogen-filled balloon was invented by in1783. Hydrogen provided the lift for the first reliable form of air-travel following the1852 invention of the first hydrogen-lifted airship by . German count promoted the idea of rigid airships lifted by hydrogen that later were called , the first of which had its maiden flight in1900. Regularly-scheduled flights started in1910 and by the outbreak of World WarI in August1914, they had carried 35,000 passengers without a serious incident. Hydrogen-lifted airships in the form of blimps were used as observation platforms and bombers during World WarII, especially on the USEastern seaboard.\nThe first non-stop transatlantic crossing was made by the British airship\"R34\" in1919 and regular passenger service resumed in the1920s. Hydrogen was used in the , which caught fire over New Jersey on 6May 1937. The hydrogen that filled the airship was ignited, possibly by static electricity, and burst into flames. Following this disaster, commercial hydrogen airship travel ceased. Hydrogen is still used, in preference to non-flammable but more expensive helium, as a lifting gas for weather balloons.\nDeuterium and tritium.\nDeuterium was discovered in December1931 by Harold Urey, and tritium was prepared in1934 by Ernest Rutherford, Mark Oliphant, and Paul Harteck. Heavy water, which consists of deuterium in the place of regular hydrogen, was discovered by Urey's group in1932.\nChemistry.\nReactions of H2.\n is relatively unreactive. The thermodynamic basis of this low reactivity is the very strong H\u2013H bond, with a bond dissociation energy of . It does form coordination complexes called dihydrogen complexes. These species provide insights into the early steps in the interactions of hydrogen with metal catalysts. According to neutron diffraction, the metal and two Hatoms form a triangle in these complexes. The H-H bond remains intact but is elongated. They are acidic.\nAlthough exotic on Earth, the ion is common in the universe. It is a triangular species, like the aforementioned dihydrogen complexes. It is known as protonated molecular hydrogen or the trihydrogen cation.\nHydrogen reacts with chlorine to produceHCl, and with bromine to produceHBr, via a chain reaction. The reaction requires initiation. For example, in the case of Br2, the dibromine molecule is split apart: . Propagating reactions consume hydrogen molecules and produceHBr, as well as Brand Hatoms: \n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\nFinally the terminating reaction:\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\nconsumes the remaining atoms.\nThe addition of H2 to unsaturated organic compounds, such as alkenes and alkynes, is called hydrogenation. Even if the reaction is energetically favorable, it does not occur spontaneously even at higher temperatures. In the presence of a catalyst like finely divided platinum or nickel, the reaction proceeds at room temperature.\nHydrogen-containing compounds.\nHydrogen can exist in both +1 and \u22121oxidation states, forming compounds through ionic and covalent bonding. The element is part of a wide range of substances, including water, hydrocarbons, and numerous other organic compounds. The H+ion\u2014commonly referred to as a proton due to its single proton and absence of electrons\u2014is central to acid\u2013base chemistry, although the proton does not move freely. In the \u2013Lowry framework, acids are defined by their ability to donate H+ions to bases.\nHydrogen forms a vast variety of compounds with carbon, known as hydrocarbons, and an even greater diversity with other elements (heteroatoms), giving rise to the broad class of organic compounds often associated with living organisms.\nHydrogen compounds with hydrogen in the oxidation state\u22121 are known as hydrides, which are usually formed between hydrogen and metals. The hydrides can be ionic (aka saline), covalent, or metallic. With heating, H2 reacts efficiently with the alkali and alkaline earth metals to give the ionic hydrides of the formulasMH and MH2, respectively. These salt-like crystalline compounds have high melting points and all react with water to liberate hydrogen. Covalent hydrides include boranes and polymeric aluminium hydride. Transition metals form metal hydrides via continuous dissolution of hydrogen into the metal. A well-known hydride is lithium aluminium hydride: the anion carries hydridic centers firmly attached to the Al(III). Perhaps the most extensive series of hydrides are the boranes, compounds consisting only of boron and hydrogen.\nHydrides can bond to these electropositive elements not only as a terminal ligand but also as bridging ligands. In diborane(), four hydrogen atoms are terminal, while two bridge between the two boron atoms.\nHydrogen bonding.\nWhen bonded to a more electronegative element, particularly fluorine, oxygen, or nitrogen, hydrogen can participate in a form of medium-strength noncovalent bonding with another electronegative element with a lone pair like oxygen or nitrogen. This phenomenon, called hydrogen bonding, is critical to the stability of many biological molecules. Hydrogen bonding alters molecule structures, viscosity, solubility, melting and boiling points, and even protein folding dynamics.\nProtons and acids.\nIn water, hydrogen bonding plays an important role in reaction thermodynamics. A hydrogen bond can shift over to proton transfer.\nUnder the \u2013Lowry acid\u2013base theory, acids are proton donors, while bases are proton acceptors.28\nA bare proton() essentially cannot exist in anything other than a vacuum. Otherwise it attaches to other atoms, ions, or molecules. Even chemical species as inert as methane can be protonated. The term \"proton\" is used loosely and metaphorically to refer to solvated hydrogen cations attached to other solvated chemical species; it is denoted\"\" without any implication that any single protons exist freely in solution as a species. To avoid the implication of the naked proton in solution, acidic aqueous solutions are sometimes considered to contain the \"hydronium ion\"(), or still more accurately, . Other oxonium ions are found when water is in acidic solution with other solvents.\nThe concentration of these solvated protons determines the pH of a solution, a logarithmic scale that reflects its acidity or basicity. Lower pHvalues indicate higher concentrations of hydronium ions, corresponding to more acidic conditions.\nOccurrence.\nCosmic.\nHydrogen, as atomic H, is the most abundant chemical element in the universe, making up 75% of normal matter by mass. and &gt;90% by number of atoms. In the early universe, protons formed in the first second after the Big Bang; neutral hydrogen atoms formed about 370,000years later during the recombination epoch as the universe expanded and plasma had cooled enough for electrons to remain bound to protons.\nIn astrophysics, neutral hydrogen in the interstellar medium is called \"HI\" and ionized hydrogen is called \"HII\". Radiation from stars ionizes HI to HII, creating spheres of ionized HII around stars. In the chronology of the universe neutral hydrogen dominated until the birth of stars during the era of reionization, which then produced bubbles of ionized hydrogen that grew and merged over hundreds of millions of years.\nThese are the source of the 21-centimeter hydrogen line, at , that is detected in order to probe primordial hydrogen. The large amount of neutral hydrogen found in the damped Lyman-alpha systems is thought to dominate the cosmological baryonic density of the universe up to a redshift of \"z\" \n 4.\nHydrogen is found in great abundance in stars and gas giant planets. Molecular clouds of are associated with star formation. Hydrogen plays a vital role in powering stars through the proton-proton reaction in lower-mass stars, and through the CNOcycle of nuclear fusion in stars more massive than the Sun.\nProtonated molecular hydrogen() is found in the interstellar medium, where it is generated by ionization of molecular hydrogen by cosmic rays. This ion has also been observed in the upper atmosphere of Jupiter. The ion is long-lived in outer space due to the low temperature and density. is one of the most abundant ions in the universe, and it plays a notable role in the chemistry of the interstellar medium. Neutral triatomic hydrogen can exist only in an excited form and is unstable.\nTerrestrial.\nHydrogen is the third most abundant element on the Earth's surface, mostly existing within chemical compounds such as hydrocarbons and water. Elemental hydrogen is normally in the form of a gas, , at standard conditions. It is present in a very low concentration in Earth's atmosphere (around on a molar basis) because of its light weight, which enables it to escape the atmosphere more rapidly than heavier gases. Despite its low concentration in the atmosphere, terrestrial hydrogen is sufficiently abundant to support the metabolism of several varieties of bacteria.\nLarge underground deposits of hydrogen gas have been discovered in several countries including Mali, France and Australia. As of 2024, it is uncertain how much underground hydrogen can be extracted economically.\nProduction and storage.\nIndustrial routes.\nNearly all of the world's current supply of hydrogen gas() is produced from fossil fuels. Many methods exist for producing H2, but three dominate commercially: steam reforming often coupled to water-gas shift, partial oxidation of hydrocarbons, and water electrolysis.\nSteam reforming.\nHydrogen is mainly produced by steam methane reforming(SMR), the reaction of water and methane. Thus, at high temperature (), steam (water vapor) reacts with methane to yield carbon monoxide and.\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\nProducing one tonne of hydrogen through this process emits tonnes of carbon dioxide. The production of natural gas feedstock also produces emissions such as vented and fugitive methane, which further contributes to the overall carbon footprint of hydrogen.\nThis reaction is favored at low pressures but is nonetheless conducted at high pressures() because high-pressure is the most marketable product, and pressure swing adsorption(PSA) purification systems work better at higher pressures. The product mixture is known as \"synthesis gas\" because it is often used directly for the production of methanol and many other compounds. Hydrocarbons other than methane can be used to produce synthesis gas with varying product ratios. One of the many complications to this highly-optimized technology is the formation of coke or carbon:\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\nTherefore, steam reforming typically employs an excess of. Additional hydrogen can be recovered from the steam by using carbon monoxide through the water gas shift reaction(WGS). This process requires an iron oxide catalyst:\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\nHydrogen is sometimes produced and consumed in the same industrial process, without being separated. In the process for ammonia production, hydrogen is generated from natural gas.\nPartial oxidation of hydrocarbons.\nOther methods for CO and production include partial oxidation of hydrocarbons:\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\nAlthough less important commercially, coal can serve as a prelude to the above shift reaction:\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\nOlefin production units may produce substantial quantities of byproduct hydrogen, particularly from cracking light feedstocks like ethane or propane.\nWater electrolysis.\nElectrolysis of water is a conceptually simple method of producing hydrogen. \n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\nCommercial electrolyzers use nickel-based catalysts in strongly alkaline solution. Platinum is a better catalyst but is expensive. The hydrogen created through electrolysis using renewable energy is commonly referred to as \"green hydrogen\".\nElectrolysis of brine to yield chlorine also produces high-purity hydrogen as a co-product, which is used for a variety of transformations such as hydrogenations.\nThe electrolysis process is more expensive than producing hydrogen from methane without carbon capture and storage.\nInnovation in hydrogen electrolyzers could make large-scale production of hydrogen from electricity more cost-competitive.\nMethane pyrolysis.\nHydrogen can be produced by pyrolysis of natural gas (methane), producing hydrogen gas and solid carbon with the aid of a catalyst and input heat:\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt; (\u0394\"H\"\u00b0 \n 74 kJ/mol)\nThe carbon may be sold as a manufacturing feedstock or fuel, or landfilled. This route could have a lower carbon footprint than existing hydrogen production processes, but mechanisms for removing the carbon and preventing it from reacting with the catalyst remain obstacles for industrial-scale use.\nThermochemical.\nWater splitting is the process by which water is decomposed into its components. Relevant to the biological scenario is this equation:\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\nThe reaction occurs in the light-dependent reactions in all photosynthetic organisms. A few organisms, including the alga and cyanobacteria, have evolved a second step in the dark reactions in which protons and electrons are reduced to form gas by specialized hydrogenases in the chloroplast.\nEfforts have been undertaken to genetically modify cyanobacterial hydrogenases to more efficiently generate gas even in the presence of oxygen. Efforts have also been undertaken with genetically\u2010modified alga in a bioreactor.\nRelevant to the thermal water-splitting scenario is this simple equation:\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\nOver 200 thermochemical cycles can be used for water splitting. Many of these cycles such as the iron oxide cycle, cerium(IV) oxide\u2013cerium(III) oxide cycle, zinc\u2013zinc oxide cycle, sulfur\u2013iodine cycle, copper\u2013chlorine cycle and hybrid sulfur cycle have been evaluated for their commercial potential to produce hydrogen and oxygen from water and heat without using electricity. A number of labs (including in France, Germany, Greece, Japan, and the United States) are developing thermochemical methods to produce hydrogen from solar energy and water.\nNatural routes.\nBiohydrogen.\n is produced in organisms by enzymes called hydrogenases. This process allows the host organism to use fermentation as a source of energy. These same enzymes also can oxidizeH2, such that the host organisms can subsist by reducing oxidized substrates using electrons extracted fromH2.\nHydrogenase enzymes feature iron or iron\u2013nickel centers at their active sites. The natural cycle of hydrogen production and consumption by organisms is called the hydrogen cycle.\nSome bacteria such as can use the small amount of hydrogen in the atmosphere as a source of energy when other sources are lacking. Their hydrogenases feature small channels that exclude oxygen from the active site, permitting the reaction to occur even though the hydrogen concentration is very low and the oxygen concentration is as in normal air.\nConfirming the existence of hydrogenase\u2010employing microbes in the human gut, occurs in human breath. The concentration in the breath of fasting people at rest is typically under (ppm), but can reach when people with intestinal disorders consume molecules they cannot absorb during diagnostic hydrogen breath tests.\nSerpentinization.\nSerpentinization is a geological mechanism which produces highly-reducing conditions. Under these conditions, water is capable of oxidizing ferrous(Fe2+) ions in fayalite, generating hydrogen gas:\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\nClosely related to this geological process is the reaction:\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\nThis process also is relevant to the corrosion of iron and steel in oxygen-free groundwater and in reducing soils below the water table.\nLaboratory syntheses.\n is produced in laboratory settings, such as in the small-scale electrolysis of water using metal electrodes and water containing an electrolyte, which liberates hydrogen gas at the cathode:\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\nHydrogen is also often a by-product of other reactions. Many metals react with water to produce, but the rate of hydrogen evolution depends on the metal, the pH, and the presence of alloying agents. Most often, hydrogen evolution is induced by acids. The alkali and alkaline earth metals as well as aluminium, zinc, manganese, and iron, react readily with aqueous acids.\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\nMany metals, such as aluminium, are slow to react with water because they form passivated oxide coatings. An alloy of aluminium and gallium, however, does react with water. In high-pH solutions, aluminium can react with :\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\nStorage.\nIf H2 is to be used as an energy source, its storage is important. It dissolves only poorly in solvents. For example, at room temperature and , &lt;templatestyles src=\"Template:Tooltip/styles.css\" /&gt; of hydrogen dissolve into of diethyl ether. H2 can be stored in compressed form, although compressing costs energy. Liquefaction is impractical given hydrogen's low critical temperature. In contrast, ammonia and many hydrocarbons can be liquified at room temperature under pressure. For these reasons, hydrogen \"carriers\"\u2014materials that reversibly bindH2\u2014have attracted much attention. The key question is then the weight percent of H2-equivalents within the carrier material. For example, hydrogen can be reversibly absorbed into many rare earths and transition metals and is soluble in both nanocrystalline and amorphous metals. Hydrogen solubility in metals is influenced by local distortions or impurities in the crystal lattice. These properties may be useful when hydrogen is purified by passage through hot palladium disks, but the gas's high solubility is also a metallurgical problem, contributing to the embrittlement of many metals, complicating the design of pipelines and storage tanks.\nThe most problematic aspect of metal hydrides for storage is their modest H2content, often on the order of1%. For this reason, there is interest in storage of H2 in compounds of low molecular weight. For example, ammonia borane () contains 19.8weight percent ofH2. The problem with this material is that after release of H2, the resulting boron nitride does not re-add H2: i.e., ammonia borane is an irreversible hydrogen carrier. More attractive are hydrocarbons such as tetrahydroquinoline, which reversibly release someH2 when heated in the presence of a catalyst:\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\nApplications.\nPetrochemical industry.\nLarge quantities of are used in the \"upgrading\" of fossil fuels. Key consumers of include hydrodesulfurization and hydrocracking. Many of these reactions can be classified as hydrogenolysis, i.e., the cleavage of bonds by hydrogen. Illustrative is the separation of sulfur from liquid fossil fuels:\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\nHydrogenation.\nHydrogenation, the addition of to various substrates, is done on a large scale. Hydrogenation of produces ammonia by the process:\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\nThis process consumes a few percent of the energy budget in the entire industry and is the biggest consumer of hydrogen. The resulting ammonia is used extensively in fertilizer production; these fertilizers have become essential feedstocks in modern agriculture. Hydrogenation is also used to convert unsaturated fats and oils to saturated fats and oils. The major application is the production of margarine. Methanol is produced by hydrogenation of carbon dioxide; the mixture of hydrogen and carbon dioxide used for this process is known as syngas. It is similarly the source of hydrogen in the manufacture of hydrochloric acid. is also used as a reducing agent for the conversion of some ores to the metals.\nFuel.\nThe potential for using hydrogen(H2) as a fuel has been widely discussed. Hydrogen can be used in fuel cells to produce electricity, or burned to generate heat. When hydrogen is consumed in fuel cells, the only emission at the point of use is water vapor. When burned, hydrogen produces relatively little pollution at the point of combustion, but can lead to thermal formation of harmful nitrogen oxides.\nIf hydrogen is produced with low or zero greenhouse gas emissions (green hydrogen), it can play a significant role in decarbonizing energy systems where there are challenges and limitations to replacing fossil fuels with direct use of electricity.\nHydrogen fuel can produce the intense heat required for industrial production of steel, cement, glass, and chemicals, thus contributing to the decarbonization of industry alongside other technologies, such as electric arc furnaces for steelmaking. However, it is likely to play a larger role in providing industrial feedstock for cleaner production of ammonia and organic chemicals. For example, in steelmaking, hydrogen could function as a clean fuel and also as a low-carbon catalyst, replacing coal-derived coke (carbon):\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;vs\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\nHydrogen used to decarbonize transportation is likely to find its largest applications in shipping, aviation and, to a lesser extent, heavy goods vehicles, through the use of hydrogen-derived synthetic fuels such as ammonia and methanol and fuel cell technology. For light-duty vehicles including cars, hydrogen is far behind other alternative fuel vehicles, especially compared with the rate of adoption of battery electric vehicles, and may not play a significant role in future.\nLiquid hydrogen and liquid oxygen together serve as cryogenic propellants in liquid-propellant rockets, as in the Space Shuttle main engines. NASA has investigated the use of rocket propellant made from atomic hydrogen, boron or carbon that is frozen into solid molecular hydrogen particles suspended in liquid helium. Upon warming, the mixture vaporizes to allow the atomic species to recombine, heating the mixture to high temperature.\nHydrogen produced when there is a surplus of variable renewable electricity could in principle be stored and later used to generate heat or to re-generate electricity. It can be further transformed into synthetic fuels such as ammonia and methanol. Disadvantages of hydrogen fuel include high costs of storage and distribution due to hydrogen's explosivity, its large volume compared to other fuels, and its tendency to embrittle materials.\nNickel\u2013hydrogen battery.\nThe very long-lived, rechargeable nickel\u2013hydrogen battery developed for satellite power systems uses pressurized gaseousH2. The International Space Station, Mars Odyssey and the Mars Global Surveyor are equipped with nickel-hydrogen batteries. In the dark part of its orbit, the Hubble Space Telescope is also powered by nickel-hydrogen batteries, which were finally replaced in May2009, more than 19years after launch and 13years beyond their design life.\nSemiconductor industry.\nHydrogen is employed in semiconductor manufacturing to saturate broken (\"dangling\") bonds of amorphous silicon and amorphous carbon, which helps in stabilizing the materials' properties. Hydrogen, introduced as an unintended side-effect of production, acts as a shallow electron donor leading to n-type conductivity in ZnO, with important uses in transducers and phosphors. Detailed analysis of ZnO and of MgO shows evidence of four and six-fold hydrogen multicentre bonds.\nThe doping behavior of hydrogen varies with material.\nNiche and evolving uses.\nBeyond than the uses mentioned above, hydrogen is used in smaller scales in the following applications:\nSafety and precautions.\n&lt;templatestyles src=\"Chembox/styles.css\"/&gt;\nChemical compound\nIn hydrogen pipelines and steel storage vessels, hydrogen molecules are prone to reacting with metals, causing hydrogen embrittlement and leaks in the pipeline or storage vessel. Since it is lighter than air, hydrogen does not easily accumulate to form a combustible gas mixture. However, even without ignition sources, high-pressure hydrogen leakage may cause spontaneous combustion and detonation.\nHydrogen is flammable when mixed even in small amounts with air. Ignition can occur at a volumetric ratio of hydrogen to air as low as 4%. In approximately 70% of hydrogen ignition accidents, the ignition source cannot be found, and it is widely believed by scholars that spontaneous ignition of hydrogen occurs.\nHydrogen fire, while being extremely hot, is almost invisible to the human eye, and thus can lead to accidental burns. Hydrogen is non-toxic, but like most gases it can cause asphyxiation in the absence of adequate ventilation.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "13256", "revid": "7903804", "url": "https://en.wikipedia.org/wiki?curid=13256", "title": "Helium", "text": "element with atomic number 2 (He)\nHelium (from ) is a chemical element; it has symbol He and atomic number 2. It is a colorless, odorless, non-toxic, inert, monatomic gas and the first in the noble gas group in the periodic table. Its boiling point is the lowest among all the elements, and it does not have a melting point at standard pressures. It is the second-lightest and second-most abundant element in the observable universe, after hydrogen. It is present at about 24% of the total elemental mass, which is more than 12 times the mass of all the heavier elements combined. Its abundance is similar to this in both the Sun and Jupiter, because of the very high nuclear binding energy (per nucleon) of helium-4 with respect to the next three elements after helium. This helium-4 binding energy also accounts for why it is a product of both nuclear fusion and radioactive decay. The most common isotope of helium in the universe is helium-4, the vast majority of which was formed during the Big Bang. Large amounts of new helium are created by nuclear fusion of hydrogen in stars.\nHelium was first detected as an unknown, yellow spectral line signature in sunlight during a solar eclipse in 1868 by Georges Rayet, Captain C. T. Haig, Norman R. Pogson, and Lieutenant John Herschel, and was subsequently confirmed by French astronomer Jules Janssen. Janssen is often jointly credited with detecting the element, along with Norman Lockyer. Janssen recorded the helium spectral line during the solar eclipse of 1868, while Lockyer observed it from Britain. However, only Lockyer proposed that the line was due to a new element, which he named after the Sun. The formal discovery of the element was made in 1895 by chemists Sir William Ramsay, Per Teodor Cleve, and Nils Abraham Langlet, who found helium emanating from the uranium ore cleveite, which is now not regarded as a separate mineral species, but as a variety of uraninite. In 1903, large reserves of helium were found in natural gas fields in parts of the United States, by far the largest supplier of the gas today.\nLiquid helium is used in cryogenics (its largest single use, consuming about a quarter of production), and in the cooling of superconducting magnets, with its main commercial application in MRI scanners. Helium's other industrial uses\u2014as a pressurizing and purge gas, as a protective atmosphere for arc welding, and in processes such as growing crystals to make silicon wafers\u2014account for half of the gas produced. A small but well-known use is as a lifting gas in balloons and airships. As with any gas whose density differs from that of air, inhaling a small volume of helium temporarily changes the timbre and quality of the human voice. In scientific research, the behavior of the two fluid phases of helium-4 (helium\u00a0I and helium\u00a0II) is important to researchers studying quantum mechanics (in particular the property of superfluidity) and to those looking at the phenomena, such as superconductivity, produced in matter near absolute zero.\nOn Earth, it is relatively rare\u20145.2 ppm by volume in the atmosphere. Most terrestrial helium present today is created by the natural radioactive decay of heavy radioactive elements (thorium and uranium, although there are other examples), as the alpha particles emitted by such decays consist of helium-4 nuclei. This radiogenic helium is trapped with natural gas in concentrations as great as 7% by volume, from which it is extracted commercially by a low-temperature separation process called fractional distillation. Terrestrial helium is a non-renewable resource because once released into the atmosphere, it promptly escapes into space. Its supply is thought to be rapidly diminishing. However, some studies suggest that helium produced deep in the Earth by radioactive decay can collect in natural gas reserves in larger-than-expected quantities, in some cases having been released by volcanic activity.\nHistory.\nScientific discoveries.\nThe first evidence of helium was observed on August 18, 1868, as a bright yellow line with a wavelength of 587.49 nanometers in the spectrum of the chromosphere of the Sun. The line was detected by French astronomer Jules Janssen during a total solar eclipse in Guntur, India. This line was initially assumed to be sodium. On October 20 of the same year, English astronomer Norman Lockyer observed a yellow line in the solar spectrum, which he named the D3 because it was near the known D1 and D2 Fraunhofer lines of sodium. He concluded that it was caused by an element in the Sun unknown on Earth. Lockyer named the element with the Greek word for the Sun, \u1f25\u03bb\u03b9\u03bf\u03c2 (\"helios\"). It is sometimes said that English chemist Edward Frankland was also involved in the naming, but this is unlikely as he doubted the existence of this new element. The ending \"-ium\" is unusual, as it normally applies only to metallic elements; probably Lockyer, being an astronomer, was unaware of the chemical conventions.\nIn 1881, Italian physicist Luigi Palmieri detected helium on Earth for the first time through its D3 spectral line, when he analyzed a material that had been sublimated during a recent eruption of Mount Vesuvius.\nOn March 26, 1895, Scottish chemist Sir William Ramsay isolated helium on Earth by treating the mineral cleveite (a variety of uraninite with at least 10% rare-earth elements) with mineral acids. Ramsay was looking for argon but, after separating nitrogen and oxygen from the gas, liberated by sulfuric acid, he noticed a bright yellow line that matched the D3 line observed in the spectrum of the Sun. These samples were identified as helium by Lockyer and British physicist William Crookes. It was independently isolated from cleveite in the same year by chemists Per Teodor Cleve and Abraham Langlet in Uppsala, Sweden, who collected enough of the gas to accurately determine its atomic weight. Helium was also isolated by American geochemist William Francis Hillebrand prior to Ramsay's discovery, when he noticed unusual spectral lines while testing a sample of the mineral uraninite. Hillebrand, however, attributed the lines to nitrogen. His letter of congratulations to Ramsay offers an interesting case of discovery, and near-discovery, in science.\nIn 1907, Ernest Rutherford and Thomas Royds demonstrated that alpha particles are helium nuclei by allowing the particles to penetrate the thin glass wall of an evacuated tube, then creating a discharge in the tube, to study the spectrum of the new gas inside. In 1908, helium was first liquefied by Dutch physicist Heike Kamerlingh Onnes by cooling the gas to less than . He tried to solidify it by further reducing the temperature but failed, because helium does not solidify at atmospheric pressure. Onnes' student Willem Hendrik Keesom was eventually able to solidify 1\u00a0cm3 of helium in 1926 by applying additional external pressure.\nIn 1913, Niels Bohr published his \"trilogy\" on atomic structure that included a reconsideration of the Pickering\u2013Fowler series as central evidence in support of his model of the atom. This series is named for Edward Charles Pickering, who in 1896 published observations of previously unknown lines in the spectrum of the star \u03b6 Puppis (these are now known to occur with Wolf\u2013Rayet and other hot stars). Pickering attributed the observation (lines at 4551, 5411, and 10123\u00a0\u00c5) to a new form of hydrogen with half-integer transition levels. In 1912, Alfred Fowler managed to produce similar lines from a hydrogen-helium mixture, and supported Pickering's conclusion as to their origin. Bohr's model does not allow for half-integer transitions (nor does quantum mechanics) and Bohr concluded that Pickering and Fowler were wrong, and instead assigned these spectral lines to ionised helium, He+. Fowler was initially skeptical but was ultimately convinced that Bohr was correct, and by 1915 \"spectroscopists had transferred [the Pickering\u2013Fowler series] definitively [from hydrogen] to helium.\" Bohr's theoretical work on the Pickering series had demonstrated the need for \"a re-examination of problems that seemed already to have been solved within classical theories\" and provided important confirmation for his atomic theory.\nIn 1938, Russian physicist Pyotr Leonidovich Kapitsa discovered that helium-4 has almost no viscosity at temperatures near absolute zero, a phenomenon now called superfluidity. This phenomenon is related to Bose\u2013Einstein condensation. In 1972, the same phenomenon was observed in helium-3, but at temperatures much closer to absolute zero, by American physicists Douglas D. Osheroff, David M. Lee, and Robert C. Richardson. The phenomenon in helium-3 is thought to be related to pairing of helium-3 fermions to make bosons, in analogy to Cooper pairs of electrons producing superconductivity.\nIn 1961, Vignos and Fairbank reported the existence of a different phase of solid helium-4, designated the gamma-phase. It exists for a narrow range of pressure between 1.45 and 1.78 K.\nExtraction and use.\nAfter an oil drilling operation in 1903 in Dexter, Kansas produced a gas geyser that would not burn, Kansas state geologist Erasmus Haworth collected samples of the escaping gas and took them back to the University of Kansas at Lawrence where, with the help of chemists Hamilton Cady and David McFarland, he discovered that the gas consisted of, by volume, 72% nitrogen, 15% methane (a combustible percentage only with sufficient oxygen), 1% hydrogen, and 12% an unidentifiable gas. With further analysis, Cady and McFarland discovered that 1.84% of the gas sample was helium. This showed that despite its overall rarity on Earth, helium was concentrated in large quantities under the American Great Plains, available for extraction as a byproduct of natural gas.\nFollowing a suggestion by Sir Richard Threlfall, the United States Navy sponsored three small experimental helium plants during World War I. The goal was to supply barrage balloons with the non-flammable, lighter-than-air gas. A total of of 92% helium was produced in the program even though less than a cubic meter of the gas had previously been obtained. Some of this gas was used in the world's first helium-filled airship, the U.S. Navy's C-class blimp C-7, which flew its maiden voyage from Hampton Roads, Virginia, to Bolling Field in Washington, D.C., on December 1, 1921, nearly two years before the Navy's first \"rigid\" helium-filled airship, the Naval Aircraft Factory-built USS \"Shenandoah\", flew in September 1923.\nAlthough the extraction process using low-temperature gas liquefaction was not developed in time to be significant during World War I, production continued. Helium was primarily used as a lifting gas in lighter-than-air craft. During World War II, the demand increased for helium for lifting gas and for shielded arc welding. The helium mass spectrometer was also vital in the atomic bomb Manhattan Project.\nThe government of the United States set up the National Helium Reserve in 1925 at Amarillo, Texas, with the goal of supplying military airships in time of war and commercial airships in peacetime. Because of the Helium Act of 1925, which banned the export of scarce helium on which the US then had a production monopoly, together with the prohibitive cost of the gas, German Zeppelins were forced to use hydrogen as lifting gas, which would gain infamy in the Hindenburg disaster. The helium market after World War II was depressed but the reserve was expanded in the 1950s to ensure a supply of liquid helium as a coolant to create oxygen/hydrogen rocket fuel (among other uses) during the Space Race and Cold War. Helium use in the United States in 1965 was more than eight times the peak wartime consumption.\nAfter the Helium Acts Amendments of 1960 (Public Law 86\u2013777), the U.S. Bureau of Mines arranged for five private plants to recover helium from natural gas. For this helium conservation program, the Bureau built a pipeline from Bushton, Kansas, to connect those plants with the government's partially depleted Cliffside gas field near Amarillo, Texas. This helium-nitrogen mixture was injected and stored in the Cliffside gas field until needed, at which time it was further purified.\nBy 1995, a billion cubic meters of the gas had been collected and the reserve was US$1.4\u00a0billion in debt, prompting the Congress of the United States in 1996 to discontinue the reserve. The resulting Helium Privatization Act of 1996 (Public Law 104\u2013273) directed the United States Department of the Interior to empty the reserve, with sales starting by 2005.\nHelium produced between 1930 and 1945 was about 98.3% pure (2% nitrogen), which was adequate for airships. In 1945, a small amount of 99.9% helium was produced for welding use. By 1949, commercial quantities of Grade A 99.95% helium were available.\nFor many years, the United States produced more than 90% of commercially usable helium in the world, while extraction plants in Canada, Poland, Russia, and other nations produced the remainder. In the mid-1990s, a new plant in Arzew, Algeria, producing began operation, with enough production to cover all of Europe's demand. Meanwhile, by 2000, the consumption of helium within the U.S. had risen to more than 15 million kg per year. In 2004\u20132006, additional plants in Ras Laffan, Qatar, and Skikda, Algeria were built. Algeria quickly became the second leading producer of helium. Through this time, both helium consumption and the costs of producing helium increased. From 2002 to 2007 helium prices doubled.\nAs of 2012[ [update]], the United States National Helium Reserve accounted for 30 percent of the world's helium. The reserve was expected to run out of helium in 2018. Despite that, a proposed bill in the United States Senate would allow the reserve to continue to sell the gas. Other large reserves were in the Hugoton in Kansas, United States, and nearby gas fields of Kansas and the panhandles of Texas and Oklahoma. New helium plants were scheduled to open in 2012 in Qatar, Russia, and the US state of Wyoming, but they were not expected to ease the shortage.\nIn 2013, Qatar started up the world's largest helium unit, although the 2017 Qatar diplomatic crisis severely affected helium production there. 2014 was widely acknowledged to be a year of over-supply in the helium business, following years of renowned shortages. Nasdaq reported (2015) that for Air Products, an international corporation that sells gases for industrial use, helium volumes remain under economic pressure due to feedstock supply constraints.\nCharacteristics.\nAtom.\nIn quantum mechanics.\nIn the perspective of quantum mechanics, helium is the second simplest atom to model, following the hydrogen atom. Helium is composed of two electrons in atomic orbitals surrounding a nucleus containing two protons and (usually) two neutrons. As in Newtonian mechanics, no system that consists of more than two particles can be solved with an exact analytical mathematical approach (see 3-body problem) and helium is no exception. Thus, numerical mathematical methods are required, even to solve the system of one nucleus and two electrons. Such computational chemistry methods have been used to create a quantum mechanical picture of helium electron binding which is accurate to within &lt; 2% of the correct value, in a few computational steps. Such models show that each electron in helium partly screens the nucleus from the other, so that the effective nuclear charge \"Z\"eff which each electron sees is about 1.69 units, not the 2 charges of a classic \"bare\" helium nucleus.\nRelated stability of the helium-4 nucleus and electron shell.\nThe nucleus of the helium-4 atom is identical with an alpha particle. High-energy electron-scattering experiments show its charge to decrease exponentially from a maximum at a central point, exactly as does the charge density of helium's own electron cloud. This symmetry reflects similar underlying physics: the pair of neutrons and the pair of protons in helium's nucleus obey the same quantum mechanical rules as do helium's pair of electrons (although the nuclear particles are subject to a different nuclear binding potential), so that all these fermions fully occupy 1s orbitals in pairs, none of them possessing orbital angular momentum, and each cancelling the other's intrinsic spin. This arrangement is thus energetically extremely stable for all these particles and has astrophysical implications. Namely, adding another particle \u2013 proton, neutron, or alpha particle \u2013 would consume rather than release energy; all systems with mass number 5, as well as beryllium-8 (comprising two alpha particles), are unbound.\nFor example, the stability and low energy of the electron cloud state in helium accounts for the element's chemical inertness, and also the lack of interaction of helium atoms with each other, producing the lowest melting and boiling points of all the elements. In a similar way, the particular energetic stability of the helium-4 nucleus, produced by similar effects, accounts for the ease of helium-4 production in atomic reactions that involve either heavy-particle emission or fusion. Some stable helium-3 (two protons and one neutron) is produced in fusion reactions from hydrogen, though its estimated abundance in the universe is about relative to helium-4.\nThe unusual stability of the helium-4 nucleus is also important cosmologically: it explains the fact that in the first few minutes after the Big Bang, as the \"soup\" of free protons and neutrons which had initially been created in about 6:1 ratio cooled to the point that nuclear binding was possible, almost all first compound atomic nuclei to form were helium-4 nuclei. Owing to the relatively tight binding of helium-4 nuclei, its production consumed nearly all of the free neutrons in a few minutes, before they could beta-decay, and thus few neutrons were available to form heavier atoms such as lithium, beryllium, or boron. Helium-4 nuclear binding per nucleon is stronger than in any of these elements (see nucleogenesis and binding energy) and thus, once helium had been formed, no energetic drive was available to make elements 3, 4 and 5. It is barely energetically favorable for helium to fuse into the next element with a lower energy per nucleon, carbon. However, due to the short lifetime of the intermediate beryllium-8, this process requires three helium nuclei striking each other nearly simultaneously (see triple-alpha process). There was thus no time for significant carbon to be formed in the few minutes after the Big Bang, before the early expanding universe cooled to the temperature and pressure point where helium fusion to carbon was no longer possible. This left the early universe with a very similar ratio of hydrogen/helium as is observed today (3 parts hydrogen to 1 part helium-4 by mass), with nearly all the neutrons in the universe trapped in helium-4.\nAll heavier elements (including those necessary for rocky planets like the Earth, and for carbon-based or other life) have thus been created since the Big Bang in stars which were hot enough to fuse helium itself. All elements other than hydrogen and helium today account for only 2% of the mass of atomic matter in the universe. Helium-4, by contrast, comprises about 24% of the mass of the universe's ordinary matter\u2014nearly all the ordinary matter that is not hydrogen.\nGas and plasma phases.\nHelium is the second least reactive noble gas after neon, and thus the second least reactive of all elements. It is chemically inert and monatomic in all standard conditions. Because of helium's relatively low molar (atomic) mass, its thermal conductivity, specific heat, and sound speed in the gas phase are all greater than any other gas except hydrogen. For these reasons and the small size of helium monatomic molecules, helium diffuses through solids at a rate three times that of air and around 65% that of hydrogen.\nHelium is the least water-soluble monatomic gas, and one of the least water-soluble of any gas (CF4, SF6, and C4F8 have lower mole fraction solubilities: 0.3802, 0.4394, and 0.2372 x2/10\u22125, respectively, versus helium's 0.70797 x2/10\u22125), and helium's index of refraction is closer to unity than that of any other gas. Helium has a negative Joule\u2013Thomson coefficient at normal ambient temperatures, meaning it heats up when allowed to freely expand. Only below its Joule\u2013Thomson inversion temperature (of about 32 to 50\u00a0K at 1 atmosphere) does it cool upon free expansion. Once precooled below this temperature, helium can be liquefied through expansion cooling.\nMost extraterrestrial helium is plasma in stars, with properties quite different from those of atomic helium. In a plasma, helium's electrons are not bound to its nucleus, resulting in very high electrical conductivity, even when the gas is only partially ionized. The charged particles are highly influenced by magnetic and electric fields. For example, in the solar wind together with ionized hydrogen, the particles interact with the Earth's magnetosphere, giving rise to Birkeland currents and the aurora.\nLiquid phase.\nHelium liquifies when cooled below 4.2\u00a0K at atmospheric pressure. Unlike any other element, however, helium remains liquid down to a temperature of absolute zero. This is a direct effect of quantum mechanics: specifically, the zero point energy of the system is too high to allow freezing. Pressures above about 25 atmospheres are required to freeze it. There are two liquid phases: Helium I is a conventional liquid, and Helium II, which occurs at a lower temperature, is a superfluid.\nHelium I.\nBelow its boiling point of and above the lambda point of , the isotope helium-4 exists in a normal colorless liquid state, called \"helium\u00a0I\". Like other cryogenic liquids, helium\u00a0I boils when it is heated and contracts when its temperature is lowered. Below the lambda point, however, helium does not boil, and it expands as the temperature is lowered further. \nHelium\u00a0I has a gas-like index of refraction of 1.026 which makes its surface so hard to see that floats of Styrofoam are often used to show where the surface is. This colorless liquid has a very low viscosity and a density of 0.145\u20130.125 g/mL (between about 0 and 4 K), which is only one-fourth the value expected from classical physics. Quantum mechanics is needed to explain this property and thus both states of liquid helium (helium I and helium II) are called \"quantum fluids\", meaning they display atomic properties on a macroscopic scale. This may be an effect of its boiling point being so close to absolute zero, preventing random molecular motion (thermal energy) from masking the atomic properties.\nHelium II.\nLiquid helium below its lambda point (called \"helium\u00a0II\") exhibits very unusual characteristics. Due to its high thermal conductivity, when it boils, it does not bubble but rather evaporates directly from its surface. Helium-3 also has a superfluid phase, but only at much lower temperatures; as a result, less is known about the properties of the isotope.\nHelium\u00a0II is a superfluid, a quantum mechanical state of matter with strange properties. For example, when it flows through capillaries as thin as 10 to 100 nm it has no measurable viscosity. However, when measurements were done between two moving discs, a viscosity comparable to that of gaseous helium was observed. Existing theory explains this using the \"two-fluid model\" for helium II. In this model, liquid helium below the lambda point is viewed as containing a proportion of helium atoms in a ground state, which are superfluid and flow with exactly zero viscosity, and a proportion of helium atoms in an excited state, which behave more like an ordinary fluid.\nIn the \"fountain effect\", a chamber is constructed which is connected to a reservoir of helium\u00a0II by a sintered disc through which superfluid helium leaks easily but through which non-superfluid helium cannot pass. If the interior of the container is heated, the superfluid helium changes to non-superfluid helium. In order to maintain the equilibrium fraction of superfluid helium, superfluid helium leaks through and increases the pressure, causing liquid to fountain out of the container.\nThe thermal conductivity of helium\u00a0II is greater than that of any other known substance, a million times that of helium\u00a0I and several hundred times that of copper. This is because heat conduction occurs by an exceptional quantum mechanism. Most materials that conduct heat well have a valence band of free electrons which serve to transfer the heat. Helium\u00a0II has no such valence band but nevertheless conducts heat well. The flow of heat is governed by equations that are similar to the wave equation used to characterize sound propagation in air. When heat is introduced, it moves at 20 meters per second at 1.8\u00a0K through helium\u00a0II as waves in a phenomenon known as \"second sound\".\nHelium\u00a0II also exhibits a creeping effect. When a surface extends past the level of helium\u00a0II, the helium\u00a0II moves along the surface, against the force of gravity. Helium\u00a0II will escape from a vessel that is not sealed by creeping along the sides until it reaches a warmer region where it evaporates. It moves in a 30\u00a0nm-thick film regardless of surface material. This film is called a Rollin film and is named after the man who first characterized this trait, Bernard V. Rollin. As a result of this creeping behavior and helium\u00a0II's ability to leak rapidly through tiny openings, it is very difficult to confine. Unless the container is carefully constructed, the helium\u00a0II will creep along the surfaces and through valves until it reaches somewhere warmer, where it will evaporate. Waves propagating across a Rollin film are governed by the same equation as gravity waves in shallow water, but rather than gravity, the restoring force is the van der Waals force. These waves are known as \"third sound\".\nSolid phases.\nHelium remains liquid down to absolute zero at atmospheric pressure, but it freezes at high pressure. Solid helium requires a temperature of 1\u20131.5\u00a0K (about \u2212272\u00a0\u00b0C or \u2212457\u00a0\u00b0F) at about 25 bar (2.5\u00a0MPa) of pressure. It is often hard to distinguish solid from liquid helium since the refractive index of the two phases are nearly the same. The solid has a sharp melting point and has a crystalline structure, but it is highly compressible; applying pressure in a laboratory can decrease its volume by more than 30%. With a bulk modulus of about 27 MPa it is ~100 times more compressible than water. Solid helium has a density of at 1.15\u00a0K and 66\u00a0atm; the projected density at 0\u00a0K and 25 bar (2.5 MPa) is . At higher temperatures, helium will solidify with sufficient pressure. At room temperature, this requires about 114,000 atm.\nHelium-4 and helium-3 both form several crystalline solid phases, all requiring at least 25\u00a0bar. They both form an \u03b1 phase, which has a hexagonal close-packed (hcp) crystal structure, a \u03b2 phase, which is face-centered cubic (fcc), and a \u03b3 phase, which is body-centered cubic (bcc).\nIsotopes.\nThere are nine known isotopes of helium of which two, helium-3 and helium-4, are stable. In the Earth's atmosphere, one atom is 3He for every million that are 4He. Unlike most elements, helium's isotopic abundance varies greatly by origin, due to the different formation processes. The most common isotope, helium-4, is produced on Earth by alpha decay of heavier radioactive elements; the alpha particles that emerge are fully ionized helium-4 nuclei. Helium-4 is an unusually stable nucleus because its nucleons are arranged into complete shells. It was also formed in enormous quantities during Big Bang nucleosynthesis.\nHelium-3 is present on Earth only in trace amounts. Most of it has been present since Earth's formation, though some falls to Earth trapped in cosmic dust. Trace amounts are also produced by the beta decay of tritium. Rocks from the Earth's crust have isotope ratios varying by as much as a factor of ten, and these ratios can be used to investigate the origin of rocks and the composition of the Earth's mantle. 3He is much more abundant in stars as a product of nuclear fusion. Thus in the interstellar medium, the proportion of 3He to 4He is about 100 times higher than on Earth. Extraplanetary material, such as lunar and asteroid regolith, have trace amounts of helium-3 from being bombarded by solar winds. The Moon's surface contains helium-3 at concentrations on the order of 10 ppb, much higher than the approximately 5 ppt found in the Earth's atmosphere. A number of people, starting with Gerald Kulcinski in 1986, have proposed to explore the Moon, mine lunar regolith, and use the helium-3 for fusion.\nLiquid helium-4 can be cooled to about using evaporative cooling in a 1-K pot. Similar cooling of helium-3, which has a lower boiling point, can achieve about in a helium-3 refrigerator. Equal mixtures of liquid 3He and 4He below separate into two immiscible phases due to their dissimilarity (they follow different quantum statistics: helium-4 atoms are bosons while helium-3 atoms are fermions). Dilution refrigerators use this immiscibility to achieve temperatures of a few millikelvins.\nIt is possible to produce exotic helium isotopes, which rapidly decay into other substances. The shortest-lived heavy helium isotope is the unbound helium-10 with a half-life of . Helium-6 decays by emitting a beta particle and has a half-life of 0.8 second. Helium-7 and helium-8 are created in certain nuclear reactions. Helium-6 and helium-8 are known to exhibit a nuclear halo.\nProperties.\nTable of thermal and physical properties of helium gas at atmospheric pressure:\nCompounds.\nHelium has a valence of zero and is chemically unreactive under all normal conditions. It is an electrical insulator unless ionized. As with the other noble gases, helium has metastable energy levels that allow it to remain ionized in an electrical discharge with a voltage below its ionization potential. Helium can form unstable compounds, known as excimers, with tungsten, iodine, fluorine, sulfur, and phosphorus when it is subjected to a glow discharge, to electron bombardment, or reduced to plasma by other means. The molecular compounds HeNe, HgHe10, and WHe2, and the molecular ions He2+, He22+, HeH+, and HeD+ have been created this way. HeH+ is also stable in its ground state but is extremely reactive\u2014it is the strongest Br\u00f8nsted acid known, and therefore can exist only in isolation, as it will protonate any molecule or counteranion it contacts. This technique has also produced the neutral molecule He2, which has a large number of band systems, and HgHe, which is apparently held together only by polarization forces.\nVan der Waals compounds of helium can also be formed with cryogenic helium gas and atoms of some other substance, such as LiHe and He2.\nTheoretically, other true compounds may be possible, such as helium fluorohydride (HHeF), which would be analogous to HArF, discovered in 2000. Calculations show that two new compounds containing a helium-oxygen bond could be stable. Two new molecular species, predicted using theory, CsFHeO and N(CH3)4FHeO, are derivatives of a metastable FHeO\u2212 anion first theorized in 2005 by a group from Taiwan.\nHelium atoms have been inserted into the hollow carbon cage molecules (the fullerenes) by heating under high pressure. The endohedral fullerene molecules formed are stable at high temperatures. When chemical derivatives of these fullerenes are formed, the helium stays inside. If helium-3 is used, it can be readily observed by helium nuclear magnetic resonance spectroscopy. Many fullerenes containing helium-3 have been reported. Although the helium atoms are not attached by covalent or ionic bonds, these substances have distinct properties and a definite composition, like all stoichiometric chemical compounds.\nUnder high pressures helium can form compounds with various other elements. Helium-nitrogen clathrate (He(N2)11) crystals have been grown at room temperature at pressures ca. 10 GPa in a diamond anvil cell. The insulating electride Na2He has been shown to be thermodynamically stable at pressures above 113 GPa. It has a fluorite structure.\nOccurrence and production.\nNatural abundance.\nAlthough it is rare on Earth, helium is the second most abundant element in the known Universe, constituting 23% of its baryonic mass. Only hydrogen is more abundant. The vast majority of helium was formed by Big Bang nucleosynthesis one to three minutes after the Big Bang. As such, measurements of its abundance contribute to cosmological models. The first molecular bonds when formed when primordial helium atoms combined with protons to form helium hydride ions, HeH+. In stars, helium is formed by the nuclear fusion of hydrogen in proton\u2013proton chain reactions and the CNO cycle, part of stellar nucleosynthesis.\nIn the Earth's atmosphere, the concentration of helium by volume is only 5.2 parts per million. The concentration is low and fairly constant despite the continuous production of new helium because most helium in the Earth's atmosphere escapes into space by several processes. In the Earth's heterosphere, a part of the upper atmosphere, helium and hydrogen are the most abundant elements.\nMost helium on Earth is a result of radioactive decay. Helium is found in large amounts in minerals of uranium and thorium, such as uraninite and its varieties cleveite and pitchblende, as well as carnotite and monazite (a group name; \"monazite\" usually refers to monazite-(Ce)), because they emit alpha particles (helium nuclei, He2+) to which electrons immediately combine as soon as the particle is stopped by the rock. In this way an estimated 3000 metric tons of helium are generated per year throughout the lithosphere. In the Earth's crust, the concentration of helium is 8 parts per billion. In seawater, the concentration is only 4 parts per trillion. There are also small amounts in mineral springs, volcanic gas, and meteoric iron. Because helium is trapped in the subsurface under conditions that also trap natural gas, the greatest natural concentrations of helium on the planet are found in natural gas, from which most commercial helium is extracted. The concentration varies in a broad range from a few ppm to more than 7% in a small gas field in San Juan County, New Mexico.\nAs of 2021[ [update]], the world's helium reserves were estimated at 31 billion cubic meters, with a third of that being in Qatar. In 2015 and 2016 additional probable reserves were announced to be under the Rocky Mountains in North America and in the East African Rift.\nThe Bureau of Land Management (BLM) has proposed an October 2024 plan for managing natural resources in western Colorado. The plan involves closing 543,000 acres to oil and gas leasing while keeping 692,300 acres open. Among the open areas, 165,700 acres have been identified as suitable for helium recovery. The United States possesses an estimated 306 billion cubic feet of recoverable helium, sufficient to meet current consumption rates of 2.15 billion cubic feet per year for approximately 150 years.\nModern extraction and distribution.\nExtracting helium from air is not economical. \nFor large-scale use, helium is extracted by fractional distillation from natural gas, which can contain as much as 7% helium. Since helium has a lower boiling point than any other element, low temperatures and high pressure are used to liquefy nearly all the other gases (mostly nitrogen and methane). The resulting crude helium gas is purified by successive exposures to lowering temperatures, in which almost all of the remaining nitrogen and other gases are precipitated out of the gaseous mixture. Activated charcoal is used as a final purification step, usually resulting in 99.995% pure Grade-A helium. The principal impurity in Grade-A helium is neon. In a final production step, most of the helium that is produced is liquefied via a cryogenic process. This is necessary for applications requiring liquid helium and also allows helium suppliers to reduce the cost of long-distance transportation, as the largest liquid helium containers have more than five times the capacity of the largest gaseous helium tube trailers.\nIn 2008, approximately 169 million standard cubic meters (SCM) of helium were extracted from natural gas or withdrawn from helium reserves, with approximately 78% from the United States, 10% from Algeria, and most of the remainder from Russia, Poland, and Qatar. By 2013, increases in helium production in Qatar (under the company Qatargas managed by Air Liquide) had increased Qatar's fraction of world helium production to 25%, making it the second largest exporter after the United States. In 2024, the United States surpassed Qatar as the world's largest producer of the gas, having extracted 68\u00a0million SCM of helium that year compared to Qatar's 64\u00a0million SCM.\nAn estimated deposit of helium was found in Tanzania in 2016, and a large-scale helium plant was opened in Ningxia, China in 2020.\nIn the United States, most helium is extracted from the natural gas of the Hugoton and nearby gas fields in Kansas, Oklahoma, and the Panhandle Field in Texas. Much of this gas was once sent by pipeline to the National Helium Reserve, but since 2005, this reserve has been depleted and sold off, and it was expected to be largely depleted by 2021 under the October 2013 \"Responsible Helium Administration and Stewardship Act\" (H.R. 527). Despite efforts to sell the remaining reserve in 2021, the remnants of the National Helium Reserve were auctioned off by the Bureau of Land Management over the course of 3 years. It was finally sold to Messer Group on June 27, 2024. The helium fields of the western United States are emerging as an alternate source of helium supply, particularly those of the \"Four Corners\" region (the states of Arizona, Colorado, New Mexico and Utah). \nDiffusion of crude natural gas through special semipermeable membranes and other barriers is another method to recover and purify helium. In 1996, the U.S. had \"proven\" helium reserves in such gas well complexes of about 147 billion standard cubic feet (4.2 billion SCM). At rates of use at that time (72 million SCM per year in the U.S.; see pie chart below) this would have been enough helium for about 58 years of U.S. use, and less than this (perhaps 80% of the time) at world use rates, although factors in saving and processing impact effective reserve numbers.\nHelium is commercially available in either liquid or gaseous form. As a liquid, it can be supplied in small insulated containers called dewars which hold as much as 1,000 liters of helium, or in large ISO containers, which have nominal capacities as large as 42\u00a0m3 (around 11,000 U.S. gallons). In gaseous form, small quantities of helium are supplied in high-pressure cylinders holding as much as 8\u00a0m3 (approximately . 282 standard cubic feet), while large quantities of high-pressure gas are supplied in tube trailers, which have capacities of as much as 4,860\u00a0m3 (approx. 172,000 standard cubic feet).\nConservation advocates.\nAccording to helium conservationists like Nobel laureate physicist Robert Coleman Richardson, writing in 2010, the free market price of helium has contributed to \"wasteful\" usage (e.g. for helium balloons). Prices in the 2000s had been lowered by the decision of the U.S. Congress to sell off the country's large helium stockpile by 2015. Richardson posited that the price of helium needed to be multiplied by 20 to eliminate excessive wasting of the gas. In a 2012 paper by Nuttall and colleagues titled \"Stop squandering helium\", they proposed to create an International Helium Agency that would build a sustainable helium market.\nApplications.\n&lt;templatestyles src=\"Pie chart/styles.css\"/&gt;\nWhile balloons are perhaps the best-known use of helium, they are a minor part of all helium use. Helium is used for many purposes that require some of its unique properties, such as its low boiling point, low density, low solubility, high thermal conductivity, or inertness. Of the 2014 world helium total production of about 32 million kg (180 million standard cubic meters) helium per year, the largest use (about 32% of the total in 2014) is in cryogenic applications, most of which involves cooling the superconducting magnets in medical MRI scanners and NMR spectrometers. Other major uses were pressurizing and purging systems, welding, maintenance of controlled atmospheres, and leak detection. Other uses by category were relatively minor fractions.\nControlled atmospheres.\nHelium is used as a protective gas in growing silicon and germanium crystals, in titanium and zirconium production, and in gas chromatography, because it is inert. Because of its inertness, thermally and calorically perfect nature, high speed of sound, and high value of the heat capacity ratio, it is also useful in supersonic wind tunnels and impulse facilities.\nGas tungsten arc welding.\nHelium is used as a shielding gas in arc welding processes on materials that are contaminated and weakened by air or nitrogen at welding temperatures. A number of inert shielding gases are used in gas tungsten arc welding, but helium is used instead of cheaper argon especially for welding materials that have higher heat conductivity, like aluminium or copper.\nMinor uses.\nIndustrial leak detection.\nOne industrial application for helium is leak detection. Because helium diffuses through solids three times faster than air, it is used as a tracer gas to detect leaks in high-vacuum equipment (such as cryogenic tanks) and high-pressure containers. The tested object is placed in a chamber, which is then evacuated and filled with helium. The helium that escapes through the leaks is detected by a sensitive device (helium mass spectrometer), even at the leak rates as small as 10\u22129 mbar\u00b7L/s (10\u221210 Pa\u00b7m3/s). The measurement procedure is normally automatic and is called helium integral test. A simpler procedure is to fill the tested object with helium and to manually search for leaks with a hand-held device.\nHelium leaks through cracks should not be confused with gas permeation through a bulk material. While helium has documented permeation constants (thus a calculable permeation rate) through glasses, ceramics, and synthetic materials, inert gases such as helium will not permeate most bulk metals.\nFlight.\nBecause it is lighter than air, airships and balloons are inflated with helium for lift. While hydrogen gas is more buoyant and escapes permeating through a membrane at a lower rate, helium has the advantage of being non-flammable, and indeed fire-retardant. Another minor use is in rocketry, where helium is used as an ullage medium to backfill rocket propellant tanks in flight and to condense hydrogen and oxygen to make rocket fuel. It is also used to purge fuel and oxidizer from ground support equipment prior to launch and to pre-cool liquid hydrogen in space vehicles. For example, the Saturn V rocket used in the Apollo program needed about of helium to launch.\nMinor commercial and recreational uses.\nHelium as a breathing gas has no narcotic properties, so helium mixtures such as trimix, heliox and heliair are used for deep diving to reduce the effects of narcosis, which worsen with increasing depth. As pressure increases with depth, the density of the breathing gas also increases, and the low molecular weight of helium is found to considerably reduce the effort of breathing by lowering the density of the mixture. This reduces the Reynolds number of flow, leading to a reduction of turbulent flow and an increase in laminar flow, which requires less breathing. At depths below divers breathing helium-oxygen mixtures begin to experience tremors and a decrease in psychomotor function, symptoms of high-pressure nervous syndrome. This effect may be countered to some extent by adding an amount of narcotic gas such as hydrogen or nitrogen to a helium\u2013oxygen mixture.\nHelium\u2013neon lasers, a type of low-powered gas laser producing a red beam, had various practical applications which included barcode readers and laser pointers, before they were almost universally replaced by cheaper diode lasers.\nFor its inertness and high thermal conductivity, neutron transparency, and because it does not form radioactive isotopes under reactor conditions, helium is used as a heat-transfer medium in some gas-cooled nuclear reactors.\nHelium, mixed with a heavier gas such as xenon, is useful for thermoacoustic refrigeration due to the resulting high heat capacity ratio and low Prandtl number. The inertness of helium has environmental advantages over conventional refrigeration systems which contribute to ozone depletion or global warming.\nHelium is also used in some hard disk drives.\nScientific uses.\nThe use of helium reduces the distorting effects of temperature variations in the space between lenses in some telescopes due to its extremely low index of refraction. This method is especially used in solar telescopes where a vacuum tight telescope tube would be too heavy.\nHelium is a commonly used carrier gas for gas chromatography.\nThe age of rocks and minerals that contain uranium and thorium can be estimated by measuring the level of helium with a process known as helium dating.\nHelium at low temperatures is used in cryogenics and in certain cryogenic applications. As examples of applications, liquid helium is used to cool certain metals to the extremely low temperatures required for superconductivity, such as in superconducting magnets for magnetic resonance imaging. The Large Hadron Collider at CERN uses 96 metric tons of liquid helium to maintain the temperature at .\nMedical uses.\nHelium was approved for medical use in the United States in April 2020 for humans and animals.\nAs a contaminant.\nWhile chemically inert, helium contamination impairs the operation of microelectromechanical systems (MEMS) such that iPhones may fail.\nInhalation and safety.\nEffects.\nNeutral helium at standard conditions is non-toxic, plays no biological role and is found in trace amounts in human blood.\nThe speed of sound in helium is nearly three times the speed of sound in air. Because the natural resonance frequency of a gas-filled cavity is proportional to the speed of sound in the gas, when helium is inhaled, a corresponding increase occurs in the resonant frequencies of the vocal tract, which is the amplifier of vocal sound. This increase in the resonant frequency of the amplifier (the vocal tract) gives increased amplification to the high-frequency components of the sound wave produced by the direct vibration of the vocal folds, compared to the case when the voice box is filled with air. When a person speaks after inhaling helium gas, the muscles that control the voice box still move in the same way as when the voice box is filled with air; therefore the fundamental frequency (sometimes called pitch) produced by direct vibration of the vocal folds does not change. However, the high-frequency-preferred amplification causes a change in timbre of the amplified sound, resulting in a reedy, duck-like vocal quality. The opposite effect, lowering resonant frequencies, can be obtained by inhaling a dense gas such as sulfur hexafluoride or xenon.\nHazards.\n&lt;templatestyles src=\"Chembox/styles.css\"/&gt;\nChemical compound\nInhaling helium can be dangerous if done to excess, since helium is a simple asphyxiant and so displaces oxygen needed for normal respiration. Fatalities have been recorded, including a youth who suffocated in Vancouver in 2003 and two adults who suffocated in South Florida in 2006. In 1998, an Australian girl from Victoria fell unconscious and temporarily turned blue after inhaling the entire contents of a party balloon.\nInhaling helium directly from pressurized cylinders or even balloon filling valves is extremely dangerous, as high flow rate and pressure can result in barotrauma, fatally rupturing lung tissue.\nDeath caused by helium is rare. The first media-recorded case was that of a 15-year-old girl from Texas who died in 1998 from helium inhalation at a friend's party; the exact type of helium death is unidentified.\nIn the United States, only two fatalities were reported between 2000 and 2004, including a man who died in North Carolina of barotrauma in 2002. A youth asphyxiated in Vancouver during 2003, and a 27-year-old man in Australia had an embolism after breathing from a cylinder in 2000. Since then, two adults asphyxiated in South Florida in 2006, and there were cases in 2009 and 2010, one of whom was a Californian youth who was found with a bag over his head, attached to a helium tank, and another teenager in Northern Ireland died of asphyxiation. At Eagle Point, Oregon a teenage girl died in 2012 from barotrauma at a party. A girl from Michigan died from hypoxia later in the year.\nOn February 4, 2015, it was revealed that, during the recording of their main TV show on January 28, a 12-year-old member (name withheld) of Japanese all-girl singing group 3B Junior suffered from air embolism, losing consciousness and falling into a coma as a result of air bubbles blocking the flow of blood to the brain after inhaling huge quantities of helium as part of a game. The incident was not made public until a week later. The staff of TV Asahi held an emergency press conference to communicate that the member had been taken to the hospital and is showing signs of rehabilitation such as moving eyes and limbs, but her consciousness has not yet been sufficiently recovered. Police have launched an investigation due to a neglect of safety measures.\nThe safety issues for cryogenic helium are similar to those of liquid nitrogen; its extremely low temperatures can result in cold burns, and the liquid-to-gas expansion ratio can cause explosions if no pressure-relief devices are installed. Containers of helium gas at 5 to 10 K should be handled as if they contain liquid helium due to the rapid and significant thermal expansion that occurs when helium gas at less than 10 K is warmed to room temperature.\nAt high pressures (more than about 20\u00a0atm or two\u00a0MPa), a mixture of helium and oxygen (heliox) can lead to high-pressure nervous syndrome, a sort of reverse-anesthetic effect; adding a small amount of nitrogen to the mixture can alleviate the problem.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nBibliography.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "13257", "revid": "40745614", "url": "https://en.wikipedia.org/wiki?curid=13257", "title": "Hydrocarbon", "text": "Organic compound consisting entirely of hydrogen and carbon\n \nIn organic chemistry, a hydrocarbon is an organic compound consisting entirely of hydrogen and carbon. Hydrocarbons are examples of group 14 hydrides. Hydrocarbons are generally colourless and hydrophobic; their odor is usually faint, and may be similar to that of gasoline or lighter fluid. They occur in a diverse range of molecular structures and phases: they can be gases (such as methane and propane), liquids (such as hexane and benzene), low melting solids (such as paraffin wax and naphthalene) or polymers (such as polyethylene and polystyrene).\nIn the fossil fuel industries, \"hydrocarbon\" refers to naturally occurring petroleum, natural gas and coal, or their hydrocarbon derivatives and purified forms. Combustion of hydrocarbons is the main source of the world's energy. Petroleum is the dominant raw-material source for organic commodity chemicals such as solvents and polymers. Most anthropogenic (human-generated) emissions of greenhouse gases are either carbon dioxide released by the burning of fossil fuels, or methane released from the handling of natural gas or from agriculture.\nTypes.\nAs defined by the International Union of Pure and Applied Chemistry's nomenclature of organic chemistry, hydrocarbons are classified as follows:\nThe term 'aliphatic' refers to non-aromatic hydrocarbons. Saturated aliphatic hydrocarbons are sometimes referred to as 'paraffins'. Aliphatic hydrocarbons containing a double bond between carbon atoms are sometimes referred to as 'olefins'.\nUsage.\nThe predominant use of hydrocarbons is as a combustible fuel source. Methane is the predominant component of natural gas. C6 through C10 alkanes, alkenes, cycloalkanes, and aromatic hydrocarbons are the main components of gasoline, naphtha, jet fuel, and specialized industrial solvent mixtures. With the progressive addition of carbon units, the simple non-ring structured hydrocarbons have higher viscosities, lubricating indices, boiling points, and solidification temperatures. At the opposite extreme from methane lie the heavy tars that remain as the \"lowest fraction\" in a crude oil refining retort. They are collected and widely utilized as roofing compounds, pavement material (bitumen), wood preservatives (the creosote series) and as extremely high viscosity shear-resisting liquids.\nSome large-scale non-fuel applications of hydrocarbons begin with ethane and propane, which are obtained from petroleum and natural gas. These two gases are converted either to syngas or to ethylene and propylene respectively. Global consumption of benzene in 2021 is estimated at more than 58 million metric tons, which will increase to 60 million tons in 2022.\nHydrocarbons are also prevalent in nature. Some eusocial arthropods, such as the Brazilian stingless bee, \"Schwarziana quadripunctata\", use unique cuticular hydrocarbon \"scents\" in order to determine kin from non-kin. This hydrocarbon composition varies between age, sex, nest location, and hierarchal position.\nThere is also potential to harvest hydrocarbons from plants like \"Euphorbia lathyris\" and \"E.\u00a0tirucalli\" as an alternative and renewable energy source for vehicles that use diesel. Furthermore, endophytic bacteria from plants that naturally produce hydrocarbons have been used in hydrocarbon degradation in attempts to deplete hydrocarbon concentration in polluted soils.\nReactions.\nSaturated hydrocarbons are notable for their inertness. Unsaturated hydrocarbons (alkenes, alkynes and aromatic compounds) react more readily, by means of substitution, addition, polymerization. At higher temperatures they undergo dehydrogenation, oxidation and combustion.\nSaturated hydrocarbons.\nCracking.\nThe cracking of saturated hydrocarbons is the main industrial route to alkenes and alkyne. These reactions require heterogeneous catalysts and temperatures &gt;500 \u00b0C.\nOxidation.\nOxidation of hydrocarbons involves their reaction with oxygen. In the presence of excess oxygen, hydrocarbons combust. With careful conditions, which have been optimized for many years, partial oxidation results. Useful compounds can be obtained in this way: maleic acid from butane, terephthalic acid from xylenes, acetone together with phenol from cumene (isopropylbenzene), and cyclohexanone from cyclohexane. The process, which is called autoxidation, begins with the formation of hydroperoxides (ROOH).\nCombustion.\nCombustion of hydrocarbons is currently the main source of the world's energy for electric power generation, heating (such as home heating), and transportation. Often this energy is used directly as heat such as in home heaters, which use either petroleum or natural gas. The hydrocarbon is burnt and the heat is used to heat water, which is then circulated. A similar principle is used to create electrical energy in power plants. Both saturated and unsaturated hydrocarbons undergo this process.\nCommon properties of hydrocarbons are the facts that they produce steam, carbon dioxide and heat during combustion and that oxygen is required for combustion to take place. The simplest hydrocarbon, methane, burns as follows:\n&lt;chem&gt;\\underset{methane}{CH4} + 2O2 -&gt; CO2 + 2H2O&lt;/chem&gt;\nIn inadequate supply of air, carbon black and water vapour are formed:\n&lt;chem&gt;\\underset{methane}{CH4} + O2 -&gt; C + 2H2O&lt;/chem&gt;\nAnd finally, for any linear alkane of \"n\" carbon atoms,\nformula_1\nPartial oxidation characterizes the reactions of alkenes and oxygen. This process is the basis of rancidification and paint drying.\nBenzene burns with sooty flame when heated in air:\n&lt;chem&gt;\\underset{benzene}{C6H6} + {15\\over 2}O2 -&gt; 6CO2 {+} 3H2O&lt;/chem&gt;\nHalogenation.\nSaturated hydrocarbons react with chlorine and fluorine. In the case of chlorination, one of the chlorine atoms replaces a hydrogen atom. The reactions proceed via free-radical pathways, in which the halogen first dissociates into two neutral radical atoms (homolytic fission).\nCH{{sub|4}} + Cl{{sub|2}} \u2192 CH{{sub|3}}Cl + HCl\nCH{{sub|3}}Cl + Cl{{sub|2}} \u2192 CH{{sub|2}}Cl{{sub|2}} + HCl\nall the way to CCl{{sub|4}} (carbon tetrachloride)\nC{{sub|2}}H{{sub|6}} + Cl{{sub|2}} \u2192 C{{sub|2}}H{{sub|5}}Cl + HCl\nC{{sub|2}}H{{sub|4}}Cl{{sub|2}} + Cl{{sub|2}} \u2192 C{{sub|2}}H{{sub|3}}Cl{{sub|3}} + HCl\nall the way to C{{sub|2}}Cl{{sub|6}} (hexachloroethane)\nUnsaturated hydrocarbons.\nSubstitution.\nAromatic compounds, almost uniquely for hydrocarbons, undergo substitution reactions. The chemical process practiced on the largest scale is the reaction of benzene and ethene to give ethylbenzene:\n{{chem2|C6H6 + C2H4 -&gt; C6H5CH2CH3}}\nThe resulting ethylbenzene is dehydrogenated to styrene and then polymerized to manufacture polystyrene, a common thermoplastic material.\nAddition.\nAddition reactions apply to alkenes and alkynes. It is because they add reagents that they are called unsaturated. In this reaction a variety of reagents add \"across\" the pi-bond(s). Chlorine, hydrogen chloride, water, and hydrogen are illustrative reagents. \nPolymerization is a form of addition. Alkenes and some alkynes undergo polymerization by opening of the multiple bonds to produce polyethylene, polybutylene, and polystyrene. The alkyne acetylene polymerizes to produce polyacetylene. Oligomers (chains of a few monomers) may be produced, for example in the Shell higher olefin process, where \u03b1-olefins are extended to make longer \u03b1-olefins by adding ethylene repeatedly.\nMetathesis.\nSome hydrocarbons undergo \"metathesis\", in which substituents attached by C\u2013C bonds are exchanged between molecules. For a single C\u2013C bond it is alkane metathesis, for a double C\u2013C bond it is alkene metathesis (olefin metathesis), and for a triple C\u2013C bond it is alkyne metathesis.\nOrigin.\nThe vast majority of hydrocarbons found on Earth occur in crude oil, petroleum, coal, and natural gas. For thousands of years they have been exploited and used for a vast range of purposes. Petroleum ({{lit|rock oil}}) and coal are generally thought to be products of decomposition of organic matter. Coal, in contrast to petroleum, is richer in carbon and poorer in hydrogen. Natural gas is the product of methanogenesis.\nA seemingly limitless variety of compounds comprise petroleum, hence the necessity of refineries. These hydrocarbons consist of saturated hydrocarbons, aromatic hydrocarbons, or combinations of the two. Missing in petroleum are alkenes and alkynes. Their production requires refineries. Petroleum-derived hydrocarbons are mainly consumed for fuel, but they are also the source of virtually all synthetic organic compounds, including plastics and pharmaceuticals. Natural gas is consumed almost exclusively as fuel. Coal is used as a fuel and as a reducing agent in metallurgy.\nA small fraction of hydrocarbon found on earth, and all currently known hydrocarbon found on other planets and moons, is thought to be abiological.\nHydrocarbons such as ethylene, isoprene, and monoterpenes are emitted by living vegetation.\nSome hydrocarbons also are widespread and abundant in the Solar System. Lakes of liquid methane and ethane have been found on Titan, Saturn's largest moon, as confirmed by the \"Cassini\u2013Huygens\" space probe. Hydrocarbons are also abundant in nebulae forming polycyclic aromatic hydrocarbon compounds.\nEnvironmental impact.\nBurning hydrocarbons as fuel, which produces carbon dioxide and water, is a major contributor to anthropogenic global warming.\nHydrocarbons are introduced into the environment through their extensive use as fuels and chemicals as well as through leaks or accidental spills during exploration, production, refining, or transport of fossil fuels. Anthropogenic hydrocarbon contamination of soil is a serious global issue due to contaminant persistence and the negative impact on human health.\nWhen soil is contaminated by hydrocarbons, it can have a significant impact on its microbiological, chemical, and physical properties. This can serve to prevent, slow down or even accelerate the growth of vegetation depending on the exact changes that occur. Crude oil and natural gas are the two largest sources of hydrocarbon contamination of soil.\nBioremediation.\nBioremediation of hydrocarbon from soil or water contaminated is a formidable challenge because of the chemical inertness that characterize hydrocarbons (hence they survived millions of years in the source rock). Nonetheless, many strategies have been devised, bioremediation being prominent. The basic problem with bioremediation is the paucity of enzymes that act on them. Nonetheless, the area has received regular attention.\nBacteria in the gabbroic layer of the ocean's crust can degrade hydrocarbons; but the extreme environment makes research difficult. Other bacteria such as \"Lutibacterium anuloederans\" can also degrade hydrocarbons.\nMycoremediation or breaking down of hydrocarbon by mycelium and mushrooms is possible.\nSafety.\nHydrocarbons are generally of low toxicity, hence the widespread use of gasoline and related volatile products. Aromatic compounds such as benzene and toluene are narcotic and chronic toxins, and benzene in particular is known to be carcinogenic. Certain rare polycyclic aromatic compounds are carcinogenic.\nHydrocarbons are highly flammable."}
{"id": "13258", "revid": "10274643", "url": "https://en.wikipedia.org/wiki?curid=13258", "title": "Halogen", "text": "Group of chemical elements\nThe halogens () are a group in the periodic table consisting of six chemically related elements: fluorine (F), chlorine (Cl), bromine (Br), iodine (I), and the radioactive elements astatine (At) and tennessine (Ts), though some authors would exclude tennessine as its chemistry is unknown and is theoretically expected to be more like that of gallium. In the modern IUPAC nomenclature, this group is known as group 17.\nThe word \"halogen\" means \"salt former\" or \"salt maker\". When halogens react with metals, they produce a wide range of salts, including calcium fluoride, sodium chloride (common table salt), silver bromide, and potassium iodide.\nThe group of halogens is the only periodic table group that contains elements in three of the main states of matter at standard temperature and pressure, though not far above room temperature the same becomes true of groups 1 and 15, assuming white phosphorus is taken as the standard state. All of the halogens form acids when bonded to hydrogen. Most halogens are typically produced from minerals or salts. The middle halogens\u2014chlorine, bromine, and iodine\u2014are often used as disinfectants. Organobromides are the most important class of flame retardants, while elemental halogens are dangerous and can be toxic.\n&lt;templatestyles src=\"Template:TOC limit/styles.css\" /&gt;\nHistory.\nThe fluorine mineral fluorspar was known as early as 1529. Early chemists realized that fluorine compounds contain an undiscovered element, but were unable to isolate it. In 1869, George Gore, an English chemist, ran a current of electricity through hydrofluoric acid and probably produced fluorine, but he was unable to prove his results at the time. In 1886, Henri Moissan, a chemist in Paris, performed electrolysis on potassium bifluoride dissolved in anhydrous hydrogen fluoride, and successfully isolated fluorine.\nHydrochloric acid was known to alchemists and early chemists. However, elemental chlorine was not produced until 1774, when Carl Wilhelm Scheele heated hydrochloric acid with manganese dioxide. Scheele called the element \"dephlogisticated muriatic acid\", which is how chlorine was known for 33 years. In 1807, Humphry Davy investigated chlorine and discovered that it is an actual element. Chlorine gas was used as a poisonous gas during World War I. It displaced oxygen in contaminated areas and replaced common oxygenated air with the toxic chlorine gas. The gas would burn human tissue externally and internally, especially the lungs, making breathing difficult or impossible depending on the level of contamination.\nBromine was discovered in the 1820s by Antoine J\u00e9r\u00f4me Balard. Balard discovered bromine by passing chlorine gas through a sample of brine. He originally proposed the name \"muride\" for the new element, but the French Academy changed the element's name to bromine.\nIodine was discovered by Bernard Courtois, who was using seaweed ash as part of a process for saltpeter manufacture. Courtois typically boiled the seaweed ash with water to generate potassium chloride. However, in 1811, Courtois added sulfuric acid to his process and found that his process produced purple fumes that condensed into black crystals. Suspecting that these crystals were a new element, Courtois sent samples to other chemists for investigation. Iodine was proven to be a new element by Joseph Gay-Lussac.\nIn 1931, Fred Allison claimed to have discovered element 85 with a magneto-optical machine, and named the element Alabamine, but was mistaken. In 1937, Rajendralal De claimed to have discovered element 85 in minerals, and called the element dakine, but he was also mistaken. An attempt at discovering element 85 in 1939 by Horia Hulubei and Yvette Cauchois via spectroscopy was also unsuccessful, as was an attempt in the same year by Walter Minder, who discovered an iodine-like element resulting from beta decay of polonium. Element 85, now named astatine, was produced successfully in 1940 by Dale R. Corson, K.R. Mackenzie, and Emilio G. Segr\u00e8, who bombarded bismuth with alpha particles.\nIn 2010, a team led by nuclear physicist Yuri Oganessian involving scientists from the JINR, Oak Ridge National Laboratory, Lawrence Livermore National Laboratory, and Vanderbilt University successfully bombarded berkelium-249 atoms with calcium-48 atoms to make tennessine. \nEtymology.\nIn 1811, the German chemist Johann Schweigger proposed that the name \"halogen\" \u2013 meaning \"salt producer\", from \u03b1\u03bb\u03c2 [hals] \"salt\" and \u03b3\u03b5\u03bd\u03b5\u03b9\u03bd [genein] \"to beget\" \u2013 replace the name \"chlorine\", which had been proposed by the English chemist Humphry Davy. Davy's name for the element prevailed. However, in 1826, the Swedish chemist Baron J\u00f6ns Jacob Berzelius proposed the term \"halogen\" for the elements fluorine, chlorine, and iodine, which produce a sea-salt-like substance when they form a compound with an alkaline metal.\nThe English names of these elements all have the ending -ine. Fluorine's name comes from the Latin word \"fluere\", meaning \"to flow\", because it was derived from the mineral fluorite, which was used as a flux in metalworking. Chlorine's name comes from the Greek word \"chloros\", meaning \"greenish-yellow\". Bromine's name comes from the Greek word \"bromos\", meaning \"stench\". Iodine's name comes from the Greek word \"iodes\", meaning \"violet\". Astatine's name comes from the Greek word \"astatos\", meaning \"unstable\". Tennessine is named after the US state of Tennessee, where it was synthesized.\nCharacteristics.\nChemical.\nThe halogens fluorine, chlorine, bromine, and iodine are nonmetals; the chemical properties of astatine and tennessine, two heaviest group\u00a017 members, have not been conclusively investigated. The halogens show trends in chemical bond energy moving from top to bottom of the periodic table column with fluorine deviating slightly. It follows a trend in having the highest bond energy in compounds with other atoms, but it has very weak bonds within the diatomic F2 molecule. This means that further down group\u00a017 in the periodic table, the reactivity of elements decreases because of the increasing size of the atoms.\nHalogens are highly reactive, and as such can be harmful or lethal to biological organisms in sufficient quantities. This high reactivity is due to the high electronegativity of the atoms due to their high effective nuclear charge. Because the halogens have seven valence electrons in their outermost energy level, they can gain an electron by reacting with atoms of other elements to satisfy the octet rule. Fluorine is the most reactive of all elements; it is the only element more electronegative than oxygen, it attacks otherwise-inert materials such as glass, and it forms compounds with the usually inert noble gases. It is a corrosive and highly toxic gas. The reactivity of fluorine is such that, if used or stored in laboratory glassware, it can react with glass in the presence of small amounts of water to form silicon tetrafluoride (SiF4). Thus, fluorine must be handled with substances such as Teflon (which is itself an organofluorine compound), extremely dry glass, or metals such as copper or steel, which form a protective layer of fluoride on their surface.\nThe high reactivity of fluorine allows some of the strongest bonds possible, especially to carbon. For example, Teflon is fluorine bonded with carbon and is extremely resistant to thermal and chemical attacks and has a high melting point.\nMolecules.\nDiatomic halogen molecules.\nThe stable halogens form homonuclear diatomic molecules.\nDue to relatively weak intermolecular forces, chlorine and fluorine form part of the group known as \"elemental gases\".\nThe elements become less reactive and have higher melting points as the atomic number increases. The higher melting points are caused by stronger London dispersion forces resulting from more electrons.\nCompounds.\nHydrogen halides.\nAll of the halogens have been observed to react with hydrogen to form hydrogen halides. For fluorine, chlorine, and bromine, this reaction is in the form of:\n H2 + X2 \u2192 2HX\nHowever, hydrogen iodide and hydrogen astatide can split back into their constituent elements.\nThe hydrogen-halogen reactions get gradually less reactive toward the heavier halogens. A fluorine-hydrogen reaction is explosive even when it is dark and cold. A chlorine-hydrogen reaction is also explosive, but only in the presence of light and heat. A bromine-hydrogen reaction is even less explosive; it is explosive only when exposed to flames. Iodine and astatine only partially react with hydrogen, forming equilibria.\nAll halogens form binary compounds with hydrogen known as the hydrogen halides: hydrogen fluoride (HF), hydrogen chloride (HCl), hydrogen bromide (HBr), hydrogen iodide (HI), and hydrogen astatide (HAt). All of these compounds form acids when mixed with water. Hydrogen fluoride is the only hydrogen halide that forms hydrogen bonds. Hydrochloric acid, hydrobromic acid, hydroiodic acid, and hydroastatic acid are all strong acids, but hydrofluoric acid is a weak acid.\nAll of the hydrogen halides are irritants. Hydrogen fluoride and hydrogen chloride are highly acidic. Hydrogen fluoride is used as an industrial chemical, and is highly toxic, causing pulmonary edema and damaging cells. Hydrogen chloride is also a dangerous chemical. Breathing in gas with more than fifty parts per million of hydrogen chloride can cause death in humans. Hydrogen bromide is even more toxic and irritating than hydrogen chloride. Breathing in gas with more than thirty parts per million of hydrogen bromide can be lethal to humans. Hydrogen iodide, like other hydrogen halides, is toxic.\nMetal halides.\nAll the halogens are known to react with sodium to form sodium fluoride, sodium chloride, sodium bromide, sodium iodide, and sodium astatide. Heated sodium's reaction with halogens produces bright-orange flames. Sodium's reaction with chlorine is in the form of:\n 2Na + Cl2 \u2192 2NaCl\nIron reacts with fluorine, chlorine, and bromine to form iron(III) halides. These reactions are in the form of:\n 2Fe + 3X2 \u2192 2FeX3\nHowever, when iron reacts with iodine, it forms only iron(II) iodide.\n Fe + I2 \u2192 FeI2\nIron wool can react rapidly with fluorine to form the white compound iron(III) fluoride even in cold temperatures. When chlorine comes into contact with a heated iron, they react to form the black iron(III) chloride. However, if the reaction conditions are moist, this reaction will instead result in a reddish-brown product. Iron can also react with bromine to form iron(III) bromide. This compound is reddish-brown in dry conditions. Iron's reaction with bromine is less reactive than its reaction with fluorine or chlorine. A hot iron can also react with iodine, but it forms iron(II) iodide. This compound may be gray, but the reaction is always contaminated with excess iodine, so it is not known for sure. Iron's reaction with iodine is less vigorous than its reaction with the lighter halogens.\nInterhalogen compounds.\nInterhalogen compounds are in the form of XYn where X and Y are halogens and n is one, three, five, or seven. Interhalogen compounds contain at most two different halogens. Large interhalogens, such as ClF3 can be produced by a reaction of a pure halogen with a smaller interhalogen such as ClF. All interhalogens except IF7 can be produced by directly combining pure halogens in various conditions.\nInterhalogens are typically more reactive than all diatomic halogen molecules except F2 because interhalogen bonds are weaker. However, the chemical properties of interhalogens are still roughly the same as those of diatomic halogens. Many interhalogens consist of one or more atoms of fluorine bonding to a heavier halogen. Chlorine and bromine can bond with up to five fluorine atoms, and iodine can bond with up to seven fluorine atoms. Most interhalogen compounds are covalent gases. However, some interhalogens are liquids, such as BrF3, and many iodine-containing interhalogens are solids.\nOrganohalogen compounds.\nMany synthetic organic compounds such as plastic polymers, and a few natural ones, contain halogen atoms; these are known as \"halogenated\" compounds or organic halides. Chlorine is by far the most abundant of the halogens in seawater, and the only one needed in relatively large amounts (as chloride ions) by humans. For example, chloride ions play a key role in brain function by mediating the action of the inhibitory transmitter GABA and are also used by the body to produce stomach acid. Iodine is needed in trace amounts for the production of thyroid hormones such as thyroxine. Organohalogens are also synthesized through the nucleophilic abstraction reaction.\nPolyhalogenated compounds.\nPolyhalogenated compounds are industrially created compounds substituted with multiple halogens. Many of them are very toxic and bioaccumulate in humans, and have a very wide application range. They include PCBs, PBDEs, and perfluorinated compounds (PFCs), as well as numerous other compounds.\nReactions.\nReactions with water.\nFluorine reacts vigorously with water to produce oxygen (O2) and hydrogen fluoride (HF):\n 2 F2(g) + 2 H2O(l) \u2192 O2(g) + 4 HF(aq)\nChlorine has maximum solubility of ca. 7.1 g Cl2 per kg of water at ambient temperature (21\u00a0\u00b0C). Dissolved chlorine reacts to form hydrochloric acid (HCl) and hypochlorous acid, a solution that can be used as a disinfectant or bleach:\n Cl2(g) + H2O(l) \u2192 HCl(aq) + HClO(aq)\nBromine has a solubility of 3.41 g per 100 g of water, but it slowly reacts to form hydrogen bromide (HBr) and hypobromous acid (HBrO):\n Br2(g) + H2O(l) \u2192 HBr(aq) + HBrO(aq)\nIodine, however, is minimally soluble in water (0.03 g/100 g water at 20\u00a0\u00b0C) and does not react with it. However, iodine will form an aqueous solution in the presence of iodide ion, such as by addition of potassium iodide (KI), because the triiodide ion is formed.\nPhysical and atomic.\nThe table below is a summary of the key physical and atomic properties of the halogens. Data marked with question marks are either uncertain or are estimations partially based on periodic trends rather than observations.\nIsotopes.\nFluorine has one stable and naturally occurring isotope, fluorine-19. However, there are trace amounts in nature of the radioactive isotope fluorine-23, which occurs via cluster decay of protactinium-231. A total of eighteen isotopes of fluorine have been discovered, with atomic masses ranging from 13 to 31. \nChlorine has two stable and naturally occurring isotopes, chlorine-35 and chlorine-37. However, there are trace amounts in nature of the isotope chlorine-36, which occurs via spallation of argon-36. A total of 24 isotopes of chlorine have been discovered, with atomic masses ranging from 28 to 51.\nThere are two stable and naturally occurring isotopes of bromine, bromine-79 and bromine-81. A total of 33 isotopes of bromine have been discovered, with atomic masses ranging from 66 to 98. \nThere is one stable and naturally occurring isotope of iodine, iodine-127. However, there are trace amounts in nature of the radioactive isotope iodine-129, which occurs via spallation and from the radioactive decay of uranium in ores. Several other radioactive isotopes of iodine have also been created naturally via the decay of uranium. A total of 38 isotopes of iodine have been discovered, with atomic masses ranging from 108 to 145.\nThere are no stable isotopes of astatine. However, there are four naturally occurring radioactive isotopes of astatine produced via radioactive decay of uranium, neptunium, and plutonium. These isotopes are astatine-215, astatine-217, astatine-218, and astatine-219. A total of 31 isotopes of astatine have been discovered, with atomic masses ranging from 191 to 227.\nThere are no stable isotopes of tennessine. Tennessine has only two known synthetic radioisotopes, tennessine-293 and tennessine-294.\nProduction.\nApproximately six million metric tons of the fluorine mineral fluorite are produced each year. Four hundred-thousand metric tons of hydrofluoric acid are made each year. Fluorine gas is made from hydrofluoric acid produced as a by-product in phosphoric acid manufacture. Approximately 15,000 metric tons of fluorine gas are made per year.\nThe mineral halite is the mineral that is most commonly mined for chlorine, but the minerals carnallite and sylvite are also mined for chlorine. Forty million metric tons of chlorine are produced each year by the electrolysis of brine.\nApproximately 450,000 metric tons of bromine are produced each year. Fifty percent of all bromine produced is produced in the United States, 35% in Israel, and most of the remainder in China. Historically, bromine was produced by adding sulfuric acid and bleaching powder to natural brine. However, in modern times, bromine is produced by electrolysis, a method invented by Herbert Dow. It is also possible to produce bromine by passing chlorine through seawater and then passing air through the seawater.\nIn 2003, 22,000 metric tons of iodine were produced. Chile produces 40% of all iodine produced, Japan produces 30%, and smaller amounts are produced in Russia and the United States. Until the 1950s, iodine was extracted from kelp. However, in modern times, iodine is produced in other ways. One way that iodine is produced is by mixing sulfur dioxide with nitrate ores, which contain some iodates. Iodine is also extracted from natural gas fields.\nEven though astatine is naturally occurring, it is usually produced by bombarding bismuth with alpha particles.\nTennessine is made by using a cyclotron, fusing berkelium-249 and calcium-48 to make tennessine-293 and tennessine-294.\nApplications.\nDisinfectants.\nBoth chlorine and bromine are used as disinfectants for drinking water, swimming pools, fresh wounds, spas, dishes, and surfaces. They kill bacteria and other potentially harmful microorganisms through a process known as sterilization. Their reactivity is also put to use in bleaching. Sodium hypochlorite, which is produced from chlorine, is the active ingredient of most fabric bleaches, and chlorine-derived bleaches are used in the production of some paper products.\nLighting.\nHalogen lamps are a type of incandescent lamp using a tungsten filament in bulbs that have small amounts of a halogen, such as iodine or bromine added. This enables the production of lamps that are much smaller than non-halogen incandescent lightbulbs at the same wattage. The gas reduces the thinning of the filament and blackening of the inside of the bulb resulting in a bulb that has a much greater life. Halogen lamps glow at a higher temperature (2800 to 3400 kelvin) with a whiter colour than other incandescent bulbs. However, this requires bulbs to be manufactured from fused quartz rather than silica glass to reduce breakage.\nDrug components.\nIn drug discovery, the incorporation of halogen atoms into a lead drug candidate results in analogues that are usually more lipophilic and less water-soluble. As a consequence, halogen atoms are used to improve penetration through lipid membranes and tissues. It follows that there is a tendency for some halogenated drugs to accumulate in adipose tissue.\nThe chemical reactivity of halogen atoms depends on both their point of attachment to the lead and the nature of the halogen. Aromatic halogen groups are far less reactive than aliphatic halogen groups, which can exhibit considerable chemical reactivity. For aliphatic carbon-halogen bonds, the C-F bond is the strongest and usually less chemically reactive than aliphatic C-H bonds. The other aliphatic-halogen bonds are weaker, their reactivity increasing down the periodic table. They are usually more chemically reactive than aliphatic C-H bonds. As a consequence, the most common halogen substitutions are the less reactive aromatic fluorine and chlorine groups.\nBiological role.\nFluoride anions are found in ivory, bones, teeth, blood, eggs, urine, and hair of organisms. Fluoride anions in very small amounts may be essential for humans. There are 0.5 milligrams of fluorine per liter of human blood. Human bones contain 0.2 to 1.2% fluorine. Human tissue contains approximately 50 parts per billion of fluorine. A typical 70-kilogram human contains 3 to 6 grams of fluorine.\nChloride anions are essential to a large number of species, humans included. The concentration of chlorine in the dry weight of cereals is 10 to 20 parts per million, while in potatoes the concentration of chloride is 0.5%. Plant growth is adversely affected by chloride levels in the soil falling below 2 parts per million. Human blood contains an average of 0.3% chlorine. Human bone typically contains 900 parts per million of chlorine. Human tissue contains approximately 0.2 to 0.5% chlorine. There is a total of 95 grams of chlorine in a typical 70-kilogram human.\nSome bromine in the form of the bromide anion is present in all organisms. A biological role for bromine in humans has not been proven, but some organisms contain organobromine compounds. Humans typically consume 1 to 20 milligrams of bromine per day. There are typically 5 parts per million of bromine in human blood, 7 parts per million of bromine in human bones, and 7 parts per million of bromine in human tissue. A typical 70-kilogram human contains 260 milligrams of bromine.\nHumans typically consume less than 100 micrograms of iodine per day. Iodine deficiency can cause intellectual disability. Organoiodine compounds occur in humans in some of the glands, especially the thyroid gland, as well as the stomach, epidermis, and immune system. Foods containing iodine include cod, oysters, shrimp, herring, lobsters, sunflower seeds, seaweed, and mushrooms. However, iodine is not known to have a biological role in plants. There are typically 0.06 milligrams per liter of iodine in human blood, 300 parts per billion of iodine in human bones, and 50 to 700 parts per billion of iodine in human tissue. There are 10 to 20 milligrams of iodine in a typical 70-kilogram human.\nAstatine, although very scarce, has been found in micrograms in the earth. It has no known biological role because of its high radioactivity, extreme rarity, and has a half-life of just about 8 hours for the most stable isotope. \nTennessine is purely man-made and has no other roles in nature.\nToxicity.\nThe halogens tend to decrease in toxicity towards the heavier halogens.\nFluorine gas is extremely toxic; breathing in fluorine at a concentration of 25 parts per million is potentially lethal. Hydrofluoric acid is also toxic, being able to penetrate skin and cause highly painful burns. In addition, fluoride anions are toxic, but not as toxic as pure fluorine. Fluoride can be lethal in amounts of 5 to 10 grams. Prolonged consumption of fluoride above concentrations of 1.5\u00a0mg/L is associated with a risk of dental fluorosis, an aesthetic condition of the teeth. At concentrations above 4\u00a0mg/L, there is an increased risk of developing skeletal fluorosis, a condition in which bone fractures become more common due to the hardening of bones. Current recommended levels in water fluoridation, a way to prevent dental caries, range from 0.7 to 1.2\u00a0mg/L to avoid the detrimental effects of fluoride while at the same time reaping the benefits. People with levels between normal levels and those required for skeletal fluorosis tend to have symptoms similar to arthritis.\nChlorine gas is highly toxic. Breathing in chlorine at a concentration of 3 parts per million can rapidly cause a toxic reaction. Breathing in chlorine at a concentration of 50 parts per million is highly dangerous. Breathing in chlorine at a concentration of 500 parts per million for a few minutes is lethal. In addition, breathing in chlorine gas is highly painful because of its corrosive properties. Hydrochloric acid is the acid of chlorine, while relatively nontoxic, it is highly corrosive and releases very irritating and toxic hydrogen chloride gas in open air.\nPure bromine is somewhat toxic but less toxic than fluorine and chlorine. One hundred milligrams of bromine is lethal. Bromide anions are also toxic, but less so than bromine. Bromide has a lethal dose of 30 grams.\nIodine is somewhat toxic, being able to irritate the lungs and eyes, with a safety limit of 1 milligram per cubic meter. When taken orally, 3 grams of iodine can be lethal. Iodide anions are mostly nontoxic, but these can also be deadly if ingested in large amounts.\nAstatine is radioactive and thus highly dangerous, but it has not been produced in macroscopic quantities and hence it is most unlikely that its toxicity will be of much relevance to the average individual.\nTennessine cannot be chemically investigated due to how short its half-life is, although its radioactivity would make it very dangerous.\nSuperhalogen.\nCertain aluminium clusters have superatom properties. These aluminium clusters are generated as anions (Al with \"n\" = 1,\u20092,\u20093,\u2009...\u2009) in helium gas and reacted with a gas containing iodine. When analyzed by mass spectrometry one main reaction product turns out to be .&lt;ref name=\"bergeron/2004\"&gt;&lt;/ref&gt; These clusters of 13 aluminium atoms with an extra electron added do not appear to react with oxygen when it is introduced in the same gas stream. Assuming each atom liberates its 3 valence electrons, this means 40 electrons are present, which is one of the magic numbers for sodium and implies that these numbers are a reflection of the noble gases.\nCalculations show that the additional electron is located in the aluminium cluster at the location directly opposite from the iodine atom. The cluster must therefore have a higher electron affinity for the electron than iodine and therefore the aluminium cluster is called a superhalogen (i.e., the vertical electron detachment energies of the moieties that make up the negative ions are larger than those of any halogen atom). The cluster component in the ion is similar to an iodide ion or a bromide ion. The related cluster is expected to behave chemically like the triiodide ion.&lt;ref name=\"bergeron/2005\"&gt;&lt;/ref&gt;\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "13259", "revid": "44120587", "url": "https://en.wikipedia.org/wiki?curid=13259", "title": "Home page", "text": "Main page of a website\nA home page (or homepage) is the main web page of a website. Usually, the home page is located at the root of the website's domain or subdomain. For example, if the domain is codice_1, the home page is likely located at the URL codice_2.\nThe term may also refer to the start page shown in a web browser when the application first opens.\nFunction.\nA home page is the main web page that a visitor will view when they navigate to a website via a search engine, and it may also function as a landing page to attract visitors. In some cases, the home page is a site directory, particularly when a website has multiple home pages.\nGood home page design is usually a high priority for a website; for example, a news website may curate headlines and first paragraphs of top stories, with links to full articles. According to \"Homepage Usability\", the home page is the \"most important page on any website\" and receives the most views of any page. A poorly designed home page can overwhelm and deter visitors from the site. One important use of home pages is communicating the identity and value of a company.\nBrowser start page.\nWhen a web browser is launched, it will automatically open at least one web page. This is the browser's start page, which is also called its home page.\nStart pages can be a website or a special browser page, such as thumbnails of frequently visited websites. Moreover, there is a niche market of websites intended to be used solely as start pages.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nBibliography.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "13260", "revid": "14001956", "url": "https://en.wikipedia.org/wiki?curid=13260", "title": "Hee Haw", "text": "American television variety show (1969\u201393 and 1996\u201397)\nHee Haw is an American television variety show featuring country music and humor with the fictional rural \"Kornfield Kounty\" as the backdrop. It aired from 1969 to 1993. Reruns of the series were broadcast on TNN from 1996 to 1997 on RFD-TV from September 2008 to April 2020, and aired on Circle. The \"Hee Haw\" reruns resumed in May 2024 on the RFD-TV / RuralTV network.\nThe show was inspired by \"Rowan &amp; Martin's Laugh-In\", but centered on country music, rural rather than pop culture\u2013inspired humor, and with far less topical material. Hosted by country music artists Buck Owens and Roy Clark for most of its run, the show was equally well known for its cornpone humor as for its voluptuous, scantily clad women (the \"Hee Haw Honeys\") in stereotypical farmer's daughter outfits.\n\"Hee Haw\"'s appeal, however, was not limited to a rural audience. It was successful in all of the major markets, including network-based Los Angeles and New York City, as well as Boston and Chicago. Other niche programs such as \"The Lawrence Welk Show\" and \"Soul Train\", which targeted older and black audiences, respectively, also rose to prominence in syndication during the era. Like \"Laugh-In\", the show minimized production costs by taping all of the recurring sketches for a season in batches, setting up the cornfield set one day, the joke fence on another, etc. At its peak, a season's worth of shows were recorded over the course of two separate, week-long shoots, and then assembled in the editing suite. Only musical performances were taped with a live audience, while a laugh track was added to all other segments.\nThe series was taped for the CBS Television Network at its station affiliate WLAC-TV (now WTVF) in downtown Nashville, Tennessee, and later at Opryland USA in the city's Donelson area. The show was produced by Yongestreet Productions through the mid-1980s; it was later produced by Gaylord Entertainment, which distributed the show in syndication. The show's name, derived from a common English onomatopoeia used to describe a donkey's braying, was coined by show-business talent manager and producer Bernie Brillstein.\nThe series initially ended its run in June 1993, after 25 seasons. It was soon picked up by TNN for reruns.\nSynopsis.\n\"Hee Haw\" is set in Kornfield Kounty, a rural farming community in an unspecified state in the Southern United States. The show's sketches mostly center around visits to local businesses in the county and the offbeat characters who live and work there.\nRecurring sketches and segments.\nSome of the most popular sketches and segments on \"Hee Haw\" included:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nThe \"PFFT\" would be done as \"blowing a raspberry\"; the one who got spat upon during the \"PFFT\" changed for each show. Following Campbell's death, whole groups and even women would be part of the chorus, with George Lindsey often singing the verse. Occasionally, Roni Stoneman (in her role of Ida Lee Nagger) would sometimes sing the verse. The song was written by Lee Roberts and recorded in 1952 by country singer Bob Newman.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nThe quartet began by singing the chorus together, followed by each quartet member reciting some humorous reason for his misery in spoken form, then (in the first several seasons) the quartet reprised the chorus and end with all four sobbing in typical overstated manner.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nTwo of the four girls then sang the verse. Misty Rowe, a long-time member of the \"Gossip Girls\", enhanced the comedy of the sketch by singing her part of the verse out of tune (as a young child would do). In later years, male cast members, in drag, sometimes replaced the girls in the sketch, in retaliation for the girls singing \"Gloom, Despair...\" Sometimes, in later seasons, the four female cast members sang the song on the cornfield set, with a male guest star standing in the center, between the four girls.\nCast.\nRural-style comedians Gordie Tapp and Don Harron gained their first major U.S. exposure on \"Hee Haw\".\nOther cast members over the years included:\nRoy Acuff,\nCathy Baker,\nWillie Ackerman,\nBilly Jim Baker,\nBarbi Benton,\nKelly Billingsley,\nVicki Bird,\nJennifer Bishop,\nArchie Campbell,\nPhil Campbell,\nHarry Cole (Weeping Willie),\nMackenzie Colt,\nJohn Henry Faulk,\nTennessee Ernie Ford,\nDiana Goodman,\nMarianne Gordon (Rogers),\nJim and Jon Hager,\nVictoria Hallman,\nLittle Jimmy Henley,\nGunilla Hutton,\nLinda Johnson,\nGrandpa Jones,\nZella Lehr (the \"unicycle girl\"),\nGeorge Lindsey (reprising his \"Goober\" character from \"The Andy Griffith Show\"),\nLittle Jimmy Dickens,\nIrlene Mandrell,\nCharlie McCoy,\nDawn McKinley,\nPatricia McKinnon,\nSherry Miles,\nRev. Grady Nutt,\nMinnie Pearl,\nClaude \"Jackie\" Phelps,\nSlim Pickens,\nKenny Price,\nAnne Randall,\nChase Randolph,\nSusan Raye,\nJimmie Riddle,\nJeannine Riley,\nAlice Ripley,\nLulu Roman,\nMisty Rowe,\nJunior Samples,\nRay Sanders,\nTerry Sanders,\nGailard Sartain,\nDiana Scott,\nShotgun Red,\nGerald Smith (the \"Georgia Quacker\"),\nJeff Smith,\nMike Snider,\nDonna Stokes,\nDennis Stone,\nRoni Stoneman,\nMary Taylor,\nNancy Taylor,\nLinda Thompson,\nLisa Todd,\nPedro Tomas,\nNancy Traylor,\nBuck Trent,\nJackie Waddell,\nPat Woodell, and\nJonathan Winters, among many others.\nThe Buckaroos (Buck Owens' band) initially served as the house band on the show and consisted of members Don Rich, Jim Shaw, Jerry Brightman, Jerry Wiggins, Rick Taylor, Doyle Singer (Doyle Curtsinger), Don Lee, Ronnie Jackson, Terry Christoffersen, Doyle Holly, fiddle player Jana Jae, and Victoria Hallman, who replaced Don Rich on harmony vocals. In later seasons, the show hired Nashville musicians to serve as the show's \"house band.\" George Richey was the first music director. When he left to marry Tammy Wynette, harmonica player Charlie McCoy, already a member of the band when he was not playing on recording sessions, became the show's music director, forming the \"Hee Haw Band\", which became the house band for the remainder of the series' run. The Nashville Edition, a singing quartet consisting of two males and two females, served as the background singers for most of the musical performances, along with performing songs on their own.\nGuest stars.\n\"Hee Haw\" featured at least two, and sometimes three or four, guest celebrities each week. While most of the guest stars were country music artists, a wide range of other famous luminaries were featured from actors and actresses to sports stars to politicians.\nSheb Wooley, one of the original cast members, wrote the show's theme song. After filming the initial 13 episodes, other professional demands caused him to leave the show, but he returned from time to time as a guest star.\nLoretta Lynn was the first guest star of \"Hee Haw\" and made more guest appearances (24) than any other artist. She also co-hosted the show more than any other guest co-host and therefore appears on more of the DVD releases for retail sale than any other guest star. Tammy Wynette was second with 21 guest appearances, and Wynette married George Richey (the musical director for \"Hee Haw\" from 1970 to 1977) in 1978.\nFrom 1990 to 1992, country megastar Garth Brooks appeared on the show four times. In 1992, producer Sam Lovullo tried unsuccessfully to contact Brooks because he wanted him for the final show. Brooks then surprised Lovullo by showing up at the last minute, ready to don his overalls and perform for the final episode.\nElvis connection.\nElvis Presley was a fan of \"Hee Haw\" and wanted to appear as a guest on the program, but Presley knew his manager, Colonel Tom Parker, would not allow him to do so (following Presley's death, Parker would be sued by Elvis Presley Enterprises for mismanagement). Two of the Hee Haw Honeys dated Presley long before they joined the cast: Linda Thompson in the mid-1970s, with whom Presley had a long-term relationship after his divorce from Priscilla; and Diana Goodman shortly afterwards. Charlie McCoy played harmonica on a select few of Presley's recordings in the late 1960s, Joe Babcock of the Nashville Edition also sang backup vocals on a couple of his recordings at that time, and the Nashville Edition sang backup on Presley's recording of \"Early Morning Rain.\" Shortly after Presley's death, his father, Vernon Presley, made a cameo appearance on the show, alongside Thompson and Buck Owens, and paid tribute to his late son, noting how much Elvis enjoyed watching the show, and introduced one of his favorite gospel songs, which was performed by the Hee Haw Gospel Quartet.\nProduction.\nCreation.\n\"Hee Haw's\" creators, Frank Peppiatt and John Aylesworth, were both Canadian-born writers who had extensive experience in writing for variety shows. Inspired by the enormous prior success of rural sitcoms of the 1960s, especially on CBS, which included the small-town sympathetic \"The Andy Griffith Show\", followed by the country-parodying \"The Beverly Hillbillies\", \"Petticoat Junction\" and \"Green Acres\", Peppiatt and Aylesworth sought to create a variety show catering to the same audience\u2014although neither one had a firm grasp on rural comedy.\nThe producers selected a pair of hosts who represented each side in a divide in country/western music at the time: Buck Owens was a prominent architect of the California-based Bakersfield sound and one of the biggest country hitmakers of the 1960s. Roy Clark, who had worked in Washington, D.C., and Las Vegas, was a stalwart of Nashville's Music Row known for his skill at mixing music and comedy onstage. Both Clark and Owens had been regular guests on \"The Jimmy Dean Show\" during Peppiatt and Aylesworth's time writing for that series. Peppiatt and Aylesworth brought on two fellow Canadian writers with more experience in rural humor, Gordie Tapp and Don Harron; Harron would appear in the recurring role of \"Charlie Farquharson\", the rural anchorman for station KORN. The producers also scored a country comedy expert familiar to rural audiences in Archie Campbell, who co-starred in and wrote many of the jokes and sketches, along with Tapp, George Yanok and comedian Jack Burns (who himself had briefly replaced Don Knotts on \"The Andy Griffith Show\") in the sixth season.\nStage settings.\nA barn interior set was used as the main stage for most of the musical performances from the show's premiere until the debut of the \"Hee Haw Honky Tonk\" sketch in the early 1980s. Afterwards, the \"Hee Haw Honky Tonk\" set would serve as the main stage for the remainder of the series' run. Buck Owens then began using the barn interior set for his performances after it was replaced by the \"Hee Haw Honky Tonk\" set and was named \"Buck's Place\" (as a nod to one of Owens' hits, \"Sam's Place\"). Other settings for the musical performances throughout the series' run included a haystack (where the entire cast performed songs), the living room of a Victorian house, the front porch and lawn of the Samuel B. Sternwheeler home, a grist mill (where Roy Clark performed many of his songs in earlier seasons), and a railroad depot, where Buck Owens performed his songs before acquiring \"Buck's Place.\"\nMusic.\n\"Hee Haw\" featured a premiere showcase on commercial television throughout its run for country, bluegrass, gospel, and other styles of American traditional music, featuring hundreds of elite musical performances that were paramount to the success, popularity and legacy of the series for a broad audience of Southern, rural and purely music fans alike. Although country music was the primary genre of music featured on the show, guest stars and cast members alike also performed music from other genres, such as rock 'n' roll oldies, big band, and pop standards.\nSome of the music-based segments on the show (other than guest stars' performances) included:\nLovullo also has made the claim the show presented \"what were, in reality, the first musical videos.\" Lovullo said his videos were conceptualized by having the show's staff go to nearby rural areas and film animals and farmers, before editing the footage to fit the storyline of a particular song. \"The video material was a very workable production item for the show\", he wrote. \"It provided picture stories for songs. However, some of our guests felt the videos took attention away from their live performances, which they hoped would promote record sales. If they had a hit song, they didn't want to play it under comic barnyard footage.\" The concept's mixed reaction eventually spelled an end to the \"video\" concept on \"Hee Haw\". However, several of co-host Owens' songs\u2014including \"Tall, Dark Stranger\", \"Big in Vegas\", and \"I Wouldn't Live in New York City (If They Gave Me the Whole Dang Town)\"\u2014aired on the series and have since aired on Great American Country and CMT as part of their classic country music programming blocks.\nRelease.\nBroadcast.\n\"Hee Haw\" premiered on CBS on June 15, 1969, as a summer series. The show played to the rural roots of its humor with the producers arranging with the network to have the show segments recorded and edited in Nashville at CBS affiliate WLAC-TV (now WTVF). The network picked it up as a last-minute replacement for \"The Smothers Brothers Comedy Hour\", a popular but controversial variety show that had been canceled amid feuds between the Smothers Brothers and the network censors over the show's topical humor.\nThough \"Hee Haw\" had solid ratings overall (it sat at No. 16 for the 1970\u201371 season), it was dropped in July 1971 by CBS as part of the so-called \"Rural Purge\" that abruptly canceled all of the network's country-themed shows, including those with still-respectable ratings. The success of shows like \"Hee Haw\" was the source of a heated dispute in CBS's corporate offices: Vice President of network programming Michael Dann, although he personally disliked the shows, argued in favor of ratings (reflecting audience size), while his subordinate, Fred Silverman, head of daytime programming, held that certain demographics within total television viewership\u2014in which \"Hee Haw\" and the others performed poorly\u2014could draw more advertising dollars. Silverman's view won out, Dann was fired, Silverman promoted, and CBS canceled its rural shows in the summer of 1971.\nSyndication.\nUndaunted, and noting that one instigating factor for the rural purge\u2014the Prime Time Access Rule\u2014had opened up an opportunity for independent syndicated productions, \"Hee Haw's\" producers put together a syndication deal for the show, which continued in roughly the same format for the rest of its run. Peppiatt and Aylesworth's company, Yongestreet Productions (named for Yonge Street, a prominent thoroughfare in their home city of Toronto), maintained ownership of the series.\nAt its peak, \"Hee Haw\" often competed in syndication against \"The Lawrence Welk Show\", a long-running ABC program which had likewise been canceled in 1971, in its case in a purge of the networks' older demographic-leaning programs. Like \"Hee Haw\", \"Lawrence Welk\" was picked up for syndication in the fall of 1971, in some markets by the same stations. The success of the two shows in syndication, and the network decisions that led to their respective cancellations, were the inspiration for a novelty song, \"The Lawrence Welk-Hee Haw Counter-Revolution Polka\", performed by Clark; it rose to become a top 10 hit on the \"Billboard\" Hot Country Singles chart in the fall of 1972.\n\"Welk\" and \"Hee Haw\" also competed against another music-oriented niche program that moved to syndication in 1971, \"Soul Train\". Originally a local program based in Chicago, the black-oriented program also went on to a very long run in syndication; unlike either program, \"Soul Train\" entered the market after achieving success at the local level.\nIn 1981, Yongestreet was acquired by Gaylord Entertainment (best known for the \"Grand Ole Opry\" and its related businesses). Mirroring the long downward trend in the popularity of variety shows in general that had taken place in the 1970s, ratings began to decline for \"Hee Haw\" around 1986. That year, Owens departed as host, leaving Clark to continue with a celebrity guest host each week. The ratings decline continued into the early 1990s. In the fall of 1991, in an attempt to win back viewers, attract a younger audience, and keep pace with sweeping changes in the country music industry of the era, the show's format and setting underwent a dramatic overhaul. The changes included a new title (\"The Hee Haw Show\"), more pop-oriented country music, and the barnyard-cornfield setting replaced by a city street and shopping mall set. The first of the new episodes aired in January 1992. The changes alienated many of the show's longtime viewers while failing to gain the hoped-for younger viewers, and the ratings continued their decline.\nDuring the summer of 1992, a decision was made to end first-run production, and instead air highlights of the show's earlier years in a revamped program called \"Hee Haw Silver\" (as part of celebrating the show's 25th season). Under the new format, Clark hosted a mixture of classic clips and new footage.\n\"Hee Haw Silver\" episodes also aired a series of retrospective looks at performers who had died since performing in highlighted content, such as David \"Stringbean\" Akeman, Archie Campbell, Junior Samples, and Kenny Price. According to the show's producer, Sam Lovullo, the ratings showed improvement with these classic reruns; however, the series was finally canceled in June 1993 at the conclusion of its 25th season. \"Hee Haw\" continued to pop up in reruns throughout the 1990s and later during the following decade in a series of successful DVD releases from Time Life.\nReruns.\nAfter the show's syndication run ended, reruns aired on The Nashville Network from 1993 until 1995. Upon the cancellation of reruns in 1995, the program resurfaced a year later, for another run of reruns, ultimately concluding in 1997. Its 22 years in TV syndication (1971\u201393) was, during its latter years, tied with \"Soul Train\" with the record for the longest-running American syndicated TV program (\"Soul Train\" continued until 2006); \"Hee Haw\" has fallen well behind several other American first-run syndicated shows since then.\nDuring the 2006\u201307 season CMT aired a series of reruns and TV Land also recognized the series with an award presented by k.d. lang; in attendance were Roy Clark, Gunilla Hutton, Barbi Benton, the Hager twins, Linda Thompson, Misty Rowe, and others. It was during this point, roughly between the years of 2004 and 2007, that Time Life began selling selected episodes of the show on DVD. Among the DVD content offered was the 1978 10th anniversary special that had not been seen since its original airing. CMT sporadically aired the series, usually in graveyard slots, and primarily held the rights in order to be able to air the musical performances as part of their music video library (such as during the \"Pure Vintage\" block on CMT Pure Country).\nReruns of \"Hee Haw\" began airing on RFD-TV in September 2008, where it ran for 12 years, anchoring the network's Sunday night lineup, although beginning in January 2014 an episode airs on Saturday afternoon and the same episode is rerun the following Sunday night; those episodes were cut down to comply with the 44-minute minimum. In 2011, the network began re-airing the earliest episodes from 1969 to 1970 on Thursday evenings. That summer, many of the surviving cast members, along with a number of country artists who were guest stars on the show, taped a \"Country's Family Reunion\" special, entitled \"Salute to the Kornfield\", which aired on RFD-TV in January 2012. The special is also part of \"Country's Family Reunion\"'s DVD series. Concurrent with the special was the unveiling of a \"Hee Haw\" exhibit, titled \"Pickin' and Grinnin' \", at the Oklahoma History Center in Oklahoma City.\n\"Hee Haw\" left RFD-TV in 2020 and then aired on the Grand Ole Opry-operated Circle network. In May 2024, after Circle had left terrestrial television and ceased carrying the series online, RFD-TV resumed carrying \"Hee Haw\".\nAs part of the promotions for its DVD products, Time-Life also compiles and syndicates a half-hour clip show series \"The Hee Haw Collection\".\nReception.\nNielsen ratings.\nWhen \"Hee Haw\" went into syndication, many stations aired the program on Saturday evening in the early fringe hour, generally at 7:00pm ET / PT. But as \"Hee Haw\" was syndicated and not restrained by the scheduling of a network, stations could schedule the program at any day or time that they saw fit.\nLegacy.\n\"Hee Haw\" continues to remain popular with its long-time fans and younger viewers who have discovered the program through DVD releases or its reruns through the years on TNN, CMT, RFD-TV, and now Circle TV. In spite of the popularity among its fans, the program has never been a favorite of television critics or reviewers; the \"Hee Haw Honeys\" spin-off, in particular, was cited in a 2002 \"TV Guide\" article as one of the 10 worst television series ever.\nIn popular culture.\nIn the third-season episode of \"The Simpsons\", \"Colonel Homer\", \"Hee Haw\" is parodied as the TV show \"Ya Hoo!\".\nOn at least four episodes of the animated Fox series \"Family Guy\", when the storyline hits a dead-end, a cutaway to Conway Twitty performing a song is inserted. The hand-off is done in \"Hee Haw\" style, and often uses actual footage of Twitty performing on the show.\nLulu Roman released a new album titled \"At Last\" on January 15, 2013. The album features Lulu's versions of 12 classics and standards, including guest appearances by Dolly Parton, T. Graham Brown, Linda Davis, and Georgette Jones (daughter of George Jones and Tammy Wynette).\nThe series was referenced in \"The Critic\" as a parody crossover with \"\" under the title of \"Hee Haw: The Next Generation\", where the characters of the \"Star Trek\" series act out as the cast of \"Hee Haw\".\n\"Wonder Showzen\" has a segment (\"Horse Apples\") and eventually full episode, \"Mathematics\", which parodies \"Hee Haw\". The latter episode featured several guest actors including David Cross, Zach Galifianakis and Heather Lawless.\nOther media.\n\"Hee Haw Honeys\" (spin-off series).\n\"Hee Haw\" produced a short-lived spin-off series, \"Hee Haw Honeys\", for the 1978\u201379 television season. This musical sitcom starred Kathie Lee Johnson (Gifford) along with \"Hee Haw\" regulars Misty Rowe, Gailard Sartain, Lulu Roman, and Kenny Price as a family who owned a truck stop restaurant (likely inspired by the \"Lulu's Truck Stop\" sketch on \"Hee Haw\"). Their restaurant included a bandstand, where guest country artists would perform a couple of their hits of the day, sometimes asking the cast to join them. Cast members would also perform songs occasionally; and the Nashville Edition, \"Hee Haw's\" backup singing group, frequently appeared on the show, portraying regular patrons of the restaurant. Notable guest stars on \"Honeys\" included, but were not limited to: Loretta Lynn, The Oak Ridge Boys, Larry Gatlin, Dave &amp; Sugar, and the Kendalls. Some stations that carried \"Hee Haw\" would air an episode of \"Honeys\" prior to \"Hee Haw\".\nHee Haw Theater.\nThe Hee Haw Theater opened in Branson, Missouri in 1981 and operated through 1983. It featured live shows using the cast of the television series, as well as guests and other talent. The format was similar with a country variety show-type family theme.\nComic book adaptations.\nCharlton Comics also published humor comics based on \"Hee Haw\". They were drawn by Frank Roberge.\nFootnotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "13263", "revid": "51061067", "url": "https://en.wikipedia.org/wiki?curid=13263", "title": "Hexadecimal", "text": "Base-16 numeric representation\nHexadecimal (hex for short) is a positional numeral system for representing a numeric value as base 16. For the most common convention, a digit is represented as \"0\" to \"9\" like for decimal and as a letter of the alphabet from \"A\" to \"F\" (either upper or lower case) for the digits with decimal value 10 to 15.\nAs typical computer hardware is binary in nature and that hex is power of 2, the hex representation is often used in computing as a dense representation of binary information. A hex digit represents 4 contiguous bits \u2013known as a nibble. An 8-bit byte is two hex digits, such as .\nSpecial notation is often used to indicate that a number is hex. In mathematics, a subscript is typically used to specify the base. For example, the decimal value would be expressed in hex as . In computer programming, various notations are used. In C and many related languages, the prefix codice_1 is used. For example, codice_1.\nWritten representation.\nCommon convention.\nTypically, a hex representation convention allows either lower or upper case letters and treats the letter the same regardless of its case.\nOften when rendering non-textual data, a value stored in memory is displayed as a sequence of hex digits with spaces between values. For instance, in the following hex dump, each 8-bit byte is a 2-digit hex number, with spaces between them, while the 32-bit offset at the start is an 8-digit hex number.\n00000000 57 69 6B 69 70 65 64 69 61 2C 20 74 68 65 20 66 \n00000010 72 65 65 20 65 6E 63 79 63 6C 6F 70 65 64 69 61 \n00000020 20 74 68 61 74 20 61 6E 79 6F 6E 65 20 63 61 6E\n00000030 20 65 64 69 74 2C 20 69 6E 63 6C 75 64 69 6E 67\n00000040 20 79 6F 75 20 28 61 6E 64 20 6D 65 29 21\nIdentification.\nThere are several conventions for expressing that a number is represented as hex.\nImplicit.\nIn some contexts, a number is always written as hex, and therefore, needs no identification notation.\nAlternative symbols.\nNotable other hexadecimal representations that use symbols other than letters \"A\" through \"F\" to represent the digits above 9 include:\nSign.\nThe hex system can express negative numbers the same way as in decimal, by putting a minus sign (\u2212) before the number to indicate that it is negative.\nBit pattern.\nHex can express the bit pattern in a processor, so a sequence of hex digits may represent a signed or even a floating-point value. This way, the negative number \u22124210 can be written as FFFF\u00a0FFD6 in a 32-bit CPU register (in two's complement), as C228\u00a00000 in a 32-bit FPU register or C045\u00a00000\u00a00000\u00a00000 in a 64-bit FPU register (in the IEEE floating-point standard).\nExponential notation.\nJust as decimal numbers can be represented in exponential notation, so too can hex numbers. P notation uses the letter \"P\" (or \"p\", for \"power\"), whereas \"E\" (or \"e\") serves a similar purpose in decimal E notation. The number after the \"P\" is \"decimal\" and represents the \"binary\" exponent. Increasing the exponent by 1 multiplies by 2, not 16: 20p0 = 10p1 = 8p2 = 4p3 = 2p4 = 1p5. Usually, the number is normalized so that the hex digits start with 1. (zero is usually 0 with no \"P\").\nExample: 1.3DEp42 represents 1.3DE16\u2009\u00d7\u200924210.\nP notation is required by the IEEE 754-2008 binary floating-point standard and can be used for floating-point literals in the C99 edition of the C programming language.\nUsing the \"%a\" or \"%A\" conversion specifiers, this notation can be produced by implementations of the \"printf\" family of functions following the C99 specification and\nSingle Unix Specification (IEEE Std 1003.1) POSIX standard.\nVerbal representation.\nSince there were no traditional numerals to represent the quantities from ten to fifteen, alphabetic letters were re-employed as a substitute. Most European languages lack non-decimal-based words for some of the numerals eleven to fifteen. Some people read hex numbers digit by digit, like a phone number, or using the NATO phonetic alphabet, the Joint Army/Navy Phonetic Alphabet, or a similar ad hoc system. In the wake of the adoption of hex among IBM System/360 programmers, Magnuson (1968) suggested a pronunciation guide that gave short names to the letters of hex \u2013 for instance, \"A\" was pronounced \"ann\", B \"bet\", C \"chris\", etc. Another naming-system was published online by Rogers (2007) that tries to make the verbal representation distinguishable in any case, even when the actual number does not contain numbers A\u2013F. Examples are listed in the tables below. Yet another naming system was elaborated by Babb (2015), based on a joke in \"Silicon Valley\". The system proposed by Babb was further improved by Atkins-Bittner in 2015-2016.\nOthers have proposed using the verbal Morse code conventions to express four-bit hex digits, with \"dit\" and \"dah\" representing zero and one, respectively, so that \"0000\" is voiced as \"dit-dit-dit-dit\" (...), \"dah-dit-dit-dah\" (-..-) voices the digit with a value of nine, and \"dah-dah-dah-dah\" (----) voices the hex digit for decimal 15.\nSystems of counting on digits have been devised for both binary and hex. Arthur C. Clarke suggested using each finger as an on/off bit, allowing finger counting from zero to 102310 on ten fingers. Another system for counting up to FF16 (25510) is illustrated on the right.\nConversion.\nBinary conversion.\nMost computers manipulate binary data, but it is difficult for humans to work with a large number of digits for even a relatively small binary number. Although most humans are familiar with the base 10 system, it is much easier to map binary to hex than to decimal because each hex digit maps to a whole number of bits (410).\nThis example converts 11112 to base ten. Since each position in a binary numeral can contain either a 1 or a 0, its value may be easily determined by its position from the right:\nTherefore:\nWith little practice, mapping 11112 to F16 in one step becomes easy. The advantage of using hex rather than decimal increases rapidly with the size of the number. When the number becomes large, conversion to decimal is very tedious. However, when mapping to hex, it is trivial to regard the binary string as 4-digit groups and map each to a single hex digit.\nThis example shows the conversion of a binary number to decimal, mapping each digit to the decimal value, and adding the results.\nCompare this to the conversion to hex, where each group of four digits can be considered independently and converted directly:\nThe conversion from hex to binary is equally direct.\nOther simple conversions.\nAlthough quaternary (base 4) is little used, it can easily be converted to and from hex or binary. Each hex digit corresponds to a pair of quaternary digits, and each quaternary digit corresponds to a pair of binary digits. In the above example 2\u00a05\u00a0C16 = 02\u00a011\u00a0304.\nThe octal (base 8) system can also be converted with relative ease, although not quite as trivially as with bases 2 and 4. Each octal digit corresponds to three binary digits, rather than four. Therefore, we can convert between octal and hex via an intermediate conversion to binary followed by regrouping the binary digits in groups of either three or four.\nDivision-remainder in source base.\nAs with all bases there is a simple algorithm for converting a representation of a number to hex by doing integer division and remainder operations in the source base. In theory, this is possible from any base, but for most humans, only decimal and for most computers, only binary (which can be converted by far more efficient methods) can be easily handled with this method.\nLet d be the number to represent in hex, and the series hihi\u22121...h2h1 be the hex digits representing the number.\n\"16\" may be replaced with any other base that may be desired.\nThe following is a JavaScript implementation of the above algorithm for converting any number to a hex in String representation. Its purpose is to illustrate the above algorithm. To work with data seriously, however, it is much more advisable to work with bitwise operators.\nfunction toHex(d) {\n var r = d % 16;\n if (d - r == 0) {\n return toChar(r);\n return toHex((d - r) / 16) + toChar(r);\nfunction toChar(n) {\n const alpha = \"0123456789ABCDEF\";\n return alpha.charAt(n);\nConversion through addition and multiplication.\nIt is also possible to make the conversion by assigning each place in the source base the hex representation of its place value \u2013before carrying out multiplication and addition to get the final representation. For example, to convert the number B3AD to decimal, one can split the hex number into its digits: B (1110), 3 (310), A (1010) and D (1310), and then get the final result by multiplying each decimal representation by 16\"p\" (\"p\" being the corresponding hex digit position, counting from right to left, beginning with 0). In this case, we have that:\nB3AD \n (11\u2009\u00d7\u2009163) + (3\u2009\u00d7\u2009162) + (10\u2009\u00d7\u2009161) + (13\u2009\u00d7\u2009160)\nwhich is 45997 in base 10.\nTools for conversion.\nMany computer systems provide a calculator utility capable of performing conversions between the various radices frequently including hex.\nIn Microsoft Windows, the Calculator, on its Programmer mode, allows conversions between hex and other common programming bases.\nElementary arithmetic.\nElementary operations such as division can be carried out indirectly through conversion to an alternate numeral system, such as the commonly used decimal system or the binary system where each hex digit corresponds to four binary digits.\nAlternatively, one can also perform elementary operations directly within the hex system itself \u2013by relying on its addition/multiplication tables and its corresponding standard algorithms such as long division and the traditional subtraction algorithm.\nReal numbers.\nRational numbers.\nAs with other numeral systems, the hex system can be used to represent rational numbers, although repeating expansions are common since sixteen (1016) has only a single prime factor: two.\nFor any base, 0.1 (or \"1/10\") is always equivalent to one divided by the representation of that base value in its own number system. Thus, whether dividing one by two for binary or dividing one by sixteen for hex, both of these fractions are written as codice_43. Because the radix 16 is a perfect square (42), fractions expressed in hex have an odd period much more often than decimal ones, and there are no cyclic numbers (other than trivial single digits). Recurring digits are exhibited when the denominator in lowest terms has a prime factor not found in the radix; thus, when using hex notation, all fractions with denominators that are not a power of two result in an infinite string of recurring digits (such as thirds and fifths). This makes hex (and binary) less convenient than decimal for representing rational numbers since a larger proportion lies outside its range of finite representation.\nAll rational numbers finitely representable in hex are also finitely representable in decimal, duodecimal and sexagesimal: that is, any hex number with a finite number of digits also has a finite number of digits when expressed in those other bases. Conversely, only a fraction of those finitely representable in the latter bases are finitely representable in hex. For example, decimal 0.1 corresponds to the infinite recurring representation 0.19 in hex. However, hex is more efficient than duodecimal and sexagesimal for representing fractions with powers of two in the denominator. For example, 0.062510 (one-sixteenth) is equivalent to 0.116, 0.0912, and 0;3,4560.\nIrrational numbers.\nThe table below gives the expansions of some common irrational numbers in decimal and hex.\nPowers.\nThe first 16 powers of 2 are below as hex to show relative simplicity compared to decimal representation.\nCultural history.\nThe traditional Chinese units of measurement were base-16. For example, one j\u012bn\u00a0(\u65a4) in the old system equals sixteen taels. The suanpan (Chinese abacus) can be used to perform hex calculations such as additions and subtractions.\nAs with the duodecimal system, there have been occasional attempts to promote hex as the preferred numeral system. These attempts often propose specific pronunciation and symbols for the individual numerals. Some proposals unify standard measures so that they are multiples of 16.\nAn early such proposal was put forward by John W. Nystrom in \"Project of a New System of Arithmetic, Weight, Measure and Coins: Proposed to be called the Tonal System, with Sixteen to the Base\", published in 1862.\nNystrom among other things suggested hexadecimal time, which subdivides a day by 16,\nso that there are 16 \"hours\" (or \"10 \"tims\"\", pronounced \"tontim\") in a day.\nThe word \"hexadecimal\" is first recorded in 1952. It is macaronic in the sense that it combines Greek \u1f15\u03be (hex) \"six\" with Latinate \"-decimal\".\nThe all-Latin alternative \"sexadecimal\" (compare the word \"sexagesimal\" for base 60) is older, and sees at least occasional use from the late 19th century.\nIt is still in use in the 1950s in Bendix documentation.\nSchwartzman (1994) argues that use of \"sexadecimal\" may have been avoided because of its suggestive abbreviation to \"sex\".\nMany western languages since the 1960s have adopted terms equivalent in formation to \"hexadecimal\" (e.g. French \"hexad\u00e9cimal\", Italian \"esadecimale\", Romanian \"hexazecimal\", Serbian \"\u0445\u0435\u043a\u0441\u0430\u0434\u0435\u0446\u0438\u043c\u0430\u043b\u043d\u0438\", etc.)\nbut others have introduced terms which substitute native words for \"sixteen\" (e.g. Greek \u03b4\u03b5\u03ba\u03b1\u03b5\u03be\u03b1\u03b4\u03b9\u03ba\u03cc\u03c2, Icelandic \"sext\u00e1ndakerfi\", Russian \"\u0448\u0435\u0441\u0442\u043d\u0430\u0434\u0446\u0430\u0442\u0435\u0440\u0438\u0447\u043d\u043e\u0439\" etc.)\nTerminology and notation did not become settled until the end of the 1960s.\nIn 1969, Donald Knuth argued that the etymologically correct term would be \"senidenary\", or possibly \"sedenary\", a Latinate term intended to convey \"grouped by 16\" modelled on \"binary\", \"ternary\", \"quaternary\", etc.\nAccording to Knuth's argument, the correct terms for \"decimal\" and \"octal\" arithmetic would be \"denary\" and \"octonary\", respectively.\nAlfred B. Taylor used \"senidenary\" in his mid-1800s work on alternative number bases, although he rejected base 16 because of its \"incommodious number of digits\".\nThe now-current notation using the letters A to F establishes itself as the de facto standard beginning in 1966, in the wake of the\npublication of the Fortran IV manual for IBM System/360, which (unlike earlier variants of Fortran) recognizes a standard for entering hexadecimal constants.\nAs noted above, alternative notations were used by NEC (1960) and The Pacific Data Systems\u00a01020 (1964). The standard adopted by IBM seems to have become widely adopted by 1968, when Bruce Alan Martin\nin his letter to the editor of the CACM complains that\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;With the ridiculous choice of letters A, B, C, D, E, F as hexadecimal number symbols adding to already troublesome problems of distinguishing octal (or hex) numbers from decimal numbers (or variable names), the time is overripe for reconsideration of our number symbols. This should have been done before poor choices gelled into a de facto standard!\nMartin's argument was that use of numerals 0 to 9 in nondecimal numbers \"imply to us a base-ten place-value scheme\":\n\"Why not use entirely new symbols (and names) for the seven or fifteen nonzero digits needed in octal or hex. Even use of the letters A through P would be an improvement, but entirely new symbols could reflect the binary nature of the system\".\nHe also argued that \"re-using alphabetic letters for numerical digits represents a gigantic backward step from the invention of distinct, non-alphabetic glyphs for numerals sixteen centuries ago\" (as Brahmi numerals, and later in a Hindu\u2013Arabic numeral system),\nand that the recent ASCII standards (ASA X3.4-1963 and USAS X3.4-1968)\n\"should have preserved six code table positions following the ten decimal digits\n-- rather than needlessly filling these with punctuation characters\"\n(\":;&lt;=&gt;?\") that might have been placed elsewhere among the 128 available positions.\nBase16.\nBase16 is a binary to text encoding in the family that also contains Base32, Base58, and Base64. Data is broken into 4-bit sequences, and each value (0-15) is encoded as a character. Although any 16 characters could be used, in practice, the ASCII digits \"0\"\u2013\"9\" and letters \"A\"\u2013\"F\" (or \"a\"\u2013\"f\") are used to align with the typical notation for hex numbers.\nSupport for Base16 encoding is ubiquitous in modern computing. It is the basis for the W3C standard for URL percent encoding, where a character is replaced with a percent sign \"%\" and its Base16-encoded form. Most modern programming languages directly include support for formatting and parsing Base16-encoded numbers.\nAdvantages of Base16 encoding include:\nDisadvantages include:"}
{"id": "13264", "revid": "5229428", "url": "https://en.wikipedia.org/wiki?curid=13264", "title": "Hex", "text": "Hex usually refers to:\nHex, HEX, or The Hex may also refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "13265", "revid": "37108366", "url": "https://en.wikipedia.org/wiki?curid=13265", "title": "Hitler (disambiguation)", "text": "Adolf Hitler (1889\u20131945) was the leader of Nazi Germany from 1933 to 1945.\nHitler may also refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "13266", "revid": "49325011", "url": "https://en.wikipedia.org/wiki?curid=13266", "title": "Histogram", "text": "Graphical representation of the distribution of numerical data\nA histogram is a visual representation of the distribution of quantitative data. To construct a histogram, the first step is to \"bin\" (or \"bucket\") the range of values\u2014 divide the entire range of values into a series of intervals\u2014and then count how many values fall into each interval. The bins are usually specified as consecutive, non-overlapping intervals of a variable. The bins (intervals) are adjacent and are typically (but not required to be) of equal size.\nHistograms give a rough sense of the density of the underlying distribution of the data, and often for density estimation: estimating the probability density function of the underlying variable. The total area of a histogram used for probability density is always normalized to 1. If the length of the intervals on the \"x\"-axis are all 1, then a histogram is identical to a relative frequency plot.\nHistograms are sometimes confused with bar charts. In a histogram, each bin is for a different range of values, so altogether the histogram illustrates the distribution of values. But in a bar chart, each bar is for a different category of observations (e.g., each bar might be for a different population), so altogether the bar chart can be used to compare different categories. Some authors recommend that bar charts always have gaps between the bars to clarify that they are not histograms.\nEtymology.\nThe term \"histogram\" was first introduced by Karl Pearson, the founder of mathematical statistics, in lectures delivered in 1892 at University College London. Pearson's term is sometimes incorrectly said to combine the Greek root \"\u03b3\u03c1\u03b1\u03bc\u03bc\u03b1\" (gramma) = \"figure\" or \"drawing\" with the root \"\u1f31\u03c3\u03c4\u03bf\u03c1\u03af\u03b1\" (historia) = \"inquiry\" or \"history\". Alternatively the root \"\u1f31\u03c3\u03c4\u03af\u03bf\u03bd\" (histion) is also proposed, meaning \"web\" or \"tissue\" (as in histology, the study of biological tissue). Both of these etymologies are incorrect, and in fact Pearson, who knew Ancient Greek well, derived the term from a different if homophonous Greek root, \"\u1f31\u03c3\u03c4\u03cc\u03c2\" = \"something set upright\", \"mast\", referring to the vertical bars in the graph. Pearson's new term was embedded in a series of other analogous neologisms, such as \"stigmogram\" and \"radiogram\". \nPearson himself noted in 1895 that although the term \"histogram\" was new, the type of graph it designates was \"a common form of graphical representation\".\nIn fact the technique of using a bar graph to represent statistical measurements was devised by the Scottish economist, William Playfair, in his \"Commercial and political atlas\" (1786).\nExamples.\nThis is the data for the histogram to the right, using 500 items:\nThe words used to describe the patterns in a histogram are: \"symmetric\", \"skewed left\" or \"right\", \"unimodal\", \"bimodal\" or \"multimodal\".\nIt is a good idea to plot the data using several different bin widths to learn more about it. Here is an example on tips given in a restaurant.\nThe U.S. Census Bureau found that there were 124 million people who work outside of their homes. Using their data on the time occupied by travel to work, the table below shows the absolute number of people who responded with travel times \"at least 30 but less than 35 minutes\" is higher than the numbers for the categories above and below it. This is likely due to people rounding their reported journey time. The problem of reporting values as somewhat arbitrarily rounded numbers is a common phenomenon when collecting data from people.\nThis histogram shows the number of cases per unit interval as the height of each block, so that the area of each block is equal to the number of people in the survey who fall into its category. The area under the curve represents the total number of cases (124 million). This type of histogram shows absolute numbers, with Q in thousands.\nThis histogram differs from the first only in the vertical scale. The area of each block is the fraction of the total that each category represents, and the total area of all the bars is equal to 1 (the fraction meaning \"all\"). The curve displayed is a simple density estimate. This version shows proportions, and is also known as a unit area histogram.\nIn other words, a histogram represents a frequency distribution by means of rectangles whose widths represent class intervals and whose areas are proportional to the corresponding frequencies: the height of each is the average frequency density for the interval. The intervals are placed together in order to show that the data represented by the histogram, while exclusive, is also contiguous. (E.g., in a histogram it is possible to have two connecting intervals of 10.5\u201320.5 and 20.5\u201333.5, but not two connecting intervals of 10.5\u201320.5 and 22.5\u201332.5. Empty intervals are represented as empty and not skipped.)\nMathematical definitions.\nThe data used to construct a histogram are generated via a function \"m\"\"i\" that counts the number of observations that fall into each of the disjoint categories (known as \"bins\"). Thus, if we let \"n\" be the total number of observations and \"k\" be the total number of bins, the histogram data \"m\"\"i\" meet the following conditions:\n formula_1\nA histogram can be thought of as a simplistic kernel density estimation, which uses a kernel to smooth frequencies over the bins. This yields a smoother probability density function, which will in general more accurately reflect distribution of the underlying variable. The density estimate could be plotted as an alternative to the histogram, and is usually drawn as a curve rather than a set of boxes. Histograms are nevertheless preferred in applications, when their statistical properties need to be modeled. The correlated variation of a kernel density estimate is very difficult to describe mathematically, while it is simple for a histogram where each bin varies independently.\nAn alternative to kernel density estimation is the average shifted histogram,\nwhich is fast to compute and gives a smooth curve estimate of the density without using kernels.\nCumulative histogram.\nA cumulative histogram: a mapping that counts the cumulative number of observations in all of the bins up to the specified bin. That is, the cumulative histogram \"M\"\"i\" of a histogram \"m\"\"j\" can be defined as:\n formula_2\nNumber of bins and width.\nThere is no \"best\" number of bins, and different bin sizes can reveal different features of the data. Grouping data is at least as old as Graunt's work in the 17th century, but no systematic guidelines were given until Sturges's work in 1926.\nUsing wider bins where the density of the underlying data points is low reduces noise due to sampling randomness; using narrower bins where the density is high (so the signal drowns the noise) gives greater precision to the density estimation. Thus varying the bin-width within a histogram can be beneficial. Nonetheless, equal-width bins are widely used.\nSome theoreticians have attempted to determine an optimal number of bins, but these methods generally make strong assumptions about the shape of the distribution. Depending on the actual data distribution and the goals of the analysis, different bin widths may be appropriate, so experimentation is usually needed to determine an appropriate width. There are, however, various useful guidelines and rules of thumb.\nThe number of bins \"k\" can be assigned directly or can be calculated from a suggested bin width\u00a0\"h\" as:\nformula_3\nThe braces indicate the ceiling function.\nformula_4\nSquare-root choice.\nwhich takes the square root of the number of data points in the sample and rounds to the next integer. This rule is suggested by a number of elementary statistics textbooks and widely implemented in many software packages.\nSturges's formula.\nSturges's rule is derived from a binomial distribution and implicitly assumes an approximately normal distribution.\nformula_5\nSturges's formula implicitly bases bin sizes on the range of the data, and can perform poorly if \"n\"\u00a0&lt;\u00a030, because the number of bins will be small\u2014less than seven\u2014and unlikely to show trends in the data well. On the other extreme, Sturges's formula may overestimate bin width for very large datasets, resulting in oversmoothed histograms. It may also perform poorly if the data are not normally distributed.\nWhen compared to Scott's rule and the Terrell-Scott rule, two other widely accepted formulas for histogram bins, the output of Sturges's formula is closest when \"n\" \u2248 100.\nformula_6\nRice rule.\nThe Rice rule is presented as a simple alternative to Sturges's rule.\nDoane's formula.\nDoane's formula is a modification of Sturges's formula which attempts to improve its performance with non-normal data.\nformula_7\nwhere formula_8 is the estimated 3rd-moment-skewness of the distribution and\nformula_9\nScott's normal reference rule.\nBin width formula_10 is given by\nformula_11\nwhere formula_12 is the sample standard deviation. Scott's normal reference rule is optimal for random samples of normally distributed data, in the sense that it minimizes the integrated mean squared error of the density estimate. This is the default rule used in Microsoft Excel.\nformula_13\nTerrell\u2013Scott rule.\nThe Terrell\u2013Scott rule is not a normal reference rule. It gives the minimum number of bins required for an asymptotically optimal histogram, where optimality is measured by the integrated mean squared error. The bound is derived by finding the 'smoothest' possible density, which turns out to be formula_14. Any other density will require more bins, hence the above estimate is also referred to as the 'oversmoothed' rule. The similarity of the formulas and the fact that Terrell and Scott were at Rice University when the proposed it suggests that this is also the origin of the Rice rule.\nFreedman\u2013Diaconis rule.\nThe Freedman\u2013Diaconis rule gives bin width formula_10 as:\nformula_16\nwhich is based on the interquartile range, denoted by IQR. It replaces 3.5\u03c3 of Scott's rule with 2 IQR, which is less sensitive than the standard deviation to outliers in data.\nMinimizing cross-validation estimated squared error.\nThis approach of minimizing integrated mean squared error from Scott's rule can be generalized beyond normal distributions, by using leave-one out cross validation:\nformula_17\nHere, formula_18 is the number of datapoints in the \"k\"th bin, and choosing the value of \"h\" that minimizes \"J\" will minimize integrated mean squared error.\nShimazaki and Shinomoto's choice.\nThe choice is based on minimization of an estimated \"L\"2 risk function\nformula_19\nwhere formula_20 and formula_21 are mean and biased variance of a histogram with bin-width formula_22, formula_23 and formula_24.\nVariable bin widths.\nRather than choosing evenly spaced bins, for some applications it is preferable to vary the bin width. This avoids bins with low counts. A common case is to choose \"equiprobable bins\", where the number of samples in each bin is expected to be approximately equal. The bins may be chosen according to some known distribution or may be chosen based on the data so that each bin has formula_25 samples. When plotting the histogram, the \"frequency density\" is used for the dependent axis. While all bins have approximately equal area, the heights of the histogram approximate the density distribution.\nFor equiprobable bins, the following rule for the number of bins is suggested:\nformula_26\nThis choice of bins is motivated by maximizing the power of a Pearson chi-squared test testing whether the bins do contain equal numbers of samples. More specifically, for a given confidence interval formula_27 it is recommended to choose between 1/2 and 1 times the following equation:\nformula_28\nWhere formula_29 is the probit function. Following this rule for formula_30 would give between formula_31 and formula_32; the coefficient of 2 is chosen as an easy-to-remember value from this broad optimum.\nRemark.\nA good reason why the number of bins should be proportional to formula_33 is the following: suppose that the data are obtained as formula_34 independent realizations of a bounded probability distribution with smooth density. Then the histogram remains equally \"rugged\" as formula_34 tends to infinity. If formula_36 is the \"width\" of the distribution (e. g., the standard deviation or the inter-quartile range), then the number of units in a bin (the frequency) is of order formula_37 and the \"relative\" standard error is of order formula_38. Compared to the next bin, the relative change of the frequency is of order formula_39 provided that the derivative of the density is non-zero. These two are of the same order if formula_10 is of order formula_41, so that formula_42 is of order formula_33. This simple cubic root choice can also be applied to bins with non-constant widths.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "13268", "revid": "13286072", "url": "https://en.wikipedia.org/wiki?curid=13268", "title": "Human anatomy", "text": "Scientific study of the morphology of the human body\nHuman anatomy (gr. \u1f00\u03bd\u03b1\u03c4\u03bf\u03bc\u03af\u03b1, \"dissection\", from \u1f00\u03bd\u03ac, \"up\", and \u03c4\u03ad\u03bc\u03bd\u03b5\u03b9\u03bd, \"cut\") is primarily the scientific study of the morphology of the human body. Anatomy is subdivided into gross anatomy and microscopic anatomy. Gross anatomy (also called macroscopic anatomy, topographical anatomy, regional anatomy, or anthropotomy) is the study of anatomical structures that can be seen by the naked eye. Microscopic anatomy is the study of minute anatomical structures assisted with microscopes, which includes histology (the study of the organization of tissues), and cytology (the study of cells). Anatomy, human physiology (the study of function), and biochemistry (the study of the chemistry of living structures) are complementary basic medical sciences that are generally together (or in tandem) to students studying medical sciences.\nIn some of its facets human anatomy is closely related to embryology, comparative anatomy and comparative embryology, through common roots in evolution; for example, much of the human body maintains the ancient segmental pattern that is present in all vertebrates with basic units being repeated, which is particularly obvious in the vertebral column and in the ribcage, and can be traced from very early embryos.\nThe human body consists of biological systems, that consist of organs, that consist of tissues, that consist of cells and connective tissue.\nThe history of anatomy has been characterized, over a long period of time, by a continually developing understanding of the functions of organs and structures of the body. Methods have also advanced dramatically, advancing from examination of animals through dissection of fresh and preserved cadavers (corpses) to technologically complex techniques developed in the 20th century.\nStudy.\nGenerally, physicians, dentists, physiotherapists, nurses, paramedics, radiographers, and students of certain biological sciences, learn gross anatomy and microscopic anatomy from anatomical models, skeletons, textbooks, diagrams, photographs, lectures, and tutorials. The study of microscopic anatomy (or histology) can be aided by practical experience examining histological preparations (or slides) under a microscope; and in addition, medical and dental students generally also learn anatomy with practical experience of dissection and inspection of cadavers (dead human bodies). A thorough working knowledge of anatomy is required for all medical doctors, especially surgeons, and doctors working in some diagnostic specialities, such as histopathology and radiology.\nHuman anatomy, physiology, and biochemistry are basic medical sciences, which are generally taught to medical students in their first year at medical school. Human anatomy can be taught regionally or systemically; that is, respectively, studying anatomy by bodily regions such as the head and chest, or studying by specific systems, such as the nervous or respiratory systems. The major anatomy textbook, \"Gray's Anatomy\", has recently been reorganized from a systems format to a regional format, which is in line with the modern teaching.\nAnatomy in visual arts.\nGross anatomy has become a key part of visual arts. Basic concepts of how muscles and bones function and deform with movement is key to drawing, painting or animating a human figure. Many books such as \"Human Anatomy for Artists: The Elements of Form\", are written as a guide to drawing the human body anatomically correctly. Leonardo da Vinci sought to improve his art through a better understanding of human anatomy. In the process he advanced both human anatomy and its representation in art.\nBecause the structure of a living organism is complex, anatomy is organized by levels, from the smallest components of cells to the largest organs and their relationship to other organs.\nApproaches.\nInternal organs (by region).\nHead and neck\nThorax\nAbdomen and pelvis (both sexes)\nMale pelvis\nFemale pelvis\nSurface anatomy.\nSurface anatomy, or superficial anatomy, is the study of anatomical landmarks that can be identified readily from the contours or other reference points on the surface of the body. It is important in human anatomy: with knowledge of superficial anatomy, physicians gauge the position and anatomy of deeper structures.\nCommon names of parts of the human body, from top to bottom:\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "13269", "revid": "40240973", "url": "https://en.wikipedia.org/wiki?curid=13269", "title": "Hilter", "text": "Place in Lower Saxony, Germany\nHilter is a municipality in the district Osnabr\u00fcck, Lower Saxony, Germany, in the hills of the Teutoburg Forest. As of 2020 it has a population of 10,429, and covers an area of 52.61\u00a0km2. Its highest elevation is the Hohnangel, 262 metres above sea level.\nHistory.\nThe municipality was united on 14 July 1972 by merging the municipalities Borgloh, Hankenberge and Hilter. Already in 1977 the municipalities Allendorf, Borgloh-Wellendorf, Ebbendorf, Eppendorf and Uph\u00f6fen were joined into the \"Einheitsgemeinde\" Borgloh.\nIndustry.\n&lt;templatestyles src=\"Stack/styles.css\"/&gt;\nHilter was well known for mining \"Hilter Gold\" ochre as well as its big margarine factory which owned one of the largest whaling fleets in the early 20th century.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "13270", "revid": "27823944", "url": "https://en.wikipedia.org/wiki?curid=13270", "title": "Hawaii", "text": "U.S. state\nHawaii ( ; ) is an island state of the United States, in the Pacific Ocean about southwest of the U.S. mainland. One of the two non-contiguous U.S. states (along with Alaska), it is the only state not on the North American mainland, the only state that is an archipelago, the only state in the tropics, and one of the two U.S. states, along with Texas, that were internationally recognized sovereign countries before becoming U.S. states. \nHawaii consists of 137 volcanic islands that make up almost the entire Hawaiian archipelago (the exception is Midway Atoll). Spanning , the state is physiographically and ethnologically part of the Polynesian subregion of Oceania. Hawaii's ocean coastline is consequently the fourth-longest in the U.S., at about . The eight main islands, from northwest to southeast, are Ni\u02bbihau, Kaua\u02bbi, O\u02bbahu, Moloka\u02bbi, L\u0101na\u02bbi, Kaho\u02bbolawe, Maui, and Hawai\u02bbi, after which the state is named; the last is often called the \"Big Island\" or \"Hawai\u02bbi Island\" to avoid confusion with the state or archipelago. The uninhabited Northwestern Hawaiian Islands make up most of the Papah\u0101naumoku\u0101kea Marine National Monument, the largest protected area in the U.S. and the fourth-largest in the world.\nOf the 50 U.S. states, Hawaii is the eight-smallest in land area and the 11th-least populous; but with 1.4 million residents, it ranks 13th in population density. Two-thirds of Hawaii residents live on O\u02bbahu, home to the state's capital and largest city, Honolulu. Hawaii is one of the most demographically diverse U.S. states, owing to its location in the central Pacific and over two centuries of migration. As one of nine majority-minority states, it has the only Asian American plurality, the largest Buddhist community, and largest proportion of multiracial people in the U.S. Consequently, Hawaii is a unique melting pot of North American and East Asian cultures, in addition to its indigenous Hawaiian heritage.\nSettled by Polynesians sometime between 1000 and 1200 CE, Hawaii was home to numerous independent chiefdoms. In 1778, British explorer James Cook was the first known non-Polynesian to arrive at the archipelago; early British influence is reflected in the state flag, which bears a Union Jack. An influx of European and American explorers, traders, and whalers soon arrived, leading to the decimation of the once-isolated indigenous community through the introduction of diseases such as syphilis, tuberculosis, smallpox, and measles; the native Hawaiian population declined from between 300,000 and one million to less than 40,000 by 1890. Hawaii became a unified, internationally recognized kingdom in 1810, remaining independent until American and European businessmen overthrew the monarchy in 1893; this led to annexation by the U.S. in 1898. As a strategically valuable U.S. territory, Hawaii was attacked by Japan on December 7, 1941, which brought it global and historical significance, and contributed to America's entry into World War II. Hawaii is the most recent state to join the union, on August 21, 1959. In 1993, the U.S. government formally apologized for its role in the overthrow of Hawaii's government, which had spurred the Hawaiian sovereignty movement and has led to ongoing efforts to obtain redress for the indigenous population.\nHistorically dominated by a plantation economy, Hawaii remains a major agricultural exporter due to its fertile soil and uniquely tropical climate in the U.S. Its economy has gradually diversified since the mid-20th century, with tourism and military defense becoming the two largest sectors. The state attracts visitors, surfers, and scientists with its diverse natural scenery, warm tropical climate, abundant public beaches, oceanic surroundings, active volcanoes, and clear skies on the Big Island. Hawaii hosts the United States Pacific Fleet, the world's largest naval command, as well as 75,000 employees of the Defense Department. Hawaii's isolation results in one of the highest costs of living in the U.S. But Hawaii is the third-wealthiest state, and residents have the longest life expectancy of any U.S. state, at 80.7 years.&lt;templatestyles src=\"Template:TOC limit/styles.css\" /&gt;\nEtymology.\nThe State of Hawaii derives its name from the name of its largest island, . A common explanation of the name of is that it was named for , a figure from Hawaiian oral tradition. He is said to have discovered the islands when they were first settled.\nThe Hawaiian language word is very similar to Proto-Polynesian \"*Sawaiki\", with the reconstructed meaning 'homeland'. Cognates of are found in other Polynesian languages, including M\u0101ori (), Rarotongan () and Samoan (). According to linguists Pukui and Elbert, \"elsewhere in Polynesia, or a cognate is the name of the underworld or of the ancestral home, but in Hawaii, the name has no meaning\".\nSpelling of state name.\nIn 1978, Hawaiian was added to the Constitution of the State of Hawaii as an official state language alongside English. The title of the state constitution is \"The Constitution of the State of Hawaii\". Article\u00a0XV, Section\u00a01 of the Constitution uses \"The State of Hawaii\". Diacritics were not used because the document, drafted in 1949, predates the use of the \u27e8\u02bb\u27e9 and the in modern Hawaiian orthography. The exact spelling of the state's name in the Hawaiian language is . \nIn the Hawaii Admission Act that granted Hawaiian statehood, the federal government used \"Hawaii\" as the state name, but most official state government publications, departments, and office titles use \"Hawai\u02bbi\", including the Governor of Hawai\u02bbi, the Hawai\u02bbi State Legislature, the Hawai\u02bbi State Judiciary, the University of Hawai\u02bbi, the Hawai\u02bbi State Seal, the Flag of Hawai\u02bbi, and the Hawai\u02bbi Board on Geographic Names. The Hawai\u02bbi Tourism Authority's official policy is to \"recognize the importance of using these markings to preserve the indigenous language and culture of Hawai\u02bbi and use them in all forms of communications.\"\nGeography and environment.\n&lt;templatestyles src=\"Template:Table alignment/tables.css\" /&gt;\nThere are eight main Hawaiian islands. Seven are inhabited, but only six are open to tourists and locals. Ni\u02bbihau is privately managed by brothers Bruce and Keith Robinson; access is restricted to those who have their permission. This island is also home to native Hawaiians. Access to uninhabited Kaho\u02bbolawe island is also restricted and anyone who enters without permission is subject to arrest. Kaho\u02bbolawe may also be dangerous since it was a military base during the world wars and could still have unexploded ordnance.\nTopography.\nThe Hawaiian archipelago is southwest of the contiguous United States. Hawaii is the southernmost U.S. state and the second farthest west, after Alaska. Like Alaska, Hawaii borders no other U.S. state. It is the only U.S. state not in North America, as it is in Oceania, and the only one completely surrounded by water and entirely an archipelago.\nIn addition to the eight main islands, the state has many smaller islands and islets. Ka\u02bbula is a small island near Ni\u02bbihau. The Northwestern Hawaiian Islands is a group of nine small, older islands northwest of Kaua\u02bbi that extends from N\u012bhoa to Kure Atoll; they are remnants of much larger volcanic mountains. Across the archipelago are around 130 small rocks and islets, such as Molokini, which are made up of either volcanic or marine sedimentary rock.\nHawai\u02bbi's tallest mountain, Mauna Kea, is above mean sea level; it is taller than Mount Everest if measured from the base of the mountain, which is on the floor of the Pacific Ocean, rising about .\nGeology.\nThe Hawaiian islands were formed by volcanic activity initiated at an undersea magma source called the Hawai\u02bbi hotspot. The process continues to build islands; the tectonic plate beneath much of the Pacific Ocean continually moves northwest and the hotspot remains stationary, slowly creating new volcanoes. Because of the hotspot's location, all active land volcanoes are on the southern half of Hawai\u02bbi Island. The newest volcano, Kama\u02bbehuakanaloa (formerly L\u014d\u02bbihi), is south of the coast of Hawai\u02bbi Island.\nThe last volcanic eruption outside Hawai\u02bbi Island occurred at on Maui before the late 18th century, possibly hundreds of years earlier. In 1790, K\u012blauea exploded; it is the deadliest eruption known to have occurred in the modern era in what is now the United States. Up to 5,405 warriors and their families marching on K\u012blauea were killed by the eruption. Volcanic activity and subsequent erosion have created impressive geological features. Hawaii Island has the second-highest point among the world's islands.\nOn the volcanoes' flanks, slope instability has generated damaging earthquakes and related tsunamis, particularly in 1868 and 1975. Catastrophic debris avalanches on the ocean island volcanoes' submerged flanks have created steep cliffs.\n erupted in May 2018, opening 22 fissure vents on its eastern rift zone. The Leilani Estates and Lanipuna Gardens are within this territory. The eruption destroyed at least 36 buildings and this, coupled with the lava flows and the sulfur dioxide fumes, necessitated the evacuation of more than 2,000 inhabitants from their neighborhoods.\nFlora and fauna.\nThe islands of Hawai\u02bbi are distant from other land habitats, and life is thought to have arrived there by wind, waves (i.e., ocean currents), and wings (i.e., birds, insects, and seeds they may have carried on their feathers). Hawai\u02bbi has more endangered species and has lost a higher percentage of its endemic species than any other U.S. state. The endemic plant \"Brighamia\" now requires hand pollination because its natural pollinator is presumed to be extinct. The two species of \"Brighamia\"\u2014\"B. rockii\" and \"B. insignis\"\u2014are represented in the wild by around 120 individual plants. To ensure that these plants set seed, biologists rappel down cliffs to brush pollen onto their stigmas.\nTerrestrial ecology.\nThe archipelago's extant main islands have been above the ocean's surface for less than 10 million years, a fraction of the time biological colonization and evolution have occurred there. The islands are known for the environmental diversity that occurs on high mountains within a trade winds field. Native Hawaiians developed complex horticultural practices to utilize the surrounding ecosystem for agriculture. Cultural practices developed to enshrine values of environmental stewardship and reciprocity with the natural world, resulting in widespread biodiversity and intricate social and environmental relationships that still persist. On a single island, the climate around the coasts can range from dry tropical (less than annual rainfall) to wet tropical; on the slopes, environments range from tropical rainforest (more than per year), through a temperate climate, to alpine conditions with a cold, dry climate. The rainy climate affects soil development, which largely determines ground permeability and the distribution of streams and wetlands.\nProtected areas.\nSeveral areas in Hawai\u02bbi are under the National Park Service's protection. Hawaii has two national parks: Haleakal\u0101 National Park, near Kula on Maui, which features the dormant volcano Haleakal\u0101 that formed east Maui; and Hawaii Volcanoes National Park, in the southeast region of Hawai\u02bbi Island, which includes the active volcano K\u012blauea and its rift zones.\nThere are three national historical parks: Kalaupapa National Historical Park in Kalaupapa, Moloka\u02bbi, the site of a former leper colony; Kaloko-Honok\u014dhau National Historical Park in Kailua-Kona on Hawai\u02bbi Island; and Pu\u02bbuhonua o H\u014dnaunau National Historical Park, an ancient place of refuge on Hawai\u02bbi Island's west coast. Other areas under the National Park Service's control include Ala Kahakai National Historic Trail on Hawai\u02bbi Island and the USS \"Arizona\" Memorial at Pearl Harbor on O\u02bbahu.\nPresident George W. Bush proclaimed the Papah\u0101naumoku\u0101kea Marine National Monument on June 15, 2006. The monument covers roughly of reefs, atolls, and shallow and deep sea out to offshore in the Pacific Ocean\u2014an area larger than all the national parks in the U.S. combined.\nClimate.\nHawai\u02bbi has a tropical climate. Temperatures and humidity tend to be less extreme because of near-constant trade winds from the east. Summer highs reach around during the day, with lows of at night. Winter day temperatures are usually around ; at low elevation they seldom dip below at night. Snow, not usually associated with the tropics, falls at on Mauna Kea and Mauna Loa on Hawaii Island in the winter. Snow rarely falls on Haleakal\u0101. Mount Wai\u02bbale\u02bbale on Kaua\u02bbi has the second-highest average annual rainfall on Earth, about per year. Most of Hawaii experiences only two seasons; the dry season runs from May to October and the wet season is from October to April.\nWith climate change, Hawai\u02bbi is getting drier and hotter. The highest temperature recorded in the state, in Pahala on April 27, 1931, is , tied with Alaska as the lowest record high temperature observed in a U.S. state. Hawai\u02bbi's record low temperature is , observed in May 1979 on the summit of Mauna Kea. Hawai\u02bbi is the only state to have never recorded subzero Fahrenheit temperatures.\nClimates vary considerably on each island; they can be divided into windward and leeward (\"ko\u02bbolau\" and \"kona\", respectively) areas based upon location relative to the higher mountains. Windward sides face cloud cover.\nEnvironmental issues.\nHawaii has a decades-long history of hosting more military space for the United States than any other territory or state. This military activity has taken a sharp toll on the environmental health of the Hawaiian archipelago, degrading its beaches and soil and making some places entirely unsafe due to unexploded ordnance. According to scholar Winona LaDuke: \"The vast militarization of Hawaii has profoundly damaged the land. According to the Environmental Protection Agency, there are more federal hazardous waste sites in Hawaii\u201431\u2014than in any other U.S. state.\" Hawaii State Representative Roy Takumi writes in \"Challenging U.S. Militarism in Hawai\u02bbi and Okinawa\" that these military bases and hazardous waste sites have meant \"the confiscation of large tracts of land from native peoples\" and quotes the Hawaiian activist George Helm as asking: \"What is national defense when what is being destroyed is the very thing the military is entrusted to defend, the sacred land of Hawai\u02bbi?\" Contemporary Indigenous Hawaiians are still protesting the occupation of their homeland and environmental degradation due to increased militarization in the wake of 9/11.\nAfter the rise of sugarcane plantations in the mid-19th century, island ecology changed dramatically. Plantations require massive quantities of water, and European and American plantation owners transformed the land in order to access it, primarily by building tunnels to divert water from the mountains to the plantations, constructing reservoirs, and digging wells. These changes have made lasting impacts on the land and continue to contribute to resource scarcity for Native Hawaiians.\nAccording to Stanford scientist and scholar Sibyl Diver, Indigenous Hawaiians engage in a reciprocal relationship with the land, \"based on principles of mutual caretaking, reciprocity and sharing\". This relationship ensures the longevity, sustainability, and natural cycles of growth and decay, as well as cultivating a sense of respect for the land and humility towards one's place in an ecosystem.\nThe tourism industry's ongoing expansion and its pressure on local systems of ecology, cultural tradition and infrastructure creates a conflict between economic and environmental health. In 2020, the Center for Biological Diversity reported on the plastic pollution of Hawaii's Kamilo beach, citing \"massive piles of plastic waste\". Invasive species are spreading, and chemical and pathogenic runoff is contaminating groundwater and coastal waters.\nHistory.\nHawai\u02bbi is one of two U.S. states, along with Texas, that were internationally recognized sovereign nations before becoming U.S. states. The Kingdom of Hawai\u02bbi was sovereign from 1810 until 1893, when resident American and European capitalists and landholders overthrew the monarchy. Hawai\u02bbi was an independent republic from 1894 until August 12, 1898, when it officially became a U.S. territory. Hawai\u02bbi was admitted as a U.S. state on August 21, 1959.\nFirst human settlement \u2013 Ancient Hawai\u02bbi (1000\u20131778).\nThe date of the human discovery and habitation of the Hawaiian Islands is the subject of academic debate. Early archaeological studies suggested that Polynesian explorers from the Marquesas Islands or Society Islands may have arrived as early as the 3rd century CE. Some archaeologists and historians think it was a later wave of immigrants from Tahiti around 1100 CE who introduced a new line of high chiefs, the kapu system, the practice of human sacrifice, and the building of \"heiau\". This later immigration is detailed in Hawaiian mythology (\"mo\u02bbolelo\") about Pa\u02bbao. Other authors say there is no archaeological or linguistic evidence of a later influx of Tahitian settlers and that Pa\u02bbao must be regarded as a myth. More recent archaeological studies further suggest that the first settlement of Hawaii was not until around 900\u20131200 CE.\nThe islands' history is marked by a slow, steady growth in population and the size of the chiefdoms, which grew to encompass whole islands. Local chiefs, called ali\u02bbi, ruled their settlements, and launched wars to extend their influence and defend their communities from predatory rivals. Ancient Hawai\u02bbi was a caste-based society, much like that of Hindus in India. Population growth was facilitated by ecological and agricultural practices that combined upland agriculture (\"manuka\"), ocean fishing (\"makai\"), fishponds and gardening systems. These systems were upheld by spiritual and religious beliefs, like the \"lokahi\", that linked cultural continuity with the health of the natural world. According to Hawaiian scholar Mililani Trask, the \"lokahi\" symbolizes the \"greatest of the traditions, values, and practices of our people\u00a0... There are three points in the triangle\u2014the Creator, \"Akua\"; the peoples of the earth, \"Kanaka Maoli\"; and the land, the \"\u02bbaina\". These three things all have a reciprocal relationship.\"\nFirst recorded contact.\nIn January 1778, British Captain James Cook encountered the Hawaiian Islands serendipitously while crossing the Pacific during his third voyage of exploration. This marked the first documented contact by a European explorer with Hawai\u02bbi. Cook named the archipelago \"the Sandwich Islands\" in honor of his sponsor, John Montagu, 4th Earl of Sandwich. Cook returned to the Hawaiian Islands in 1779 to resupply and overwinter, anchoring in Kealakakua off Hawaii Island for one month. Relations with the local people were peaceful at first, then deteriorated, and Cook was among those killed when violence broke out between the British and local Hawaiians.\nAfter Cook, Hawaii was not visited by any foreign ships for seven years but after 1786 visits became increasingly frequent. At the end of the 18th century, the maritime fur trade developed between the northwest coast of North America and Asia, bringing ships of many nations to the North Pacific Ocean. The Hawaiian islands became established as a convenient source of supplies and destination for overwintering not only for fur traders but also ships engaged in general cross-Pacific commerce.20\u201321\nHistorian Ralph Kuykendall has called the impact of these foreign visitors on the hitherto isolated Hawaiian Islands an \"invasion\" that \"little by little overwhelmed the old culture of the islands\".12 Over the decades after the first contact, the foreign resident population slowly grew; foreigners imported iron tools, manufactured items, and household utensils; they also introduced firearms, alcohol, tobacco, non-native plants, and\u2014inadvertently\u2014insects previously unknown to the islands such as mosquitoes and scorpions.26\u201328 Native Hawaiians were vulnerable to Eurasian diseases to which they had less resistance. It is estimated that the native population had declined by half 40 years after Cook's arrival and continued to decline throughout the 19th century. During the 1850s, measles killed a fifth of Hawai\u02bbi's people.\nKingdom of Hawai\u02bbi.\nHouse of Kamehameha.\nDuring the 1780s and early 1790s, the Hawaiian Islands were divided among several warring chiefdoms. In 1795, the fighting ended when Kamehameha, then a chief (ali'i) of Hawaii Island, conquered most of the main islands in the archipelago (including Maui and Oahu), then founded the Hawaiian Kingdom and the House of Kamehameha dynasty. Kaua\u02bbi (with nearby Ni\u02bbihau) remained independent until 1810, when it joined the Hawaiian Kingdom peacefully.29\u201360\nAfter Kamehameha II inherited the throne in 1819, American Protestant missionaries to Hawai\u02bbi converted many Hawaiians to Christianity. Missionaries have argued that one function of missionary work was to \"civilize\" and \"purify\" perceived heathenism in the New World. This carried into Hawai\u02bbi. According to historical archaeologist James L. Flexner, \"missionaries provided the moral means to rationalize conquest and wholesale conversion to Christianity\". But rather than abandon traditional beliefs entirely, most native Hawaiians merged their Indigenous religion with Christianity. Missionaries used their influence to end many traditional practices, including the \"kapu\" system, the prevailing legal system before European contact, and \"heiau\", or \"temples\" to religious figures. \"Kapu\", which typically translates to \"the sacred\", refers to social regulations (like gender and class restrictions) based on spiritual beliefs.\nUnder the missionaries' guidance, laws against gambling, consuming alcohol, dancing the \"hula\", breaking the Sabbath, and polygamy were enacted. Without the \"kapu\" system, many temples and priestly statuses were jeopardized, idols were burned, and participation in Christianity increased. When Kamehameha III inherited the throne at age 12, his advisors pressured him to merge Christianity with traditional Hawaiian ways. Under the guidance of his \"kuhina nui\" (his mother and coregent Elizabeth Ka\u02bbahumanu) and British allies, Hawai\u02bbi turned into a Christian monarchy with the signing of the 1840 Constitution. Hiram Bingham I, a prominent Protestant missionary, was a trusted adviser to the monarchy during this period. Other missionaries and their descendants became active in commercial and political affairs, leading to conflicts between the monarchy and its restive American subjects. Missionaries from the Roman Catholic Church and from The Church of Jesus Christ of Latter-day Saints were also active in the kingdom, initially converting a minority of the Native Hawaiian population, but later becoming the first and second largest religious denominations on the islands, respectively. Missionaries from each major group administered to the leper colony at Kalaupapa on Moloka\u02bbi, which was established in 1866 and operated well into the 20th century. The best known were Father Damien and Mother Marianne Cope, both of whom were canonized in the early 21st century as Roman Catholic saints.\nThe death of the bachelor King Kamehameha V\u2014who did not name an heir\u2014resulted in the popular election of Lunalilo over Kal\u0101kaua. Lunalilo died the next year, also without naming an heir. In 1874, the election was contested within the legislature between Kal\u0101kaua and Emma, Queen Consort of Kamehameha IV. After riots broke out, the U.S. and Britain landed troops on the islands to restore order. The Legislative Assembly chose King Kal\u0101kaua as monarch by a vote of 39 to 6 on February 12, 1874.\n1887 Constitution and overthrow preparations.\nIn 1887, Kal\u0101kaua was forced to sign the 1887 Constitution of the Kingdom of Hawai\u02bbi. Drafted by white businessmen and lawyers, the document stripped the king of much of his authority. It established a property qualification for voting that effectively disenfranchised most Hawaiians and immigrant laborers and favored the wealthier, white elite. Resident whites were allowed to vote but resident Asians were not. As the 1887 Constitution was signed under threat of violence, it is known as the Bayonet Constitution. King Kal\u0101kaua, reduced to a figurehead, reigned until his death in 1891. His sister, Queen Lili\u02bbuokalani, succeeded him; she was the last monarch of Hawai\u02bbi.\nIn 1893, Lili\u02bbuokalani announced plans for a new constitution to proclaim herself an absolute monarch. On January 14, 1893, a group of mostly Euro-American business leaders and residents formed the Committee of Safety to stage a coup d'\u00e9tat against the kingdom and seek annexation by the United States. U.S. Government Minister John L. Stevens, responding to a request from the Committee of Safety, summoned a company of U.S. Marines. The queen's soldiers did not resist. According to historian William Russ, the monarchy was unable to protect itself. In \"Hawaiian Autonomy\", Lili\u02bbuokalani wrote: If we did not by force resist their final outrage, it was because we could not do so without striking at the military force of the United States. Whatever constraint the executive of this great country may be under to recognize the present government at Honolulu has been forced upon it by no act of ours, but by the unlawful acts of its own agents. Attempts to repudiate those acts are vain.In a message to Sanford B. Dole, Lili\u02bbuokalani wrote:Now to avoid any collision of armed forces and perhaps the loss of life, I do under this protest, and impelled by said force, yield my authority until such time as the Government of the United States shall, upon the facts being presented to it, undo the action of its representatives and reinstate me in the authority which I claim as the constitutional sovereign of the Hawaiian Islands.\nOverthrow of 1893 \u2013 Republic of Hawai\u02bbi (1894\u20131898).\nThe treason trials of 1892 brought together the main players in the 1893 overthrow. American Minister John L. Stevens voiced support for Native Hawaiian revolutionaries; William R. Castle, a Committee of Safety member, served as a defense counsel in the treason trials; Alfred Stedman Hartwell, the 1893 annexation commissioner, led the defense effort; and Sanford B. Dole ruled as a supreme court justice against acts of conspiracy and treason.\nOn January 17, 1893, a small group of sugar and pineapple-growing businessmen, aided by the U.S. minister to Hawaii and backed by heavily armed U.S. soldiers and marines, deposed Queen Lili\u02bbuokalani and installed a provisional government composed of members of the Committee of Safety. According to scholar Lydia Kualapai and Hawaii State Representative Roy Takumi, this committee was formed against the will of Indigenous Hawaiian voters, who constituted the majority of voters at the time. According to scholar J Kehaulani Kauanui, it consisted of \"thirteen white men\". Stevens conspired with U.S. citizens to overthrow the monarchy. After the overthrow, Dole, a citizen of Hawaii and cousin to James Dole, owner of Hawaiian Fruit Company, a company that benefited from the annexation of Hawaii, became president of the republic when the Provisional Government of Hawai\u02bbi ended on July 4, 1894.\nControversy ensued in the following years as the queen tried to regain her throne. Scholar Lydia Kualapai writes that Lili\u02bbuokalani had \"yielded under protest not to the counterfeit Provisional Government of Hawaii but to the superior force of the United States of America\" and wrote letters of protest to the president requesting a recognizance of allyship and a reinstatement of her sovereignty against the recent actions of the Provisional Government of Hawaii. Following the January 1893 coup that deposed Lili\u02bbuokalani, many royalists were preparing to overthrow the white-led Republic of Hawai\u02bbi oligarchy. Hundreds of rifles were covertly shipped to Hawaii and hidden in caves nearby. As armed troops came and went, a Republic of Hawai\u02bbi patrol discovered the rebel group. On January 6, 1895, gunfire began on both sides and later the rebels were surrounded and captured. Over the next 10 days several skirmishes occurred, until the last armed opposition surrendered or were captured. The Republic of Hawai\u02bbi took 123 troops into custody as prisoners of war. The mass arrest of nearly 300 more men and women, including Queen Lili\u02bbuokalani, as political prisoners was intended to incapacitate the political resistance against the ruling oligarchy. In March 1895, a military tribunal convicted 170 prisoners of treason and sentenced six troops to be \"hung by the neck\" until dead, according to historian Ronald Williams Jr. The other prisoners were variously sentenced to from five to thirty-five years' imprisonment at hard labor, while those convicted of lesser charges received sentences from six months' to six years' imprisonment at hard labor. The queen was sentenced to five years in prison, but spent eight months under house arrest until she was released on parole. The total number of arrests related to the 1895 Kaua K\u016bloko was 406 people on a summary list of statistics, published by the government of the Republic of Hawai\u02bbi.\nThe administration of President Grover Cleveland commissioned the Blount Report, which concluded that the removal of Lili\u02bbuokalani had been illegal. Commissioner Blount found the U.S. and its minister guilty on all counts including the overthrow, the landing of the marines, and the recognition of the provisional government. In a message to Congress, Cleveland wrote:And finally, but for the lawless occupation of Honolulu under false pretexts by the United States forces, and but for Minister Stevens' recognition of the provisional government when the United States forces were its sole support and constituted its only military strength, the Queen and her Government would never have yielded to the provisional government, even for a time and for the sole purpose of submitting her case to the enlightened justice of the United States. By an act of war, committed with the participation of a diplomatic representative of the United States and without authority of Congress, the Government of a feeble but friendly and confiding people has been overthrown. A substantial wrong has thus been done which a due regard for our national character as well as the rights of the injured people requires we should endeavor to repair. The provisional government has not assumed a republican or other constitutional form, but has remained a mere executive council or oligarchy, set up without the assent of the people. It has not sought to find a permanent basis of popular support and has given no evidence of an intention to do so.The U.S. government first demanded that Queen Lili\u02bbuokalani be reinstated, but the Provisional Government refused. On December 23, 1893, the response from the Provisional Government of Hawaii, authored by President Sanford B. Dole, was received by Cleveland's representative Minister Albert S. Willis and emphasized that the Provisional Government of Hawaii \"unhesitatingly\" rejected the demand from the Cleveland Administration.\nCongress conducted an independent investigation, and on February 26, 1894, submitted the Morgan Report, which found all parties, including Stevens\u2014with the exception of the queen\u2014\"not guilty\" and not responsible for the coup. Partisans on both sides of the debate questioned the accuracy and impartiality of both the Blount and Morgan reports over the events of 1893.\nIn 1993, Congress passed a joint Apology Resolution regarding the overthrow; it was signed by President Bill Clinton. The resolution apologized and said that the overthrow was illegal in the following phrase: \"The Congress\u2014on the occasion of the 100th anniversary of the illegal overthrow of the Kingdom of Hawai\u02bbi on January 17, 1893, acknowledges the historical significance of this event which resulted in the suppression of the inherent sovereignty of the Native Hawaiian people.\" The Apology Resolution also \"acknowledges that the overthrow of the Kingdom of Hawai\u02bbi occurred with the active participation of agents and citizens of the United States and further acknowledges that the Native Hawaiian people never directly relinquished to the United States their claims to their inherent sovereignty as a people over their national lands, either through the Kingdom of Hawai\u02bbi or through a plebiscite or referendum\".\nAnnexation \u2013 Territory of Hawai\u02bbi (1898\u20131959).\nAfter William McKinley won the 1896 U.S. presidential election, advocates pressed to annex the Republic of Hawai\u02bbi. The previous president, Grover Cleveland, was a friend of Queen Lili\u02bbuokalani. McKinley was open to persuasion by U.S. expansionists and by annexationists from Hawai\u02bbi. He met with three non-native annexationists: Lorrin A. Thurston, Francis March Hatch and William Ansel Kinney. After negotiations in June 1897, Secretary of State John Sherman agreed to a treaty of annexation with these representatives of the Republic of Hawai\u02bbi. The U.S. Senate never ratified the treaty. Despite the opposition of most native Hawaiians, the Newlands Resolution was used to annex the republic to the U.S.; it became the Territory of Hawai\u02bbi. The Newlands Resolution was passed by the House on June 15, 1898, by a vote of 209 to 91 and by the Senate on July 6, 1898, by a vote of 42 to 21.\nA majority of Native Hawaiians opposed annexation, voiced chiefly by Lili\u02bbuokalani, whom Hawaiian Haunani-Kay Trask described as beloved and respected by her people. Lili\u02bbuokalani wrote, \"it had not entered into our hearts to believe that these friends and allies from the United States\u00a0... would ever go so far as to absolutely overthrow our form of government, seize our nation by the throat, and pass it over to an alien power\" in her retelling of the overthrow of her government. According to Trask, newspapers at the time argued Hawaiians would suffer \"virtual enslavement under annexation\", including further loss of lands and liberties, in particular to sugar plantation owners. These plantations were protected by the U.S. Navy as economic interests, justifying a continued military presence in the islands.\nIn 1900, Hawai\u02bbi was granted self-governance and retained \u02bbIolani Palace as the territorial capitol building. Despite several attempts to become a state, Hawaii remained a territory for 60 years. Plantation owners and capitalists, who maintained control through financial institutions such as the Big Five, found territorial status convenient because they remained able to import cheap, foreign labor. Such immigration and labor practices were prohibited in many states.\nPuerto Rican immigration to Hawai\u02bbi began in 1899, when Puerto Rico's sugar industry was devastated by a hurricane, causing a worldwide shortage of sugar and a huge demand for sugar from Hawai\u02bbi. Hawaiian sugarcane plantation owners began to recruit experienced, unemployed laborers in Puerto Rico. Two waves of Korean immigration to Hawai\u02bbi occurred in the 20th century. The first wave arrived between 1903 and 1924; the second wave began in 1965 after President Lyndon B. Johnson signed the Immigration and Nationality Act of 1965, which removed racial and national barriers and resulted in significantly altering the demographic mix in the U.S.\nO\u02bbahu was the target of a surprise attack on Pearl Harbor by the Empire of Japan on December 7, 1941. The attack on Pearl Harbor and other military and naval installations, carried out by aircraft and by midget submarines, brought the United States into World War\u00a0II.\nPolitical changes of 1954 \u2013 State of Hawai\u02bbi (1959\u2013present).\nIn the 1950s, the plantation owners' power was broken by the descendants of immigrant laborers, who were born in Hawai\u02bbi and were U.S. citizens. They voted against the Hawai\u02bbi Republican Party, strongly supported by plantation owners. The new majority voted for the Democratic Party of Hawai\u02bbi, which dominated territorial and state politics for more than 40 years. Eager to gain full representation in Congress and the Electoral College, residents actively campaigned for statehood. In Washington, there was talk that Hawai\u02bbi would be a Republican Party stronghold. As a result, the admission of Hawaii was matched with the admission of Alaska, which was seen as a Democratic Party stronghold. These predictions proved inaccurate; as of 2017, Hawai\u02bbi almost always votes Democratic, while Alaska typically votes Republican.\nDuring the Cold War, Hawai\u02bbi became an important site for U.S. cultural diplomacy, military training, research, and as a staging ground for the U.S. war in Vietnam.105\nIn March 1959, Congress passed the Hawai\u02bbi Admissions Act, which U.S. President Dwight D. Eisenhower signed into law. The act excluded Palmyra Atoll from statehood; it had been part of the Kingdom and Territory of Hawai\u02bbi. On June 27, 1959, a referendum asked residents of Hawai\u02bbi to vote on the statehood bill; 94.3% voted in favor of statehood and 5.7% opposed it. The referendum asked voters to choose between accepting the Act and remaining a U.S. territory. The United Nations' Special Committee on Decolonization later removed Hawai\u02bbi from its list of non-self-governing territories.\nAfter attaining statehood, Hawai\u02bbi quickly modernized through construction and a rapidly growing tourism economy. Later, state programs promoted Hawaiian culture. The Hawai\u02bbi State Constitutional Convention of 1978 created institutions such as the Office of Hawaiian Affairs to promote indigenous language and culture.\nLegacy of annexation on Hawaiian land.\nIn 1897, over 21,000 Natives, representing the overwhelming majority of adult Hawaiians, signed anti-annexation petitions in one of the first examples of protest against the overthrow of Queen Lili\u02bbuokalani's government. Nearly 100 years later, in 1993, 17,000 Hawaiians marched to demand access and control over Hawaiian trust lands and as part of the modern Hawaiian sovereignty movement. Hawaiian trust land ownership and use is still widely contested as a consequence of annexation. According to scholar Winona LaDuke, as of 2015, 95% of Hawai\u02bbi's land was owned or controlled by just 82 landholders, including over 50% by federal and state governments, as well as the established sugar and pineapple companies. The Thirty Meter Telescope is planned to be built on Hawaiian trust land, but has faced resistance as the project \nDemographics.\nPopulation.\n&lt;templatestyles src=\"US Census population/styles.css\"/&gt;\nAfter Europeans and mainland Americans first arrived during the Kingdom of Hawaii period, the overall population of Hawaii\u2014which until that time composed solely of Indigenous Hawaiians\u2014fell dramatically. Many people of the Indigenous Hawaiian population died to foreign diseases, declining from an estimated 300,000 in the 1770s, to 60,000 in the 1850s, to 24,000 in 1920. Other estimates for the pre-contact population range from 150,000 to 1.5 million. The population of Hawaii began to finally increase after an influx of primarily Asian settlers that arrived as migrant laborers at the end of the 19th\u00a0century. In 1923, 42% of the population was of Japanese descent, 9% of Chinese descent, and 16% Native Hawaiian descent.\nIn 2010, 156,000 residents declared themselves to be solely of Native Hawaiian ancestry, just over half the estimated pre-contact population. An additional 371,000 declared themselves to possess Native Hawaiian ancestry in combination with one or more other races (including other Polynesian groups, but mostly Asian or White).\nIn 2018, the United States Census Bureau estimated the population of Hawaii to be 1,420,491, a decrease of 7,047 from the previous year but an increase of 60,190 (4.42%) since 2010. This includes a natural increase of 48,111 (96,028 births minus 47,917 deaths) and an increase due to net migration of 16,956 people into the state. Immigration from outside the United States resulted in a net increase of 30,068; migration within the country produced a net loss of 13,112 people.\nThe center of population of Hawaii is located on the island of O\u02bbahu. Large numbers of Native Hawaiians have moved to Las Vegas, which has been called the \"ninth island\" of Hawaii.\nHawaii has a \"de facto\" population of over 1.4\u00a0million, due in part to a large number of military personnel and tourist residents. O\u02bbahu is the most populous island; it has the highest population density with a resident population of just under one million in , approximately 1,650 people per square mile. Hawaii's 1.4\u00a0million residents, spread across of land, result in an average population density of 188.6 persons per square mile. The state has a lower population density than Ohio and Illinois.\nThe average projected lifespan of people born in Hawaii in 2000 is 79.8 years; 77.1 years if male, 82.5 if female\u2014longer than the average lifespan of any other U.S. state. As of 2011[ [update]] the U.S. military reported it had 42,371 personnel on the islands.\nAccording to HUD's 2022 Annual Homeless Assessment Report, there were an estimated 5,967 homeless people in Hawaii.\nIn 2018, the top countries of origin for immigrants in Hawaii were the Philippines, China, Japan, Korea and the Marshall Islands.\nAncestry.\nAccording to the 2020 United States Census, Hawaii had a population of 1,455,271. The state's population identified as 37.2% Asian; 25.3% Multiracial; 22.9% White; 10.8% Native Hawaiians and other Pacific Islanders; 9.5% Hispanic and Latinos of any race; 1.6% Black or African American; 1.8% from some other race; and 0.3% Native American and Alaskan Native.\nHawaii has the highest percentage of Asian Americans and multiracial Americans and the lowest percentage of White Americans of any state. It is the only state where people who identify as Asian Americans are the largest ethnic group. In 2012, 14.5% of the resident population under age 1 was non-Hispanic white. Hawaii's Asian population consists mainly of 198,000 (14.6%) Filipino Americans, 185,000 (13.6%) Japanese Americans, roughly 55,000 (4.0%) Chinese Americans, and 24,000 (1.8%) Korean Americans.\nOver 120,000 (8.8%) Hispanic and Latino Americans live in Hawaii. Mexican Americans number over 35,000 (2.6%); Puerto Ricans exceed 44,000 (3.2%). Multiracial Americans constitute almost 25% of Hawaii's population, exceeding 320,000 people. Hawaii is the only state to have a tri-racial group as its largest multiracial group, one that includes white, Asian and Native Hawaiian/Pacific Islander (22% of all multiracial population). The non-Hispanic White population numbers around 310,000\u2014just over 20% of the population. The multi-racial population outnumbers the non-Hispanic white population by about 10,000 people. In 1970, the Census Bureau reported Hawaii's population was 38.8% white and 57.7% Asian and Pacific Islander.\nThere are more than 80,000 Indigenous Hawaiians\u20145.9% of the population. Including those with partial ancestry, Samoan Americans constitute 2.8% of Hawaii's population, and Tongan Americans constitute 0.6%.\nThe five largest European ancestries in Hawaii are German (7.4%), Irish (5.2%), English (4.6%), Portuguese (4.3%) and Italian (2.7%). About 82.2% of the state's residents were born in the United States. Roughly 75% of foreign-born residents originate from Asia. Hawaii is a majority-minority state. It was expected to be one of three states that would not have a non-Hispanic white plurality in 2014; the other two are California and New Mexico.\nThe third group of foreigners to arrive in Hawaii were from China. Chinese workers on Western trading ships settled in Hawaii starting in 1789. In 1820, the first American missionaries arrived to preach Christianity and teach the Hawaiians Western ways. As of 2015[ [update]], a large proportion of Hawaii's population have Asian ancestry\u2014especially Filipino, Japanese and Chinese. Many are descendants of immigrants brought to work on the sugarcane plantations in the mid-to-late 19th century. The first 153 Japanese immigrants arrived in Hawaii on June 19, 1868. They were not approved by the then-current Japanese government because the contract was between a broker and the Tokugawa shogunate\u2014by then replaced by the Meiji Restoration. The first Japanese current-government-approved immigrants arrived on February 9, 1885, after Kal\u0101kaua's petition to Emperor Meiji when Kal\u0101kaua visited Japan in 1881.\nAlmost 13,000 Portuguese migrants had arrived by 1899; they also worked on the sugarcane plantations. By 1901, more than 5,000 Puerto Ricans were living in Hawaii.\nLanguages.\nEnglish and Hawaiian are listed as Hawaii's official languages in the state's 1978 constitution, in Article XV, Section 4. However, the use of Hawaiian is limited because the constitution specifies that \"Hawaiian shall be required for public acts and transactions only as provided by law\". Hawai\u02bbi Creole English, locally referred to as \"Pidgin\", is the native language of many native residents and is a second language for many others.\nThe 2000 Census found that 73.4% of Hawaii residents age\u00a05 and older exclusively spoke English at home. According to the 2008 American Community Survey, 74.6% of Hawaii's residents older than\u00a05 spoke only English at home. In their homes, 21.0% of state residents speak an additional Asian language, 2.6% speak Spanish, 1.6% speak other Indo-European languages and 0.2% speak another language.\nAfter English, other languages popularly spoken in the state are Tagalog, Ilocano, and Japanese. 5.4% of residents speak Tagalog, which includes non-native speakers of Filipino, a Tagalog-based national and co-official language of the Philippines; 5.0% speak Japanese and 4.0% speak Ilocano; 1.2% speak Chinese, 1.7% speak Hawaiian; 1.7% speak Spanish; 1.6% speak Korean; and 1.0% speak Samoan.\nHawaiian.\nThe Hawaiian language has about 2,000 native speakers, about 0.15% of the total population. According to the United States Census, there were more than 24,000 total speakers of the language in Hawaii in 2006\u20132008. Hawaiian is a Polynesian member of the Austronesian language family. It is closely related to other Polynesian languages, such as Marquesan, Tahitian, M\u0101ori, Rapa Nui (the language of Easter Island), and less closely to Samoan and Tongan.\nAccording to Sch\u00fctz, the Marquesans colonized the archipelago in roughly 300 CE and were later followed by waves of seafarers from the Society Islands, Samoa and Tonga. These Polynesians remained in the islands; they eventually became the Hawaiian people and their languages evolved into the Hawaiian language. Kimura and Wilson say: \"[l]inguists agree that Hawaiian is closely related to Eastern Polynesian, with a particularly strong link in the Southern Marquesas, and a secondary link in Tahiti, which may be explained by voyaging between the Hawaiian and Society Islands\".\nBefore the arrival of Captain James Cook, the Hawaiian language had no written form. That form was developed mainly by American Protestant missionaries between 1820 and 1826 who assigned to the Hawaiian phonemes letters from the Latin alphabet. Interest in Hawaiian increased significantly in the late 20th century. With the help of the Office of Hawaiian Affairs, specially designated immersion schools in which all subjects would be taught in Hawaiian were established. The University of Hawai\u02bbi developed a Hawaiian-language graduate studies program. Municipal codes were altered to favor Hawaiian place and street names for new civic developments.\nHawaiian distinguishes between long and short vowel sounds. In modern practice, vowel length is indicated with a macron (\"kahak\u014d\"). Hawaiian-language newspapers (\"n\u016bpepa\") published from 1834 to 1948 and traditional native speakers of Hawaiian generally omit the marks in their own writing. The \u02bbokina and kahak\u014d are intended to capture the proper pronunciation of Hawaiian words. The Hawaiian language uses the glottal stop (\"\u02bbOkina\") as a consonant. It is written as a symbol similar to the apostrophe or left-hanging (opening) single quotation mark.\nThe keyboard layout used for Hawaiian is QWERTY.\nHawaiian Pidgin.\nHawaiian Pidgin, officially known as Hawai\u02bbi Creole English (HCE), is a creole language that emerged in Hawai\u02bbi during the 19th century as a means of communication among diverse groups working on sugarcane plantations. Its lexicon is primarily derived from English, with significant contributions from Hawaiian, Chinese, Japanese, Portuguese, Ilocano, and Tagalog.\nThe development of Hawaiian Pidgin began with Pidgin Hawaiian, an earlier pidgin that formed in the 1790s during initial contact between Native Hawaiians and foreigners. As plantation laborers from various countries arrived, a new pidgin based on English evolved to facilitate communication among workers and supervisors.\nBy the early 20th century, children of these plantation workers began acquiring Hawaiian Pidgin as their first language, leading to its creolization. This transition marked the emergence of HCE as a fully developed creole language.\nHCE incorporates Hawaiian words, especially in place names and terms for local flora and fauna. For instance, the Hawaiian term for tuna, \"ahi,\" is commonly used in HCE. Additionally, certain English words have adapted meanings; \"aunty\" and \"uncle\" are used to address any respected elder, regardless of familial relation.\nSome expressions from HCE have permeated other communities, particularly through surfing culture. Terms like \"brah\" (brother) and \"da kine\" (a versatile placeholder term) have gained recognition beyond Hawai\u02bbi.\nIn 2015, the U.S. Census Bureau recognized Hawaiian Pidgin as an official language in Hawai\u02bbi, reflecting its widespread use among residents. Despite this recognition, debates continue about its role in education and its impact on learning Standard English.\nHawai\u02bbi Sign Language.\nHawai\u02bbi Sign Language, a sign language for the Deaf based on the Hawaiian language, has been in use in the islands since the early 1800s. It is dwindling in numbers due to American Sign Language supplanting HSL through schooling and various other domains.\nReligion.\n&lt;templatestyles src=\"Pie chart/styles.css\"/&gt;\n&lt;templatestyles src=\"Pie chart/styles.css\"/&gt;\nHawaii is among the most religiously diverse states in the U.S., with one in ten residents practicing a non-Christian faith. Roughly one-quarter to half the population identify as unaffiliated and nonreligious, making Hawaii one of the most secular states as well.\nChristianity remains the majority religion, represented mainly by various Protestant groups and Catholicism. The second-largest religion is Buddhism, which comprises a larger proportion of the population than in any other state; it is concentrated in the Japanese community. Native Hawaiians continue to engage in traditional religious and spiritual practices today, often adhering to Christian and traditional beliefs at the same time.\nThe Cathedral Church of Saint Andrew in Honolulu was formally the seat of the Hawaiian Reformed Catholic Church, a province of the Anglican Communion that had been the state church of the Kingdom of Hawaii; it subsequently merged into the Episcopal Church in the 1890s following the overthrow of the Kingdom of Hawaii, becoming the seat of the Episcopal Diocese of Hawaii. The Cathedral Basilica of Our Lady of Peace and the Co-Cathedral of Saint Theresa of the Child Jesus serve as seats of the Diocese of Honolulu. The Eastern Orthodox community is centered around the Saints Constantine and Helen Greek Orthodox Cathedral of the Pacific.\nThe largest religious denominations by membership were the Catholic Church with 249,619 adherents in 2010; the Church of Jesus Christ of Latter-day Saints with 68,128 adherents in 2009; the United Church of Christ with 115 congregations and 20,000 members; and the Southern Baptist Convention with 108 congregations and 18,000 members. Nondenominational churches collectively have 128 congregations and 32,000 members.\nAccording to data provided by religious establishments, religion in Hawaii in 2000 was distributed as follows:\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nHowever, a Pew poll found that the religious composition was as follows:\nBirth data.\n\"Note: Births in this table do not add up, because Hispanic peoples are counted both by their ethnicity and by their race, giving a higher overall number.\"\n1) Until 2016, data for births of Asian origin, included also births of the Pacific Islander group.\n2) Since 2016, data for births of White Hispanic origin are not collected, but included in one \"Hispanic\" group; persons of Hispanic origin may be of any race.\nPercentage surviving.\nThe percentage surviving, is the percent of the population that would survive to certain age, if their life conditions in a given year, were extrapolated to their whole life. Data for 2019.\n&lt;templatestyles src=\"template:row hover highlight/styles.css\"/&gt;&lt;templatestyles src=\"template:sticky header/styles.css\"/&gt;&lt;templatestyles src=\"Template:Table alignment/tables.css\" /&gt;\nData source: US Mortality DataBase.\nLGBTQ people.\nHawaii has had a long history of LGBTQIA+ identities. (\"in the middle\") were a precolonial third gender with traditional spiritual and social roles, widely respected as healers. Homosexual relationships known as \"aik\u0101ne\" were widespread and normal in ancient Hawaiian society. Among men, \"aik\u0101ne\" relationships often began as teens and continued throughout their adult lives, even if they also maintained heterosexual partners. While \"aik\u0101ne\" usually refers to male homosexuality, some stories also refer to women, implying that women may have been involved in \"aik\u0101ne\" relationships as well. Journals written by Captain Cook's crew record that many \"ali\u02bbi\" (hereditary nobles) also engaged in \"aik\u0101ne\" relationships, and Kamehameha the Great, the founder and first ruler of the Kingdom of Hawaii, was also known to participate. Cook's second lieutenant and co-astronomer James King observed that \"all the chiefs had them\", and recounts that Cook was actually asked by one chief to leave King behind, considering the role a great honor.\nHawaiian scholar Lilikal\u0101 Kame\u02bbeleihiwa notes that \"aik\u0101ne\" served a practical purpose of building mutual trust and cohesion; \"If you didn't sleep with a man, how could you trust him when you went into battle? How would you know if he was going to be the warrior that would protect you at all costs, if he wasn't your lover?\"\nAs Western colonial influences intensified in the late 19th and early 20th century, the word \"aik\u0101ne\" was expurgated of its original sexual meaning, and in print simply meant \"friend\". Nonetheless, in Hawaiian language publications its metaphorical meaning can still mean either \"friend\" or \"lover\" without stigmatization.\nA 2012 Gallup poll found that Hawaii had the largest proportion of LGBTQIA+ adults in the U.S., at 5.1%, an estimated 53,966 individuals. The number of same-sex couple households in 2010 was 3,239, representing a 35.5% increase from a decade earlier. In 2013, Hawaii became the fifteenth U.S. state to legalize same-sex marriage; this reportedly boosted tourism by $217\u00a0million.\nEconomy.\nThe history of Hawaii's economy can be traced through a succession of dominant industries: sandalwood, whaling, sugarcane, pineapple, the military, tourism and education. By the 1840s, sugar plantations had gained a strong foothold in the Hawaiian economy, due to a high demand of sugar in the United States and rapid transport via steamships. Sugarcane plantations were tightly controlled by American missionary families and businessmen known as \"the Big Five\", who monopolized control of the sugar industry's profits. By the time Hawaiian annexation was being considered in 1898, sugarcane producers turned to cultivating tropical fruits like pineapple, which became the principal export for Hawai\u02bbi's plantation economy. Since statehood in 1959, tourism has been the largest industry, contributing 24.3% of the gross state product (GSP) in 1997, despite efforts to diversify. The state's gross output for 2003 was US$\u00a0billion; per capita income for Hawaii residents in 2014 was US$. Hawaiian exports include food and clothing. These industries play a small role in the Hawaiian economy, due to the shipping distance to viable markets, such as the West Coast of the United States. The state's food exports include coffee, macadamia nuts, pineapple, livestock, sugarcane and honey.\nBy weight, honey bees may be the state's most valuable export. According to the Hawaii Agricultural Statistics Service, in 2002 agricultural sales were US$\u00a0million from diversified agriculture, US$\u00a0million from pineapple, and US$\u00a0million from sugarcane. Hawaii's relatively consistent climate has attracted the seed industry, which is able to test three generations of crops per year on the islands, compared with one or two on the mainland. Seeds yielded US$ million in 2012, supporting 1,400 workers.\nAs of August\u00a02024[ [update]], the state's unemployment rate was 3.0%. In 2009, the United States military spent US$\u00a0billion in Hawaii, accounting for 18% of spending in the state for that year. 75,000 United States Department of Defense personnel live in Hawaii. According to a 2013 study by Phoenix Marketing International, Hawaii at that time had the fourth-largest number of millionaires per capita in the United States, with a ratio of 7.2%.\nTaxation.\nTax is collected by the Hawaii Department of Taxation. Most government revenue comes from personal income taxes and a general excise tax (GET) levied primarily on businesses; there is no statewide tax on sales, personal property, or stock transfers, while the effective property tax rate is among the lowest in the country. The high rate of tourism means that millions of visitors generate public revenue through GET and the hotel room tax. However, Hawaii residents generally pay among the most state taxes per person in the U.S.\nThe Tax Foundation of Hawaii considers the state's tax burden too high, claiming that it contributes to higher prices and the perception of an unfriendly business climate. The nonprofit Tax Foundation ranks Hawaii third in income tax burden and second in its overall tax burden, though notes that a significant portion of taxes are borne by tourists. Former State Senator Sam Slom attributed Hawaii's comparatively high tax rate to the fact that the state government is responsible for education, health care, and social services that are usually handled at a county or municipal level in most other states.\nCost of living.\nThe cost of living in Hawaii, specifically Honolulu, is high compared to that of most major U.S. cities, although it is 6.7% lower than in New York City and 3.6% lower than in San Francisco. These numbers may not take into account some costs, such as increased travel costs for flights, additional shipping fees, and the loss of promotional participation opportunities for customers outside the contiguous U.S. While some online stores offer free shipping on orders to Hawaii, many merchants exclude Hawaii, Alaska, Puerto Rico and certain other U.S. territories.\nHawaiian Electric Industries, a privately owned company, provides 95% of the state's population with electricity, mostly from fossil-fuel power stations. Average electricity prices in October 2014 () were nearly three times the national average () and 80% higher than the second-highest state, Connecticut.\nThe median home value in Hawaii in the 2000 U.S. Census was US$, while the national median home value was US$. Hawaii home values were the highest of all states, including California with a median home value of US$. Research from the National Association of Realtors places the 2010 median sale price of a single family home in Honolulu, Hawaii, at US$ and the U.S. median sales price at US$. The sale price of single family homes in Hawaii was the highest of any U.S. city in 2010, just above that of the Silicon Valley area of California (US$).\nHawaii's very high cost of living is the result of several interwoven factors of the global economy in addition to domestic U.S. government trade policy. Like other regions with desirable weather year-round, such as California, Arizona and Florida, Hawaii's residents can be considered to be subject to a \"sunshine tax\". This situation is further exacerbated by the natural factors of geography and world distribution that lead to higher prices for goods due to increased shipping costs, a problem which many island states and territories suffer from as well.\nThe higher costs to ship goods across an ocean may be further increased by the requirements of the Jones Act, which generally requires that goods be transported between places within the U.S., including between the mainland U.S. west coast and Hawaii, using only U.S.-owned, built, and crewed ships. Jones Act-compliant vessels are often more expensive to build and operate than foreign equivalents, which can drive up shipping costs. While the Jones Act does not affect transportation of goods to Hawaii directly from Asia, this type of trade is nonetheless not common; this is a result of other primarily economic reasons including additional costs associated with stopping over in Hawaii (e.g. pilot and port fees), the market size of Hawaii, and the economics of using ever-larger ships that cannot be handled in Hawaii for transoceanic voyages. Therefore, Hawaii relies on receiving most inbound goods on Jones Act-qualified vessels originating from the U.S. west coast, which may contribute to the increased cost of some consumer goods and therefore the overall cost of living. Critics of the Jones Act contend that Hawaii consumers ultimately bear the expense of transporting goods imposed by the Jones Act.\nCulture.\nThe aboriginal culture of Hawaii is Polynesian. Hawaii represents the northernmost extension of the vast Polynesian Triangle of the south and central Pacific Ocean. While traditional Hawaiian culture remains as vestiges in modern Hawaiian society, there are re-enactments of the ceremonies and traditions throughout the islands. Some of these cultural influences, including the popularity (in greatly modified form) of \"l\u016b\u02bbau\" and \"hula\", and gestures such as the Shaka sign, are strong enough to affect the wider United States.\nCuisine.\nThe cuisine of Hawaii is a fusion of many foods brought by immigrants to the Hawaiian Islands, including the earliest Polynesians and Native Hawaiian cuisine, and American, Chinese, Filipino, Japanese, Korean, Polynesian, Puerto Rican, and Portuguese origins. Plant and animal food sources are imported from around the world for agricultural use in Hawaii. \"Poi\", a starch made by pounding taro, is one of the traditional foods of the islands. Many local restaurants serve the ubiquitous plate lunch, which features two scoops of rice, a simplified version of American macaroni salad and a variety of toppings including hamburger patties, a fried egg, and gravy of a \"loco moco\", Japanese style \"tonkatsu\" or the traditional l\u016b\u02bbau favorites, including \"k\u0101lua\" pork and \"laulau\". \"Spam musubi\" is an example of the fusion of ethnic cuisine that developed on the islands among the mix of immigrant groups and military personnel. In the 1990s, a group of chefs developed Hawaii regional cuisine as a contemporary fusion cuisine.\nCustoms and etiquette.\nSome key customs and etiquette in Hawaii are as follows: when visiting a home, it is considered good manners to bring a small gift for one's host (for example, a dessert). Thus, parties are usually in the form of potlucks. Most locals take their shoes off before entering a home. It is customary for Hawaiian families, regardless of ethnicity, to hold a luau to celebrate a child's first birthday. It is also customary at Hawaiian weddings, especially at Filipino weddings, for the bride and groom to do a money dance (also called the pandanggo). Print media and local residents recommend that one refer to residents of Hawaii who are not ethnically Hawaiian as \"locals of Hawaii\" or \"people of Hawaii\".\nHawaiian mythology.\nHawaiian mythology includes the legends, historical tales, and sayings of the ancient Hawaiian people. It is considered a variant of a more general Polynesian mythology that developed a unique character for several centuries before c.\u20091800. It is associated with the Hawaiian religion, which was officially suppressed in the 19th century but was kept alive by some practitioners to the modern day. Prominent figures and terms include Aumakua, the spirit of an ancestor or family god and K\u0101ne, the highest of the four major Hawaiian deities.\nPolynesian mythology.\nPolynesian mythology is the oral traditions of the people of Polynesia, a grouping of Central and South Pacific Ocean island archipelagos in the Polynesian triangle together with the scattered cultures known as the Polynesian outliers. Polynesians speak languages that descend from a language reconstructed as Proto-Polynesian that was probably spoken in the area around Tonga and Samoa in around 1000 BC.\nPrior to the 15th century, Polynesian people migrated east to the Cook Islands, and from there to other island groups such as Tahiti and the Marquesas. Their descendants later discovered the islands Tahiti, Rapa Nui, and later the Hawaiian Islands and New Zealand.\nThe Polynesian languages are part of the Austronesian language family. Many are close enough in terms of vocabulary and grammar to be mutually intelligible. There are also substantial cultural similarities between the various groups, especially in terms of social organization, childrearing, horticulture, building and textile technologies. Their mythologies in particular demonstrate local reworkings of commonly shared tales. The Polynesian cultures each have distinct but related oral traditions; legends or myths are traditionally considered to recount ancient history (the time of \"p\u014d\") and the adventures of gods (\"atua\") and deified ancestors.\nList of state parks.\nThere are many Hawaiian state parks.\nLiterature.\nThe literature of Hawaii is diverse and includes authors Kiana Davenport, Lois-Ann Yamanaka, and Kaui Hart Hemmings. Hawaiian magazines include \"Hana Hou!\", \"Hawaii Business\" and \"Honolulu\", among others.\nMusic.\nThe music of Hawaii includes traditional and popular styles, ranging from native Hawaiian folk music to modern rock and hip hop.\nStyles such as slack-key guitar are well known worldwide, while Hawaiian-tinged music is a frequent part of Hollywood soundtracks. Hawaii also made a major contribution to country music with the introduction of the steel guitar.\nTraditional Hawaiian folk music is a major part of the state's musical heritage. The Hawaiian people have inhabited the islands for centuries and have retained much of their traditional musical knowledge. Their music is largely religious in nature, and includes chanting and dance music.\nHawaiian music has had an enormous impact on the music of other Polynesian islands; according to Peter Manuel, the influence of Hawaiian music is a \"unifying factor in the development of modern Pacific musics\". Native Hawaiian musician and Hawaiian sovereignty activist Israel Kamakawiwo\u02bbole, famous for his medley of \"Somewhere Over the Rainbow/What a Wonderful World\", was named \"The Voice of Hawaii\" by NPR in 2010 in its 50 great voices series.\nSports.\nDue to its distance from the continental United States, team sports in Hawaii are characterised by youth, collegial and amateur teams over professional teams, although some professional teams sports teams have at one time played in the state. Notable professional teams include The Hawaiians, which played at the World Football League in 1974 and 1975; the Hawaii Islanders, a Triple-A minor league baseball team that played at the Pacific Coast League from 1961 to 1987; and Team Hawaii, a North American Soccer League team that played in 1977.\nNotable college sports events in Hawaii include the Maui Invitational Tournament, Diamond Head Classic (basketball) and Hawaii Bowl (football). The only NCAA Division I team in Hawaii is the Hawaii Rainbow Warriors and Rainbow Wahine, which competes at the Big West Conference (major sports), Mountain West Conference (football) and Mountain Pacific Sports Federation (minor sports). There are three teams in NCAA Division II: Chaminade Silverswords, Hawaii Pacific Sharks and Hawaii-Hilo Vulcans, all of which compete at the Pacific West Conference.\nSurfing has been a central part of Polynesian culture for centuries. Since the late 19th century, Hawaii has become a major site for surfists from around the world. Notable competitions include the Triple Crown of Surfing and The Eddie. Likewise, Hawaii has produced elite-level swimmers, including five-time Olympic medalist Duke Kahanamoku and Buster Crabbe, who set 16 swimming\nworld records.\nHawaii has hosted the Sony Open in Hawaii golf tournament since 1965, the Tournament of Champions golf tournament since 1999, the Lotte Championship golf tournament since 2012, the Honolulu Marathon since 1973, the Ironman World Championship triathlon race since 1978, the Ultraman triathlon since 1983, the National Football League's Pro Bowl from 1980 to 2016, the 2000 FINA World Open Water Swimming Championships, and the 2008 Pan-Pacific Championship and 2012 Hawaiian Islands Invitational soccer tournaments.\nHawaii has produced a number of notable Mixed Martial Arts fighters, such as former UFC Lightweight Champion and UFC Welterweight Champion B.J. Penn, and former UFC Featherweight Champion Max Holloway. Other notable Hawaiian Martial Artists include Travis Browne, K. J. Noons, Brad Tavares and Wesley Correira.\nHawaiians have found success in the world of sumo wrestling. Takamiyama Daigor\u014d was the first foreigner to ever win a sumo title in Japan, while his protege Akebono Tar\u014d became a top-level sumo wrestler in Japan during the 1990s before transitioning into a successful professional wrestling career in the 2000s. Akebono was the first foreign-born Sumo to reach Yokozuna in history and helped fuel a boom in interest in Sumo during his career.\nTourism.\nTourism is an important part of the Hawaiian economy as it represents a quarter of the economy. According to the Hawaii Tourism: 2019 Annual Visitor Research Report, a total of 10,386,673 visitors arrived in 2019 which increased 5% from the previous year, with expenditures of almost $18 billion. In 2019, tourism provided over 216,000 jobs statewide and contributed more than $2 billion in tax revenue. Due to mild year-round weather, tourist travel is popular throughout the year. Tourists across the globe visited Hawaii in 2019 with over 1 million tourists from the U.S. East, almost 2 million Japanese tourists, and almost 500,000 Canadian tourists.\nIt was with statehood in 1959 that the Hawaii tourism industry began to grow.\nAccording to Hawaiian scholar Haunani-Kay Trask, tourism in Hawaii has led to the commodification and exploitation of Hawaiian culture resulting in insidious forms of \"cultural prostitution\". Hawaii has been used to fuel ideas of escapism yet tourism in Hawaii ignores the harm Kanaka and locals experience. Cultural traditions such as the hula have been made \"ornamental\u00a0... a form of exotica\" for tourists as a way for large corporations and land owners to gain profit over the exploitation of Hawaiian people and culture.\nTourism in Hawai\u02bbi has been considered as an escape from reality resulting in the dismissal of violence faced by Native Hawaiians and locals living on the land. According to scholar Winona LaDuke, native Hawaiians have been forced to gather \"shrimp and fish from ponds sitting on resort property\". Tourism has also had damaging effects on the environment such as water shortages, overcrowding, sea level rising, elevated sea surface temperatures and micro plastics on beaches.\nDue to the COVID-19 pandemic, tourism in Hawai\u02bbi came to a halt, which allowed the land, water, and animals to began to heal. Fish like the baby akule and big ulua have returned after years of not being around the bay. The coral reefs, fish, water growth, and limu (algae) growth was able to flourish without the heavy toll of tourism.\nThere has been pushback against tourism by Native Hawaiians, urging people not to visit the islands. A survey by the Hawaii Tourism Authority indicated over two-thirds of Hawaiians did not want tourists to return to Hawaii. Tourism had \"become extractive and hurtful, with tourists coming here and taking, taking, taking, taking, without any reciprocation with locals\".\nHawaii hosts numerous cultural events. The annual Merrie Monarch Festival is an international Hula competition. The Hawaii International Film Festival is the premier film festival for Pacific rim cinema. Honolulu hosts the state's long-running LGBT film festival, the Rainbow Film Festival.\nHealth.\nAs of 2009[ [update]], Hawaii's health care system insures 92% of residents. Under the state's plan, businesses are required to provide insurance to employees who work more than twenty hours per week. Heavy regulation of insurance companies helps reduce the cost to employers. Due in part to heavy emphasis on preventive care, Hawaiians require hospital treatment less frequently than the rest of the United States, while total health care expenses measured as a percentage of state GDP are substantially lower. Proponents of universal health care elsewhere in the U.S. sometimes use Hawaii as a model for proposed federal and state health care plans.\nEducation.\nPublic schools.\nHawaii has the only school system within the U.S. that is unified statewide. Policy decisions are made by the fourteen-member state Board of Education, which sets policy and hires the superintendent of schools, who oversees the Hawaii Department of Education. The Department of Education is divided into seven districts; four on O\u02bbahu and one for each of the other three counties.\nPublic elementary, middle and high school test scores in Hawaii are below national averages on tests mandated under the No Child Left Behind Act. The Hawaii Board of Education requires all eligible students to take these tests and report all student test scores. This may have unbalanced the results that reported in August 2005 that of 282 schools across the state, 185 failed to reach federal minimum performance standards in mathematics and reading. The ACT college placement tests show that in 2005, seniors scored slightly above the national average (21.9 compared with 20.9), but in the widely accepted SAT examinations, Hawaii's college-bound seniors tend to score below the national average in all categories except mathematics.\nThe first native controlled public charter school was the Kanu O Ka Aina New Century Charter School.\nPrivate schools.\nHawaii has the highest rates of private school attendance in the nation. During the 2011\u20132012 school year, Hawaii public and charter schools had an enrollment of 181,213, while private schools had 37,695. Private schools educated over 17% of students in Hawaii that school year, nearly three times the approximate national average of 6%. According to Alia Wong of \"Honolulu Civil Beat\", this is due to private schools being relatively inexpensive compared to ones on the mainland as well as the overall reputations of private schools.\nIt has four of the largest independent schools; \u02bbIolani School, Kamehameha Schools, Mid-Pacific Institute and Punahou School. Pacific Buddhist Academy, the second Buddhist high school in the U.S. and first such school in Hawaii, was founded in 2003.\nIndependent schools can select their students, while most public schools of HIDOE are open to all students in their attendance zones. The Kamehameha Schools are the only schools in the U.S. that openly grant admission to students based on ancestry; collectively, they are one of the wealthiest schools in the United States, if not the world, having over eleven billion US dollars in estate assets. In 2005, Kamehameha enrolled 5,398 students, 8.4% of the Native Hawaiian children in the state.\nColleges and universities.\nThe largest institution of higher learning in Hawaii is the University of Hawai\u02bbi System, which consists of the research university at M\u0101noa, two comprehensive campuses at Hilo and West O\u02bbahu, and seven community colleges. Private universities include Brigham Young University\u2013Hawaii, Chaminade University of Honolulu, Hawaii Pacific University, and Wayland Baptist University. Saint Stephen Diocesan Center is a seminary of the Roman Catholic Diocese of Honolulu. Kona hosts the University of the Nations, which is not an accredited university.\nTransportation.\nA system of state highways encircles each main island. Only O\u02bbahu has federal highways, and is the only area outside the contiguous 48 states to have signed Interstate highways. Narrow, winding roads and congestion in populated places can slow traffic. Each major island has a public bus system.\nDaniel K. Inouye International Airport (IATA:\u00a0HNL), which shares runways with the adjacent Hickam Field (IATA:\u00a0HIK), is the major commercial aviation hub of Hawaii. The airport was previously known as Honolulu International Airport, before its official renaming on May 30, 2017, after the late U.S. Senator Daniel K. Inouye. The commercial aviation airport offers intercontinental service to North America, Asia, Australia and Oceania. Hawaiian Airlines and Mokulele Airlines use jets to provide services between the large airports in Honolulu, L\u012bhu\u02bbe, Kahului, Kona and Hilo. These airlines also provide air freight services between the islands.\nUntil air passenger services began in the 1920s, private boats were the sole means of traveling between the islands. Seaflite operated hydrofoils between the major islands in the mid-1970s.\nThe Hawaii Superferry operated between O\u02bbahu and Maui between December 2007 and March 2009, with additional routes planned for other islands. Protests and legal problems over environmental impact statements ended the service, though the company operating Superferry has expressed a wish to recommence ferry services in the future. Currently there is a passenger ferry service in Maui County between Lana\u02bbi and Maui, which does not take vehicles; a passenger ferry to Molokai ended in 2016. Currently Norwegian Cruise Lines and Princess Cruises provide passenger cruise ship services between the larger islands.\nRail.\nAt one time Hawaii had a network of railroads on each of the larger islands that transported farm commodities and passengers. Most were narrow gauge systems but there were some gauge on some of the smaller islands. The standard gauge in the U.S. is . By far the largest railroad was the Oahu Railway and Land Company (OR&amp;L) that ran lines from Honolulu across the western and northern part of Oahu.\nThe OR&amp;L was important for moving troops and goods during World War II. Traffic on this line was busy enough for signals to be used to facilitate movement of trains and to require wigwag signals at some railroad crossings for the protection of motorists. The main line was officially abandoned in 1947, although part of it was bought by the U.S. Navy and operated until 1970. of track remain; preservationists occasionally run trains over a portion of this line.\nSkyline is an elevated passenger rail line operated by HART, a semi-autonomous agency of the City and County of Honolulu. It was built with the intention to relieve highway congestion. A portion of Skyline opened for service in 2023, with the next phase expected to open in October 2025, and the final phase in 2031.\nGovernance.\nPolitical subdivisions and local government.\nThe movement of the Hawaiian royal family from Hawai\u02bbi Island to Maui, and subsequently to O\u02bbahu, explains the modern-day distribution of population centers. Kamehameha III chose the largest city, Honolulu, as his capital because of its natural harbor\u2014the present-day Honolulu Harbor. Now the state capital, Honolulu is located along the southeast coast of O\u02bbahu. The previous capital was Lahaina, Maui, and before that Kailua-Kona, Hawai\u02bbi. Some major towns are Hilo; Kaneohe; Kailua; Pearl City; Waipahu; Kahului; Kailua-Kona. K\u012bhei; and L\u012bhu\u02bbe.\nHawaii has five counties: the City and County of Honolulu, Hawaii County, Maui County, Kauai County, and Kalawao County.\nHawaii has the fewest local governments among U.S. states. Unique to this state is the lack of municipal governments. All local governments are generally administered at the county level. The only incorporated area in the state is Honolulu County, a consolidated city\u2013county that governs the entire island of Oahu. County executives are referred to as mayors; these are the Mayor of Hawaii County, Mayor of Honolulu, Mayor of Kaua\u02bbi, and the Mayor of Maui. The mayors are all elected in nonpartisan elections. Kalawao County has no elected government, and as mentioned above there are no local school districts; instead, all local public education is administered at the state level by the Hawaii Department of Education. The remaining local governments are special districts.\nState government.\nThe state government of Hawaii is modeled after the federal government with adaptations originating from the kingdom era of Hawaiian history. As codified in the Constitution of Hawaii, there are three branches of government: executive, legislative, and judicial, although the Office of Hawaiian Affairs is often referred to as the fourth branch of government as it does not fall under the other three branches. The executive branch is led by the Governor of Hawaii, who is assisted by the Lieutenant Governor of Hawaii, both of whom are elected on the same ticket. The governor is the only state public official elected statewide; all others are appointed by the governor. The lieutenant governor acts as the Secretary of State. The governor and lieutenant governor oversee twenty agencies and departments from offices in the State Capitol. The official residence of the governor is Washington Place.\nThe legislative branch consists of the bicameral Hawaii State Legislature, which is composed of the 51-member Hawaii House of Representatives led by the Speaker of the House, and the 25-member Hawaii Senate led by the President of the Senate. The Legislature meets at the State Capitol. The unified judicial branch of Hawaii is the Hawaii State Judiciary. The state's highest court is the Supreme Court of Hawaii, which uses Ali\u02bbi\u014dlani Hale as its chambers.\nFederal government.\nHawaii is represented in the United States Congress by two senators and two representatives. As of 2023[ [update]], all four seats are held by Democrats. Former representative Ed Case was elected in 2018 to the 1st congressional district. Jill Tokuda represents the 2nd congressional district, representing the rest of the state, which is largely rural and semi-rural.\nBrian Schatz is the senior United States senator from Hawaii. He was appointed to the office on December 26, 2012, by Governor Neil Abercrombie, following the death of former senator Daniel Inouye. Schatz then won the 2014 special election, and the 2016 and 2022 regular elections in Hawaii as Senator.\nThe state's junior senator is Mazie Hirono, the former representative from the second congressional district. She won in the 2012, 2018, and 2024 elections for Senator in Hawaii, following the retirement of Daniel Akaka. Hirono is the first female Asian American senator and the first Buddhist senator.\nHawaii incurred the biggest seniority shift between the 112th and 113th Congresses. The state went from a delegation consisting of senators who were first and twenty-first in seniority to their respective replacements, relative newcomers Schatz and Hirono.\nFederal officials in Hawaii are based at the Prince K\u016bhi\u014d Federal Building near the Aloha Tower and Honolulu Harbor. The Federal Bureau of Investigation, Internal Revenue Service and the Secret Service maintain their offices there; the building is also the site of the federal District Court for the District of Hawaii and the United States Attorney for the District of Hawaii.\nPolitics.\nSince gaining statehood and participating in its first election in 1960, Hawaii has supported Democrats in all but two presidential elections: 1972 and 1984, both of which were landslide reelection victories for Republicans Richard Nixon and Ronald Reagan respectively. In Hawaii's statehood tenure, only Minnesota has supported Republican candidates fewer times in presidential elections. The 2022 Cook Partisan Voting Index ranks Hawaii as the third-most heavily Democratic state in the nation.\nHawaii has not elected a Republican to represent the state in the U.S. Senate since Hiram Fong in 1970; since 1977, both of the state's U.S. Senators have been Democrats.\nIn 2004, John Kerry won the state's four electoral votes by a margin of nine percentage points with 54% of the vote. Every county supported the Democratic candidate. In 1964, favorite son candidate senator Hiram Fong of Hawaii sought the Republican presidential nomination, while Patsy Mink ran in the Oregon primary in 1972.\nHonolulu-born Barack Obama, then serving as a United States senator from Illinois, was elected the 44th president of the United States on November 4, 2008, and was re-elected for a second term on November 6, 2012. Obama had won the Hawaii Democratic caucus on February 19, 2008, with 76% of the vote. He was the third Hawaii-born candidate to seek the nomination of a major party, the first presidential nominee and first president from Hawaii.\nIn a 2020 study, Hawaii was ranked as the 6th easiest state for citizens to vote in.\nLaw enforcement.\nHawaii has a statewide sheriff department under its Department of Public Safety that provides law enforcement protection to government buildings and Daniel K. Inouye International Airport as well as correction services to all correctional facilities owned by the state.\nCounties have their own respective police departments with their own jurisdictions:\nForensic services for all agencies in the state are provided by the Honolulu Police Department.\nIn January 2022, state officials proposed legislation that would split the sheriff department from the Department of Public Safety and consolidate it with the criminal investigation division from the Department of the Attorney General to create a new Department of Law Enforcement that would create a statewide police agency with the ability to investigate crimes.\nHawaiian sovereignty movement.\nWhile Hawaii is internationally recognized as a state of the United States while also being broadly accepted as such in mainstream understanding, the legality of this status has been questioned in U.S. District Court, the U.N., and other international forums. Domestically, the debate is a topic covered in the Kamehameha Schools curriculum, and in classes at the University of Hawai\u02bbi at M\u0101noa.\nPolitical organizations seeking some form of sovereignty for Hawaii have been active since the late 19th century. Generally, their focus is on self-determination and self-governance, either for Hawaii as an independent nation (in many proposals, for \"Hawaiian nationals\" descended from subjects of the Hawaiian Kingdom or declaring themselves as such by choice), or for people of whole or part native Hawaiian ancestry in an indigenous \"nation to nation\" relationship akin to tribal sovereignty with US federal recognition of Native Hawaiians. The pro-federal recognition Akaka Bill drew substantial opposition among Hawaiian residents in the 2000s. Opponents to the tribal approach argue it is not a legitimate path to Hawaiian nationhood; they also argue that the U.S. government should not be involved in re-establishing Hawaiian sovereignty.\nThe Hawaiian sovereignty movement views the overthrow of the Kingdom of Hawaii in 1893 as illegal, and views the subsequent annexation of Hawaii by the United States as illegal as well; the movement seeks some form of greater autonomy for Hawaii, such as free association or independence from the United States.\nSome groups also advocate some form of redress from the United States for the 1893 overthrow of Queen Lili\u02bbuokalani, and for what is described as a prolonged military occupation beginning with the 1898 annexation. The Apology Resolution passed by US Congress in 1993 is cited as a major impetus by the movement for Hawaiian sovereignty. The sovereignty movement considers Hawaii to be an illegally occupied nation.\nReferences.\nInformational notes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "13274", "revid": "49034531", "url": "https://en.wikipedia.org/wiki?curid=13274", "title": "Hearse", "text": "Large funeral vehicle\nA hearse () is a large vehicle, originally a horse carriage but later with the introduction of motor vehicles, a car, used to carry the body of a deceased person in a coffin to a funeral, wake, or graveside service. They range from deliberately anonymous vehicles to heavily decorated vehicles.\nIn the funeral trade of some countries hearses are called funeral cars or funeral coaches.\nHistory.\nThe name is derived, through the French herse, from the Latin , which means a harrow. The funeral hearse was originally a wooden or metal framework, which stood over the bier or coffin and supported the pall. It was provided with numerous spikes to hold burning candles, and, owing to the resemblance of these spikes to the teeth of a harrow, was called a hearse. Later on, the word was applied, not only to the construction above the coffin, but to any receptacle in which the coffin was placed. Thus from about 1650 it came to denote the vehicle on which the dead are carried to the grave.\nHearses were originally hand-drawn then horse-drawn after the decoration and weight of the hearse increased. The first electric motorized hearses were introduced to the United States in the early 1900s. Petrol-powered hearses began to be produced from 1907 and, after slow initial uptake due to their high cost, became widely accepted in the 1920s. The vast majority of hearses since then have been based on larger, more powerful car chassis, generally retaining the front end up to and possibly including the front doors but with custom bodywork to the rear to contain the coffin.\nFirst call vehicles.\nA first call vehicle is used to pick up the remains of a recently deceased person, and transport them to a funeral home or morgue.\nRail transport.\nA few big cities provided special rail lines and/or funeral trolley cars and/or subway cars to carry bodies and mourners to remote cemeteries such as in Sydney, NSW and London and tram services were common. Chicago, Illinois operated 3 different funeral trolley cars over the elevated tracks in downtown Chicago to outlying cemeteries in the western suburbs. A special funeral bureau handled the funeral trains which sometimes operated 3\u20134 funeral trains a week over the \"L\".\nMotorcycle hearses.\nA motorcycle hearse may be used during the funeral of a motorcycle enthusiast. It is either a motorcycle with a sidecar built to carry a casket or urn at the side of the rider, or a trike that carries the casket behind the rider.\nModern usage.\nTwo styles of formal hearse bodywork are common. One style has opaque rear panels so the coffin is barely glimpsed. This American style is fitted with a heavily padded leather or vinyl roof and each side decorated with large mock landau bars resembling the braces used for the folding leather tops on some horse-drawn carriages. The other has narrow pillars and large windows revealing the coffin.\nSince the working life of a hearse is generally one of light duty and short, sedate drives, hearses often remain serviceable for a long time and hearses 30 years old or more may still be in service. Due to the costs of owning an expensive custom vehicle that sits idle \"80 to 90 percent of the week\", individual funeral homes reduce costs by renting or utilizing a shared motor pool.\nPerhaps owing to the morbid associations of the hearse, its luxurious accommodations for the driver, or both, the hearse has a number of enthusiasts who own and drive retired hearses. There are several hearse clubs.\nNorth America.\nUsually, more luxurious automobile brands are used as a base for funeral cars; since the 1930s, the vast majority of hearses in the United States and Canada have been Cadillacs and less frequently, Lincolns.\nThe Cadillac Commercial Chassis was a longer and strengthened version of the long-wheelbase Fleetwood limousine frame to carry the extra weight of bodywork, rear deck and cargo. The rear of the Cadillac commercial chassis was considerably lower than the passenger car frame, thereby lowering the rear deck height as well for ease of loading and unloading. The Cadillac hearses were shipped as incomplete cars to coachbuilders for final assembly. Since the late 1990s, most Cadillac based funeral cars have been constructed from modified Cadillac sedans, until late 2019; The XTS chassis was discontinued from General Motors, and as such any new Cadillac hearse will be built on the XT5 SUV chassis, with the S&amp;S Coach Company now building certain models of hearse on the XT6 platform. \nThe fleet division of Ford Motor Company sells a Lincoln Town Car with a special \"hearse package\" strictly to coachbuilders. Shipped without rear seat, rear interior trim, rear window or decklid, the hearse package also features upgraded suspension, brakes, charging system and tires. This was replaced with the Lincoln MKT, which has also been discontinued, followed by the Continental which also was discontinued after a short run. \nThe limousine style of hearse is more popular in the United States. It is common practice in the US for the windows to be curtained, while in other countries the windows are normally left unobscured.\nUntil the 1970s, it was common for many hearses to also be used as ambulances, due to the large cargo capacity in the rear of the vehicle. These vehicles were called \"combination cars\" and were especially used in small towns and rural areas. Car-based ambulances and combination coaches were unable to meet stricter Federal specifications for such vehicles and were discontinued after 1979.\nEurope.\nCoachbuilders modify Mercedes-Benz, Jaguar, Opel, Ford, Vauxhall Motors and Volvo products to hearses. Some second-hand Rolls-Royce cars have traditionally been used as hearses though the high cost of newer models is generally considered prohibitive.\nIn the United Kingdom it is possible to hire 'non-traditional' hearses that have usually been converted from various production vehicles such as vans or 'estate' style cars which may have held a particular memory for the deceased. An example of this is the Morris Minor Traveller, a popular and well-loved car in the United Kingdom. \nJapan.\nIn Japan, hearses, called , can come in two styles: \"Foreign\" style, which is similar in build and style to an American hearse, or a \"Japanese\" style, in which the rear area of the vehicle is modified to resemble a small, ornate Buddhist temple.\nThe Japanese-style hearse generally requires the rear of the vehicle to be extensively altered; commonly, the rear roof is cut away from the front windows back and all interior parts are removed from the rear as well. The ornate Buddhist-style rear area, generally constructed of wood and in which the casket or urn is placed, is built on top of this empty cavity and most often is wider than the base of the vehicle, so that it sticks out on the sides, over the rear body panels. Popular bases for these hearses are large sedans, minivans and pickup trucks.\nThe ornaments on a Japanese-style hearse vary by region. Nagoya style decorates both the upper and lower halves of the car body.\nKansai style has a relatively modest decorations unpainted.\nKanazawa style is known for having a red body (other styles mostly have black bodies) with gilded ornaments.\nTokyo style, found anywhere else in Japan, features painted/gilded ornaments on the upper half of the body.\n\"Foreign\" style hearses are mostly similar in appearance to their US counterparts, although their exterior dimensions and interiors reflect the Japanese preference for smaller, less ornate caskets (this in light of the national preference for cremation). This means that, in contrast to American hearses, the rear quarter panels require less, and sometimes no, alteration. These are generally built from station wagons such as the Nissan Stagea, or from executive sedans such as the Toyota Celsior (Lexus LS in the US) and Nissan Cima (Infiniti Q45 in the US). American market vehicles such as the Lincoln Town Car and Cadillac DeVille, which are otherwise fairly uncommon in Japan, are often converted to hearses in both styles.\nHong Kong.\nIn Hong Kong, light goods vehicles of Isuzu, Volkswagen and Ford are used as hearses by most of the privately operated funeral homes.\nSingapore.\nIn Singapore, most standard hearses are built on a commercial van chassis, such as the Toyota Hiace, the Nissan Urvan and the Mercedes-Benz Vito, while the traditional Chinese or Indian hearses are built on a lorry chassis such as the Mitsubishi Fuso Canter and the Isuzu Elf. There are also some limousine hearses in Singapore that are built on a luxury car chassis, such as Mercedes-Benz, Maserati and Jaguar.\nIn popular culture.\nAmongst hearse enthusiasts, the 1959 Cadillac Miller-Meteor hearse is considered one of the most desirable, due to its especially ornate styling and appearances in several feature films, notably an ambulance version (Ecto-1) in the 1984 film \"Ghostbusters\".\nIn the 2016 \"Ghostbusters\" reboot, the Ecto-1 is a 1984 Cadillac Superior hearse.\nThe Rogues prowl around in a graffitied 1955 Cadillac Hearse in the film \"The Warriors\".\nMusician Neil Young's first car was a hearse, which was used to transport the band's equipment.\nCelebrity hearse enthusiasts include rock singer Neil Young and three-time NASCAR Sprint Cup Champion Tony Stewart, who had his hearse customised for a television show. Sam the Sham of the Pharaohs (known for Wooly Bully and Lil' Red Riding Hood) was known for transporting all his equipment in a 1952 Packard hearse.\nIn April 2021, following the death of Prince Philip, Duke of Edinburgh, it was revealed that the prince had helped to design a custom-built military green, Land Rover Defender which was used to transport his coffin in his funeral procession at Windsor Castle.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "13275", "revid": "35498457", "url": "https://en.wikipedia.org/wiki?curid=13275", "title": "Hungary", "text": "Country in Central Europe\nHungary is a landlocked country in Central Europe. Spanning much of the Carpathian Basin, it is bordered by Slovakia to the north, Ukraine to the northeast, Romania to the east and southeast, Serbia to the south, Croatia and Slovenia to the southwest, and Austria to the west. Hungary lies within the drainage basin of the Danube River and is dominated by great lowland plains. It has a population of 9.6 million, consisting mostly of ethnic Hungarians (Magyars) and a significant Romani minority. Hungarian is the official language, and among the few in Europe outside the Indo-European family. Budapest is the country's capital and largest city, and the dominant cultural and economic centre.\nPrior to the foundation of the Hungarian state, various peoples settled in the territory of present-day Hungary, including the Celts, Romans, Huns, Germanic peoples, Avars and Slavs. Hungarian statehood is traced to the Principality of Hungary, which was established in the late ninth century by \u00c1lmos and his son \u00c1rp\u00e1d through the conquest of the Carpathian Basin. King Stephen I ascended the throne in 1000 and converted his realm to a Christian kingdom. The medieval Kingdom of Hungary was a European power, reaching its height in the Late Middle Ages.\nAfter a long period of Ottoman wars, Hungary's forces were defeated at the Battle of Moh\u00e1cs in 1526 and its capital Buda was captured in 1541, opening a period of more than 150 years where the country was divided into three parts: Royal Hungary (loyal to the Habsburgs), Ottoman Hungary and the semi-independent Principality of Transylvania. The Ottomans recognised the loss of Ottoman Hungary by the Treaty of Karlowitz in 1699. Most of Hungary was reunited and came under Habsburg rule by the turn of the 18th century.\nWars of independence against the Habsburgs in 1703\u20131711 and 1848\u20131849 resulted in a compromise that established the Austro-Hungarian Monarchy in 1867, a major power in the early 20th century. Austria-Hungary collapsed after World War I, and the subsequent Treaty of Trianon in 1920 established Hungary's current borders, resulting in the loss of 71% of its historical territory, majority of its economy, 58% of its population, and 32% of its ethnic Hungarians.\nReeling from the aftermath of the war, Hungary endured turmoil in the early interwar period, culminating in the nationalist conservative regime of Regent ruler Mikl\u00f3s Horthy. Hungary joined the Axis powers in World War II, suffering significant damage and casualties. It was occupied by the Soviet Union, which established the Hungarian People's Republic as a satellite state. Following the failed 1956 revolution, Hungary became comparatively freer but remained a repressed member of the Eastern Bloc. As part of the Revolutions of 1989, Hungary peacefully transitioned into a democratic parliamentary republic. It joined the European Union in 2004 and the Schengen Area since 2007.\nHungary is a high-income economy with universal health care and tuition-free secondary education. Hungary has a long history of significant contributions to arts, music, literature, sports, science and technology. It is a popular tourist destination in Europe, drawing 24.5 million international visitors in 2019. Hungary is a member of numerous international organisations, including the Council of Europe, European Union, NATO, United Nations, World Health Organization, World Trade Organization, World Bank, Asian Infrastructure Investment Bank, and the Visegr\u00e1d Group.\n&lt;templatestyles src=\"Template:TOC limit/styles.css\" /&gt;\nEtymology.\nThe \"H\" in the name of Hungary is most likely derived from historical associations with the Huns, who had settled Hungary prior to the Avars. The rest of the word comes from the Latinised form of Byzantine Greek (). The Greek name might be borrowed from Old Slavonic , in turn borrowed from Oghur-Turkic \"Onogur\" ('ten [tribes of the] Ogurs'). \"Onogur\" was the collective name for the tribes who later joined the Bulgar tribal confederacy that ruled the eastern parts of Hungary after the Avars. Peter B. Golden also considers the suggestion of \u00c1rp\u00e1d Berta that the name derives from Khazar Turkic (o\u014b \"right\", o\u014bar- \"to make something better, to put (it) right\", o\u014bgar- \"to make something better, to put (it) right\", o\u014baru \"towards the right\") \"right wing\". This points to the idea that the Magyar Union before the Conquest formed the \"right wing\" (western wing) of the Khazar military forces.\nThe Hungarian endonym is , composed of ('Hungarian') and ('country'). The name \"Magyar\", which refers to the people of the country, more accurately reflects the name of the country in some other languages such as Turkish, Persian and other languages as \"Magyaristan\" or \"Land of Magyars\" or similar. The word \"magyar\" is taken from the name of the leading tribe name of the seven major semi-nomadic Hungarian tribes.\nHistory.\nBefore 895.\nThe Roman Empire conquered the territory between the Alps and the area west of the Danube River from 16 to 15 BC, the Danube being the frontier of the empire. In 14 BC, Pannonia, the western part of the Carpathian Basin, which includes the west of today's Hungary, was recognised by emperor Augustus in the \"Res Gestae Divi Augusti\" as part of the Roman Empire. The area south-east of Pannonia was organised as the Roman province Moesia in 6 BC. An area east of the river Tisza became the Roman province of Dacia in 106 AD, which included today's east Hungary. It remained under Roman rule until 271.\nFrom 235, the Roman Empire went through troubled times, caused by revolts, rivalry and rapid succession of emperors. The Western Roman Empire collapsed in the 5th century under the stress of the migration of Germanic tribes and Carpian pressure. This period brought many invaders into Central Europe, beginning with the Hunnic Empire (c.\u2009370\u2013469). The most powerful ruler of the Hunnic Empire was Attila the Hun (434\u2013453), who later became a central figure in Hungarian mythology. After the disintegration of the Hunnic Empire, the Gepids, an Eastern Germanic tribe, who had been vassalised by the Huns, established their own kingdom in the Carpathian Basin. Other groups which reached the Carpathian Basin during the Migration Period were the Goths, Vandals, Lombards, and Slavs.\nIn the 560s, the Avars founded the Avar Khaganate, a state that maintained supremacy in the region for more than two centuries. The Franks under Charlemagne defeated the Avars in a series of campaigns during the 790s. Between 804 and 829, the First Bulgarian Empire conquered the lands east of the Danube and took over the rule of the local Slavic tribes and remnants of the Avars. By the mid-9th century, the Balaton Principality, also known as Lower Pannonia, was established west of the Danube as part of the Frankish March of Pannonia.\nMiddle Ages (895\u20131526).\nFoundation of the Hungarian state is connected to the Hungarian conquerors, who arrived from the Pontic-Caspian steppe as a confederation of seven tribes. The Hungarians arrived in the Carpathian Basin as a frame of a strong centralised steppe-empire under the leadership of Grand Prince \u00c1lmos and his son \u00c1rp\u00e1d: founders of the \u00c1rp\u00e1d dynasty, the Hungarian ruling dynasty and the Hungarian state. The \u00c1rp\u00e1d dynasty claimed to be a direct descendant of Attila the Hun. The Hungarians took possession of the area in a pre-planned manner, with a long move-in between 862 and 895. The rising Hungary conducted successful fierce campaigns and raids, from Constantinople to as far as today's Spain. The Hungarians defeated three major East Frankish imperial armies between 907 and 910. A defeat at the Battle of Lechfeld in 955 signaled a provisory end to most campaigns on foreign territories, at least towards the west.\nAge of \u00c1rp\u00e1dian kings.\nIn 972, the ruling prince () G\u00e9za of the \u00c1rp\u00e1d dynasty officially started to integrate Hungary into Christian Western Europe. His son Saint Stephen I became the first King of Hungary after defeating his pagan uncle Kopp\u00e1ny. Under Stephen, Hungary was recognised as a Catholic Apostolic Kingdom. Applying to Pope Sylvester II, Stephen received the insignia of royalty (including probably a part of the Holy Crown of Hungary) from the papacy.\nBy 1006, Stephen consolidated his power and started sweeping reforms to convert Hungary into a Western-style feudal state. The country switched to using Latin for administration purposes, and until as late as 1844, Latin remained the official language of administration. King Saint Ladislaus completed the work of King Saint Stephen, consolidating the Hungarian state's power and strengthening Christianity. His charismatic personality, strategic leadership and military talents resulted in the termination of internal power struggles and foreign military threats. The wife of the Croatian king Demetrius Zvonimir was Ladislaus's sister. At Helen's request, Ladislaus intervened in the conflict and invaded Croatia in 1091. The Kingdom of Croatia entered a personal union with the Kingdom of Hungary in 1102 with the coronation of King Coloman as \"King of Croatia and Dalmatia\" in 1102 in Biograd.\nOne of the most powerful and wealthiest king of the \u00c1rp\u00e1d dynasty was B\u00e9la III, who disposed of the equivalent of 23 tonnes of silver per year, according to a contemporary income register. This exceeded the income of the French king (estimated at 17 tonnes) and was double the receipts of the English Crown. Andrew II issued the \"Diploma Andreanum\" which secured the special privileges of the Transylvanian Saxons and is considered the first autonomy law in the world. He led the Fifth Crusade to the Holy Land in 1217, setting up the largest royal army in the history of Crusades. His Golden Bull of 1222 was the first constitution in Continental Europe. The lesser nobles also began to present Andrew with grievances, a practice that evolved into the institution of the parliament (\"parlamentum publicum\").\nIn 1241\u20131242, the kingdom received a major blow with the Mongol (Tatar) invasion. Up to half of Hungary's population of 2 million were victims of the invasion. King B\u00e9la IV let Cumans and Jassic people into the country, who were fleeing the Mongols. Over the centuries, they were fully assimilated. After the Mongols retreated, King B\u00e9la ordered the construction of hundreds of stone castles and fortifications, to defend against a possible second Mongol invasion. The Mongols returned to Hungary in 1285, but the newly built stone-castle systems and new tactics (using a higher proportion of heavily armed knights) stopped them. The invading Mongol force was defeated near Pest by the royal army of King Ladislaus IV. As with later invasions, it was repelled handily, the Mongols losing much of their invading force.\nAge of elected kings.\nThe Kingdom of Hungary reached one of its greatest extents during the \u00c1rp\u00e1dian kings, yet royal power was weakened at the end of their rule in 1301. After a destructive period of interregnum (1301\u20131308), the first Angevin king, Charles I of Hungary \u2013 a bilineal descendant of the \u00c1rp\u00e1d dynasty \u2013 successfully restored royal power and defeated oligarch rivals, the so-called \"little kings\". The second Angevin Hungarian king, Louis the Great (1342\u20131382), led many successful military campaigns from Lithuania to southern Italy (Kingdom of Naples) and was also King of Poland from 1370. After King Louis died without a male heir, the country was stabilised only when Sigismund of Luxembourg (1387\u20131437) succeeded to the throne, who in 1433 also became Holy Roman Emperor.\nThe first Hungarian Bible translation was completed in 1439. For half a year in 1437, there was an antifeudal and anticlerical peasant revolt in Transylvania which was strongly influenced by Hussite ideas. From a small noble family in Transylvania, John Hunyadi grew to become one of the country's most powerful lords, thanks to his capabilities as a mercenary commander. He was elected governor, then regent. He was a successful crusader against the Ottoman Turks, one of his greatest victories being the siege of Belgrade in 1456.\nThe last strong king of medieval Hungary was the Renaissance king Matthias Corvinus (1458\u20131490), son of John Hunyadi. His election was the first time that a member of the nobility mounted to the Hungarian royal throne without dynastic background. He was a successful military leader and an enlightened patron of the arts and learning. His library, the Bibliotheca Corviniana, was Europe's greatest collection of historical chronicles, philosophic and scientific works in the 15th century, and second only in size to the Vatican Library. Items from the Bibliotheca Corviniana were inscribed on UNESCO's Memory of the World Register in 2005. The serfs and common people considered him a just ruler because he protected them from excessive demands and other abuses by the magnates. Under his rule, in 1479, the Hungarian army destroyed the Ottoman and Wallachian troops at the Battle of Breadfield. Abroad he defeated the Polish and German imperial armies of Frederick at Breslau (Wroc\u0142aw). Matthias' mercenary standing army, the Black Army of Hungary, was an unusually large army for its time, and it conquered Vienna as well as parts of Austria and Bohemia.\nKing Matthias died without lawful sons, and the Hungarian magnates procured the accession of the Pole Vladislaus II (1490\u20131516), supposedly because of his weak influence on Hungarian aristocracy. Hungary's international role declined, its political stability was shaken, and social progress was deadlocked. In 1514, the weakened old King Vladislaus II faced a major peasant rebellion led by Gy\u00f6rgy D\u00f3zsa, which was ruthlessly crushed by the nobles, led by John Z\u00e1polya. The resulting degradation of order paved the way for Ottoman preeminence. In 1521, the strongest Hungarian fortress in the South, N\u00e1ndorfeh\u00e9rv\u00e1r (today's Belgrade, Serbia), fell to the Turks. The early appearance of Protestantism further worsened internal relations in the country.\nOttoman wars (1526\u20131699).\nAfter some 150 years of wars with the Hungarians and other states, the Ottomans gained a decisive victory over the Hungarian army at the Battle of Moh\u00e1cs in 1526, where King Louis II died while fleeing. Amid political chaos, the divided Hungarian nobility elected two kings simultaneously, John Z\u00e1polya and Ferdinand I of the Habsburg dynasty. With the conquest of Buda by the Turks in 1541, Hungary was divided into three parts and remained so until the end of the 17th century. The north-western part, termed as Royal Hungary, was annexed by the Habsburgs who ruled as kings of Hungary. The eastern part of the kingdom became independent as the Principality of Transylvania, under Ottoman (and later Habsburg) suzerainty. The remaining central area, including the capital Buda, was known as the Pashalik of Buda.\nIn 1686, the Holy League's army, containing over 74,000 men from various nations, reconquered Buda from the Turks. After some more crushing defeats of the Ottomans in the next few years, the entire Kingdom of Hungary was removed from Ottoman rule by 1718. The last raid into Hungary by the Ottoman vassals Tatars from Crimea took place in 1717. The constrained Habsburg Counter-Reformation efforts in the 17th century reconverted the majority of the kingdom to Catholicism. The ethnic composition of Hungary was fundamentally changed as a consequence of the prolonged warfare with the Turks. A large part of the country became devastated, population growth was stunted, and many smaller settlements perished. The Austrian-Habsburg government settled large groups of Serbs and other Slavs in the depopulated south, and settled Germans (called Danube Swabians) in various areas, but Hungarians were not allowed to settle or re-settle in the south of the Carpathian Basin.\nFrom the 18th century to World War I (1699\u20131918).\nBetween 1703 and 1711, there was a large-scale war of independence led by Francis II R\u00e1k\u00f3czi, who after the dethronement of the Habsburgs in 1707 at the Diet of \u00d3nod, took power provisionally as the ruling prince for the wartime period, but refused the Hungarian crown and the title \"king\". The uprisings lasted for years. The Hungarian Kuruc army, although taking over most of the country, lost the main battle at Trencs\u00e9n (1708). Three years later, because of the growing desertion, defeatism, and low morale, the Kuruc forces surrendered.\nDuring the Napoleonic Wars and afterward, the Hungarian Diet had not convened for decades. In the 1820s, the emperor was forced to convene the Diet, which marked the beginning of a Reform Period (1825\u20131848, ). The Hungarian Parliament was reconvened in 1825 to handle financial needs. A liberal party emerged and focused on providing for the peasantry. Lajos Kossuth emerged as a leader of the lower gentry in the Parliament. A remarkable upswing started as the nation concentrated its forces on modernisation even though the Habsburg monarchs obstructed all important liberal laws relating to civil and political rights and economic reforms. Many reformers (Lajos Kossuth, Mih\u00e1ly T\u00e1ncsics) were imprisoned by the authorities.\nOn 15 March 1848, mass demonstrations in Pest and Buda enabled Hungarian reformists to push through a list of 12 demands. Under Governor and President Lajos Kossuth and Prime Minister Lajos Batthy\u00e1ny, the House of Habsburg was dethroned. The Habsburg ruler and his advisors skillfully manipulated the Croatian, Serbian and Romanian peasantry, led by priests and officers firmly loyal to the Habsburgs, into rebelling against the Hungarian government, though the Hungarians were supported by the vast majority of the Slovak, German and Rusyn nationalities and by all the Jews of the kingdom, as well as by a large number of Polish, Austrian and Italian volunteers. In July 1849 the Hungarian Parliament proclaimed and enacted the first laws of ethnic and minority rights in the world. Many members of the nationalities gained the coveted highest positions within the Hungarian Army, like J\u00e1nos Damjanich and J\u00f3zef Bem. The Hungarian forces (\"Honv\u00e9ds\u00e9g\") defeated Austrian armies. To counter the successes of the Hungarian revolutionary army, Habsburg Emperor Franz Joseph I asked for help from the \"Gendarme of Europe\", Tsar Nicholas I, whose Russian armies invaded Hungary. This made Art\u00far G\u00f6rgey surrender in August 1849. The leader of the Austrian army, Julius Jacob von Haynau, became governor of Hungary for a few months and ordered the execution of the 13 Martyrs of Arad, leaders of the Hungarian army, and Prime Minister Batthy\u00e1ny in October 1849. Kossuth escaped into exile. Following the war of 1848\u20131849, the whole country was in \"passive resistance\".\nBecause of external and internal problems, reforms seemed inevitable, and major military defeats of Austria forced the Habsburgs to negotiate the Austro-Hungarian Compromise of 1867, by which the dual monarchy of Austria-Hungary was formed. This empire had the second largest area in Europe (after the Russian Empire), and it was the third most populous (after Russia and the German Empire). The two realms were governed separately by two parliaments from two capital cities, with a common monarch and common external and military policies. Economically, the empire was a customs union. The old Hungarian Constitution was restored, and Franz Joseph I was crowned as King of Hungary. The era witnessed impressive economic development. The formerly backward Hungarian economy became relatively modern and industrialised by the turn of the 20th century, although agriculture remained dominant until 1890. In 1873, the old capital Buda and \u00d3buda were officially united with Pest, creating the new metropolis of Budapest. Many of the state institutions and the modern administrative system of Hungary were established during this period.\nAfter the assassination of Archduke Franz Ferdinand in Sarajevo, Prime Minister Istv\u00e1n Tisza and his cabinet tried to avoid the outbreak and escalating of a war in Europe, but their diplomatic efforts were unsuccessful. Austria-Hungary drafted over 4\u00a0million soldiers from the Kingdom of Hungary on the side of Germany, Bulgaria, and Turkey. The troops raised in the Kingdom of Hungary spent little time defending the actual territory of Hungary, with the exceptions of the Brusilov offensive in June 1916 and a few months later when the Romanian army made an attack into Transylvania, both of which were repelled. The Central Powers conquered Serbia. Romania declared war. The Central Powers conquered southern Romania and the Romanian capital Bucharest. In 1916 Franz Joseph died, and the new monarch Charles IV sympathised with the pacifists. With great difficulty, the Central Powers stopped and repelled the attacks of the Russian Empire.\nThe Eastern Front of the Allied (Entente) Powers completely collapsed. The Austro-Hungarian Empire then withdrew from all defeated countries. Despite great success on the Eastern Front, Germany suffered complete defeat on the Western Front. By 1918, the economic situation had deteriorated (strikes in factories were organised by leftist and pacifist movements) and uprisings in the army had become common. In the capital cities, the Austrian and Hungarian leftist liberal movements and their leaders supported the separatism of ethnic minorities. Austria-Hungary signed a general armistice in Padua on 3 November 1918. In October 1918, Hungary's union with Austria was dissolved.\nBetween the World Wars (1918\u20131941).\nFollowing the First World War, Hungary underwent a period of profound political upheaval, beginning with the Aster Revolution in 1918, which brought the social-democratic Mih\u00e1ly K\u00e1rolyi to power as prime minister. The Hungarian Royal Honv\u00e9d army still had more than 1,400,000 soldiers when K\u00e1rolyi was installed. K\u00e1rolyi yielded to U.S. President Woodrow Wilson's demand for pacifism by ordering the disarmament of the Hungarian army. Disarmament meant that Hungary was to remain without a national defence at a time of particular vulnerability. During the rule of K\u00e1rolyi's pacifist cabinet, Hungary lost control over approximately 75% of its pre-war territories () without a fight and was subject to foreign occupation. The Little Entente, sensing an opportunity, invaded the country from three sides\u2014Romania invaded Transylvania, Czechoslovakia annexed Upper Hungary (today's Slovakia), and a joint Serb-French coalition annexed Vojvodina and other southern regions. In March 1919, communists led by B\u00e9la Kun ousted the K\u00e1rolyi government and proclaimed the Hungarian Soviet Republic (\"Tan\u00e1csk\u00f6zt\u00e1rsas\u00e1g\"), followed by a thorough Red Terror campaign. Despite some successes on the Czechoslovak front, Kun's forces were ultimately unable to resist the Romanian invasion; by August 1919, Romanian troops occupied Budapest and ousted Kun.\nIn November 1919, rightist forces led by former Austro-Hungarian admiral Mikl\u00f3s Horthy entered Budapest; exhausted by the war and its aftermath, the populace accepted Horthy's leadership. In January 1920, parliamentary elections were held, and Horthy was proclaimed regent of the reestablished Kingdom of Hungary, inaugurating the so-called \"Horthy era\" (\"Horthy-kor\"). The new government worked quickly to normalise foreign relations while turning a blind eye to a White Terror that swept through the countryside; extrajudicial killings of suspected communists and Jews lasted well into 1920.\nOn 4 June 1920, the Treaty of Trianon established new borders for Hungary. The country lost 71% of its territory and 66% of its pre-war population, as well as many sources of raw materials and its sole port at Fiume. An estimated 3.3 million ethnic Hungarians were living in the ceded territories, mostly in what is now Romania, Slovakia and Serbia, although modern sources for this figure range from 2 million to 5 million. Though the revision of the treaty quickly rose to the top of the national political agenda, the Horthy government was not willing to resort to military intervention to do so.\nThe initial years of the Horthy regime were preoccupied with putsch attempts by Charles IV, the Austro-Hungarian pretender; continued suppression of communists; and a migration crisis triggered by the Trianon territorial changes. The government's actions continued to drift right with the passage of antisemitic laws and, because of the continued isolation of the Little Entente, economic and then political gravitation towards Italy and Germany. The Great Depression further exacerbated the situation, and the popularity of fascist politicians increased, such as Gyula G\u00f6mb\u00f6s and Ferenc Sz\u00e1lasi, promising economic and social recovery. Horthy's nationalist agenda reached its apogee in 1938 and 1940, when the Nazis rewarded Hungary's staunchly pro-Germany foreign policy in the First and Second Vienna Awards, peacefully restoring ethnic-Hungarian-majority areas lost after Trianon. In 1939, Hungary regained further territory from Czechoslovakia through force. Hungary formally joined the Axis powers on 20 November 1940 and in 1941 participated in the invasion of Yugoslavia, gaining some of its former territories in the south.\nWorld War II (1941\u20131945).\nHungary formally entered World War II as an Axis power on 26 June 1941, declaring war on the Soviet Union after unidentified planes bombed Kassa, Munk\u00e1cs, and Rah\u00f3. Hungarian troops fought on the Eastern Front for two years. Despite early success at the Battle of Uman, the government began seeking a secret peace pact with the Allies after the Second Army suffered catastrophic losses at the River Don in January 1943. Learning of the planned defection, German troops occupied Hungary on 19 March 1944 to guarantee Horthy's compliance.\nIn October, as the Soviet front approached, and the government made further efforts to disengage from the war, German troops ousted Horthy and installed a puppet government under Sz\u00e1lasi's fascist Arrow Cross Party. Sz\u00e1lasi pledged all the country's capabilities in service of the German war machine. By October 1944, the Soviets had reached the river Tisza, and despite some losses, succeeded in encircling and besieging Budapest in December.\nOn 13 February 1945, Budapest surrendered; by April, German troops left the country under Soviet military occupation. 200,000 Hungarians were expelled from Czechoslovakia in exchange for 70,000 Slovaks living in Hungary. 202,000 ethnic Germans were expelled to Germany, and through the 1947 Paris Peace Treaties, Hungary was again reduced to its immediate post-Trianon borders.\nThe war left Hungary devastated, destroying over 60% of the economy and causing significant loss of life. In addition to the over 600,000 Hungarian Jews killed,&lt;ref name=\"ind09/96\"&gt;&lt;/ref&gt; as many as 280,000 other Hungarians were raped, murdered and executed or deported for slave labour. After German occupation, Hungary participated in the Holocaust, deporting nearly 440,000 Jews, mainly to Auschwitz; nearly all of them were murdered. The Horthy government's complicity in the Holocaust remains a point of controversy and contention.\nCommunism (1945\u20131989).\nFollowing the defeat of Nazi Germany, Hungary became a satellite state of the Soviet Union. The Soviet leadership selected M\u00e1ty\u00e1s R\u00e1kosi to front the Stalinisation of the country, and R\u00e1kosi \"de facto\" ruled Hungary from 1949 to 1956. His government's policies of militarisation, industrialisation, collectivisation, and war compensation led to a severe decline in living standards. In imitation of Stalin's KGB, the R\u00e1kosi government established a secret political police, the \u00c1VH, to enforce the regime; approximately 350,000 officials and intellectuals were imprisoned or executed from 1948 to 1956. Many freethinkers, democrats, and Horthy-era dignitaries were secretly arrested and extrajudicially interned in domestic and foreign gulags. Some 600,000 Hungarians were deported to Soviet labour camps, where at least 200,000 died.\nAfter Stalin's death in 1953, the Soviet Union pursued a programme of de-Stalinisation that was inimical to R\u00e1kosi, leading to his deposition. The following political cooling saw the ascent of Imre Nagy to the premiership. Nagy promised market liberalisation and political openness. R\u00e1kosi eventually managed to discredit Nagy and replace him with the more hard-line Ern\u0151 Ger\u0151. Hungary joined the Warsaw Pact in May 1955, as societal dissatisfaction with the regime swelled. Following the firing on peaceful demonstrations by Soviet soldiers and secret police, and rallies throughout the country on 23 October 1956, protesters took to the streets in Budapest, initiating the 1956 Revolution.\nIn an effort to quell the chaos, Nagy returned as premier, promised free elections, and took Hungary out of the Warsaw Pact. The violence nonetheless continued as revolutionary militias sprung up against the Soviet Army and the \u00c1VH; the roughly 3,000-strong resistance fought Soviet tanks using Molotov cocktails and machine-pistols. Though the preponderance of the Soviets was immense, they suffered heavy losses, and by 30 October 1956, most Soviet troops had withdrawn from Budapest to garrison the countryside. For a time, the Soviet leadership was unsure how to respond but eventually decided to intervene to prevent a destabilisation of the Soviet bloc. On 4 November, reinforcements of more than 150,000 troops and 2,500 tanks entered the country from the Soviet Union. Nearly 20,000 Hungarians were killed resisting the intervention, while an additional 21,600 were imprisoned afterward for political reasons. Some 13,000 were interned and 230 brought to trial and executed. Nagy was secretly tried, found guilty, sentenced to death, and executed by hanging in June 1958. Because borders were briefly opened, nearly a quarter of a million people fled the country by the time the revolution was suppressed.\nAfter a second, briefer period of Soviet military occupation, J\u00e1nos K\u00e1d\u00e1r, Nagy's former minister of state, was chosen by the Soviet leadership to head the new government and chair the new ruling Socialist Workers' Party. K\u00e1d\u00e1r quickly normalised the situation. In 1963, the government granted a general amnesty. K\u00e1d\u00e1r proclaimed a new policy line, according to which the people were no longer compelled to profess loyalty to the party if they tacitly accepted the socialist regime as a fact of life. K\u00e1d\u00e1r introduced new planning priorities in the economy, such as allowing farmers significant plots of private land within the collective farm system (\"h\u00e1zt\u00e1ji gazd\u00e1lkod\u00e1s\"). The living standard rose as consumer goods and food production took precedence over military production, which was reduced to one-tenth of prerevolutionary levels.\nIn 1968, the New Economic Mechanism introduced free-market elements into the socialist command economy. From the 1960s through the late 1980s, Hungary was often referred to as \"the happiest barrack\" within the Eastern bloc. During the latter part of the Cold War Hungary's GDP per capita was fourth only to East Germany, Czechoslovakia, and the Soviet Union. As a result of this relatively high standard of living, a more liberalised economy, a less censored press, and less restricted travel rights, Hungary was generally considered one of the more liberal countries in which to live in Central Europe during communism. In 1980, Hungary sent a Cosmonaut into space as part of the Interkosmos. The first Hungarian astronaut was Bertalan Farkas. Hungary became the seventh nation to be represented in space by him. In the 1980s, however, living standards steeply declined again because of a worldwide recession to which communism was unable to respond. By the time K\u00e1d\u00e1r died in 1989, the Soviet Union was in steep decline and a younger generation of reformists saw liberalisation as the solution to economic and social issues.\nThird Republic (1989\u2013present).\nHungary's transition from communism to capitalism (\"rendszerv\u00e1lt\u00e1s\", \"regime change\") was peaceful and prompted by economic stagnation, domestic political pressure, and changing relations with other Warsaw Pact countries. Although the Hungarian Socialist Workers' Party began Round Table Talks with various opposition groups in March 1989, the reburial of Imre Nagy as a revolutionary martyr that June is widely considered the symbolic end of communism in Hungary. Free elections were held in May 1990, and the Hungarian Democratic Forum, a major conservative opposition group, was elected to the head of a coalition government. J\u00f3zsef Antall became the first democratically elected prime minister since World War II.\nWith the removal of state subsidies and rapid privatisation in 1991, Hungary was affected by a severe economic recession. The Antall government's austerity measures proved unpopular, and the Communist Party's legal and political heir, the Socialist Party, won the subsequent 1994 elections. This abrupt shift in the political landscape was repeated in 1998 and 2002; in each electoral cycle, the governing party was ousted and the erstwhile opposition elected. Like most other post-communist European states, however, Hungary broadly pursued an integrationist agenda, joining NATO in 1999 and the European Union in 2004. As a NATO member, Hungary was involved in the Yugoslav Wars.\nIn 2006, major nationwide protests erupted after it was revealed that Prime Minister Ferenc Gyurcs\u00e1ny had claimed in a closed-door speech that his party \"lied\" to win the recent elections. The popularity of left-wing parties plummeted in the ensuing political upheaval, and in 2010, Viktor Orb\u00e1n's national-conservative Fidesz party was elected to a parliamentary supermajority. The legislature consequently approved a new constitution, among other sweeping governmental and legal changes. Fidesz has won supermajorities in every subsequent election.\nSince Orb\u00e1n's election in 2010, Hungary has undergone democratic backsliding. It has been characterised as an illiberal democracy, hybrid regime, kleptocracy, dominant-party system, and mafia state. Orb\u00e1n has publicly embraced illiberalism,9 characterising Hungary as an \"illiberal Christian democracy\". As a result of these developments, Hungary's relationship with the United States and the European Union have entered a period of protracted strain. Various EU bodies and member states have moved to penalize Hungary or curtail its EU voting rights. Past and ongoing areas of conflict include LGBT rights, migration, the \"lex CEU,\" Hungary's decision to authorise Russian and Chinese vaccines during the coronavirus pandemic, and international sanctions against Russia. The Orb\u00e1n government has simultaneously come under increased international scrutiny over rule of law concerns. Hungary has and continues to dispute these allegations.\nGeography.\nHungary is a landlocked country. Its geography has traditionally been defined by its two main waterways, the Danube and Tisza rivers. The common tripartite division\u2014\"Dun\u00e1nt\u00fal\" (\"beyond the Danube\", Transdanubia), \"Tisz\u00e1nt\u00fal\" (\"beyond the Tisza\"), and \"Duna\u2013Tisza k\u00f6ze\" (\"between the Danube and Tisza\")\u2014is a reflection of this. The Danube flows north\u2013south through the centre of contemporary Hungary, and the entire country lies within its drainage basin.\nTransdanubia, which stretches westward from the centre of the country towards Austria, is a primarily hilly region with a terrain varied by low mountains. These include the very eastern stretch of the Alps, \"Alpokalja\", in the west of the country, the Transdanubian Mountains in the central region of Transdanubia, and the Mecsek Mountains and Vill\u00e1ny Mountains in the south. The highest point of the area is the \u00cdrott-k\u0151 in the Alps, at . The Little Hungarian Plain (\"Kisalf\u00f6ld\") is found in northern Transdanubia. Lake Balaton and Lake H\u00e9v\u00edz, the largest lake in Central Europe and the largest thermal lake in the world, respectively, are in Transdanubia as well.\nThe \"Duna\u2013Tisza k\u00f6ze\" and \"Tisz\u00e1nt\u00fal\" are characterised mainly by the Great Hungarian Plain (\"Alf\u00f6ld\"), which stretches across most of the eastern and southeastern areas of the country. To the north of the plain are the foothills of the Carpathians in a wide band near the Slovakian border. The K\u00e9kes at is the tallest mountain in Hungary and is found there.\nPhytogeographically, Hungary belongs to the Central European province of the Circumboreal Region within the Boreal Kingdom. According to the WWF, the territory of Hungary belongs to the terrestrial ecoregion of Pannonian mixed forests.\nClimate.\nHungary has a temperate seasonal climate, with generally warm summers with low overall humidity levels but frequent rain showers and cold snowy winters. Average annual temperature is . Temperature extremes are on 20 July 2007 at Kiskunhalas in the summer and on 16 February 1940 at Miskolc in the winter. Average high temperature in the summer is and average low temperature in the winter is . The average yearly rainfall is approximately . \nGovernment and politics.\nHungary is a unitary, parliamentary republic. The Hungarian political system operates under a framework reformed in 2012; this constitutional document is the Fundamental Law of Hungary. Amendments generally require a two-thirds majority of parliament; the fundamental principles of the constitution (as expressed in the articles guaranteeing human dignity, the separation of powers, the state structure, and the rule of law) are valid in perpetuity. 199 Members of Parliament (') are elected to the highest organ of state authority, the unicameral ' (National Assembly), every four years in a single-round first-past-the-post election with an election threshold of 5%.\nThe President of the Republic (\") serves as the head of state and is elected by the National Assembly every five years. The president is invested primarily with representative responsibilities and powers: receiving foreign heads of state, formally nominating the prime minister at the recommendation of the National Assembly, and serving as commander-in-chief of the armed forces. Importantly, the president is also invested with veto power and may send legislation to the 15-member Constitutional Court for review. The third most significant governmental position in Hungary is the Speaker of the National Assembly, who is elected by the National Assembly and responsible for overseeing the daily sessions of the body.\nThe prime minister (\") is elected by the National Assembly, serving as the head of government and exercising executive power. Traditionally, the prime minister is the leader of the largest party in parliament. The prime minister selects Cabinet ministers and has the exclusive right to dismiss them, although cabinet nominees must appear before consultative open hearings before one or more parliamentary committees, survive a vote in the National Assembly, and be formally approved by the president. The Cabinet reports to Parliament.\nPolitical parties.\nSince the fall of communism, Hungary has a multi-party system. The last Hungarian parliamentary election took place on 3 April 2022. The result was a victory for Fidesz\u2013KDNP alliance, preserving its two-thirds majority with Orb\u00e1n remaining prime minister. It was the third election according to the new Constitution of Hungary which went into force on 1 January 2012. The new electoral law also entered into force that day. The voters elected 199 MPs instead of previous 386 lawmakers. Since 2014, voters of ethnic minorities in Hungary are able to vote on nationality lists. The minorities can obtain a preferential mandate if they reach the quarter of the ninety-third part of the list votes. Nationalities who did not get a mandate could send a nationality spokesman to the National Assembly. The current political landscape in Hungary is dominated by the conservative Fidesz, who have a near supermajority, and three medium-sized parties, the left-wing Democratic Coalition (DK), the far-right Our Homeland Movement and liberal Momentum.\nLaw and judicial system.\nThe judicial system of Hungary is a civil law system, divided between courts with regular civil and criminal jurisdiction, and administrative courts with jurisdiction over litigation between individuals and the public administration. Hungarian law is codified and based on German law and, in a wider sense, civil law or Roman law. The court system for civil and criminal jurisdiction consists of local courts ('), regional appellate courts ('), and the supreme court (\"\"). Hungary's highest courts are located in Budapest.\nLaw enforcement in Hungary is split among the police and the National Tax and Customs Administration. The Hungarian Police is the main and largest state law enforcement agency in Hungary. It carries nearly all general police duties such as criminal investigation, patrol activity, traffic policing, border control. It is led by the national police commissioner under the control of the Minister of the Interior. The body is divided into county police departments which are also divided into regional and town police departments. The National Police has subordinate agencies with nationwide jurisdiction, such as the \"Nemzeti Nyomoz\u00f3 Iroda\" (National Bureau of Investigation), a civilian police force specialised in investigating serious crimes, and the gendarmerie-like, militarised \"K\u00e9szenl\u00e9ti rend\u0151rs\u00e9g\" (Stand-by Police) mainly dealing with riots and often reinforcing local police forces. Because of Hungary's accession to the Schengen Treaty, the police and border guards were merged into a single national corps, with the border guards (\"\") becoming police officers. This merger took place in January 2008. The Customs and Excise Authority remained subject to the Ministry of Finance under the National Tax and Customs Administration.\nForeign relations.\nThe foreign policy is based on four basic commitments: to Atlantic co-operation, to European integration, to international development and to international law. Hungary has been a member of the United Nations since December 1955 and a member of the European Union, NATO, the OECD, the Visegr\u00e1d Group, the WTO, the World Bank, the AIIB and the IMF. Hungary took on the presidency of the Council of the European Union for half a year in 2011 and the next will be in 2024. In 2015, Hungary was the fifth largest OECD non-DAC donor of development aid in the world, which represents 0.13% of its Gross National Income.\nBudapest is home to more than 100 embassies and representative bodies as an international political actor. Hungary hosts the main and regional headquarters of many international organisations as well, including European Institute of Innovation and Technology, European Police College, United Nations High Commissioner for Refugees, Food and Agriculture Organization of the United Nations, International Centre for Democratic Transition, Institute of International Education, International Labour Organization, International Organization for Migration, International Red Cross, Regional Environmental Centre for Central and Eastern Europe, Danube Commission and others.\nSince 1989, the top foreign policy goal has been achieving integration into Western economic and security organisations. Hungary joined the Partnership for Peace programme in 1994 and has actively supported the IFOR and SFOR missions in Bosnia. Since 1989 Hungary has improved its often frosty neighbour relations by signing basic treaties with Romania, Slovakia, and Ukraine. These renounce all outstanding territorial claims and lay the foundation for constructive relations. However, the issue of ethnic Hungarian minority rights in Romania, Slovakia, and Serbia periodically cause bilateral tensions to flare up. However, relations with Serbia have more recently become extremely close due to strong Hungarian advocacy for Serbian EU membership, while relations with Slovakia have warmed due to cooperation on shared priorities within EU structures. Since 2017, the relations with Ukraine rapidly deteriorated over the issue of the Hungarian minority in Ukraine. Since 1989, Hungary has signed all of the OSCE documents, and served as the OSCE's Chairman-in-Office in 1997. Historically, Hungary has had particularly friendly relations with Poland; this special relationship was recognised by the parliaments of both countries in 2007 with the joint declaration of 23 March as \"The Day of Polish-Hungarian Friendship\". According to the 2024 Global Peace Index, Hungary is the 14th most peaceful country in the world.\nMilitary.\nThe president holds the title of commander-in-chief of the nation's armed forces. The Ministry of Defence jointly with chief of staff administers the armed forces, including the Hungarian Ground Force (HDF) and the Hungarian Air Force. Since 2007, the Hungarian Armed Forces has been under a unified command structure. The Ministry of Defence maintains political and civil control over the army. A subordinate Joint Forces Command coordinates and commands the HDF. In 2016, the armed forces had 31,080 personnel on active duty, the operative reserve brought the total number of troops to fifty thousand. In 2016, it was planned that military spending the following year would be $1.21\u00a0billion, about 0.94% of the country's GDP, well below the NATO target of 2%. In 2012, the government adopted a resolution in which it pledged to increase defence spending to 1.4% of GDP by 2022.\nMilitary service is voluntary, though conscription may occur in wartime. In a significant move for modernisation, Hungary decided in 2001 to buy 14 JAS 39 Gripen fighter aircraft for about 800\u00a0million EUR. Hungarian National Cyber Security Centre was re-organised in 2016 in order to become more efficient through cyber security. In 2016, the Hungarian military had about 700 troops stationed in foreign countries as part of international peacekeeping forces, including 100 HDF troops in the NATO-led ISAF force in Afghanistan, 210 Hungarian soldiers in Kosovo under command of KFOR, and 160 troops in Bosnia and Herzegovina. Hungary sent a 300-strong logistics unit to Iraq in order to help the U.S. occupation with armed transport convoys, though public opinion opposed the country's participation in the war.\nAdministrative divisions.\nHungary is divided into 19 counties ('). The capital (') Budapest is an independent entity. The counties and the capital are the 20 NUTS third-level units of Hungary. The states are further subdivided into 174 districts ('). The districts are further divided into towns and villages, of which 25 are designated towns with county rights ('), sometimes known as \"urban counties\" in English. The local authorities of these towns have extended powers, but these towns belong to the territory of the respective district instead of being independent territorial units. County and district councils and municipalities have different roles and separate responsibilities relating to local government. The role of the counties are basically administrative and focus on strategic development, while preschools, public water utilities, garbage disposal, elderly care, and rescue services are administered by the municipalities.\nSince 1996, the counties and city of Budapest have been grouped into seven regions for statistical and development purposes. These seven regions constitute NUTS' second-level units of Hungary. They are Central Hungary, Central Transdanubia, Northern Great Plain, Northern Hungary, Southern Transdanubia, Southern Great Plain, and Western Transdanubia.\nCities and towns.\nHungary has 3,152 municipalities as of 15 July 2013: 346 towns (Hungarian term: , plural: ; the terminology does not distinguish between cities and towns \u2013 the term town is used in official translations) and 2,806 villages (Hungarian: , plural: ) which fully cover the territory of the country. The number of towns can change, since villages can be elevated to town status by act of the president. Budapest has a special status and is not included in any county while 23 of the towns are so-called urban counties ( \u2013 town with county rights). All county seats except Budapest are urban counties. Four of the cities (Budapest, Miskolc, Gy\u0151r, and P\u00e9cs) have agglomerations, and the Hungarian Statistical Office distinguishes seventeen other areas in earlier stages of agglomeration development. The largest city is Budapest. There are more than 100 villages with fewer than 100 inhabitants while the smallest villages have fewer than 20 inhabitants.\nEconomy.\nHungary is an OECD high-income mixed economy with a very high human development index and skilled labour force with the 16th lowest income inequality in the world. Furthermore, it is the 9th most complex economy according to the Economic Complexity Index. The economy is the 57th-largest in the world (out of 188 countries measured by IMF) with $265.037\u00a0billion output and ranks 49th in the world in terms of GDP per capita by purchasing power parity. The employment rate was 68.3% in 2017; the employment structure shows the characteristics of post-industrial economies, 63.2% of employed workforce work in service sector, the industry contributed by 29.7%, while agriculture with 7.1%. Unemployment rate was 4.1% in 2017, down from 11% during the 2008 financial crisis.\nHungary is part of the European single market which represents more than 508\u00a0million consumers. Several domestic commercial policies are determined by agreements among European Union members and by EU legislation. Hungary is an export-oriented market economy with a heavy emphasis on foreign trade, thus the country is the 36th largest export economy in the world. The country has more than $100\u00a0billion export in 2015 with high, $9.003\u00a0billion trade surplus, of which 79% went to the EU and 21% was extra-EU trade. Hungary has a more than 80% privately owned economy with 39.1% overall taxation, which provides the basis for the country's welfare economy. On the expenditure side, household consumption is the main component of GDP and accounts for 50% of its total use, followed by gross fixed capital formation with 22% and government expenditure with 20%.\nHungary continues to be one of the leading nations for attracting foreign direct investment (FDI) in Central and Eastern Europe; the inward FDI in the country was $119.8\u00a0billion in 2015, while investing more than $50\u00a0billion abroad. As of 2015[ [update]], the key trading partners were Germany, Austria, Romania, Slovakia, France, Italy, Poland and Czech Republic. Major industries include food processing, pharmaceuticals, motor vehicles, information technology, chemicals, metallurgy, machinery, electrical goods, and tourism (with 12.1\u00a0million international tourists in 2014). Hungary is the largest electronics producer in Central and Eastern Europe. Electronics manufacturing and research are among the main drivers of innovation and economic growth in the country. In the past 20 years Hungary has also grown into a major centre for mobile technology, information security, and related hardware research.\nLarge Hungarian companies are included in the BUX, the stock market index listed on Budapest Stock Exchange. Well-known companies include the Fortune Global 500 firm MOL Group, the OTP Bank, Gedeon Richter Plc., Magyar Telekom, CIG Pannonia, FHB Bank, Zwack Unicum and more. Besides this Hungary has a large portion of specialised small and medium enterprise, for example a significant number of automotive suppliers and technology start ups among others.\nBudapest is the financial and business capital, classified as an Beta+ world city in the study by the Globalization and World Cities Research Network. Budapest is the primate city of Hungary regarding business and economy, accounting for 39% of the national income, the city has a gross metropolitan product more than $100\u00a0billion in 2015, making it one of the largest regional economies in the European Union. Budapest is also among the Top 100 GDP performing cities in the world, measured by PricewaterhouseCoopers.\nHungary maintains its own currency, the Hungarian forint (HUF), although the economy fulfills the Maastricht criteria with the exception of public debt, but it is also significantly below the EU average with the level of 75.3% in 2015. The Hungarian National Bank is currently focusing on price stability with an inflation target of 3%. Hungary's corporate tax rate is only 9%, which is relatively low for EU states.\nScience and technology.\nHungary's achievements in science and technology have been significant, and research and development efforts form an integral part of the country's economy. Hungary spent 1.61% of its gross domestic product (GDP) on civil research and development in 2020, which is the 25th highest ratio in the world. Hungary ranks 32nd among the most innovative countries in the Bloomberg Innovation Index. Hungary was ranked 36th in the Global Innovation Index in 2025. In 2014, Hungary counted 2,651 full-time equivalent researchers per million inhabitants, steadily increasing from 2,131 in 2010 and compares with 3,984 in the U.S. or 4,380 in Germany. Hungary's high technology industry has benefited from both the country's skilled workforce and the strong presence of foreign high-tech firms and research centres. Hungary also has one of the highest rates of filed patents, the sixth highest ratio of high-tech and medium high-tech output in the total industrial output, the 12th highest research FDI inflow, placed 14th in research talent in business enterprise and has the 17th best overall innovation efficiency ratio in the world.\nThe key actor of research and development in Hungary is the National Research, Development and Innovation (NRDI) Office, which is a national strategic and funding agency for scientific research, development and innovation, the primary source of advice on RDI policy for the Hungarian government and the primary RDI funding agency. Its role is to develop RDI policy and ensure that Hungary adequately invest in RDI by funding excellent research and supporting innovation to increase competitiveness and to prepare the RDI strategy of the government, to handle the NRDI Fund and represents the government and RDI community in international organisations.\nScientific research is supported partly by industry and partly by the state, through universities and by scientific state-institutions such as Hungarian Academy of Sciences. Hungary has been the home of some of the most prominent researchers in various scientific disciplines, notably physics, mathematics, chemistry and engineering. As of 2018, thirteen Hungarian scientists have been recipients of a Nobel Prize. Until 2012 three individuals\u2014Csoma, J\u00e1nos Bolyai and Tihanyi\u2014were included in the UNESCO Memory of the World register as well as the collective contributions Tabula Hungariae and Bibliotheca Corviniana. Contemporary scientists include mathematician L\u00e1szl\u00f3 Lov\u00e1sz, physicist Albert-L\u00e1szl\u00f3 Barab\u00e1si, physicist Ferenc Krausz, and biochemist \u00c1rp\u00e1d Pusztai. Hungary has excellent mathematics education which has trained numerous outstanding scientists. Famous Hungarian mathematicians include father Farkas Bolyai and son J\u00e1nos Bolyai, who was one of the founders of non-Euclidean geometry; Paul Erd\u0151s, famed for publishing in over forty languages and whose Erd\u0151s numbers are still tracked, and John von Neumann, a key contributor in the fields of quantum mechanics and game theory, a pioneer of digital computing, and the chief mathematician in the Manhattan Project. Notable Hungarian inventions include the lead dioxide match (J\u00e1nos Irinyi), a type of carburetor (Don\u00e1t B\u00e1nki, J\u00e1nos Csonka), the electric (AC) train engine and generator (K\u00e1lm\u00e1n Kand\u00f3), holography (Dennis Gabor), the Kalman filter (Rudolf E. K\u00e1lm\u00e1n), and Rubik's Cube (Ern\u0151 Rubik).\nTransport.\nHungary has a highly developed road, railway, air, and water transport system. Budapest serves as an important hub for the Hungarian railway system (\"M\u00c1V\"). The capital is served by three large train stations called \"Keleti\" (Eastern), \"Nyugati\" (Western), and \"D\u00e9li\" (Southern) \"p\u00e1lyaudvar\"s (termii). Szolnok is the most important railway hub outside Budapest, while Tiszai Railway Station in Miskolc and the main stations of Szombathely, Gy\u0151r, Szeged, and Sz\u00e9kesfeh\u00e9rv\u00e1r are also key to the network.\nFrom March 2024, transport on the Hungarian railway \"M\u00c1V\" will be free for people aged 65 and over and under 14 years of age.\nBudapest, Debrecen, Miskolc, and Szeged have tram networks. The Budapest Metro is the second-oldest underground metro system in the world; its Line 1 dates from 1896. The system consists of four lines. A commuter rail system, \"H\u00c9V\", operates in the Budapest metropolitan area.\nHungary has a total length of approximately motorways (). Motorway sections are being added to the existing network, which already connects many major economically important cities to the capital. Ports are located at Budapest, Duna\u00fajv\u00e1ros and Baja.\nThere are five international airports: Budapest Ferenc Liszt (informally called \"Ferihegy\"), Debrecen, H\u00e9v\u00edz\u2013Balaton (also called S\u00e1rmell\u00e9k Airport), Gy\u0151r-P\u00e9r, and P\u00e9cs-Pog\u00e1ny, but only two of these (Budapest and Debrecen) receive scheduled flights. Low-budget airline Wizz Air is based at Ferihegy.\nEnergy.\nHungary's total energy supply is dominated by fossil fuels, with natural gas occupying the largest share, followed by oil and coal. In June 2020, Hungary passed a law binding itself to a target of net-zero emissions by 2050. As part of a broader restructuring of the nation's energy and climate policies, Hungary also extended its National Energy Strategy 2030 to look even further, adding an outlook until 2040 that prioritises carbon-neutral and cost-effective energy while focusing on reinforcing energy security and energy independence. Key forces in the country's 2050 target include renewables, nuclear electricity, and electrification of end-use sectors. Significant investments in the power sector are expected, including for the construction of two new nuclear energy generating units. Renewable energy capacity has increased significantly, but in recent years growth in the renewables sector has stagnated. What is more, certain policies that limit development of wind power are expected to negatively impact the renewables sector.\nHungary's emission of greenhouse gases has dropped alongside the economy's decreasing use of carbon-based fuels. However, independent analysis has identified space for Hungary to set more ambitious emissions reduction targets.\nDemographics.\nHungary's population was 9,689,000 in 2021, according to the Hungarian Central Statistical Office, making it the fifth most populous country in Central and Eastern Europe, and a medium-sized member state of the European Union. As in other former Eastern bloc countries, its population has decreased markedly since the fall of communism, having peaked at 10.8 million in 1980. Population density stands at 107 inhabitants per square kilometre, which is about two times higher than the world average. Around 70% of the population lives in cities and towns overall, which is well above the global rate of 56% but lower than most developed countries; one quarter of Hungarians live in the Budapest metropolitan area in north-central region.\nLike most European countries, Hungary is experiencing sub-replacement fertility; its estimated total fertility rate of 1.43 children per woman is well below the replacement rate of 2.1. Consequently, its population has been gradually declining and rapidly aging; the average age is 42.7 years, among the highest in the world. This trend has been exacerbated by a high rate of emigration, particularly among young adults, and anti-immigration policies, which accelerated in the 1990s but have since somewhat abated.\nIn 2011, the conservative government began a programme to increase the birth rate among ethnic Magyars by reinstating three-year maternity leave and boosting the availability of part-time jobs; the fertility rate has since gradually increased from its nadir of 1.27 children per woman in 2011, in some years rising as high as 1.5. In 2015, 47.9% of births were to unmarried women. Life expectancy was 71.96 years for men and 79.62 years for women in 2015, growing continuously since the fall of Communism.\nHungary recognises two sizeable minority groups, designated as \"national minorities\" because their ancestors have lived in their respective regions for centuries in Hungary: a German community of about 130,000 that lives throughout the country, and a Romani minority that numbers around 300,000 and mainly resides in the northern part of the country. Some studies indicate a considerably larger number of Romani in Hungary (876,000 people \u2013 c. 9% of the population.). According to the 2011 census, there were 8,314,029 (83.7%) ethnic Hungarians, 308,957 (3.1%) Romani, 131,951 (1.3%) Germans, 29,647 (0.3%) Slovaks, 26,345 (0.3%) Romanians, and 23,561 (0.2%) Croats in Hungary; 1,455,883 people (14.7% of the total population) did not declare their ethnicity. Thus, Hungarians made up more than 90% of people who declared their ethnicity. In Hungary, people can declare more than one ethnicity, so the sum of ethnicities is higher than the total population.\nApproximately 5\u00a0million Hungarians live outside Hungary.\n&lt;templatestyles src=\"Template:Largest_cities/styles.css\" /&gt;\nLanguages.\nHungarian is the official and predominant spoken language. Hungarian is the 13th most widely spoken first language in Europe with around 13\u00a0million native speakers and it is one of 24 official and working languages of the European Union. Outside Hungary, it is also spoken in neighbouring countries and by Hungarian diaspora communities worldwide. According to the 2011 census, 9,896,333 people (99.6%) speak Hungarian in Hungary, of whom 9,827,875 people (99%) speak it as a first language, while 68,458 people (0.7%) speak it as a second language. English (1,589,180 speakers, 16.0%), and German (1,111,997 speakers, 11.2%) are the most widely spoken foreign languages, while there are several recognised minority languages in Hungary (Armenian, Bulgarian, Croatian, German, Greek, Romanian, Romani, Rusyn, Serbian, Slovak, Slovenian, and Ukrainian).\nHungarian is a member of the Uralic language family, unrelated to any neighbouring language and distantly related to Finnish and Estonian. It is the largest of the Uralic languages in terms of the number of speakers and the only one spoken in Central Europe. Standard Hungarian is based on the variety spoken in Budapest. Although the use of the standard dialect is enforced, Hungarian has several urban and rural dialects.\nReligion.\nHungary is a historically Christian country. Hungarian historiography identifies the foundation of the Hungarian state with Stephen I's baptism and coronation with the Holy Crown in A.D. 1000. Stephen promulgated Catholicism as the state religion, and his successors were traditionally known as the Apostolic Kings. The Catholic Church in Hungary remained strong through the centuries, and the Archbishop of Esztergom was granted extraordinary temporal privileges as prince-primate (\"hercegpr\u00edm\u00e1s\") of Hungary. The transition to statehood occurred at the turn of the 1st to 2nd millennium when the federation of Magyar tribes was transformed into the Kingdom of Hungary, and Western Christianity, specifically Roman Catholicism, was adopted as state religion.\nContemporary Hungary has no official religion and recognises freedom of religion as a fundamental right. However, the constitution \"recognises Christianity's nation-building role\" in its preamble and in Article VII affirms that \"the state may cooperate with the churches for community goals.\" The 2022 census showed that 42.5% of the Hungarians were Christians, most of whom were Roman Catholics (\"r\u00f3mai katolikusok\") (27.5%) and Hungarian Reformed Calvinists (\"reform\u00e1tusok\") (9.8%), alongside Lutherans (\"evang\u00e9likusok\") (1.8%), Greek Catholics (1.7%), and other Christians (1.7%). Jewish (0.1%), Buddhist (0.1%) and Islamic (0.1%) communities are small minorities. 40.1% of the population did not declare a religious affiliation, while 16.1% declared themselves explicitly irreligious.\nDuring the initial stages of the Protestant Reformation, most Hungarians adopted first Lutheranism and then Calvinism in the form of the Hungarian Reformed Church. Key figures in the Calvinist movement included M\u00e1rton K\u00e1lm\u00e1ncsehi (1500\u20131550) and P\u00e9ter Melius Juh\u00e1sz (1532\u20131572). Melius Juh\u00e1sz played a pivotal role in translating the Bible and other religious texts into Hungarian, and he established Debrecen in the Great Plain as the heart of Hungarian Calvinism, earning it the titles \"Hungarian Geneva\" or \"the Calvinist Rome.\" In the second half of the 16th century, the Jesuits led a Counter-Reformation campaign, and the population once again became predominantly Catholic. This campaign was only partially successful, however, and the (mainly Reformed) Hungarian nobility were able to secure freedom of worship for Protestants. In practice, this meant \"cuius regio, eius religio\"; thus, most individual localities in Hungary are still identifiable as historically Catholic, Lutheran, or Reformed. The country's eastern regions, especially around Debrecen, remain almost completely Reformed, a trait they share with historically contiguous ethnically Hungarian regions across the Romanian border. Orthodox Christianity in Hungary is associated with the country's ethnic minorities: Armenians, Bulgarians, Greeks, Romanians, Rusyns, Ukrainians, and Serbs.\nHistorically, Hungary was home to a significant Jewish community, with a pre-World War II population of more than 800,000; however, it is estimated that just over 564,000 Hungarian Jews were killed between 1941 and 1945 during the Holocaust in Hungary. Between 15 May and 9 July 1944 alone, over 434,000 Jews were deported. Of over 800,000 Jews living within Hungary's borders in 1941\u20131944, about 255,500 are thought to have survived. There are about 120,000 Jews in Hungary today.\nEducation.\nEducation is predominantly public, run by the Ministry of Education. Preschool-kindergarten education is compulsory and provided for all children between three and six years old, after which school attendance is also compulsory until the age of sixteen. Primary education usually lasts for eight years. Secondary education includes three traditional types of schools focused on different academic levels: the Gymnasium enrolls the most gifted children and prepares students for university studies; the secondary vocational schools for intermediate students lasts four years and the technical school prepares pupils for vocational education and work. The system is partly flexible and bridges exist. The Trends in International Mathematics and Science Study rated 13\u201314-year-old pupils in Hungary among the best in the world for maths and science.\nMost of the universities are public institutions, and students traditionally study without fees. The general requirement for university is the Matura. The Hungarian public higher education system includes universities and other higher education institutes that provide both education curricula and related degrees up to doctoral degree and also contribute to research activities. Health insurance for students is free until the end of their studies. English and German language are important in Hungarian higher education; there are a number of degree programmes that are taught in these languages, which attracts thousands of exchange students every year. Hungary's higher education and training has been ranked 44 out of 148 countries in the Global Competitiveness Report 2014.\nHungary has a long tradition of higher education and an established knowledge economy. Several universities are among the oldest in continuous operation in the world, including the University of P\u00e9cs (founded 1367), \u00d3buda University (1395), and Universitas Istropolitana (1465). Nagyszombat University was founded in 1635 and moved to Buda in 1777, and it is called E\u00f6tv\u00f6s Lor\u00e1nd University today. The world's first institute of technology was founded in Selmecb\u00e1nya in 1735; its legal successor is the University of Miskolc. The Budapest University of Technology and Economics is considered the oldest institute of technology in the world with university rank and structure, its legal predecessor the Institutum Geometrico-Hydrotechnicum was founded in 1782 by Emperor Joseph II.\nHungary ranks fourth (above neighbour Romania, and after China, the United States and Russia) in the all-time medal count at the International Mathematical Olympiad with 336 total medals, dating back to 1959.\nHealth.\nHungary maintains a universal health care system largely financed by government national health insurance. According to the OECD, 100% of the population is covered by universal health insurance, which is free for children, students, pensioners, people with low income, handicapped people, and church employees. Hungary spends 7.2% of GDP on healthcare, spending $2,045 per capita, of which $1,365 is provided by the government.\nHungary is one of the main destinations of medical tourism in Europe, particularly for dentistry, in which its share is 42% in Europe and 21% worldwide. Plastic surgery is also a key sector, with 30% of the clients coming from abroad. Hungary is well known for its spa culture and is home to numerous medicinal spas, which attract \"spa tourism\".\nIn common with developed countries, cardiovascular disease is a leading cause of mortality, accounting for 49.4% (62,979) of all deaths in 2013. However, this number peaked in 1985 with 79,355 deaths, and has been declining continuously since the fall of communism. The second leading cause of death is cancer with 33,274 (26.2%), which has been stagnant since the 1990s. Deaths from accidents dropped from 8,760 in 1990 to 3,654 in 2013; the number of suicides has declined greatly from 4,911 in 1983 to 2,093 in 2013 (21.1 per 100,000 people), the lowest since 1956. There are considerable health disparities between the western and eastern parts of Hungary; heart disease, hypertension, stroke, and suicide is prevalent in the mostly agricultural and low-income Great Plain region in the east, but infrequent in the high-income, middle class areas of Western Transdanubia and Central Hungary. Smoking is a leading cause of death, although it is in steep decline: The proportion of adult smokers declined to 19% in 2013 from 28% in 2012, owing to strict regulations such as a nationwide smoking ban in every indoor public place and the limiting of tobacco sales to state-controlled \"National Tobacco Shops\".\nCulture.\nArchitecture.\nHungary is home to the largest synagogue in Europe, built in 1859 in Moorish Revival style with a capacity of 3,000 people; the largest medicinal bath in Europe, completed in 1913 in Modern Renaissance style and located in the Budapest city park; one of the largest basilicas in Europe; the second-largest territorial abbey in the world; and the largest early Christian necropolis outside Italy. Notable architectural styles include Historicism and variants of Art Nouveau. In contrast to Historicism, Hungarian Art Nouveau is based on national architectural characteristics. Taking the eastern origins of the Hungarians into account, \u00d6d\u00f6n Lechner, the most important figure in Hungarian Art Nouveau, was initially inspired by Asian architecture and later by traditional Hungarian decorative designs. In this way, he created an original synthesis of architectural styles. By applying them to three-dimensional architectural elements, he produced a version of Art Nouveau that was specific to Hungary. Turning away from the style of Lechner, yet taking inspiration from his approach, the group of \"Young People\" (\"Fiatalok\"), which included K\u00e1roly K\u00f3s and Dezs\u00f6 Zrumeczky, used the characteristic structures and forms of traditional Hungarian architecture to achieve the same end.\nBesides the two principal styles, Budapest also displays local versions of trends originating from other European countries. The \"Sezession\" from Vienna, the German \"Jugendstil\", \"Art Nouveau\" from Belgium and France, and the influence of English and Finnish architecture are all reflected in the buildings constructed at the turn of the 20th century. B\u00e9la Lajta initially adopted Lechner's style, subsequently drawing his inspiration from English and Finnish trends; after developing an interest in the Egyptian style, he finally arrived at modern architecture. Alad\u00e1r \u00c1rkay took almost the same route. Istv\u00e1n Medgyaszay developed his own style, which differed from Lechner's, using stylised traditional motifs to create decorative designs in concrete. In the sphere of applied arts, those chiefly responsible for promoting the spread of Art Nouveau were the School and Museum of Decorative Arts, which opened in 1896.\nIn the Budapest downtown area almost all the buildings are about one hundred years old, with thick walls, high ceilings, and motifs on the front walls.\nMusic.\nHungarian music consists mainly of traditional Hungarian folk music and music by prominent composers such as Franz Liszt and B\u00e9la Bart\u00f3k, considered to be among the greatest Hungarian composers. Other renowned composers are Ernst von Dohn\u00e1nyi, Franz Schmidt, Zolt\u00e1n Kod\u00e1ly, Gabriel von Wayditch, Rudolf Wagner-R\u00e9geny, L\u00e1szl\u00f3 Lajtha, Franz Leh\u00e1r, Imre K\u00e1lm\u00e1n, S\u00e1ndor Veress and Mikl\u00f3s R\u00f3zsa. Hungarian traditional music tends to have a strong dactylic rhythm, as the language is invariably stressed on the first syllable of each word.\nHungary has renowned composers of contemporary classical music, Gy\u00f6rgy Ligeti, Gy\u00f6rgy Kurt\u00e1g, P\u00e9ter E\u00f6tv\u00f6s, Zolt\u00e1n Kod\u00e1ly and Zolt\u00e1n Jeney among them. Bart\u00f3k was among the most significant musicians of the 20th century. His music was invigorated by the themes, modes, and rhythmic patterns of the Hungarian and neighbouring folk music traditions he studied, which he synthesised with influences from his contemporaries into his own distinctive style.\nFolk music is a prominent part of the national identity and has been significant in former country parts that belong\u2014since the 1920 Treaty of Trianon\u2014to neighbouring countries such as Romania, Slovakia, Poland and especially in southern Slovakia and Transylvania. After the establishment of a music academy led by Liszt and Ferenc Erkel, \nBroughton claims that Hungary's \"infectious sound has been surprisingly influential on neighboring countries (thanks perhaps to the common Austro-Hungarian history) and it's not uncommon to hear Hungarian-sounding tunes in Romania, Slovakia and Poland\". It is also strong in the Szabolcs-Szatm\u00e1r area and in the southwest part of Transdanubia, near the border with Croatia. The Bus\u00f3j\u00e1r\u00e1s carnival in Moh\u00e1cs is a major Hungarian folk music event, formerly featuring the long-established and well-regarded Bogyiszl\u00f3 Orchestra.\nHungarian classical music has long been an \"experiment, made from Hungarian antecedents and on Hungarian soil, to create a conscious musical culture [using the] musical world of the folk song\". Although the Hungarian upper class has long had cultural and political connections with the rest of Europe, leading to an influx of European musical ideas, the rural peasants maintained their own traditions such that by the end of the 19th-century Hungarian composers could draw on rural peasant music to (re)create a Hungarian classical style. For example, Bart\u00f3k collected folk songs from across Central and Eastern Europe, including Romania and Slovakia, while Kod\u00e1ly was more interested in creating a distinctively Hungarian musical style.\nDuring the era of communist rule in Hungary, a Song Committee scoured and censored popular music for traces of subversion and ideological impurity. Since then, however, the Hungarian music industry has begun to recover, producing successful performers in the fields of jazz such as trumpeter Rudolf Tomsits, pianist-composer K\u00e1roly Binder and, in a modernised form of Hungarian folk, Ferenc Seb\u0151 and M\u00e1rta Sebesty\u00e9n. The three giants of Hungarian rock, Ill\u00e9s, Metr\u00f3 and Omega, remain very popular, especially Omega, which has followings in Germany and beyond as well as in Hungary. Older veteran underground bands such as Beatrice, from the 1980s, also remain popular.\nCuisine.\n \nTraditional dishes such as the world-famous goulash (\"guly\u00e1s\" stew or \"guly\u00e1s\" soup) feature prominently in Hungarian cuisine. Dishes are often flavoured with paprika (ground red peppers), a Hungarian innovation. The paprika powder, obtained from a special type of pepper, is one of the most common spices used in typical Hungarian cuisine. Thick, heavy sour cream called \"tejf\u00f6l\" is often used to soften the flavour of a dish. The famous Hungarian hot river fish soup called fisherman's soup or \"hal\u00e1szl\u00e9\" is usually a rich mixture of several kinds of poached fish.\nOther dishes are chicken paprikash, foie gras made of goose liver, \"p\u00f6rk\u00f6lt\" stew, \"vadas\", (game stew with vegetable gravy and dumplings), trout with almonds and salty and sweet dumplings, like \"t\u00far\u00f3s csusza\", (dumplings with fresh quark cheese and thick sour cream). Desserts include the iconic Dobos torte, strudels (\"r\u00e9tes\"), filled with apple, cherry, poppy seed or cheese, Gundel pancake, plum dumplings (\"szilv\u00e1s gomb\u00f3c\"), \"soml\u00f3i\" dumplings, dessert soups like chilled sour cherry soup and sweet chestnut puree, \"gesztenyep\u00fcr\u00e9\" (cooked chestnuts mashed with sugar and rum and split into crumbs, topped with whipped cream). \"Perec\" and \"kifli\" are widely popular pastries.\nThe \"cs\u00e1rda\" is the most distinctive type of Hungarian inn, an old-style tavern offering traditional cuisine and beverages. \"Boroz\u00f3\" usually denotes a cosy old-fashioned wine tavern, \"pince\" is a beer or wine cellar and a \"s\u00f6r\u00f6z\u0151\" is a pub offering draught beer and sometimes meals. The \"bisztr\u00f3\" is an inexpensive restaurant often with self-service. The \"b\u00fcf\u00e9\" is the cheapest place, although one may have to eat standing at a counter. Pastries, cakes and coffee are served at the confectionery called \"cukr\u00e1szda\", while an \"eszpressz\u00f3\" is a caf\u00e9.\nP\u00e1linka is a fruit brandy, distilled from fruit grown in the orchards situated on the Great Hungarian Plain. It is a spirit native to Hungary and comes in a variety of flavours including apricot (\"barack\") and cherry (\"cseresznye\"). However, plum (\"szilva\") is the most popular flavour. Beer goes well with many traditional Hungarian dishes. The five main Hungarian beer brands are: Borsodi, Soproni, Arany \u00c1szok, K\u00f5b\u00e1nyai, and Dreher. People traditionally do not clink their glasses or mugs when drinking beer. There is an urban legend in Hungarian culture that Austrian generals clinked their beer glasses to celebrate the execution of the 13 Martyrs of Arad in 1849. Many people still follow the tradition, although younger people often disavow it, citing that the vow was only meant to last 150 years.\nHungary is ideal for wine-making, and the country can be divided into numerous regions. The Romans brought vines to Pannonia, and by the 5th century AD, there are records of extensive vineyards in what is now Hungary. The Hungarians brought their wine-making knowledge from the East. According to Ibn Rustah, the Hungarian tribes were familiar with wine-making long before their conquest of the Carpathian Basin. The different wine regions offer a great variety of styles: the main products of the country are elegant and full-bodied dry whites with good acidity, although complex sweet whites (Tokaj), elegant (Eger) and full-bodied robust reds (Vill\u00e1ny and Szeksz\u00e1rd). The main varieties are: Olaszrizling, H\u00e1rslevel\u0171, Furmint, Pinot gris or Sz\u00fcrkebar\u00e1t, Chardonnay (whites), K\u00e9kfrankos (or Blaufrankisch in German), Kadarka, Portugieser, Zweigelt, Cabernet Sauvignon, Cabernet Franc and Merlot. The most famous wines from Hungary are Tokaji Asz\u00fa and Egri Bikav\u00e9r. Tokaji wine has received accolades from numerous great writers and composers.\nFor over 150 years, a blend of forty Hungarian herbs has been used to create the liqueur unicum, a bitter, dark-coloured liqueur that can be drunk as an ap\u00e9ritif or after a meal.\nSport.\nHungarian athletes have been successful contenders in the Summer Olympic Games. Hungary ranks 9th with a total of 511 medals in the all-time Summer Olympic Games medal count. Hungary has the third-highest number of Olympic medals per capita and second-highest number of gold medals per capita in the world. Hungary has historically excelled in Olympic water sports. In water polo the men's Hungarian team is the leading medal winner by a significant margin, and in swimming the men's and the women's teams are both rank fifth-most successful. Hungary leads the overall medal count in canoeing and kayaking. Hungary won its first gold medal in Winter Olympics in 2018 in men's short track speed skating with a team of four: Csaba Burj\u00e1n, Shaolin S\u00e1ndor Liu, Shaoang Liu, and Viktor Knoch.\nHungary hosted many global sports events, including the 1997 World Amateur Boxing Championships, 2000 World Fencing Championships, 2001 World Allround Speed Skating Championships, 2008 World Interuniversity Games, 2008 World Modern Pentathlon Championships, 2010 ITU World Championship Series, 2011 IIHF World Championship, 2013 World Fencing Championships, 2013 World Wrestling Championships, 2014 World Masters Athletics Championships, 2017 World Aquatics Championships and 2017 World Judo Championships, only in the last two decade. Besides these, Hungary was the home of many European-level tournaments, like 2006 European Aquatics Championships, 2010 European Aquatics Championships, 2013 European Judo Championships, 2013 European Karate Championships, 2017 European Rhythmic Gymnastics Championship and hosted 4 matches in the UEFA Euro 2020, which were held in the 67,889-seat new multi-purpose Pusk\u00e1s Ferenc Stadium.\nHungary has won three Olympic football titles. Hungary revolutionised the sport in the 1950s, laying the tactical fundamentals of total football and dominating international football with the \"Aranycsapat\" (\"Golden Team\"), which included Ferenc Pusk\u00e1s, top goal scorer of the 20th century, to whom FIFA dedicated its newest award, the Pusk\u00e1s Award. The team of that era has the second all-time highest Football Elo Rating in the world, with 2166, and one of the longest undefeated runs in football history, remaining unbeaten in 31 games spanning more than four years. The post-golden age decades saw a gradually weakening Hungary, though recently there is renewal in all aspects. The Hungarian Children's Football Federation was founded in 2008, as youth development thrives. They hosted the 2010 UEFA Futsal Championship in Budapest and Debrecen, the first time the MLSZ staged a UEFA finals tournament.\nThe Hungarian Grand Prix in Formula One has been held at the Hungaroring just outside Budapest, which circuit has FIA Grade 1 licence. Since 1986, the race has been a round of the Formula One World Championship. The track was completely resurfaced for the first time in early 2016, and it was announced the Grand Prix's deal was extended for a further five years, until 2026.\nChess is a popular and successful sport, and the Hungarian players are the eighth most powerful overall on the ranking of World Chess Federation. There are about 54 Grandmasters and 118 International Masters, which is more than in France or United Kingdom. Judit Polg\u00e1r generally considered the strongest female chess player of all time. Some of the world's best sabre athletes have historically also hailed from Hungary, and in 2009, the Hungary men's national ice hockey team qualified for their first IIHF World Championship, in 2015, they qualified for their second world championship in the top division.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nExternal links.\nGovernment\nGeneral information"}
{"id": "13276", "revid": "382591", "url": "https://en.wikipedia.org/wiki?curid=13276", "title": "Historiography", "text": "Study of the methods used by historians\nHistoriography is the study of the methods used by historians in developing history as an academic discipline. By extension, the term \"historiography\" is any body of historical work on a particular subject. The historiography of a specific topic covers how historians have studied that topic by using particular sources, techniques of research, and theoretical approaches to the interpretation of documentary sources. Scholars discuss historiography by topic\u2014such as the historiography of the United Kingdom, of WWII, of the pre-Columbian Americas, of early Islam, and of China\u2014and different approaches to the work and the genres of history, such as political history and social history. Beginning in the nineteenth century, the development of academic history produced a great corpus of historiographic literature. The extent to which historians are influenced by their own groups and loyalties\u2014such as to their nation state\u2014remains a debated question.\nIn Europe, the academic discipline of historiography was established in the 5th century BC with the \"Histories\", by Herodotus, who thus established Greek historiography. In the 2nd century BC, the Roman statesman Cato the Elder produced the \"Origines\", which is the first Roman historiography. In Asia, the father and son intellectuals Sima Tan and Sima Qian established Chinese historiography with the book \"Shiji\" (\"Records of the Grand Historian\"), in the time of the Han Empire in Ancient China. During the Middle Ages, medieval historiography included the works of chronicles in medieval Europe, the Ethiopian Empire in the Horn of Africa, Islamic histories by Muslim historians, and the Korean and Japanese historical writings based on the existing Chinese model. During the 18th-century Age of Enlightenment, historiography in the Western world was shaped and developed by figures such as Voltaire, David Hume, and Edward Gibbon, who among others set the foundations for the modern discipline. In the 19th century, historical studies became professionalized at universities and research centers along with a belief that history was like a science. In the 20th century, historians incorporated social science dimensions like politics, economy, and culture in their historiography.\nThe research interests of historians change over time, and there has been a shift away from traditional diplomatic, economic, and political history toward newer approaches, especially social and cultural studies. From 1975 to 1995 the proportion of professors of history in American universities identifying with social history increased from 31 to 41 percent, while the proportion of political historians decreased from 40 to 30 percent. In 2007, of 5,723 faculty members in the departments of history at British universities, 1,644 (29 percent) identified themselves with social history and 1,425 (25 percent) identified themselves with political history. Since the 1980s there has been a special interest in the memories and commemoration of past events\u2014the histories as remembered and presented for popular celebration.\nTerminology.\nIn the early modern period, the term \"historiography\" meant \"the writing of history\", and \"historiographer\" meant \"historian\". In that sense certain official historians were given the title \"Historiographer Royal\" in Sweden (from 1618), England (from 1660), and Scotland (from 1681). The Scottish post is still in existence.\nHistoriography was more recently defined as \"the study of the way history has been and is written\u2014the history of historical writing\", which means that, \"When you study 'historiography' you do not study the events of the past directly, but the changing interpretations of those events in the works of individual historians.\"\nHistory.\nAntiquity.\nUnderstanding the past appears to be a universal human need, and the \"telling of history\" has emerged independently in civilizations around the world. \nWhat constitutes history is a philosophical question (see philosophy of history). The earliest chronologies date back to ancient Egypt and Sumerian/Akkadian Mesopotamia, in the form of chronicles and annals. However, most historical writers in these early civilizations were not known by name, and their works usually did not contain narrative structures or detailed analysis. By contrast, the term \"historiography\" is taken to refer to written history recorded in a narrative format for the purpose of informing future generations about events. In this limited sense, \"ancient history\" begins with the written history of early historiography in Classical Antiquity, established in 5th century BC Classical Greece.\nEurope.\nGreece.\nThe earliest known systematic historical thought and methodologies emerged in ancient Greece and the wider Greek world, a development which would be an important influence on the writing of history elsewhere around the Mediterranean region. The tradition of logography in Archaic Greece preceded the full narrative form of historiography, in which logographers such as Hecataeus of Miletus provided prose compilations about places in geography and peoples in an early form of cultural anthropology, as well as speeches used in courts of law. The earliest known fully narrative critical historical works were \"The Histories\", composed by Herodotus of Halicarnassus (484\u2013425\u00a0BC) who became known as the \"father of history\". Herodotus attempted to distinguish between more and less reliable accounts, and personally conducted research by travelling extensively, giving written accounts of various Mediterranean cultures. Although Herodotus' overall emphasis lay on the actions and characters of men, he also attributed an important role to divinity in the determination of historical events.\nThe generation following Herodotus witnessed a spate of local histories of the individual city-states (\"poleis\"), written by the first of the local historians who employed the written archives of city and sanctuary. Dionysius of Halicarnassus characterized these historians as the forerunners of Thucydides, and these local histories continued to be written into Late Antiquity, as long as the city-states survived. Two early figures stand out: Hippias of Elis, who produced the lists of winners in the Olympic Games that provided the basic chronological framework as long as the pagan classical tradition lasted, and Hellanicus of Lesbos, who compiled more than two dozen histories from civic records, all of them now lost.\nThucydides largely eliminated divine causality in his account of the war between Athens and Sparta, establishing a rationalistic element which set a precedent for subsequent Western historical writings. He was also the first to distinguish between cause and immediate origins of an event, while his successor Xenophon (c.\u2009431\u00a0\u2013 355\u00a0BC) introduced autobiographical elements and biographical character studies in his \"Anabasis\".\nThe proverbial Philippic attacks of the Athenian orator Demosthenes (384\u2013322\u00a0BC) on Philip\u00a0II of Macedon marked the height of ancient political agitation. The now lost history of Alexander's campaigns by the diadoch Ptolemy\u00a0I (367\u2013283\u00a0BC) may represent the first historical work composed by a ruler. Polybius (c.\u2009203\u00a0\u2013 120\u00a0BC) wrote on the rise of the Roman Republic to world prominence, and attempted to harmonize the Greek and Roman points of view. Diodorus Siculus composed a universal history, the \"Bibliotheca historica\", that sought to explain various known civilizations from their origins up until his own day in the 1st century BC.\nBerossus, a Chaldean priest (fl.\u20093rd century\u00a0BC) composed a Greek-language \"History of Babylonia\" for the Seleucid king Antiochus\u00a0I, combining Hellenistic methods of historiography and Mesopotamian accounts to form a unique composite. Reports exist of other near-eastern histories, such as that of the Phoenician historian Sanchuniathon; but he is considered semi-legendary and writings attributed to him are fragmentary, known only through the later historians Philo of Byblos and Eusebius, who asserted that he wrote before even the Trojan War. The native Egyptian priest and historian Manetho composed a history of Egypt in Greek for the Ptolemaic royal court during the 3rd century BC.\nRome.\nThe Romans adopted the Greek tradition, writing at first in Greek, but eventually chronicling their history in a freshly non-Greek language. Early Roman works were still written in Greek, such as the annals of Quintus Fabius Pictor. However, the \"Origines\", composed by the Roman statesman Cato the Elder (234\u2013149\u00a0BC), was written in Latin, in a conscious effort to counteract Greek cultural influence. It marked the beginning of Latin historical writings. Hailed for its lucid style, Julius Caesar's (103\u201344\u00a0BC) \"de Bello Gallico\" exemplifies autobiographical war coverage. The politician and orator Cicero (106\u201343\u00a0BC) introduced rhetorical elements in his political writings.\nStrabo (63\u00a0BC\u00a0\u2013 c.\u200924\u00a0AD) was an important exponent of the Greco-Roman tradition of combining geography with history, presenting a descriptive history of peoples and places known to his era. The Roman historian Sallust (86\u201335\u00a0BC) sought to analyze and document what he viewed as the decline of the Republican Roman state and its virtues, highlighted in his respective narrative accounts of the Catilinarian conspiracy and the Jugurthine War. Livy (59\u00a0BC\u00a0\u2013 17\u00a0AD) records the rise of Rome from city-state to empire. His speculation about what would have happened if Alexander the Great had marched against Rome represents the first known instance of alternate history.\nBiography, although popular throughout antiquity, was introduced as a branch of history by the works of Plutarch (c.\u200945\u00a0\u2013 125\u00a0AD) and Suetonius (c.\u200969\u00a0\u2013 after 130\u00a0AD) who described the deeds and characters of ancient personalities, stressing their human side. Tacitus (c.\u200956\u00a0\u2013 c.\u2009117\u00a0AD) denounces Roman immorality by praising German virtues, elaborating on the topos of the Noble savage. Tacitus' focus on personal character can also be viewed as pioneering work in psychohistory. Although rooted in Greek historiography, in some ways Roman historiography shared traits with Chinese historiography, lacking speculative theories and instead relying on annalistic forms, revering ancestors, and imparting moral lessons for their audiences, laying the groundwork for medieval Christian historiography.\nBiblical.\nBiblical historiography is the study of the writing of history in the context of the Hebrew Bible, and covers from the 12th century BC to the mid-4th century BC with a revival during the Hasmonean period in the second century BC. It encompasses two main trends: a quasi-secular approach focusing on political history, and a kerygmatic approach emphasizing divine action and moral lessons.\nEast Asia.\nChina.\nThe Han dynasty eunuch Sima Qian (145\u201386\u00a0BC) was the first in China to lay the groundwork for professional historical writing. His work superseded the older style of the \"Spring and Autumn Annals\", compiled in the 5th century BC, the \"Bamboo Annals\", the \"Classic of History\", and other court and dynastic annals that recorded history in a chronological form that abstained from analysis and focused on moralistic teaching. In 281\u00a0AD the tomb of King Xiang of Wei (d.\u2009296\u00a0BC) was opened, inside of which was found a historical text called the \"Bamboo Annals\", after the writing material. It is similar in style to the \"Spring and Autumn Annals\" and covers events from the mythical Yellow Emperor to 299\u00a0BC. Opinions on the authenticity of the text has varied throughout the centuries, and it was rediscovered too late to gain the same status as the \"Spring and Autumn Annals\".\nSima's \"Shiji\" (\"Records of the Grand Historian\"), initiated by his father the court astronomer Sima Tan (165\u2013110\u00a0BC), pioneered the \"Annals-biography\" format, which would become the standard for prestige history writing in China. In this genre a history opens with a chronological outline of court affairs, and then continues with detailed biographies of prominent people who lived during the period in question. The scope of his work extended as far back as the 16th century\u00a0BC with the founding of the Shang dynasty. It included many treatises on specific subjects and individual biographies of prominent people. He also explored the lives and deeds of commoners, both contemporary and those of previous eras.\nWhereas Sima's had been a universal history from the beginning of time down to the time of writing, his successor Ban Gu wrote an annals-biography history limiting its coverage to only the Western Han dynasty, the \"Book of Han\" (96\u00a0AD). This established the notion of using dynastic boundaries as start- and end-points, and most later Chinese histories would focus on a single dynasty or group of dynasties.\nThe Records of the Grand Historian and Book of Han were eventually joined by the \"Book of the Later Han\" (AD 488) (replacing the earlier, and now only partially extant, Han Records from the Eastern Pavilion) and the \"Records of the Three Kingdoms\" (AD 297) to form the \"Four Histories\". These became mandatory reading for the Imperial Examinations and have therefore exerted an influence on Chinese culture comparable to the Confucian Classics. More annals-biography histories were written in subsequent dynasties, eventually bringing the number to between twenty-four and twenty-six, but none ever reached the popularity and impact of the first four.\nTraditional Chinese historiography describes history in terms of dynastic cycles. In this view, each new dynasty is founded by a morally righteous founder. Over time, the dynasty becomes morally corrupt and dissolute. Eventually, the dynasty becomes so weak as to allow its replacement by a new dynasty.\nMiddle Ages to Renaissance.\nChristendom.\nChristian historical writing arguably begins with the narrative sections of the New Testament, particularly Luke-Acts, which is the primary source for the Apostolic Age, though its historical reliability is disputed. The first tentative beginnings of a specifically Christian historiography can be seen in Clement of Alexandria in the second century.\nThe growth of Christianity and its enhanced status in the Roman Empire after Constantine\u00a0I (see State church of the Roman Empire) led to the development of a distinct Christian historiography, influenced by both Christian theology and the nature of the Christian Bible, encompassing new areas of study and views of history. The central role of the Bible in Christianity is reflected in the preference of Christian historians for written sources, compared to the classical historians' preference for oral sources and is also reflected in the inclusion of politically unimportant people. Christian historians also focused on development of religion and society. This can be seen in the extensive inclusion of written sources in the \"Ecclesiastical History\" of Eusebius of Caesarea around 324 and in the subjects it covers. Christian theology considered time as linear, progressing according to divine plan. As God's plan encompassed everyone, Christian histories in this period had a universal approach. For example, Christian writers often included summaries of important historical events prior to the period covered by the work.\nWriting history was popular among Christian monks and clergy in the Middle Ages. They wrote about the history of Jesus Christ, that of the Church and that of their patrons, the dynastic history of the local rulers. In the Early Middle Ages historical writing often took the form of annals or chronicles recording events year by year, but this style tended to hamper the analysis of events and causes. An example of this type of writing is the \"Anglo-Saxon Chronicle\", which was the work of several different writers: it was started during the reign of Alfred the Great in the late 9th\u00a0century, but one copy was still being updated in 1154. Some writers in the period did construct a more narrative form of history. These included Gregory of Tours and more successfully Bede, who wrote both secular and ecclesiastical history and who is known for writing the \"Ecclesiastical History of the English People\".\nOutside of Europe and West Asia, Christian historiography also existed in Africa. For instance, Augustine of Hippo, the Berber theologian and bishop of Hippo Regius in Numidia (Roman North Africa), wrote a multiple volume autobiography called \"Confessions\" between 397 and 400 AD. While earlier pagan rulers of the Kingdom of Aksum produced autobiographical style epigraphic texts in locations spanning Ethiopia, Eritrea, and Sudan and in either Greek or the native Ge'ez script, the 4th century AD Ezana Stone commemorating Ezana of Axum's conquest of the Kingdom of Kush in Nubia also emphasized his conversion to Christianity (the first indigenous African head of state to do so). Aksumite manuscripts from the 5th to 7th centuries AD chronicling the dioceses and episcopal sees of the Coptic Orthodox Church demonstrate not only an adherence to Christian chronology but also influences from the non-Christian Kingdom of Kush, the Ptolemaic dynasty of Hellenistic Egypt, and the Yemenite Jews of the Himyarite Kingdom. The tradition of Ethiopian historiography evolved into a matured form during the Solomonic dynasty. Though works such as the 13th century \"Kebra Nagast\" blended Christian mythology with historical events in its narrative, the first proper biographical chronicle on an Emperor of Ethiopia was made for Amda Seyon I (r. 1314\u20131344), depicted as a Christian savior of his nation in conflicts with the Islamic Ifat Sultanate. The 16th century monk Bahrey was the first in Ethiopia to produce a historical ethnography, focusing on the migrating Oromo people who came into military conflict with the Ethiopian Empire. While royal biographies existed for individual Ethiopian emperors authored by court historians who were also clerical scholars within the Ethiopian Orthodox Church, the reigns of Iyasu II (r. 1730\u20131755) and Iyoas I (r. 1755\u20131769) were the first to be included in larger general dynastic histories.\nDuring the Renaissance, history was written about states or nations. The study of history changed during the Enlightenment and Romanticism. Voltaire described the history of certain ages that he considered important, rather than describing events in chronological order. History became an independent discipline. It was not called \"philosophia historiae\" anymore, but merely history (\"historia\").\nIslamic world.\nMuslim historical writings first began to develop in the 7th century, with the reconstruction of the Prophet Muhammad's life in the centuries following his death. With numerous conflicting narratives regarding Muhammad and his companions from various sources, it was necessary to verify which sources were more reliable. In order to evaluate these sources, various methodologies were developed, such as the \"science of biography\", \"science of hadith\" and \"Isnad\" (chain of transmission). These methodologies were later applied to other historical figures in the Islamic civilization. Famous historians in this tradition include Urwah (d.\u00a0712), Wahb ibn Munabbih (d.\u00a0728), Ibn Ishaq (d.\u00a0761), al-Waqidi (745\u2013822), Ibn Hisham (d.\u00a0834), Muhammad al-Bukhari (810\u2013870) and Ibn Hajar (1372\u20131449). Historians of the medieval Islamic world also developed an interest in world history. Islamic historical writing eventually culminated in the works of the Arab Muslim historian Ibn Khaldun (1332\u20131406), who published his historiographical studies in the \"Muqaddimah\" (translated as \"Prolegomena\") and \"Kitab al-I'bar\" (\"Book of Advice\"). His work was forgotten until it was rediscovered in the late 19th century.\nJewish.\nJewish historiography built on biblical and medieval historiography with significant periods in the 16th and 19th centuries, building on works such as the chains of tradition of the oral law, Christian and Hellenistic historiography, and the Josippon.\nEast Asia.\nJapan.\nThe earliest works of history produced in Japan were the \"Rikkokushi\" (Six National Histories), a corpus of six national histories covering the history of Japan from its mythological beginnings until the 9th century. The first of these works were the \"Nihon Shoki\", compiled by Prince Toneri in 720.\nKorea.\nThe tradition of Korean historiography was established with the \"Samguk sagi\", a history of Korea from its allegedly earliest times. It was compiled by Goryeo court historian Kim Pusik after its commission by King Injong of Goryeo (r. 1122\u20131146). It was completed in 1145 and relied not only on earlier Chinese histories for source material, but also on the \"Hwarang Segi\" written by the Silla historian Kim Taemun in the 8th century. The latter work is now lost.\nChina.\nThe \"Shitong\", published around 710 by the Tang Chinese historian Liu Zhiji (661\u2013721), was the first work to provide an outline of the entire tradition of Chinese historiography up to that point, and the first comprehensive work on historical criticism, arguing that historians should be skeptical of primary sources, rely on systematically gathered evidence, and should not treat previous scholars with undue deference. In 1084 the Song dynasty official Sima Guang completed the \"Zizhi Tongjian\" (Comprehensive Mirror to Aid in Government), which laid out the entire history of China from the beginning of the Warring States period (403 BC) to the end of the Five Dynasties period (959) in chronological annals form, rather than in the traditional annals-biography form. This work is considered much more accessible than the \"Official Histories\" for the Six dynasties, Tang dynasty, and Five Dynasties, and in practice superseded those works in the mind of the general reader.\nThe great Song Neo-Confucian Zhu Xi found the Mirror to be overly long for the average reader, as well as too morally nihilist, and therefore prepared a didactic summary of it called the \"Zizhi Tongjian Gangmu\" (Digest of the Comprehensive Mirror to Aid in Government), posthumously published in 1219. It reduced the original's 249 chapters to just 59, and for the rest of imperial Chinese history would be the first history book most people ever read.\nSouth East Asia.\nPhilippines.\nHistoriography of the Philippines refers to the studies, sources, critical methods and interpretations used by scholars to study the history of the Philippines. It includes historical and archival research and writing on the history of the Philippine archipelago including the islands of Luzon, Visayas, and Mindanao. The Philippine archipelago was part of many empires before the Spanish Empire arrived in the 16th century.\nSoutheast Asia is classified as part of the Indosphere and the Sinosphere. The archipelago had direct contact with China during the Song dynasty (960\u20131279), and was a part of the Srivijaya and Majapahit empires. The pre-colonial Philippines widely used the abugida system in writing and seals on documents, though it was for communication and no recorded writings of early literature or history. Ancient Filipinos usually wrote documents on bamboo, bark, and leaves, which did not survive, unlike inscriptions on clay, metal, and ivory did, such as the Laguna Copperplate Inscription and Butuan Ivory Seal. The discovery of the Butuan Ivory Seal also proves the use of paper documents in ancient Philippines.\nAfter the Spanish conquest, pre-colonial Filipino manuscripts and documents were gathered and burned to eliminate pagan beliefs. This has been the burden of historians in the accumulation of data and the development of theories that gave historians many aspects of Philippine history that were left unexplained. The interplay of pre-colonial events and the use of secondary sources written by historians to evaluate the primary sources, do not provide a critical examination of the methodology of the early Philippine historical study.\nEnlightenment.\nDuring the Age of Enlightenment, the modern development of historiography through the application of scrupulous methods began. Among the many Italians who contributed to this were Leonardo Bruni (c. 1370\u20131444), Francesco Guicciardini (1483\u20131540), and Cesare Baronio (1538\u20131607).\nVoltaire.\nFrench \"philosophe\" Voltaire (1694\u20131778) had an enormous influence on the development of historiography during the Age of Enlightenment through his demonstration of fresh new ways to look at the past. Guillaume de Syon argues:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Voltaire recast historiography in both factual and analytical terms. Not only did he reject traditional biographies and accounts that claim the work of supernatural forces, but he went so far as to suggest that earlier historiography was rife with falsified evidence and required new investigations at the source. Such an outlook was not unique in that the scientific spirit that 18th-century intellectuals perceived themselves as invested with. A rationalistic approach was key to rewriting history.\nVoltaire's best-known histories are \"The Age of Louis XIV\" (1751), and his \"Essay on the Customs and the Spirit of the Nations\" (1756). He broke from the tradition of narrating diplomatic and military events, and emphasized customs, social history and achievements in the arts and sciences. He was the first scholar to make a serious attempt to write the history of the world, eliminating theological frameworks, and emphasizing economics, culture and political history. Although he repeatedly warned against political bias on the part of the historian, he did not miss many opportunities to expose the intolerance and frauds of the church over the ages. Voltaire advised scholars that anything contradicting the normal course of nature was not to be believed. Although he found evil in the historical record, he fervently believed reason and educating the illiterate masses would lead to progress. Voltaire's \"History of Charles XII\" (1731) about the Swedish warrior king (Swedish: Karl XII) is also one of his most famous works. It is not least known as one of Napoleon's absolute favorite books.\nVoltaire explains his view of historiography in his article on \"History\" in Diderot's \"Encyclop\u00e9die\": \"One demands of modern historians more details, better ascertained facts, precise dates, more attention to customs, laws, mores, commerce, finance, agriculture, population.\" Already in 1739 he had written: \"My chief object is not political or military history, it is the history of the arts, of commerce, of civilization\u2014in a word\u2014of the human mind.\" Voltaire's histories used the values of the Enlightenment to evaluate the past. He helped free historiography from antiquarianism, Eurocentrism, religious intolerance and a concentration on great men, diplomacy, and warfare. Peter Gay says Voltaire wrote \"very good history\", citing his \"scrupulous concern for truths\", \"careful sifting of evidence\", \"intelligent selection of what is important\", \"keen sense of drama\", and \"grasp of the fact that a whole civilization is a unit of study\".\nDavid Hume.\nAt the same time, philosopher David Hume was having a similar effect on the study of history in Great Britain. In 1754 he published \"The History of England\", a 6-volume work which extended \"From the Invasion of Julius Caesar to the Revolution in 1688\". Hume adopted a similar scope to Voltaire in his history; as well as the history of Kings, Parliaments, and armies, he examined the history of culture, including literature and science, as well. His short biographies of leading scientists explored the process of scientific change and he developed new ways of seeing scientists in the context of their times by looking at how they interacted with society and each other\u2014he paid special attention to Francis Bacon, Robert Boyle, Isaac Newton and William Harvey.\nHe also argued that the quest for liberty was the highest standard for judging the past, and concluded that after considerable fluctuation, England at the time of his writing had achieved \"the most entire system of liberty, that was ever known amongst mankind\".\nEdward Gibbon.\nThe apex of Enlightenment history was reached with Edward Gibbon's monumental six-volume work, \"The History of the Decline and Fall of the Roman Empire\", published on 17 February 1776. Because of its relative objectivity and heavy use of primary sources, its methodology became a model for later historians. This has led to Gibbon being called the first \"modern historian\". The book sold impressively, earning its author a total of about \u00a39000. Biographer Leslie Stephen wrote that thereafter, \"His fame was as rapid as it has been lasting.\"\nGibbon's work has been praised for its style, its piquant epigrams and its effective irony. Winston Churchill memorably noted, \"I set out upon\u00a0... Gibbon's \"Decline and Fall of the Roman Empire\" [and] was immediately dominated both by the story and the style.\u00a0... I devoured Gibbon. I rode triumphantly through it from end to end and enjoyed it all.\" Gibbon was pivotal in the secularizing and 'desanctifying' of history, remarking, for example, on the \"want of truth and common sense\" of biographies composed by Saint Jerome. Unusually for an 18th-century historian, Gibbon was never content with secondhand accounts when the primary sources were accessible (though most of these were drawn from well-known printed editions). He said, \"I have always endeavoured to draw from the fountain-head; that my curiosity, as well as a sense of duty, has always urged me to study the originals; and that, if they have sometimes eluded my search, I have carefully marked the secondary evidence, on whose faith a passage or a fact were reduced to depend.\" In this insistence upon the importance of primary sources, Gibbon broke new ground in the methodical study of history:\nIn accuracy, thoroughness, lucidity, and comprehensive grasp of a vast subject, the 'History' is unsurpassable. It is the one English history which may be regarded as definitive.\u00a0... Whatever its shortcomings the book is artistically imposing as well as historically unimpeachable as a vast panorama of a great period.\n19th century.\nThe tumultuous events surrounding the French Revolution inspired much of the historiography and analysis of the early 19th century. Interest in the 1688 Glorious Revolution was also rekindled by the Reform Act of 1832 in England. Nineteenth century historiography, especially among American historians, featured conflicting viewpoints that represented the times. According to 20th-century historian Richard Hofstadter:&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The historians of the nineteenth century worked under the pressure of two internal tensions: on one side there was the constant demand of society\u2014whether through the nationstate, the church, or some special group or class interest\u2014for memory mixed with myth, for the historical tale that would strengthen group loyalties or confirm national pride; and against this there were the demands of critical method, and even, after a time, the goal of writing \"scientific\" history.\nThomas Carlyle.\nThomas Carlyle published his three-volume \"\", in 1837. The first volume was accidentally burned by John Stuart Mill's maid. Carlyle rewrote it from scratch. Carlyle's style of historical writing stressed the immediacy of action, often using the present tense. He emphasised the role of forces of the spirit in history and thought that chaotic events demanded what he called 'heroes' to take control over the competing forces erupting within society. He considered the dynamic forces of history as being the hopes and aspirations of people that took the form of ideas, and were often ossified into ideologies. Carlyle's \"The French Revolution\" was written in a highly unorthodox style, far removed from the neutral and detached tone of the tradition of Gibbon. Carlyle presented the history as dramatic events unfolding in the present as though he and the reader were participants on the streets of Paris at the famous events. Carlyle's invented style was epic poetry combined with philosophical treatise. It is rarely read or cited in the last century.\nFrench historians: Michelet and Taine.\nIn his main work \"Histoire de France\" (1855), French historian Jules Michelet (1798\u20131874) coined the term Renaissance (meaning \"rebirth\" in French), as a period in Europe's cultural history that represented a break from the Middle Ages, creating a modern understanding of humanity and its place in the world. The 19-volume work covered French history from Charlemagne to the outbreak of the French Revolution. His inquiry into manuscript and printed authorities was most laborious, but his lively imagination, and his strong religious and political prejudices, made him regard all things from a singularly personal point of view.\nMichelet was one of the first historians to shift the emphasis of history to the common people, rather than the leaders and institutions of the country. He had a decisive impact on scholars. Gayana Jurkevich argues that, led by Michelet,\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;19th-century French historians no longer saw history as the chronicling of royal dynasties, armies, treaties, and great men of state, but as the history of ordinary French people and the landscape of France.\nHippolyte Taine (1828\u20131893), although unable to secure an academic position, was the chief theoretical influence of French naturalism, a major proponent of sociological positivism, and one of the first practitioners of historicist criticism. He pioneered the idea of \"the milieu\" as an active historical force which amalgamated geographical, psychological, and social factors. Historical writing for him was a search for general laws. His brilliant style kept his writing in circulation long after his theoretical approaches were pass\u00e9.\nCultural and constitutional history.\nOne of the major progenitors of the history of culture and art, was the Swiss historian Jacob Burckhardt. Siegfried Giedion described Burckhardt's achievement in the following terms: \"The great discoverer of the age of the Renaissance, he first showed how a period should be treated in its entirety, with regard not only for its painting, sculpture and architecture, but for the social institutions of its daily life as well.\"\nHis most famous work was \"The Civilization of the Renaissance in Italy\", published in 1860; it was the most influential interpretation of the Italian Renaissance in the nineteenth century and is still widely read. According to John Lukacs, he was the first master of cultural history, which seeks to describe the spirit and the forms of expression of a particular age, a particular people, or a particular place. His innovative approach to historical research stressed the importance of art and its inestimable value as a primary source for the study of history. He was one of the first historians to rise above the narrow nineteenth-century notion that \"history is past politics and politics current history.\"\nBy the mid-19th century, scholars were beginning to analyse the history of institutional change, particularly the development of constitutional government. William Stubbs's \"Constitutional History of England\" (3 vols., 1874\u20131878) was an important influence on this developing field. The work traced the development of the English constitution from the Teutonic invasions of Britain until 1485, and marked a distinct step in the advance of English historical learning. He argued that the theory of the unity and continuity of history should not remove distinctions between ancient and modern history. He believed that, though work on ancient history is a useful preparation for the study of modern history, either may advantageously be studied apart. He was a good palaeographer, and excelled in textual criticism, in examination of authorship, and other such matters, while his vast erudition and retentive memory made him second to none in interpretation and exposition.\nVon Ranke and professionalization in Germany.\nThe modern academic study of history and methods of historiography were pioneered in 19th-century German universities, especially the University of G\u00f6ttingen. Leopold von Ranke (1795\u20131886) at Berlin was a pivotal influence in this regard, and was the founder of modern source-based history. According to Caroline Hoefferle, \"Ranke was probably the most important historian to shape historical profession as it emerged in Europe and the United States in the late 19th century.\"\nSpecifically, he implemented the seminar teaching method in his classroom, and focused on archival research and analysis of historical documents. Beginning with his first book in 1824, the \"History of the Latin and Teutonic Peoples from 1494 to 1514\", Ranke used an unusually wide variety of sources for a historian of the age, including \"memoirs, diaries, personal and formal missives, government documents, diplomatic dispatches and first-hand accounts of eye-witnesses\". Over a career that spanned much of the century, Ranke set the standards for much of later historical writing, introducing such ideas as reliance on primary sources, an emphasis on narrative history and especially international politics (). Sources had to be solid, not speculations and rationalizations. His credo was to write history the way it was. He insisted on primary sources with proven authenticity.\nRanke also rejected the 'teleological approach' to history, which traditionally viewed each period as inferior to the period which follows. In Ranke's view, the historian had to understand a period on its own terms, and seek to find only the general ideas which animated every period of history. In 1831 and at the behest of the Prussian government, Ranke founded and edited the first historical journal in the world, called .\nAnother important German thinker was Georg Wilhelm Friedrich Hegel, whose theory of historical progress ran counter to Ranke's approach. In Hegel's own words, his philosophical theory of \"World history\u00a0... represents the development of the spirit's consciousness of its own freedom and of the consequent realization of this freedom.\" This realization is seen by studying the various cultures that have developed over the millennia, and trying to understand the way that freedom has worked itself out through them:\nWorld history is the record of the spirit's efforts to attain knowledge of what it is in itself. The Orientals do not know that the spirit or man as such are free in themselves. And because they do not know that, they are not themselves free. They only know that One is free.\u00a0... The consciousness of freedom first awoke among the Greeks, and they were accordingly free; but, like the Romans, they only knew that Some, and not all men as such, are free.\u00a0... The Germanic nations, with the rise of Christianity, were the first to realize that All men are by nature free, and that freedom of spirit is his very essence.\nKarl Marx introduced the concept of historical materialism into the study of world historical development. In his conception, the economic conditions and dominant modes of production determined the structure of society at that point. In his view five successive stages in the development of material conditions would occur in Western Europe. The first stage was primitive communism where property was shared and there was no concept of \"leadership\". This progressed to a slave society where the idea of class emerged and the State developed. Feudalism was characterized by an aristocracy working in partnership with a theocracy and the emergence of the nation-state. Capitalism appeared after the bourgeois revolution when the capitalists (or their merchant predecessors) overthrew the feudal system and established a market economy, with\nprivate property and parliamentary democracy. Marx then predicted the eventual proletarian revolution that would result in the attainment of socialism, followed by communism, where property would be communally owned.\nPrevious historians had focused on cyclical events of the rise and decline of rulers and nations. Process of nationalization of history, as part of national revivals in the 19th century, resulted with separation of \"one's own\" history from common universal history by such way of perceiving, understanding and treating the past that constructed history as history of a nation. A new discipline, sociology, emerged in the late 19th century and analyzed and compared these perspectives on a larger scale.\nMacaulay and Whig history.\nThe term \"Whig history\", coined by Herbert Butterfield in his short book \"The Whig Interpretation of History\" in 1931, means the approach to historiography which presents the past as an inevitable progression towards ever greater liberty and enlightenment, culminating in modern forms of liberal democracy and constitutional monarchy. In general, Whig historians emphasized the rise of constitutional government, personal freedoms and scientific progress. The term has been also applied widely in historical disciplines outside of British history (the history of science, for example) to criticize any teleological (or goal-directed), hero-based, and transhistorical narrative.\nPaul Rapin de Thoyras's history of England, published in 1723, became \"the classic Whig history\" for the first half of the 18th century. It was later supplanted by the immensely popular \"The History of England\" by David Hume. Whig historians emphasized the achievements of the Glorious Revolution of 1688. This included James Mackintosh's \"History of the Revolution in England in 1688\", William Blackstone's \"Commentaries on the Laws of England\", and Henry Hallam's \"Constitutional History of England\".\nThe most famous exponent of 'Whiggery' was Thomas Babington Macaulay. His writings are famous for their ringing prose and for their confident, sometimes dogmatic, emphasis on a progressive model of British history, according to which the country threw off superstition, autocracy and confusion to create a balanced constitution and a forward-looking culture combined with freedom of belief and expression. This model of human progress has been called the Whig interpretation of history. He published the first volumes of his most famous work of history, \"The History of England from the Accession of James II\", in 1848. It proved an immediate success and replaced Hume's history to become the new orthodoxy. His 'Whiggish convictions' are spelled out in his first chapter:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;I shall relate how the new settlement was\u00a0... successfully defended against foreign and domestic enemies; how\u00a0... the authority of law and the security of property were found to be compatible with a liberty of discussion and of individual action never before known; how, from the auspicious union of order and freedom, sprang a prosperity of which the annals of human affairs had furnished no example; how our country, from a state of ignominious vassalage, rapidly rose to the place of umpire among European powers; how her opulence and her martial glory grew together;\u00a0... how a gigantic commerce gave birth to a maritime power, compared with which every other maritime power, ancient or modern, sinks into insignificance\u00a0... the history of our country during the last hundred and sixty years is eminently the history of physical, of moral, and of intellectual improvement.\nHis legacy continues to be controversial; Gertrude Himmelfarb wrote that \"most professional historians have long since given up reading Macaulay, as they have given up writing the kind of history he wrote and thinking about history as he did.\" However, J. R. Western wrote that: \"Despite its age and blemishes, Macaulay's \"History of England\" has still to be superseded by a full-scale modern history of the period\".\nThe Whig consensus was steadily undermined during the post-World War I re-evaluation of European history, and Butterfield's critique exemplified this trend. Intellectuals no longer believed the world was automatically getting better and better. Subsequent generations of academic historians have similarly rejected Whig history because of its presentist and teleological assumption that history is driving toward some sort of goal. Other criticized 'Whig' assumptions included viewing the British system as the apex of human political development, assuming that political figures in the past held current political beliefs (anachronism), considering British history as a march of progress with inevitable outcomes and presenting political figures of the past as heroes, who advanced the cause of this political progress, or villains, who sought to hinder its inevitable triumph. J. Hart says \"a Whig interpretation requires human heroes and villains in the story.\"\n20th century.\n20th-century historiography in major countries is characterized by a move to universities and academic research centers. Popular history continued to be written by self-educated amateurs, but scholarly history increasingly became the province of PhD's trained in research seminars at a university. The training emphasized working with primary sources in archives. Seminars taught graduate students how to review the historiography of the topics, so that they could understand the conceptual frameworks currently in use, and the criticisms regarding their strengths and weaknesses. Western Europe and the United States took leading roles in this development. The emergence of area studies of other regions also developed historiographical practices.\nFrance: \"Annales\" school.\nThe French \"Annales\" school radically changed the focus of historical research in France during the 20th century by stressing long-term social history, rather than political or diplomatic themes. The school emphasized the use of quantification and the paying of special attention to geography.\nThe \"Annales d'histoire \u00e9conomique et sociale\" journal was founded in 1929 in Strasbourg by Marc Bloch and Lucien Febvre. These authors, the former a medieval historian and the latter an early modernist, quickly became associated with the distinctive \"Annales\" approach, which combined geography, history, and the sociological approaches of the Ann\u00e9e Sociologique (many members of which were their colleagues at Strasbourg) to produce an approach which rejected the predominant emphasis on politics, diplomacy and war of many 19th and early 20th-century historians as spearheaded by historians whom Febvre called Les Sorbonnistes. Instead, they pioneered an approach to a study of long-term historical structures (\"la longue dur\u00e9e\") over events and political transformations. Geography, material culture, and what later Annalistes called \"mentalit\u00e9s\", or the psychology of the epoch, are also characteristic areas of study. The goal of the \"Annales\" was to undo the work of the \"Sorbonnistes\", to turn French historians away from the narrowly political and diplomatic toward the new vistas in social and economic history. For early modern Mexican history, the work of Marc Bloch's student Fran\u00e7ois Chevalier on the formation of landed estates (haciendas) from the sixteenth century to the seventeenth had a major impact on Mexican history and historiography, setting off an important debate about whether landed estates were basically feudal or capitalistic.\nAn eminent member of this school, Georges Duby, described his approach to history as one that relegated the sensational to the sidelines and was reluctant to give a simple accounting of events, but strived on the contrary to pose and solve problems and, neglecting surface disturbances, to observe the long and medium-term evolution of economy, society and civilisation. The Annalistes, especially Lucien Febvre, advocated a \"histoire totale\", or \"histoire tout court\", a complete study of a historical problem.\nThe second era of the school was led by Fernand Braudel and was very influential throughout the 1960s and 1970s, especially for his work on the Mediterranean region in the era of Philip II of Spain. Braudel developed the idea, often associated with Annalistes, of different modes of historical time: \"l'histoire quasi immobile\" (motionless history) of historical geography, the history of social, political and economic structures (\"la longue dur\u00e9e\"), and the history of men and events, in the context of their structures. His 'longue dur\u00e9e' approach stressed slow, and often imperceptible effects of space, climate and technology on the actions of human beings in the past. The \"Annales\" historians, after living through two world wars and major political upheavals in France, were deeply uncomfortable with the notion that multiple ruptures and discontinuities created history. They preferred to stress slow change and the longue dur\u00e9e. They paid special attention to geography, climate, and demography as long-term factors. They considered the continuities of the deepest structures were central to history, beside which upheavals in institutions or the superstructure of social life were of little significance, for history lies beyond the reach of conscious actors, especially the will of revolutionaries.\nNoting the political upheavals in Europe and especially in France in 1968, Eric Hobsbawm argued that \"in France the virtual hegemony of Braudelian history and the \"Annales\" came to an end after 1968, and the international influence of the journal dropped steeply.\" Multiple responses were attempted by the school. Scholars moved in multiple directions, covering in disconnected fashion the social, economic, and cultural history of different eras and different parts of the globe. By the time of crisis the school was building a vast publishing and research network reaching across France, Europe, and the rest of the world. Influence indeed spread out from Paris, but few new ideas came in. Much emphasis was given to quantitative data, seen as the key to unlocking all of social history. However, the \"Annales\" ignored the developments in quantitative studies underway in the U.S. and Britain, which reshaped economic, political and demographic research.\nMarxist historiography.\nMarxist historiography developed as a school of historiography influenced by the chief tenets of Marxism, including the centrality of social class and economic constraints in determining historical outcomes (historical materialism). Friedrich Engels wrote \"The Peasant War in Germany\", which analysed social warfare in early Protestant Germany in terms of emerging capitalist classes. Although it lacked a rigorous engagement with archival sources, it indicated an early interest in history from below and class analysis, and it attempts a dialectical analysis. Another treatise of Engels, \"The Condition of the Working Class in England in 1844\", was salient in creating the socialist impetus in British politics from then on, e.g. the Fabian Society.\nR. H. Tawney was an early historian working in this tradition. \"The Agrarian Problem in the Sixteenth Century\" (1912) and \"Religion and the Rise of Capitalism\" (1926), reflected his ethical concerns and preoccupations in economic history. He was profoundly interested in the issue of the enclosure of land in the English countryside in the sixteenth and seventeenth centuries and in Max Weber's thesis on the connection between the appearance of Protestantism and the rise of capitalism. His belief in the rise of the gentry in the century before the outbreak of the Civil War in England provoked the 'Storm over the Gentry' in which his methods were subjected to severe criticisms by Hugh Trevor-Roper and John Cooper.\nHistoriography in the Soviet Union was greatly influenced by Marxist historiography, as historical materialism was extended into the Soviet version of dialectical materialism.\nA circle of historians inside the Communist Party of Great Britain (CPGB) formed in 1946 and became a highly influential cluster of British Marxist historians, who contributed to history from below and class structure in early capitalist society. While some members of the group (most notably Christopher Hill and E. P. Thompson) left the CPGB after the 1956 Hungarian Revolution, the common points of British Marxist historiography continued in their works. They placed a great emphasis on the subjective determination of history.\nChristopher Hill's studies on 17th-century English history were widely acknowledged and recognised as representative of this school. His books include \"Puritanism and Revolution\" (1958), \"Intellectual Origins of the English Revolution\" (1965 and revised in 1996), \"The Century of Revolution\" (1961), \"AntiChrist in 17th-century England\" (1971), \"The World Turned Upside Down\" (1972) and many others. E. P. Thompson pioneered the study of history from below in his work, \"The Making of the English Working Class\", published in 1963. It focused on the forgotten history of the first working-class political left in the world in the late-18th and early-19th centuries. In his preface to this book, Thompson set out his approach to writing history from below:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;I am seeking to rescue the poor stockinger, the Luddite cropper, the \"obsolete\" hand-loom weaver, the \"Utopian\" artisan, and even the deluded follower of Joanna Southcott, from the enormous condescension of posterity. Their crafts and traditions may have been dying. Their hostility to the new industrialism may have been backward-looking. Their communitarian ideals may have been fantasies. Their insurrectionary conspiracies may have been foolhardy. But they lived through these times of acute social disturbance, and we did not. Their aspirations were valid in terms of their own experience; and, if they were casualties of history, they remain, condemned in their own lives, as casualties.\nThompson's work was also significant because of the way he defined \"class\". He argued that class was not a structure, but a relationship that changed over time. He opened the gates for a generation of labor historians, such as David Montgomery and Herbert Gutman, who made similar studies of the American working classes.\nOther important Marxist historians included Eric Hobsbawm, C. L. R. James, Raphael Samuel, A. L. Morton and Brian Pearce.\nBiography.\nBiography has been a major form of historiography since the days when Plutarch wrote the parallel lives of great Roman and Greek leaders. It is a field especially attractive to nonacademic historians, and often to the spouses or children of famous people, who have access to the trove of letters and documents. Academic historians tend to downplay biography because it pays too little attention to broad social, cultural, political and economic forces, and perhaps too much attention to popular psychology. The \"Great Man\" tradition in Britain originated in the multi-volume \"Dictionary of National Biography\" (which originated in 1882 and issued updates into the 1970s); it continues to this day in the new \"Oxford Dictionary of National Biography\". In the United States, the \"Dictionary of American Biography\" was planned in the late 1920s and appeared with numerous supplements into the 1980s. It has now been displaced by the \"American National Biography\" as well as numerous smaller historical encyclopedias that give thorough coverage to Great Persons. Bookstores do a thriving business in biographies, which sell far more copies than the esoteric monographs based on post-structuralism, cultural, racial or gender history. Michael Holroyd says the last forty years \"may be seen as a golden age of biography\", but nevertheless calls it the \"shallow end of history\". Nicolas Barker argues that \"more and more biographies command an ever larger readership\", as he speculates that biography has come \"to express the spirit of our age\".\nDaniel R. Meister argues that:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Biography Studies is emerging as an independent discipline, especially in the Netherlands. This Dutch School of biography is moving biography studies away from the less scholarly life writing tradition and towards history by encouraging its practitioners to utilize an approach adapted from microhistory.\nBritish debates.\nMarxist historian E. H. Carr developed a controversial theory of history in his 1961 book \"What Is History?\", which proved to be one of the most influential books ever written on the subject. He presented a middle-of-the-road position between the empirical or (Rankean) view of history and R. G. Collingwood's idealism, and rejected the empirical view of the historian's work being an accretion of \"facts\" that they have at their disposal as nonsense. He maintained that there is such a vast quantity of information that the historian always chooses the \"facts\" they decide to make use of. In Carr's famous example, he claimed that millions had crossed the Rubicon, but only Julius Caesar's crossing in 49\u00a0BC is declared noteworthy by historians. For this reason, Carr argued that Leopold von Ranke's famous dictum \"wie es eigentlich gewesen\" (show what actually happened) was wrong because it presumed that the \"facts\" influenced what the historian wrote, rather than the historian choosing what \"facts of the past\" they intended to turn into \"historical facts\". At the same time, Carr argued that the study of the facts may lead the historian to change his or her views. In this way, Carr argued that history was \"an unending dialogue between the past and present\".\nCarr is held by some critics to have had a deterministic outlook in history. Others have modified or rejected this use of the label \"determinist\". He took a hostile view of those historians who stress the workings of chance and contingency in the workings of history. In Carr's view, no individual is truly free of the social environment in which they live, but contended that within those limitations, there was room, albeit very narrow room for people to make decisions that affect history. Carr emphatically contended that history was a social science, not an art, because historians like scientists seek generalizations that helped to broaden the understanding of one's subject.\nOne of Carr's most forthright critics was Hugh Trevor-Roper, who argued that Carr's dismissal of the \"might-have-beens of history\" reflected a fundamental lack of interest in examining historical causation. Trevor-Roper asserted that examining possible alternative outcomes of history was far from being a \"parlour-game\" was rather an essential part of the historians' work, as only by considering all possible outcomes of a given situation could a historian properly understand the period.\nThe controversy inspired Sir Geoffrey Elton to write his 1967 book \"The Practice of History\". Elton criticized Carr for his \"whimsical\" distinction between the \"historical facts\" and the \"facts of the past\", arguing that it reflected \"...an extraordinarily arrogant attitude both to the past and to the place of the historian studying it\". Elton, instead, strongly defended the traditional methods of history and was also appalled by the inroads made by postmodernism. Elton saw the duty of historians as empirically gathering evidence and objectively analyzing what the evidence has to say. As a traditionalist, he placed great emphasis on the role of individuals in history instead of abstract, impersonal forces. Elton saw political history as the highest kind of history. Elton had no use for those who seek history to make myths, to create laws to explain the past, or to produce theories such as Marxism.\nU.S. approaches.\nClassical and European history was part of the 19th-century grammar curriculum. American history became a topic later in the 19th century. In the historiography of the United States, there were a series of major approaches in the 20th century. In 2009\u20132012, there were an average of 16,000 new academic history books published in the U.S. every year.\nProgressive historians.\nThe Progressive historians were a group of 20th century historians of the United States associated with a historiographical tradition that embraced an economic interpretation of American history. Most prominent among these was Charles A. Beard, who was influential in academia and with the general public.\nConsensus history.\nConsensus history emphasizes the basic unity of American values and downplays conflict as superficial. It was especially attractive in the 1950s and 1960s. Prominent leaders included Richard Hofstadter, Louis Hartz, Daniel Boorstin, Allan Nevins, Clinton Rossiter, Edmund Morgan, and David M. Potter. In 1948 Hofstadter made a compelling statement of the consensus model of the U.S. political tradition:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The fierceness of the political struggles has often been misleading: for the range of vision embraced by the primary contestants in the major parties has always been bounded by the horizons of property and enterprise. However much at odds on specific issues, the major political traditions have shared a belief in the rights of property, the philosophy of economic individualism, the value of competition; they have accepted the economic virtues of capitalist culture as necessary qualities of man.\nNew Left history.\nConsensus history was rejected by New Left viewpoints that attracted a younger generation of radical historians in the 1960s. These viewpoints stress conflict and emphasize the central roles of class, race and gender. The history of dissent, and the experiences of racial minorities and disadvantaged classes was central to the narratives produced by New Left historians.\nQuantification and new approaches to history.\nSocial history, sometimes called the \"new social history\", is a broad branch that studies the experiences of ordinary people in the past. It had major growth as a field in the 1960s and 1970s, and still is well represented in history departments. However, after 1980 the \"cultural turn\" directed the next generation to new topics. In the two decades from 1975 to 1995, the proportion of professors of history in U.S. universities identifying with social history rose from 31 to 41 percent, while the proportion of political historians fell from 40 to 30 percent.\nThe growth was enabled by the social sciences, computers, statistics, new data sources such as individual census information, and summer training programs at the Newberry Library and the University of Michigan. The New Political History saw the application of social history methods to politics, as the focus shifted from politicians and legislation to voters and elections. The Social Science History Association was formed in 1976 as an interdisciplinary group with a journal \"Social Science History\" and an annual convention. The goal was to incorporate in historical studies perspectives from all the social sciences, especially political science, sociology and economics. The pioneers shared a commitment to quantification. However, by the 1980s the first blush of quantification had worn off, as traditional historians counterattacked. Harvey J. Graff says:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The case against the new mixed and confused a lengthy list of ingredients, including the following: history's supposed loss of identity and humanity in the stain of social science, the fear of subordinating quality to quantity, conceptual and technical fallacies, violation of the literary character and biographical base of \"good\" history (rhetorical and aesthetic concern), loss of audiences, derogation of history rooted in \"great men\" and \"great events\", trivialization in general, a hodgepodge of ideological objections from all directions, and a fear that new historians were reaping research funds that might otherwise come to their detractors. To defenders of history as they knew it, the discipline was in crisis, and the pursuit of the new was a major cause.\nMeanwhile, \"new\" economic history became well-established. However, cliometrics has never been considered a historical field by the vast majority of historians so that cliometric articles have not been cited by historians. Economists mostly employed economic theories and econometric applications similar to typical economic papers. As a result, quantification remained central to demographic studies, but slipped behind in political and social history as traditional narrative approaches made a comeback. Recently, as the newest approach in economic history \"new history of capitalism\" appeared. In the first article of the related journal, Marc Flandreau defined their purpose as \"crossing border\" to create a truly interdisciplinary field.\nLatin America.\nLatin America is the former Spanish American empire in the Western Hemisphere plus Portuguese Brazil. Professional historians pioneered the creation of this field, starting in the late nineteenth century. The term \"Latin America\" did not come into general usage until the twentieth century and in some cases it was rejected. The historiography of the field has been more fragmented than unified, with historians of Spanish America and Brazil generally remaining in separate spheres. Another standard division within the historiography is the temporal factor, with works falling into either the early modern period (or \"colonial era\") or the post-independence (or \"national\") period, from the early nineteenth onward. Relatively few works span the two eras and few works except textbooks unite Spanish America and Brazil. There is a tendency to focus on histories of particular countries or regions (the Andes, the Southern Cone, the Caribbean) with relatively little comparative work.\nHistorians of Latin America have contributed to various types of historical writing, but one major, innovative development in Spanish American history is the emergence of ethnohistory, the history of indigenous peoples, especially in Mexico based on alphabetic sources in Spanish or in indigenous languages.\nFor the early modern period, the emergence of Atlantic history, based on comparisons and linkages of Europe, the Americas, and Africa from 1450 to 1850 that developed as a field in its own right has integrated early modern Latin American history into a larger framework. For all periods, global or world history have focused on the connections between areas, likewise integrating Latin America into a larger perspective. Latin America's importance to world history is notable but often overlooked. \"Latin America's central, and sometimes pioneering, role in the development of globalization and modernity did not cease with the end of colonial rule and the early modern period. Indeed, the region's political independence places it at the forefront of two trends that are regularly considered thresholds of the modern world. The first is the so-called liberal revolution, the shift from monarchies of the ancien r\u00e9gime, where inheritance legitimated political power, to constitutional republics... The second, and related, trend consistently considered a threshold of modern history that saw Latin America in the forefront is the development of nation-states.\"\nHistorical research appears in a number of specialized journals. These include \"Hispanic American Historical Review\" (est. 1918), published by the Conference on Latin American History; \"The Americas\", (est. 1944); \"Journal of Latin American Studies\" (1969); \"Canadian Journal of Latin American and Caribbean Studies\", (est.1976) \"Bulletin of Latin American Research\", (est. 1981); \"Colonial Latin American Review\" (1992); and \"Colonial Latin American Historical Review\" (est. 1992). \"Latin American Research Review\" (est. 1969), published by the Latin American Studies Association, does not focus primarily on history, but it has often published historiographical essays on particular topics.\nGeneral works on Latin American history have appeared since the 1950s, when the teaching of Latin American history expanded in U.S. universities and colleges. Most attempt full coverage of Spanish America and Brazil from the conquest to the modern era, focusing on institutional, political, social and economic history. An important, eleven volume treatment of Latin American history is \"The Cambridge History of Latin America\", with separate volumes on the colonial era, nineteenth century, and the twentieth century. There is a small number of general works that have gone through multiple editions. Major trade publishers have also issued edited volumes on Latin American history and historiography. Reference works include the \"Handbook of Latin American Studies\", which publishes articles by area experts, with annotated bibliographic entries, and the \"Encyclopedia of Latin American History and Culture\".\nAfrica.\nSince most African societies recorded their history orally, written records largely focussed on the actions of outsiders. Historiography in the colonial period was undertaken by European academics and historians from a European perspective, under the pretence of Western superiority supported by scientific racism. Oral sources were deprecated and dismissed by unfamiliar historians, giving them the impression Africa had history nor desire to create it.\nAfrican historiography became organised at the academic level in the mid 20th century. Kenneth Dike, among others, pioneered a new methodology of reconstructing African history using the oral traditions, alongside evidence from European-style histories and other historical sciences.212 This movement towards utilising oral sources in a multi-disciplinary approach culminated in UNESCO commissioning the \"General History of Africa\", edited by specialists drawn from across the African continent, and publishing from 1981 to 2024. are still tasked with building the institutional frameworks incorporating African epistemologies and representing an African perspective.\nWorld history.\nWorld history, as a distinct field of historical study, emerged as an independent academic field in the 1980s. It focused on the examination of history from a global perspective and looked for common patterns that emerged across all cultures. The basic thematic approach of this field was to analyse two major focal points: integration\u2014how processes of world history have drawn people of the world together, and difference\u2014how patterns of world history reveal the diversity of the human experience.\nArnold J. Toynbee's ten-volume \"A Study of History\", took an approach that was widely discussed in the 1930s and 1940s. By the 1960s his work was virtually ignored by scholars and the general public. He compared 26 independent civilizations and argued that they displayed striking parallels in their origin, growth, and decay. He proposed a universal model to each of these civilizations, detailing the stages through which they all pass: genesis, growth, time of troubles, universal state, and disintegration. The later volumes gave too much emphasis on spirituality to satisfy critics.\nChicago historian William H. McNeill wrote \"The Rise of the West\" (1965) to show how the separate civilizations of Eurasia interacted from the very beginning of their history, borrowing critical skills from one another, and thus precipitating still further change as adjustment between traditional old and borrowed new knowledge and practice became necessary. He then discusses the dramatic effect of Western civilization on others in the past 500 years of history. McNeill took a broad approach organized around the interactions of peoples across the globe. Such interactions have become both more numerous and more continual and substantial in recent times. Before about 1500, the network of communication between cultures was that of Eurasia. The term for these areas of interaction differ from one world historian to another and include \"world-system\" and \"ecumene\". His emphasis on cultural fusions influenced historical theory significantly.\nThe cultural turn.\nThe \"cultural turn\" of the 1980s and 1990s affected scholars in most areas of history. Inspired largely by anthropology, it turned away from leaders, ordinary people and famous events to look at the use of language and cultural symbols to represent the changing values of society.\nThe British historian Peter Burke finds that cultural studies has numerous spinoffs, or topical themes it has strongly influenced. The most important include gender studies and postcolonial studies, as well as memory studies, and film studies. Diplomatic historian Melvyn P. Leffler finds that the problem with the \"cultural turn\" is that the culture concept is imprecise, and may produce excessively broad interpretations, because it:&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;seems infinitely malleable and capable of giving shape to totally divergent policies; for example, to internationalism or isolationism in the United States, and to cooperative internationalism or race hatred in Japan. The malleability of culture suggest to me that in order to understand its effect on policy, one needs also to study the dynamics of political economy, the evolution of the international system, and the roles of technology and communication, among many other variables.\nMemory studies.\nMemory studies is a new field, focused on how nations and groups (and historians) construct and select their memories of the past in order to celebrate (or denounce) key features, thus making a statement of their current values and beliefs. Historians have played a central role in shaping the memories of the past as their work is diffused through popular history books and school textbooks. French sociologist Maurice Halbwachs, opened the field with \"La m\u00e9moire collective\" (Paris: 1950).\nMany historians examine how the memory of the past has been constructed, memorialized or distorted. Historians examine how legends are invented. For example, there are numerous studies of the memory of atrocities from World War II, notably the Holocaust in Europe and Japanese war crimes in Asia. British historian Heather Jones argues that the historiography of the First World War in recent years has been reinvigorated by the cultural turn. Scholars have raised entirely new questions regarding military occupation, radicalization of politics, race, and the male body.\nRepresentative of recent scholarship is a collection of studies on the \"Dynamics of Memory and Identity in Contemporary Europe\". Sage has published the scholarly journal \"Memory Studies\" since 2008, and the book series \"Memory Studies\" was launched by Palgrave Macmillan in 2010 with 5\u201310 titles a year.\nNarrative.\nAccording to Lawrence Stone, narrative has traditionally been the main rhetorical device used by historians. In 1979, at a time when the new Social History was demanding a social-science model of analysis, Stone detected a move back toward the narrative. Stone defined narrative as follows: it is organized chronologically; it is focused on a single coherent story; it is descriptive rather than analytical; it is concerned with people not abstract circumstances; and it deals with the particular and specific rather than the collective and statistical. He reported that, \"More and more of the 'new historians' are now trying to discover what was going on inside people's heads in the past, and what it was like to live in the past, questions which inevitably lead back to the use of narrative.\"\nHistorians committed to a social science approach, however, have criticized the narrowness of narrative and its preference for anecdote over analysis, and its use of clever examples rather than statistically verified empirical regularities.\nTopics studied.\nSome of the common topics in historiography are:\nApproaches.\nHow a historian approaches historical events is one of the most important decisions within historiography. Historians commonly recognise that chronicle-style listings of individual historical facts\u2014dealing with names, dates and places\u2014are not particularly meaningful in themselves. Such facts only become useful/informative when assembled with other historical evidence, and the process of assembling this evidence is understood as a particular historiographical approach.\nHistorical revisionism can highlight the limitations of various historiographic traditions. And nomadologists may claim: \"History is always written from the sedentary point of view and in the name of a unitary State apparatus [...].\"\nSome influential historiographical approaches include:\nRelated fields.\nImportant related fields include:\nScholarly journals.\nThe historical journal, a forum where academic historians could exchange ideas and publish newly discovered information, came into being in the 19th century. The early journals were similar to those for the physical sciences, and were seen as a means for history to become more professional. The first journal to do this was \"Historische Zeitschrift\" in Germany in 1859. In France the \"Revue des questions historiques\" was set up on the model of the \"Historische Zeitschrift\" in 1866, with the more left wing \"Revue historique\" starting in reaction ten years later and they would continue to duel at least until the RQH temporarily stopped publication in 1915. Lord Acton wrote about the German historical techniques in the first issue of the English Historical Review in 1886 which he helped found, and the William and Mary Quarterly brought the format to America in 1892.\nJournals also helped historians to establish various historiographical approaches, the most notable example of which was \"Annales. \u00c9conomies, soci\u00e9t\u00e9s, civilisations\", a publication of the \"Annales\" school in France. Journals now typically have one or more editors and associate editors, an editorial board, and a pool of scholars to whom articles that are submitted are sent for confidential evaluation. The editors will send out new books to recognized scholars for reviews that usually run 500 to 1000 words. The vetting and publication process often takes months or longer. Publication in a prestigious journal (which accept 10 percent or fewer of the articles submitted) is an asset in the academic hiring and promotion process. Publication demonstrates that the author is conversant with the scholarly field. Page charges and fees for publication are uncommon in history. Journals are subsidized by universities or historical societies, scholarly associations, and subscription fees from libraries and scholars. Increasingly they are available through library pools that allow many academic institutions to pool subscriptions to online versions. Most libraries have a system for obtaining specific articles through inter-library loan.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "13277", "revid": "1071745", "url": "https://en.wikipedia.org/wiki?curid=13277", "title": "Holy Roman Empire", "text": "European political entity (800/962\u20131806)\nThe Holy Roman Empire, also known as the Holy Roman Empire of the German Nation after 1512, was a polity in Central and Western Europe, usually headed by the Holy Roman Emperor. It developed in the Early Middle Ages (beginning in either 800 or 924), and lasted for a millennium until its dissolution in 1806 during the Napoleonic Wars. Initially, it comprised three constituent kingdoms\u2014Germany, Italy, and, from 1032, Burgundy\u2014held together by the emperor's overlordship. By the 15th century, imperial governance became concentrated in the Kingdom of Germany, as the empire's effective control over Italy and Burgundy had largely disappeared.\nOn 25 December 800, Pope Leo III crowned the Frankish king Charlemagne Roman emperor, reviving the title more than three centuries after the fall of the Western Roman Empire in 476. The title lapsed in 924, but was revived in 962 when OttoI was crowned emperor by Pope John XII, as Charlemagne's and the Carolingian Empire's successor. From 962 until the 12th century, the empire was one of the most powerful monarchies in Europe. It depended on cooperation between emperors and vassals; this was disturbed during the Salian period. The empire reached the apex of territorial expansion and power under the House of Hohenstaufen in the mid-13th century, but overextension led to a partial collapse. The imperial office was traditionally elective by the mostly German prince-electors. In theory and diplomacy, the emperors were considered the first among equals of all of Europe's Catholic monarchs.\nA process of Imperial Reform in the late 15th and early 16th centuries transformed the empire, creating a set of institutions which endured until its final demise in the 19th century. On 6 August 1806, Emperor Francis II abdicated and formally dissolved the empire following the creation by French emperor Napoleon of the Confederation of the Rhine from German client states loyal to France.\nFor most of its history the Empire comprised the entirety of the modern countries of the Czech Republic, the Netherlands, Switzerland, Luxembourg, Liechtenstein, and Monaco, almost all of Germany, Austria and Slovenia, most of Belgium and northern and central Italy, and large parts of modern-day eastern France and western Poland.\nName and general perception.\nSince Charlemagne, the realm was merely referred to as the \"Roman Empire\". The term (\"holy\", in the sense of \"consecrated\") in connection with the medieval Roman Empire was used beginning in 1157 under Frederick I Barbarossa (\"Holy Empire\"): the term was added to reflect Frederick's ambition to dominate Italy and the Papacy. The form \"Holy Roman Empire\" is attested from 1254 onward.\nThe exact term \"Holy Roman Empire\" was not used until the 13th century, before which the empire was referred to variously as (\"the whole kingdom\", as opposed to the regional kingdoms), (\"Christian empire\"), or (\"Roman empire\"), but the Emperor's legitimacy always rested on the concept of , that he held supreme power inherited from the ancient emperors of Rome.\nFrom the mid-13th century onward, the Holy Roman Empire came to be more firmly associated with a German (\"deutsch\") identity. By around 1500, contemporary sources often referred to it simply as \"Germany\", reflecting its identification as a specifically German polity. In a decree following the Diet of Cologne in 1512, the name was changed to the \"Holy Roman Empire of the German Nation\" (, ), a form first used in a document in 1474. The adoption of this new name coincided with the loss of imperial territories in Italy and Burgundy to the south and west by the late 15th century, but also to emphasize the new importance of the German Imperial Estates in ruling the Empire due to the Imperial Reform. The Hungarian denomination \"German Roman Empire\" () is the shortening of this.\nBy the end of the 18th century, the term \"Holy Roman Empire of the German Nation\" fell out of official use. Contradicting the traditional view concerning that designation, Hermann Weisert has argued in a study on imperial titulature that, despite the claims of many textbooks, the name \"Holy Roman Empire of the German Nation\" never had an official status and points out that documents were thirty times as likely to omit the national suffix as include it. Similarly, Peter Wilson states that \"of the German Nation\" was \"appended more frequently after 1512 without becoming the Empire's official title \u2013 despite numerous later claims to the contrary\", and that \"German historians are far more likely to refer to [the Empire] as 'of the German nation' than were its actual inhabitants.\" Still, the full name including \u201cof the German Nation\u201d was used in official documents and by contemporary chroniclers alike.\nIn a famous assessment of the name, the political philosopher Voltaire remarked sardonically: \"This body which was called and which still calls itself the Holy Roman Empire was in no way holy, nor Roman, nor an empire.\"\nIn the modern period, the Empire was often informally called the \"German Empire\" () or \"Roman-German Empire\" (). After its dissolution through the end of the German Empire, it was often called \"the old Empire\" (). Beginning in 1923, early twentieth-century German nationalists and Nazi Party propaganda would identify the Holy Roman Empire as the \"First\" Reich (, meaning empire), with the German Empire as the \"Second\" Reich and what would eventually become Nazi Germany as the \"Third\" Reich.\nDavid S. Bachrach opines that the Ottonian kings actually built their empire on the back of military and bureaucratic apparatuses as well as the cultural legacy they inherited from the Carolingians, who ultimately inherited these from the Late Roman Empire. He argues that the Ottonian empire was hardly an archaic kingdom of primitive Germans, maintained by personal relationships only and driven by the desire of the magnates to plunder and divide the rewards among themselves but instead, notable for their abilities to amass sophisticated economic, administrative, educational and cultural resources that they used to serve their enormous war machine.\nUntil the end of the 15th century, the empire comprised three major blocks\u2014Germany, Italy and Burgundy. Effectively, the Kingdom of Germany became the sole remaining component. The Burgundian territories were lost to France. Although the Italian territories were formally part of the empire, the territories were ignored in the Imperial Reform and splintered into numerous de facto independent territorial entities. The status of Italy in particular varied throughout the 16th to 18th centuries. Some territories like Piedmont-Savoy became increasingly independent, while others became more dependent due to the extinction of their ruling noble houses causing these territories to often fall under the dominions of the Habsburgs and their cadet branches. Barring the loss of Franche-Comt\u00e9 in 1678, the external borders of the Empire did not change noticeably from the Peace of Westphalia \u2013 which acknowledged the exclusion of Switzerland and the Northern Netherlands, and the French protectorate over Alsace \u2013 to the dissolution of the Empire. At the conclusion of the Napoleonic Wars in 1815, most of the Holy Roman Empire was included in the German Confederation, with the main exceptions being the Italian states.\nHistory.\nEarly Middle Ages.\nCarolingian Empire.\nAs Roman power in Gaul declined during the 5th century, local Germanic tribes assumed control. In the late 5th and early 6th centuries, the Merovingians, under Clovis I and his successors, consolidated Frankish tribes and extended hegemony over others to gain control of northern Gaul and the middle Rhine river valley region. By the middle of the 8th century, the Merovingians were reduced to figureheads, and the Carolingians, led by Charles Martel, became the rulers. In 751, Martel's son Pepin became King of the Franks, and later gained the sanction of the Pope. The Carolingians would maintain a close alliance with the Papacy.\nIn 768, Pepin's son Charlemagne became King of the Franks and began an extensive expansion of the realm. He eventually incorporated the territories of present-day France, Germany, northern Italy, the Low Countries and beyond, linking the Frankish kingdom with Papal lands.\nAlthough antagonism about the expense of Byzantine domination had long persisted within Italy, a political rupture was set in motion in earnest in 726 by the iconoclasm of Emperor Leo III the Isaurian, in what Pope Gregory II saw as the latest in a series of imperial heresies. In 797, the Eastern Roman Emperor Constantine VI was removed from the throne by his mother, Empress Irene, who declared herself sole ruler. As the Latin Church only regarded a male Roman emperor as the head of Christendom, Pope Leo III sought a new candidate for the dignity, excluding consultation with the patriarch of Constantinople.\nCharlemagne's good service to the Church in his defense of Papal possessions against the Lombards made him the ideal candidate. On Christmas Day of 800, Pope Leo III crowned Charlemagne emperor, restoring the title in the West for the first time in over three centuries. This can be seen as symbolic of the papacy turning away from the declining Byzantine Empire toward the new power of Carolingian Francia. Charlemagne adopted the formula (\"renewal of the Roman Empire\"). In 802, Irene was overthrown and exiled by Nikephoros I and henceforth there were two Roman emperors.\nAfter Charlemagne died in 814, the imperial crown passed to his son, Louis the Pious. Upon Louis' death in 840, it passed to his son Lothair, who had been his co-ruler. By this point the territory of Charlemagne was divided into several territories (\"cf\". Treaty of Verdun, Treaty of Pr\u00fcm, Treaty of Meerssen and Treaty of Ribemont), and over the course of the later 9th century the title of emperor was disputed by the Carolingian rulers of the Western Frankish Kingdom or West Francia and the Eastern Frankish Kingdom or East Francia, with first the western king (Charles the Bald) and then the eastern (Charles the Fat), who briefly reunited the Empire, attaining the prize. In the 9th century, Charlemagne and his successors promoted the intellectual revival, known as the Carolingian Renaissance. Some, like Mortimer Chambers, opine that the Carolingian Renaissance made possible the subsequent renaissances (even though by the early 10th century, the revival already diminished).\nAfter the death of Charles the Fat in 888, Carolingian rule in the Roman Empire came to an end. According to Regino of Pr\u00fcm, the parts of the realm \"spewed forth kinglets\", and each part elected a kinglet \"from its own bowels\". The last such emperor was Berengar I of Italy, who died in 924.\nPost-Carolingian Eastern Frankish Kingdom.\nAround 900, East Francia's autonomous stem duchies (Franconia, Bavaria, Swabia, Saxony, and Lotharingia) reemerged. After the Carolingian king Louis the Child died without issue in 911, East Francia did not turn to the Carolingian ruler of West Francia to take over the realm but instead elected one of the dukes, Conrad of Franconia, as . On his deathbed, Conrad yielded the crown to his main rival, Henry the Fowler of Saxony (r.\u2009919\u00a0\u2013\u00a0936), who was elected king at the Diet of Fritzlar in 919. Henry reached a truce with the raiding Magyars, and in 933 he won a first victory against them in the Battle of Riade.\nHenry died in 936, but his descendants, the Liudolfing (or Ottonian) dynasty, would continue to rule the Eastern kingdom or the Kingdom of Germany for roughly a century. Upon Henry the Fowler's death, Otto, his son and designated successor, was elected king in Aachen in 936. He overcame a series of revolts from a younger brother and from several dukes. After that, the king managed to control the appointment of dukes and often also employed bishops in administrative affairs. He replaced leaders of most of the major East Frankish duchies with his own relatives. At the same time, he was careful to prevent members of his own family from making infringements on his royal prerogatives.\nFormation of the Holy Roman Empire.\nIn 951, Otto came to the aid of Queen Adelaide of Italy, defeating her enemies, marrying her, and taking control over Italy. In 955, Otto won a decisive victory over the Magyars in the Battle of Lechfeld. In 962, Otto was crowned emperor by Pope John XII, thus intertwining the affairs of the German kingdom with those of Italy and the Papacy. Otto's coronation as emperor marked the German kings as successors to the empire of Charlemagne, which through the concept of , also made them consider themselves as successors to Ancient Rome. The flowering of arts beginning with Otto the Great's reign is known as the Ottonian Renaissance, centered in Germany but also happening in Northern Italy and France.\nOtto created the imperial church system, often called \"Ottonian church system of the Reich\", which tied the great imperial churches and their representatives to imperial service, thus providing \"a stable and long-lasting framework for Germany\". During the Ottonian era, imperial women played a prominent role in political and ecclesiastic affairs, often combining their functions as religious leader and advisor, regent or co-ruler, notably Matilda of Ringelheim, Eadgyth, Adelaide of Italy, Theophanu, and Matilda of Quedlinburg.\nIn 963, Otto deposed John XII and chose Leo VIII as the new pope (although John XII and Leo VIII both claimed the papacy until 964, when John XII died). This also renewed the conflict with the Byzantine emperor, especially after Otto's son Otto II (r.\u2009967\u00a0\u2013\u00a0983) adopted the designation . Still, Otto II formed marital ties with the east when he married the Byzantine princess Theophanu. Their son, Otto III, came to the throne only three years old, and was subjected to a power struggle and series of regencies until his age of majority in 994. Up to that time, he remained in Germany, while a deposed duke, Crescentius II, ruled over Rome and part of Italy, ostensibly in his stead.\nIn 996 Otto III appointed his cousin Gregory V the first German pope. A foreign pope and foreign papal officers were seen with suspicion by Roman nobles, who were led by Crescentius II to revolt. Otto III's former mentor Antipope John XVI briefly held Rome, until the Holy Roman emperor seized the city.\nOtto died young in 1002, and was succeeded by his cousin Henry II, who focused on Germany.\nOtto III's (and his mentor Pope Sylvester's) diplomatic activities coincided with and facilitated the Christianization and the spread of Latin culture in different parts of Europe. They coopted a new group of nations (Slavic) into the framework of Europe, with their empire functioning, as some remark, as a \"Byzantine-like presidency over a family of nations, centered on pope and emperor in Rome\". This has proved a lasting achievement. Though, Otto's early death made his reign \"the tale of largely unrealized potential\".\nHenry II died in 1024 and Conrad II, first of the Salian dynasty, was elected king only after some debate among dukes and nobles. This group eventually developed into the college of electors.\nThe Holy Roman Empire eventually came to be composed of four kingdoms:\nHigh Middle Ages.\nInvestiture Controversy.\nKings often employed bishops in administrative affairs and often determined who would be appointed to ecclesiastical offices. In the wake of the Cluniac Reforms, this involvement was increasingly seen as inappropriate by the Papacy. The reform-minded Pope Gregory VII was determined to oppose such practices, which led to the Investiture Controversy with King Henry IV (r.\u20091056\u00a0\u2013\u00a01106, crowned emperor in 1084).\nHenry IV repudiated the pope's interference and persuaded his bishops to excommunicate the pope, whom he famously addressed by his birth name \"Hildebrand\" rather than his papal name \"Gregory\". The pope, in turn, excommunicated the king, declared him deposed, and dissolved the oaths of loyalty made to Henry. The king found himself with almost no political support and was forced to make the famous Walk to Canossa in 1077, by which he achieved a lifting of the excommunication at the price of humiliation. Meanwhile, the German princes had elected another king, Rudolf of Swabia.\nHenry managed to defeat Rudolf, but was subsequently confronted with more uprisings, renewed excommunication, and even the rebellion of his sons. After his death, his second son, Henry V, reached an agreement with the Pope and the bishops in the 1122 Concordat of Worms. The political power of the Empire was maintained, but the conflict had demonstrated the limits of the ruler's power, especially in regard to the Church, and it robbed the king of the sacral status he had previously enjoyed. The pope and the German princes had surfaced as major players in the political system of the Holy Roman Empire.\nOstsiedlung.\nAs the result of Ostsiedlung, less populated regions of Central Europe (i.e. sparsely populated border areas in present-day Poland and the Czech Republic) received a significant number of German speakers. Silesia became part of the Holy Roman Empire as the result of the local Piast dukes' push for autonomy from the Polish Crown. From the late 12th century, the Duchy of Pomerania was under the suzerainty of the Holy Roman Empire and the conquests of the Teutonic Order made that region German-speaking.\nHohenstaufen dynasty.\nWhen the Salian dynasty ended with Henry V's death in 1125, the princes chose not to elect the next of kin, but rather Lothair III, the moderately powerful but already old duke of Saxony. When he died in 1137, the princes again aimed to check royal power; accordingly they did not elect Lothair's favoured heir, his son-in-law, Henry the Proud of the Welf family, but Conrad III of the Hohenstaufen family, the grandson of Emperor Henry IV and nephew of Emperor Henry V. This led to over a century of strife between the two houses. Conrad ousted the Welfs from their possessions, but after his death in 1152, his nephew Frederick Barbarossa succeeded him and made peace with the Welfs, restoring his cousin Henry the Lion to his \u2013 albeit diminished \u2013 possessions.\nThe Hohenstaufen rulers increasingly lent land to \"ministeriales\", formerly non-free servicemen, who Frederick hoped would be more reliable than dukes. Initially used mainly for war services, this new class of people would form the basis for the later knights, another basis of imperial power. A further important constitutional move at Roncaglia was the establishment of a new peace mechanism for the entire empire, the Landfrieden, with the first imperial one being issued in 1103 under Henry IV at Mainz. This was an attempt to abolish private feuds, between the many dukes and other people, and to tie the emperor's subordinates to a legal system of jurisdiction and public prosecution of criminal acts\u00a0\u2013 a predecessor of the modern concept of rule of law. Another new concept of the time was the systematic founding of new cities by the emperor and by the local dukes. These were partly a result of the explosion in population; they also concentrated economic power at strategic locations. Before this, cities had only existed in the form of old Roman foundations or older bishoprics. Cities that were founded in the 12th century include Freiburg, possibly the economic model for many later cities, and Munich.\nFrederick Barbarossa was crowned emperor in 1155. He emphasized the \"Romanness\" of the empire, partly in an attempt to justify the power of the emperor independent of the (now strengthened) pope. An imperial assembly at the fields of Roncaglia in 1158 reclaimed imperial rights in reference to Justinian I's Corpus Juris Civilis. Imperial rights had been referred to as \"regalia\" since the Investiture Controversy but were enumerated for the first time at Roncaglia. This comprehensive list included public roads, tariffs, coining, collecting punitive fees, and the seating and unseating of office-holders. These rights were now explicitly rooted in Roman law, a far-reaching constitutional act.\nFrederick's policies were primarily directed at Italy, where he clashed with the free-minded cities of the north, especially the Duchy of Milan. He also embroiled himself in another conflict with the Papacy by supporting a candidate elected by a minority against Pope Alexander III (1159\u20131181). Frederick supported a succession of antipopes before finally making peace with Alexander in 1177. In Germany, the emperor had repeatedly protected Henry the Lion against complaints by rival princes or cities (especially in the cases of Munich and L\u00fcbeck). Henry gave only lackluster support to Frederick's policies, and, in a critical situation during the Italian wars, Henry refused the emperor's plea for military support. After returning to Germany, an embittered Frederick opened proceedings against the duke, resulting in a public ban and the confiscation of all Henry's territories. In 1190, Frederick participated in the Third Crusade, dying in the Armenian Kingdom of Cilicia.\nDuring the Hohenstaufen period, German princes facilitated a successful, peaceful eastward settlement of lands that were uninhabited or inhabited sparsely by West Slavs. German-speaking farmers, traders, and craftsmen from the western part of the Empire, both Christians and Jews, moved into these areas. The gradual Germanization of these lands was a complex phenomenon that should not be interpreted in the biased terms of 19th-century nationalism. The eastward settlement expanded the influence of the empire to include Pomerania and Silesia, as did the intermarriage of the local, still mostly Slavic, rulers with German spouses. The Teutonic Knights were invited to Prussia by Duke Konrad of Masovia to Christianize the Prussians in 1226. The monastic state of the Teutonic Order () and its later German successor state of the Duchy of Prussia was never part of the Holy Roman Empire.\nUnder the son and successor of Frederick Barbarossa, Henry VI, the Hohenstaufen dynasty reached its apex, with the addition of the Norman kingdom of Sicily through the marriage of Henry VI and Constance of Sicily. Bohemia and Poland were under feudal dependence, while Cyprus and Lesser Armenia also paid homage. The Iberian-Moroccan caliph accepted his claims over the suzerainty over Tunis and Tripolitania and paid tribute. Fearing the power of Henry, the most powerful monarch in Europe since Charlemagne, the other European kings formed an alliance. But Henry broke this coalition by blackmailing English king Richard the Lionheart. The Byzantine emperor worried that Henry would turn his Crusade plan against his empire, and began to collect the \"alamanikon\" to prepare against the expected invasion. Henry also had plans for turning the Empire into a hereditary monarchy, although this met with opposition from some of the princes and the pope. The emperor suddenly died in 1197, leading to the partial collapse of his empire. As his son, Frederick II, though already elected king, was still a small child and living in Sicily, German princes chose to elect an adult king, resulting in the dual election of Frederick Barbarossa's youngest son Philip of Swabia and Henry the Lion's son Otto of Brunswick, who competed for the crown. After Philip was murdered in a private squabble in 1208, Otto prevailed for a while, until he began to also claim Sicily.\nPope Innocent III, who feared the threat posed by a union of the empire and Sicily, was now supported by Frederick II, who marched to Germany and defeated Otto. After his victory, Frederick did not act upon his promise to keep the two realms separate. Though he had made his son Henry king of Sicily before marching on Germany, he still reserved real political power for himself. This continued after Frederick was crowned emperor in 1220. Fearing Frederick's concentration of power, the pope finally excommunicated him. Another point of contention was the Crusade, which Frederick had promised but repeatedly postponed. Now, although excommunicated, Frederick led the Sixth Crusade in 1228, which ended in negotiations and a temporary restoration of the Kingdom of Jerusalem.\nFor his many-sided activities, prestige, and dynamic personality Frederick II has been called the greatest of all the medieval German emperors. In the Kingdom of Sicily and much of Italy, Frederick built upon the work of his Norman predecessors and forged an early absolutist state bound together by an efficient secular bureaucracy. Despite his imperial prestige and power, Frederick II's rule was a major turning point toward the partitioning of central rule in the Empire. Since his political focus was south of the Alps, he was mostly absent from Germany and issued far-reaching privileges to Germany's secular and ecclesiastical princes to ensure their cooperation. In the 1220 , Frederick gave up a number of \"regalia\" in favour of the bishops, among them tariffs, coining, and the right to build fortification. The 1232 mostly extended these privileges to secular territories. Although many of these privileges had existed earlier, they were now granted globally, and once and for all, to allow the German princes to maintain order north of the Alps while Frederick concentrated on Italy. The 1232 document marked the first time that the German dukes were called , owners of their lands, a remarkable change in terminology as well. the affirmed a division of labor between the emperor and the princes and laid much groundwork for the development of particularism in Germany. Even so, from 1232 the vassals of the emperor had a veto over imperial legislative decisions and any new law established by the emperor had to be approved by the princes.\nThese provisions not withstanding, royal power in Germany remained strong under Frederick and by the 1240s the crown was still rich in fiscal resources, land holdings, retinues, and all other rights, revenues, and jurisdictions. Frederick II used the political loyalty and practical jurisdictions granted to the higher German aristocracy to impose peace, order, and justice upon Germany. The jurisdictional autarky of the German princes was favoured by the crown itself in the twelfth and thirteenth centuries in the interests of order and local peace. The inevitable result was the territorial particularism of churchmen, lay princes, and interstitial cities. However, Frederick was a ruler of vast territories and \"could not be everywhere at once\". The transference of jurisdiction was a practical solution to secure the further support of the German princes and, moreover, was a process which had already been underway even under Henry VI and Frederick Barbarossa. It is unlikely that a particularly \"strong ruler\" such as Frederick II would have even pragmatically agreed to legislation that was truly concessionary rather than cooperative, neither would the princes have insisted on such. The Mainz Landfriede or , decreed at the Imperial Diet of 1235, became one of the basic laws of the empire and provided that the princes should share the burden of local government in Germany. The authority of the crown was not in question, rather its practical allocation in such a wide region which lacked a general administrative apparatus. Far from a broad diminution of royal power, the Mainz Landfriede was a constitutional recalibration based on the culmination of multi-decade political realities and a testament to Frederick II's considerable political strength, his increased prestige during the early 1230s, and sheer overpowering might that he succeeded in securing the princes' support and rebound them to Hohenstaufen power.\nKingdom of Bohemia.\nThe Kingdom of Bohemia was a significant regional power during the Middle Ages. In 1212, King Ottokar I (bearing the title \"king\" since 1198) extracted a Golden Bull of Sicily (a formal edict) from Emperor Frederick II, confirming the royal title for Ottokar and his descendants, and the Duchy of Bohemia was raised to a kingdom. Bohemia's political and financial obligations to the Empire were gradually reduced. Charles IV set Prague to be the seat of the Holy Roman emperor.\nInterregnum.\nAfter the death of Frederick II in 1250, Conrad IV, Frederick's son (died 1254), enjoyed a strong position having defeated his papal-backed rival anti-king, William of Holland (died 1256). However, Conrad's death was followed by the Interregnum, during which no king could achieve universal recognition, allowing the princes to consolidate their holdings and become even more independent as rulers. After 1257, the crown was contested between Richard of Cornwall, who was supported by the Guelph party, and Alfonso X of Castile, who was recognized by the Hohenstaufen party but never set foot on German soil. After Richard's death in 1273, Rudolf I of Germany, a minor pro-Hohenstaufen count, was elected. He was the first of the Habsburgs to hold a royal title, but he was never crowned emperor. After Rudolf's death in 1291, Adolf and Albert were two further weak kings who were never crowned emperor.\nAlbert was assassinated in 1308. Almost immediately, King Philip IV of France began aggressively seeking support for his brother, Charles of Valois, to be elected the next king of the Romans. Philip thought he had the backing of the French Pope, Clement V (established at Avignon in 1309), and that his prospects of bringing the empire into the orbit of the French royal house were good. He lavishly spread French money in the hope of bribing the German electors. Although Charles of Valois had the backing of pro-French Henry, Archbishop of Cologne, many were not keen to see an expansion of French power, least of all Clement V. The principal rival to Charles appeared to be Count Palatine Rudolf II.\nBut the electors, the great territorial magnates who had lived without a crowned emperor for decades, were unhappy with both Charles and Rudolf. Instead Count Henry of Luxembourg, with the aid of his brother, Archbishop Baldwin of Trier, was elected as Henry VII with six votes at Frankfurt on 27 November 1308. Though a vassal of King Philip, Henry was bound by few national ties, and thus suitable as a compromise candidate. Henry VII was crowned king at Aachen on 6 January 1309, and emperor by Pope Clement V on 29 June 1312 in Rome, ending the interregnum.\nChanges in political structure.\nDuring the 13th century, a general structural change in how land was administered prepared the shift of political power toward the rising bourgeoisie at the expense of the aristocratic feudalism that would characterize the Late Middle Ages. The rise of the cities and the emergence of the new burgher class eroded the societal, legal and economic order of feudalism.\nPeasants were increasingly required to pay tribute to their landlords. The concept of property began to replace more ancient forms of jurisdiction, although they were still very much tied together. In the territories (not at the level of the Empire), power became increasingly bundled: whoever owned the land had jurisdiction, from which other powers derived. Jurisdiction at the time did not include legislation, which was virtually nonexistent until well into the 15th century. Court practice heavily relied on traditional customs or rules described as customary.\nDuring this time, territories began to transform into the predecessors of modern states. The process varied greatly among the various lands and was most advanced in those territories that were almost identical to the lands of the old Germanic tribes, \"e.g.\", Bavaria. It was slower in those scattered territories that were founded through imperial privileges.\nIn the 12th century the Hanseatic League established itself as a commercial and defensive alliance of the merchant guilds of towns and cities in the empire and all over northern and central Europe. It dominated marine trade in the Baltic Sea, the North Sea and along the connected navigable rivers. Each of the affiliated cities retained the legal system of its sovereign and, with the exception of the Free imperial cities, had only a limited degree of political autonomy. By the late 14th century, the powerful league enforced its interests with military means, if necessary. This culminated in the Danish\u2013Hanseatic War from 1361 to 1370. The league declined after 1450.\nLate Middle Ages.\nRise of the territories after the Hohenstaufens.\nThe difficulties in electing the king eventually led to the emergence of a fixed college of prince-electors (\"Kurf\u00fcrsten\"), whose composition and procedures were set forth in the Golden Bull of 1356, issued by Charles IV (reigned 1355\u20131378, King of the Romans since 1346), which remained valid until 1806. This development probably best symbolizes the emerging duality between emperor and realm (\"Kaiser und Reich\"), which were no longer considered identical. The Golden Bull also set forth the system for election of the Holy Roman Emperor. The emperor now was to be elected by a majority rather than by consent of all seven electors. For electors the title became hereditary, and they were given the right to mint coins and to exercise jurisdiction. Also it was recommended that their sons learn the imperial languages \u2013 German, Latin, Italian, and Czech. The decision by Charles IV is the subject of debates: on one hand, it helped to restore peace in the lands of the Empire, that had been engulfed in civil conflicts after the end of the Hohenstaufen era; on the other hand, the \"blow to central authority was unmistakable\". Thomas Brady Jr. opines that Charles IV's intention was to end contested royal elections (from the Luxembourghs' perspective, they also had the advantage that the King of Bohemia had a permanent and preeminent status as one of the Electors himself). At the same time, he built up Bohemia as the Luxembourghs' core land of the Empire and their dynastic base. His reign in Bohemia is often considered the land's Golden Age. According to Brady Jr. though, under all the glitter, one problem arose: the government showed an inability to deal with the German immigrant waves into Bohemia, thus leading to religious tensions and persecutions. The imperial project of the Luxembourgh halted under Charles's son Wenceslaus (reigned 1378\u20131419 as King of Bohemia, 1376\u20131400 as King of the Romans), who also faced opposition from 150 local baronial families.\nThe shift in power away from the emperor is also revealed in the way the post-Hohenstaufen kings attempted to sustain their power. Earlier, the Empire's strength (and finances) greatly relied on the Empire's own lands, the so-called \"Reichsgut\", which always belonged to the king of the day and included many Imperial Cities. After the 13th century, the relevance of the \"Reichsgut\" faded, even though some parts of it did remain until the Empire's end in 1806. Instead, the \"Reichsgut\" was increasingly pawned to local dukes, sometimes to raise money for the Empire, but more frequently to reward faithful duty or as an attempt to establish control over the dukes. The direct governance of the \"Reichsgut\" no longer matched the needs of either the king or the dukes.\nThe kings beginning with Rudolf I of Germany increasingly relied on the lands of their respective dynasties to support their power. In contrast with the \"Reichsgut\", which was mostly scattered and difficult to administer, these territories were relatively compact and thus easier to control. In 1282, Rudolf I thus lent Austria and Styria to his own sons. In 1312, Henry VII of the House of Luxembourg was crowned as the first Holy Roman Emperor since Frederick II. After him all kings and emperors relied on the lands of their own family (\"Hausmacht\"): Louis IV of Wittelsbach (king 1314, emperor 1328\u20131347) relied on his lands in Bavaria; Charles IV of Luxembourg, the grandson of Henry VII, drew strength from his own lands in Bohemia. It was thus increasingly in the king's own interest to strengthen the power of the territories, since the king profited from such a benefit in his own lands as well.\nImperial Reform.\nThe \"constitution\" of the Empire still remained largely unsettled at the beginning of the 15th century. Feuds often happened between local rulers. The \"robber baron\" (\"Raubritter\") became a social factor.\nSimultaneously, the Catholic Church experienced crises of its own, with wide-reaching effects in the Empire. The conflict between several papal claimants (two anti-popes and the \"legitimate\" Pope) ended only with the Council of Constance (1414\u20131418); after 1419 the Papacy directed much of its energy to suppressing the Hussites. The medieval idea of unifying all Christendom into a single political entity, with the Church and the Empire as its leading institutions, began to decline.\nWith these drastic changes, much discussion emerged in the 15th century about the Empire itself. Rules from the past no longer adequately described the structure of the time, and a reinforcement of earlier \"Landfrieden\" was urgently needed.\nThe vision for a simultaneous reform of the Empire and the Church on a central level began with Sigismund (reigned 1433\u20131437, King of the Romans since 1411), who, according to historian Thomas Brady Jr., \"possessed a breadth of vision and a sense of grandeur unseen in a German monarch since the thirteenth century\". But external difficulties, self-inflicted mistakes and the extinction of the Luxembourg male line made this vision unfulfilled.\nFrederick III was the first Habsburg to be crowned Holy Roman Emperor, in 1452. He had been very careful regarding the reform movement in the empire. For most of his reign, he considered reform as a threat to his imperial prerogatives. He avoided direct confrontations, which might lead to humiliation if the princes refused to give way. After 1440, the reform of the Empire and Church was sustained and led by local and regional powers, particularly the territorial princes. In his last years, he felt more pressure on taking action from a higher level. Berthold von Henneberg, the Archbishop of Mainz, who spoke on behalf of reform-minded princes (who wanted to reform the Empire without strengthening the imperial hand), capitalized on Frederick's desire to secure the imperial election for his son Maximilian. Thus, in his last years, he presided over the initial phase of Imperial Reform, which would mainly unfold under Maximilian. Maximilian himself was more open to reform, although naturally he also wanted to preserve and enhance imperial prerogatives. After Frederick retired to Linz in 1488, as a compromise, Maximilian acted as mediator between the princes and his father. When he attained sole rule after Frederick's death, he would continue this policy of brokerage, acting as the impartial judge between options suggested by the princes.\nCreation of institutions.\nMajor measures for the Reform were launched at the 1495 Reichstag at Worms. A new organ was introduced, the \"Reichskammergericht\", that was to be largely independent from the Emperor. A new tax was launched to finance it, the \"Gemeine Pfennig\", although this would only be collected under Charles V and Ferdinand I, and not fully.\nTo create a rival for the \"Reichskammergericht\", Maximilian established the \"Reichshofrat\" in 1497, which had its seat in Vienna. During Maximilian's reign, this council was not popular though. In the long run, the two Courts functioned in parallel, sometimes overlapping.\nIn 1500, Maximilian agreed to establish an organ called the \"Reichsregiment\" (central imperial government, consisting of twenty members including the Electors, with the Emperor or his representative as its chairman), first organized in 1501 in Nuremberg. But Maximilian resented the new organization, while the Estates failed to support it. The new organ proved politically weak, and its power returned to Maximilian in 1502.\nThe most important governmental changes targeted the heart of the regime: the chancery. Early in Maximilian's reign, the Court Chancery at Innsbruck competed with the Imperial Chancery (which was under the elector-archbishop of Mainz, the senior Imperial chancellor). By referring the political matters in Tyrol, Austria as well as Imperial problems to the Court Chancery, Maximilian gradually centralized its authority. The two chanceries became combined in 1502. In 1496, the emperor created a general treasury (\"Hofkammer\") in Innsbruck, which became responsible for all the hereditary lands. The chamber of accounts (\"Raitkammer\") at Vienna was made subordinate to this body. Under Paul von Liechtenstein, the \"Hofkammer\" was entrusted with not only hereditary lands' affairs, but Maximilian's affairs as the German king too.\nReception of Roman law.\nAt the 1495 Diet of Worms, the Reception of Roman Law was accelerated and formalized. The Roman Law was made binding in German courts, except in the case it was contrary to local statutes. In practice, it became the basic law throughout Germany, displacing Germanic local law to a large extent, although Germanic law was still operative at the lower courts. Other than the desire to achieve legal unity and other factors, the adoption also highlighted the continuity between the Ancient Roman empire and the Holy Roman Empire. To realize his resolve to reform and unify the legal system, the emperor frequently intervened personally in matters of local legal matters, overriding local charters and customs. This practice was often met with irony and scorn from local councils, who wanted to protect local codes.\nThe legal reform seriously weakened the ancient Vehmic court (\"Vehmgericht\", or Secret Tribunal of Westphalia, traditionally held to be instituted by Charlemagne but this theory is now considered unlikely), although it would not be abolished completely until 1811 (when it was abolished under the order of J\u00e9r\u00f4me Bonaparte).\nNational political culture.\nMaximilian and Charles V (despite the fact both emperors were internationalists personally) were the first who mobilized the rhetoric of the Nation, firmly identified with the Reich by the contemporary humanists. With encouragement from Maximilian and his humanists, iconic spiritual figures were reintroduced or became notable. The humanists rediscovered the work \"Germania\", written by Tacitus. According to Peter H. Wilson, the female figure of Germania was reinvented by the emperor as the virtuous pacific Mother of Holy Roman Empire of the German Nation. Whaley further suggests that, despite the later religious divide, \"patriotic motifs developed during Maximilian's reign, both by Maximilian himself and by the humanist writers who responded to him, formed the core of a national political culture.\"\nMaximilian's reign also witnessed the gradual emergence of the German common language, with the notable roles of the imperial chancery and the chancery of the Wettin Elector Frederick the Wise. The development of the printing industry together with the emergence of the postal system (the first modern one in the world), initiated by Maximilian himself with contribution from Frederick III and Charles the Bold, led to a revolution in communication and allowed ideas to spread. Unlike the situation in more centralized countries, the decentralized nature of the Empire made censorship difficult.\nTerence McIntosh comments that the expansionist, aggressive policy pursued by Maximilian I and Charles V at the inception of the early modern German nation (although not to further the aims specific to the German nation per se), relying on German manpower as well as utilizing fearsome Landsknechte and mercenaries, would affect the way neighbours viewed the German polity, although in the longue dur\u00e9e, Germany tended to be at peace.\nImperial power.\nMaximilian was \"the first Holy Roman Emperor in 250 years who ruled as well as reigned\". In the early 1500s, he was true master of the Empire, although his power weakened during the last decade before his death. Whaley notes that, despite struggles, what emerged at the end of Maximilian's rule was a strengthened monarchy and not an oligarchy of princes. Benjamin Curtis opines that while Maximilian was not able to fully create a common government for his lands (although the chancellery and court council were able to coordinate affairs across the realms), he strengthened key administrative functions in Austria and created central offices to deal with financial, political and judicial matters \u2013 these offices replaced the feudal system and became representative of a more modern system that was administered by professionalized officials. After two decades of reforms, the emperor retained his position as first among equals, while the empire gained common institutions through which the emperor shared power with the estates.\nBy the early 16th century, the Habsburg rulers had become the most powerful in Europe, but their strength relied on their composite monarchy as a whole, and not only the Holy Roman Empire (see also: Empire of Charles V). Maximilian had seriously considered combining the Burgundian lands (inherited from his wife Mary of Burgundy) with his Austrian lands to form a powerful core (while also extending toward the east). After the unexpected addition of Spain to the Habsburg Empire, at one point he intended to leave Austria (raised to a kingdom) to his younger grandson Ferdinand. His elder grandson Charles V later gave Spain and most of the Burgundian lands to his son Philip II of Spain, the founder of the Spanish branch, and the Habsburg hereditary lands to his brother Ferdinand, the founder of the Austrian branch.\nIn France and England, from the 13th century onward, stationary royal residences had begun to develop into capital cities that grew rapidly and developed corresponding infrastructure: the \"Palais de la Cit\u00e9\" and the \"Palace of Westminster\" became the respective main residences. This was not possible in the Holy Roman Empire because no real hereditary monarchy emerged, but rather the tradition of elective monarchy prevailed \"(see: Imperial election)\" which, in the High Middle Ages, led to kings of very different regional origins being elected \"(List of royal and imperial elections in the Holy Roman Empire)\". If they wanted to control the empire and its rebellious regional rulers, they could not limit themselves to their home region and their private palaces. As a result, kings and emperors continued to travel around the empire well into modern times, using their temporary residences \"(Kaiserpfalz)\" as transit stations for their \"itinerant courts\". From the late Middle Ages onward, the weakly fortified \"pfalzen\" were replaced by imperial castles. It was only King Ferdinand I, the younger brother of the then Emperor Charles V, who moved his main residence to the Vienna Hofburg in the middle of the 16th century, where most of the following Habsburg emperors subsequently resided. Vienna did not become the capital of the empire, just of a Habsburg hereditary state (the Archduchy of Austria). The emperors continued to travel to their elections and coronations at Frankfurt and Aachen, to the Imperial Diets at different places and to other occasions. The Perpetual Diet of Regensburg was based in Regensburg from 1663 to 1806. Rudolf II resided in Prague, the Wittelsbach emperor Charles VII in Munich. A German capital in the true sense only existed in the Second German Empire from 1871, when the Kaiser, Reichstag and Reichskanzler resided in Berlin.\nEarly capitalism.\nWhile particularism prevented the centralization of the Empire, it gave rise to early developments of capitalism. In Italian and Hanseatic cities like Genoa and Pisa, Hamburg and L\u00fcbeck, warrior-merchants appeared and pioneered raiding-and-trading maritime empires. These practices declined before 1500, but they managed to spread to the maritime periphery in Portugal, Spain, the Netherlands and England, where they \"provoked emulation in grander, oceanic scale\". William Thompson agrees with M.N. Pearson that this distinctively European phenomenon happened because in the Italian and Hanseatic cities which lacked resources and were \"small in size and population\", the rulers (whose social status was not much higher than the merchants) had to pay attention to trade. Thus the warrior-merchants gained the state's coercive powers, which they could not gain in Mughal or other Asian realms \u2013 whose rulers had few incentives to help the merchant class, as they controlled considerable resources and their revenue was land-bound.\nIn the 1450s, the economic development in Southern Germany gave rise to banking empires, cartels and monopolies in cities such as Ulm, Regensburg, and Augsburg. Augsburg in particular, associated with the reputation of the Fugger, Welser and Baumgartner families, is considered the capital city of early capitalism. Augsburg benefitted majorly from the establishment and expansion of the Kaiserliche Reichspost in the late 15th and early 16th century. Even when the Habsburg empire began to extend to other parts of Europe, Maximilian's loyalty to Augsburg, where he conducted a lot of his endeavours, meant that the imperial city became \"the dominant centre of early capitalism\" of the 16th century, and \"the location of the most important post office within the Holy Roman Empire\". From Maximilian's time, as the \"terminuses of the first transcontinental post lines\" began to shift from Innsbruck to Venice and from Brussels to Antwerp, in these cities, the communication system and the news market started to converge. As the Fuggers as well as other trading companies based their most important branches in these cities, these traders gained access to these systems as well. The 1557, 1575 and 1607 bankruptcies of the Spanish branch of the Habsburgs though damaged the Fuggers substantially. Moreover, \"Discovery of water routes to India and the New World shifted the focus of European economic development from the Mediterranean to the Atlantic \u2013 emphasis shifted from Venice and Genoa to Lisbon and Antwerp. Eventually American mineral developments reduced the importance of Hungarian and Tyrolean mineral wealth. The nexus of the European continent remained landlocked until the time of expedient land conveyances in the form of primarily rail and canal systems, which were limited in growth potential; in the new continent, on the other hand, there were ports in abundance to release the plentiful goods obtained from those new lands.\" The economic pinnacles achieved in Germany in the period between 1450 and 1550 would not be seen again until the end of the 19th century.\nIn the Netherlands part of the empire, financial centres evolved together with markets of commodities. Topographical development in the 15th century made Antwerp a port city. Boosted by the privileges it received as a loyal city after the Flemish revolts against Maximilian, it became the leading seaport city in Northern Europe and served as \"the conduit for a remarkable 40% of world trade\". Conflicts with the Habsburg-Spanish government in 1576 and 1585 though made merchants relocate to Amsterdam, which eventually replaced it as the leading port city.\nReformation and Renaissance.\nIn 1516, Ferdinand II of Aragon died. His grandson Charles would go on to inherit the thrones of Castile and Aragon (with his mother Joanna of Castile), despite only being a teenager at the time. This succession to both thrones would later evolve into the union of Spain. Another important event happened in 1517: Martin Luther launched what would later be known as the Protestant Reformation. The Reformation divided the Empire along religious lines as it proceeded, with the north, the east, and many of the major cities \u2013 Strasbourg, Frankfurt, and Nuremberg \u2013 becoming Protestant while the southern and western regions largely remained Catholic.\nMaximilian died in 1519, triggering an election for the next Emperor. Charles was Ferdinand's grandson on his mother's side, but Maximilian's grandson on his father's side, and was one of the two main candidates for the position along with Francis I of France. Charles won the election, becoming Charles V, Holy Roman Emperor; he traveled to Germany in 1520.\nAt the beginning of Charles's reign, another \"Reichsregiment\" was set up again (1522), although Charles declared that he would only tolerate it in his absence and its chairman had to be a representative of his. Charles V was absent in Germany from 1521 to 1530. Similar to the one set up in the early 1500s, the \"Reichsregiment\" failed to create a federal authority independent of the emperor, due to the unsteady participation and differences between princes. Charles V defeated the Protestant princes in 1547 in the Schmalkaldic War, but the momentum was lost and the Protestant estates were able to survive politically despite military defeat. In the 1555 Peace of Augsburg, Charles V, through his brother Ferdinand, officially recognized the right of rulers to choose Catholicism or Lutheranism (Zwinglians, Calvinists and radicals were not included). In 1555, Paul IV was elected pope and took the side of France, whereupon an exhausted Charles finally gave up his hopes of a world Christian empire.\nThe succession Charles V arranged split the Habsburgs into two branches. The senior branch continued to rule in Spain and in the Burgundian inheritance, headed by Charles's son, Philip II of Spain. The Holy Roman Empire went to a junior branch of the Habsburgs, Charles's brother Ferdinand I. Many factors contribute to this result. For James D. Tracy, it was the polycentric character of the European civilization that made it hard to maintain \"a dynasty whose territories bestrode the continent from the Low Countries to Sicily and from Spain to Hungary\u00a0\u2013 not to mention Spain's overseas possessions\". Others point out the religious tensions, fiscal problems and obstruction from external forces including France and the Ottomans. On a more personal level, Charles failed to persuade the German princes to support his son Philip, whose \"awkward and withdrawn character and lack of German language skills doomed this enterprise to failure\".\nBaroque period.\nGermany would enjoy relative peace for the next six decades. On the eastern front, the Turks continued to loom large as a threat, although war would mean further compromises with the Protestant princes, and so the Emperor sought to avoid it. In the west, the Rhineland increasingly fell under French influence. After the Dutch revolt against Spain erupted, the Empire remained neutral, allowing the Netherlands to depart the empire in 1581. A side effect was the Cologne War, which ravaged much of the upper Rhine. Emperor Ferdinand III formally accepted Dutch neutrality in 1653, a decision ratified by the Reichstag in 1728.\nAfter Ferdinand died in 1564, his son Maximilian II became Emperor, and like his father accepted the existence of Protestantism and the need for occasional compromise with it. Maximilian was succeeded in 1576 by Rudolf II, who preferred classical Greek philosophy to Christianity and lived an isolated existence in Bohemia. He became afraid to act when the Catholic Church was forcibly reasserting control in Austria and Hungary, and the Protestant princes became upset over this.\nImperial power sharply deteriorated by the time of Rudolf's death in 1612. When Bohemians rebelled against the Emperor, the immediate result was the series of conflicts known as the Thirty Years' War (1618\u20131648), which devastated the empire. Foreign powers, including France and Sweden, intervened in the conflict and strengthened those fighting the Imperial power, but also seized considerable territory for themselves. Accordingly, the empire could never return to its former glory, leading Voltaire to make his infamous quip that the Holy Roman Empire was \"neither Holy nor Roman nor an Empire.\"\nStill, its actual end did not come for two centuries. The Peace of Westphalia in 1648, which ended the Thirty Years' War allowed Calvinism, but Anabaptists, Arminians and other Protestant communities would still lack any support and continue to be persecuted well until the end of the empire. The Habsburg emperors focused on consolidating their own estates in Austria and elsewhere.\nAt the Battle of Vienna (1683), the Army of the Holy Roman Empire, led by the Polish King John III Sobieski, decisively defeated a large Turkish army, stopping the western Ottoman advance and leading to the eventual dismemberment of the Ottoman Empire in Europe. The army was one third forces of the Polish\u2013Lithuanian Commonwealth and two thirds forces of the Holy Roman Empire.\nModern period.\nPrussia and Austria.\nBy the rise of Louis XIV, the Habsburgs were chiefly dependent on their hereditary lands to counter the rise of Prussia, which possessed territories inside the Empire. Throughout the 18th century, the Habsburgs were embroiled in various European conflicts, such as the War of the Spanish Succession (1701\u20131714), the War of the Polish Succession (1733\u20131735), and the War of the Austrian Succession (1740\u20131748). The rivalry between Austria and Prussia dominated the empire's history after 1740.\nFrench Revolutionary Wars and final dissolution.\nFrom 1792 onward, revolutionary France was at war with various parts of the Empire intermittently.\nThe German mediatization was the series of mediatizations and secularizations that occurred between 1795 and 1814, during the latter part of the era of the French Revolution and then the Napoleonic era. \"Mediatization\" was the process of annexing the lands of one imperial estate to another, often leaving the annexed some rights. For example, the estates of the Imperial Knights were formally mediatized in 1806, having been seized by the great territorial states in 1803 in the so-called \"Rittersturm\". \"Secularization\" was the abolition of the temporal power of an ecclesiastical ruler such as a bishop or an abbot and the annexation of the secularized territory to a secular territory.\nThe empire was dissolved on 6 August 1806, when the last Holy Roman Emperor Francis II (from 1804, Emperor Francis I of Austria) abdicated, following a military defeat by the French under Napoleon at the Battle of Austerlitz in 1805 (see Treaty of Pressburg). Napoleon reorganized much of the Empire into the Confederation of the Rhine, a French satellite. Francis' House of Habsburg-Lorraine survived the demise of the empire, continuing to reign as Emperors of Austria and Kings of Hungary until the Habsburg empire's final dissolution in 1918 in the aftermath of World War I.\nThe Napoleonic Confederation of the Rhine was replaced by a new union, the German Confederation in 1815, following the end of the Napoleonic Wars. It lasted until 1866 when Prussia founded the North German Confederation, a forerunner of the German Empire which united the German-speaking territories outside of Austria and Switzerland under Prussian leadership in 1871. This state developed into modern Germany.\nThe abdication indicated that the Kaiser no longer felt capable of fulfilling his duties as head of the Reich, and so declared:\n\"That we consider the tie that has bound us to the body politic of the German Reich to be broken, that we have expired the office and dignity of the head of the Reich through the unification of the confederated Rhenish estates and that we are thereby relieved of all the duties we have assumed towards the German Reich Consider counted, and lay down the imperial crown worn by the same until now and conducted imperial government, as is hereby done.\"\nThe only princely member states of the Holy Roman Empire that have preserved their status as monarchies until today are the Grand Duchy of Luxembourg and the Principality of Liechtenstein. The only Free Imperial Cities still existing as states within Germany are Hamburg and Bremen. All other historic member states of the Holy Roman Empire were either dissolved or have adopted republican systems of government.\nDemographics.\nPopulation.\nOverall population figures for the Holy Roman Empire are extremely vague and vary widely. The empire of Charlemagne may have had as many as 20 million people. Given the political fragmentation of the later Empire, there were no central agencies that could compile such figures. Nevertheless, it is believed the demographic disaster of the Thirty Years' War meant that the population of the Empire in the early 17th century was similar to what it was in the early 18th century; by one estimate, the Empire did not exceed 1618 levels of population until 1750.\nIn the early 17th century, the electors held under their rule the following number of Imperial subjects:\nWhile not electors, the Spanish Habsburgs had the second highest number of subjects within the Empire after the Austrian Habsburgs, with over 3 million in the early 17th century in the Burgundian Circle and Duchy of Milan.\nPeter Wilson estimates the Empire's population at 20 million in 1700, plus 5 million in Imperial Italy, a total of around 25 million. By 1800 he estimates the Empire's population at 29 million (excluding Italy), with another 12.6 million held by under Austrian and Prussian dominion outside of the Empire.\nAccording to a contemporary estimate of the Austrian War Archives for the first decade of the 18th century, the Empire\u00a0\u2013 including Bohemia and the Spanish Netherlands\u00a0\u2013 had a population of close to 28\u00a0million with a breakdown as follows:\nGerman demographic historians have traditionally worked on estimates of the population of the Holy Roman Empire based on assumed population within the frontiers of Germany in 1871 or 1914. More recent estimates use less outdated criteria, but they remain guesswork. One estimate based on the frontiers of Germany in 1870 gives a population of some 15\u201317\u00a0million around 1600, declined to 10\u201313\u00a0million around 1650 (following the Thirty Years' War). Other historians who work on estimates of the population of the early modern Empire suggest the population declined from 20\u00a0million to some 16\u201317million by 1650.\nA credible estimate for 1800 gives 27\u201328million inhabitants for the Empire (which at this point had already lost the remaining Low Countries, Italy, and the Left Bank of the Rhine in the 1797 Treaty of Campo Formio) with an overall breakdown as follows:\nThere are also numerous estimates for the Italian states that were formally part of the Empire:\nLargest cities.\nLargest cities or towns of the Empire by year:\nReligion.\nCatholicism constituted the single official religion of the Empire until 1555; the Holy Roman Emperor was always Catholic.\nLutheranism was officially recognized in the Peace of Augsburg of 1555, and Calvinism in the Peace of Westphalia of 1648. Those two constituted the only officially recognized Protestant denominations, while various other Protestant confessions such as Anabaptism, Arminianism, etc. coexisted illegally within the Empire. Anabaptism came in a variety of denominations, including Mennonites, Schwarzenau Brethren, Hutterites, the Amish, and multiple other groups.\nFollowing the Peace of Augsburg, the official religion of a territory was determined by the principle according to which a ruler's religion determined that of his subjects. The Peace of Westphalia abrogated that principle by stipulating that the official religion of a territory was to be what it had been on 1 January 1624, considered to have been a \"normal year\". Henceforth, the conversion of a ruler to another faith did not entail the conversion of his subjects.\nIn addition, all Protestant subjects of a Catholic ruler and vice versa were guaranteed the rights that they had enjoyed on that date. While the adherents of a territory's official religion enjoyed the right of public worship, the others were allowed the right of private worship (in chapels without either spires or bells). In theory, no one was to be discriminated against or excluded from commerce, trade, craft or public burial on grounds of religion. For the first time, the permanent nature of the division between the Christian churches of the empire was more or less assumed.\nA Jewish minority existed in the Holy Roman Empire. The Holy Roman Emperors claimed the right of protection and taxation of all the Jews of the empire, but there were also large-scale massacres of Jews, especially at the time of the First Crusade and during the wars of religion in the 16th century.\nInstitutions.\nThe Holy Roman Empire was neither a centralized state nor a nation-state. Instead, it was divided into dozens \u2013 eventually hundreds \u2013 of individual entities governed by kings, dukes, counts, bishops, abbots, and other rulers, collectively known as princes. There were also some areas ruled directly by the Emperor.\nFrom the High Middle Ages onwards, the Holy Roman Empire was marked by an uneasy coexistence with the princes of the local territories who were struggling to take power away from it. To a greater extent than in other medieval kingdoms such as France and England, the emperors were unable to gain much control over the lands that they formally owned. Instead, to secure their own position from the threat of being deposed, emperors were forced to grant more and more autonomy to local rulers, both nobles and bishops. This process began in the 11th century with the Investiture Controversy and was more or less concluded with the 1648 Peace of Westphalia. Several Emperors attempted to reverse this steady dilution of their authority but were thwarted both by the papacy and by the princes of the Empire.\nImperial estates.\nThe number of territories represented in the Imperial Diet was considerable, numbering about 300 at the time of the Peace of Westphalia. Many of these \"Kleinstaaten\" (\"little states\") covered no more than a few square miles, or included several non-contiguous pieces, so the Empire was often called a (\"patchwork carpet\").\nAn entity was considered a (imperial estate) if, according to feudal law, it had no authority above it except the Holy Roman Emperor himself. The imperial estates comprised:\nA sum total of 1,500 Imperial estates has been reckoned. For a list of in 1792, see List of Imperial Diet participants (1792).\nThe most powerful lords of the later empire were the Austrian Habsburgs, who ruled of land within the Empire in the first half of the 17th century, mostly in modern-day Austria and the Czech Republic. At the same time the lands ruled by the electors of Saxony, Bavaria, and Brandenburg (prior to the acquisition of Prussia) were all close to ; the Duke of Brunswick-L\u00fcneburg (later the Elector of Hanover) had a territory around the same size. These were the largest of the German realms. The Elector of the Palatinate had significantly less at , and the ecclesiastical Electorates of Mainz, Cologne, and Trier were much smaller, with around . Just larger than them, with roughly , were the Duchy of W\u00fcrttemberg, the Landgraviate of Hessen-Kassel, and the Duchy of Mecklenburg-Schwerin. They were roughly matched in size by the prince-bishoprics of Salzburg and M\u00fcnster. The majority of the other German territories, including the other prince-bishoprics, were under , the smallest being those of the Imperial Knights; around 1790 the Knights consisted of 350 families ruling a total of only collectively. Imperial Italy was less fragmented politically, most of it c.\u20091600 being divided between Savoy (Savoy, Piedmont, Nice, Aosta), the Grand Duchy of Tuscany (Tuscany, bar Lucca), the Republic of Genoa (Liguria, Corisca), the duchies of Modena-Reggio and Parma-Piacenza (Emilia), and the Spanish Duchy of Milan (most of Lombardy), each with between half a million and one and a half million people. The Low Countries were also more coherent than Germany, being entirely under the dominion of the Spanish Netherlands as part of the Burgundian Circle, at least nominally.\nIn 1792, 21 families (8 electors and 13 princely families) held 81 percent of the Empire's territory, plus all electoral and 56 of the 100 princely votes. These 21 families held 25 territories (some families had cadet branches e.g. the Bavarian and Palatinate Wittelsbachs), by far the largest being Austria and Prussia. Another 16.4 percent of the Empire was split between 151 ecclesiastical and secular lords, generally lacking princely status, with the majority of that 16.4 percent being held by a tenth of the lords. The remaining 2.6 percent of the Empire was split between 51 disconnected imperial cities and 400 families of Imperial Knights.\nKing of the Romans.\nA prospective Emperor first had to be elected King of the Romans. German kings had been elected since the 9th century; at that point they were chosen by the leaders of the five most important tribes (the Salian Franks of Lorraine, Ripuarian Franks of Franconia, Saxons, Bavarians, and Swabians). In the Holy Roman Empire, the main dukes and bishops of the kingdom elected the King of the Romans.\nThe imperial throne was transferred by election, but Emperors often ensured their own sons were elected during their lifetimes, enabling them to keep the crown for their families. This only changed after the end of the Salian dynasty in the 12th century.\nIn 1356, Emperor Charles IV issued the Golden Bull, which limited the electors to seven: the King of Bohemia, the Count Palatine of the Rhine, the Duke of Saxony, the Margrave of Brandenburg, and the archbishops of Cologne, Mainz, and Trier. During the Thirty Years' War, the Duke of Bavaria was given the right to vote as the eighth elector, and the Duke of Brunswick-L\u00fcneburg (colloquially, Hanover) was granted a ninth electorate; additionally, the Napoleonic Wars resulted in several electorates being reallocated, but these new electors never voted before the Empire's dissolution. A candidate for election would be expected to offer concessions of land or money to the electors in order to secure their vote.\nAfter being elected, the King of the Romans could theoretically claim the title of \"Emperor\" only after being crowned by the Pope. In many cases, this took several years while the King was held up by other tasks: frequently he first had to resolve conflicts in rebellious northern Italy or was quarreling with the Pope himself. Later Emperors dispensed with the papal coronation altogether, being content with the styling \"Emperor-Elect\": the last Emperor to be crowned by the Pope was Charles V in 1530.\nThe Emperor had to be male and of noble blood. No law required him to be a Catholic, but as the majority of the Electors adhered to this faith, no Protestant was ever elected. Whether and to what degree he had to be German was disputed among the Electors, contemporary experts in constitutional law, and the public. During the Middle Ages, some Kings and Emperors were not of German origin, but since the Renaissance, German heritage was regarded as vital for a candidate in order to be eligible for imperial office.\nImperial Diet.\nThe Imperial Diet ( or ) was not a legislative body as is understood today, as its members envisioned it to be more like a central forum, where it was more important to negotiate than to decide. The Diet was theoretically superior to the emperor himself. It was divided into three classes. The first class, the Council of Electors, consisted of the electors, or the princes who could vote for King of the Romans. The second class, the Council of Princes, consisted of the other princes. The Council of Princes was divided into two \"benches\", one for secular rulers and one for ecclesiastical ones. Higher-ranking princes had individual votes, while lower-ranking princes were grouped into \"colleges\" by geography. Each college had one vote.\nThe third class was the Council of Imperial Cities, which was divided into two colleges: Swabia and the Rhine. The Council of Imperial Cities was not fully equal with the others; it could not vote on several matters such as the admission of new territories. The representation of the Free Cities at the Diet had become common since the late Middle Ages. Nevertheless, their participation was formally acknowledged only as late as 1648 with the Peace of Westphalia ending the Thirty Years' War.\nImperial Aulic Chancellery.\nThe Imperial Aulic Chancellery () was the main \"Aulic\" (Courtly) Chancellery of the Holy Roman Empire. It was formed in 1559, by emperor Ferdinand I, and existed until the dissolution of the Empire in 1806. During that period, it was headed by the Imperial Archchancellor (), an honorary post traditionally reserved for the Archbishops of Mainz. In practice, it was run by the Imperial Vicechancellor (), who was appointed among notable statesmen and administrators in imperial service.\nImperial courts.\nThe Empire also had two courts: the \"Reichshofrat\" (also known in English as the Aulic Council) at the court of the King/Emperor, and the \"Reichskammergericht\" (Imperial Chamber Court), established with the Imperial Reform of 1495 by Maximilian I. The Reichskammergericht and the Aulic Council were the two highest judicial instances in the Old Empire. The Imperial Chamber court's composition was determined by both the Holy Roman Emperor and the subject states of the Empire. Within this court, the Emperor appointed the chief justice, always a highborn aristocrat, several divisional chief judges, and some of the other puisne judges.\nThe Aulic Council held standing over many judicial disputes of state, both in concurrence with the Imperial Chamber court and exclusively on their own. The provinces Imperial Chamber Court extended to breaches of the public peace, cases of arbitrary distraint or imprisonment, pleas which concerned the treasury, violations of the Emperor's decrees or the laws passed by the Imperial Diet, disputes about property between immediate tenants of the Empire or the subjects of different rulers, and finally suits against immediate tenants of the Empire, with the exception of criminal charges and matters relating to imperial fiefs, which went to the Aulic Council. The Aulic Council even allowed the emperors the means to depose rulers who did not live up to expectations.\nImperial circles.\nAs part of the Imperial Reform, six Imperial circles were established in 1500; four more were established in 1512. These were regional groupings of most (though not all) of the various states of the Empire for the purposes of defense, imperial taxation, supervision of coining, peace-keeping functions, and public security. Each circle had its own parliament, known as a \"Kreistag\" (\"Circle Diet\"), and one or more directors, who coordinated the affairs of the circle. Not all imperial territories were included within the imperial circles, even after 1512; the Lands of the Bohemian Crown were excluded, as were Switzerland, the imperial fiefs in northern Italy, the lands of the Imperial Knights, and certain other small territories like the Lordship of Jever.\nArmy.\nThe Army of the Holy Roman Empire (, or ; ) was created in 1422 and as a result of the Napoleonic Wars came to an end even before the Empire. It should not be confused with the Imperial Army () of the Emperor.\nDespite appearances to the contrary, the Army of the Empire did not constitute a permanent standing army that was always at the ready to fight for the Empire. When there was danger, an Army of the Empire was mustered from among the elements constituting it, in order to conduct an imperial military campaign or . In practice, the imperial troops often had local allegiances stronger than their loyalty to the Emperor.\nAdministrative centres.\nThroughout the first half of its history the Holy Roman Empire was reigned over by a travelling court. Kings and emperors toured between the numerous Kaiserpfalzes (Imperial palaces), usually resided for several weeks or months and furnished local legal matters, law and administration. Most rulers maintained one or a number of favourite Imperial palace sites, where they would advance development and spent most of their time: Charlemagne (Aachen from 794), Otto I (Magdeburg, from 955), Frederick II (Palermo 1220\u20131254), Wittelsbacher (Munich 1328\u20131347 and 1744\u20131745), Habsburger (Prague 1355\u20131437 and 1576\u20131611; and Vienna 1438\u20131576, 1611\u20131740 and 1745\u20131806).\nThis practice eventually ended during the 16th century, as the emperors of the Habsburg dynasty chose Vienna and Prague and the Wittelsbach rulers chose Munich as their permanent residences (Maximilian I's \"true home\" was still \"the stirrup, the overnight rest and the saddle\", although Innsbruck was probably his most important base; Charles V was also a nomadic emperor). Vienna became Imperial capital during the 1550s under Ferdinand I (reigned 1556\u20131564). Except for a period under Rudolf II (reigned 1570\u20131612) who moved to Prague, Vienna kept its primacy under his successors. Before that, certain sites served only as the individual residence for a particular sovereign. A number of cities held official status, where the Imperial Estates would summon at Imperial Diets, the deliberative assembly of the empire.\nThe Imperial Diet (\"Reichstag\") resided variously in Paderborn, Bad Lippspringe, Ingelheim am Rhein, Diedenhofen (now Thionville), Aachen, Worms, Forchheim, Trebur, Fritzlar, Ravenna, Quedlinburg, Dortmund, Verona, Minden, Mainz, Frankfurt am Main, Merseburg, Goslar, W\u00fcrzburg, Bamberg, Schw\u00e4bisch Hall, Augsburg, Nuremberg, Quierzy-sur-Oise, Speyer, Gelnhausen, Erfurt, Eger (now Cheb), Esslingen, Lindau, Freiburg, Cologne, Konstanz and Trier before it was moved permanently to Regensburg.\nUntil the early 16th century the elected emperor was crowned and anointed by the Pope in Rome, among some exceptions in Ravenna, Reims, and the last coronation in 1530 in Bologna. Since then, rulers proclaimed themselves as emperor after their coronation as German king. The Imperial elections usually took place in Frankfurt am Main.\nIn December 1497 the Aulic Council (\"Reichshofrat\") was established in Vienna.\nIn 1495 the \"Reichskammergericht\" was established, which variously resided in Worms, Augsburg, Nuremberg, Regensburg, Speyer and Esslingen before it was moved permanently to Wetzlar.\nForeign relations.\nThe Habsburg royal family had its own diplomats to represent its interests. The larger principalities in the Holy Roman Empire, beginning around 1648, also did the same. The Holy Roman Empire did not have its own dedicated ministry of foreign affairs and therefore the Imperial Diet had no control over these diplomats; occasionally the Diet criticised them.\nWhen Regensburg served as the site of the Diet, France and, in the late 1700s, Russia, had diplomatic representatives there. The kings of Denmark, Great Britain, and Sweden had land holdings in Germany and so had representation in the Diet itself. The Netherlands also had envoys in Regensburg. Regensburg was the place where envoys met as it was where representatives of the Diet could be reached.\nImperial families and dynasties.\nSome constituencies of the Holy Roman Empire had additional royal or imperial territories that were, sometimes from the outset, outside the jurisdiction of the Holy Roman Empire. Henry VI, inheriting both German aspirations for imperial sovereignty and the Norman Sicilian kings' dream of hegemony in the Mediterranean, had ambitious design for a world empire. Boettcher remarks that marriage policy also played an important role here, \"The marital policy of the Staufer ranged from Iberia to Russia, from Scandinavia to Sicily, from England to Byzantium and to the crusader states in the East. Henry was already casting his eyes beyond Africa and Greece, to Asia Minor and Syria and of course on Jerusalem.\" His annexation of Sicily changed the strategic balance in the Italian peninsula. The emperor, who wanted to make all his lands hereditary, also asserted that papal fiefs were imperial fiefs. On his death at the age of 31 though, he was unable to pass his powerful position to his son, Frederick II, who had only been elected King of the Romans. The union between Sicily and the Empire thus remained personal union. Frederick II became King of Sicily in 1225 through marriage to Isabella II (or Yolande) of Jerusalem and regained Bethlehem and Nazareth for the Christian side through negotiation with Al-Kamil. The Hohenstaufen dream of world empire ended with Frederick's death in 1250.\nIn its earlier days, the Empire provided the principal medium for Christianity to infiltrate the pagans' realms in the North and the East (Scandinavians, Magyars, Slavic people etc.). By the Reform era, the Empire, in its nature, was defensive and not aggressive, desiring of both internal peace and security against invading forces, a fact that even warlike princes such as Maximilian I appreciated. In the Early Modern age, the association with the Church (the Church Universal for the Luxemburgs, and the Catholic Church for the Habsburgs) as well as the emperor's responsibility for the defence of Central Europe remained a reality though. Even the trigger for the conception of the Imperial Reform under Sigismund was the idea of helping the Church to put its house in order.\nTraditionally, German dynasties had exploited the potential of the imperial title to bring Eastern Europe into the fold, in addition to their lands north and south of the Alps. Marriage and inheritance strategies, following by (usually defensive) warfare, played a great role both for the Luxemburgs and the Habsburgs. It was under Sigismund of the Luxemburg, who married Mary, Queen regnal and the rightful heir of Hungary and later consolidated his power with the marriage to the capable and well-connected noblewoman Barbara of Cilli, that the emperor's personal empire expanded to a kingdom outside the boundary of the Holy Roman Empire: Hungary. This last monarch of the Luxemburg dynasty (who wore four royal crowns) had managed to gain an empire almost comparable in scale to the later Habsburg empire, although at the same time they lost the Kingdom of Burgundy and control over Italian territories. The Luxemburgs' focus on the East, especially Hungary, allowed the new Burgundian rulers from the Valois dynasty to foster discontent among German princes. Thus, the Habsburgs were forced to refocus their attention on the West. Frederick III's cousin and predecessor, Albert II of Germany (who was Sigismund's son-in-law and heir through his marriage with Elizabeth of Luxembourg) had managed to combine the crowns of Germany, Hungary, Bohemia and Croatia under his rule, but he died young.\nDuring his rule, Maximilian I had a double focus on both the East and the West. The successful expansion (with the notable role of marriage policy) under Maximilian bolstered his position in the Empire, and also created more pressure for an imperial reform, so that they could get more resources and coordinated help from the German territories to defend their realms and counter hostile powers such as France. Ever since he became King of the Romans in 1486, the Empire provided essential help for his activities in Burgundian Netherlands as well as dealings with Bohemia, Hungary and other eastern polities. In the reigns of his grandsons, Croatia and the remaining rump of the Hungarian kingdom chose Ferdinand as their ruler after he managed to rescue Silesia and Bohemia from Hungary's fate against the Ottoman. Simms notes that their choice was a contractual one, tying Ferdinand's rulership in these kingdoms and territories to his election as King of the Romans and his ability to defend Central Europe. In turn, the Habsburgs' imperial rule also \"depended on holding these additional extensive lands as independent sources of wealth and prestige.\"\nThe later Austrian Habsburgs from Ferdinand I were careful to maintain a distinction between their dynastic empire and the Holy Roman Empire. Peter Wilson argues that the institutions and structures developed by the Imperial Reform mostly served German lands and, although the Habsburg monarchy \"remained closely entwined with the Empire\", the Habsburgs deliberately refrained from including their other territories in its framework. \"Instead, they developed their own institutions to manage what was, effectively, a parallel dynastic-territorial empire and which gave them an overwhelming superiority of resources, in turn allowing them to retain an almost unbroken grip on the imperial title over the next three centuries.\" Ferdinand had an interest in keeping Bohemia separate from imperial jurisdiction and making the connection between Bohemia and the Empire looser (Bohemia did not have to pay taxes to the Empire). As he refused the rights of an Imperial Elector as King of Bohemia (which provided him with half of his revenue), he was able to give Bohemia (as well as associated territories such as Upper and Lower Alsatia, Silesia and Moravia) the same privileged status as Austria, therefore affirming his superior position in the Empire. The Habsburgs also tried to mobilize imperial aid for Hungary (which, throughout the 16th century, cost the dynasty more money in defence expenditure than the total revenue it yielded).\nSince 1542, Charles V and Ferdinand had been able to collect the Common Penny tax, or \"T\u00fcrkenhilfe\" (Turkish aid), designed to protect the Empire against the Ottomans or France. But as Hungary, unlike Bohemia, was not part of the Empire, the imperial aid for Hungary depended on political factors. The obligation was only in effect if Vienna or the Empire were threatened. Wilson notes that, \"In the early 1520s the Reichstag hesitated to vote aid for Hungary's King Louis II, because it regarded him as a foreign prince. This changed once Hungary passed to the Habsburgs on Louis' death in battle in 1526 and the main objective of imperial taxation across the next 90 years was to subsidize the cost of defending the Hungarian frontier against the Ottomans. The bulk of the weaponry and other military materiel was supplied by firms based in the Empire and financed by German banks. The same is true of the troops who eventually evicted the Ottomans from Hungary between 1683 and 1699. The imperial law code of 1532 was used in parts of Hungary until the mid-17th century, but otherwise Hungary had its own legal system and did not import Austrian ones. Hungarian nobles resisted the use of Germanic titles like Graf for count until 1606, and very few acquired the personal status of imperial prince.\"\nResponding to the opinion that the Habsburg's dynastic concerns were damaging to the Holy Roman Empire, Whaley writes that, \"There was no fundamental incompatibility between dynasticism and participation in the empire, either for the Habsburgs or for the Saxons or others.\" Imperial marriage strategies had double-edged effects for the Holy Roman Empire though. The Spanish connection was an example: while it provided a powerful partner in the defence of Christendom against the Ottomans, it allowed Charles V to transfer the Burgundian Netherlands, Franche-Comte as well as other imperial fiefs such as Milan to his son Philip II's Spanish Empire.\nOther than the imperial families, other German princes possessed foreign lands as well, and foreign rulers could also acquire imperial fiefs and thus become imperial princes. This phenomenon contributed to the fragmentation of sovereignty, in which imperial vassals remained semi-sovereign, while strengthening the interconnections (and chances of mutual interference) between the Kingdom of Germany and the Empire in general with other kingdoms such as Denmark and Sweden, who accepted the status of imperial vassals on behalf of their German possessions (which were subjected to imperial laws). The two Scandinanvian monarchies honoured the obligations to come to the aid of the Empire in the wars of 17th and early 18th centuries. They also imported German princely families as rulers, although in both cases, this did not produce direct unions. Denmark consistently tried to take advantage of its influence in imperial institutions to gain new imperial fiefs along the Elbe, although these attempts generally did not succeed.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nSources.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "13278", "revid": "40192293", "url": "https://en.wikipedia.org/wiki?curid=13278", "title": "Holidays", "text": ""}
{"id": "13279", "revid": "25046916", "url": "https://en.wikipedia.org/wiki?curid=13279", "title": "Holiday", "text": "Festive day set aside by custom or by law\nA holiday is a day or other period of time set aside for festivals or recreation. \"Public holidays\" are set by public authorities and vary by state or region. Religious holidays are set by religious organisations for their members and are often also observed as public holidays in religious majority countries. Some religious holidays, such as Christmas, have become secularised by part or all of those who observe them. In addition to secularisation, many holidays have become commercialised due to the growth of industry.\nHolidays can be thematic, celebrating or commemorating particular groups, events, or ideas, or non-thematic, days of rest that do not have any particular meaning. In Commonwealth English, the term can refer to any period of rest from work, such as vacations or school holidays. In American English, \"the holidays\" typically refers to the period from Thanksgiving to New Year's (late November to January 1), which contains many important holidays in American culture.\nTerminology.\nThe word \"holiday\" comes from the Old English word \"h\u0101ligd\u00e6g\" (\"h\u0101lig\" \"holy\" + \"d\u00e6g\" \"day\"). The word originally referred only to special religious days.\nThe word \"holiday\" has differing connotations in different regions. In the United States, the word is used exclusively to refer to the nationally, religiously, or culturally observed day(s) of rest or celebration or the events themselves, whereas in the United Kingdom and other Commonwealth nations, the word may refer to the period of time where leave from one's duties has been agreed upon and is used as a synonym for the US preferred \"vacation\". This time is usually set aside for rest, travel, or participation in recreational activities, with entire industries targeted to coincide with or enhance these experiences. The days of leave may not coincide with any specific customs or laws. Employers and educational institutes may designate 'holidays' themselves, which may or may not overlap nationally or culturally relevant dates, which again comes under this connotation, but it is the first implication detailed that this article is concerned with. Modern use varies geographically. In North America, it means any dedicated day or period of celebration. In the United Kingdom, Australia, and New Zealand, \"holiday\" is often used instead of the word \"vacation\".\nGlobal holidays.\nThe celebration of the New Year has been a common holiday across cultures for at least four millennia. Such holidays normally celebrate the last day of a year and the arrival of the next year in a calendar system. In modern cultures using the Gregorian calendar, the New Year's celebration spans New Year's Eve on 31 December and New Year's Day on 1 January. However, other calendar systems also have New Year's celebration, such as Chinese New Year and Vietnamese Tet. New Year's Day is the most common public holiday, observed by all countries using the Gregorian calendar except Israel.\nChristmas is a popular holiday globally due to the spread of Christianity. The holiday is recognised as a public holiday in many countries in Europe, the Americas, Africa and Australasia and is celebrated by over 2 billion people. Although a holiday with religious origins, Christmas is often celebrated by non-Christians as a secular holiday. For example, 61% of British people celebrate Christmas in an entirely secular way. Christmas has also become a tradition in some non-Christian countries. For many Japanese people, it has become customary to buy and eat fried chicken on Christmas.\nRecently invented holidays commemorate a range of modern social and political issues and other important topics. The United Nations publishes a list of International Days and Weeks. One such day is International Women's Day on 8 March, which celebrates women's achievements and campaigns for gender equality and women's rights. Earth Day has been celebrated by people across the world since 1970, with 10,000 events in 2007. It is a holiday marking the dangers of environmental damage, such as pollution and the climate crisis.\nCommon secular holidays.\nOther secular holidays are observed regionally, nationally and across multi-country regions. The United Nations Calendar of Observances dedicates decades to a specific topic, but also a complete year, month, week and days. Holidays dedicated to an observance such as the commemoration of the ending of World War II, or the Shoah, can also be part of the reparation obligation as per UN General Assembly Resolution 60/147 Basic Principles and Guidelines on the Right to a Remedy and Reparation for Victims of Gross Violations of International Human Rights Law and Serious Violations of International Humanitarian Law.\nAnother example of a major secular holiday is the Lunar New Year, which is celebrated across East Asia and South East Asia. Many other days are marked to celebrate events or people, but are not strictly holidays as time off work is rarely given; examples include Arbor Day, International Worker's Day (celebrated sometimes under different names and on different days in different countries), and Earth Day (22 April).\nPublic holidays.\nSubstitute holidays.\nIf a holiday coincides with another holiday or a weekend day a substitute holiday may be recognised in lieu. In the United Kingdom the government website states that \"If a bank holiday is on a weekend, a 'substitute' weekday becomes a bank holiday, normally the following Monday.\", and the list of bank holidays for the year 2020 includes Monday 28 December as \"Boxing Day (substitute day)\", as 26 December is a Saturday. The process of moving a holiday from a weekend day to the following Monday is known as Mondayisation in New Zealand.\nNational days.\nNational days are days of significance to a nation or nation state. National days are typically celebratory of a state's independence (e.g. 4 July in the US), founding or unification (e.g. German Unity Day), the commemoration of a revolution (e.g. Bastille Day in France) or liberation (e.g. 9 May in the Channel Islands), or the feast day for a patron saint (e.g. St Patrick's Day in Ireland) or ruler (e.g. 5 December in Thailand). Belgium's national day, on the 21st of July, commemorates the oath of office of the first King of the Belgians (an uncle of the then-future Queen Victoria), i.e., so to say, the day Belgium became a kingdom by ending the initial interregnum. Every country other than Denmark and the United Kingdom observes a national day. In the UK, constituent countries have official or unofficial national days associated with their patron saint. A British national day has often been proposed, such as the date of the Acts of Union 1707 (1 May) or the King's Official Birthday, but never adopted.\nOther days of national importance exist, such as one to celebrate the country's military or veterans. For example, Armistice Day (11 November) is recognised in World War I Allied nations (and across the Commonwealth) to memorialise those lost in the World Wars. National leaders will typically attend remembrance ceremonies at national memorial sites. Maybe surprisingly, World War II Armistice Day (and victory against Nazism) day, on 8 May, is much less celebrated.\nReligious holidays.\nMany holidays are linked to faiths and religions (see etymology above). Christian holidays are defined as part of the liturgical year, the chief ones being Easter and Christmas. The Orthodox Christian and Western-Roman Catholic patronal feast day or \"name day\" is celebrated on each place's patron saint's day, according to the calendar of saints. Jehovah's Witnesses annually commemorate \"The Memorial of Jesus Christ's Death\", but do not celebrate other holidays with any religious significance such as Easter, Christmas or New Year. This holds especially true for those holidays that have combined and absorbed rituals, overtones or practices from non-Christian beliefs into the celebration, as well as those holidays that distract from or replace the worship of Jehovah. In Islam, the largest holidays are Eid al-Fitr (after Ramadan) and Eid al-Adha (at the end of the Hajj). Ahmadi Muslims additionally celebrate Promised Messiah Day, Promised Reformer Day, and Khilafat Day, but contrary to popular belief, neither are regarded as holidays. Hindus, Jains and Sikhs observe several holidays, one of the largest being Diwali (Festival of Light). Japanese holidays as well as few Catholic holidays contain heavy references to several different faiths and beliefs. Celtic, Norse, and Neopagan holidays follow the order of the Wheel of the Year. For example, Christmas ideas like decorating trees and colors (green, red, and white) have very similar ideas to modern Wicca (a modern Pagan belief) Yule which is a lesser Sabbat of the wheel of the year. Some are closely linked to Swedish festivities. The Bah\u00e1\u02bc\u00ed Faith observes 11 annual holidays on dates determined using the Bah\u00e1\u02bc\u00ed calendar. Jews have two holiday seasons: the Spring Feasts of Pesach (Passover) and Shavuot (Weeks, called Pentecost in Greek); and the Fall Feasts of Rosh Hashanah (Head of the Year), Yom Kippur (Day of Atonement), Sukkot (Tabernacles), and Shemini Atzeret (Eighth Day of Assembly).\nSecularisation.\nSome religious holidays are also celebrated by many as secular holidays. For example, 61% of Brits celebrate Christmas in an entirely secular way. 81% of non-Christian Americans also celebrate Christmas. A 2019 Gallup poll found that two-thirds of Americans still celebrate an at least somewhat religious Christmas.\nThe claimed over-secularisation of particular holidays has caused controversy and claims of censorship of religion or political correctness. For example, in the 1990s, Birmingham City Council promoted a series of events in the Christmas season under the brand Winterval to create a more multi-cultural atmosphere about the seasonal festivities. The Bishop of Birmingham responded to the events, saying \"the secular world, which expresses respect for all, is actually embarrassed by faith. Or perhaps it is Christianity which is censored\". In the United States, conservative commentators have characterised the secularisation of Winter festivities as \"the War on Christmas\".\nUnofficial holidays.\nThese are holidays that are not traditionally marked on calendars. These holidays are celebrated by various groups and individuals. Some promote a cause, others recognize historical events not officially recognized, and others are \"funny\" holidays celebrated with humorous intent. For example, Monkey Day is celebrated on December 14, International Talk Like a Pirate Day is observed on September 19, and Blasphemy Day is held on September 30. Other examples are April Fools' Day on April 1 and World No Tobacco Day on May 31. Various community organizers and marketers promote odd social media holidays.\nCommercialism.\nIn the United States, holidays have been drawn into a culture of consumption since the late 19th century. Many civic, religious and folk festivals have been commercialised. As such, traditions have been reshaped to serve the needs of industry. Leigh Eric Schmidt argues that the growth of consumption culture allowed the growth of holidays as an opportunity for increased public consumption and the orderly timing of it. Thus, after the Civil War, as department stores became the spatial expression of commercialism, holidays became the temporal expression of it.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "13281", "revid": "36767729", "url": "https://en.wikipedia.org/wiki?curid=13281", "title": "History of Science and Technology/Astronomy and Astrophysics", "text": ""}
{"id": "13287", "revid": "28146993", "url": "https://en.wikipedia.org/wiki?curid=13287", "title": "Hobby", "text": "Regular activity done for enjoyment\n \nA hobby is considered to be a regular activity that is done for enjoyment, typically during one's leisure time. Hobbies include collecting themed items and objects, engaging in creative and artistic pursuits, playing sports, or pursuing other amusements or avocations. Participation in hobbies encourages acquiring substantial skills and knowledge in that area. A list of hobbies changes with renewed interests and developing fashions, making it diverse and lengthy. Hobbies tend to follow trends in society. For example, stamp collecting was popular during the nineteenth and twentieth centuries as postal systems were the main means of communication; as of 2024[ [update]], video games became more popular following technological advances. The advancing production, technology, and labour movements of the nineteenth century provided workers with more leisure time to engage in hobbies. Because of this, the efforts of people investing in hobbies has increased with time.\nThere are various types of hobbies, which can be classified in various ways, including subject matter, degree of time commitment, and social versus solitary nature. The Serious Leisure Perspective of Robert Stebbins identifies hobbies under three sub-categories: \"casual leisure,\" which is intrinsically rewarding, short-lived, pleasurable activity requiring little or no preparation; \"serious leisure,\" which is the systematic pursuit of an amateur, hobbyist, or volunteer that is substantial, rewarding and results in a sense of accomplishment; and finally \"project-based leisure,\" which is a short-term, often one-off, project that is rewarding.\nEtymology.\nIn the 16th century, the term \"hobby\" had the meaning of \"small horse and pony\". The term \"hobby horse\" was documented in a 1557 payment confirmation for a \"Hobbyhorse\" from Reading, England. The item, originally called a \"Tourney Horse\", was made of a wooden or basketwork frame with an artificial tail and head. It was designed for a child to mimic riding a real horse. By 1816 the derivative, \"hobby\", was introduced into the vocabulary of a number of English people. Over the course of subsequent centuries, the term came to be associated with recreation and leisure. In the 17th century, the term was used in a pejorative sense by suggesting that a hobby was a childish pursuit, however, in the 18th century with more industrial society and more leisure time, hobbies took on greater respectability. A hobby is also called a pastime, derived from the use of hobbies to \"pass the time\". A hobby became an activity that is practiced regularly and usually with some worthwhile purpose. Hobbies are usually, but not always, practiced primarily for interest and enjoyment, rather than financial reward.\nHistory.\nPrior to the mid-19th century, hobbies were generally considered as an obsession, childish or trivial, with negative connotations. However, as early as 1676 Sir Matthew Hale, in \"Contemplations Moral and Divine\", wrote \"Almost every person hath some hobby horse or other wherein he prides himself.\" He was acknowledging that a \"hobby horse\" produces a legitimate sense of pride. The cultural shift towards acceptance of hobbies was thought to begin during the mid 18th century as working people had more regular hours of work and greater leisure time, spending more time to pursue interests that brought them satisfaction. However, there was concern that these working people might not use their leisure time in worthwhile pursuits. \"The hope of weaning people away from bad habits by the provision of counter-attractions came to the fore in the 1830s, and has rarely waned since. Initially, the bad habits were perceived to be of a sensual and physical nature, and the counter attractions, or perhaps more accurately alternatives, deliberately cultivated rationality and the intellect.\" The book and magazine trade of the day encouraged worthwhile hobbies and pursuits. The burgeoning manufacturing trade made materials used in hobbies cheap and was responsive to the changing interests of hobbyists.\nIn 1941, George Orwell identified hobbies as central to English culture at the time: \"Another English characteristic which is so much a part of us that we barely notice it \u2026 is the addiction to hobbies and spare-time occupations, the \"privateness\" of English life. We are a nation of flower-lovers, but also a nation of stamp-collectors, pigeon-fanciers, amateur carpenters, coupon-snippers, darts-players, crossword-puzzle fans. All the culture that is most truly native centers round things which even when they are communal are not official\u2014the pub, the football match, the back garden, the fireside and the 'nice cup of tea'.\"\nDeciding what to include in a list of hobbies provokes debate because it is difficult to decide which pleasurable pass-times can also be described as hobbies. During the 20th century the term hobby suggested activities, such as stamp collecting, embroidery, knitting, painting, woodwork, and photography. Typically the description did not include activities like listening to music, watching television, or reading. These latter activities bring pleasure, but lack the sense of achievement usually associated with a hobby. They are usually not structured, organized pursuits, as most hobbies are. The pleasure of a hobby is usually associated with making something of value or achieving something of value. \"Such leisure is socially valorized precisely because it produces feelings of satisfaction with something that looks very much like work but that is done of its own sake.\" \"Hobbies are a contradiction: they take work and turn it into leisure, and take leisure and turn it into work.\" A 2018 study using survey results identified the term \"hobby\" to most accurately describe activities associated with making or collecting objects, especially when done alone.\nCultural trends related to hobbies change with time. In the 21st century, the video game industry has been popular as a hobby involving millions of children and adults. Stamp collecting declined along with the importance of the postal system. Woodwork and knitting declined as hobbies, because manufactured goods provide cheap alternatives for handmade goods. Through the internet, an online community has become a hobby for many people; sharing advice, information and support, and in some cases, allowing a traditional hobby, such as collecting, to flourish and support trading in a new environment.\nHobbyists.\nHobbyists are a part of a wider group of people engaged in leisure pursuits where the boundaries of each group overlap to some extent. The \"Serious Leisure Perspective\" groups hobbyists with amateurs and volunteers and identifies three broad groups of leisure activity with hobbies being found mainly in the Serious leisure category. \"Casual leisure\" is intrinsically rewarding, short-lived, pleasurable activity requiring little or no preparation. \"Serious leisure\" is the systematic pursuit of an amateur, hobbyist, or volunteer that is substantial, rewarding and results in a sense of accomplishment. Finally, \"project-based leisure\" is a short-term often a one-off project that is rewarding.\nThe terms amateur and hobbyist are often used interchangeably. Stebbins has a framework which distinguishes the terms in a useful categorization of leisure in which \"casual leisure\" is separated from \"serious Leisure\". He describes serious leisure as undertaken by \"amateurs\", \"hobbyists\" and \"volunteers\". \"Amateurs\" engage in pursuits that have a professional counterpart, such as playing an instrument or astronomy. Hobbyists engage in five broad types of activity: \"collecting\", \"making and tinkering\" (like embroidery and car restoration), \"activity participation\" (like fishing and singing), \"sports and games\", and \"liberal-arts\" hobbies (like languages, cuisine, literature). Volunteers commit to organizations where they work as guides, counsellors, gardeners and so on. The separation of the amateur from the hobbyist is because the amateur has the ethos of the professional practitioner as a guide to practice. An amateur clarinetist is conscious of the role and procedures of a professional clarinetist.\nA large proportion of hobbies are mainly solitary in nature. However, individual pursuit of a hobby often includes club memberships, organized sharing of products and regular communication between participants. For many hobbies there is an important role in being in touch with fellow hobbyists. Some hobbies are of communal nature, like choral singing and volunteering.\nPeople who engage in hobbies have an interest in and time to pursue them. Children have been an important group of hobbyists because they are enthusiastic for collecting, making and exploring, in addition to this they have the leisure time that allows them to pursue those hobbies. The growth in hobbies occurred during industrialization which gave workers set time for leisure. During the Depression there was an increase in the participation in hobbies because the unemployed had the time and a desire to be purposefully occupied. Hobbies are often pursued with an increased interest by retired people because they have the time and seek the intellectual and physical stimulation a hobby provides.\nTypes of hobbies.\n Hobbies are a diverse set of activities and it is difficult to categorize them in a logical manner. The following categorization of hobbies was developed by Stebbins. \nCollecting.\nCollecting includes seeking, locating, acquiring, organizing, cataloging, displaying and storing. Collecting is appealing to many people due to their interest in a particular subject and a desire to categorize and make order out of complexity. Some collectors are generalists, accumulating items from countries of the world. Others focus on a subtopic within their area of interest, perhaps 19th century postage stamps, milk bottle labels from Sussex, or Mongolian harnesses and tack, Firearms (both modern and vintage).\nCollecting is an ancient hobby, with Caesar Augustus being a collector of coins. Sometimes collectors have turned their hobby into a business, becoming commercial dealers that trade in the items being collected.\nObserving.\nAn alternative to collecting physical objects is to observe and collect records of events of a particular kind. Examples include train spotting, bird-watching, aircraft spotting, and any other form of systematic recording a particular phenomenon. The recording form can be written, photographic, online, etc.\nMaking and tinkering.\n\"Making\" and \"tinkering\" includes working on self-motivated projects for fulfillment. These projects may be progressive, irregular tasks performed over a long period of time. Making and tinkering hobbies include higher-end projects, such as building or restoring a car or building a computer from individual parts. For computer savvy do-it-yourself hobbyists, CNC (Computer Numerical Control) machining may also be popular. A CNC machine can be assembled and programmed to make different parts from wood or metal.\nTinkering is 'dabbling' with the making process, often applied to the hobby of tinkering with car repairs, and various kinds of restoration: of furniture, antique cars, etc. It also applies to household tinkering: repairing a wall, laying a pathway, etc. Examples of Making and Tinkering hobbies include Scale modeling, model engineering, 3D printing, dressmaking, and cooking.\nScale modeling is making a replica of a real-life object in a smaller scale and dates back to prehistoric times with small clay \"dolls\" and other children's toys that have been found near known populated areas. Some of the earliest scale models of residences were found in Cucuteni\u2013Trypillia culture in Eastern Europe. These artifacts were dated to be around 3000\u20136000 BC. Similar models dating back to the same period were found in ancient Egypt, India, China and Mesopotamia archaeological sites.\nAt the turn of the Industrial Age and through the 1920s, some families could afford things such as electric trains, wind-up toys (typically boats or cars) and the increasingly valuable tin toy soldiers. The current form of scale modeling became popular shortly after World War II. Before 1946, children as well as adults were content in carving and shaping wooden replicas from block wood kits, often depicting enemy aircraft to help with identification in case of an invasion.\nWith the advent of modern plastics, the amount of skill required to get the basic shape accurately shown for any given subject was lessened, making it easier for people of all ages to begin assembling replicas in varying scales. Superheroes, aero planes, boats, cars, tanks, artillery, and even figures of soldiers became quite popular subjects to build, paint and display. Although almost any subject can be found in almost any scale, there are common scales for such miniatures which remain constant today.\nModel engineering refers to building functioning machinery in metal, such as internal combustion motors and live steam models or locomotives. This is a demanding hobby that requires a multitude of large and expensive machine tools, such as lathes and mills. This hobby originated in the United Kingdom in the late 19th century, later spreading and flourishing in the mid-20th century. Due to the expense and space required, it is becoming rare.\n3D Printing is a relatively new technology and already a major hobby as the cost of printers has fallen sharply. It is a good example of how hobbyists quickly engage with new technologies, communicate with one another and become producers related to their former hobby. 3D modeling is the process of making mathematical representations of three dimensional items and is an aspect of 3D printing.\nDressmaking has been a major hobby up until the late 20th century, in order to make cheap clothes, but also as a creative design and craft challenge. It has been reduced by the low cost of manufactured clothes.\nCooking is for some people an interest, a hobby, a challenge and a source of significant satisfaction. For many other people it is a job, a chore, a duty, like cleaning. In the early 21st century the importance of cooking as a hobby was demonstrated by the high popularity of competitive television cooking programs.\nActivity participation.\nActivity participation includes partaking in \"non-competitive, rule-based pursuits.\"\nOutdoor pursuits are the group of activities which occur outdoors. These hobbies include gardening, hill walking, hiking, backpacking, cycling, canoeing, climbing, caving, fishing, hunting, target shooting (informal or formal), wildlife viewing (as birdwatching) and engaging in watersports and snowsports.\nOne large subset of outdoor pursuits is gardening. Residential gardening most often takes place in or about one's own residence, in a space referred to as the garden. Although a garden typically is located on the land near a residence, it may also be located on a roof, in an atrium, on a balcony, in a windowbox, or on a patio or vivarium.\nGardening also takes place in non-residential green areas, such as parks, public or semi-public gardens (botanical gardens or zoological gardens), amusement and theme parks, along transportation corridors, and around tourist attractions and hotels. In these situations, a staff of gardeners or groundskeepers maintains the gardens.\nIndoor gardening is concerned with growing houseplants within a residence or building, in a conservatory, or in a greenhouse. Indoor gardens are sometimes incorporated into air conditioning or heating systems.\nWater gardening is concerned with growing plants that have adapted to pools and ponds, along with aqua-scaping in planted aquariums. Bog gardens are also considered a type of water garden. A simple water garden may consist solely of a tub containing the water and plants.\nContainer gardening is concerned with growing plants in containers that are placed above the ground.\nLiberal arts pursuits.\nMany hobbies involve performances by the hobbyist, such as singing, acting, juggling, magic, dancing, playing a musical instrument, martial arts, and other performing arts.\nSome hobbies may result in an end product. Examples of this would be woodworking, photography, moviemaking, jewelry making, software projects such as Photoshopping and home music or video production, making bracelets, artistic projects such as drawing, painting, cosplay (design, creation, and wearing a costume based on an already existing creative property), creating models out of card stock or paper \u2013 called papercraft (which includes origami), Many of these fall under the category visual arts.\nWriting is often taken up as a hobby by aspiring writers and usually appears in the form of personal blog, guest posting or fan fiction (literary art resulting in creation of written content based on already existing, licensed creative property under specified terms).\nReading books, eBooks, magazines, comics, or newspapers, along with browsing the internet is a common hobby, and one that can trace its origins back hundreds of years. A love of literature, later in life, may be sparked by an interest in reading children's literature as a child. Many of these fall under the category literary arts.\nKnitting or crocheting is a calming and productive hobby. It allows for creativity while making cozy items like scarves, blankets, or hats. It's easy on the joints and can be done at a leisurely pace, making it perfect for staying engaged and creating thoughtful gifts.\nSports and games.\nStebbins distinguishes an amateur sports person and a hobbyist by suggesting a hobbyist plays in less formal sports, or games that are rule bound and have no professional equivalent. While an amateur sports individual plays a sport with a professional equivalent, such as football or tennis. Amateur sport may range from informal play to highly competitive practice, such as deck tennis or long distance trekking.\nThe Department for Culture, Media, and Support in England suggests that playing sports benefits physical and mental health. A positive relationship appeared between engaging in sports and improving overall health.\nPsychological role.\nDuring the 20th century, there was extensive research into the important role that play has in human development. While most evident in childhood, play continues throughout life for many adults in the form of games, hobbies, and sport. Moreover, studies of aging and society support the value of hobbies in healthy aging.\nSignificant achievements.\nThere have been many instances where hobbyists and amateurs have achieved significant discoveries and developments. These are a small sample.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "13288", "revid": "13079754", "url": "https://en.wikipedia.org/wiki?curid=13288", "title": "Holland", "text": "Region and former province of the Netherlands\nHolland is a geographical region and former province on the western coast of the Netherlands. From the 10th to the 16th century, Holland proper was a unified political region within the Holy Roman Empire as a county ruled by the counts of Holland. By the 17th century, the province of Holland had risen to become a maritime and economic power, dominating the other provinces of the newly independent Dutch Republic.\nThe area of the former County of Holland roughly coincides with the two current Dutch provinces of North Holland and South Holland into which it was divided, and which together include the Netherlands' three largest cities: the capital city (Amsterdam), the home of Europe's largest port (Rotterdam), and the seat of government (The Hague). Holland has a population of 6,583,534 as of November 2019, and a population density of 1203/km2.\nThe name \"Holland\" has frequently been used informally to refer to the whole of the country of the Netherlands. This casual usage is commonly accepted in other countries, and is even employed by many Dutch themselves. However, some in the Netherlands (particularly those from regions outside Holland or the west) find it undesirable or misrepresentative to use the term for the whole country. In January 2020, the Netherlands officially dropped its support of the word \"Holland\" for the whole country, which included a logo redesign that changed \"Holland\" to \"NL\".\nEtymology and terminology.\nThe name \"Holland\" first appeared in sources for the region around Haarlem, and by 1064 was being used as the name of the entire county. By the early twelfth century, the inhabitants of Holland were called \"Hollandi\" in a Latin text. \"Holland\" is derived from the Old Dutch term \"holtlant\" ('wood-land'). This spelling variation remained in use until around the 14th century, at which time the name stabilised as \"Holland\" (alternative spellings at the time were \"Hollant\" and \"Hollandt\"). A popular but erroneous folk etymology holds that \"Holland\" is derived from \"hol land\" ('hollow land' in Dutch), purportedly inspired by the low-lying geography of the land.\n\"Holland\" is informally used in English and other languages, including sometimes the Dutch language itself, to mean the whole of the modern country of the Netherlands. This example of \"pars pro toto\" or synecdoche is similar to the tendency to refer to the United Kingdom as \"England\", and developed due to Holland's becoming the dominant province and thus having the majority of political and economic interactions with other countries.\nBetween 1806 and 1810 \"Holland\" was the official name for the country as a whole, after Napoleon made his brother Louis Bonaparte the monarch of the Kingdom of Holland.\nThe people of Holland are referred to as \"Hollanders\" in both Dutch and English, though in English this is now unusual. Today this refers specifically to people from the current provinces of North Holland and South Holland. Strictly speaking, the term \"Hollanders\" does not refer to people from the other provinces in the Netherlands, but colloquially \"Hollanders\" is sometimes used in this wider sense.\nIn Dutch, the word \"Hollands\" is the adjectival form for \"Holland\". \"Hollands\" is also colloquially used by some Dutch people in the sense of \"Nederlands\" (the Dutch language), occasionally with the intention of contrasting with other types of Dutch people or forms of the language\u2014for example Limburgish, the Belgian varieties of the Dutch language (\"Flemish\"), or even any southern variety of Dutch within the Netherlands itself.\nIn English, \"Dutch\" refers to the Netherlands as a whole, but there is no commonly used adjective for \"Holland\". The word \"Hollandish\" is no longer in common use. \"Hollandic\" is the name linguists give to the dialect spoken in Holland, and is occasionally also used by historians and when referring to pre-Napoleonic Holland.\nHistory.\nInitially, Holland was a remote corner of the Holy Roman Empire. Gradually, its regional importance increased until it began to have a decisive, and ultimately dominant, influence on the History of the Netherlands.\nCounty of Holland.\nUntil the start of the 12th century, the inhabitants of the area that became Holland were known as Frisians. The area was initially part of Frisia. At the end of the 9th century, West-Frisia became a separate county in the Holy Roman Empire. The first count known about with certainty was Dirk I, who ruled from 896 to 931. He was succeeded by a long line of counts in the House of Holland (who were in fact known as counts of Frisia until 1101). When John I died childless in 1299, the county was inherited by Count John II of Hainaut. By the time of William V (House of Wittelsbach; 1354\u20131388) the count of Holland was also the count of Hainaut and Zealand.\nAfter the St. Lucia's flood in 1287 the part of Frisia west of the later Zuiderzee, West Friesland, was conquered. As a result, most provincial institutions, including the States of Holland and West Frisia, would for more than five centuries refer to \"Holland and West Frisia\" as a unit. The Hook and Cod wars started around this time and ended when the countess of Holland, Jacoba or Jacqueline was forced to cede Holland to the Burgundian Philip III, known as Philip the Good, in 1432.\nIn 1432, Holland became part of the Burgundian Netherlands and since 1477 of the Habsburg Seventeen Provinces. In the 16th century the county became the most densely urbanised region in Europe, with the majority of the population living in cities. Within the Burgundian Netherlands, Holland was the dominant province in the north; the political influence of Holland largely determined the extent of Burgundian dominion in that area. The last count of Holland was Philip III, better known as Philip II, king of Spain. He was deposed in 1581 by the Act of Abjuration, although the kings of Spain continued to carry the titular appellation of Count of Holland until the Peace of M\u00fcnster signed in 1648.\nDutch Republic.\nIn the Dutch Rebellion against the Habsburgs during the Eighty Years' War, the naval forces of the rebels, the Watergeuzen, established their first permanent base in 1572 in the town of Brill. In this way, Holland, now a sovereign state in a larger Dutch confederation, became the centre of the rebellion. It became the cultural, political and economic centre of the United Provinces (), in the 17th century, the Dutch Golden Age, the wealthiest nation in the world. After the King of Spain was deposed as the count of Holland, the executive and legislative power rested with the States of Holland, which was led by a political figure who held the office of Grand Pensionary.\nThe largest cities in the Dutch Republic were in the province of Holland, such as Amsterdam, Rotterdam, Leiden, Alkmaar, The Hague, Delft, Dordrecht and Haarlem. From the great ports of Holland, Hollandic merchants sailed to and from destinations all over Europe, and merchants from all over Europe gathered to trade in the warehouses of Amsterdam and other trading cities of Holland.\nMany Europeans thought of the United Provinces first as \"Holland\" rather than as the \"Republic of the Seven United Provinces of the Netherlands\". A strong impression of \"Holland\" was planted in the minds of other Europeans, which then was projected back onto the Republic as a whole. Within the provinces themselves, a gradual slow process of cultural expansion took place, leading to a \"Hollandification\" of the other provinces and a more uniform culture for the whole of the Republic. The dialect of urban Holland became the standard language.\nUnder French rule.\nThe formation of the Batavian Republic, inspired by the French Revolution, led to a more centralised government. Holland became a province of a unitary state. Its independence was further reduced by an administrative reform in 1798, in which its territory was divided into several departments called \"Amstel\", \"Delf\", \"Texel\", and part of \"Schelde en Maas\".\nFrom 1806 to 1810, Napoleon styled his vassal state, governed by his brother Louis Napoleon and shortly by the son of Louis, Napoleon Louis Bonaparte, as the \"Kingdom of Holland\". This kingdom encompassed much of what would become the modern Netherlands. The name reflects how natural at the time it had become to equate Holland with the non-Belgian Netherlands as a whole.\nDuring the period when the Low Countries were annexed by the French Empire and actually incorporated into France (from 1810 to 1813), Holland was divided into d\u00e9partements Zuyderz\u00e9e, and Bouches-de-la-Meuse. From 1811 to 1813, Charles-Fran\u00e7ois Lebrun, duc de Plaisance served as governor-general. He was assisted by Antoine de Celles, Goswin de Stassart and Fran\u00e7ois Jean-Baptiste d'Alphonse. In 1813, Dutch dignitaries proclaimed the Sovereign Principality of the United Netherlands.\nKingdom of the Netherlands.\nIn 1815, Holland was restored as a province of the United Kingdom of the Netherlands. Holland was divided into the present provinces North Holland and South Holland in 1840, after the Belgian Revolution of 1830. This reflected a historical division of Holland along the IJ into a Southern Quarter (\"Zuiderkwartier\") and a Northern Quarter (\"Noorderkwartier\"), but the present division is different from the old division. From 1850, a strong process of nation formation took place, the Netherlands being culturally unified and economically integrated by a modernisation process, with the cities of Holland as its centre.\nGeography.\nHolland is located in the west of the Netherlands. A maritime region, Holland lies on the North Sea at the mouths of the Rhine and the Meuse (Maas). It contains numerous rivers and lakes, and has an extensive inland canal and waterway system. To the south is Zealand. The region is bordered on the east by the IJsselmeer and four Dutch provinces.\nHolland is protected from the sea by a long line of coastal dunes. The highest point in Holland, about above sea level, is in the Schoorlse Duinen (Schoorl Dunes). Most of the land area behind the dunes consists of polder landscape lying well below sea level. At present the lowest point in Holland is a polder near Rotterdam, which is about below sea level. Continuous drainage is necessary to keep Holland from flooding. In earlier centuries, windmills were used for this task. The landscape was (and in places still is) dotted with windmills, which have become a symbol of Holland.\nHolland is , land and water included, making it roughly 13% of the area of the Netherlands. Looking at land alone, it is in area. The combined population was 6.5\u00a0million in 2018.\nThe main cities in Holland are Amsterdam, Rotterdam and The Hague. Amsterdam is formally the capital of the Netherlands and its largest city. The Port of Rotterdam is Europe's largest and most important harbour and port. The Hague is the seat of government of the Netherlands. These cities, combined with Utrecht and other smaller municipalities, effectively form a single metroplex\u2014a conurbation called Randstad.\nThe Randstad area is one of the most densely populated regions of Europe, but still relatively free of urban sprawl. There are strict zoning laws. Population pressures are enormous, property values are high, and new housing is constantly under development on the edges of the built-up areas. Nevertheless, much of the province still has a rural character. The remaining agricultural land and natural areas are highly valued and protected. Most of the arable land is used for intensive agriculture, including horticulture and greenhouse agri-businesses.\nReclamation of the land.\nThe land that is now Holland has not been geographically \"stable\" since prehistoric times. The western coastline shifted up to to the east and storm surges regularly broke through the row of coastal dunes. The Frisian Isles, originally joined to the mainland, became detached islands in the north. The main rivers, the Rhine and the Meuse (Maas), flooded regularly and changed course repeatedly and dramatically.\nThe people of Holland found themselves living in an unstable, watery environment. Behind the dunes on the coast of the Netherlands a high peat plateau had grown, forming a natural protection against the sea. Much of the area was marsh and bog. By the tenth century the inhabitants set about cultivating this land by draining it. However, the drainage resulted in extreme soil shrinkage, lowering the surface of the land by up to .\nTo the south of Holland, in Zeeland, and to the north, in Frisia, this development led to catastrophic storm floods literally washing away entire regions, as the peat layer disintegrated or became detached and was carried away by the flood water. From the Frisian side the sea even flooded the area to the east, gradually hollowing Holland out from behind and forming the Zuiderzee (the present IJsselmeer). This inland sea threatened to link up with the \"drowned lands\" of Zealand in the south, reducing Holland to a series of narrow dune barrier islands in front of a lagoon. Only drastic administrative intervention saved the county from utter destruction. The counts and large monasteries took the lead in these efforts, building the first heavy emergency dikes to bolster critical points. Later special autonomous administrative bodies were formed, the \"waterschappen\" (\"water control boards\"), which had the legal power to enforce their regulations and decisions on water management. They eventually constructed an extensive dike system that covered the coastline and the polders, thus protecting the land from further incursions by the sea.\nHollanders began land reclamation projects around the 16th century, converting lakes, marshy areas and adjoining mudflats into polders. This continued well into the 20th century. As a result, historical maps of medieval and early modern Holland bear little resemblance to present maps.\nCulture.\nThe stereotypical image of Holland is a contrived amalgam of tulips, windmills, clogs, Edam cheese and the traditional dress (\"\") of the village of Volendam, far from the reality of everyday Holland. These stereotypes were deliberately created in the late 19th century by official \"Holland Promotion\" to attract tourists.\nThe predominance of Holland in the Netherlands has resulted in regionalism on the part of the other provinces, a reaction to the perceived threat that Holland poses to their local culture and identity. The other provinces have a strong, and often negative, image of Holland and the Hollanders, to whom certain qualities are ascribed within a mental geography, a conceptual mapping of spaces and their inhabitants. On the other hand, some Hollanders take Holland's cultural dominance for granted and treat the concepts of \"Holland\" and \"the Netherlands\" as coinciding. Consequently, they see themselves not primarily as Hollanders, but simply as Dutch (\"Nederlanders\"). This phenomenon has been called \"hollandocentrism\".\nLanguages.\nThe predominant language spoken in Holland is Dutch. Hollanders sometimes call the Dutch language \"Hollands,\" instead of the standard term \"Nederlands\". Inhabitants of Belgium and other provinces of the Netherlands use \"Hollands\" to mean a Hollandic dialect or strong accent.\nStandard Dutch was historically largely based on the dialect of the County of Holland, incorporating many traits derived from the dialects of the previously more powerful Duchy of Brabant and County of Flanders. Strong dialectal variation still exists throughout the Low Countries. Today, Holland proper is the region where the original dialects are least spoken, in many areas having been completely replaced by standard Dutch, and the Randstad has the largest influence on the developments of the standard language\u2014with the exception of the Dutch spoken in Belgium.\nDespite this correspondence between standard Dutch and the Dutch spoken in the Randstad, there are local variations within Holland itself that differ from standard Dutch. The main cities each have their own modern urban dialect, that can be considered a sociolect. Some people, especially in the area north of Amsterdam, still speak the original dialect of the county, Hollandic. This dialect is present in the north: Volendam and Marken and the area around there, West Friesland and the Zaanstreek; and in a southeastern fringe bordering the provinces of North Brabant and Utrecht. In the south on the island of Goeree-Overflakkee, Zeelandic is spoken.\nLegacy.\nNew Holland.\nThe province of Holland gave its name to a number of colonial settlements and regions that were called \"Nieuw Holland\" or New Holland. The largest was the island continent presently known as Australia: New Holland was first applied to Australia in 1644 by the Dutch seafarer Dirk Hartog as a Latin \"Nova Hollandia\", and remained in international use for 190 years. New Zealand was likewise named after the Dutch province of Zealand, after an exploratory voyage led by the Dutch explorer Abel Tasman landed there. In the Netherlands \"Nieuw Holland\" would remain the usual name of the continent until the end of the 19th century; it is now no longer in use there, the Dutch name today being \"Australi\u00eb\".\nAs contemporary exonym for the Netherlands.\nWhile \"Holland\" has been replaced in English as the official name for the country of the Netherlands, many other languages use it or a variant of it to officially refer to the Netherlands. This is the case in Southeast Asia particularly Indonesia, Malaysia, and Cambodia for example:\nThis is also the case in certain European languages:\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "13289", "revid": "44514643", "url": "https://en.wikipedia.org/wiki?curid=13289", "title": "History of the Netherlands", "text": "The history of the Netherlands extends back before the founding of the modern Kingdom of the Netherlands in 1815 after the defeat of Napoleon. For thousands of years, people have been living together around the river deltas of this section of the North Sea coast. Records begin with the four centuries during which the region formed a militarized border zone of the Roman Empire. As the Western Roman Empire collapsed and the Middle Ages began, three dominant Germanic peoples coalesced in the area \u2013 Frisians in the north and coastal areas, Low Saxons in the northeast, and the Franks to the south. By 800, the Frankish Carolingian dynasty had once again integrated the area into an empire covering a large part of Western Europe. The region was part of the duchy of Lower Lotharingia within the Holy Roman Empire, but neither the empire nor the duchy were governed in a centralized manner. For several centuries, medieval lordships such as Brabant, Holland, Zeeland, Friesland, Guelders and others held a changing patchwork of territories.\nBy 1433, the Duke of Burgundy had assumed control over most of Lower Lotharingia, creating the Burgundian Netherlands. This included what is now the Netherlands, Belgium, Luxembourg, and a part of France. When their heirs the Catholic kings of Spain took measures against Protestantism, the subsequent Dutch revolt led to the splitting in 1581 of the Netherlands into southern and northern parts. The southern \"Spanish Netherlands\" corresponds approximately to modern Belgium and Luxembourg, and the northern \"United Provinces\" (or \"Dutch Republic)\", which spoke Dutch and was predominantly Protestant, was the predecessor of the modern Netherlands.\nIn the Dutch Golden Age, which had its zenith around 1667, there was a flowering of trade, industry, and the sciences. The Dutch Republic practiced religious toleration and Amsterdam attracted Portuguese Jews, many of whom were merchants, that practiced their religion and engaged in economic activity. A worldwide Dutch empire developed in Asia and the Americas. The Dutch East India Company became one of the earliest and most important of national mercantile companies of the time, based on invasion, colonialism, and extraction of outside resources, but not religious evangelization. During the eighteenth century, the power, wealth and influence of the Netherlands declined. A series of wars with the more powerful British and French neighbours weakened it. The English seized the North American colony of New Amsterdam, and renamed it \"New York\". There was growing unrest and conflict between the Orangists and the Patriots. The French Revolution spilled over after 1789, and a pro-French Batavian Republic was established in 1795\u20131806. Napoleon made it a satellite state, the Kingdom of Holland (1806\u20131810), and later simply a French imperial province.\nAfter the defeat of Napoleon in 1813\u20131815, an expanded \"United Kingdom of the Netherlands\" was created with the House of Orange as monarchs, also ruling Belgium and Luxembourg. After the King imposed unpopular Protestant reforms on Belgium, it left the kingdom in 1830 and new borders were agreed in 1839. After an initially conservative period, following the introduction of the 1848 constitution, the country became a parliamentary democracy with a constitutional monarch. Modern-day Luxembourg became officially independent of the Netherlands in 1839, but a personal union remained until 1890. Since 1890, it is ruled by another branch of the same dynasty.\nThe Netherlands was neutral during the First World War, but during the Second World War, it was invaded and occupied by Nazi Germany. The Nazis, including many collaborators, rounded up and killed almost all of the country's Jewish population. When the Dutch resistance increased, the Nazis cut off food supplies to much of the country, causing severe starvation in 1944\u20131945. In 1942, the Dutch East Indies were conquered by Japan, but prior to this the Dutch destroyed the oil wells for which Japan was desperate. Indonesia proclaimed its independence from the Netherlands in 1945, followed by Suriname in 1975. The post-war years saw rapid economic recovery (helped by the American Marshall Plan), followed by the introduction of a welfare state during an era of peace and prosperity. The Netherlands formed a new economic alliance with Belgium and Luxembourg, the Benelux, and all three became founding members of the European Union and NATO. In recent decades, the Dutch economy has been closely linked to that of Germany and is highly prosperous. The four countries adopted the euro on 1 January 2002, along with eight other EU member states.\nPrehistory (before 57 BC).\nDuring the last ice age, the Netherlands had a tundra climate with scarce vegetation, and the inhabitants survived as hunter-gatherers. The Swifterbant culture, appearing around 5600 BC were hunter gatherers strongly linked to rivers and open water and related to the southern Scandinavian Erteb\u00f8lle culture.\nAgriculture also arrived in areas near the Netherlands somewhere around 5000 BC with the Linear Pottery culture, who were central European farmers with Mediterranean ancestry. Their farms were restricted to southern Limburg and only temporarily established. However, there is some evidence that the coastal Swifterband people took up pottery and animal husbandry in the rest of the country. Local groups made the switch to animal husbandry sometime between 4800 BC and 4500 BC. By about 4000 BC the Funnelbeaker culture brought farming permanently into the region. This culture extended from Denmark through northern Germany into the northern Netherlands. The Vlaardingen culture continued the hunter-gatherer tradition in coastal areas.\nBy around 2950 BCE, there was a transition from the Funnelbeaker farming culture to the Corded Ware culture which extended across much of northern and central Europe. The expansion of this culture is believed to have involved the movement of people from the direction of Ukraine, bringing Indo-European languages and Copper Age technology. The earliest bronze tools were in the Wageningen horde, found in the grave of a Bronze Age metalworker. The Elp culture in the north and the Hilversum culture in the south developed during the Bronze Age, with the latter having cultural ties with Britain.\nThe Iron Age brought a measure of prosperity to the people living in the area of the present-day Netherlands with iron ore available throughout the country. Smiths travelled from small settlement to settlement with bronze and iron, fabricating tools on demand, including axes, knives, pins, arrowheads and swords. The Vorstengraf large burial mound contained a number of objects, including a curved iron sword. Leading up to the arrival of the Romans, the probably Germanic Harpstedt culture rose in the north possibly migrating from Scandinavia due to climatic deterioration which had separated into a northern group that would later become early Frisians and early Saxons and a southern group that extended into the Rhine which eventually developed into the Salian Franks, while further to the south were peoples influenced by the Hallstatt culture who eventually assimilated into the Celtic La T\u00e8ne culture with some mixture between the two. This is consistent with Caesar's account of the Rhine forming the boundary between Celtic and Germanic tribes. Some scholars have speculated that a separate ethnic identity with its own language that was neither Germanic nor Celtic, formed a Nordwestblock stretching from the Somme to the Weser and survived until the Roman period before being absorbed by their Celtic and Germanic neighbours.\nRoman era (57 BC \u2013 410 AD).\nDuring his Gallic Wars, Julius Caesar conquered all of Gaul for Rome, and this included the Netherlands south of the Rhine. He also wrote about his experiences in his \"Commentarii de Bello Gallico\", which is the first surviving written account of the region. Caesar mentioned the Menapii living in the river delta, and the Eburones to their southeast towards what is now Limburg. He called the land between the Rhine and Waal \"the island of the Batavi\" (\"insula batavorum\"). He portrayed the Rhine as a natural boundary between the Gauls and Germanic peoples on the other side but he understood that peoples such as the Eburones had a kinship with their neighbours over the river. Later Roman authors such as Tacitus and Pliny the Elder describe the region north of the Rhine being inhabited by the Frisii, Chamavi and Tubantes. Within the delta lived the Cananefates, Batavians, Sturii, Marsacii, and Frisiavones. The Texuandri, Baetasii and Tungri lived south of the delta.\nThe 450 years of Roman rule profoundly changed the region that would later become the Netherlands. The Rhine was a militarized border, frequently destabilized by violent incursions, and Rome recruited soldiers on both sides of it. The tribes of the region were esteemed soldiers in the empire, often serving in the Roman cavalry. The frontier culture was influenced by Roman, Germanic, and Gaulish elements, and trade flourished after Rome's conquest of Gaul. There were still grievances against Roman rule, including the taking of young Batavians as slaves. This led to the Batavian rebellion under Gaius Julius Civilis in 69 AD, which resulted in the burning of several Roman Castellum and the desertion of sections of the northern Roman army. In April 70 AD, legions led by Quintus Petillius Cerialis defeated the rebels.\nThe Batavians were considered the \"true\" forefathers of the Dutch by 17th and 18th-century writers, inspiring the naming of colonial Jakarta as \"Batavia\" in 1619 and the Batavian Republic of 1795. The term \"Batavian\" is occasionally used to describe the Dutch today, similar to how \"Gallic\" describes the French. A Frankish identity emerged in the lower and middle Rhine valley during the first half of the 3rd century, forming a confederation of smaller Germanic groups including the descendants of the Batavian rebels. The Frisii probably disappeared from the northern Netherlands with the last reference to them in c. 296, likely due to resettlement to other areas of Roman control and coastal flooding.\nEarly Middle Ages (411\u20131000).\nFrisians.\nAs climatic conditions improved, there was another mass migration of Germanic peoples into the area from the east. This is known as the \"Migration Period\" (\"Volksverhuizingen\"). The northern Netherlands received an influx of new migrants and settlers, mostly Saxons, but also Angles and Jutes. Many of these migrants did not stay in the northern Netherlands but moved on to England and are known today as the Anglo-Saxons. The newcomers who stayed in the northern Netherlands would eventually be referred to as \"Frisians\", although they were not descended from the ancient Frisii. These new Frisians settled in the northern Netherlands and would become the ancestors of the modern Frisians. (Because the early Frisians and Anglo-Saxons were formed from largely identical tribal confederacies, their respective languages were very similar. Old Frisian is the most closely related language to Old English and the modern Frisian dialects are in turn the closest related languages to contemporary English.) By the end of the 6th century, the Frisian territory in the northern Netherlands had expanded west to the North Sea coast and, by the 7th century, south to Dorestad. During this period most of the northern Netherlands was known as Frisia. This extended Frisian territory is sometimes referred to as \"Frisia Magna\" (or Greater Frisia).\nIn the 7th and 8th centuries, the Frankish chronologies mention this area as the kingdom of the Frisians. This kingdom comprised the coastal provinces of the Netherlands and the German North Sea coast. During this time, the Frisian language was spoken along the entire southern North Sea coast. The 7th-century Frisian Kingdom (650\u2013734) under King Aldegisel and King Redbad, had its centre of power in Utrecht.\nDorestad was the largest settlement (emporia) in northwestern Europe. It had grown around a former Roman fortress. It was a large, flourishing trading place, three kilometers long and situated where the rivers Rhine and Lek diverge southeast of Utrecht near the modern town of Wijk bij Duurstede. Although inland, it was a North Sea trading centre that primarily handled goods from the Middle Rhineland. Wine was among the major products traded at Dorestad, likely from vineyards south of Mainz. It was also widely known because of its mint. Between 600 and around 719 Dorestad was often fought over between the Frisians and the Franks.\nFranks.\nAfter Roman government in the area collapsed, the Franks expanded their territories until there were numerous small Frankish kingdoms, especially at Cologne, Tournai, Le Mans and Cambrai. The kings of Tournai eventually came to subdue the other Frankish kings. By the 490s, Clovis I had conquered and united all the Frankish territories to the west of the Meuse, including those in the southern Netherlands. He continued his conquests into Gaul.\nAfter the death of Clovis I in 511, his four sons partitioned his kingdom amongst themselves, with Theuderic I receiving the lands that were to become Austrasia (including the southern Netherlands). A line of kings descended from Theuderic ruled Austrasia until 555, when it was united with the other Frankish kingdoms of Chlothar I, who inherited all the Frankish realms by 558. He redivided the Frankish territory amongst his four sons, but the four kingdoms coalesced into three on the death of Charibert I in 567. Austrasia (including the southern Netherlands) was given to Sigebert I. The southern Netherlands remained the northern part of Austrasia until the rise of the Carolingians.\nThe Franks who expanded south into Gaul settled there and eventually adopted the Vulgar Latin of the local population. However, a Germanic language was spoken as a second tongue by public officials in western Austrasia and Neustria as late as the 850s. It completely disappeared as a spoken language from these regions during the 10th century. During this expansion to the south, many Frankish people remained in the north (i.e. southern Netherlands, Flanders and a small part of northern France). A widening cultural divide grew between the Franks remaining in the north and the rulers far to the south in what is now France. Salian Franks continued to reside in their original homeland and the area directly to the south and to speak their original language, Old Frankish, which by the 9th century had evolved into Old Dutch. A Dutch-French language boundary came into existence (but this was originally south of where it is today). In the Maas and Rhine areas of the Netherlands, the Franks had political and trading centres, especially at Nijmegen and Maastricht. These Franks remained in contact with the Frisians to the north, especially in places like Dorestad and Utrecht.\nDoubts over archaeological divisions.\nIn the 19th century, Dutch historians believed that the Franks, Frisians, and Saxons had populated and inhabited the Low Countries, but this theory fell out of favour in the 20th century. Due to the scarcity of written sources, knowledge of this period depends to a large degree on the interpretation of archaeological data. The traditional view of a clear-cut division between Frisians in the north and coast, Franks in the south and Saxons in the east has proven historically problematic. Archeological evidence suggests dramatically different models for different regions, with demographic continuity for some parts of the country and depopulation and possible replacement in other parts, notably the coastal areas of Frisia and Holland.\nEmergence of the Dutch language.\nThe language from which Old Dutch arose is unknown with certainty, but it is thought to be the language spoken by the Salian Franks. Even though the Franks are traditionally categorized as Weser\u2013Rhine Germanic, Dutch has a number of Ingvaeonic characteristics and is classified by modern linguists as an Ingvaeonic language. Dutch also has a number of Old Saxon characteristics. There was a close relationship between Old Dutch, Old Saxon, Old English and Old Frisian. Because texts written in the language spoken by the Franks are almost non-existent, and Old Dutch texts scarce and fragmentary, not much is known about the development of Old Dutch. Old Dutch made the transition to Middle Dutch around 1150.\nChristianization.\nThe Christianity that arrived in the Netherlands with the Romans appears not to have died out completely (in Maastricht, at least) after the withdrawal of the Romans in about 411.\nThe Franks became Christians after their king Clovis I converted to Catholicism, an event which is traditionally set in 496. Christianity was introduced in the north after the conquest of Friesland by the Franks. The Saxons in the east were converted before the conquest of Saxony, and became Frankish allies.\nHiberno-Scottish and Anglo-Saxon missionaries, particularly Willibrord, Wulfram and Boniface, played an important role in converting the Frankish and Frisian peoples to Christianity by the 8th century. Boniface was martyred by the Frisians in Dokkum (754).\nFrankish dominance and incorporation into the Holy Roman Empire.\nIn the early 8th century the Frisians came increasingly into conflict with the Franks to the south, resulting in a series of wars in which the Frankish Empire eventually subjugated Frisia. In 734, at the Battle of the Boarn, the Frisians in the Netherlands were defeated by the Franks, who thereby conquered the area west of the Lauwers. The Franks then conquered the area east of the Lauwers in 785 when Charlemagne defeated Widukind.\nThe linguistic descendants of the Franks, the modern Dutch -speakers of the Netherlands and Flanders, seem to have broken with the endonym \"Frank\" around the 9th century. By this time Frankish identity had changed from an ethnic identity to a national identity, becoming localized and confined to the modern \"Franconia\" and principally to the French province of \"\u00cele-de-France\".\nAlthough the people no longer referred to themselves as \"Franks\", the Netherlands was still part of the Frankish empire of Charlemagne. Indeed, because of the Austrasian origins of the Carolingians in the area between the Rhine and the Maas, the cities of Aachen, Maastricht, Li\u00e8ge and Nijmegen were at the heart of Carolingian culture. Charlemagne maintained his \"palatium\" in Nijmegen at least four times.\nThe Carolingian empire would eventually include France, Germany, northern Italy and much of Western Europe. In 843, the Frankish empire was divided into three parts, giving rise to West Francia in the west, East Francia in the east, and Middle Francia in the centre. Most of what is today the Netherlands became part of Middle Francia; Flanders became part of West Francia. This division was an important factor in the historical distinction between Flanders and the other Dutch-speaking areas.\nMiddle Francia () was an ephemeral Frankish kingdom that had no historical or ethnic identity to bind its varied peoples. It was created by the Treaty of Verdun in 843, which divided the Carolingian Empire among the sons of Louis the Pious. Situated between the realms of East and West Francia, Middle Francia comprised the Frankish territory between the rivers Rhine and Scheldt, the Frisian coast of the North Sea, the former Kingdom of Burgundy (except for a western portion, later known as \"Bourgogne\"), Provence and the Kingdom of Italy.\nMiddle Francia fell to Lothair I, the eldest son and successor of Louis the Pious, after an intermittent civil war with his younger brothers Louis the German and Charles the Bald. In acknowledgement of Lothair's Imperial title, Middle Francia contained the imperial cities of Aachen, the residence of Charlemagne, as well as Rome. In 855, on his deathbed at Pr\u00fcm Abbey, Emperor Lothair I again partitioned his realm amongst his sons. Most of the lands north of the Alps, including the Netherlands, passed to Lothair II and consecutively were named Lotharingia. After Lothair II died in 869, Lotharingia was partitioned by his uncles Louis the German and Charles the Bald in the Treaty of Meerssen in 870. Although some of the Netherlands had come under Viking control, in 870 it technically became part of East Francia, which became the Holy Roman Empire in 962.\nViking raids.\nIn the 9th and 10th centuries, the Vikings raided the largely defenceless Frisian and Frankish towns lying on the coast and along the rivers of the Low Countries. Although Vikings never settled in large numbers in those areas, they did set up long-term bases and were even acknowledged as lords in a few cases. In Dutch and Frisian historical tradition, the trading centre of Dorestad declined after Viking raids from 834 to 863; however, since no convincing Viking archaeological evidence has been found at the site (as of 2007), doubts about this have grown in recent years.\nOne of the most important Viking families in the Low Countries was that of Rorik of Dorestad (based in Wieringen) and his brother the \"younger Harald\" (based in Walcheren), both thought to be nephews of Harald Klak. Around 850, Lothair I acknowledged Rorik as ruler of most of Friesland. And again in 870, Rorik was received by Charles the Bald in Nijmegen, to whom he became a vassal. Viking raids continued during that period. Harald's son Rodulf and his men were killed by the people of Oostergo in 873. Rorik died sometime before 882.\nBuried Viking treasures consisting mainly of silver have been found in the Low Countries. Two such treasures have been found in Wieringen. A large treasure found in Wieringen in 1996 dates from around 850 and is thought perhaps to have been connected to Rorik. The burial of such a valuable treasure is seen as an indication that there was a permanent settlement in Wieringen.\nAround 879, Godfrid arrived in Frisian lands as the head of a large force that terrorised the Low Countries. Using Ghent as his base, they ravaged Ghent, Maastricht, Li\u00e8ge, Stavelot, Pr\u00fcm, Cologne, and Koblenz. Controlling most of Frisia between 882 and his death in 885, Godfrid became known to history as Godfrid, Duke of Frisia. His lordship over Frisia was acknowledged by Charles the Fat, to whom he became a vassal. Godfried was assassinated in 885, after which Gerolf of Holland assumed lordship and Viking rule of Frisia came to an end.\nViking raids of the Low Countries continued for over a century. Remains of Viking attacks dating from 880 to 890 have been found in Zutphen and Deventer. In 920, King Henry of Germany liberated Utrecht. According to a number of chronicles, the last attacks took place in the first decade of the 11th century and were directed at Tiel and/or Utrecht.\nThese Viking raids occurred about the same time that French and German lords were fighting for supremacy over the middle empire that included the Netherlands, so their sway over this area was weak. Resistance to the Vikings, if any, came from local nobles, who gained in stature as a result.\nHigh and Late Middle Ages (1000\u20131433).\nPart of the Holy Roman Empire.\nThe German kings and emperors ruled the Netherlands in the 10th and 11th century, with the assistance of the Dukes of Lotharingia, and the bishops of Utrecht and Li\u00e8ge. Germany was called the Holy Roman Empire after the coronation of King Otto the Great as emperor. The Dutch city of Nijmegen used to be the spot of an important domain of the German emperors. Several German emperors were born and died there, including, for example, Byzantine empress Theophanu, who died in Nijmegen. Utrecht was also an important city and trading port at the time.\nPolitical disunity.\nThe Holy Roman Empire was not able to maintain political unity. In addition to the growing independence of the towns, local rulers turned their counties and duchies into private kingdoms and felt little sense of obligation to the emperor who reigned over large parts of the nation in name only. Large parts of what now comprise the Netherlands were governed by the Count of Holland, the Duke of Gelre, the Duke of Brabant and the Bishop of Utrecht. Friesland and Groningen in the north maintained their independence and were governed by the lower nobility.\nThe various feudal states were in a state of almost continual war. Gelre and Holland fought for control of Utrecht. Utrecht, whose bishop had in 1000 ruled over half of what is today the Netherlands, was marginalised as it experienced continuing difficulty in electing new bishops. At the same time, the dynasties of neighbouring states were more stable. Groningen, Drenthe and most of Gelre, which used to be part of Utrecht, became independent. Brabant tried to conquer its neighbours, but was not successful. Holland also tried to assert itself in Zeeland and Friesland, but its attempts failed.\nThe Frisians.\nThe language and culture of most of the people who lived in the area that is now Holland were originally Frisian. The sparsely populated area was known as \"West Friesland\" (\"Westfriesland\"). A common theory states that Frankish migration from either Flanders, Utrecht or both displaced the Frisians in Holland, however no evidence has been found in support of this theory and more recent studies have suggested that Frisians from the mouth of the Rhine adopted the Franconian language, feudal system and religion, spreading this new 'Hollandic' identity northward over the centuries (the part of North Holland situated north of Alkmaar is still colloquially known as West Friesland).\nThe rest of Friesland in the north continued to maintain its independence during this time. It had its own institutions (collectively called the \"Frisian freedom\") and resented the imposition of the feudal system and the patriciate found in other European towns. They regarded themselves as allies of Switzerland. The Frisian battle cry was \"better dead than a slave\". They later lost their independence when they were defeated in 1498 by the German Landsknecht mercenaries of Duke Albrecht of Saxony-Meissen.\nThe rise of Holland.\nThe center of power in these emerging independent territories was in the County of Holland. Originally granted as a fief to the Danish chieftain Rorik in return for loyalty to the emperor in 862, the region of Kennemara (the region around modern Haarlem) rapidly grew under Rorik's descendants in size and importance. By the early 11th century, Dirk III, Count of Holland was levying tolls on the Meuse estuary and was able to resist military intervention from his overlord, the Duke of Lower Lorraine.\nIn 1083, the name \"Holland\" first appears in a deed referring to a region corresponding more or less to the current province of South Holland and the southern half of what is now North Holland. Holland's influence continued to grow over the next two centuries. The counts of Holland conquered most of Zeeland but it was not until 1289 that Count Floris V was able to subjugate the Frisians in West Friesland (that is, the northern half of North Holland).\nExpansion and growth.\nDraining of low-lying swampy areas and flood control was expanded significantly after 1200 CE. Before that, towns were built north of the major rivers, Utrecht, Kampen, Deventer, Zwolle, Nijmegen, and Zutphen, but with the expansion of dikes and drainage, cultivable land was created and population expanded. In this period, Holland expanded relative to the other regions. From the thirteenth century onwards, the necessity of controlling water in this northern was a given, transforming the physical environment, but also requiring institutions and cooperation between areas for water management. Drainage boards (\"heemraadschappen\") were established and the \"dike count\", took on responsibilities not only for water management issues, but also fiscal, policing, and judicial functions. By the end of the thirteenth century, Holland emerged in the dominant position of the northern region.\nThe southern Low Countries remained highly populous and developed and was among the most highly urbanized areas in Europe. Because of the east\u2013west flow of the Low Countries' large rivers, they were a military and political barrier between north and south. The southern Low Countries could not exert influence over the north. This division meant that the counts of Holland became politically important in the north. Holland extended its political power over Zeeland.\nGuilds were established and markets developed as production exceeded local needs. Also, the introduction of currency made trading a much easier affair than it had been before. Existing towns grew and new towns sprang into existence around monasteries and castles, and a mercantile middle class began to develop in these urban areas. Commerce and town development increased as the population grew.\nThe Crusades were popular in the Low Countries and drew many to fight in the Holy Land. At home, there was relative peace. Viking pillaging had stopped. Both the Crusades and the relative peace at home contributed to trade and the growth in commerce.\nCities arose and flourished, especially in Flanders and Brabant. As the cities grew in wealth and power, they started to buy certain privileges for themselves from the sovereign, including city rights, the right to self-government and the right to pass laws. In practice, this meant that the wealthiest cities became quasi-independent republics in their own right. Two of the most important cities were Bruges and Antwerp (in Flanders) which would later develop into some of the most important cities and ports in Europe.\nHook and Cod Wars.\nThe Hook and Cod Wars () were a series of wars and battles in the County of Holland between 1350 and 1490. Most of these wars were fought over the title of count of Holland, but some have argued that the underlying reason was because of the power struggle of the traders in the cities against the ruling nobility.\nThe Cod faction generally consisted of the more progressive cities of Holland. The Hook faction consisted for a large part of the conservative noblemen. Some of the main figures in this multi-generational conflict were William IV, Margaret, William V, William VI, Count of Holland and Hainaut, John and Philip the Good, Duke of Burgundy. But perhaps the most well known is Jacqueline, Countess of Hainaut.\nThe conquest of the county of Holland by the Duke Philip the Good of Burgundy was an odd affair. Leading noblemen in Holland invited the duke to conquer Holland, even though he had no historical claim to it. Some historians say that the ruling class in Holland wanted Holland to integrate with the Flemish economic system and adopt Flemish legal institutions. Europe had been wracked by many civil wars in the 14th and 15th centuries, while Flanders had grown rich and enjoyed peace.\nBurgundian and Habsburg period (1433\u20131567).\nBurgundian period.\nMost of what is now the Netherlands and Belgium was eventually united by the Duke of Burgundy, Phillip the Good (1396\u20131467). Before the Burgundian union, the Dutch identified themselves by the town they lived in, their local duchy or county or as subjects of the Holy Roman Empire. These collections of fiefs were ruled under the personal union of the House of Valois-Burgundy.\nTrade in the region developed rapidly, especially in the areas of shipping and transport. The new rulers defended Dutch trading interests. Amsterdam grew and in the 15th century became the primary trading port in Europe for grain from the Baltic region. Amsterdam distributed grain to the major cities of Belgium, Northern France and England. This trade was vital to the people of the region as they could no longer produce enough grain to feed themselves. Land drainage had caused the peat of the former wetlands to reduce to a level that was too low for drainage to be maintained.\nHabsburg rule from Spain.\nCharles V (1500\u20131558) was born and raised in the Flemish city of Ghent; he spoke French. Charles extended the Burgundian territory with the annexation of Tournai, Artois, Utrecht, Groningen and Guelders to create the Seventeen Provinces. The towns of the region had already been unified by Charles's Burgundian ancestors, but were nominally fiefs of either France or the Holy Roman Empire. When he was a minor, his aunt Margaret acted as regent until 1515. France relinquished its ancient claim on Flanders in 1528.\nFrom 1515 to 1523, Charles's government in the Netherlands had to contend with the rebellion of Frisian peasants (led by Pier Gerlofs Donia and Wijard Jelckama). Gelre attempted to build up its own state in northeast Netherlands and northwest Germany. Lacking funds in the 16th century, Gelre had soldiers provide for themselves by pillaging enemy lands. These soldiers were a great menace to the Habsburg Netherlands, as when they pillaged The Hague.\nThe dukes of Burgundy over the years through astute marriages, purchases and wars, had taken control of the Seventeen Provinces that made up the Low Countries. They are now the Netherlands in the north, the Southern Netherlands (now Belgium) in the south, and Luxemburg in the southeast. Known as the \"Burgundian Circle\", these lands came under the control of the Habsburg family.\nCharles became the ruler in 1506, but in 1515 he left the territory to become king of Spain and later Holy Roman Emperor. Charles turned over control to regents (his close relatives), and in practice the rule over the Low Countries were exercised by the Spaniards under his authority. The provinces each had their own governments and courts, controlled by the local nobility, and their own traditions and rights (\"liberties\") dating back centuries. Likewise the numerous cities had their own legal rights and local governments, usually controlled by the merchants. On top of this the Spanish had imposed a somewhat centralized government, the Estates General of the Netherlands, with its own officials and courts. The Spanish officials sent by Charles ignored traditions and the Dutch nobility as well as local officials, inciting an anti-Spanish sense of nationalism which led to the Dutch Revolt. With the emergence of the Protestant Reformation, Charles\u2014now the Emperor\u2014was determined to crush Protestantism. Unrest began in the south, centered in the large rich metropolis of Antwerp. The Netherlands was an especially rich unit of the Spanish realm, especially after the Treaty of Cateau-Cambr\u00e9sis of 1559; it ended four decades of warfare between France and Spain and allowed Spain to reposition its army.\nIn 1548, Charles granted the Netherlands status as an entity in which many of the laws of the Holy Roman Empire became obsolete. The \"Transaction of Augsburg\" created the Burgundian Circle of the Holy Roman Empire, which comprised the Netherlands and Franche-Comt\u00e9. A year later the Pragmatic Sanction of 1549 stated that the Seventeen Provinces could only be passed on to his heirs as a composite entity.\nThe Reformation.\nDuring the 16th century, the Protestant Reformation rapidly gained ground in northern Europe, especially in its Lutheran and Calvinist forms. Dutch Protestants, after initial repression, were tolerated by local authorities. By the 1560s, the Protestant community had become a significant influence in the Netherlands, although it clearly formed a minority then. In a society dependent on trade, freedom and tolerance were considered essential. Nevertheless, the Catholic rulers Charles V, and later Philip II, made it their mission to defeat Protestantism, which was considered a heresy by the Catholic Church and a threat to the stability of the whole hierarchical political system. On the other hand, the intensely moralistic Dutch Protestants insisted their Biblical theology, sincere piety and humble lifestyle was morally superior to the luxurious habits and superficial religiosity of the ecclesiastical nobility. The rulers' harsh punitive measures led to increasing grievances in the Netherlands, where the local governments had embarked on a course of peaceful coexistence. In the second half of the century, the situation escalated. Philip sent troops to crush the rebellion and make the Netherlands once more a Catholic region.\nIn the first wave of the Reformation, Lutheranism won over the elites in Antwerp and the South. The Spanish successfully suppressed it there, and Lutheranism only flourished in east Friesland.\nThe second wave of the Reformation, came in the form of Anabaptism, that was popular among ordinary farmers in Holland and Friesland. Anabaptists were socially very radical and equalitarian; they believed that the apocalypse was very near. They refused to live the old way, and began new communities, creating considerable chaos. A prominent Dutch Anabaptist was Menno Simons, who initiated the Mennonite church. The movement was allowed in the north, but never grew to a large scale.\nThe third wave of the Reformation, that ultimately proved to be permanent, was Calvinism. It arrived in the Netherlands in the 1540s, attracting both the elite and the common population, especially in Flanders. The Catholic Spanish responded with harsh persecution and introduced the Inquisition of the Netherlands. Calvinists rebelled. First there was the iconoclasm in 1566, which was the systematic destruction of statues of saints and other Catholic devotional depictions in churches. In 1566, William the Silent, a Calvinist, started the Eighty Years' War to liberate all Dutch of whatever religion from Catholic Spain. Blum says, \"His patience, tolerance, determination, concern for his people, and belief in government by consent held the Dutch together and kept alive their spirit of revolt.\" The provinces of Holland and Zeeland, being mainly Calvinist by 1572, submitted to the rule of William. The other states remained almost entirely Catholic.\nPrelude to war.\nThe Netherlands was a valuable part of the Spanish Empire, especially after the Treaty of Cateau-Cambresis of 1559. This treaty ended a forty-year period of warfare between France and Spain conducted in Italy from 1521 to 1559. The Treaty of Cateau-Cambresis was somewhat of a watershed\u2014not only for the battleground that Italy had been, but also for northern Europe. Spain had been keeping troops in the Netherlands to be ready to attack France from the north as well as from the south.\nWith the settlement of so many major issues between France and Spain by the Treaty of Cateau-Cambresis, there was no longer any reason to keep Spanish troops in the Netherlands. Thus, the people of the Netherlands could get on with their peacetime pursuits. As they did so they found that there was a great deal of demand for their products. Fishing had long been an important part of the economy of the Netherlands. However, now the fishing of herring alone came to occupy 2,000 boats operating out of Dutch ports. Spain, still the Dutch trader's best customer, was buying fifty large ships full of furniture and household utensils from Flanders merchants. Additionally, Dutch woolen goods were desired everywhere. The Netherlands bought and processed enough Spanish wool to sell four million florins of wool products through merchants in Bruges. So strong was the Dutch appetite for raw wool at this time that they bought nearly as much English wool as they did Spanish wool. Total commerce with England alone amounted to 24 million florins. Much of the export going to England resulted in pure profit to the Dutch because the exported items were of their own manufacture. The Netherlands was just starting to enter its \"Golden Age.\" Brabant and Flanders were the richest and most flourishing parts of the Dutch Republic at the time. The Netherlands was one of the richest places in the world. The population reached 3 million in 1560, with 25 cities of 10,000 people or more, by far the largest urban presence in Europe; with the trading and financial center of Antwerp being especially important (population 100,000). Spain could not afford to lose this rich land, nor allow it to fall from Catholic control. Thus came 80 years of warfare.\nA devout Catholic, Philip was appalled by the success of the Reformation in the Low Countries, which had led to an increasing number of Calvinists. His attempts to enforce religious persecution of the Protestants, and his centralization of government, law enforcement, and taxes, made him unpopular and led to a revolt. Fernando Alvarez de Toledo, Duke of Alba, was sent with a Spanish Army to punish the unruly Dutch in 1567.\nThe only opposition the Duke of Alba faced in his march across the Netherlands were the nobles, Lamoral, Count of Egmont; Philippe de Montmorency, Count of Horn and others. With the approach of Alba and the Spanish army, William the Silent of Orange fled to Germany with his three brothers and his whole family on 11 April 1567. The Duke of Alba sought to meet and negotiate with the nobles that now faced him with armies. However, when the nobles arrived in Brussels they were all arrested and Egmont and Horn were executed. Alba then revoked all the prior treaties that Margaret, the Duchess of Parma had signed with the Protestants of the Netherlands and instituted the Inquisition to enforce the decrees of the Council of Trent.\nThe Eighty Years' War (1568\u20131648).\nThe Dutch War for Independence from Spain is frequently called the Eighty Years' War (1568\u20131648). The first fifty years (1568 through 1618) were a war solely between Catholic Spain and the Protestant rebels of the Netherlands. It was a military conflict with integral religious elements. During the last thirty years (1618\u20131648) the conflict between Spain and the Netherlands was submerged in the general European War that became known as the Thirty Years' War. The seven rebellious provinces of the Netherlands were eventually united by the Union of Utrecht in 1579 and formed the Republic of the Seven United Netherlands (also known as the \"United Provinces\"). The Act of Abjuration or \"Plakkaat van Verlatinghe\" was signed on 26 July 1581, and was the formal declaration of independence of the northern Low Countries from the Spanish king. Religious toleration was a key element of Protestant ideology.\nWilliam of Orange (1533\u20131584), the founder of the Dutch royal family, led the Dutch during the first part of the war. The very first years were a success for the Spanish troops. However, the Dutch countered subsequent sieges in Holland. In November and December 1572, all the citizens of Zutphen and Naarden were slaughtered by the Spanish. From 11 December that year the city of Haarlem was besieged, holding out for seven months until 13 July 1573. Oudewater was conquered by the Spanish on 7 August 1575, and most of its inhabitants were killed. Maastricht was besieged, sacked and destroyed twice in succession (in 1576 and 1579) by the Spanish.\nIn a war largely of sieges rather than battles, Governor-General Alexander Farnese proved his mettle. His strategy was to offer generous terms for the surrender of a city: there would be no more massacres or looting; historic urban privileges were retained; there was a full pardon and amnesty; return to the Catholic Church would be gradual. Conservative Catholics in the south and east supported the Spanish. Farnese recaptured Antwerp and nearly all of what became Belgium. Most of the Dutch-speaking territory in the Netherlands was taken from Spain, but not in Flanders, which to this day remains part of Belgium. Flanders was the most radical anti-Spanish territory. Many Flemish fled to Holland, among them half of the population of Antwerp, 3/4 of Bruges and Ghent and the entire population of Nieuwpoort, Dunkerque and countryside. His successful campaign gave the Catholics control of the lower half of the Low Countries, and was part of the Catholic Counter-Reformation.\nThe war dragged on for another half century, but the main fighting was over. The Peace of Westphalia, signed in 1648, confirmed the independence of the United Provinces from Spain. The Dutch people started to develop a national identity, beginning in the 15th century, but they officially remained a part of the Holy Roman Empire until 1648. National identity was mainly formed by the province people came from. Holland was the most important province by far.\nThe Catholics in the Netherlands were an outlawed minority that had been suppressed by the Calvinists. After 1572, however, they made a striking comeback (also as part of the Catholic Counter-Reformation), setting up seminaries, reforming their Church, and sending missionaries into Protestant districts. Laity often took the lead; the Calvinist government often arrested or harassed priests who seemed too effective. Catholic numbers stabilized at about a third of the population in the Netherlands; they were strongest in the southeast.\nGolden Age.\nThe \"Dutch Golden Age\" was a period which roughly lasted from 1588, when the Dutch Republic was established, to 1672, when the \"Rampjaar\" occurred. During this period, Dutch trade, scientific developments, art and overseas colonisation was among the most prominent in Europe. The first half of the period spanned from the beginning of the Eighty Years' War until its conclusion in 1648, with the second half lasting until the outbreak of the Franco-Dutch War. During the period, Dutch colonialists, many of them affiliated with the East India Company and West India Company, established trading posts and colonies in the Americas, Southern Africa and Asia, protected by the powerful Dutch States Navy. The Dutch dominated the triangular trade and Atlantic slave trade.\nDutch culture experienced a renaissance. However, by the end of the 17th century, conflicts with neighbouring powers as well as a declining economic influence led to waning of Dutch power. The process by which the Dutch Republic became one of the foremost maritime and economic powers of the world during the era has been referred to as the \"Dutch Miracle\" by historian K. W. Swart. The term \"Dutch Golden Age\" has been controversial in the 21st century due to the extensive Dutch involvement in slavery and colonialism during the period, and it has been deprecated by several museums in the Netherlands, including the Amsterdam Museum.\nDutch Empire.\nThe Dutch in the Americas.\nThe Dutch West India Company was a chartered company (known as the \"GWC\") of Dutch merchants. On 2 June 1621, it was granted a for a trade monopoly in the West Indies (meaning the Caribbean) by the Republic of the Seven United Netherlands and given jurisdiction over the African slave trade, Brazil, the Caribbean, and North America. Its area of operations stretched from West Africa to the Americas, and the Pacific islands. The company became instrumental in the Dutch colonization of the Americas. The first forts and settlements in Guyana and on the Amazon River date from the 1590s. Actual colonization, with Dutch settling in the new lands, was not as common as with England and France. Many of the Dutch settlements were lost or abandoned by the end of that century, but the Netherlands managed to retain possession of Suriname and a number of Dutch Caribbean islands.\nThe colony was a private business venture to exploit the fur trade in beaver pelts. New Netherland was slowly settled during its first decades, partially as a result of policy mismanagement by the Dutch West India Company (WIC), and conflicts with Native Americans. During the 1650s, the colony experienced dramatic growth and became a major port for trade in the Atlantic World, tolerating a highly diverse ethnic mix. The surrender of Fort Amsterdam to the British control in 1664 was formalized in 1667, contributing to the Second Anglo\u2013Dutch War. In 1673 the Dutch re-took the area, but later relinquished it under the 5 April 1674 Treaty of Westminster ending the Third Anglo-Dutch War.\nDescendants of the original settlers played a prominent role in the history of the United States, as typified by the Roosevelt and Vanderbilt families. The Hudson Valley still boasts a Dutch heritage. The concepts of civil liberties and pluralism introduced in the province became mainstays of American political and social life.\nSlave trade.\nAlthough slavery was illegal inside the Netherlands it flourished in the Dutch Empire, and helped support the economy. In 1619 The Netherlands took the lead in building large-scale slave trading between Africa and Virginia, by 1650 becoming the pre-eminent slave trading country in Europe. It was overtaken by Britain around 1700. Historians agree that in all the Dutch shipped about 550,000 African slaves across the Atlantic, about 75,000 of whom died on board before reaching their destinations. From 1596 to 1829, the Dutch traders sold 250,000 slaves in the Dutch Guianas, 142,000 in the Dutch Caribbean islands, and 28,000 in Dutch Brazil. In addition, tens of thousands of slaves, mostly from India and some from Africa, were carried to the Dutch East Indies and slaves from the East Indies to Africa and the West Indies.\nThe Dutch in Asia: The Dutch East India Company.\nThe Dutch East India Company (also called the VOC) emerged in 1602, when the government gave it a monopoly to trade with Asia, mainly to Mughal India. It had many world firsts\u2014the first multinational corporation, the first company to issue stock, and the first megacorporation, possessing quasi-governmental powers, including the ability to wage war, negotiate treaties, coin money, and establish colonial settlements.\nEngland and France soon copied its model but could not match its record. Between 1602 and 1796 the VOC sent almost a million Europeans to work in the Asia trade on 4,785 ships. It returned over 2.5\u00a0million tons of Asian trade goods. The VOC enjoyed huge profits from its spice monopoly through most of the 17th century. The VOC was active chiefly in the Dutch East Indies, now Indonesia, where its base was Batavia (now Jakarta), which remained an important trading concern and paid an 18% annual dividend for almost 200 years; colonized parts of Taiwan between 1624\u20131662 and 1664\u20131667 and was the only western trading post in Japan, Dejima.\nDuring the period of Proto-industrialization, the empire received 50% of textile and 80% of silk imports from the Mughal Empire, chiefly from its most developed region known as the Bengal Subah.\nBy the 17th century, the Dutch East India Company established their base in parts of Ceylon (modern-day Sri Lanka). Afterward, they established ports in Dutch occupied Malabar, leading to Dutch settlements and trading posts in India. However, their expansion into India was halted, after their defeat in the Battle of Colachel by the Kingdom of Travancore, during the Travancore-Dutch War. The Dutch never recovered from the defeat and no longer posed a large colonial threat to India.\nEventually, the 18th century saw the Dutch East India Company weighed down by corruption, and the VOC eventually went bankrupt in 1800. Its possessions were taken over by the government and turned into the Dutch East Indies.\nThe Dutch in Africa.\nIn 1647, a Dutch vessel was wrecked in the present-day Table Bay at Cape Town. The marooned crew, the first Europeans to attempt settlement in the area, built a fort and stayed for a year until they were rescued. Shortly thereafter, the Dutch East India Company (in the Dutch of the day: \"Vereenigde Oostindische Compagnie\", or VOC) decided to establish a permanent settlement. The VOC, one of the major European trading houses sailing the spice route to East Asia, had no intention of colonizing the area, instead wanting only to establish a secure base camp where passing ships could shelter, and where hungry sailors could stock up on fresh supplies of meat, fruit, and vegetables. To this end, a small VOC expedition under the command of Jan van Riebeeck reached Table Bay on 6 April 1652.\nTo remedy a labour shortage, the VOC released a small number of VOC employees from their contracts and permitted them to establish farms with which they would supply the VOC settlement from their harvests. This arrangement proved highly successful, producing abundant supplies of fruit, vegetables, wheat, and wine; they also later raised livestock. The small initial group of \"free burghers\", as these farmers were known, steadily increased in number and began to expand their farms further north and east.\nThe majority of burghers had Dutch ancestry and belonged to the Calvinist Reformed Church of the Netherlands, but there were also numerous Germans as well as some Scandinavians. In 1688 the Dutch and the Germans were joined by French Huguenots, also Calvinists, who were fleeing religious persecution in France under King Louis XIV. The Huguenots in South Africa were absorbed into the Dutch population but they played a prominent role in South Africa's history.\nFrom the beginning, the VOC used the cape as a place to supply ships travelling between the Netherlands and the Dutch East Indies. There was a close association between the cape and these Dutch possessions in the far east. Van Riebeeck and the VOC began to import large numbers of slaves, primarily from Madagascar and Indonesia. These slaves often married Dutch settlers, and their descendants became known as the Cape Coloureds and the Cape Malays.\nDuring the 18th century, the Dutch settlement in the area of the cape grew and prospered. By the late 1700s, the Cape Colony was one of the best developed European settlements outside Europe or the Americas. The two bases of the Cape Colony's economy for almost the entirety of its history were shipping and agriculture. Its strategic position meant that almost every ship sailing between Europe and Asia stopped off at the colony's capital Cape Town. The supplying of these ships with fresh provisions, fruit, and wine provided a very large market for the surplus produce of the colony.\nSome free burghers continued to expand into the rugged hinterlands of the north and east, many began to take up a semi-nomadic pastoralist lifestyle, in some ways not far removed from that of the Khoikhoi they had displaced. In addition to its herds, a family might have a wagon, a tent, a Bible, and a few guns. As they became more settled, they would build a mud-walled cottage, frequently located, by choice, days of travel from the nearest European settlement. These were the first of the Trekboers (Wandering Farmers, later shortened to Boers), completely independent of official controls, extraordinarily self-sufficient, and isolated from the government and the main settlement in Cape Town.\nDutch was the official language, but a dialect had formed that was quite distinct from Dutch. The Afrikaans language originated mainly from 17th-century Dutch dialects.\nThis Dutch dialect sometimes referred to as the \"kitchen language\" (\"kombuistaal\"), would eventually in the late 19th century be recognised as a distinct language called Afrikaans and replace Dutch as the official language of the Afrikaners.\nAs the 18th century drew to a close, Dutch mercantile power began to fade and the British moved in to fill the vacuum. They seized the Cape Colony in 1795 to prevent it from falling into French hands, then briefly relinquished it back to the Dutch (1803), before definitively conquering it in 1806. British sovereignty of the area was recognised at the Congress of Vienna in 1815. By the time the Dutch colony was seized by the British in 1806, it had grown into an established settlement with 25,000 slaves, 20,000 white colonists, 15,000 Khoisan, and 1,000 freed black slaves. Outside Cape Town and the immediate hinterland, isolated black and white pastoralists populated the country.\nDutch interest in South Africa was based chiefly on the strategically located VOC port. Yet in the 17th and 18th centuries the Dutch created the foundation of the modern state of South Africa. The Dutch legacy in South Africa is evident everywhere, but particularly in the Afrikaner people and the Afrikaans language.\nDutch Republic: Regents and Stadholders (1649\u20131794).\nThe \"United Provinces of the Netherlands\", commonly referred to in historiography as the \"Dutch Republic\", was a confederation of provinces that existed from 1579 until the Batavian Revolution in 1795. It was the first independent Dutch state. The republic was established after seven Dutch provinces revolted against Spanish rule, declaring their independence in 1581. As the Netherlands was a republic, it was largely governed by an aristocracy of city-merchants called the regents, rather than by a king. Every city and province had its own government and laws, and a large degree of autonomy. After attempts to find a competent sovereign proved unsuccessful, it was decided that sovereignty would be vested in the various provincial Estates, the governing bodies of the provinces. The Estates-General, with its representatives from all the provinces, would decide on matters important to the Republic as a whole. Each province was led by an official known as the ; this office was nominally open to anyone, but most provinces appointed a member of the House of Orange. The position gradually became hereditary, with the Prince of Orange simultaneously holding most or all of the stadtholderships, making him effectively the head of state. This created tension between political factions: the Orangists favoured a powerful stadtholder, while the Republicans favoured a strong States General. The Republicans forced two Stadtholderless Periods, 1650\u20131672 and 1702\u20131747, with the latter causing national instability and the end of Great Power status. In the Peace of Westphalia (1648) the republic gained approximately 20% more territory, located outside the member provinces, which was ruled directly by the States General as Generality Lands.\nAlthough the state was small and had only around 1.5\u00a0million inhabitants, it controlled a worldwide network of seafaring trade routes, with a merchant fleet initially larger than the those of England and France combined. Through its trading companies, the Dutch East India Company (VOC) and the Dutch West India Company (GWC), it established an empire. These companies were based on the English model and the success of England's joint-stock enterprises and trading guilds.\nThe income from this trade allowed the Dutch Republic to compete militarily against much larger countries. Major conflicts were fought in the Eighty Years' War against Spain, the Dutch\u2013Portuguese War (1602\u20131663), four Anglo-Dutch Wars, the Franco-Dutch War (1672\u20131678), War of the Grand Alliance (1688\u20131697), the War of the Spanish Succession (1702\u20131713), the War of Austrian Succession (1744\u20131748), and the War of the First Coalition (1792\u20131795) against the Kingdom of France.\nThe republic was more tolerant of different religions and ideas than contemporary states, allowing freedom of thought to its residents. Artists flourished under this regime, including painters such as Rembrandt. So did scientists, such as Hugo Grotius, Christiaan Huygens and Antonie van Leeuwenhoek. Dutch trade, science, armed forces, and art were among the most acclaimed in the world during much of the 17th century, a period which became known as the Dutch Golden Age.\nThe economy, based on Amsterdam's role as the center of world trade, was strong in the 17th century. In 1670 the Dutch merchant marine totalled 568,000 tons of shipping\u2014about half the European total. The province of Holland was highly commercial and dominated the country. Its nobility had little influence, for it was numerically small, politically weak, and formed a strictly closed caste. Most land in the province of Holland was commercialized for cash crops and was owned by urban capitalists, not nobles; there were few links between Holland's nobility and the merchants. By 1650 the burgher families which had grown wealthy through commerce and become influential in government controlled the province of Holland, and to a large extent shaped national policies. The other six provinces were more rural and traditional in life style, had an active nobility, and played a small role in commerce and national politics. Instead they concentrated on their flood protections and land reclamation projects.\nEconomic decline led to a period of political instability known as the Patriottentijd (1780\u20131787). This unrest was temporarily suppressed by a Prussian invasion in support of the stadtholder. The French Revolution and subsequent War of the First Coalition reignited these tensions. Following military defeat by France, the stadtholder was expelled in the Batavian Revolution of 1795, ending the Dutch Republic, which was succeeded by the Batavian Republic.\nBatavian Republic (1795\u20131806).\nThe French Revolution was popular, and numerous underground clubs were promoting it when in January 1795 the French army invaded. The underground rose up, overthrew the municipal and provincial governments, and proclaimed the Batavian Republic () in Amsterdam. Stadtholder William V fled to England and the States General dissolved itself. The new government was virtually a puppet of France. The Batavian Republic enjoyed widespread support and sent soldiers to fight in the French armies. The 1799 Anglo-Russian invasion of Holland was repulsed by Batavian\u2013French forces. Nevertheless, Napoleon replaced it because the regime of Grand Pensionary Rutger Jan Schimmelpenninck (1805\u20131806) was insufficiently docile.\nThe confederal structure of the old Dutch Republic was permanently replaced by a unitary state. The 1798 constitution had a genuinely democratic character, though a coup d'\u00e9tat of 1801 put an authoritarian regime in power. Ministerial government was introduced for the first time in Dutch history and many of the current government departments date their history back to this period.\nThe exiled stadholder handed over the Dutch colonies in \"safekeeping\" to Great Britain and ordered the colonial governors to comply. This permanently ended the colonial Dutch empire in Guyana, Ceylon and the Cape Colony. The Dutch East Indies was returned to the Netherlands under the Anglo-Dutch Treaty of 1814.\nKingdom of Holland to William I (1806\u20131815).\nIn 1806 Napoleon transformed the Netherlands (along with a small part of what is now Germany) into the Kingdom of Holland, putting his brother Louis Bonaparte (1778\u20131846), on the throne. The new king was unpopular, but he was willing to cross his brother for the benefit of his new kingdom. Napoleon forced his abdication in 1810 and incorporated the Netherlands directly into the French empire, imposing economic controls and conscription of all young men as soldiers. \nWhen the French retreated from the northern provinces in 1813, a Triumvirate took over at the helm of a provisional government. Although most members of the provisional government had been among the men who had driven out William V 18 years earlier, the leaders of the provisional government knew that any new regime would have to be headed by his son, William Frederick. They also knew that it would be better in the long term if the Dutch people themselves installed the prince, rather than have him imposed on the country by the anti-French alliance. Accordingly, the Triumvirate called William Frederick back on 30 November and offered him the crown. He refused, but instead proclaimed himself \"hereditary sovereign prince\" on 6 December.\nThe Great Powers had secretly agreed to merge the northern Netherlands with the more populated Austrian Netherlands and the smaller Prince-Bishopric of Li\u00e8ge into a single constitutional monarchy. Having a stronger country on France's northern border was considered (especially by Tsar Alexander) to be an important part of the strategy to keep France's power in check. In 1814, William Frederick gained sovereignty over the Austrian Netherlands and Li\u00e8ge as well. Thus, William Frederick had fulfilled his family's three-century quest to unite the Low Countries under a single rule.\nOn 15 March 1815; with the encouragement of the powers gathered at the Congress of Vienna, William Frederick raised the Netherlands to the status of a kingdom and proclaimed himself King William I. This was made official later in 1815, when the Low Countries were formally recognized as the United Kingdom of the Netherlands. The crown was made a hereditary office of the House of Orange-Nassau.\nUnited Kingdom of the Netherlands (1815\u20131839).\nWilliam I became king and also became the hereditary Grand Duke of Luxembourg, that was part of the Netherlands but at the same time part of the German Confederation. The newly created country had two capitals: Amsterdam and Brussels. The new nation had two equal parts. The north (Netherlands proper) had 2 million people. They spoke chiefly Dutch but were divided religiously between a Protestant majority and a large Catholic minority. The south (which would be known as \"Belgium\" after 1830) had a population of 3.4\u00a0million people. Nearly all were Catholic, but it was divided between French-speaking Walloons and Dutch-speaking Flemings. The upper and middle classes in the south were mostly French-speaking. About 60,000 Belgians were eligible to vote, compared to about 80,000 Dutchmen. Officially Amsterdam was the capital, but in a compromise the government met alternately in Brussels and The Hague.\nAdolphe Quetelet (1796\u20131874), the great Belgian statistician, calculated that the new nation was significantly better off than other states. Mortality was low, the food supply was good, education was good, public awareness was high and the charity rate was the highest in the world. The best years were in the mid-1820s.\nThe quality of schooling was dismal, however. According to Schama, about 1800 the local school teacher was the \"humble auxiliary of the local priest. Despised by his co-villagers and forced to subsist on the gleanings of the peasants, he combined drumming the catechism into the heads of his unruly charges with the duties of winding the town clock, ringing the church bells or digging its graves. His principal use to the community was to keep its boys out of mischief when there was no labour for them in the fields, or setting the destitute orphans of the town to the 'useful arts' of picking tow or spinning crude flax. As one would expect, standards in such an occupation were dismal.\" But in 1806 the Dutch, led by Adriaan van den Ende, energetically set out to modernise education, focusing on a new system for advanced training of teachers with an elaborate system of inspectors, training courses, teacher examinations and teaching societies. By 1826, although much smaller than France, the Dutch national government was spending 12 times more than Paris on education.\nConstitutional monarchy.\nWilliam I, who reigned from 1815 to 1840, had great constitutional power. An enlightened despot, he accepted the modernizing transformations of the previous 25 years, including equality of all before the law. However, he resurrected the estates as a political class and elevated a large number of people to the nobility. Voting rights were still limited, and only the nobility were eligible for seats in the upper house. The old provinces were reestablished in name only. The government was now fundamentally unitary, and all authority flowed from the center.\nWilliam I was a Calvinist and unsympathetic to the religious culture and practices of the Catholic majority. He promulgated the \"Fundamental Law of Holland\", with some modifications. This entirely overthrew the old order of things in the southern Netherlands: it abolished the privileges of the Catholic Church, and guaranteed equal protection to every religious creed and the enjoyment of the same civil and political rights to every subject of the king. It reflected the spirit of the French Revolution and in so doing did not please the Catholic bishops in the south, who had detested the Revolution.\nWilliam I actively promoted economic modernization. The first 15 years of the Kingdom showed progress and prosperity, as industrialization proceeded rapidly in the south, where the Industrial Revolution allowed entrepreneurs and labor to combine in a new textile industry, powered by local coal mines. There was little industry in the northern provinces, but most overseas colonies were restored, and highly profitable trade resumed after a 25-year hiatus. Economic liberalism combined with moderate monarchical authoritarianism accelerated the adaptation of the Netherlands to the new conditions of the 19th century. The country prospered until a crisis arose in relations with the southern provinces.\nBelgium breaks away.\nWilliam was determined to create a united people, even though the north and south had drifted far apart in the past three centuries. Protestants were the largest denomination in the North (population 2 million), but formed a quarter of the population in the overwhelmingly Catholic South (population 3.5\u00a0million). Nevertheless, Protestants dominated William's government and army. The Catholics did not consider themselves an integral part of the United Netherlands, preferring instead to identify with mediaeval Dutch culture. Other factors that contributed to this feeling were economic (the South was industrialising, the North had always been a merchants' nation) and linguistic (French was spoken in Wallonia and a large part of the bourgeoisie in Flemish cities).\nAfter having been dominant for centuries, the French-speaking elite in the Southern Netherlands now felt like second-class citizens.\nIn the Catholic South, William's policies were unpopular. The French-speaking Walloons strenuously rejected his attempt to make Dutch the universal language of government, while the population of Flanders was divided. Flemings in the south spoke a Dutch dialect (\"Flemish\") and welcomed the encouragement of Dutch with a revival of literature and popular culture. Other Flemings, notably the educated bourgeoisie, preferred to speak French. Although Catholics possessed legal equality, they resented their subordination to a government that was fundamentally Protestant in spirit and membership after having been the state church for centuries in the north. Few Catholics held high office in state or army. Furthermore, political liberals in the south complained about the king's authoritarian methods. All southerners complained of underrepresentation in the national legislature. Although the south was industrializing and was more prosperous than the north the accumulated grievances allowed the multiple opposition forces to coalesce.\nThe outbreak of revolution in France in 1830 was a signal for action, at first on behalf of autonomy for Belgium, as the southern provinces were now called, and later on behalf of total independence. William dithered and his half-hearted efforts to reconquer Belgium were thwarted both by the efforts of the Belgians themselves and by the diplomatic opposition of the great powers.\nAt the London Conference of 1830, the chief powers of Europe ordered (in November 1830) an armistice between the Dutch and the Belgians. The first draft for a treaty of separation of Belgium and the Netherlands was rejected by the Belgians. A second draft (June 1831) was rejected by William I, who resumed hostilities. Franco-British intervention forced William to withdraw Dutch forces from Belgium late in 1831, and in 1833 an armistice of indefinite duration was concluded. Belgium was effectively independent but William's attempts to recover Luxembourg and Limburg led to renewed tension. The London Conference of 1838\u20131839 prepared the final Dutch-Belgian separation treaty of 1839. It divided Luxembourg and Limburg between the Dutch and Belgian crowns. The Kingdom of the Netherlands thereafter was made up of the 11 northern provinces.\nDemocratic and Industrial Development (1840\u20131900).\nThe Netherlands did not industrialize as rapidly as Belgium after 1830, but it was prosperous enough. Griffiths argues that certain government policies facilitated the emergence of a national economy in the 19th century. They included the abolition of internal tariffs and guilds, a unified coinage system, modern methods of tax collection, standardized weights and measures, and the building of many roads, canals, and railroads. However, compared to Belgium, which was leading in industrialization on the Continent, the Netherlands moved slowly. Possible explanations for this difference are the higher costs due to geography and high wages, and the emphasis of entrepreneurs on trade rather than industry.\nFor example, in the Dutch coastal provinces agricultural productivity was relatively high. Hence, industrial growth arrived relatively late \u2013 after 1860 \u2013 because incentives to move to labour-intensive industry were quite weak.\nHowever, the provinces of North Brabant and Overijssel did industrialize, and they became the most economically advanced areas of the country.\nAs in the rest of Europe, the 19th century saw the gradual transformation of the Netherlands into a modern middle-class industrial society. The number of people employed in agriculture decreased, while the country made a strong effort to revive its stake in the highly competitive shipping and trade business. The Netherlands lagged behind Belgium until the late 19th century in industrialization, and caught up around 1920. Major industries included textiles and (later) the great Philips industrial conglomerate. Rotterdam became a major shipping and manufacturing center. Poverty slowly declined as begging largely disappeared along with steadily improving working conditions for the population.\n1848 Constitutional reform and liberalism.\nIn 1840 William I abdicated in favor of his son, William II, who attempted to carry on the policies of his father in the face of a powerful liberal movement. In 1848 unrest broke out all over Europe. Although there were no major events in the Netherlands, these foreign developments persuaded King William II to agree to liberal and democratic reform. That same year Johan Rudolf Thorbecke, a prominent liberal, was asked by the king to draft a constitution that would turn the Netherlands into a constitutional monarchy. The new constitution was proclaimed on 3 November 1848. It severely limited the king's powers (making the government accountable only to an elected parliament), and it protected civil liberties. The new liberal constitution, which put the government under the control of the States General, was accepted by the legislature in 1848. The relationship between monarch, government and parliament has remained essentially unchanged ever since. In fact, the current Constitution of the Netherlands is the 1848 Constitution, albeit with amendments.\nWilliam II was succeeded by William III in 1849. The new king reluctantly chose Thorbecke to head the new government, which introduced several liberal measures, notably the extension of suffrage. However, Thorbecke's government soon fell, when Protestants rioted against the Vatican's reestablishment of the Catholic episcopate, in abeyance since the 16th century. A conservative government was formed, but it did not undo the liberal measures, and the Catholics were finally given equality after two centuries of subordination. Dutch political history from the middle of the 19th century until the First World War was fundamentally one of the extension of liberal reforms in government, the reorganization and modernization of the Dutch economy, and the rise of trade unionism and socialism as working-class movements independent of traditional liberalism. The growth in prosperity was enormous, as real per capita GNP soared from 106 guilders in 1804 to 403 in 1913.\nReligion and pillarisation.\nReligion was a contentious issue with repeated struggles over the relations of church and state in the field of education. In 1816, the government took full control of the Dutch Reformed Church (). In 1857, all religious instruction was ended in public schools, but the various churches set up their own schools, and even universities. Dissident members broke away from the Dutch Reformed Church in the Secession of 1834. They were harassed by the government under an onerous Napoleonic law prohibiting gatherings of more than 20 members without a permit. After the harassment ended in the 1850s, a number of these dissidents eventually created the Christian Reformed Church in 1869; thousands migrated to Michigan, Illinois, and Iowa in the United States. By 1900, the dissidents represented about 10% of the population, compared to 45% of the population who were in the Dutch Reformed Church, which continued to be the only church to receive state money.\nAt mid-century, most Dutch belonged either to the Dutch Reformed Church or dissenter groups that separated from it (around 55%), or the Roman Catholic Church (35% to 40%), together with smaller Protestant (for example, Lutheran) and Jewish groups. A large and powerful sector of nominal Protestants were in fact secular liberals seeking to minimize religious influence. In reaction a novel alliance developed with Catholics and devout Calvinists joining against secular liberals. The Catholics, who had been loosely allied with the liberals in earlier decades, turned against them on the issue of state support, which the liberals insisted should be granted only to public schools, and joined with Protestant political parties in demanding equal state support to schools maintained by religious groups.\nThe Netherlands remained one of the most tolerant countries in Europe towards religious belief, although conservative Protestants objected to the liberalization of the Dutch Reformed Church during the 19th century and faced opposition from the government when they tried to establish separate communities (Catholics and other non-Protestants were left unmolested by Dutch authorities). Some moved to the United States as a consequence, but as the century drew to a close, religious persecution had totally ceased.\nDutch social and political life became divided by fairly clear-cut internal borders that were emerging as the society pillarized into three separate parts based on religion. The economy was not affected. One of the people most responsible for designing pillarization was Abraham Kuyper (1837\u20131920), a leading politician, neo-Calvinist theologian, and journalist. Kuyper established orthodox Calvinist organizations, and also provided a theoretical framework by developing such concepts as \"sphere-sovereignty\" that celebrated Dutch society as a society of organized minorities. \"Verzuiling\" (\"pillarization\" or \"pluralism\") after 1850 became the solution to the danger of internal conflict. Everyone was part of one (and only one) pillar (\"zuil\") based chiefly on religion (Protestant, Catholic, secular). The secular pillar eventually split into a socialist/working class pillar and a liberal (pro-business) secular pillar. Each pillar built a full set of its own social organizations, including churches (for the religious pillars), political parties, schools, universities, labor unions, sport clubs, boy scout unions and other youth clubs, and newspapers. The members of different \"zuilen\" lived in close proximity in cities and villages, spoke the same language, and did business with one another, but seldom interacted informally and rarely intermarried. In politics Kuyper formed the Anti-Revolutionary Party (ARP) in 1879, and headed it until 1905.\nPillarization was officially recognized in the Pacification of 1917, whereby socialists and liberals achieved their goal of universal male suffrage and the religious parties were guaranteed equal funding of all schools. In 1930 radio was organized so that each pillar had full control of its own network. When television began in the late 1940s the pillars divided up time equally on the one station. In politics and civic affairs leaders of the pillar organizations cooperated and they acknowledged the right of the other pillars, so public life generally ran smoothly.\nFlourishing of art, culture and science.\nThe late 19th century saw a cultural revival. The Hague School brought a revival of realist painting, 1860\u20131890. The world-famous Dutch painter was Vincent van Gogh, but he spent most of his career in France. Literature, music, architecture and science also flourished. A representative leader of science was Johannes Diderik van der Waals (1837\u20131923), a working class youth who taught himself physics, earned a PhD at the nation's leading school Leiden University, and in 1910 won the Nobel Prize for his discoveries in thermodynamics. Hendrik Lorentz (1853\u20131928) and his student Pieter Zeeman (1865\u20131943) shared the 1902 Nobel Prize in physics. Other notable scientists included biologist Hugo de Vries (1848\u20131935), who rediscovered Mendelian genetics.\n1900 to present.\nFrom 1900 to 1940, the Netherlands experienced significant population growth. This era included significant colonial expansion, particularly in the Dutch East Indies, coupled with the challenges posed by World War I and the Great Depression. Although the Netherlands maintained neutrality during World War I, its strategic geographic location and colonial resources had profound implications for its economic and political stability. The period saw the rise of socialism and labor unrest, which were partly driven by industrialization and the shifting dynamics of Dutch society. A half-hearted socialist revolution attempt during the Red Week in November 1918 failed.\nWorld War II marked a devastating period for the Netherlands, which suffered under German occupation from 1940 until liberation in 1945. The war's impact was severe, with the Rotterdam Blitz causing extensive destruction and loss of life. Dutch resistance was significant, though the nation also faced collaboration from within. Post-war, the Netherlands underwent a painful process of recovery and retribution against collaborators. The immediate post-war years were focused on rebuilding and economic stabilization, facilitated by U.S. aid through the Marshall Plan, which helped to revive the Dutch economy and infrastructure.\nThe post-war period saw significant changes in the Dutch empire, with Indonesia proclaiming independence in 1945, leading to a violent and tumultuous decolonization process completed in 1949. This era brought about substantial social change within the Netherlands, including the establishment of a welfare state in the subsequent decades. Economic prosperity in the 1960s and 1970s led to social liberalization, culminating in progressive policies on immigration, drugs, and euthanasia. The Netherlands also became a founding member of key international institutions, including the European Union, reflecting its deepening commitment to international cooperation.\nHistoriography.\nThe American John Lothrop Motley was the first foreign historian to write a major history of the Dutch Republic. In 3500 pages he crafted a literary masterpiece that was translated into numerous languages; his dramatic story reached a wide audience in the 19th century. Motley relied heavily on Dutch scholarship and immersed himself in the sources. His style no longer attracts readers, and scholars have moved away from his simplistic dichotomies of good versus evil, Dutch versus Spanish, Catholic versus Protestant, freedom versus authoritarianism. His theory of causation overemphasized ethnicity as an unchanging characteristic, exaggerated the importance of William of Orange, and gave undue importance to the issue of religious tolerance.\nThe pioneering Dutch cultural historian Johan Huizinga, author of \"The Autumn of the Middle Ages\" (1919) (the English translation was called \"The Waning of the Middle Ages\") and \"Homo Ludens: A Study of the Play Element in Culture\" (1935), which expanded the field of cultural history and influenced the historical anthropology of younger historians of the French Annales School. He was influenced by art history and advised historians to trace \"patterns of culture\" by studying \"themes, figures, motifs, symbols, styles and sentiments\".\nThe \"polder model\" continues to strongly influence historians as well as Dutch political discussion. The polder model stressed the need for finding consensus and discouraged furious debate and angry dissent in both academia and politics \u2013 in contrast to the highly developed, intense debates in Germany.\nThe H-Net list \"H-Low-Countries\" is published free by email and is edited by scholars. Its occasional messages serve an international community with diverse methodological approaches, archival experiences, teaching styles, and intellectual traditions, promotes discussion relevant to the region and to the different national histories in particular, with an emphasis on the Netherlands. H-Low-Countries publishes conference announcements, questions and discussions; reviews of books, journals, and articles; and tables of contents of journals on the history of the Low Countries (in both Dutch and English). After World War II both research-oriented and teaching-oriented historians have been rethinking their interpretive approaches to Dutch history, balancing traditional memories and modern scholarship. In terms of popular history, there has been an effort to ensure greater historical accuracy in museums and historic tourist sites.\nOnce heralded as the leading event of modern Dutch history, the Dutch Revolt lasted from 1568 to 1648, and historians have worked to interpret it for even longer. In 2007, Laura Cruz explained the major debates among scholars regarding the Dutch bid for independence from Spanish rule. While agreeing that the intellectual milieus of late 19th and 20th centuries affected historians' interpretations, Cruz argued that writings about the revolt trace changing perceptions of the role played by small countries in the history of Europe. In recent decades grand theory has fallen out of favor among most scholars, who emphasize the particular over the general. Dutch and Belgian historiography since 1945 no longer says the revolt was the culmination of an inevitable process leading to independence and freedom. Instead scholars have put the political and economic details of the towns and provinces under the microscope, while agreeing on the weaknesses of attempts at centralization by the Habsburg rulers. The most influential new studies have been rooted in demographic and economic history, though scholars continue to debate the relationship between economics and politics. The religious dimension has been viewed in terms of mentalities, exposing the minority position of Calvinism, while the international aspects have been studied more seriously by foreign historians than by the Dutch themselves.\nPieter Geyl was the leading historian of the Dutch Revolt, and an influential professor at the University of London (1919\u20131935) and at the State University of Utrecht (1936\u20131958). He wrote a six-volume history of the Dutch-speaking peoples. The Nazis imprisoned him in World War II. In his political views, Geyl adopted the views of the 17th-century Dutch Louvestein faction, led by Johan van Oldenbarneveldt and Johan de Witt. It stood for liberty, toleration, and national interests in contrast to the Orange stadholders who sought to promote their own self-interest. According to Geyl, the Dutch Republic reached the peak of its powers during the 17th century. He was also a staunch nationalist and suggested that Flanders could split off from Belgium and join the Netherlands. Later he decried what he called radical nationalism and stressed more the vitality of Western Civilization. Geyl was highly critical of the world history approach of Arnold J. Toynbee.\nJan Romein created a \"theoretical history\" in an attempt to reestablish the relevance of history to public life in the 1930s at a time of immense political uncertainty and cultural crisis, when Romein thought that history had become too inward-looking and isolated from other disciplines. Romein, a Marxist, wanted history to contribute to social improvement. At the same time, influenced by the successes of theoretical physics and his study of Oswald Spengler, Arnold J. Toynbee, Frederick John Teggart, and others, he spurred on the development of theoretical history in the Netherlands, to the point where it became a subject in its own right at the university level after the war. Romein used the term integral history as a substitute for cultural history and focused his attention on the period around the turn of the century. He concluded that a serious crisis occurred in European civilization in 1900 because of the rise of anti-Semitism, extreme nationalism, discontent with the parliamentary system, depersonalization of the state, and the rejection of positivism. European civilization waned as the result of this crisis which was accompanied by the rise of the United States, the Americanization of the world, and the emergence of Asia. His interpretation is reminiscent of that of his mentor Johan Huizinga and was criticized by his colleague Pieter Geyl.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nSources.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "13290", "revid": "5108662", "url": "https://en.wikipedia.org/wiki?curid=13290", "title": "Harold and Maude", "text": "1971 film by Hal Ashby\nHarold and Maude is a 1971 American romantic black comedy-drama film directed by Hal Ashby and released by Paramount Pictures. It incorporates elements of dark humor and existentialist drama. The plot follows the exploits of Harold Chasen (Bud Cort), a young man who is intrigued with death, and who rejects the life his detached mother (Vivian Pickles) prescribes for him. Harold develops a friendship, and eventual romantic relationship, with 79-year-old Maude (Ruth Gordon) who teaches Harold about the importance of living life to its fullest.\nThe screenplay by Colin Higgins began as his master's thesis for film school. Filming took place in and around San Francisco and San Mateo, California, with locations including both Holy Cross Cemetery and Golden Gate National Cemetery, the ruins of the Sutro Baths, Mori Point, and Rosecourt Mansion in Hillsborough, California.\nCritically and commercially unsuccessful when first released, the film eventually developed a cult following, and first made a profit in 1983. The film was selected for preservation in the National Film Registry in 1997, and was ranked number 45 on the American Film Institute list of 100 funniest films of all time in 2000. The Criterion Collection released a special-edition Blu-ray and DVD in 2012.\nPlot.\nHarold Chasen is a young man obsessed with death. He stages elaborate fake suicides, attends funerals (usually for people that he does not know), and drives a hearse, all to the chagrin of his self-obsessed, wealthy socialite mother. His mother sends Harold to a psychoanalyst, sets him up with blind dates, and buys him a luxury car, all schemes he subverts in his own way.\nHarold meets 79-year-old Maude one day while at a random stranger's funeral Mass, and discovers that they share a hobby. Harold is entranced by Maude's quirky outlook on life, which is bright and delightfully carefree in contrast to his morbid demeanor. Maude lives in a decommissioned railroad car and thinks nothing of breaking the law; she is quite skilled at stealing cars and will swiftly uproot an ailing tree in a city sidewalk to replant it in the forest. She and Harold form a bond and Maude shows Harold the pleasures of art and music (including how to play the banjo), and teaches him how to make \"the most of his time on earth.\"\nMeanwhile, Harold's mother is determined, against Harold's wishes, to find him a wife. One by one, Harold frightens and horrifies each of his appointed computer dates, by appearing to commit gruesome acts, including self-immolation, self-mutilation, and \"seppuku\". His mother attempts to enlist him in the military by sending Harold to his uncle, who lost an arm serving under General MacArthur in World War II, but Harold deters the recruitment by staging a scene where Maude poses as a pacifist protester and Harold seemingly murders her out of militarist fanaticism.\nAs Harold and Maude grow closer, their friendship blossoms into a romance. Holding her hand, Harold discovers a number tattooed on her forearm, indicating Maude survived the Nazi death camps. Harold announces that he will marry Maude, resulting in disgusted outbursts from his family, analyst, and priest. Unbeknownst to Harold, Maude has been planning to end her own life on her 80th birthday. (Although she had actually mentioned her plan twice, early on.) Maude's birthday arrives, and Harold throws a surprise party for her. As the pair dance, Maude tells Harold that she \"couldn't imagine a lovelier farewell.\" When Maude reveals that she has taken an overdose of sleeping pills and will be dead by midnight, Harold rushes Maude to the hospital. However, she succumbs to the pill overdose. Devastated after learning of Maude's death, Harold speeds down a country road and sends his car off a seaside cliff, appearing to have died by suicide. Following the crash, Harold is revealed to be standing calmly atop the cliff, holding his banjo. After gazing down at the wreckage, he plucks the banjo strings and dances away to \"If You Want to Sing Out, Sing Out\".\nCast.\nDirector Hal Ashby appears in an uncredited cameo, seen at a penny arcade watching a model train at the Santa Cruz Beach Boardwalk.\nProduction.\nUCLA film school student Colin Higgins wrote \"Harold and Maude\" as his master's thesis. While working as producer Edward Lewis's pool boy, Higgins showed the script to Lewis's wife, Mildred. Mildred was so impressed that she got Edward to give it to Stanley Jaffe at Paramount. Higgins sold the script with the understanding that he would direct the film, but he was told he was not ready after tests he shot proved unsatisfactory to the studio heads. Ashby said that he would only commit to directing the film after getting Higgins' blessing, and took Higgins on as a co-producer so he could watch and learn from him on the set. Higgins says he originally thought of the story as a play. It then became a 20-minute thesis while at film school. The film script was turned into a novel and then a play, which ran for several years in Paris.\nAshby felt that the actress portraying Maude should ideally be European and his list of possible actresses included Peggy Ashcroft, Edith Evans, Gladys Cooper, and Celia Johnson, as well as Lotte Lenya, Luise Rainer, Pola Negri, Minta Durfee, and Agatha Christie. Ruth Gordon indicated that in addition, she heard that Edwige Feuill\u00e8re, Elisabeth Bergner, Mildred Natwick, Mildred Dunnock, and Dorothy Stickney had been considered.\nFor Harold, in addition to Bud Cort, Ashby considered all promising unknowns, Richard Dreyfuss, Bob Balaban, and John Savage. Also on his list were John Rubinstein, for whom Higgins had written the part, and then-up-and-coming British singer Elton John, whom Ashby had seen live and hoped would also do the music. Anne Brebner, the casting director, was almost cast as Harold's mother, when Vivian Pickles was briefly unable to do the role.\nPrincipal photography began in late December 1970 and concluded in mid-March 1971. Filming took place in and around San Francisco and San Mateo, California, including locations such as Holy Cross Cemetery in Colma (Harold catches his first glimpse of Maude at a funeral), St. Thomas Aquinas Church in Palo Alto (the church funeral where Harold first meets Maude), Oyster Point Boulevard in South San Francisco (Maude's railroad car), an abandoned warehouse at the Southern Pacific Railroad Bayshore Yard in Brisbane (Glaucus' studio), Half Moon Bay, Golden Gate National Cemetery in San Bruno, Redwood City (Maude rescues a street tree to be transplanted to the forest), the Dumbarton Bridge (a motorcycle officer pulls over Harold and Maude on their way to replant the tree), Sutro Heights Park (Harold rides in a limousine and walks with Uncle Victor) and the ruins of the Sutro Baths (Maude poses as a protester and later falls through a hole to her apparent death) in San Francisco, the Emeryville mudflats (Harold discovers Maude's concentration camp tattoo), Oakland, the Santa Cruz Beach Boardwalk (amusement park), Peninsula Hospital in Burlingame (Maude is hospitalized), and Mori Point in Pacifica (Harold drives his car off a cliff). For the Chasen mansion, scenes were shot at Rosecourt Mansion in Hillsborough, California. According to Ashby, there were some issues securing the location because Otto Preminger had previously filmed in the Hillsborough area and had antagonized the local residents.\nNovelization.\nA novelization by Higgins was released alongside the film; they differ in several respects, including the film's omission of certain scenes and characters. Other different details include the novel's version of Maude having white hair (unlike Gordon in the film) and introducing herself as \"the Countess Mathilde Chardin\", a different name and title than used in the film. In the novel, Maude's home is characterized as a \"cottage\" (unlike the retired railroad car Maude inhabits in the film), and she and Harold briefly interact with Maude's neighbor, Madame Arouet, who is not present in the film. The novel includes an additional scene during the tree-planting expedition where Maude leads Harold in climbing to the top of a very tall pine tree to show him the view over the forest from near its summit.\nRelease.\n\"Harold and Maude\" was released with a vague, text-only poster and very little marketing. The initial release underperformed at the box office, but it gradually found success in repertory theatres and recouped its costs after several years. Danny Peary, author of the \"Cult Movies\" series, referred to the film as \"[o]ne of the runaway cult favorites of the seventies\" and commented that it \"[broke] longevity records in cities like Detroit, Montreal, and most memorably, Minneapolis, where residents actually picketed the Westgate Theater trying to get management to replace the picture after a consecutive three-year run.\"\nHome media.\nThe Criterion Collection released \"Harold and Maude\" for Region 1 on DVD and Blu-ray on June 12, 2012, including a collection of audio excerpts of Ashby from January 11, 1972, and of screenwriter Colin Higgins from January 10, 1979, a new video interview with Yusuf/Cat Stevens, a new audio commentary by Ashby biographer Nick Dawson and producer Charles B. Mulvehill, and a booklet which includes a new film essay by Matt Zoller Seitz. Exclusive to the Blu-ray edition are a new digital restoration of the film with an uncompressed monaural soundtrack and an optional remastered uncompressed stereo soundtrack. Other exclusives are a \"New York Times\" profile of Gordon from 1971, an interview from 1997 with Cort and cinematographer John Alonzo, and an interview from 2001 with executive producer Mildred Lewis.\nReception.\nCritical response.\nAt the time of its release, \"Harold and Maude\" received mixed reviews, with several critics being offended by the film's dark humor. Roger Ebert gave the film one-and-a-half out of four stars. He wrote, \"And so what we get, finally, is a movie of attitudes. Harold is death, Maude life, and they manage to make the two seem so similar that life's hardly worth the extra bother. The visual style makes everyone look fresh from the Wax Museum, and all the movie lacks is a lot of day-old gardenias and lilies and roses in the lobby, filling the place with a cloying sweet smell. Nothing more to report today. Harold doesn't even make pallbearer.\"\nVincent Canby of \"The New York Times\" also panned the film, stating that the actors \"are so aggressive, so creepy and off-putting, that Harold and Maude are obviously made for each other, a point the movie itself refuses to recognize with a twist ending that betrays, I think, its life-affirming pretensions.\"\nRetrospective appraisal.\nThe reputation of the film has since increased greatly. On the review aggregator website Rotten Tomatoes, the film holds an approval rating of 86% based on 50 reviews, with an average rating of 7.8/10. The website's critics consensus reads, \"Hal Ashby's comedy is too dark and twisted for some, and occasionally oversteps its bounds, but there's no denying the film's warm humor and big heart.\"\nIn 2013, the Writers Guild of America ranked the screenplay number 86 on its list of the \"101 Greatest Screenplays\" ever written.\nIn \"Sight &amp; Sound\"'s 2012 \"Greatest Films of All Time\" poll, Niki Caro, Wanuri Kahiu, and Cyrus Frisch voted for \"Harold and Maude\". Frisch commented: \"An encouragement to think beyond the obvious!\"\nIn 2017, \"Chicago Tribune\" critic Mark Caro wrote a belated appreciation, \"I'm sorry, \"Harold and Maude\", for denying you for so long. You're my favorite movie once again.\"\nAccolades.\nAt the 29th Golden Globe Awards, Cort and Gordon were nominated as Best Actor and Best Actress \u2013 Motion Picture Musical or Comedy, respectively.\nThe film was selected for preservation in the National Film Registry in 1997, along with others deemed \"culturally, historically or aesthetically significant\" by the Library of Congress.\nIn September 2008, \"Empire\" ranked \"Harold and Maude\" number 65 on their list of the \"500 Greatest Movies of All Time\". \"Entertainment Weekly\" ranked the film number four on their 2003 list of \"The Top 50 Cult Films\".\nAmerican Film Institute lists.\n\"Harold and Maude\" has repeatedly been ranked among the various lists compiled by the American Film Institute (AFI). In 2000. the film ranked number 45 on AFI's 100 Years...100 Laughs, a list of the top 100 comedies. Two years later, \"Harold and Maude\" ranked number 69 on AFI's 100 Years...100 Passions, honoring the greatest love stories of the past century. In 2006, the film ranked number 89 on AFI's 100 Years...100 Cheers, recognizing the most inspiring films. In June 2008, AFI revealed its 10 Top 10, the 10 best films in 10 \"classic\" American film genres, placing \"Harold and Maude\" at number nine in the romantic comedy genre.\nMusic.\nThe music in \"Harold and Maude\" was composed and performed by Cat Stevens. He had been suggested by Elton John to do the music after John had dropped out of the project. Stevens composed two original songs for the film, \"Don't Be Shy\" and \"If You Want to Sing Out, Sing Out\" and performed instrumental and alternative versions of the previously released songs \"On the Road to Find Out\", \"I Wish, I Wish\", \"Miles from Nowhere\", \"Tea for the Tillerman\", \"I Think I See the Light\", \"Where Do the Children Play?\" and \"Trouble\" (all from his albums \"Mona Bone Jakon\" and \"Tea for the Tillerman\"). \"Don't Be Shy\" and \"If You Want to Sing Out, Sing Out\" remained unreleased on any album until the 1984 compilation \"\".\nAdditional music in the film is sourced from well known compositions. \"Greensleeves\" is played on the harp during dinner. The opening bars of Tchaikovsky's Piano Concerto No. 1 are heard during the scene of Harold floating face-down in the swimming pool. The Sunnyvale HS Marching Band plays \"The Klaxon\" by Henry Fillmore outside the church following a funeral. A calliope version of the waltz \"Over the Waves\" by Juventino Rosas is played at the amusement park. Harold and Maude waltz together in her home to \"The Blue Danube\" by Johann Strauss II.\nThe soundtrack album charted at number 173 on the US \"Billboard\" 200 in July 2021.\n1972 soundtrack.\nThe first soundtrack was released in Japan in 1972 on vinyl and cassette (A&amp;M Records GP-216). It omitted the two original songs and all instrumental and alternative versions of songs and was generally composed of re-released material that was in the film, along with five songs that were not in the film.\n2007 soundtrack.\nThe second soundtrack was released on December 28, 2007, by Vinyl Films Records as a vinyl-only limited-edition release of 2,500 copies. It contained a 30-page oral history of the making of the film, comprising the most extensive series of interviews yet conducted on \"Harold and Maude\".\n2021 soundtrack.\nA Record Store Day limited edition, available in yellow or orange vinyl, was released July 2021. It contained all the main songs from the 2007 album, but omitted the bonus material.\n2022 soundtrack.\nThe full soundtrack album received its first regular wide commercial release on February 11, 2022, to commemorate the film's 50th anniversary. The entire album was remastered at Abbey Road Studios. The disc includes previously unheard audio masters discovered in the Island/A&amp;M Records archive for the two original songs Stevens wrote for the film, \"Don't Be Shy\" and \"If You Want To Sing Out, Sing Out\". While there was an LP, this was also the album's first-ever release on CD. The digital release contains eight additional tracks.\nAdaptations.\nStage play adaptation.\nColin Higgins turned the story into a stage play, which, itself adapted into French by Jean-Claude Carri\u00e8re, opened in 1973 at the Th\u00e9\u00e2tre R\u00e9camier in Paris and proved a major hit. With Madeleine Renaud as Maude and Daniel Rivi\u00e8re as Harold, the play was directed by Renaud's husband, Jean-Louis Barrault, and costumed by Yves Saint Laurent. Renaud would reprise the role in multiple revivals.\nA London production, with Bessie Love mentioned for Maude, was planned for 1978 but didn't happen. Two years later, the Broadway production, starring Janet Gaynor as Maude and Keith McDermott as Harold, closed after four performances in February 1980.\nThe Yugoslav premiere of \"Harold i Mod\" was staged at the Belgrade Drama Theatre (BDP) on March 23, 1980, directed by Paolo Magelli, with Tatjana Lukjanova (Maude), Milan Erak (Harold), and \u017di\u017ea Stojanovi\u0107 (Mrs. Chasen). Slobodan Be\u0161ti\u0107 later assumed the role of Harold. The play remained in the BDP repertoire until Lukjanova's death in 2003.\nIn Brazil, the first run of the play premiered in 2007, directed by Jo\u00e3o Falc\u00e3o and starring Arlindo Lopes as Harold and Gloria Menezes as Maude. Nivea Maria later assumed the role of Maude.\nFrench television adaptation.\nA French adaptation for television, translated and written by Jean-Claude Carri\u00e8re, aired in 1978. It was also adapted for the stage by the Compagnie Viola L\u00e9ger in Moncton, New Brunswick, starring Roy Dupuis.\nMusical adaptation.\nA musical adaptation, with songs by Joseph Thalken and Tom Jones, premiered at the Paper Mill Playhouse in Millburn, NJ, in January 2005. The production starred Estelle Parsons as Maude and Eric Millegan as Harold.\nUnproduced sequel and prequel.\nHiggins expressed interest in 1978 regarding both a sequel and prequel to \"Harold and Maude\". Cort would return for \"Harold's Story\", living life after Maude. Higgins also imagined the prequel \"Grover and Maude\", where Maude learns how to steal cars from Grover Muldoon\u2014the character portrayed by Richard Pryor in Higgins' 1976 film \"Silver Streak\"\u2014with Gordon and Pryor reprising their respective roles.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nBibliography.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "13291", "revid": "7646666", "url": "https://en.wikipedia.org/wiki?curid=13291", "title": "Habitus (sociology)", "text": "How individuals perceive and react to the social world\nIn sociology, habitus () is the way that people perceive and respond to the social world they inhabit, by way of their personal habits, skills, and disposition of character.\nOverview.\nPeople with a common cultural background (social class, religion, and nationality, ethnic group, education, and profession) share a habitus as the way that group culture and personal history shape the mind of a person; consequently, the habitus of a person influences and shapes the social actions of the person.\nThe sociologist Pierre Bourdieu said that the \"habitus\" consists of the \"hexis\", a person's carriage (posture) and speech (accent), and the mental habits of perception, classification, appreciation, feeling, and action. The habitus allows the individual person to consider and resolve problems based upon gut feeling and intuition. This way of living (social attitudes, mannerisms, tastes, morality, etc.) influences the availability of opportunities in life; thus the habitus is structured by the person's social class, but also gives structure to the future paths available to the person. Therefore, the reproduction of social structures results from the habitus of the individual persons who compose the given social structure.\nThe habitus is criticised as being a deterministic concept, because, as \"social actors\", people behave as \"automata\", in the sense proposed in the Monadology of the philosopher G.W. Leibniz.\nOrigins.\nThe concept of the \"habitus\" was used as early as Aristotle. In contemporary usage it was introduced by Marcel Mauss and later Maurice Merleau-Ponty; however, it was Pierre Bourdieu who used it as a cornerstone of his sociology, and to address the sociological problem of agency and structure.\nIn Bourdieu's work, the habitus is shaped by structural position and generates action. Thus, when people act and demonstrate agency, they simultaneously reflect and reproduce social structure. Bourdieu elaborated his theory of the habitus while borrowing ideas on cognitive and generative schemes from Noam Chomsky and Jean Piaget regarding dependency on history and human memory. For instance, a certain behaviour or belief becomes part of a society's structure when the original purpose of that behaviour or belief can no longer be recalled and becomes socialized into individuals of that culture.\nAccording to Bourdieu, habitus is composed of:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;systems of durable, transposable dispositions, structured structures predisposed to function as structuring structures, that is, as principles which generate and organize practices and representations that can be objectively adapted to their outcomes without presupposing a conscious aiming at ends or an express mastery of the operations necessary in order to attain them.\nLo\u00efc Wacquant wrote that habitus is an old philosophical notion, originating in the thought of Aristotle, whose notion of \"hexis\" (\"state\") was translated into \"habitus\" by the Medieval Scholastics. Giorgio Agamben stresses that this term \"habitus\" itself \"originally signified 'a way of being or acting'\" in the Christian monastic tradition; he claims that the term had been in use already among the Stoics as a description of personal attributes synonymous with virtue. Bourdieu first adapted the term in his 1967 postface to Erwin Panofsky's \"Gothic Architecture and Scholasticism\". The term was earlier used in sociology by Norbert Elias in \"The Civilizing Process\" (1939) and in Marcel Mauss's account of \"body techniques\" (). The concept is also present in the work of Max Weber, Gilles Deleuze, and Edmund Husserl.\nMauss defined habitus as those aspects of culture that are anchored in the body or daily practices of individuals, groups, societies, and nations. It includes the totality of learned habits, bodily skills, styles, tastes, and other non-discursive knowledges that might be said to \"go without saying\" for a specific group (Bourdieu 1990:66\u201367) \u2013 in that way it can be said to operate beneath the level of rational ideology.\nNon-sociological uses.\nLiterary criticism.\nThe term has also been adopted in literary criticism, adapting from Bourdieu's usage of the term. For example, Joe Moran's examination of authorial identities in \"Star Authors: Literary Celebrity in America\" uses the term in discussion of how authors develop a habitus formed around their own celebrity and status as authors, which manifests in their writing.\nUse in literary theory.\nBourdieu's principle of habitus is interwoven with the concept of structuralism in literary theory. Peter Barry explains, \"in the structuralist approach to literature there is a constant movement away from interpretation of the individual literary work and a parallel drive towards understanding the larger structures which contain them\" (2009, p.\u00a039). There is therefore a strong desire to understand the larger influencing factors which makes an individual literary work. As Bourdieu explains, habitus\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;... are structured structures, generative principles of distinct and distinctive practices - what the worker eats, and especially the way he eats it, the sport he practices and the way he practices it, his political opinions and the way he expresses them are systematically different from the industrial proprietor's corresponding activities - habitus are also structuring structures, different classifying schemes classification principles, different principles of vision and division, different tastes. Habitus make different differences; they implement distinctions between what is good and what is bad, what is right and what is wrong, between what is distinguished and what is vulgar, and so on, but they are not the same. Thus, for instance, the same behaviour or even the same good can appear distinguished to one person, pretentious to someone else, and cheap or showy to yet another.\u2014\u200a\nAs a result, habitus may be employed in literary theory in order to understand those larger, external structures which influence individual theories and works of literature.\nBody habitus.\nBody habitus (or \"bodily habitus\") is the medical term for physique, and is categorized as either endomorphic (relatively short and stout), ectomorphic (relatively long and thin) or mesomorphic (muscular proportions). In this sense, habitus has in the past been interpreted as the physical and constitutional characteristics of an individual, especially as related to the tendency to develop a certain disease. For example, \"Marfanoid bodily habitus\".\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "13292", "revid": "18779361", "url": "https://en.wikipedia.org/wiki?curid=13292", "title": "Hypoxia (medicine)", "text": "Medical condition of lack of oxygen in the tissues\nMedical condition&lt;templatestyles src=\"Template:Infobox/styles-images.css\" /&gt;\nHypoxia is a condition in which the body or a region of the body is deprived of an adequate oxygen supply at the tissue level. Hypoxia may be classified as either \"generalized\", affecting the whole body, or \"local\", affecting a region of the body. Although hypoxia is often a pathological condition, variations in arterial oxygen concentrations can be part of the normal physiology, for example, during strenuous physical exercise.\nHypoxia differs from hypoxemia and anoxemia, in that hypoxia refers to a state in which oxygen present in a tissue or the whole body is insufficient, whereas hypoxemia and anoxemia refer specifically to states that have low or no oxygen in the blood. Hypoxia in which there is complete absence of oxygen supply is referred to as anoxia.\nHypoxia can be due to external causes, when the breathing gas is hypoxic, or internal causes, such as reduced effectiveness of gas transfer in the lungs, reduced capacity of the blood to carry oxygen, compromised general or local perfusion, or inability of the affected tissues to extract oxygen from, or metabolically process, an adequate supply of oxygen from an adequately oxygenated blood supply.\nGeneralized hypoxia occurs in healthy people when they ascend to high altitude, where it causes altitude sickness leading to potentially fatal complications: high-altitude pulmonary edema (HAPE) and high-altitude cerebral edema (HACE). Hypoxia also occurs in healthy individuals when breathing inappropriate mixtures of gases with a low oxygen content, e.g., while diving underwater, especially when using malfunctioning closed-circuit rebreather systems that control the amount of oxygen in the supplied air. Mild, non-damaging intermittent hypoxia is used intentionally during altitude training to develop an athletic performance adaptation at both the systemic and cellular level.\nHypoxia is a common complication of preterm birth in newborn infants. Because the lungs develop late in pregnancy, premature infants frequently possess underdeveloped lungs. To improve blood oxygenation, infants at risk of hypoxia may be placed inside incubators that provide warmth, humidity, and supplemental oxygen. More serious cases are treated with continuous positive airway pressure (CPAP).\nClassification.\nHypoxia exists when there is a reduced amount of oxygen in the tissues of the body. Hypoxemia refers to a reduction in arterial oxygenation below the normal range, regardless of whether gas exchange is impaired in the lung, arterial oxygen content (CaO2 \u2013 which represents the amount of oxygen delivered to the tissues) is adequate, or tissue hypoxia exists. The classification categories are not always mutually exclusive, and hypoxia can be a consequence of a wide variety of causes.\nBy cause.\nIntermittent hypoxic training induces mild generalized hypoxia for short periods as a training method to improve sporting performance. This is not considered a medical condition. Acute cerebral hypoxia leading to blackout can occur during freediving. This is a consequence of prolonged voluntary apnea underwater, and generally occurs in trained athletes in good health and good physical condition.\nBy extent.\nHypoxia may affect the whole body, or just some parts.\nGeneralized hypoxia.\nThe term \"generalized hypoxia\" may refer to hypoxia affecting the whole body, or may be used as a synonym for hypoxic hypoxia, which occurs when there is insufficient oxygen in the breathing gas to oxygenate the blood to a level that will adequately support normal metabolic processes, and which will inherently affect all perfused tissues.\nThe symptoms of generalized hypoxia depend on its severity and acceleration of onset. In the case of altitude sickness, where hypoxia develops gradually, the symptoms include fatigue, numbness / tingling of extremities, nausea, and cerebral hypoxia. These symptoms are often difficult to identify, but early detection of symptoms can be critical.\nIn severe hypoxia, or hypoxia of very rapid onset, ataxia, confusion, disorientation, hallucinations, behavioral change, severe headaches, reduced level of consciousness, papilloedema, breathlessness, pallor, tachycardia, and pulmonary hypertension eventually leading to the late signs cyanosis, slow heart rate, cor pulmonale, and low blood pressure followed by heart failure eventually leading to shock and death.\nBecause hemoglobin is a darker red when it is not bound to oxygen (deoxyhemoglobin), as opposed to the rich red color that it has when bound to oxygen (oxyhemoglobin), when seen through the skin it has an increased tendency to reflect blue light back to the eye. In cases where the oxygen is displaced by another molecule, such as carbon monoxide, the skin may appear 'cherry red' instead of cyanotic. Hypoxia can cause premature birth, and injure the liver, among other deleterious effects.\nLocalized hypoxia.\nHypoxia that is localized to a region of the body, such as an organ or a limb, is usually the consequence of ischemia, the reduced perfusion to that organ or limb, and may not necessarily be associated with general hypoxemia. A locally reduced perfusion is generally caused by an increased resistance to flow through the blood vessels of the affected area.\nIschemia is a restriction in blood supply to any tissue, muscle group, or organ, causing a shortage of oxygen. Ischemia is generally caused by problems with blood vessels, with resultant damage to or dysfunction of tissue i.e. hypoxia and microvascular dysfunction. It also means local hypoxia in a given part of a body sometimes resulting from vascular occlusion such as vasoconstriction, thrombosis, or embolism. Ischemia comprises not only insufficiency of oxygen, but also reduced availability of nutrients and inadequate removal of metabolic wastes. Ischemia can be a partial (poor perfusion) or total blockage.\nCompartment syndrome is a condition in which increased pressure within one of the body's anatomical compartments results in insufficient blood supply to tissue within that space. There are two main types: acute and chronic. Compartments of the leg or arm are most commonly involved.\nIf tissue is not being perfused properly, it may feel cold and appear pale; if severe, hypoxia can result in cyanosis, a blue discoloration of the skin. If hypoxia is very severe, a tissue may eventually become gangrenous.\nBy affected tissues and organs.\nAny living tissue can be affected by hypoxia, but some are particularly sensitive, or have more noticeable or notable consequences.\nCerebral hypoxia.\nCerebral hypoxia is hypoxia specifically involving the brain. The four categories of cerebral hypoxia in order of increasing severity are: diffuse cerebral hypoxia (DCH), focal cerebral ischemia, cerebral infarction, and global cerebral ischemia. Prolonged hypoxia induces neuronal cell death via apoptosis, resulting in a hypoxic brain injury.\nOxygen deprivation can be hypoxic (reduced general oxygen availability) or ischemic (oxygen deprivation due to a disruption in blood flow) in origin. Brain injury as a result of oxygen deprivation is generally termed hypoxic injury. Hypoxic ischemic encephalopathy (HIE) is a condition that occurs when the entire brain is deprived of an adequate oxygen supply, but the deprivation is not total. While HIE is associated in most cases with oxygen deprivation in the neonate due to birth asphyxia, it can occur in all age groups, and is often a complication of cardiac arrest.\nCorneal hypoxia.\nAlthough corneal hypoxia can arise from any of several causes, it is primarily attributable to the prolonged use of contact lenses. The corneas are not perfused and get their oxygen from the atmosphere by diffusion. Impermeable contact lenses form a barrier to this diffusion, and therefore can cause damage to the corneas. Symptoms may include irritation, excessive tearing and blurred vision. The sequelae of corneal hypoxia include punctate keratitis, corneal neovascularization and epithelial microcysts.\nIntrauterine hypoxia.\nIntrauterine hypoxia, also known as fetal hypoxia, occurs when the fetus is deprived of an adequate supply of oxygen. It may be due to a variety of reasons such as prolapse or occlusion of the umbilical cord, placental infarction, maternal diabetes (prepregnancy or gestational diabetes) and maternal smoking. Intrauterine growth restriction may cause or be the result of hypoxia. Intrauterine hypoxia can cause cellular damage that occurs within the central nervous system (the brain and spinal cord). This results in an increased mortality rate, including an increased risk of sudden infant death syndrome (SIDS). Oxygen deprivation in the fetus and neonate have been implicated as either a primary or as a contributing risk factor in numerous neurological and neuropsychiatric disorders such as epilepsy, attention deficit hyperactivity disorder, eating disorders and cerebral palsy.\nTumor hypoxia.\nTumor hypoxia is the situation where tumor cells have been deprived of oxygen. As a tumor grows, it rapidly outgrows its blood supply, leaving portions of the tumor with regions where the oxygen concentration is significantly lower than in healthy tissues. Hypoxic microenvironements in solid tumors are a result of available oxygen being consumed within 70 to 150 \u03bcm of tumour vasculature by rapidly proliferating tumor cells thus limiting the amount of oxygen available to diffuse further into the tumor tissue. The severity of hypoxia is related to tumor types and varies between different types. Research has shown that the level of oxygenation in hypoxic tumor tissues is poorer than normal tissues and it is reported somewhere between 1%\u20132% O2. In order to support continuous growth and proliferation in challenging hypoxic environments, cancer cells are found to alter their metabolism. Furthermore, hypoxia is known to change cell behavior and is associated with extracellular matrix remodeling and increased migratory and metastatic behavior. Tumour hypoxia is usually associated with highly malignant tumours, which frequently do not respond well to treatment.\nVestibular system.\nIn acute exposure to hypoxic hypoxia on the vestibular system and the visuo-vestibular interactions, the gain of the vestibulo-ocular reflex (VOR) decreases under mild hypoxia at altitude. Postural control is also disturbed by hypoxia at altitude, postural sway is increased, and there is a correlation between hypoxic stress and adaptive tracking performance.\nSigns and symptoms.\nArterial oxygen tension can be measured by blood gas analysis of an arterial blood sample, and less reliably by pulse oximetry, which is not a complete measure of circulatory oxygen sufficiency. If there is insufficient blood flow or insufficient hemoglobin in the blood (anemia), tissues can be hypoxic even when there is high arterial oxygen saturation.\nCauses.\nOxygen passively diffuses in the lung alveoli according to a concentration gradient, also referred to as a partial pressure gradient. Inhaled air rapidly reaches saturation with water vapour, which slightly reduces the partial pressures of the other components. Oxygen diffuses from the inhaled air to arterial blood, where its partial pressure is around 100\u00a0mmHg (13.3\u00a0kPa). In the blood, oxygen is bound to hemoglobin, a protein in red blood cells. The binding capacity of hemoglobin is influenced by the partial pressure of oxygen in the environment, as described by the oxygen\u2013hemoglobin dissociation curve. A smaller amount of oxygen is transported in solution in the blood.\nIn systemic tissues, oxygen again diffuses down a concentration gradient into cells and their mitochondria, where it is used to produce energy in conjunction with the breakdown of glucose, fats, and some amino acids. Hypoxia can result from a failure at any stage in the delivery of oxygen to cells. This can include low partial pressures of oxygen in the breathing gas, problems with diffusion of oxygen in the lungs through the interface between air and blood, insufficient available hemoglobin, problems with blood flow to the end user tissue, problems with the breathing cycle regarding rate and volume, and physiological and mechanical dead space.\nExperimentally, oxygen diffusion becomes rate limiting when arterial oxygen partial pressure falls to 60\u00a0mmHg (5.3\u00a0kPa) or below.\nAlmost all the oxygen in the blood is bound to hemoglobin, so interfering with this carrier molecule limits oxygen delivery to the perfused tissues. Hemoglobin increases the oxygen-carrying capacity of blood by about 40-fold, with the ability of hemoglobin to carry oxygen influenced by the partial pressure of oxygen in the local environment, a relationship described in the oxygen\u2013hemoglobin dissociation curve. When the ability of hemoglobin to carry oxygen is degraded, a hypoxic state can result.\nIschemia.\nIschemia, meaning insufficient blood flow to a tissue, can also result in hypoxia in the affected tissues. This is called 'ischemic hypoxia'. Ischemia can be caused by an embolism, a heart attack that decreases overall blood flow, trauma to a tissue that results in damage reducing perfusion, and a variety of other causes. A consequence of insufficient blood flow causing local hypoxia is gangrene that occurs in diabetes.\nDiseases such as peripheral vascular disease can also result in local hypoxia. Symptoms are worse when a limb is used, increasing the oxygen demand in the active muscles. Pain may also be felt as a result of increased hydrogen ions leading to a decrease in blood pH (acidosis) created as a result of anaerobic metabolism.\nG-LOC, or g-force induced loss of consciousness, is a special case of ischemic hypoxia which occurs when the body is subjected to high enough acceleration sustained for long enough to lower cerebral blood pressure and circulation to the point where loss of consciousness occurs due to cerebral hypoxia. The human body is most sensitive to longitudinal acceleration towards the head, as this causes the largest hydrostatic pressure deficit in the head.\nHypoxemic hypoxia.\nThis refers specifically to hypoxic states where the arterial content of oxygen is insufficient. This can be caused by alterations in respiratory drive, such as in respiratory alkalosis, physiological or pathological shunting of blood, diseases interfering in lung function resulting in a ventilation-perfusion mismatch, such as a pulmonary embolus, or alterations in the partial pressure of oxygen in the environment or lung alveoli, such as may occur at altitude or when diving.\nCommon disorders that can cause respiratory dysfunction include trauma to the head and spinal cord, nontraumatic acute myelopathies, demyelinating disorders, stroke, Guillain\u2013Barr\u00e9 syndrome, and myasthenia gravis. These dysfunctions may necessitate mechanical ventilation. Some chronic neuromuscular disorders, such as motor neuron disease and muscular dystrophy, may require ventilatory support in advanced stages.\nCarbon monoxide poisoning.\nCarbon monoxide competes with oxygen for binding sites on hemoglobin molecules. As carbon monoxide binds with hemoglobin hundreds of times tighter than oxygen, it can prevent the carriage of oxygen.\nCarbon monoxide poisoning can occur acutely, as with smoke intoxication, or over a period of time, as with cigarette smoking. Due to physiological processes, carbon monoxide is maintained at a resting level of 4\u20136 ppm. This is increased in urban areas (7\u201313 ppm) and in smokers (20\u201340 ppm). A carbon monoxide level of 40 ppm is equivalent to a reduction in hemoglobin levels of 10 g/L.\nCarbon monoxide has another harmful effect: it changes how hemoglobin binds to oxygen, preventing the normal release of oxygen to body tissues and shifting the oxygen dissociation curve to the left, making the binding tighter. In so doing, the hemoglobin is less likely to release its oxygen at the peripheral tissues. Certain abnormal hemoglobin variants also have higher than normal affinity for oxygen, and so are also poor at delivering oxygen to the periphery.\nAltitude.\nAtmospheric pressure reduces with altitude and proportionally, so does the oxygen content of the air. The reduction in the partial pressure of inspired oxygen at higher altitudes lowers the oxygen saturation of the blood, ultimately leading to hypoxia. The clinical features of altitude sickness include: sleep problems, dizziness, headache and oedema.\nHypoxic breathing gases.\nThe breathing gas may contain an insufficient partial pressure of oxygen. Such situations may lead to unconsciousness without symptoms since carbon dioxide levels remain normal and the human body senses pure hypoxia poorly. Hypoxic breathing gases can be defined as mixtures with a lower oxygen fraction than air, though gases containing sufficient oxygen to reliably maintain consciousness at normal sea level atmospheric pressure may be described as normoxic even when the oxygen fraction is slightly below normoxic. Hypoxic breathing gas mixtures in this context are those which will not reliably maintain consciousness at sea level pressure.\nOne of the most widespread circumstances of exposure to hypoxic breathing gas is ascent to altitudes where the ambient pressure drops sufficiently to reduce the partial pressure of oxygen to hypoxic levels.\nGases with as little as 2% oxygen by volume in a helium diluent are used for deep diving operations. The ambient pressure at 190 msw is sufficient to provide a partial pressure of about 0.4 bar, which is suitable for saturation diving. As the divers are decompressed, the breathing gas must be oxygenated to maintain a breathable atmosphere.\nIt is also possible for the breathing gas for diving to have a dynamically controlled oxygen partial pressure, known as a set point, which is maintained in the breathing gas circuit of a diving rebreather by addition of oxygen and diluent gas to maintain the desired oxygen partial pressure at a safe level between hypoxic and hyperoxic at the ambient pressure due to the current depth. A malfunction of the control system may lead to the gas mixture becoming hypoxic at the current depth.\nA special case of hypoxic breathing gas is encountered in deep freediving where the partial pressure of the oxygen in the lung gas is depleted during the dive, but remains sufficient at depth, and when it drops during ascent, it becomes too hypoxic to maintain consciousness, and the diver loses consciousness before reaching the surface.\nHypoxic gases may also occur in industrial, mining, and firefighting environments. Some of these may also be toxic or narcotic, others are just asphyxiant. Some are recognisable by smell, others are odourless.\nInert gas asphyxiation may be deliberate with use of a suicide bag. Accidental death has occurred in cases where concentrations of nitrogen in controlled atmospheres, or methane in mines, has not been detected or appreciated.\nOther.\nHemoglobin function can also be impaired when the iron atom in its heme group is oxidized from the ferrous (Fe\u00b2\u207a) to the ferric (Fe\u00b3\u207a) state. This inactive form, known as methemoglobin, cannot bind oxygen effectively. Elevated levels of methemoglobin can occur following exposure to oxidizing substances such as sodium nitrite, nitrates, or certain medications and other chemicals.\nAnemia.\nHemoglobin plays a substantial role in carrying oxygen throughout the body, and when it is deficient, anemia can result, causing 'anaemic hypoxia' if tissue oxygenation is decreased. Iron deficiency is the most common cause of anemia. As iron is used in the synthesis of hemoglobin, less hemoglobin will be synthesised when there is less iron, due to insufficient intake, or poor absorption.\nAnemia is typically a chronic process that is compensated over time by increased levels of red blood cells via upregulated erythropoetin. A chronic hypoxic state can result from a poorly compensated anaemia.\nHistotoxic hypoxia.\nHistotoxic hypoxia (also called histoxic hypoxia) is the inability of cells to take up or use oxygen from the bloodstream, despite physiologically normal delivery of oxygen to such cells and tissues. Histotoxic hypoxia results from tissue poisoning, such as that caused by cyanide (which acts by inhibiting cytochrome oxidase) and certain other poisons like hydrogen sulfide (byproduct of sewage and used in leather tanning).\nMechanism.\nTissue hypoxia from low oxygen delivery may be due to low haemoglobin concentration (anaemic hypoxia), low cardiac output (stagnant hypoxia) or low haemoglobin saturation (hypoxic hypoxia). The consequence of oxygen deprivation in tissues is a switch to anaerobic metabolism at the cellular level. As such, reduced systemic blood flow may result in increased serum lactate. Serum lactate levels have been correlated with illness severity and mortality in critically ill adults and in ventilated neonates with respiratory distress.\nPhysiological responses.\nAll vertebrates must maintain oxygen homeostasis to survive, and have evolved physiological systems to ensure adequate oxygenation of all tissues. In air breathing vertebrates this is based on lungs to acquire the oxygen, hemoglobin in red corpuscles to transport it, a vasculature to distribute, and a heart to deliver. Short term variations in the levels of oxygenation are sensed by chemoreceptor cells which respond by activating existing proteins, and over longer terms by regulation of gene transcription. Hypoxia is also involved in the pathogenesis of some common and severe pathologies.\nThe most common causes of death in an aging population include myocardial infarction, stroke and cancer. These diseases share a common feature that limitation of oxygen availability contributes to the development of the pathology. Cells and organisms are also able to respond adaptively to hypoxic conditions, in ways that help them to cope with these adverse conditions. Several systems can sense oxygen concentration and may respond with adaptations to acute and long-term hypoxia.\nThe systems activated by hypoxia usually help cells to survive and overcome the hypoxic conditions. Erythropoietin, which is produced in larger quantities by the kidneys under hypoxic conditions, is an essential hormone that stimulates production of red blood cells, which are the primary transporter of blood oxygen, and glycolytic enzymes are involved in anaerobic ATP formation.\nHypoxia-inducible factors (HIFs) are transcription factors that respond to decreases in available oxygen in the cellular environment, or hypoxia. The HIF signaling cascade mediates the effects of hypoxia on the cell. Hypoxia often keeps cells from differentiating. However, hypoxia promotes the formation of blood vessels, and is important for the formation of a vascular system in embryos and tumors. The hypoxia in wounds also promotes the migration of keratinocytes and the restoration of the epithelium. It is therefore not surprising that HIF-1 modulation was identified as a promising treatment paradigm in wound healing.\nExposure of a tissue to repeated short periods of hypoxia, between periods of normal oxygen levels, influences the tissue's later response to prolonged ischaemic exposure. This is known as ischemic preconditioning, and it is known to occur in many tissues.\nAcute.\nIf oxygen delivery to cells is insufficient for the demand (hypoxia), electrons will be shifted to pyruvic acid in the process of lactic acid fermentation. This temporary measure (anaerobic metabolism) allows small amounts of energy to be released. Lactic acid buildup (in tissues and blood) is a sign of inadequate mitochondrial oxygenation, which may be due to hypoxemia, poor blood flow (e.g., shock) or a combination of both. If severe or prolonged, it could lead to cell death.\nIn humans, hypoxia is detected by the peripheral chemoreceptors in the carotid body and aortic body, with the carotid body chemoreceptors being the major mediators of reflex responses to hypoxia. This response does not control ventilation rate at normal PO2, but below normal the activity of neurons innervating these receptors increases dramatically, so much as to override the signals from central chemoreceptors in the hypothalamus, increasing PO2 despite a falling PCO2\nIn most tissues of the body, the response to hypoxia is vasodilation. By widening the blood vessels, the tissue allows greater perfusion.\nBy contrast, in the lungs, the response to hypoxia is vasoconstriction. This is known as hypoxic pulmonary vasoconstriction, or \"HPV\", and has the effect of redirecting blood away from poorly ventilated regions, which helps match perfusion to ventilation, giving a more even oxygenation of blood from different parts of the lungs. In conditions of hypoxic breathing gas, such as at high altitude, HPV is generalized over the entire lung, but with sustained exposure to generalized hypoxia, HPV is suppressed.\nHypoxic ventilatory response (HVR) is the increase in ventilation induced by hypoxia that allows the body to take in and transport lower concentrations of oxygen at higher rates. It is initially elevated in lowlanders who travel to high altitude, but reduces significantly over time as people acclimatize.\nChronic.\nWhen the pulmonary capillary pressure remains elevated chronically (for at least 2 weeks), the lungs become even more resistant to pulmonary edema because the lymph vessels expand greatly, increasing their capability of carrying fluid away from the interstitial spaces perhaps as much as 10-fold. Therefore, in patients with chronic mitral stenosis, pulmonary capillary pressures of 40 to 45\u00a0mm Hg have been measured without the development of lethal pulmonary edema.\nThere are several potential physiologic mechanisms for hypoxemia, but in patients with chronic obstructive pulmonary disease (COPD), ventilation/perfusion (V/Q) mismatching is most common, with or without alveolar hypoventilation, as indicated by arterial carbon dioxide concentration. Hypoxemia caused by V/Q mismatching in COPD is relatively easy to correct, and relatively small flow rates of supplemental oxygen (less than 3 L/min for the majority of patients) are required for long term oxygen therapy (LTOT). Hypoxemia normally stimulates ventilation and produces dyspnea, but these and the other signs and symptoms of hypoxia are sufficiently variable in COPD to limit their value in patient assessment. Chronic alveolar hypoxia is the main factor leading to development of cor pulmonale \u2014 right ventricular hypertrophy with or without overt right ventricular failure \u2014 in patients with COPD. Pulmonary hypertension adversely affects survival in COPD, proportional to resting mean pulmonary artery pressure elevation. Although the severity of airflow obstruction as measured by forced expiratory volume tests FEV1 correlates best with overall prognosis in COPD, chronic hypoxemia increases mortality and morbidity for any severity of disease. Large-scale studies of long term oxygen therapy in patients with COPD show a dose\u2013response relationship between daily hours of supplemental oxygen use and survival. Continuous, 24-hours-per-day oxygen use in appropriately selected patients may produce a significant survival benefit.\nPathological responses.\nCerebral ischemia.\nThe brain has relatively high energy requirements, using about 20% of the oxygen under resting conditions, but low reserves, which make it specially vulnerable to hypoxia. In normal conditions, an increased demand for oxygen is easily compensated by an increased cerebral blood flow. but under conditions when there is insufficient oxygen available, increased blood flow may not be sufficient to compensate, and hypoxia can result in brain injury. A longer duration of cerebral hypoxia will generally result in larger areas of the brain being affected. The brainstem, hippocampus and cerebral cortex seem to be the most vulnerable regions. Injury becomes irreversible if oxygenation is not soon restored. Most cell death is by necrosis but delayed apoptosis also occurs. In addition, presynaptic neurons release large amounts of glutamate which further increases Ca2+ influx and causes catastrophic collapse in postsynaptic cells. Although it is the only way to save the tissue, reperfusion also produces reactive oxygen species and inflammatory cell infiltration, which induces further cell death. If the hypoxia is not too severe, cells can suppress some of their functions, such as protein synthesis and spontaneous electrical activity, in a process called \"penumbra\", which is reversible if the oxygen supply is resumed soon enough.\nMyocardial ischemia.\nParts of the heart are exposed to ischemic hypoxia in the event of occlusion of a coronary artery. Short periods of ischaemia are reversible if reperfused within about 20 minutes, without development of necrosis, but the phenomenon known as \"stunning\" is generally evident. If hypoxia continues beyond this period, necrosis propagates through the myocardial tissue. Energy metabolism in the affected area shifts from mitochondrial respiration to anaerobic glycolysis almost immediately, with concurrent reduction of effectiveness of contractions, which soon cease. Anaerobic products accumulate in the muscle cells, which develop acidosis and osmotic load leading to cellular edema. Intracellular Ca2+ increases and eventually leads to cell necrosis. Arterial flow must be restored to return to aerobic metabolism and prevent necrosis of the affected muscle cells, but this also causes further damage by reperfusion injury. Myocadial stunning has been described as \"prolonged postischaemic dysfunction of viable tissue salvaged by reperfusion\", which manifests as temporary contractile failure in oxygenated muscle tissue. This may be caused by a release of reactive oxygen species during the early stages of reperfusion.\nTumor angiogenesis.\nAs tumors grow, regions of relative hypoxia develop as the oxygen supply is unevenly utilized by the tumor cells. The formation of new blood vessels is necessary for continued tumor growth, and is also an important factor in metastasis, as the route by which cancerous cells are transported to other sites.\nUnder hypoxic conditions, tumor cells activate a coordinated molecular response largely mediated by hypoxia-inducible factors (HIFs), particularly HIF-1\u03b1. Stabilization of HIF-1\u03b1 leads to the transcription of numerous pro-angiogenic genes, including vascular endothelial growth factor (VEGF), platelet-derived growth factor (PDGF), and angiopoietins, which promote endothelial cell proliferation, migration, and the formation of new capillaries around the hypoxic tumor core.\nThe resulting tumor vasculature is often abnormal in structure and function \u2014 characterized by irregular vessel diameters, increased permeability, and poor perfusion \u2014 which further perpetuates local hypoxia and genomic instability. This feedback loop enhances the tumor\u2019s adaptive potential and resistance to therapies such as radiotherapy and chemotherapy, both of which rely on adequate oxygenation to maximize cytotoxic effects.\nIn addition to promoting angiogenesis, HIF signaling also supports metabolic reprogramming toward anaerobic glycolysis, enhances the expression of matrix metalloproteinases (MMPs) that degrade extracellular matrix components, and increases the expression of adhesion molecules that facilitate tumor invasion and metastatic dissemination.\nTogether, these mechanisms make hypoxia-induced angiogenesis a central hallmark of malignant progression and a major therapeutic target in oncology. Agents that block VEGF signaling (such as bevacizumab) or inhibit HIF-1\u03b1 activity are currently used or under investigation to counteract tumor angiogenesis and improve treatment outcomes.\nDiagnosis.\nPhysical examination and history.\nHypoxia can present as acute or chronic.\nAcute presentation may include dyspnea (shortness of breath) and tachypnea (rapid, often shallow, breathing). Severity of symptom presentation is commonly an indication of severity of hypoxia. Tachycardia (rapid pulse) may develop to compensate for low arterial oxygen tension. Stridor may be heard in upper airway obstruction, and cyanosis may indicate severe hypoxia. Neurological symptoms and organ function deterioration occur when the oxygen delivery is severely compromised. In moderate hypoxia, restlessness, headache and confusion may occur, with coma and eventual death possible in severe cases.\nIn chronic presentation, dyspnea following exertion is most commonly mentioned. Symptoms of the underlying condition that caused the hypoxia may be apparent, and can help with differential diagnosis. A productive cough and fever may be present with lung infection, and leg edema may suggest heart failure.\nLung auscultation can provide useful information.\nTests.\nAn arterial blood gas test (ABG) may be done, which usually includes measurements of oxygen content, hemoglobin, oxygen saturation (how much of the hemoglobin is carrying oxygen), arterial partial pressure of oxygen (PaO2), partial pressure of carbon dioxide (PaCO2), blood pH level, and bicarbonate (HCO3)\nX-rays or CT scans of the chest and airways can reveal abnormalities that may affect ventilation or perfusion.\nA ventilation/perfusion scan, also called a V/Q lung scan, is a type of medical imaging using scintigraphy and medical isotopes to evaluate the circulation of air and blood within a patient's lungs, in order to determine the ventilation/perfusion ratio. The ventilation part of the test looks at the ability of air to reach all parts of the lungs, while the perfusion part evaluates how well blood circulates within the lungs.\nPulmonary function testing may include:\nDifferential diagnosis.\nTreatment will depend on severity and may also depend on the cause, as some cases are due to external causes and removing them and treating acute symptoms may be sufficient, but where the symptoms are due to underlying pathology, treatment of the obvious symptoms may only provide temporary or partial relief, so differential diagnosis can be important in selecting definitive treatment.\nCritical illness polyneuropathy or myopathy should be considered in the intensive care unit when patients have difficulty coming off the ventilator.\nPrevention.\nPrevention can be as simple as risk management of occupational exposure to hypoxic environments, and commonly involves the use of environmental monitoring and personal protective equipment. Prevention of hypoxia as a predictable consequence of medical conditions requires prevention of those conditions. Screening of demographics known to be at risk for specific disorders may be useful.\nPrevention of altitude-induced hypoxia.\nTo counter the effects of high-altitude diseases, the body must return arterial PaO2 toward normal. Acclimatization, the means by which the body adapts to higher altitudes, only partially restores PO2 to standard levels. Hyperventilation, the body's most common response to high-altitude conditions, increases alveolar PO2 by raising the depth and rate of breathing. However, while PO2 does improve with hyperventilation, it does not return to normal. Studies of miners and astronomers working at 3000 meters and above show improved alveolar PO2 with full acclimatization, yet the PO2 level remains equal to or even below the threshold for continuous oxygen therapy for patients with chronic obstructive pulmonary disease (COPD). In addition, there are complications involved with acclimatization. Polycythemia, in which the body increases the number of red blood cells in circulation, thickens the blood, raising the risk of blood clots.\nIn high-altitude situations, only oxygen enrichment or compartment pressurisation can counteract the effects of hypoxia. Pressurisation is practicable in vehicles and for emergencies in ground installations. By increasing the concentration of oxygen at ambient pressure, the effects of lower barometric pressure are countered and the level of arterial PO2 is restored toward normal capacity. A small amount of supplemental oxygen reduces the equivalent altitude in climate-controlled rooms. At 4000\u00a0m, raising the oxygen concentration level by 5% via an oxygen concentrator and an existing ventilation system provides an altitude equivalent of 3000\u00a0m, which is much more tolerable for the increasing number of lowlanders who work in high altitude. In a study of astronomers working in Chile at 5050\u00a0m, oxygen concentrators increased the level of oxygen concentration by almost 30 percent (that is, from 21 percent to 27 percent). This resulted in increased worker productivity, less fatigue, and improved sleep.\nOxygen concentrators can be used for high-altitude oxygen enrichment in climate-controlled environments. They require minimal maintenance, operate using a local air supply, and consume relatively little electricity. By extracting oxygen directly from ambient air, concentrators remove the logistical and financial burden of transporting compressed oxygen cylinders to remote or mountainous regions. Because offices and residential buildings at high altitudes often already maintain controlled temperature and humidity, these systems can be readily integrated into existing climate-control infrastructure.\nTreatment and management.\nTreatment and management depend on circumstances. For most high altitude situations the risk is known, and prevention is appropriate. At low altitudes hypoxia is more likely to be associated with a medical problem or an unexpected contingency, and treatment is more likely to be provided to suit the specific case. It is necessary to identify persons who need oxygen therapy, as supplemental oxygen is required to treat most causes of hypoxia, but different oxygen concentrations may be appropriate.\nTreatment of acute and chronic cases.\nTreatment will depend on the cause of hypoxia. If it is determined that there is an external cause, and it can be removed, then treatment may be limited to support and returning the system to normal oxygenation. In other cases a longer course of treatment may be necessary, and this may require supplemental oxygen over a fairly long term or indefinitely.\nThere are three main aspects of oxygenation treatment: maintaining patent airways, providing sufficient oxygen content of the inspired air, and improving the diffusion in the lungs. In some cases treatment may extend to improving oxygen capacity of the blood, which may include volumetric and circulatory intervention and support, hyperbaric oxygen therapy and treatment of intoxication.\nInvasive ventilation may be necessary or an elective option in surgery. This generally involves a positive pressure ventilator connected to an endotracheal tube, and allows precise delivery of ventilation, accurate monitoring of FiO2, and positive end-expiratory pressure, and can be combined with anaesthetic gas delivery. In some cases a tracheotomy may be necessary. Decreasing metabolic rate by reducing body temperature lowers oxygen demand and consumption, and can minimise the effects of tissue hypoxia, especially in the brain, and therapeutic hypothermia based on this principle may be useful. \nWhere the problem is due to respiratory failure. it is desirable to treat the underlying cause. In cases of pulmonary edema, diuretics can be used to reduce the oedems. Steroids may be effective in some cases of interstitial lung disease, and in extreme cases, extracorporeal membrane oxygenation (ECMO) can be used.\nHyperbaric oxygen has been found useful for treating some forms of localized hypoxia, including poorly perfused trauma injuries such as Crush injury, compartment syndrome, and other acute traumatic ischemias. It is the definitive treatment for severe decompression sickness, which is largely a condition involving localized hypoxia initially caused by inert gas embolism and inflammatory reactions to extravascular bubble growth. It is also effective in carbon monoxide poisoning and diabetic foot.\nA prescription renewal for home oxygen following hospitalization requires an assessment of the patient for ongoing hypoxemia.\nOutcomes.\nPrognosis in cases of hypoxia depends strongly on the underlying cause, the severity and duration of oxygen deprivation, the effectiveness and timeliness of treatment, and any pre-existing medical conditions that impair oxygen delivery or utilization, such as anemia, COPD, or cardiovascular disease. Mild, short-term hypoxia is often reversible with prompt oxygen therapy and correction of the underlying cause, whereas prolonged or severe hypoxia can result in irreversible cellular injury, hypoxic brain injury, or multi-organ failure.\nHypoxia that leads to impaired judgment, delayed reactions, or loss of consciousness can indirectly contribute to fatal outcomes in situations where the immediate cause of death is secondary. This has been documented in underwater diving accidents, where hypoxia can cause confusion or unconsciousness before drowning occurs; in high-altitude mountaineering, where it contributes to exposure, hypothermia, and falls; and in aviation, where pilots of unpressurized aircraft or performers in aerobatic maneuvers may lose control of the aircraft following hypoxic incapacitation.\nIn occupational and environmental contexts, chronic or intermittent hypoxia\u2014such as in miners, high-altitude workers, or individuals with sleep apnea\u2014can have cumulative effects on cognitive performance, cardiovascular function, and metabolic regulation. Long-term exposure may increase the risk of pulmonary hypertension, polycythemia, and cardiac remodeling, though individual susceptibility varies.\nEpidemiology.\nHypoxia is a common disorder but there are many possible causes. Prevalence is variable. Some of the causes are very\u00a0common, like pneumonia or chronic obstructive pulmonary disease; some are quite\u00a0rare like hypoxia due to cyanide poisoning. Others, like reduced oxygen tension at high altitude, may be regionally distributed or associated with a specific demographic.\nGeneralized hypoxia is an occupational hazard in several high-risk professions where oxygen availability is reduced or disrupted. These include firefighting, where smoke inhalation and exposure to carbon monoxide can impair oxygen transport; professional diving, where improper gas mixtures or equipment failure may lead to hypoxic hypoxia; mining and underground rescue, where oxygen depletion can result from combustion, gas displacement, or poor ventilation; and aviation, particularly when flying at high altitudes in unpressurized aircraft, where ambient oxygen pressure falls below levels needed for adequate blood oxygenation.\nPotentially life-threatening hypoxemia is common in critically ill patients.\nLocalized hypoxia can occur when blood flow to a specific region of the body is restricted, leading to insufficient oxygen delivery to the affected tissues. This may arise as a complication of diabetes mellitus, where peripheral artery disease and microvascular damage impair circulation to the extremities; as a consequence of decompression sickness, in which gas emboli obstruct capillaries; or following traumatic injury that compromises local blood supply.\nHypoxia related to underdeveloped lung function is also a frequent complication of premature birth. In preterm infants, incomplete maturation of the alveoli and insufficient production of surfactant can lead to respiratory distress syndrome, resulting in systemic oxygen deprivation. In the United States, intrauterine hypoxia and birth asphyxia together were ranked as the tenth leading cause of infant mortality in recent national statistics.\nSilent hypoxia.\nSilent hypoxia (also known as happy hypoxia) is generalised hypoxia that does not coincide with shortness of breath. This presentation is known to be a complication of COVID-19, and is also known in atypical pneumonia, altitude sickness, and rebreather malfunction accidents.\nHistory.\nThe 2019 Nobel Prize in Physiology or Medicine was awarded to William G. Kaelin Jr., Sir Peter J. Ratcliffe, and Gregg L. Semenza in recognition of their discovery of cellular mechanisms to sense and adapt to different oxygen concentrations, establishing a basis for how oxygen levels affect physiological function.\nThe use of the term \"hypoxia\" appears to be relatively recent, with the first recorded use in scientific publication from 1945. Previous to this the term \"anoxia\" was extensively used for all levels of oxygen deprivation. Investigation into the effects of lack of oxygen date from the mid 19th century.\nEtymology.\nHypoxia is formed from the Greek roots \u03c5\u03c0o (hypo), meaning under, below, and less than, and o\u03be\u03c5 (oxy), meaning acute or acid, which is the root for oxygen.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "13293", "revid": "25994772", "url": "https://en.wikipedia.org/wiki?curid=13293", "title": "Historical revisionism", "text": "Reinterpretation of a historical account\nIn historiography, historical revisionism is the reinterpretation of a historical account. It involves challenging the orthodox (established, accepted or traditional) scholarly views or narratives regarding a historical event, timespan, or phenomenon by introducing contrary evidence or reinterpreting the motivations of the people involved. Revision of the historical record can reflect new discoveries of fact, evidence, and interpretation as they come to light. The process of historical revision is a common, necessary, and usually uncontroversial process which develops and refines the historical record to make it more complete and accurate.\nOne form of historical revisionism involves denying the moral significance or accuracy of the historical record. This type of historical revisionism is called historical negationism, and is contentious as it often includes denying the veracity of genuine documents, or deliberately manipulating statistical data to reach predetermined conclusions. The destruction or alteration of cultural heritage sites is also considered a form of illegitimate historical revisionism when it serves to deny the cultural or historical claims of ethnic groups. Negationists may use the term \"revisionism\" to portray their pseudoscholarship as legitimate, especially in the context of genocide denial.\nBackground.\nHistorical revisionism is the means by which the historical record, the history of a society, as understood in its collective memory, continually accounts for new facts and interpretations of the events. \nRevisionist historians contest the mainstream or traditional view of historical events and raise views at odds with traditionalists. In the field of historiography, the historian who works within the existing establishment of society and has produced a body of history books from which he or she can claim authority, usually benefits from the \"status quo\". As such, historical revisionism can produce significant controversy within society. \nRevisionist history is often practiced by those who are in the minority, such as feminist historians, ethnic minority historians, those working outside of mainstream academia in smaller and less known universities, or the youngest scholars, essentially historians who have the most to gain and the least to lose in challenging the status quo. In the friction between the mainstream of accepted beliefs and the new perspectives of historical revisionism, received historical ideas are either changed, solidified, or clarified. If over a period of time, the revisionist ideas become the new establishment \"status quo\" a paradigm shift is said to have occurred. \nHistorians are influenced by the \"zeitgeist\" (spirit of the time), and the usually progressive changes to society, politics, and culture, such as occurred after the Second World War (1939\u20131945); in \"The Future of the Past\" (1989), the historian C. Vann Woodward said: \n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;...these developments will and should raise new questions about the past, and affect our reading of large areas of history, and my belief is that future revisions may be extensive enough to justify calling the coming age of historiography an \"Age of Reinterpretation\". The first illustration happens to come mainly from American history, but this should not obscure the broader scope of the revolution, which has no national limitations.\nThe philosopher of science, Thomas Kuhn, said, in contrast to the quantifiable hard sciences, characterized by a single paradigm, the social sciences are characterized by several paradigms that derive from a \"tradition of claims, counterclaims, and debates over [the] fundamentals\" of research. The philosopher Karl Popper said that \"each generation has its own troubles and problems, and, therefore, its own interests and its own point of view.\" \nNegationism and denial.\nHistorians distinguish historical revisionism from historical negationism, which is a form of denialism. \nIn contrast, historical revisionism entails the refinement of existing knowledge about a historical event, not a denial of the event, itself; that such refinement of history emerges from the examination of new, empirical evidence, and a re-examination, and consequent re-interpretation of the existing documentary evidence. That legitimate historical revisionism acknowledges the existence of a \"certain body of irrefutable evidence\" and the existence of a \"convergence of evidence\", which suggest that an event \u2013 such as the Black Death, American slavery, and the Holocaust \u2013 did occur; whereas the denialism of history rejects the entire foundation of historical evidence. Historian Deborah Lipstadt states that Holocaust deniers, such as Harry Elmer Barnes, disingenuously self-identify as \"historical revisionists\" to obscure their denialism as academic revision of the historical record.\nBasis for historical revision.\nThe process of historical revision involves updating the historical record to accommodate developments as they arise. The historical record may be revised to accommodate for a number of academic reasons, including the following:\nAccess to new data/records.\nThe release, discovery, or publicization of documents previously unknown may lead scholars to hold new views of well established events. For example, archived or sealed government records (often related to national security) will become available under the thirty-year rule and similar laws. Such documents can provide new sources and therefore new analyses of past events that will alter the historical perspective.\nWith the release of the ULTRA archives in the 1970s under the British thirty-year rule, much of the Allied high command tactical decisionmaking process was re-evaluated, particularly the Battle of the Atlantic. Before the release of the ULTRA archives, there was much debate over whether Field Marshal Bernard Montgomery could have known that Arnhem was heavily garrisoned. With the release of the archives, which indicated that they were, the balance of the evidence swung in the direction of his detractors. The release of the ULTRA archives also forced a re-evaluation of the history of the electronic computer.\nNew sources in other languages.\nAs more sources in other languages become available historians may review their theories in light of the new sources. The revision of the meaning of the Dark Ages is an example.\nDevelopments in other fields of science.\nDNA analysis has had an impact in various areas of history either confirming established historical theories or presenting new evidence that undermines the current established historical explanation. Professor Andrew Sherratt, a British prehistorian, was responsible for introducing the work of anthropological writings on the consumption of legal and illegal drugs and how to use the papers to explain certain aspects of prehistoric societies. Carbon dating, the examination of ice cores and tree rings, palynology, scanning electron microscope analysis of early metal samples, and measuring oxygen isotopes in bones, have all provided new data in the last few decades with which to argue new hypotheses. Extracting ancient DNA allows historians to debate the meaning and importance of race and indeed current identities.\nNationalism.\nGovernment bodies may engage in historical revisionism for political gain. For example, in schoolbooks' history on Europe, it is possible to read about an event from completely different perspectives. In the Battle of Waterloo, most British, French, Dutch and German schoolbooks slant the battle to emphasise the importance of the contribution of their nations. Sometimes, the name of an event is used to convey political or a national perspective. For example, the same conflict between two English-speaking countries is known by two different names: the \"American War of Independence\" and the \"American Revolutionary War\". As perceptions of nationalism change, so do the areas of history that are driven by such ideas. Wars are contests between enemies, and postwar histories select the facts and interpretations to suit their internal needs, The Korean War, for example, has sharply different interpretations in textbooks in the countries involved.\nCulture.\nFor example, as regionalism has regained some of its old prominence in British politics, some historians have suggested that the older studies of the English Civil War were centred on England and that to understand the war, events that had previously been dismissed as on the periphery should be given greater prominence. To emphasise this, revisionist historians have suggested that the English Civil War becomes just one of a number of interlocking conflicts known as Wars of the Three Kingdoms. Furthermore, as cultures develop, it may become strategically advantageous for some revision-minded groups to revise their public historical narrative in such a way so as to either discover, or in rarer cases manufacture, a precedent which contemporary members of the given subcultures can use as a basis or rationale for reform or change.\nIdeology.\nFor example, in the 1940s, it became fashionable to see the English Civil War from a Marxist school of thought. In the words of Christopher Hill, \"the Civil War was a class war.\" After World War II, the influence of Marxist interpretation waned in British academia and by the 1970s this view came under attack by a new school of revisionists and it has been largely overturned as a major mainstream explanation of the mid-17th-century conflict in England, Scotland, and Ireland.\nHistorical causation.\nIssues of causation in history are often revised with new research: for example, by the mid-20th century the status quo was to see the French Revolution as the result of the triumphant rise of a new middle class. Research in the 1960s prompted by revisionist historians like Alfred Cobban and Fran\u00e7ois Furet revealed the social situation was much more complex, and the question of what caused the revolution is now closely debated.\nSpecific issues.\nDark Ages.\nAs non-Latin texts, such as Welsh, Gaelic and the Norse sagas have been analysed and added to the canon of knowledge about the period, and as much more archaeological evidence has come to light, the period known as the Dark Ages has narrowed to the point that many historians no longer believe that such a term is useful. Moreover, the term \"dark\" implies less of a void of culture and law but more a lack of many source texts in Mainland Europe. Many modern scholars who study the era tend to avoid the term altogether for its negative connotations and find it misleading and inaccurate for any part of the Middle Ages.\nFeudalism.\nThe concept of feudalism has been questioned. Revisionist scholars led by historian Elizabeth A. R. Brown have rejected the term.\nNew World discovery and European colonization of the Americas.\nIn recounting the European colonization of the Americas, some history books of the past paid little attention to the indigenous peoples of the Americas, usually mentioning them only in passing and making no attempt to understand the events from their point of view. That was reflected in the description of Christopher Columbus having discovered America. Those events' portrayal has since been revised to avoid the word \"discovery.\"\nIn his 1990 book, \"The Conquest of Paradise\", Kirkpatrick Sale argued that Christopher Columbus was an imperialist bent on conquest from his first voyage. In a \"New York Times\" book review, historian and member of the Christopher Columbus Quincentenary Jubilee Committee William Hardy McNeill wrote about Sale: \n\"He has set out to destroy the heroic image that earlier writers have transmitted to us. Mr. Sale makes Columbus out to be cruel, greedy and incompetent (even as a sailor), and a man who was perversely intent on abusing the natural paradise on which he intruded.\"\nMcNeill declares Sale's work to be \"unhistorical, in the sense that [it] selects from the often-cloudy record of Columbus's actual motives and deeds what suits the researcher's 20th-century purposes.\" McNeill states that detractors and advocates of Columbus present a \"sort of history [that] caricatures the complexity of human reality by turning Columbus into either a bloody ogre or a plaster saint, as the case may be.\"\nNew Qing history.\nHistorians in China and from abroad long wrote that the Manchus who conquered China and established the Qing dynasty (1636\u20131912) adopted the customs and institutions of the Han Chinese dynasties that preceded them and were \"sinicized\", that is, absorbed into Chinese culture. In 1990 American historians explored Manchu language sources and newly accessible imperial archives, and discovered that the emperors retained their Manchu culture and that they regarded China proper as only one part of their larger empire. These scholars differ among themselves but agree on a major revision of the history of the Qing dynasty.\nFrench attack formations in the Napoleonic wars.\nThe military historian James R. Arnold argues:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The writings of Sir Charles Oman and Sir John Fortescue dominated subsequent English-language Napoleonic history. Their views [that the French infantry used heavy columns to attack lines of infantry] became very much the received wisdom... By 1998 a new paradigm seemed to have set in with the publication of two books devoted to Napoleonic battle tactics. Both claimed that the French fought in line at Maida and both fully explored French tactical variety. The 2002 publication of \"The Battle of Maida 1806: Fifteen Minutes of Glory\", appeared to have brought the issue of column versus line to a satisfactory conclusion: \"The contemporary sources are... the best evidence and their conclusion is clear: General Comp\u00e8re's brigade formed into line to attack Kempt's Light Battalion.\" The decisive action at Maida took place in less than 15 minutes. It had taken 72 years to rectify a great historian's error about what happened during those minutes.\nArgentine Civil Wars.\nAfter the proclamation of the Argentine Republic in late 1861, its first \"de facto\" President, Bartolom\u00e9 Mitre, wrote the first Argentine historiographical works: \"Historia de Belgrano y de la Independencia Argentina\" and \"Historia de San Mart\u00edn y de la emancipaci\u00f3n sudamericana\". Although these were criticised by notorious intellectuals such as Dalmacio V\u00e9lez Sarsfield and Juan Bautista Alberdi and even by some colleagues like Adolfo Sald\u00edas, both stated a liberal-conservative bias on Argentine history through the National Academy of History established in 1893, despite the existence of caudillos and gauchos.\nDuring the Radical Civic Union government of Hip\u00f3lito Yrigoyen, historians followed the revisionist view of anti-mitrist politicians such as Carlos D'Amico, Ernesto Quesada and David Pe\u00f1a and their theories reached the academy thanks to Dardo Corval\u00e1n Mendilharsu. Argentine historical revisionism could reach its peak during the peronist government. In 2011, the Manuel Dorrego National Institute of Argentine and Iberoamerican Historical Revisionism was established by the Secretary of Culture, but this one suffered a rupture between 21st century socialists and nationalists. Three weeks after the Inauguration of Mauricio Macri, the institute was closed.\nWithin the United States of America.\nThe historian and American Historical Association member James M. McPherson has said: \n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The fourteen-thousand members of this association [i.e., the American Historical Association], however, know that revision is the lifeblood of historical scholarship. History is a continuing dialogue, between the present and the past. Interpretations of the past are subject to change in response to new evidence, new questions asked of the evidence, new perspectives gained by the passage of time. There is no single, eternal, and immutable \"truth\" about past events and their meaning.\nThe unending quest of historians for understanding the past \u2013 that is, \"revisionism\" \u2013 is what makes history vital and meaningful ... Supreme Court decisions often reflect a \"revisionist\" interpretation of history as well as of the Constitution.\nOn resistance to the works of revised history that present a culturally-comprehensive historical narrative of the US, the perspectives of black people, women, and the labour movement, the historian David Williams said:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;These, and other, scholarly voices, called for a more comprehensive treatment of American history, stressing that the mass of Americans, not simply the power \u00e9lites, made history. Yet, it was mainly white males of the power \u00e9lite who had the means to attend college, become professional historians, and shape a view of history that served their own class, race, and gender interests at the expense of those not so fortunate \u2013 and, quite literally, to paper over aspects of history they found uncomfortable. \"One is astonished in the study of history\", wrote Du Bois in 1935, \"at the recurrence of the idea that evil must be forgotten, distorted, skimmed over... The difficulty, of course, with this philosophy is that history loses its value, as an incentive and [as] an example; it paints perfect men and noble nations, but it does not tell the truth\".\nAfter the Second World War, the study and production of history in the US was expanded by the G.I. Bill, which funding allowed \"a new and more broadly-based generation of scholars\" with perspectives and interpretations drawn from the feminist movement, the Civil Rights Movement, and the American Indian Movement. That expansion and deepening of the pool of historians voided the existence of a definitive and universally-accepted history, therefore, is presented by the revisionist historian to the national public with an history that has been corrected and augmented with new facts, evidence, and interpretations of the historical record. In \"The Cycles of American History\" (1986), in contrasting and comparing the US and the Soviet Union during the Cold War (1945\u20131991), the historian Arthur M. Schlesinger Jr. said:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;... but others, especially in the United States... represent what American historians call \"revisionism\" \u2013 that is readiness to challenge official explanations. No one should be surprised by this phenomenon. Every war in American history has been followed, in due course, by skeptical reassessments of supposedly sacred assumptions... for [historical] revisionism is an essential part of the process, by which history, through the posing of new problems and the investigation of new possibilities, enlarges its perspectives and enriches its insights.\nThe historian Forrest McDonald is often critical of the turn that revisionism has taken but admits that the turmoil of the 1960s America has changed the way history was written:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The result, as far as the study of history was concerned, was an awakened interest in subjects that historians had previously slighted. Indian history, black history, women's history, family history, and a host of specializations arose. These expanded horizons enriched our understanding of the American past, but they also resulted in works of special pleading, trivialization, and downright falsification.\nIn 1986, the historian John Hope Franklin described four stages in the historiography of the African experience of life in the US, which were based upon different models of historical consensus.\nWorld War I.\nGerman guilt.\nIn reaction to the orthodox interpretation enshrined in the Versailles Treaty, which declared that Germany was guilty of starting World War I, the self-described \"revisionist\" historians of the 1920s rejected the orthodox view and presented a complex causation in which several other countries were equally guilty. Intense debate continues among scholars.\nPoor British and French military leadership.\nThe military leadership of the British Army during World War I was frequently condemned as poor by historians and politicians for decades after the war ended. Common charges were that the generals commanding the army were blind to the realities of trench warfare, ignorant of the conditions of their men and unable to learn from their mistakes, thus causing enormous numbers of casualties (\"lions led by donkeys\"). However, during the 1960s, historians such as John Terraine began to challenge that interpretation. In recent years, as new documents have come forth and the passage of time has allowed for more objective analysis, historians such as Gary D. Sheffield and Richard Holmes observe that the military leadership of the British Army on the Western Front had to cope with many problems that they could not control, such as a lack of adequate military communications, which had not occurred. Furthermore, military leadership improved throughout the war, culminating in the Hundred Days Offensive advance to victory in 1918. Some historians, even revisionists, still criticise the British High Command severely but are less inclined to portray the war in a simplistic manner with brave troops being led by foolish officers.\nThere has been a similar movement regarding the French Army during the war with contributions by historians such as Anthony Clayton. Revisionists are far more likely to view commanders such as French General Ferdinand Foch, British General Douglas Haig and other figures, such as American John Pershing, in a sympathetic light.\nReconstruction in the United States.\nRevisionist historians of the Reconstruction era of the United States rejected the dominant Dunning School that stated that Black Americans were used by carpetbaggers, and instead stressed economic greed on the part of northern businessmen. Indeed, in recent years a \"neoabolitionist\" revisionism has become standard; it uses the moral standards of racial equality of the 19th century abolitionists to criticize racial policies. \"Foner's book represents the mature and settled Revisionist perspective\", historian Michael Perman has concluded regarding Eric Foner's \"Reconstruction: America's Unfinished Revolution, 1863\u20131877\" (1988).\nAmerican business and \"robber barons\".\nThe role of American business and the alleged \"robber barons\" began to be revised in the 1930s. Termed \"business revisionism\" by Gabriel Kolko, historians such as Allan Nevins, and then Alfred D. Chandler emphasized the positive contributions of individuals who were previously pictured as villains. Peter Novick writes, \"The argument that whatever the moral delinquencies of the robber barons, these were far outweighed by their decisive contributions to American military [and industrial] prowess, was frequently invoked by Allan Nevins.\"\nExcess mortality in the Soviet Union under Stalin.\nPrior to the collapse of the Soviet Union and the archival revelations, Western historians estimated that the numbers killed by Stalin's regime were 20 million or higher. After the Soviet Union dissolved, evidence from the Soviet archives also became available and provided information that led to a significant revision in death toll estimates for the Stalin regime, with estimates in the range from 3 million to 9 million. In post-1991 Russia the KGB archives remained briefly open during 1990's, which helped creation of organisations such as Memorial, which engaged in research of the archives and search of secret mass burial grounds. After Putin came to power however, access to archives was restricted again and research in this area once again became politically incorrect, culminating with forcibly shutting down the organization in 2021.\nSoviet Union and Russia.\nSoviet Union frequently resorted to changing its official history to suit changes in state policy, especially after splits in the Bolshevik leadership or change of political alliances. The book History of the Communist Party of the Soviet Union (Bolsheviks) was subject to numerous such changes to reflect removal of Bolshevik leaders previously trusted by Stalin but did not support him unanimously. Great Soviet Encyclopedia was also redacted frequently, with subscribers of the paper book receiving letter to cut out pages e.g. about Lavrentiy Beria or Nikolai Bukharin and replace them with unrelated articles. Historic photos were also frequently edited to remove people who later lost trust of the Party.\nThe process of rewriting history of USSR and post-1991 Russia was once again restarted in 2010's after Russia's first attack on Ukraine and intensified after 2022 full-scale invasion in Ukraine. History school books received significant changes which reflected the changes in the official history narratives: for example, while 2010 books openly mentioned decrease of life expectancy in Soviet Union caused shortages and insufficient spending on public healthcare, new 2023 books vaguely states that life expectancy has generally increased and instead focused on unspecified \"achievements in the sphere of education and science\". In chapters on Stalin, he's once again presented as a great tragedy to ordinary Russians and any mentions of repressions have disappeared. Similar changes were introduced in chapters discussing Soviet economy, space program, Brezhnev, collapse of USSR, perestroika and glasnost, where the phrase \"freedom of speech\" started to be used in scare quotes and presented as something harmful. Soviet intervention in Afghanistan in 1979 which was presented as Soviet contribution into the fight against radical Islamism, completely contradicting both Soviet and post-Soviet narratives.\nAlso, since 2014, Russian law enforcement started to prosecute public statements which do not comply with the current version of Russian history. Article 354.1 of Criminal Code of Russia which makes \"rehabilitation of Nazism\" a crime has been applied both to actual statements praising Nazism, but also to statements which recalled Nazi-Soviet cooperation 1939\u20131941 or Soviet war crimes conducted in other countries. In some cases article 20.3 of Code of the Russian Federation on Administrative Offenses is also being applied in these cases.\nGuilt for causing World War II.\nThe orthodox interpretation blamed Nazi Germany and Imperial Japan for causing the war. Revisionist historians of World War II, notably Charles A. Beard, said the United States was partly to blame because it pressed the Japanese too hard in 1940 and 1941 and rejected compromises. Other notable contributions to this discourse include Charles Tansill, \"Back Door To War\" (1952); Frederic Sanborn, \"Design For War\" (1951); and David Hoggan, \"The Forced War\" (1989). The British historian A. J. P. Taylor controversially argued that Hitler was an ineffective and inexperienced diplomat and did not deliberately set out to cause a world war.\nPatrick Buchanan, an American paleoconservative pundit, argued that the Anglo\u2013French guarantee in 1939 encouraged Poland not to seek a compromise over Danzig. He further argued that Britain and France were in no position to come to Poland's aid, and Hitler was offering the Poles an alliance in return. Buchanan argued the guarantee led the Polish government to transform a minor border dispute into a major world conflict, and handed Eastern Europe, including Poland, to Stalin. Buchanan also argued the guarantee ensured the country would be eventually invaded by the Soviet Union, as Stalin knew the British were in no position to declare war on the Soviet Union in 1939, due to their military weakness.\nAtomic bombings of Hiroshima and Nagasaki.\nThe atomic bombings of Hiroshima and Nagasaki have generated controversy and debate. Historians who accepted President Harry Truman's reasoning in justifying dropping atomic bombs to force Japanese surrender end of World War II are known as \"orthodox,\" while \"revisionists\" generally deny that the bombs were necessary. Some also claim that Truman knew they were not necessary but wanted to pressure the Soviet Union. These historians see Truman's decision as a major factor in starting the Cold War. This perspective asserts that Truman ignored or downplayed predictions of casualties.\nCold War.\nHistorians debate the causes and responsibility for the Cold War. The \"orthodox\" view puts the major blame on the Soviet Union, while a \"revisionist\" view puts more responsibility on the United States.\nVietnam War.\n\"America in Vietnam\" (1978), by Guenter Lewy, is an example of historical revisionism that differs much from the popular view of the U.S. in the Vietnam War (1955\u201375) for which the author was criticized and supported for belonging to the revisionist school on the history of the Vietnam War. Lewy's reinterpretation was the first book of a body of work by historians of the revisionist school about the geopolitical role and the U.S. military behavior in Vietnam.\nIn the introduction, Lewy said:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;It is the reasoned conclusion of this study ... that the sense of guilt created by the Vietnam war in the minds of many Americans is not warranted and that the charges of \"officially, condoned\" illegal and grossly immoral conduct are without substance. Indeed, detailed examination of battlefield practices reveals that the loss of civilian life in Vietnam was less great than in World War II [1939\u201345] and Korea [1950\u201353] and that concern with minimizing the ravages of the war was strong. To measure and compare the devastation and loss of human life caused by different war will be objectionable to those who repudiate all resort to military force as an instrument of foreign policy and may be construed as callousness. Yet as long as wars do take place at all it remains a moral duty to seek to reduce the agony caused by war, and the fulfillment of this obligation should not be disdained.\u2014\u200a\nOther reinterpretations of the historical record of the U.S. war in Vietnam, which offer alternative explanations for American behavior, include \"Why We Are in Vietnam\" (1982), by Norman Podhoretz, \"Triumph Forsaken: The Vietnam War, 1954\u20131965\" (2006), by Mark Moyar, and \"Vietnam: The Necessary War\" (1999), by Michael Lind.\nChronological revisionism.\nIt is generally accepted that the foundations of modern chronology were laid by the humanist Joseph Scaliger. Isaac Newton in his work \"The Chronology of Ancient Kingdoms\" made one of the first attempts to revise the \"Scaligerian chronology\". In the twentieth century the \"revised chronology\" of Immanuel Velikovsky can be singled out in this direction, perhaps it initiated a wave of new broad interest in the revision of chronology.\nIn general, revisionist chronological theories suggest halving the duration of the Christian era, or consider certain historical periods to be erroneously dated, such as Heribert Illig's \"Phantom time hypothesis\" or the materials of the \"New Chronology\", a proposed revision of eras by academician Anatoly Fomenko, albeit one widely rejected by mainstream scholars as pseudoscience.\nReferences.\nInformational notes\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nCitations\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading"}
