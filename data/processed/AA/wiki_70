{"id": "7580", "revid": "28633264", "url": "https://en.wikipedia.org/wiki?curid=7580", "title": "Commodore International", "text": "Home computer and electronics manufacturer\nCommodore International Corporation (CI), also known as Commodore International Limited, was a home computer and electronics manufacturer with its head office in The Bahamas and its executive office in the United States founded in 1976 by Jack Tramiel and Irving Gould. It was the successor company to Commodore Business Machines (Canada) Ltd., established in 1958 by Tramiel and Manfred Kapp. Commodore International, along with its U.S. subsidiary Commodore Business Machines, Inc. (CBM), was a significant participant in the development of the home computer industry, and at one point in the 1980s was the world's largest in the industry.\nThe company released its first home computer, the Commodore PET, in 1977; it was followed by the VIC-20, the first ever computer to reach one million units of sales. In 1982, the company developed and marketed the world's best selling computer, the Commodore 64; its success made Commodore one of the world's largest personal computer manufacturers, with sales peaking in the last quarter of 1983 at $ (equivalent to $ in 2024). However an internal struggle led to co-founder Tramiel quitting, then rivaling Commodore under Atari Corporation joined by a number of other employees. Commodore in 1985 launched the Amiga 1000 personal computer \u2014 running on AmigaOS featuring a full color graphical interface and preemptive multitasking \u2014 which would initially become a popular platform for computer games and creative software. The company did particularly well in European markets; in West Germany, Commodore machines were ubiquitous as of 1989.\nThe company's position started declining in the late 1980s amid internal conflicts and mismanagement, and while the Amiga line was popular, newer models failed to keep pace against competing IBM PC-compatibles and Apple Macintosh. By 1992, MS-DOS and 16-bit video game consoles offered by Nintendo and Sega had eroded Amiga's status as a solid gaming platform. Under co-founding chairman Irving Gould and president Mehdi Ali, Commodore filed for bankruptcy on April 29, 1994 and was soon liquidated, with its assets purchased by German company Escom. The Amiga line was revitalized and continued to be developed by Escom until it too went bankrupt, in July 1996. Commodore's computer systems, mainly the C64 and Amiga series, retain a cult following decades after its demise.\nCommodore's assets have been passed through various companies since then. After Escom's demise and liquidation, its core assets were sold to Gateway 2000 while the Commodore brand name was eventually passed to Tulip Computers of the Netherlands. The brand remained under ownership by a Dutch company until 2025, when a group of investors purchased the brand and incorporated a new U.S. company called Commodore International.\nGateway 2000 attempted but failed to market a modern Amiga, and eventually sold the copyrights, Amiga trademark and other intellectual properties to Amiga, Inc., while retaining the Commodore patents, which are now under Acer since its acquisition of Gateway. Amiga Corp., a sister company of Cloanto, owns the Amiga properties since 2019. Hyperion Entertainment of Belgium has continued development of AmigaOS (version 4) to this day under license, and have released AmigaOne computers based on PowerPC.\nHistory.\nCommodore Business Machines (Canada) Ltd. (1954\u20131976).\n Jack Tramiel and Manfred Kapp met in the early 1950s while both employed by the Ace Typewriter Repair Company in New York City. In 1954, they partnered to sell used and reconditioned typewriters and used their profits to purchase the Singer Typewriter Company. After acquiring a local dealership selling Everest adding machines, Tramiel convinced Everest to give him and Kapp exclusive Canadian rights to its products and established Everest Office Machines in Toronto in 1955.\nBy 1958, the adding machine business was slowing. Tramiel made a connection with an Everest agent in England who alerted him to a business opportunity to import portable typewriters manufactured by a Czechoslovakian company into Canada. On October 10, 1958, Tramiel and Kapp incorporated Commodore Portable Typewriter, Ltd. in Toronto to sell the imported typewriters. Commodore funded its operations through factoring over its first two years but faced a continual cash crunch. To bolster the company's financial condition, Tramiel and Kapp sold a portion of the company to Atlantic Acceptance Corporation, one of Canada's largest financing companies, and Atlantic President C. Powell Morgan became the chairman of Commodore. In 1962, the company went public on the Montreal Stock Exchange, under the name of Commodore Business Machines (Canada), Ltd.\nWith the financial backing of Atlantic Acceptance, Commodore expanded rapidly in the early 1960s. It purchased a factory in West Germany to manufacture its typewriters, began distributing office furniture for a Canadian manufacturer, and sold Pearlsound radio and stereo equipment. In 1965, it purchased the furniture company for which it served as the distributor and moved its headquarters to its facilities on Warden Avenue in the Scarborough district of Toronto. That same year, the company made a deal with a Japanese manufacturer to produce adding machines for Commodore, and purchased the office supply retailer Wilson Stationers to serve as an outlet for its typewriters.\nIn 1965, Atlantic Acceptance collapsed when it failed to make a routine payment. A subsequent investigation by a royal commission revealed a massive fraud scheme in which the company falsified financial records to acquire loans funneled into a web of subsidiaries where C. Powell Morgan held a personal stake. Morgan then pocketed the money or invested it in several unsuccessful ventures. Commodore was one of the Atlantic subsidiaries directly implicated in this scheme. Despite heavy suspicion, the commission could not find evidence of wrongdoing by Tramiel or Kapp. The scandal left Commodore in a worse financial position as it had borrowed heavily from Atlantic to purchase Wilson, and the loan was called in. Due to the financial scandal, Tramiel could only secure a bridge loan by paying interest well above the prime rate and putting the German factory up as collateral. Tramiel worked with a financier named Irving Gould to extricate himself, who brokered a deal to sell Wilson Stationers to an American company. Commodore now owed Gould money and still did not have sufficient capital to meet its payments, so Tramiel sold 17.9% of the company to Gould in 1966 for $ (equivalent to $ in 2024). As part of the deal, Gould became the company's new chairman.\nTramiel saw some of the first electronic calculators through his Japanese contacts in the late 1960s. He pivoted from adding machines to marketing calculators produced by companies like Casio under the Commodore brand name. In 1969, Commodore began manufacturing its electronic calculators. Commodore soon had a profitable calculator line and was one of the more popular brands in the early 1970s, producing both consumer and scientific/programmable calculators. However, in 1975, Texas Instruments, the leading supplier of calculator parts, entered the market directly and put out a line of machines priced at less than Commodore's cost for the parts. Commodore obtained an infusion of cash from Gould, which Tramiel used beginning in 1976 to purchase several second-source chip suppliers, including MOS Technology, Inc., to assure his supply.\nIn 1976, Commodore Business Machines (Canada) Ltd. was dissolved and replaced by the newly formed Bahamanian corporation Commodore International, which became the new parent of the Commodore group of companies.\nEntry into the computer market and success (1977\u20131984).\nChuck Peddle convinced Jack Tramiel that calculators were a dead end business and that they should turn their attention to home computers. Peddle packaged his single-board computer design in a metal case, initially with a keyboard using calculator keys, later with a full-travel QWERTY keyboard, monochrome monitor, and tape recorder for program and data storage, to produce the Commodore PET (Personal Electronic Transactor). From PET's 1977 debut, Commodore was primarily a computer company.\nCommodore had been reorganized the year before into Commodore International, Ltd., moving its financial headquarters to the Bahamas and its operational base to West Chester, Pennsylvania, near the MOS Technology site. The operational headquarters, where research and development of new products occurred, retained the name Commodore Business Machines, Inc. In 1980, Commodore launched production for the European market in Braunschweig, Germany. This site once employed up to 2000 employees, and in February 2017 an exhibition room for about 200 Commodore products was opened here to commemorate its past.\nBy 1980, Commodore was one of the three largest microcomputer companies and the largest in the Common Market. The company had lost its early domestic-market sales leadership, however by mid-1981 its US market share was less than 5% and US computer magazines rarely discussed Commodore products. \"BYTE\" stated \"the lack of a marketing strategy by Commodore, as well as its past nonchalant attitude toward the encouragement and development of good software, has hurt its credibility, especially in comparison to the other systems on the market\". Writing for \"Programming the PET/CBM\", Raeto Collin West wrote \"CBM's product manuals are widely recognized to be unhelpful; this is one of the reasons for the existence of this book.\"\nCommodore re-emphasized the US market with the VIC-20. The PET computer line was used primarily in schools, where its tough all-metal construction and ability to share printers and disk drives on a simple local area network were advantages, but PETs did not compete well in the home setting where graphics and sound were important. This was addressed with the VIC-20 in 1981, which was introduced at a cost of US$ (equivalent to $ in 2024) and sold in retail stores. Commodore bought aggressive advertisements featuring William Shatner asking consumers, \"Why buy just a video game?\" The strategy worked, and the VIC-20 became the first computer to ship more than one million units, with 2.5 million units sold over the machine's lifetime, which helped Commodore's sales in Canadian schools. In promotions aimed at schools and to reduce unsold inventory, PET models labeled 'Teacher's PET' were given away as part of a \"buy 2 get 1 free\" promotion. As of calendar year 1980, Commodore sales were $40 million, behind Apple Computer and Tandy Corporation in the market.\nIn 1982, Commodore introduced the Commodore 64 (C64) as the successor to the VIC-20. Due to its chips designed by MOS Technology, the C64 possessed advanced sound and graphics for its time, and is often credited with starting the computer demo scene. Its US$ (equivalent to $ in 2024) price was high compared to that of the VIC-20 but was much less expensive than any other 64K computer. Early C64 advertisements boasted that \"You can't buy a better computer at twice the price\", with Australian adverts in the mid-1980s using the slogan \"Are you keeping up with the Commodore? Because the Commodore is keeping up with you.\"\nIn 1983, Tramiel decided to focus on market share and cut the price of the VIC-20 and C64 dramatically, starting the home computer war. TI responded by cutting prices on its 1981 TI-99/4A, leading to a price war involving most vendors other than Apple Computer, including Commodore, TI and Atari. Commodore began selling the VIC-20 and C64 through mass-market retailers such as K-Mart, in addition to traditional computer stores. By the end of this conflict, Commodore had shipped around 22 million C64s, making the C64 the best-selling computer, until the Raspberry Pi overtook it in 2019.\nAt the June 1983 Consumer Electronics Show, Commodore lowered the retail price of the C64 to $, and stores sold it for as little as $. At one point, the company was selling as many computers as the rest of the industry combined. Prices for the VIC-20 and C64 were $50 lower than Atari's prices for the 600XL and 800XL. Commodore's strategy was to, according to a spokesman, devote 50% of its efforts to the under-$ market, 30% on the market, and 20% on the over-$ market. Its vertical integration and Tramiel's focus on cost control helped Commodore do well during the price war, with $ in 1983 sales. Although the company and Tramiel's focus on cost cutting over product testing caused hardware defects in the initial C64, some resolved in later iterations. By early 1984, Synapse Software, the largest provider of third-party Atari 8-bit software, received 65% of sales from the Commodore market, and Commodore sold almost three times as many computers as Atari that year.\nDespite its focus on the lower end of the market, Commodore's computers were also sold in upmarket department stores such as Harrods. The company also attracted several high-profile customers. In 1984, the company's British branch became the first manufacturer to receive a royal warrant for computer business systems. NASA's Kennedy Space Center was another noted customer, with over 60 Commodore systems processing documentation, tracking equipment and employees, costing jobs, and ensuring the safety of hazardous waste.\nDeparture of Tramiel, acquisition of Amiga and competition with Atari (1984\u20131987).\nBy early 1984, Commodore was the most successful home computer company, with more than $ (equivalent to $ in 2024) in annual revenue and $ (equivalent to $ in 2024) in net income, whilst competitors had large losses. The company's revenue of $425 million in the fourth calendar quarter of 1983 more than doubled its revenue of $ a year earlier. Although \"Creative Computing\" compared the company to \"a well-armed battleship [which] rules the micro waves\" and threatened to destroy rivals like Atari and Coleco, Commodore's board of directors, affected by the price spiral, decided to exit the company. In January 1984, an internal power struggle resulted after Tramiel resigned due to disagreements with the board chairman, Irving Gould. Gould replaced Tramiel with Marshall F. Smith, a steel executive without a computer or consumer marketing experience. Tramiel's departure at the moment of Commodore's greatest financial success surprised the industry.\nIn May 1984, Tramiel founded a new company, Tramel Technology, and hired several Commodore engineers to begin work on a next-generation computer design. That same year, Tramiel discovered Warner Communications wanted to sell Atari, which was rumored to be losing about $ a day. Interested in Atari's overseas manufacturing and worldwide distribution network for a new computer, he approached Atari and entered negotiations. After several talks with Atari in May and June 1984, Tramiel had secured funding and bought Atari's Consumer Division (which included the console and home computer departments) in July. In July 1984 Tramiel bought the consumer side of Atari Inc. from Warner Communications and released the Atari ST earlier in 1985 for about $. As more executives and researchers left Commodore after the announcement to join Tramiel's new company Atari Corp., Commodore followed by filing lawsuits against four former engineers for theft of trade secrets in late July. This was intended, in effect, to bar Tramiel from releasing his new computer. One of Tramiel's first acts after forming Atari Corp. was to fire most of Atari's remaining staff and to cancel almost all ongoing projects to review their continued viability. In late July to early August, Tramiel representatives discovered the original Amiga contract from the previous fall. Seeing a chance to gain some leverage, Tramiel immediately used the agreement to counter-sue Commodore on August 13.\nThe remaining Commodore management sought to salvage the company's fortunes and plan for the future, and did so by buying a small startup company called Amiga Corporation in August 1984 for $ ($ in cash and $550,000 in common shares). Amiga became a subsidiary of Commodore, called Commodore-Amiga, Inc. During development in 1981, Amiga had exhausted venture capital and needed more financing. Jay Miner and his company had approached their former employer, the Warner-owned Atari, who paid Amiga to continue development work. In return, Atari received the exclusive use of the design as a video game console for one year, after which Atari would have the right to add a keyboard and market it as a complete Amiga computer. The Atari-Amiga contract and engineering logs identify the Atari-Amiga product was designated as the 1850XLD. As Atari was heavily involved with Disney at the time, it was later code-named \"Mickey\", and the 256K memory expansion board was codenamed \"Minnie\".\nStill suffering serious financial problems, Amiga sought more monetary support from investors that entire spring. At around the same time that Tramiel was negotiating with Atari, Amiga entered into discussions with Commodore. The discussions ultimately led to Commodore's intentions to purchase Amiga outright, which Commodore viewed would cancel any outstanding contracts\u00a0\u2013 including Atari Inc.'s. Tramiel counter-sued on the basis of this interpretation, and sought damages and an injunction to bar Amiga and effectively Commodore from producing any resembling technology, to render Commodore's new acquisition and the source for its next generation of computers useless. The resulting court case lasted several years.\nCommodore introduced a new 32-bit computer design to market in the fall of 1985 named the Amiga 1000 for US$, first demonstrated at the CES in 1984. An Atari-Commodore rivalry continued throughout the life of the ST and Amiga platforms. While the rivalry was a holdover from the competition between the C64 and Atari 800, the events leading to the launch of the ST and Amiga served to further alienate fans of each computer, who disagreed as to which platform was superior. This was reflected in sales numbers for the two platforms until the release of the Amiga 500 in 1987, which led the Amiga sales to exceed the ST by about 1.5 to 1, despite reaching the market later. However, neither platform captured a significant share of the world computer market, with only the Apple Macintosh surviving the industry-wide shift to Intel-based x86 computers using Microsoft Windows.\nCommodore and Atari both sought to compete in the workstation market, with Commodore announcing in 1988 a Transputer-driven system based on the Amiga 2000 in response to the Atari Transputer Workstation. Similarly, a Unix workstation based on the Amiga 2000, featuring the 68020 CPU, was detailed as Atari announced developer shipments of its own 68030-based Unix workstation within a claimed \"to or three months\". Atari's workstation, the TT030, eventually arrived in 1990 without a version of Unix available, this only eventually becoming available to developers in late 1991. Commodore's workstation arrived in 1990 in the form of the Amiga 3000UX.\nDecline and later years (1987\u20131994).\nCommodore suffered a poor reputation with its dealers and customers, and upon the 1987 introduction of the Amiga 2000, Commodore retreated from its earlier strategy of selling its computers to discount outlets and toy stores and favored authorized dealers. Adam Osborne stated in April 1981 that \"the microcomputer industry abounds with horror stories describing the way Commodore treats its dealers and its customers.\" Commodore under Tramiel had a reputation for cannibalizing its own products with newer ones; Doug Carlston and others in the industry believed rumors in late 1983 that Commodore would discontinue the C64 despite its success because they disliked the company's business practices, including its poor treatment of dealers and introducing new computers incompatible with existing ones. A Boston reseller said, \"It's too unsettling to be one of their dealers and not know where you stand with them.\" After Tramiel's departure, another journalist wrote that he \"had never been able to establish excellent relations with computer dealers ... computer retailers have accused Commodore of treating them as harshly as if they were suppliers or competitors, and as a result, many have become disenchanted with Commodore and dropped the product line\". Software developers also disliked the company, with one stating that \"Dealing with Commodore was like dealing with Attila the Hun.\" At the 1987 Comdex, an informal \"InfoWorld\" survey found that none of the developers present planned to write for Commodore platforms. Commodore's software had a poor reputation; \"InfoWorld\" in 1984, for example, stated that \"so far, the normal standard for Commodore software is mediocrity\".\nCommodore almost went bankrupt in early 1986, obtaining a one-month extension on repaying $192 million in loans that it had defaulted on in June 1985. Tramiel's successor, Marshall F. Smith, left the company in 1986, as did his successor Thomas Rattigan in 1987 after a failed boardroom coup. The head of Blue Chip Electronics, a former Commodore employee, described the company as \"a well-known revolving door\". Commodore faced the problem when marketing the Amiga of still being seen as the company that made cheap computers like the C64 and VIC. The C64 remained the company's cash cow but its technology was aging. By the late 1980s, the personal computer market had become dominated by the IBM PC and Apple Macintosh platforms. Commodore's marketing efforts for the Amiga were less successful in breaking the new computer into an established market compared to the success of its 8-bit line. The company put effort into developing and promoting consumer products that would not be in demand for years, such as an Amiga 500-based HTPC called CDTV.\nAs early as 1986, the mainstream press was predicting Commodore's demise, and in 1990 \"Computer Gaming World\" wrote of its \"abysmal record of customer and technical support in the past\". Nevertheless, as profits and the stock price began to slide, \"The Philadelphia Inquirer's\" Top 100 Businesses Annual continued to list several Commodore executives among the highest-paid in the region and the paper documented the company's questionable hiring practices and large bonuses paid to executives amid shareholder discontent.\nCommodore failed to update the Amiga to keep pace as the PC platform advanced. CBM continued selling the Amiga 2000 with 7.14\u00a0MHz 68000 CPUs, even though the Amiga 3000 with its 25\u00a0MHz 68030 was on the market. Apple, by this time, was using the 68040 and had relegated the 68000 to its lowest-end model, the black and white Macintosh Classic. The 68000 was used in the Sega Genesis, one of the leading game consoles of the era, Computers fitted with high-color VGA graphics cards and SoundBlaster (or compatible) sound cards had also caught up with the Amiga's performance, and Commodore began to fade from the consumer market.\nAlthough the Amiga was originally conceived as a gaming machine, Commodore had always emphasized the Amiga's potential for professional applications, but the Amiga's high-performance sound and graphics were irrelevant to MS-DOS-based routine business word-processing and data-processing requirements, and the machine could not successfully compete with computers in a business market that was rapidly undergoing commoditization. Commodore introduced a range of PC compatible systems designed by its German division, and while the Commodore name was better known in the US than some of its competition, the systems' price and specifications were only average.\nSales of the PC range were strong in Germany, however, seeing Commodore acquire a 28% share of this market segment in 1990, second only to IBM. Things were less rosy in the United States, where Commodore had a 6% share in the market segment as of 1989, down from 26% in 1984. \"Forbes\"'s Evan McGlinn wrote regarding the firm's decline, citing management as the source cause: \"the absentee-landlord management style of globe-trotting chairman and chief executive Irving Gould.\" With the Amiga only representing less than 20% of the company's sales in the 1987 fiscal year, product lines such as PC-compatibles and Commodore's 8-bit computers remained important to the company's finances even as the Amiga's share of total sales increased. In 1989, with the Amiga accounting for 45% of total sales, the PC business showed modest growth to 24% of total sales, and the Commodore 64 and 128 products still generated 31% of the company's revenues.\nCommodore attempted to develop new chipsets during the early 1990s, first the Advanced Amiga Architecture and later the Hombre. Funding problems meant that they did not materialize as ultimately the company would go bust. In 1992, the Amiga 600 replaced the Amiga 500, which removed the numeric keypad, Zorro expansion slot, and other functionality, but added IDE, PCMCIA, and intended as a cost-reduced design. Designed as the Amiga 300, a non-expandable model to sell for less than the Amiga 500, the 600 became a replacement for the 500 due to the unexpectedly higher cost of manufacture. Productivity developers increasingly moved to PC and Macintosh, while the console wars took over the gaming market. David Pleasance, managing director of Commodore UK, described the Amiga 600 as a \"complete and utter screw-up\". In the same year, Commodore released the Amiga 1200 and Amiga 4000 computers, which featured an improved graphics chipset, the AGA. The advent of PC games using 3D graphics such as \"Doom\" and \"Wolfenstein 3D\" spelled the end of Amiga as a gaming platform.\nIn 1993, Commodore launched a 32-bit CD-ROM-based game console called the Amiga CD32, described as a 'make or break' system, according to Pleasance. The Amiga CD32 was not sufficiently profitable to return Commodore to solvency, however this was not a universal opinion at Commodore, with Commodore Germany hardware expert Rainer Benda stating \"The CD32 was a year late for Commodore. In other words, here, too, it might have been better to focus on the core business than jump on a console and hope to sell 300,000 or more units quickly to avoid bankruptcy.\"\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\n\"Commodore's high point was the Amiga 1000 (1985). The Amiga was so far ahead of its time that almost nobody \u2013 including Commodore's marketing department \u2013 could fully articulate what it was all about. Today, it's obvious the Amiga was the first multimedia computer. Still, in those days, it was derided as a game machine because few people grasped the importance of advanced graphics, sound, and video. Nine years later, vendors are still struggling to make systems that work like 1985 Amigas.\"\n \u2014\u00a0\"Byte Magazine,\" August 1994\nIn 1992, all UK servicing and warranty repairs were outsourced to Wang Laboratories, which was replaced by ICL after failing to meet repair demand during the Christmas rush in 1992. Commodore International's Canadian subsidiary authorized 3D Microcomputers of Ontario to manufacture IBM PC clones with the Commodore brand in late 1993. Commodore exited the IBM PC clone market entirely during the 1993 fiscal year, citing the low profitability of this market. PC sales had remained relatively stable and, accounting for 37% of revenue from sales in 1993, had grown modestly as declines in both unit sales and revenues were recorded for the Amiga and Commodore 64 product lines.\nBy 1994, only Commodore's operations in Canada, Germany, and the United Kingdom were still profitable. Commodore announced voluntary bankruptcy and liquidation on April 29, 1994, causing the board of directors to \"authorize the transfer of its assets to trustees for the benefit of its creditors\", according to an official statement. With Commodore International having reported a $8.2 million quarterly loss in the US, hopes were expressed that European divisions might be able to continue trading and even survive the demise of the parent company, with a management buyout considered a possibility. Other possibilities included the sale of profitable parts of the company to other parties, with Philips and Samsung considered \"likely choices\". However, no sale was ever completed.\nPost-bankruptcy.\nSale to Escom and bankruptcy.\nCommodore's former assets went separate ways following liquidation, with none of the descendant companies repeating Commodore's early success. Subsidiaries Commodore UK and Commodore B.V. (Netherlands) survived bankruptcy. The UK division filed a buyout proposal to the Supreme Court in the Bahamas and was considered the front runner in the bid due to press exposure at the time; the other initial bidders were Samsung, Philips and Amstrad in mid-1994. Commodore UK and Commodore BV stayed in business by selling old inventory and making computer speakers and other types of computer peripherals, however Commodore BV dissolved in early 1995. Commodore UK withdrew its bid at the start of the auction process after several larger companies, including Gateway Computers and Dell Inc., became interested, primarily for Commodore's patents relating to the Amiga. The only companies who entered bids at the end were Dell and Escom; the successful bidder was German PC maker Escom AG on April 22, 1995, beating Dell's bid by $6.6 million. Escom paid US$14 million for the assets of Commodore International. Commodore UK went into liquidation on August 30, 1995.\nEscom separated the Commodore and Amiga operations into separate divisions, the latter becoming Amiga Technologies GmbH, and quickly started using the Commodore brand name on a line of PCs sold in Europe while concepting and developing new Amiga computers. They also debuted a brand new logo for Amiga. By the late 1995, they had established a distribution network that included an American branch covering the USA and Canada, a French branch covering France, a British branch covering the UK, South Africa and India, a Belgian branch covering Belgium and Luxembourg, a German branch covering Germany and Poland, a Czech branch covering the Czech Republic and Slovakia, a Danish branch covering the five Scandinavian countries, a Swiss branch covering Switzerland, Austria, Italy, Malta, Turkey, Greece, the Balkans and the former USSR countries, a Middle Eastern branch covering the Middle East (excluding Israel, Cyprus), Libya and Morocco, and an Iberian branch covering Portugal, Spain and Africa (excluding South Africa, Libya, Morocco, Eswatini and Lesotho). However, it soon started losing money due to over-expansion, declared bankruptcy on July 15, 1996, and was liquidated. Escom's Dutch arm, Escom B.V., survived bankruptcy and went on to purchase the Commodore brand from its bankrupt parent. The company then renamed itself to Commodore B.V. Meanwhile, a deal for Chicago-based VisCorp to purchase Amiga Technologies GmbH fell through, and instead it was acquired by Gateway 2000 in March 1997, taking both the Amiga properties and the Commodore patents.\nBrand name.\nIn September 1997, Dutch computer maker Tulip Computers acquired the Commodore brand name from Commodore B.V. and made a number of Wintel computers under subsidiary Commodore International B.V., although it did not find much success. In July 2004, Tulip announced a new series of products using the Commodore name: fPET, a flash memory-based USB flash drive; mPET, a flash-based MP3 Player and digital recorder; eVIC, a 20 GB music player. Tulip also licensed the Commodore trademark and logo to the producers of the C64 DTV, a single-chip implementation of the Commodore 64 computer with 30 built-in games.\nIn late 2004, Tulip sold Commodore International B.V. to Yeahronimo Media Ventures (YMV), a digital music software startup providing legal music downloads in the Netherlands, for \u20ac22 million, to be paid in instalments over several years until 2010. The sale was completed in March 2005 after months of negotiations; YMV would not become the sole owner until 2010 after buying the remaining shares from Tulip (by then renamed to Nedfield Holding B.V.) which had gone bankrupt. YMV soon renamed itself to Commodore International Corporation (CIC) \u2014 its operational office was in the Netherlands but had headquarters in California \u2014 and started an operation intended to relaunch the Commodore brand in the video gaming field. The company then launched its Gravel line of products: Gravel in Pocket personal multimedia players equipped with Wi-Fi and the Gravel in Home, hoping the Commodore brand would help them take off, introduced at CeBIT 2007 with a media \"entertainment platform\" called CommodoreWorld, and also launched gaming PCs running Windows Vista 64-bit. However the company did not find success with these products. On June 24, 2009, CIC in the United States renamed itself to Reunite Investments, Inc., with the Commodore brand retaining under ownership by its subsidiary CIC Europe Holding B.V. (which would later be renamed into C= Holdings B.V.), trading as Commodore Consumer Electronics (CCE).\nCIC's founder, Ben van Wijhe, bought a Hong Kong-based company called Asiarim. Reunite Investments then sold the brand to Commodore Licensing B.V., a subsidiary of Asiarim, later in 2010. It was sold again on November 7, 2011. This transaction became the basis of a legal dispute between Asiarim \u2014 which, even after that date, made commercial use of the Commodore trademark, among others by advertising for sale Commodore-branded computers, and dealing licensing agreements for the trademarks \u2014 and the new owners, that was resolved by the United States District Court for the Southern District of New York on December 16, 2013, in favor of the new owners. Since then the company holding the brand name turned into Polabe Holding N.V., then Net B.V., and is currently named Commodore Corporation B.V.\nThe brand was acquired under license in 2010 by two young entrepreneurs to become Commodore USA in Florida, until 2013. On December 26, 2014, two Italian entrepreneurs licensed the brand and founded Commodore Business Machines Ltd. in London, to manufacture smartphones. The \"Commodore PET\", introduced in July 2015, was an Android smartphone with Commodore 64 and Amiga emulation built-in.\nOn June 9, 2025, a new Commodore International Corporation was incorporated in the state of Delaware by a group led by Christian \"Peri Fractic\" Simpson that acquired all trademarks, intellectual property and assets held by Commodore Corporation B.V. The new company is currently accepting preorders for an FPGA-based system called the Commodore 64 Ultimate that replicates the functionality of the Commodore 64 with a few modern enhancements.\nCopyrights and patents.\nOwnership of the remaining assets of Commodore International, including the copyrights and patents, and the Amiga trademarks, passed from bankrupt Escom to Gateway 2000 in 1997. Jim Collas became director of Amiga Technologies and he assembled a new team to work on a new generation of Amiga computers and other products on a new platform, prototyping one called the Amiga MCC and planning a potential tablet computer. However when Jeffrey Weitzen was chosen to become CEO of Gateway, who was not convinced of Collas's plans, he informed that Amiga Technologies division will be sold. On the final day of 1999, Gateway sold the copyrights and trademarks of Amiga to Amino, a Washington-based company founded, among others, by former Gateway subcontractors Bill McEwen and Fleecy Moss; Amino immediately renamed itself to Amiga, Inc. Gateway retained the patents but gave a license to Amiga, Inc. to use the patents. Gateway itself was acquired by Taiwanese Acer in 2007.\nOn March 15, 2004, Amiga, Inc. announced that on April 23, 2003, it had transferred its rights over past and future versions of the AmigaOS (but not yet over other intellectual property) to Itec, LLC, later acquired by KMOS, Inc., a Delaware-based company. Shortly afterwards, based on loans and security agreements between Amiga, Inc. and Itec, LLC, the remaining intellectual property assets were transferred from Amiga, Inc. to KMOS, Inc. On March 16, 2005, KMOS, Inc. announced that it had completed all registrations with the State of Delaware to change its corporate name to Amiga, Inc. The Commodore/Amiga copyrights, including all their works up to 1993, were later sold to Cloanto in 2015. A number of legal challenges and lawsuits have involved these companies and Hyperion Entertainment, the Belgian software company that continues development of AmigaOS. AmigaOS (as well as spin-offs MorphOS and AROS) is still maintained and updated by Hyperion Entertainment.\nSemiconductor subsidiary.\nThe Commodore Semiconductor Group (formerly MOS Technology, Inc.), the silicon wafer foundry and integrated circuit manufacturing unit of Commodore International, was bought by its former management in January 1995 and resumed operations under the name GMT Microelectronics, utilizing a troubled facility in Norristown, Pennsylvania that Commodore had closed in 1992. In 2001, the United States Environmental Protection Agency shut the plant down, and GMT ceased operations and was liquidated.\nSponsorship.\nCommodore sponsored the German football club Bayern Munich from 1984 until 1989, the English football club Chelsea from 1987 to 1994. and the French football clubs Auxerre from 1991 to 1992 and Paris Saint-Germain from 1991 to 1994.\nProduct line.\nThe product line consists of original Commodore products.\nCalculators.\n774D, 776M, 796M, 9R23, C108, C110, F4146R, F4902, MM3, Minuteman 6, P50, PR100, SR1800, SR4120D, SR4120R, SR4148D, SR4148R, SR4190R, SR4212, SR4912, SR4921RPN, SR5120D, SR5120R, SR5148D, SR5148R, SR5190R, SR59, SR7919, SR7949, SR9150R, SR9190R, US*3, US*8 and The Specialist series: M55 (The Mathematician), N60 (The Navigator), S61 (The Statistician).\n6502-based computers.\n\"(listed chronologically)\"\nMonitors.\n1000, 1024, 1070, 1080, 1081, 1083S, 1084, 1084S, 1084ST, 1085S, 1201, 1402, 1403, 1404, 1405, 1407, 1428, 1428x, 1432D, 1432V, 1701, 1702, 1703, 1801, 1802, 1803, 1900M/DM602, 1901/75BM13/M1, 1902, 1902A, 1930, 1930-II, 1930-III, 1934, 1935, 1936, 1936ALR, 1940, 1942, 1950, 1960, 1962, 2002, A2024, 2080, 76M13, CM-141, DM-14, DM602\nPrinters.\nVIC 1520 plotter.\nThe VIC 1520 plotter used the ALPS mechanicals and four-color rotary pen setup that scrolled a 4\u00bc\" roll of paper. The ALPS mechanism was shared with several other 8 bit computers of the era, including Tandy, Atari, and Apple.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "7581", "revid": "13370122", "url": "https://en.wikipedia.org/wiki?curid=7581", "title": "Commodore (rank)", "text": "Naval officer rank\nCommodore is a senior naval rank used in many navies which is equivalent to brigadier or brigadier general and air commodore. It is superior to a navy captain, but below a rear admiral. It is either regarded as the most junior of the flag officers rank or may not hold the jurisdiction of a flag officer at all depending on the officer's appointment. Non-English-speaking nations commonly use the rank of flotilla admiral, counter admiral, or senior captain as an equivalent, although counter admiral may also correspond to \"rear admiral lower half\" abbreviated as RDML.\nTraditionally, \"commodore\" is the title for any officer assigned to command more than one ship, even temporarily, much as \"captain\" is the traditional title for the commanding officer of a single ship even if the officer's official title in the service is a lower rank. As an official rank, a commodore typically commands a flotilla or squadron of ships as part of a larger task force or naval fleet commanded by an admiral. A commodore's ship is typically designated by the flying of a broad pennant, as compared to an admiral's flag.\n\"Commodore\" is typically regarded as a one-star rank with a NATO code of OF-6, known in the U.S. as \"rear admiral (lower half)\", but whether it is regarded as a flag rank varies among countries.\nIt is sometimes abbreviated as \"Cdre\" in British Royal Navy, \"CDRE\" in the US Navy, \"Cmdre\" in the Royal Canadian Navy, \"COMO\" in the Spanish Navy and in some navies speaking the Spanish language, or \"CMDE\" as used in the Indian Navy and in navies of several other countries.\nEtymology.\nThe rank of commodore derives from the French \"commandeur\", which was the second highest rank in the orders of knighthood, and in military orders the title of the knight in charge of a commandery.\nHistory.\nThe Dutch Navy also used the rank of \"commandeur\" from the end of the 16th century for a variety of temporary positions, until it became a conventional permanent rank in 1955. The Royal Netherlands Air Force has adopted the English spelling of \"commodore\" for an equivalent rank.\nIn the Royal Navy, the position was introduced in the 17th century to combat the cost of appointing more admirals\u2014a costly business with a fleet as large as the Royal Navy's at that time.\nThe rank of commodore was at first a position created as a temporary title to be bestowed upon captains who commanded squadrons of more than one vessel. In many navies, the rank of commodore was merely viewed as a senior captain position, whereas other naval services bestowed upon the rank of commodore the prestige of flag officer status.\nUnited States.\nIn 1899, the substantive rank of commodore was discontinued in the United States Navy, but revived during World War II in both the United States Navy and United States Coast Guard. It was discontinued as a rank in these services during the postwar period, but as an appointment, the title \"commodore\" was then used to identify senior U.S. Navy captains who commanded squadrons of more than one vessel or functional air wings or air groups that were not part of a carrier air wing or carrier air group. Concurrently, until the early 1980s, U.S. Navy and U.S. Coast Guard captains selected for promotion to the rank of rear admiral (lower half), would wear the same insignia as rear admiral (upper half), i.e., two silver stars for collar insignia or sleeve braid of one wide and one narrow gold stripe, even though they were actually only equivalent to one-star officers and paid at the one-star rate.\nTo correct this inequity, the rank of commodore as a single-star flag officer was reinstated by both services in the early 1980s. This immediately caused confusion with those senior U.S. Navy captains commanding destroyer squadrons, submarine squadrons, functional air wings and air groups, and so on, who held the temporary \"title\" of commodore while in their major command billet. As a result of this confusion, the services soon renamed the new one-star rank commodore admiral (CADM) within the first six months following the rank's reintroduction. However, this was considered an awkward title and the one-star flag rank was renamed a few months later, giving it its current title of rear admiral (lower half), later abbreviated by the U.S. Navy and U.S. Coast Guard as RDML. The United States Public Health Service Commissioned Corps, and NOAA Commissioned Corps, whose rank structures follow the naval pattern, also use this title and abbreviation.\nThe \"title\" of commodore continues to be used in the U.S. Navy and U.S. Coast Guard for those senior captains in command of organizations consisting of groups of ships or submarines organized into squadrons; air wings or air groups of multiple aviation squadrons other than carrier air wings (the latter whose commanders still use the title \"CAG\"); explosive ordnance disposal (EOD), mine warfare and special warfare (SEAL) groups; Mobile Inshore Underwater Warfare (MIUW) groups; and construction (SeaBee) regiments. Although not flag officers, modern day commodores in the U.S. Navy rate a blue and white command pennant, also known as a broad pennant, that is normally flown at their headquarters facilities ashore or from ships that they are embarked aboard when they are the Senior Officer Present Afloat (SOPA).\nArgentina.\nIn the Argentine Navy, the position of commodore was created in the late 1990s, and is usually, but not always, issued to senior captains holding rear-admirals' positions. It is not a rank but a distinction and, as such, can be issued by the chief of staff without congressional approval. Its equivalents are colonel-major in the Army and commodore-major in the Air Force. It is usually\u2014but incorrectly\u2014referred to as \"navy commodore\", to avoid confusion with the \"air force commodore\", which is equivalent to the navy's captain and army's colonel. The sleeve lace is identical to that of the Royal Navy, and wears one star on the epaulette.\nAir force ranks.\nCommodore, in Spanish \"comodoro\", is a rank in the Argentine Air Force. This rank is the equivalent of a colonel in the Argentine Army, and a colonel or group captain in other air forces of the world. The Argentine rank below commodore is the rank of vice-commodore (Spanish \"vicecomodoro\") equivalent to a lieutenant-colonel in the Argentine Army, and a lieutenant-colonel or wing commander in other air forces.\nCommodore is a rank in the Royal Netherlands Air Force. It is a one-star rank and has essentially the same rank insignia as the British air commodore.\nMany air forces use the rank of air commodore. This rank was first used by the Royal Air Force and is now used in many countries such as Australia, Bangladesh, Greece, India, New Zealand, Nigeria, Pakistan, Thailand and Zimbabwe. It is the equivalent rank to the navy rank of \"commodore\", and the army ranks of brigadier and brigadier general.\nThe German air force used the concept of a unit commodore for the commander of a wing, usually in the rank of colonel (OF-5).\nMerchant Service (Merchant Marine) rank and Yacht Club chief directors.\nCommodore is also a title held by many captains as recognition of exceptional navigation ability and seagoing seniority in the Merchant Service, and by the directors of a few yacht clubs and boating associations. Commodores 'in command' as Master aboard Merchant Marine ships wear distinctive rank and cap insignia denoting their honorific high rank position. In a few country the honorific high position of commodore it is indicated with the high rank denomination of senior captain. Traditionally, commodore is the title of the president of a yacht club.\nConvoy commodore.\nDuring wartime, a shipping convoy will have a ranking officer\u2014sometimes an active-duty naval officer, at other times a civilian master or retired naval officer\u2014designated as the \"convoy commodore\". This title is not related to the individual's military rank (if any), but instead is the title of the senior individual responsible for the overall operation of the merchant ships and naval auxiliary ships that make up the convoy. The convoy commodore does not command the convoy' escort forces (if any), which are commanded by a naval officer who serves as escort commander.\nCivilian use.\nCommodore in Yachting Leadership.\nCivilian yacht clubs, yachting associations and fellowships with formal hierarchical structures, began to use the title \"commodore\" in countries around the world for their presidents in the early twentieth century along with \"vice commodore\" in the same manner as \"vice president,\"and \"rear-commodore\" and \"port captain' or \"international bridge member\" in the same manner as board members.\nCommodores, vice-commodores and rear-commodores are also known as civilian flag officers because they have an epaulettes, regalia and maritime flags with designated symbols and number of stars for their ranks. Many of the clubs that are more than a century old, such as the Los Angeles Yacht Club have formal ceremonies, where commodores from more than 100 surrounding yacht clubs, flag officers of the US Navy and Coast Guard attend a ceremony at the beginning of the year. The ceremony includes a bagpipe entrance, a presentation of the country flag by commissioned officers of the country's navy and a cannon shot upon the raising of each individual officer's flags on a flag staff, (also known as flagpoles) for each flag officer (commodore, vice commodore, rear commodore) as their term of office officially begins. Sometimes a trumpet fanfare is also include for special occasions like ribbon cutting in 2019 for the 50th Transpacific Yacht Race. Salutes are given to commodores for special ceremonies, including opening days of the racing season.\nOther uses.\nThe U.S. Coast Guard Auxiliary also employs variants of the \"title\" of commodore. Members of the Auxiliary serve in the Coast Guard's uniformed auxiliary service and they do not have military rank, but who do wear modified U.S. Coast Guard uniforms and U.S. military-style officer rank insignia to indicate office. Auxiliary members who have been elected or appointed to positions in the highest levels of the organization, similar in nature to active and reserve rear admirals and vice admirals use the term commodore (e.g., district commodore, assistant national commodore, deputy national commodore, national commodore, etc.). These Coast Guard auxiliarists may permanently append the title commodore, sometimes abbreviated COMO, to their names (e.g., Commodore James A. Smith, National Commodore; or COMO Jim Smith, (NACO)).\nIn the Philippine Coast Guard Auxiliary\u2014PCGA\u2014each of the directors in command of the ten Coast Guard Auxiliary districts are commodores, as well as most of the Deputy National Directors (some may be rear admirals). Commodore is abbreviated to COMMO in the PCGA.\nVanderbilt University's intercollegiate athletics teams are nicknamed the \"Commodores\", a reference to Cornelius Vanderbilt's self-appointed title (he was the master of a large shipping fleet).\nIn the U.S. Sea Scouting program (which is part of the Boy Scouts of America), all National, Regional, Area, and Council committee chairs are titled as commodore, while senior committee members are addressed as vice commodore. Ship committee chairs do not hold this recognition.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "7582", "revid": "698909", "url": "https://en.wikipedia.org/wiki?curid=7582", "title": "Chlorinated fluorocarbons", "text": ""}
{"id": "7583", "revid": "46264695", "url": "https://en.wikipedia.org/wiki?curid=7583", "title": "Cauchy\u2013Riemann equations", "text": "Characteristic property of holomorphic functions\nIn the field of complex analysis in mathematics, the Cauchy\u2013Riemann equations, named after Augustin Cauchy and Bernhard Riemann, consist of a system of two partial differential equations which form a necessary and sufficient condition for a complex function of a complex variable to be complex differentiable. \nThese equations are \n&lt;templatestyles src=\"Numbered block/styles.css\" /&gt;\nand\n&lt;templatestyles src=\"Numbered block/styles.css\" /&gt;\nwhere \"u\"(\"x\", \"y\") and \"v\"(\"x\", \"y\") are real bivariate differentiable functions.\nTypically, \"u\" and \"v\" are respectively the real and imaginary parts of a complex-valued function \"f\"(\"x\" + \"iy\") = \"f\"(\"x\", \"y\") = \"u\"(\"x\", \"y\") + \"iv\"(\"x\", \"y\") of a single complex variable \"z\" = \"x\" + \"iy\" where \"x\" and \"y\" are real variables; \"u\" and \"v\" are real differentiable functions of the real variables. Then \"f\" is complex differentiable at a complex point if and only if the partial derivatives of \"u\" and \"v\" satisfy the Cauchy\u2013Riemann equations at that point.\nA holomorphic function is a complex function that is differentiable at every point of some open subset of the complex plane formula_1. It has been proved that holomorphic functions are analytic and analytic complex functions are complex-differentiable. In particular, holomorphic functions are infinitely complex-differentiable.\nThis equivalence between differentiability and analyticity is the starting point of all complex analysis.\nHistory.\nThe Cauchy\u2013Riemann equations first appeared in the work of Jean le Rond d'Alembert. Later, Leonhard Euler connected this system to the analytic functions. Cauchy then used these equations to construct his theory of functions. Riemann's dissertation on the theory of functions appeared in 1851.\nSimple example.\nSuppose that formula_2. The complex-valued function formula_3 is differentiable at any point z in the complex plane. \nformula_4\nThe real part formula_5 and the imaginary part formula_6 are\nformula_7\nand their partial derivatives are\nformula_8\nWe see that indeed the Cauchy\u2013Riemann equations are satisfied, formula_9 and formula_10.\nInterpretation and reformulation.\nThe Cauchy-Riemann equations are one way of looking at the condition for a function to be differentiable in the sense of complex analysis: in other words, they encapsulate the notion of function of a complex variable by means of conventional differential calculus. In the theory there are several other major ways of looking at this notion, and the translation of the condition into other language is often needed.\nConformal mappings.\nFirst, the Cauchy\u2013Riemann equations may be written in complex form\n&lt;templatestyles src=\"Numbered block/styles.css\" /&gt;\nIn this form, the equations correspond structurally to the condition that the Jacobian matrix is of the form\nformula_11\nwhere formula_12 and formula_13. A matrix of this form is the matrix representation of a complex number. Geometrically, such a matrix is always the composition of a rotation with a scaling, and in particular preserves angles. The Jacobian of a function \"f\"(\"z\") takes infinitesimal line segments at the intersection of two curves in \"z\" and rotates them to the corresponding segments in \"f\"(\"z\"). Consequently, a function satisfying the Cauchy\u2013Riemann equations, with a nonzero derivative, preserves the angle between curves in the plane. That is, the Cauchy\u2013Riemann equations are the conditions for a function to be conformal.\nMoreover, because the composition of a conformal transformation with another conformal transformation is also conformal, the composition of a solution of the Cauchy\u2013Riemann equations with a conformal map must itself solve the Cauchy\u2013Riemann equations. Thus the Cauchy\u2013Riemann equations are conformally invariant.\nComplex differentiability.\nLet\nformula_14\nwhere formula_15 and formula_16 are real-valued functions, be a complex-valued function of a complex variable formula_17 where formula_18 and formula_19 are real variables. formula_20 so the function can also be regarded as a function of real variables formula_21 and formula_19. Then, the \"complex-derivative\" of formula_23 at a point formula_24 is defined by\nformula_25\nprovided this limit exists (that is, the limit exists along every path approaching formula_26, and does not depend on the chosen path).\nA fundamental result of complex analysis is that formula_27 is complex differentiable at formula_28 (that is, it has a complex-derivative), if and only if the bivariate real functions formula_29 and formula_30 are differentiable at formula_31 and satisfy the Cauchy\u2013Riemann equations at this point.\nIn fact, if the complex derivative exists at formula_32, then it may be computed by taking the limit at formula_32 along the real axis and the imaginary axis, and the two limits must be equal. Along the real axis, the limit is \nformula_34\nand along the imaginary axis, the limit is\nformula_35\nSo, the equality of the derivatives implies \nformula_36\nwhich is the complex form of Cauchy\u2013Riemann equations (2) at formula_32.\nConversely, if f is differentiable at formula_26 (in the real sense) and satisfies the Cauchy-Riemann equations there, then it is complex-differentiable at this point. Assume that f as a function of two real variables x and y is differentiable at \"z\"0 (real differentiable). This is equivalent to the existence of the following linear approximation formula_47where formula_48, formula_49, \"z\" = \"x\" + \"iy\", and formula_50 as \u0394\"z\" \u2192 0. \nSince formula_51 and formula_52, the above can be re-written as\nformula_53formula_54 \nNow, if formula_55 is real, formula_56, while if it is imaginary, then formula_57. Therefore, the second term is independent of the path of the limit formula_58 when (and only when) it vanishes identically: formula_59, which is precisely the Cauchy\u2013Riemann equations in the complex form. This proof also shows that, in that case,\nformula_60\nNote that the hypothesis of real differentiability at the point formula_28 is essential and cannot be dispensed with. For example, the function formula_62, regarded as a complex function with imaginary part identically zero, has both partial derivatives at formula_63, and it moreover satisfies the Cauchy\u2013Riemann equations at that point, but it is not differentiable in the sense of real functions (of several variables), and so the first condition, that of real differentiability, is not met. Therefore, this function is not complex differentiable.\nSome sources state a sufficient condition for the complex differentiability at a point formula_28 as, in addition to the Cauchy\u2013Riemann equations, the partial derivatives of formula_65 and formula_16 be continuous at the point because this continuity condition ensures the existence of the aforementioned linear approximation. Note that it is not a necessary condition for the complex differentiability. For example, the function formula_67 is complex differentiable at 0, but its real and imaginary parts have discontinuous partial derivatives there. Since complex differentiability is usually considered in an open set, where it in fact implies continuity of all partial derivatives (see below), this distinction is often elided in the literature.\nIndependence of the complex conjugate.\nThe above proof suggests another interpretation of the Cauchy\u2013Riemann equations. The complex conjugate of formula_68, denoted formula_69, is defined by\nformula_70\nfor real variables \"formula_71\" and formula_72. Defining the two Wirtinger derivatives asformula_73\nthe Cauchy\u2013Riemann equations can then be written as a single equation\nformula_74\nand the complex derivative of \"formula_75\" in that case is formula_76 In this form, the Cauchy\u2013Riemann equations can be interpreted as the statement that a complex function \"formula_75\" of a complex variable \"formula_78\" is independent of the variable formula_69. As such, we can view analytic functions as true functions of \"one\" complex variable (\"formula_78\") instead of complex functions of \"two\" real variables (\"formula_21\" and \"formula_82\").\nPhysical interpretation.\nA standard physical interpretation of the Cauchy\u2013Riemann equations going back to Riemann's work on function theory is that \"u\" represents a velocity potential of an incompressible steady fluid flow in the plane, and \"v\" is its stream function. Suppose that the pair of (twice continuously differentiable) functions \"u\" and \"v\" satisfies the Cauchy\u2013Riemann equations. We will take \"u\" to be a velocity potential, meaning that we imagine a flow of fluid in the plane such that the velocity vector of the fluid at each point of the plane is equal to the gradient of \"u\", defined by\nformula_83\nBy differentiating the Cauchy\u2013Riemann equations for the functions \"u\" and \"v\", with the symmetry of second derivatives, one shows that \"u\" solves Laplace's equation:\nformula_84\nThat is, \"u\" is a harmonic function. This means that the divergence of the gradient is zero, and so the fluid is incompressible.\nThe function \"v\" also satisfies the Laplace equation, by a similar analysis. Also, the Cauchy\u2013Riemann equations imply that the dot product formula_85 (formula_86), i.e., the direction of the maximum slope of \"u\" and that of \"v\" are orthogonal to each other. This implies that the gradient of \"u\" must point along the formula_87 curves; so these are the streamlines of the flow. The formula_88 curves are the equipotential curves of the flow.\nA holomorphic function can therefore be visualized by plotting the two families of level curves formula_89 and formula_90. Near points where the gradient of \"u\" (or, equivalently, \"v\") is not zero, these families form an orthogonal family of curves. At the points where formula_91, the stationary points of the flow, the equipotential curves of formula_89 intersect. The streamlines also intersect at the same point, bisecting the angles formed by the equipotential curves.\nHarmonic vector field.\nAnother interpretation of the Cauchy\u2013Riemann equations can be found in P\u00f3lya &amp; Szeg\u0151. Suppose that \"u\" and \"v\" satisfy the Cauchy\u2013Riemann equations in an open subset of R2, and consider the vector field\nformula_93\nregarded as a (real) two-component vector. Then the second Cauchy\u2013Riemann equation (1b) asserts that formula_94 is irrotational (its curl is 0):\nformula_95\nThe first Cauchy\u2013Riemann equation (1a) asserts that the vector field is solenoidal (or divergence-free):\nformula_96\nOwing respectively to Green's theorem and the divergence theorem, such a field is necessarily a conservative one, and it is free from sources or sinks, having net flux equal to zero through any open domain without holes. (These two observations combine as real and imaginary parts in Cauchy's integral theorem.) In fluid dynamics, such a vector field is a potential flow. In magnetostatics, such vector fields model static magnetic fields on a region of the plane containing no current. In electrostatics, they model static electric fields in a region of the plane containing no electric charge.\nThis interpretation can equivalently be restated in the language of differential forms. The pair \"u\" and \"v\" satisfy the Cauchy\u2013Riemann equations if and only if the one-form formula_97 is both closed and coclosed (a harmonic differential form).\nPreservation of complex structure.\nAnother formulation of the Cauchy\u2013Riemann equations involves the complex structure in the plane, given by\nformula_98\nThis is a complex structure in the sense that the square of \"J\" is the negative of the 2\u00d72 identity matrix: formula_99. As above, if \"u\"(\"x\",\"y\") and \"v\"(\"x\",\"y\") are two functions in the plane, put\nformula_100\nThe Jacobian matrix of \"f\" is the matrix of partial derivatives\nformula_101\nThen the pair of functions \"u\", \"v\" satisfies the Cauchy\u2013Riemann equations if and only if the 2\u00d72 matrix \"Df\" commutes with \"J\".\nThis interpretation is useful in symplectic geometry, where it is the starting point for the study of pseudoholomorphic curves.\nOther representations.\nOther representations of the Cauchy\u2013Riemann equations occasionally arise in other coordinate systems. If (1a) and (1b) hold for a differentiable pair of functions \"u\" and \"v\", then so do\nformula_102\nfor any coordinate system (\"n\"(\"x\", \"y\"), \"s\"(\"x\", \"y\")) such that the pair formula_103 is orthonormal and positively oriented. As a consequence, in particular, in the system of coordinates given by the polar representation formula_104, the equations then take the form\nformula_105\nCombining these into one equation for \"f\" gives\nformula_106\nThe inhomogeneous Cauchy\u2013Riemann equations consist of the two equations for a pair of unknown functions \"u\"(\"x\", \"y\") and \"v\"(\"x\", \"y\") of two real variables\nformula_107\nfor some given functions \u03b1(\"x\", \"y\") and \u03b2(\"x\", \"y\") defined in an open subset of R2. These equations are usually combined into a single equation\nformula_108\nwhere \"f\" = \"u\" + i\"v\" and \"\ud835\udf11\" = (\"\u03b1\" + i\"\u03b2\")/2.\nIf \"\ud835\udf11\" is \"C\"\"k\", then the inhomogeneous equation is explicitly solvable in any bounded domain \"D\", provided \"\ud835\udf11\" is continuous on the closure of \"D\". Indeed, by the Cauchy integral formula,\nformula_109\nfor all \"\u03b6\" \u2208 \"D\".\nGeneralizations.\nGoursat's theorem and its generalizations.\nSuppose that \"f\" = \"u\" + i\"v\" is a complex-valued function which is differentiable as a function formula_110. Then Goursat's theorem asserts that \"f\" is analytic in an open complex domain \u03a9 if and only if it satisfies the Cauchy\u2013Riemann equation in the domain. In particular, continuous differentiability of \"f\" need not be assumed.\nThe hypotheses of Goursat's theorem can be weakened significantly. If \"f\" = \"u\" + i\"v\" is continuous in an open set \u03a9 and the partial derivatives of \"f\" with respect to \"x\" and \"y\" exist in \u03a9, and satisfy the Cauchy\u2013Riemann equations throughout \u03a9, then \"f\" is holomorphic (and thus analytic). This result is the Looman\u2013Menchoff theorem.\nThe hypothesis that \"f\" obey the Cauchy\u2013Riemann equations throughout the domain \u03a9 is essential. It is possible to construct a continuous function satisfying the Cauchy\u2013Riemann equations at a point, but which is not analytic at the point (e.g., \"f\"(\"z\") = \"z\"5/|z|4). Similarly, some additional assumption is needed besides the Cauchy\u2013Riemann equations (such as continuity), as the following example illustrates\nformula_111\nwhich satisfies the Cauchy\u2013Riemann equations everywhere, but fails to be continuous at \"z\"\u00a0=\u00a00.\nNevertheless, if a function satisfies the Cauchy\u2013Riemann equations in an open set in a weak sense, then the function is analytic. More precisely:\n If \"f\"(\"z\") is locally integrable in an open domain formula_112 and satisfies the Cauchy\u2013Riemann equations weakly, then f agrees almost everywhere with an analytic function in \u03a9.\nThis is in fact a special case of a more general result on the regularity of solutions of hypoelliptic partial differential equations.\nSeveral variables.\nThere are Cauchy\u2013Riemann equations, appropriately generalized, in the theory of several complex variables. They form a significant overdetermined system of PDEs. This is done using a straightforward generalization of the Wirtinger derivative, where the function in question is required to have the (partial) Wirtinger derivative with respect to each complex variable vanish.\nComplex differential forms.\nAs often formulated, the \"d-bar operator\"\nformula_113\nannihilates holomorphic functions. This generalizes most directly the formulation\nformula_114\nwhere\nformula_115\nB\u00e4cklund transform.\nViewed as conjugate harmonic functions, the Cauchy\u2013Riemann equations are a simple example of a B\u00e4cklund transform. More complicated, generally non-linear B\u00e4cklund transforms, such as in the sine-Gordon equation, are of great interest in the theory of solitons and integrable systems.\nDefinition in Clifford algebra.\nIn the Clifford algebra formula_116, the complex number formula_117 is represented as formula_118 where formula_119, (formula_120, so formula_121). The Dirac operator in this Clifford algebra is defined as formula_122. The function formula_123 is considered analytic if and only if formula_124, which can be calculated in the following way:\nformula_125\nGrouping by formula_126 and formula_127:\nformula_128\nHence, in traditional notation:\nformula_129\nConformal mappings in higher dimensions.\nLet \u03a9 be an open set in the Euclidean space formula_130. The equation for an orientation-preserving mapping formula_131 to be a conformal mapping (that is, angle-preserving) is that\nformula_132\nwhere \"Df\" is the Jacobian matrix, with transpose formula_133, and \"I\" denotes the identity matrix. For \"n\" = 2, this system is equivalent to the standard Cauchy\u2013Riemann equations of complex variables, and the solutions are holomorphic functions. In dimension \"n\" &gt; 2, this is still sometimes called the Cauchy\u2013Riemann system, and Liouville's theorem implies, under suitable smoothness assumptions, that any such mapping is a M\u00f6bius transformation.\nLie pseudogroups.\nOne might seek to generalize the Cauchy-Riemann equations instead by asking more generally when are the solutions of a system of PDEs closed under composition. The theory of Lie Pseudogroups addresses these kinds of questions.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nSources.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "7585", "revid": "17209722", "url": "https://en.wikipedia.org/wiki?curid=7585", "title": "Chaim Topol", "text": "Israeli actor (1935\u20132023)\nChaim Topol (\u200e; 9 September 1935 \u2013 8 March 2023), mononymously known as Topol, was an Israeli actor and singer. He is best known for his portrayal of Tevye, the lead character in the stage musical \"Fiddler on the Roof\". Topol estimates that he has played Tevye more than 3,500 times on stage from 1967 through 2009, and he also portrays the character in the 1971 film adaptation of the play.\nTopol began acting during his Israeli army service as a member of the Nahal entertainment troupe. He later toured Israel with kibbutz theatre and satirical theatre companies. He was a co-founder of the Haifa Theatre. His breakthrough film role came in 1964 as the title character in \"Sallah Shabati\", by Israeli writer Ephraim Kishon, for which he won a Golden Globe for Most Promising Newcomer\u2014Male. Topol went on to appear in more than 30 films in Israel and the United States, including \"Galileo\" (1975), \"Flash Gordon\" (1980), and the \"James Bond\" franchise film \"For Your Eyes Only\" (1981). He was described as Israel's only internationally recognized entertainer from the 1960s through the 1980s. He won a Golden Globe for Best Actor and was nominated for an Academy Award for Best Actor for his 1971 film portrayal of Tevye, and was nominated for a Tony Award for Best Actor for a 1991 Broadway revival of \"Fiddler on the Roof\".\nTopol was a founder of Variety Israel, an organization serving children with special needs, and Jordan River Village, a year-round camp for Arab and Jewish children with life-threatening illnesses, for which he served as chairman of the board. In 2015 he was awarded the Israel Prize for lifetime achievement.\nBiography.\nChaim Topol was born on September 9, 1935, in Tel Aviv, in what was then Mandatory Palestine. His father Jacob Topol was born in Russia and in the early 1930s immigrated to Palestine, where he worked as a plasterer; he also served in the Haganah paramilitary organization. His mother Imrela \"Rel\" (n\u00e9e Goldman) Topol was a seamstress.\nTopol's parents had been members of the Betar Zionist youth movement in Warsaw. His father had Hasidic roots, with a mother coming from a family of Gerrer Hasidim and a father from Aleksander Hasidim.\nTopol and his two younger sisters grew up in the South Tel Aviv working-class neighborhood of Florentin. As a young child, although he wanted to become a commercial artist, his elementary school teacher, the writer Yemima Avidar-Tchernovitz, saw a theatrical side to him, and encouraged him to act in school plays and read stories to the class.\nAt age 14 he began working as a printer at \"Davar\" newspaper while pursuing his high school studies at night. He graduated at age 17 and moved to Kibbutz Geva. A year later, he enlisted in the Israeli army and became a member of the Nahal entertainment troupe, singing and acting in traveling shows. He rose in rank to troupe commander.\nTwenty-three days after being discharged from military service on October 2, 1956, and two days after marrying Galia Finkelstein, a fellow Nahal troupe member, Topol was called up for reserve duty in the Sinai Campaign. He performed for soldiers stationed in the desert.\nAfter the war, he and his wife settled in Kibbutz Mishmar David, where Topol worked as a garage mechanic. Topol assembled a kibbutz theatre company made up of friends from his Nahal troupe; the group toured four days a week, worked on their respective kibbutzim for two days a week, and had one day off. The theatre company was in existence from early 1957 to the mid-1960s. Topol both sang and acted with the group, doing both \"loudly\".\nTopol and his wife Galia Finkelstein had three children: a son, Omer, and two daughters, Anat and Adi. The couple resided in Galia's childhood home in Tel Aviv. Topol's hobbies included sketching and sculpting. Through Adi, his granddaughter Yali Topol Margalith is an actress.\nIn June 2022, Topol's son, Omer, revealed that his father was suffering from Alzheimer's disease.\nOn March 8, 2023, Topol's family notified the press that he was near death and \"living his final hours\", and asked the public to respect the family's privacy. He died overnight at the age of 87. The day before his burial at Kvutzat Shiller on March 10, a memorial was held at the Cameri Theater in Tel Aviv.\nSinging and acting career.\nBetween 1960 and 1964, Topol performed with the Batzal Yarok (\"Green Onion\") satirical theatre company, which also toured Israel. Other members of the group included Uri Zohar, Nechama Hendel, Zaharira Harifai, Arik Einstein, and Oded Kotler. In 1960, Topol co-founded the Haifa Municipal Theatre with Yosef Milo, serving as assistant to the director and acting in plays by Shakespeare, Ionesco, and Brecht. In 1965 he performed in the Cameri Theatre in Tel Aviv.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\nHaim Topol, then a young man and of Ashkenazi heritage, plays the old Sephardic manipulator with such consummate skill that even aged immigrants from Morocco and Tunisia were convinced that he was one of them.\n\u2013Tom Tugend on Topol's portrayal of \"Sallah Shabati\"\nTopol's first film appearance was in the 1961 film \"I Like Mike\", followed by the 1963 Israeli film \"El Dorado\". His breakthrough role came as the lead character in the 1964 film \"Sallah Shabati\". Adapted for the screen by Ephraim Kishon from his original play, the social satire depicts the hardships of a Sephardic immigrant family in the rough conditions of ma'abarot, immigrant absorption camps in Israel in the 1950s, satirizing \"just about every pillar of Israeli society: the Ashkenazi establishment, the pedantic bureaucracy, corrupt political parties, rigid kibbutz ideologues and ... the Jewish National Fund's tree-planting program\". Topol, who was 29 during the filming, was familiar playing the role of the family patriarch, having performed skits from the play with his Nahal entertainment troupe during his army years. He contributed his ideas to the part, playing the character as a more universal Mizrahi Jew instead of specifically a Yemenite, Iraqi, or Moroccan Jew, and asking Kishon to change the character's first name from Saadia (a recognizably Yemenite name) to Sallah (a more general Mizrahi name).\nThe film won the Golden Globe Award for Best Foreign Language Film, and Topol won the 1964 Golden Gate Award for Best Actor at the San Francisco International Film Festival and the 1965 Golden Globe for Most Promising Newcomer\u2014Male, alongside Harve Presnell and George Segal. \"Sallah Shabati\" was nominated for the Academy Award for Best Foreign Language Film, losing to the Italian-language \"Yesterday, Today and Tomorrow\".\nIn 1966, Topol made his English-language film debut as Abou Ibn Kaqden in the Mickey Marcus biopic \"Cast a Giant Shadow\".\nTevye the Dairyman.\nTopol in 1971\nTopol came to greatest prominence in his portrayal of Tevye the Dairyman on stage and screen. He first played the lead role in the Israeli production of the musical \"Fiddler on the Roof\" in 1966, replacing Shmuel Rodensky for 10 weeks when Rodensky fell ill. Harold Prince, producer of the original \"Fiddler on the Roof\" that opened on Broadway in 1964, had seen Topol in \"Sallah Shabati\" and called him to audition for the role of the fifty-something Tevye in a new production scheduled to open at Her Majesty's Theatre in London on February 16, 1967. Not yet fluent in English, Topol memorized the score from listening to the original Broadway cast album and practiced the lyrics with a British native.\nWhen Topol arrived at the audition, Prince was surprised that this 30-year-old man had played Shabati, a character in his sixties. Topol explained, \"A good actor can play an old man, a sad face, a happy man. Makeup is not an obstacle\". Topol also surprised the producers with his familiarity with the staging, since he had already acted in the Israeli production, and was hired. He spent six months in London learning his part phonetically with vocal coach Cicely Berry. Jerome Robbins, director and choreographer of the 1964 Broadway show who came over to direct the London production, \"re-directed\" the character of Tevye for Topol and helped the actor deliver a less caricatured performance. Topol's performance received positive reviews.\nA few months after the opening, Topol was called up for reserve duty in the Six-Day War and returned to Israel. He was assigned to an army entertainment troupe on the Golan Heights. Afterward he returned to the London production, appearing in a total of 430 performances.\nIt was during the London run that he began being known by his last name only, as the English producers were unable to pronounce the voiceless uvular fricative consonant \u1e24et at the beginning of his first name, Chaim, instead calling him \"Shame\".\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\nChaim Topol breathed life into Tevye.\n \u2013Norman Jewison, 2011\nIn casting the 1971 film version of \"Fiddler on the Roof\", director Norman Jewison and his production team sought an actor other than Zero Mostel for the lead role. This decision was a controversial one, as Mostel had made the role famous in the long-running Broadway musical and wanted to star in the film. But Jewison and his team felt Mostel would eclipse the character with his larger-than-life personality. Jewison flew to London in February 1968 to see Topol perform as Tevye during his last week with the London production, and chose him over Danny Kaye, Herschel Bernardi, Rod Steiger, Danny Thomas, Walter Matthau, Richard Burton, and Frank Sinatra, who had also expressed interest in the part.\nThen 36 years old, Topol was made to look 20 years older and heavier with makeup and costuming. As in his role as Shabati, Topol used the technique of \"locking his muscles\" to convincingly play an older character. He later explained:\nAs a young man, I had to make sure that I didn't break the illusion for the audience. You have to tame yourself. I'm now someone who is supposed to be 50, 60 years old. I cannot jump. I cannot suddenly be young. You produce a certain sound [in your voice] that is not young.\nTopol in 2003\nFor his performance, Topol won the Golden Globe Award for Best Actor in a Motion Picture \u2013 Musical or Comedy, the Sant Jordi Award for Best Performance in a Foreign Film, and the 1972 David di Donatello for Best Foreign Actor, sharing the latter with Elizabeth Taylor. He was also nominated for the 1971 Academy Award for Best Actor, losing to Gene Hackman in \"The French Connection\".\nIn 1983 Topol reprised the role of Tevye in a revival of \"Fiddler on the Roof\" on the West End in London. In 1989, he played the role in a 30-city U.S. touring production. As he was by then the approximate age of the character, he commented, \"I didn't have to spend the energy playing the age\". In 1990\u20131991, he again starred as Tevye in a Broadway revival of \"Fiddler\" at the Gershwin Theatre. In that production Rosalind Harris, who had played eldest daughter Tzeitel in the film, played Tevye's wife Golde opposite Topol. In 1991, Topol was nominated for a Tony Award for Best Performance by a Leading Actor in a Musical, losing to Jonathan Pryce in \"Miss Saigon\". Topol again played Tevye in a 1994 London revival, which became a touring production. In that production, the role of one of his daughters was played by his own daughter, Adi Topol Margalith.\nTopol reprised the role of Tevye for a 1997\u20131998 touring production in Israel, as well as a 1998 show at the Regent Theatre in Melbourne. In September 2005 he returned to Australia for a \"Fiddler on the Roof\" revival at the Capitol Theatre in Sydney, followed by an April 2006 production at the Lyric Theatre in Brisbane, and a June 2006 production at Her Majesty's Theatre in Melbourne. In May 2007, he starred in a production at the Auckland Civic Theatre.\nIn 2009, Topol began a farewell tour of \"Fiddler on the Roof\" as Tevye, opening in Wilmington, Delaware. He was forced to withdraw from the tour in Boston owing to a shoulder injury, and was replaced by Theodore Bikel and Harvey Fierstein, both of whom had portrayed Tevye on Broadway. Topol estimated that he performed the role more than 3,500 times.\nIn 2014, he appeared in \"Raising the Roof\", a 50th-anniversary tribute to \"Fiddler\" at New York City's Town Hall produced by National Yiddish Theatre. The evening featured Chita Rivera, Joshua Bell, Sheldon Harnick, Andrea Martin, Jerry Zaks, and more, and was co-directed by Gary John La Rosa and Erik Liberman.\nOther stage and film roles.\nIn 1976, Topol played the lead role of the baker, Amiable, in the new musical \"The Baker's Wife\", but was fired after eight months by producer David Merrick. In her autobiography, Patti LuPone, his co-star in the production, claimed that Topol had behaved unprofessionally on stage and had a strained relationship with her off-stage. The show's composer, Stephen Schwartz, claimed that Topol's behavior greatly disturbed the cast and directors and resulted in the production not reaching Broadway as planned. In 1988, Topol starred in the title role in \"Ziegfeld\" at the London Palladium. He returned to the London stage in 2008 in the role of Honor\u00e9, played by Maurice Chevalier in the 1958 film \"Gigi\".\nTopol appeared in more than 30 films in Israel and abroad. Among his notable English-language appearances are the title role in \"Galileo\" (1975), Dr. Hans Zarkov in \"Flash Gordon\" (1980), and Milos Columbo in the James Bond film \"For Your Eyes Only\" (1981). He was said to be Israel's \"only internationally recognized entertainer\" from the 1960s through to the 1980s.\nIn Israel, Topol acted in and produced dozens of films and television series. As a voice artist, he dubbed the voice of Bagheera in the Hebrew-language versions of \"The Jungle Book\" and the 2003 sequel as well as Rubeus Hagrid in the first two films of the \"Harry Potter\" film series. He was also a playwright and screenwriter.\nTopol was featured on two BBC One programmes, the six-part series \"Topol's Israel\" (1985) and earlier \"It's Topol\" (1968). A Hebrew-language documentary of his life, \"Chaim Topol \u2013 Life as a Film\", aired on Israel's Channel 1 in 2011, featuring interviews with his longtime actor friends in Israel and abroad.\nMusical recordings.\nA baritone, Topol recorded several singles and albums, including film soundtracks, children's songs, and Israeli war songs. His albums include \"Topol With Roger Webb And His Orchestra - Topol '68\" (1967), \"Topol Sings Israeli Freedom Songs\" (1967), \"War Songs By Topol\" (1968), and \"Topol's Israel\" (1984). He appeared on the soundtrack album for the film production of \"Fiddler on the Roof\" (1971) and the London cast album (1967).\nMossad missions.\nAfter Topol's death, the family revealed that he had been involved in Mossad missions in the 1960s and 1970s. They said he went on unexplained trips abroad while equipped with a miniature state-of-the-art camera and tape recorder, and that he was in regular contact with Mossad officer Peter Malkin, who came on visits to the family home through the backyard in disguise. On several occasions, Topol carried out wiretapping and other operations with Malkin, using his international acclaim to divert attention from Malkin.\nLiterary and art career.\nHis autobiography, \"Topol by Topol\", was published in London by Weindenfel and Nicholson (1981). He also authored \"To Life!\" (1994) and \"Topol's Treasury of Jewish Humor, Wit and Wisdom\" (1995).\nTopol illustrated approximately 25 books in both Hebrew and English. He also produced drawings of Israeli national figures. His sketches of Israeli presidents were reproduced in a 2013 stamp series issued by the Israel Philatelic Federation, as was his self-portrait as Tevye for 2014 commemorative stamp marking the 50th anniversary of the Broadway debut of \"Fiddler on the Roof\".\nPhilanthropy.\nIn 1967, Topol founded Variety Israel, an organization serving children with special needs. He was also a co-founder and chairman of the board of Jordan River Village, a vacation village for Arab and Jewish children with life-threatening illnesses, which opened in 2012. It was inspired by Paul Newman's Hole in the Wall Gang Camp. The village is operated almost entirely by volunteers. Topol described it as the project he was \"most connected to.\"\nAwards and recognition.\nTopol was a recipient of Israel's Kinor David award in arts and entertainment in 1964. He received a Best Actor award from the San Sebasti\u00e1n International Film Festival for his performance in the 1972 film \"Follow Me!\" In 2008, he was named an Outstanding Member of the Israel Festival for his contribution to Israeli culture.\nIn 2014, the University of Haifa conferred upon Topol an honorary degree in recognition of his 50 years of activity in Israel's cultural and public life. In 2015, he received the Israel Prize for lifetime achievement.\nIn 2015, Chaim Topol was honoured by the Chief Rabbi of Ukraine, Rabbi Moshe Reuven Azman and the Ukrainian Jewish Community. Topol's portrayal of Tevye in Fiddler on the Roof led to the inspiration for the Anatevka Refugee Village which was named in commemoration of the fictional village.\nLegacy.\nShortly after Topol's death, President Isaac Herzog issued a statement honouring \"one of the most prominent Israeli stage artists, a gifted actor who conquered many stages in Israel and overseas, filled the cinema screens with his presence and, above all, deeply entered our hearts\". Prime minister Benjamin Netanyahu stated \"his wide smile, warm voice, and unique sense of humour made him a folk hero who won the hearts of the people\" and former prime minister Yair Lapid remarked \"He and his smile will continue to accompany Israeli culture, his rich legacy will forever remain a part of Israel\".\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "7586", "revid": "27015025", "url": "https://en.wikipedia.org/wiki?curid=7586", "title": "Christadelphians", "text": "Restorationist nontrinitarian Christian denomination\nThe Christadelphians () are a restorationist and nontrinitarian (Biblical Unitarian) Christian denomination. The name means 'brothers and sisters in Christ', from the Greek words for Christ (\"Christos\") and brothers (\"adelphoi\").\nChristadelphians believe in the inspiration of the Bible, the Virgin Birth, the status of Jesus as the son of God, believer's baptism, the resurrection of the dead, the second coming of Christ, and the future kingdom of God on earth. However, they reject a number of mainstream Christian doctrines, for example the Trinity and the immortality of the soul, believing these to be corruptions of original Christian teaching.\nThe movement developed in the United Kingdom and North America in the 19th century around the teachings of John Thomas and they were initially found predominantly in the developed English-speaking world, expanding in developing countries after the Second World War. In 2009, the BBC estimated there were approximately 50,000 Christadelphians in around 120 countries. Congregations are traditionally referred to as \"ecclesias\".\nHistory.\n19th century.\nThe Christadelphian movement traces its origins to John Thomas (1805\u20131871). He initially associated with emerging Restoration Movement in the United States but later separated from them. The Christadelphian community in the United Kingdom effectively dates from Thomas's first lecturing tour of Britain (May 1848 \u2013 October 1850). During this period, he wrote \"Elpis Israel\" in which he laid out his understanding of the main doctrines of the Bible. Since his medium for bringing change was print and debate, it was natural for the origins of the Christadelphian body to be associated with books and journals, such as Thomas's \"Herald of the Kingdom\". His message was particularly welcomed in Scotland, and Campbellite, Unitarian and Adventist friends separated to form groups of \"Baptised Believers\".\nHe was not alone in his desire to establish Biblical truth and test orthodox Christian beliefs through independent scriptural study. Among other churches, he had links with the Adventist movement and with Benjamin Wilson (who later set up the Church of God of the Abrahamic Faith in the 1860s). Although the Christadelphian movement originated through the activities of John Thomas, he never saw himself as making his own disciples. He believed rather that he had rediscovered 1st-century beliefs from the Bible alone, and sought to prove that through a process of challenge and debate and writing journals. Through that process a number of people became convinced and set up various fellowships that had sympathy with that position. Groups associated with John Thomas met under multiple names, including Believers, Baptised Believers, the Royal Association of Believers, Baptised Believers in the Kingdom of God, Nazarines (or Nazarenes), and The Antipas until the time of the American Civil War (1861\u20131865). At that time, church affiliation was required in the United States and the Confederate States of America in order to register for conscientious objector status, and in 1864, Thomas chose for registration purposes the name \"Christadelphian\".\nThrough the teaching of John Thomas and the need in the American Civil War for a name, the Christadelphians emerged as a denomination, but they were formed into a lasting structure through a passionate follower of Thomas's interpretation of the Bible, Robert Roberts. In 1864, he began to publish \"The Ambassador of the Coming Age\" magazine. John Thomas, out of concern that someone else might start a publication and call it \"The Christadelphian\", urged Robert Roberts to change the name of his magazine to \"The Christadelphian\", which he did in 1869. His editorship of the magazine continued with some assistance until his death in 1898. In church matters, Roberts was prominent in the period following the death of John Thomas in 1871 and helped craft the structures of the Christadelphian body.\nInitially, the denomination grew in the English-speaking world, particularly in the English Midlands and parts of North America. Two-thirds of ecclesias and members in Britain before 1864 were in Scotland. In the early days after the death of John Thomas, the group could have moved in a number of directions. Doctrinal issues arose, debates took place, and statements of faith were created and amended as other issues arose. These attempts were felt necessary by many to both settle and define a doctrinal stance for the newly emerging denomination and to keep out error. As a result of these debates, several groups separated from the main body of Christadelphians, most notably the Suffolk Street fellowship in 1885 (with members believing that the whole of the Bible was not inspired) and the Unamended fellowship.\n20th century.\nThe Christadelphian position on conscientious objection came to the fore with the introduction of conscription during the First World War. Varying degrees of exemption from military service were granted to Christadelphians in the United Kingdom, Canada, Australia, New Zealand, and the United States. In the Second World War, this frequently required the person seeking exemption to undertake civilian work under the direction of the authorities.\nDuring the Second World War, the Christadelphians in Britain assisted in the Kindertransport, helping to relocate several hundred Jewish children away from Nazi persecution by founding a hostel, Elpis Lodge, for that purpose. In Germany, the small Christadelphian community founded by Albert Maier went underground from 1940 to 1945, and a leading brother, Albert Merz, was imprisoned as a conscientious objector and later executed.\nAfter the Second World War, moves were made to try to reunite various earlier divisions. By the end of the 1950s, most Christadelphians had united into one community, but a number of small groups remained separate.\nToday.\nThe post-war and post-reunions periods saw an increase in co-operation and interaction between ecclesias, resulting in the establishment of a number of week-long Bible schools and the formation of national and international organisations such as the Christadelphian Bible Mission (for preaching and pastoral support overseas), the Christadelphian Support Network (for counselling), and the Christadelphian Meal-A-Day Fund (for charity and humanitarian work).\nThe period following the reunions was accompanied by expansion in the developing world, which now accounts for around 40% of Christadelphians.\nBeliefs.\nThe Christadelphian body has no central authority or co-ordinating organisation to establish and maintain a standardised set of beliefs, but there are core doctrines accepted by most Christadelphians. In the formal statements of faith a more complete list is found; for instance, the Birmingham Amended Statement of Faith has 30 doctrines to be accepted and 35 to be rejected.\nThe Bible.\nChristadelphians state that their beliefs are based wholly on the Bible, and they do not see other works as inspired by God. They regard the Bible as inspired by God and, therefore, believe that in its original form, it is error-free apart from errors in later copies due to errors of transcription or translation.\nGod.\nChristadelphians believe that God, Yahweh, is the creator of all things and the father of true believers, and that he is a separate being from his son, Jesus (who is subordinate to him). They reject the doctrine of the Trinity.\nJesus.\nChristadelphians believe that Jesus was the promised Jewish Messiah in whom the prophecies and promises of the Old Testament (Hebrew Bible) find their fulfilment. They believe he is the Son of Man\u2014in that he inherited human nature (with its inclination to sin) from his mother\u2014and the Son of God by virtue of his miraculous conception by the power of God. Christadelphians reject the doctrine of the pre-existence of Christ. They teach that he was part of God's plans from the beginning and was foreshadowed in the Old Testament, but was not an independent being prior to his human birth. The faith posits that, though he was tempted, Jesus committed no sin, and was, therefore, a perfect representative sacrifice to bring salvation to sinful humankind. They believe that God raised Jesus from death and gave him immortality, and he has ascended to Heaven, God's dwelling place, until he returns to set up the Kingdom of God on earth.\nThe Holy Spirit.\nChristadelphians believe that the Holy Spirit is the power of God used in creation and for salvation. They also believe that the phrase \"Holy Spirit\" sometimes refers to God's character/mind, depending on the context in which the phrase appears, but reject the view that people need strength, guidance and power from the Holy Spirit to live a Christian life, believing instead that the spirit a believer needs within themselves is the mind/character of God, which is developed in a believer by their reading of the Bible (which, they believe, contains words God gave by his Spirit) and trying to live by what it says during the events of their lives which God uses to help shape their character. Christadelphians deny the personhood of the Holy Spirit and the present-day possession of the Holy Spirit (both \"gift of\" and \"gifts of\") (see cessationism).\nThe Kingdom of God.\nChristadelphians believe that Jesus will return to the Earth in person to set up the Kingdom of God in fulfilment of the promises made to Abraham and David. This includes the belief that the coming Kingdom will be the restoration of God's first Kingdom of Israel, which was under David and Solomon. For Christadelphians, this is the focal point of the gospel taught by Jesus and the Twelve Apostles. They believe that the Kingdom will be centred upon Israel, but Jesus will also reign over all the other nations on the Earth. Old Paths Christadelphians continue to believe that the Kingdom of God is to be restored to the land of Israel promised to Abraham and ruled over in the past by David, with a worldwide empire.\nThe Devil.\nChristadelphians believe that the word \"devil\" is a reference in the scriptures to sin and human nature in opposition to God, while the word \"satan\" is merely a reference to an adversary or opponent (be it good or bad) and is frequently applied to human beings. According to Christadelphians, these terms are used in reference to specific political systems or individuals in opposition or conflict and not to an independent spiritual being or fallen angel. Accordingly, they do not define Hell as a place of eternal torment for sinners, but as a state of eternal death and non-existence due to annihilation of body and mind.\nSalvation.\nChristadelphians believe that people are separated from God because of their sins but that humankind can be reconciled to him by becoming disciples of Jesus. This is by belief in the Gospel, through repentance, and through baptism by total immersion in water. They reject assurance of salvation, believing instead that salvation comes as a result of remaining \"in Christ\". After death, believers are in a state of non-existence, knowing nothing until the Resurrection at the return of Jesus. Following the judgement, the \"accepted\" receive the gift of immortality and live with Jesus on a restored Earth, assisting his establishment of the Kingdom of God and rule over the remaining population for a millennium. Christadelphians deny the immortality of the soul.\nLife in Christ.\nThe \"Commandments of Christ\" demonstrates the community's recognition of the importance of biblical teaching on morality. Marriage and family life are important. Most Christadelphians believe that sexual relationships should be limited to heterosexual marriage, ideally between baptised believers.\nOrganisation.\nGeneral organisation.\nIn the absence of centralised organisation, some differences exist amongst Christadelphians on matters of belief and practice. This is because each congregation (commonly styled 'ecclesias') is organised autonomously, typically following common practices which have altered little since the 19th century. Many avoid the word \"church\" due to its association with mainstream Christianity, and its focus on the building as opposed to the congregation. Most ecclesias have a constitution, which includes a 'Statement of Faith', a list of 'Doctrines to be Rejected' and a formalised list of 'The Commandments of Christ'. The statement of faith acts as the official standard of most ecclesias to determine fellowship within and between ecclesias, and as the basis for co-operation between ecclesias. Congregational discipline and conflict resolution are applied using various forms of consultation, mediation, and discussion, with disfellowship (similar to excommunication) being the final response to those with unorthodox practices or beliefs.\nOne influence on Christadelphian organizational practices is the booklet called \"A Guide to the Formation and Conduct of Christadelphian Ecclesias,\" written early in Christadelphian history by Robert Roberts. It recommends an arrangement by which congregational members elect 'brothers' to do arranging and serving duties, and includes guidelines for the organisation of committees, as well as conflict resolution between congregational members and between congregations. Christadelphians do not have paid ministers. Male members are assessed by the congregation for their eligibility to teach and perform other duties, which are usually assigned on a rotation basis, as opposed to having a permanently appointed preacher. Congregational polity typically follows a democratic model, with an elected arranging committee for each individual ecclesia. This unpaid committee is responsible for the day-to-day running of the ecclesia and is answerable to the rest of the ecclesia's members.\nInter-ecclesial organisations co-ordinate the running of, among other things, Christadelphian schools and elderly care homes, the Christadelphian Isolation League (which cares for those prevented by distance or infirmity from attending an ecclesia regularly) and the publication of .\nAdherents.\nNo official membership figures are published, but the \"Columbia Encyclopaedia\" gives an estimated figure of 50,000 Christadelphians, spread across approximately 120 countries. Estimates for the main centers of Christadelphian population are as follows: Mozambique (17,800), Australia (9,734), the United Kingdom (8,200), Malawi (7,000), United States (6,500), Canada (3,000), Kenya (2,700), India (2,300) and New Zealand (1,785). Figures from Christadelphian mission organisations are as follows: Africa (32,500), Asia (4,000), the Caribbean (400), Europe (including Russia) (700), Latin America (275), and the Pacific (200).\nFellowships.\nThe Christadelphian body consists of a number of \"fellowships\" \u2013 groups of ecclesias which associate with one another, often to the exclusion of ecclesias outside their group. They are to some degree localised. The Unamended Fellowship, for example, exists only in North America. Christadelphian fellowships have often been named after ecclesias or magazines who took a lead in developing a particular stance.\nThe majority of Christadelphians today belong to what is commonly known as the \"Central Fellowship\". The term \"Central\" came into use around 1933 to identify ecclesias worldwide who were in fellowship with the Birmingham (Central) Ecclesia. These were previously known as the \"Temperance Hall Fellowship\". The \"Suffolk Street Fellowship\" arose in 1885 over disagreements surrounding the inspiration of the Bible. Meanwhile, in Australia, division concerning the nature of Jesus Christ resulted in the formation of the \"Shield Fellowship\". Discussions in 1957\u20131958 resulted in a worldwide reunion between the Central, Suffolk Street and Shield Fellowships.\nThe \"Unamended Fellowship\", consisting of around 1,850 members, is found in the East Coast and Midwest USA and Ontario, Canada. This group separated in 1898 as a result of differing views on who would be raised to judgement at the return of Christ. The majority of Christadelphians believe that the judgement will include anyone who had sufficient knowledge of the gospel message, and is not limited to baptised believers. The majority in England, Australia and North America amended their statement of faith accordingly. Those who opposed the amendment became known as the \"Unamended Fellowship\" and allowed the teaching that God either could not or would not raise those who had no covenant relationship with him. Opinions vary as to what the established position was on this subject prior to the controversy. Prominent in the formation of the Unamended Fellowship was Thomas Williams, editor of the Christadelphian Advocate magazine. The majority of the Unamended Fellowship outside North America joined the Suffolk Street Fellowship before its eventual incorporation into Central Fellowship. There is also some co-operation between the Central (Amended) and Unamended Fellowships in North America \u2013 most recently in the Great Lakes region, where numerous Amended and Unamended ecclesias are working together to unify their ecclesias. The Central Fellowship in North America is still often referred to today as the \"Amended Fellowship\".\nThe \"Berean Fellowship\" was formed in 1923 as a result of varying views on military service in England, and on the atonement in North America. The majority of the North American Bereans re-joined the main body of Christadelphians in 1952. A number continue as a separate community, numbering around 200 in Texas, 100 in Kenya and 30 in Wales. Most of the divisions still in existence within the Christadelphian community today stem from further divisions of the \"Berean\" \"Fellowship\".\nThe \"Dawn Fellowship\" are the result of an issue which arose in 1942 among the Berean Fellowship regarding divorce and remarriage. The stricter party formed the Dawn Fellowship who, following re-union on the basis of unity of belief with the Lightstand Fellowship in Australia in 2007 increased in number. There are now thought to be around 800 members in England, Australia, Canada, India, Jamaica, Poland, the Philippines, Russia and Kenya.\nThe \"Old Paths Fellowship\" was formed in 1957 in response to the reunion of the Central and Suffolk Street Fellowships. A minority from the Central Fellowship held that the reasons for separation remained and that full unity of belief on all fundamental principles of Bible teaching was necessary; thus reunion was only possible with the full agreement and understanding of all members rather than a decision by majority vote. Ecclesias forming the Old Paths Fellowship arose in England, Australia, New Zealand and Canada numbering around 500 members in total. They now number around 250 members in total, with members in Australia, England, Mexico and New Zealand. They maintain that they hold to the original Central Fellowship position held prior to the 1957 Reunion.\nOther fellowships (ranging in numbers from as few as 10 to over 200 members) include the \"Watchman Fellowship\", the \"Companion Fellowship\" and the \"Pioneer Fellowship\".\nAccording to Bryan Wilson, functionally the definition of a \"fellowship\" within Christadelphian history has been mutual or unilateral exclusion of groupings of ecclesias from the breaking of bread. This functional definition still holds true in North America, where the Unamended Fellowship and the Church of God of the Abrahamic Faith are not received by most North American Amended ecclesias. But outside North America this functional definition no longer holds. Many articles and books on the doctrine and practice of fellowship now reject the notion itself of separate \"fellowships\" among those who recognise the same baptism, viewing such separations as schismatic. Many ecclesias in the Central fellowship would not refuse a baptised Christadelphian from a minority fellowship from breaking bread; the exclusion is more usually the other way.\nWhile their operational methods emphasize different important qualities, the Central, Old Paths, Dawn and Berean fellowships generally subscribe to the \"Birmingham Amended Statement of Faith\" (BASF), though the latter two have additional clauses or supporting documents to explain their position. Most Unamended ecclesias use the \"Birmingham Unamended Statement of Faith\" (BUSF) with one clause being different from the aforementioned BASF. \nWithin the Central fellowship individual ecclesias also may have their own statement of faith, whilst still accepting the statement of faith of the larger community. Some ecclesias have statements on specific positions, especially on divorce and re-marriage, making clear that offence would be caused by anyone in that position seeking to join them at the 'Breaking of Bread' service. Other ecclesias tolerate a degree of divergence from commonly held Christadelphian views. \nFor each fellowship, anyone who publicly assents to the doctrines described in the statement and is in good standing in their \"home ecclesia\" is generally welcome to participate in the activities of any other ecclesia.\nRelated groups.\nThere are a number of groups who, while sharing a common heritage and many Christadelphian teachings, have adopted alternative names in order to dissociate themselves from what they believe to be false teachings and/or practice within the main Christadelphian body. Ranging in size from two or three members in size to around 50, each group restricts fellowship to its own members. These include the Nazarene Fellowship, the Ecclesia of Christ, the Remnant of Christ's Ecclesia, the Apostolic Fellowship of Christ and the Apostolic Ecclesia.\nThe Church of God of the Abrahamic Faith (CGAF) also has common origins with Christadelphians and shares Christadelphian beliefs. Numbering around 400 (primarily Ohio and Florida, USA), they are welcomed into fellowship by some \"Central\" Christadelphians and are currently involved in unity talks.\nHistorical antecedents.\nOne criticism of the Christadelphian movement has been over the claim of John Thomas and Robert Roberts to have \"re-discovered\" scriptural truth. However one might argue that \"all\" Protestant groups make the same claims to some extent. Although both men believed that they had \"recovered\" the true doctrines for themselves and contemporaries, they also believed there had always existed a group of true believers throughout the ages, albeit marred by the apostasy.\nThe most notable Christadelphian attempts to find a continuity of those with doctrinal similarities since that point have been geographer Alan Eyre's two books \"The Protesters\" (1975) and \"Brethren in Christ\" (1982) in which he shows that many individual Christadelphian doctrines had been previously believed. Eyre focused in particular on the Radical Reformation, and also among the Socinians and other early Unitarians and the English Dissenters. In this way, Eyre was able to demonstrate substantial historical precedents for individual Christadelphian teachings and practices, and believed that the Christadelphian community was the 'inheritor of a noble tradition, by which elements of the Truth were from century to century hammered out on the anvil of controversy, affliction and even anguish'. Although noting in the introduction to 'The Protestors' that 'Some recorded herein perhaps did not have \"all the truth\" \u2014 so the writer has been reminded', Eyre nevertheless claimed that the purpose of the work was to 'tell how a number of little-known individuals, groups and religious communities strove to preserve or revive the original Christianity of apostolic times', and that 'In faith and outlook they were far closer to the early springing shoots of first-century Christianity and the penetrating spiritual challenge of Jesus himself than much that has passed for the religion of the Nazarene in the last nineteen centuries'.\nEyre's research has been criticized by some of his Christadelphian peers, and as a result Christadelphian commentary on the subject has subsequently been more cautious and circumspect, with caveats being issued concerning Eyre's claims, and the two books less used and publicised than in previous years.\nNevertheless, even with most source writings of those later considered heretics destroyed, evidence can be provided that since the first century BC there have been various groups and individuals who have held certain individual Christadelphian beliefs or similar ones. For example, all the distinctive Christadelphian doctrines (with the exception of the non-literal devil), down to interpretations of specific verses, can be found particularly among sixteenth century Socinian writers (e.g. the rejection of the doctrines of the trinity, pre-existence of Christ, immortal souls, a literal hell of fire, original sin). Early English Unitarian writings also correspond closely to those of Christadelphians. Also, recent discoveries and research have shown a large similarity between Christadelphian beliefs and those held by Isaac Newton who, among other things, rejected the doctrines of the trinity, immortal souls, a personal devil and literal demons. Further examples are as follows:\nOrganised worship in England for those whose beliefs anticipated those of Christadelphians only truly became possible in 1779 when the Act of Toleration 1689 was amended to permit denial of the Trinity, and only fully when property penalties were removed in the Doctrine of the Trinity Act 1813. This is only 35 years before John Thomas' 1849 lecture tour in Britain which attracted significant support from an existing non-Trinitarian Adventist base, particularly, initially, in Scotland where Arian, Socinian, and unitarian (with a small 'u' as distinct from the Unitarian Church of Theophilus Lindsey) views were prevalent.\nPractices and worship.\nChristadelphians are organised into local congregations, that commonly call themselves \"ecclesias\", which is taken from usage in the New Testament and is Greek for \"gathering of those summoned\". Congregational worship, which usually takes place on Sunday, centres on the remembrance of the death and celebration of the resurrection of Jesus Christ by the taking part in the \"memorial service\". Additional meetings are often organised for worship, prayer, preaching and Bible study.\nEcclesias are typically involved in preaching the gospel (evangelism) in the form of public lectures on Bible teaching, college-style seminars on reading the Bible, and Bible Reading Groups. Correspondence courses are also used widely, particularly in areas where there is no established Christadelphian presence. Some ecclesias, organisations or individuals also preach through other media like video, \n and internet forums. There are also a number of Bible Education/Learning Centres around the world.\nOnly baptised (by complete immersion in water) believers are considered members of the ecclesia. Ordinarily, baptism follows someone making a \"good confession\" (cf. 1 Tim. 6:12) of their faith before two or three nominated elders of the ecclesia they are seeking to join. The good confession has to demonstrate a basic understanding of the main elements \u2013 \"first principles\" \u2013 of the faith of the community. The children of members are encouraged to attend Christadelphian Sunday schools and youth groups. Interaction between youth from different ecclesias is encouraged through regional and national youth gatherings, conferences and camping holidays.\nChristadelphians understand the Bible to teach that male and female believers are equal in God's sight, and also that there is a distinction between the roles of male and female members. Women are typically not eligible to teach in formal gatherings of the ecclesia when male believers are present, are expected to cover their heads (using hat or scarf, etc.) during formal services, and do not sit on the main ecclesial arranging (organising) committees. They do, however: participate in other ecclesial and inter-ecclesial committees; participate in discussions; teach children in Sunday schools as well as at home, teach other women and non-members; perform music; discuss and vote on business matters; and engage in the majority of other activities. Generally, at formal ecclesial and inter-ecclesial meetings the women wear head coverings when there are acts of worship and prayer.\nThere are ecclesially accountable committees for co-ordinated preaching, youth and Sunday school work, conscientious objection issues, care of the elderly, and humanitarian work. These do not have any legislative authority, and are wholly dependent upon ecclesial support. Ecclesias in an area may regularly hold joint activities combining youth groups, fellowship, preaching, and Bible study.\nChristadelphians refuse to participate in any military or police force because they are conscientious objectors (not to be confused with pacifists).\nThere is a strong emphasis on personal Bible reading and study and many Christadelphians use the Bible Companion to help them systematically read the Bible each year.\nHymnody and music.\nChristadelphian hymnody makes considerable use of the hymns of the Anglican and English Protestant traditions (even in US ecclesias the hymnody is typically more English than American). In many Christadelphian hymn books a sizeable proportion of hymns are drawn from the Scottish Psalter and non-Christadelphian hymn-writers including Isaac Watts, Charles Wesley, William Cowper and John Newton. Despite incorporating non-Christadelphian hymns however, Christadelphian hymnody preserves the essential teachings of the community.\nThe earliest hymn book published was the \"Sacred Melodist\" which was published by Benjamin Wilson in Geneva, Illinois in 1860. The next was the hymn book published for the use of \"Baptised Believers in the Kingdom of God\" (an early name for Christadelphians) by George Dowie in Edinburgh in 1864. In 1865 Robert Roberts published a collection of Scottish psalms and hymns called \"The Golden Harp\" (which was subtitled \"Psalms, Hymns, and Spiritual Songs, compiled for the use of Immersed Believers in 'The Things concerning the Kingdom of God and the Name of Jesus Christ'\"). This was replaced only five years later by the first \"Christadelphian Hymn Book\" (1869), compiled by J. J. and A. Andrew, and this was revised and expanded in 1874, 1932 and 1964. A thorough revision by the Christadelphian Magazine and Publishing Association resulted in the latest (2002) edition which is almost universally used by English-speaking Christadelphian ecclesias. In addition some Christadelphian fellowships have published their own hymn books.\nSome ecclesias use the \"Praise the Lord\" songbook. It was produced with the aim of making contemporary songs which are consistent with Christadelphian theology more widely available. Another publication, the \"Worship\" book is a compilation of songs and hymns that have been composed only by members of the Christadelphian community. This book was produced with the aim of providing extra music for non-congregational music items within services (e.g. voluntaries, meditations, et cetera) but has been adopted by congregations worldwide and is now used to supplement congregational repertoire.\nIn the English-speaking world, worship is typically accompanied by organ or piano, though in recent years a few ecclesias have promoted the use of other instruments (e.g. strings, wind and brass as mentioned in the Psalms). This trend has also seen the emergence of some Christadelphian bands and the establishment of the Christadelphian Art Trust to support performing, visual and dramatic arts within the Christadelphian community.\nIn other countries, hymn books have been produced in local languages, sometimes resulting in styles of worship which reflect the local culture. It has been noted that Christadelphian hymnody has historically been a consistent witness to Christadelphian beliefs, and that hymnody occupies a significant role in the community.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "7587", "revid": "910180", "url": "https://en.wikipedia.org/wiki?curid=7587", "title": "Cable television", "text": "Television content transmitted via signals on coaxial or fibre-optic cable\nCable television is a system of delivering television programming to consumers via radio frequency (RF) signals transmitted through coaxial cables, or in more recent systems, light pulses through fibre-optic cables. This contrasts with broadcast television, in which the television signal is transmitted over-the-air by radio waves and received by a television antenna, or satellite television, in which the television signal is transmitted over-the-air by radio waves from a communications satellite and received by a satellite dish on the roof. FM radio programming, high-speed Internet, telephone services, and similar non-television services may also be provided through these cables. Analog television was standard in the 20th century, but since the 2000s, cable systems have been upgraded to digital cable operation.\nA cable channel (sometimes known as a cable network) is a television network available via cable television. Many of the same channels are distributed through satellite television. Alternative terms include \"non-broadcast channel\" or \"programming service\", the latter being mainly used in legal contexts. The abbreviation CATV is used in the US for cable television and originally stood for community antenna television, from cable television's origins in 1948; in areas where over-the-air TV reception was limited by distance from transmitters or mountainous terrain, large \"community antennas\" were constructed, and cable was run from them to individual homes.\nIn 1968, 6.4% of Americans had cable television. The number increased to 7.5% in 1978. By 1988, 52.8% of all households were using cable. The number further increased to 62.4% in 1994.\nDistribution.\nTo receive cable television at a given location, cable distribution lines must be available on the local utility poles or underground utility lines. Coaxial cable brings the signal to the customer's building through a service drop, an overhead or underground cable. If the subscriber's building does not have a cable service drop, the cable company will install one. The standard cable used in the U.S. is RG-6, which has a 75 ohm impedance, and connects with a type F connector. The cable company's portion of the wiring usually ends at a distribution box on the building exterior, and built-in cable wiring in the walls usually distributes the signal to jacks in different rooms to which televisions are connected. Multiple cables to different rooms are split off the incoming cable with a small device called a splitter. There are two standards for cable television; older analog cable, and newer digital cable which can carry data signals used by digital television receivers such as high-definition television (HDTV) equipment. All cable companies in the United States have switched to or are in the course of switching to digital cable television since it was first introduced in the late 1990s.\nMost cable companies require a set-top box (cable converter box) or a slot on one's TV set for conditional access module cards to view their cable channels, even on newer televisions with digital cable QAM tuners, because most digital cable channels are now encrypted, or \"scrambled\", to reduce cable service theft. A cable from the jack in the wall is attached to the input of the box, and an output cable from the box is attached to the television, usually the RF-IN or composite input on older TVs. Since the set-top box only decodes the single channel that is being watched, each television in the house requires a separate box. Some unencrypted channels, usually traditional over-the-air broadcast networks, can be displayed without a receiver box. The cable company will provide set-top boxes based on the level of service a customer purchases, from basic set-top boxes with a standard-definition picture connected through the standard coaxial connection on the TV, to high-definition wireless digital video recorder (DVR) receivers connected via HDMI or component. Older analog television sets are \"cable ready\" and can receive the old analog cable without a set-top box. To receive digital cable channels on an analog television set, even unencrypted ones, requires a different type of box, a digital television adapter supplied by the cable company or purchased by the subscriber. Another new distribution method that takes advantage of the low cost high quality DVB distribution to residential areas, uses TV gateways to convert the DVB-C, DVB-C2 stream to IP for distribution of TV over IP network in the home. Many cable companies offer internet access through DOCSIS.\nPrinciple of operation.\nIn the most common system, multiple television channels (as many as 500, although this varies depending on the provider's available channel capacity) are distributed to subscriber residences through a coaxial cable, which comes from a trunkline supported on utility poles originating at the cable company's local distribution facility, called the headend. Many channels can be transmitted through one coaxial cable by a technique called frequency division multiplexing. At the headend, each television channel is translated to a different frequency. By giving each channel a different frequency \"slot\" on the cable, the separate television signals do not interfere with each other. At an outdoor cable box on the subscriber's residence, the company's service drop cable is connected to cables distributing the signal to different rooms in the building. At each television, the subscriber's television or a set-top box provided by the cable company translates the desired channel back to its original frequency (baseband), and it is displayed onscreen. Due to widespread cable theft in earlier analog systems, the signals are typically encrypted on modern digital cable systems, and the set-top box must be activated by an activation code sent by the cable company before it will function, which is only sent after the subscriber signs up. If the subscriber fails to pay their bill, the cable company can send a signal to deactivate the subscriber's box, preventing reception.\nThere are also usually upstream channels on the cable to send data from the customer box to the cable headend, for advanced features such as requesting pay-per-view shows or movies, cable internet access, and cable telephone service. The downstream channels occupy a band of frequencies from approximately 50\u00a0MHz to 1\u00a0GHz, while the upstream channels occupy frequencies of 5 to 42\u00a0MHz. Subscribers pay with a monthly fee. Subscribers can choose from several levels of service, with premium packages including more channels but costing a higher rate. At the local headend, the feed signals from the individual television channels are received by dish antennas from communication satellites. Additional local channels, such as local broadcast television stations, educational channels from local colleges, and community access channels devoted to local governments (PEG channels) are usually included on the cable service. Commercial advertisements for local business are also inserted in the programming at the headend (the individual channels, which are distributed nationally, also have their own nationally oriented commercials).\nHybrid fiber-coaxial.\nModern cable systems are large, with a single network and headend often serving an entire metropolitan area. Most systems use hybrid fiber-coaxial (HFC) distribution; this means the trunklines that carry the signal from the headend to local neighborhoods are optical fiber to provide greater bandwidth and also extra capacity for future expansion. At the headend, the electrical signal is translated into an optical signal and sent through the fiber. The fiber trunkline goes to several \"distribution hubs\", from which multiple fibers fan out to carry the signal to boxes called \"optical nodes\" in local communities. At the optical node, the optical signal is translated back into an electrical signal and carried by coaxial cable distribution lines on utility poles, from which cables branch out to a series of signal amplifiers and line extenders. These devices carry the signal to customers via passive RF devices called taps.\nHistory.\nThe very first cable networks were operated locally, notably in 1936 by Rediffusion in London in the United Kingdom and the same year in Berlin in Germany, notably for the Olympic Games, and from 1948 onwards in the United States and Switzerland. This type of local cable network was mainly used to relay terrestrial channels in geographical areas poorly served by terrestrial television signals.\nIn the United States.\nCable television began in the United States as a commercial business in 1950s.\nThe early systems simply received weak (broadcast) channels, amplified them, and sent them over unshielded wires to the subscribers, limited to a community or to adjacent communities. The receiving antenna would be taller than any individual subscriber could afford, thus bringing in stronger signals; in hilly or mountainous terrain it would be placed at a high elevation.\nAt the outset, cable systems only served smaller communities without television stations of their own, and which could not easily receive signals from stations in cities because of distance or hilly terrain. In Canada, however, communities with their own signals were fertile cable markets, as viewers wanted to receive American signals. Rarely, as in the college town of Alfred, New York, U.S. cable systems retransmitted Canadian channels.\nAlthough early (VHF) television receivers could receive 12 channels (2\u201313), the maximum number of channels that could be broadcast in one city was 7: channels 2, 4, either 5 or 6, 7, 9, 11 and 13, as receivers at the time were unable to receive strong (local) signals on adjacent channels without distortion. (There were frequency gaps between 4 and 5, and between 6 and 7, which allowed both to be used in the same city).\nAs equipment improved, all twelve channels could be utilized, except where a local VHF television station broadcast. Local broadcast channels were not usable for signals deemed to be a priority, but technology allowed low-priority signals to be placed on such channels by synchronizing their blanking intervals. TVs were unable to reconcile these blanking intervals and the slight changes due to travel through a medium, causing ghosting. The bandwidth of the amplifiers also was limited, meaning frequencies over 250\u00a0MHz were difficult to transmit to distant portions of the coaxial network, and UHF channels could not be used at all. To expand beyond 12 channels, non-standard \"midband\" channels had to be used, located between the FM band and Channel 7, or \"superband\" beyond Channel 13 up to about 300\u00a0MHz; these channels initially were only accessible using separate tuner boxes that sent the chosen channel into the TV set on Channel 2, 3 or 4. Initially, UHF broadcast stations were at a disadvantage because the standard TV sets in use at the time were unable to receive their channels. With the passage of the All-Channel Receiver Act in 1964, all new television sets were required to include a UHF tuner, nonetheless, it would still take a few years for UHF stations to become competitive.\nBefore being added to the cable box itself, these midband channels were used for early incarnations of pay TV, e.g. The Z Channel (Los Angeles) and HBO but transmitted in the clear i.e. not scrambled as standard TV sets of the period could not pick up the signal nor could the average consumer \"de-tune\" the normal stations to be able to receive it.\nOnce tuners that could receive select mid-band and super-band channels began to be incorporated into standard television sets, broadcasters were forced to either install scrambling circuitry or move these signals further out of the range of reception for early cable-ready TVs and VCRs. However, once consumer sets had the ability to receive all 181 FCC allocated channels, premium broadcasters were left with no choice but to scramble.\nThe descrambling circuitry was often published in electronics hobby magazines such as \"Popular Science\" and \"Popular Electronics\" allowing anybody with anything more than a rudimentary knowledge of broadcast electronics to be able to build their own and receive the programming without cost.\nLater, the cable operators began to carry FM radio stations, and encouraged subscribers to connect their FM stereo sets to cable. Before stereo and bilingual TV sound became common, Pay-TV channel sound was added to the FM stereo cable line-ups. About this time, operators expanded beyond the 12-channel dial to use the \"midband\" and \"superband\" VHF channels adjacent to the \"high band\" 7\u201313 of North American television frequencies. Some operators as in Cornwall, Ontario, used a dual distribution network with Channels 2\u201313 on each of the two cables.\nDuring the 1980s, United States regulations not unlike public, educational, and government access (PEG) created the beginning of cable-originated live television programming. As cable penetration increased, numerous cable-only TV stations were launched, many with their own news bureaus that could provide more immediate and more localized content than that provided by the nearest network newscast.\nSuch stations may use similar on-air branding as that used by the nearby broadcast network affiliate, but the fact that these stations do not broadcast over the air and are not regulated by the FCC, their call signs are meaningless. These stations evolved partially into today's over-the-air digital subchannels, where a main broadcast TV station e.g. NBC 37* would \u2013 in the case of no local CBS or ABC station being available \u2013 rebroadcast the programming from a nearby affiliate but fill in with its own news and other community programming to suit its own locale. Many live local programs with local interests were subsequently created all over the United States in most major television markets in the early 1980s.\nThis evolved into today's many cable-only broadcasts of diverse programming, including cable-only produced television movies and miniseries. Cable specialty channels, starting with channels oriented to show movies and large sporting or performance events, diversified further, and narrowcasting became common. By the late 1980s, cable-only signals outnumbered broadcast signals on cable systems, some of which by this time had expanded beyond 35 channels. By the mid-1980s in Canada, cable operators were allowed by the regulators to enter into distribution contracts with cable networks on their own.\nBy the 1990s, tiers became common, with customers able to subscribe to different tiers to obtain different selections of additional channels above the basic selection. By subscribing to additional tiers, customers could get specialty channels, movie channels, and foreign channels. Large cable companies used addressable descramblers to limit access to premium channels for customers not subscribing to higher tiers, however the above magazines often published workarounds for that technology as well.\nDuring the 1990s, the pressure to accommodate the growing array of offerings resulted in digital transmission that made more efficient use of the VHF signal capacity; fibre optics was common to carry signals into areas near the home, where coax could carry higher frequencies over the short remaining distance. Although for a time in the 1980s and 1990s, television receivers and VCRs were equipped to receive the mid-band and super-band channels. Because the descrambling circuitry was for a time present in these tuners, depriving the cable operator of much of their revenue, such cable-ready tuners are rarely used now \u2013 requiring a return to the set-top boxes used from the 1970s onward.\nThe digital television transition in the United States has put all signals, broadcast and cable, into digital form, rendering analog cable television service a rarity, found in an ever-dwindling number of markets. Analog television sets are accommodated, their tuners mostly obsolete and dependent entirely on the set-top box.\nDeployments by continent.\nCable television is mostly available in North America, Europe, Australia, Asia and South America. Cable television has had little success in Africa, as it is not cost-effective to lay cables in sparsely populated areas. Multichannel multipoint distribution service, a microwave-based system, may be used instead.\nOther cable-based services.\nCoaxial cables are capable of bi-directional carriage of signals as well as the transmission of large amounts of data. Cable television signals use only a portion of the bandwidth available over coaxial lines. This leaves plenty of space available for other digital services such as cable internet, cable telephony and wireless services, using both unlicensed and licensed spectra. Broadband internet access is achieved over coaxial cable by using cable modems to convert the network data into a type of digital signal that can be transferred over coaxial cable. One problem with some cable systems is the older amplifiers placed along the cable routes are unidirectional thus in order to allow for uploading of data the customer would need to use an analog telephone modem to provide for the upstream connection. This limited the upstream speed to 31.2 kbit/s and prevented the always-on convenience broadband internet typically provides. Many large cable systems have upgraded or are upgrading their equipment to allow for bi-directional signals, thus allowing for greater upload speed and always-on convenience, though these upgrades are expensive.\nIn North America, Australia and Europe, many cable operators have already introduced cable telephone service, which operates just like existing fixed line operators. This service involves installing a special telephone interface at the customer's premises that converts the analog signals from the customer's in-home wiring into a digital signal, which is then sent on the local loop (replacing the analog last mile, or plain old telephone service (POTS) to the company's switching center, where it is connected to the public switched telephone network (PSTN). The biggest obstacle to cable telephone service is the need for nearly 100% reliable service for emergency calls. One of the standards available for digital cable telephony, PacketCable, seems to be the most promising and able to work with the quality of service (QOS) demands of traditional analog plain old telephone service (POTS) service. The biggest advantage to digital cable telephone service is similar to the advantage of digital cable, namely that data can be compressed, resulting in much less bandwidth used than a dedicated analog circuit-switched service. Other advantages include better voice quality and integration to a Voice over Internet Protocol (VoIP) network providing cheap or unlimited nationwide and international calling. In many cases, digital cable telephone service is separate from cable modem service being offered by many cable companies and does not rely on Internet Protocol (IP) traffic or the Internet.\nTraditional cable television providers and traditional telecommunication companies increasingly compete in providing voice, video and data services to residences. The combination of television, telephone and Internet access is commonly called \"triple play\", regardless of whether CATV or telcos offer it.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "7588", "revid": "4977632", "url": "https://en.wikipedia.org/wiki?curid=7588", "title": "Charles S. Peirce", "text": ""}
{"id": "7591", "revid": "7903804", "url": "https://en.wikipedia.org/wiki?curid=7591", "title": "Cholera", "text": "Bacterial infection of the small intestine\nMedical condition&lt;templatestyles src=\"Template:Infobox/styles-images.css\" /&gt;\nCholera () is an infection of the small intestine by some strains of the bacterium \"Vibrio cholerae\". Symptoms may range from none, to mild, to severe. The classic symptom is large amounts of watery diarrhea lasting a few days. Vomiting and muscle cramps may also occur. Diarrhea can be so severe that it leads within hours to severe dehydration and electrolyte imbalance. This can in turn result in sunken eyes, cold or cyanotic skin, decreased skin elasticity, wrinkling of the hands and feet, and, in severe cases, death. Symptoms start two hours to five days after exposure.\nCholera is caused by a number of types of \"Vibrio cholerae\", with some types producing more severe disease than others. It is spread mostly by unsafe water and unsafe food that has been contaminated with human feces containing the bacteria. Undercooked shellfish is a common source. Humans are the only known host for the bacteria. Risk factors for the disease include poor sanitation, insufficient clean drinking water, and poverty. Cholera can be diagnosed by a stool test, or a rapid dipstick test, although the dipstick test is less accurate.\nPrevention methods against cholera include improved sanitation and access to clean water. Cholera vaccines that are given by mouth provide reasonable protection for about six months, and confer the added benefit of protecting against another type of diarrhea caused by \"E.\u00a0coli\". In 2017, the US Food and Drug Administration (FDA) approved a single-dose, live, oral cholera vaccine called Vaxchora for adults aged 18\u201364 who are travelling to an area of active cholera transmission. It offers limited protection to young children. People who survive an episode of cholera have long-lasting immunity for at least three years (the period tested).\nThe primary treatment for affected individuals is oral rehydration salts (ORS), the replacement of fluids and electrolytes by using slightly sweet and salty solutions. Rice-based solutions are preferred. In children, zinc supplementation has also been found to improve outcomes. In severe cases, intravenous fluids, such as Ringer's lactate, may be required, and antibiotics may be beneficial. The choice of antibiotic is aided by antibiotic sensitivity testing.\nCholera continues to affect an estimated 3\u20135\u00a0million people worldwide and causes 28,800\u2013130,000\u00a0deaths a year. To date, seven cholera pandemics have occurred, with the most recent beginning in 1961, and continuing today. The illness is rare in high-income countries, and affects children most severely. Cholera occurs as both outbreaks and chronically in certain areas. Areas with an ongoing risk of disease include Africa and Southeast Asia. The risk of death among those affected is usually less than 5%, given improved treatment, but may be as high as 50% without such access to treatment. Descriptions of cholera are found as early as the 5th century BCE in Sanskrit literature. In Europe, cholera was a term initially used to describe any kind of gastroenteritis, and was not used for this disease until the early 19th century. The study of cholera in England by John Snow between 1849 and 1854 led to significant advances in the field of epidemiology because of his insights about transmission via contaminated water, and a map of the same was the first recorded incidence of epidemiological tracking. \nSigns and symptoms.\nThe primary symptoms of cholera are profuse diarrhea and vomiting of clear fluid. These symptoms usually start suddenly, half a day to five days after ingestion of the bacteria. The diarrhea is frequently described as \"rice water\" in nature and may have a fishy odor. An untreated person with cholera may produce of diarrhea a day. Severe cholera, without treatment, kills about half of affected individuals. If the severe diarrhea is not treated, it can result in life-threatening dehydration and electrolyte imbalances. Estimates of the ratio of asymptomatic to symptomatic infections have ranged from 3 to 100. Cholera has been nicknamed the \"blue death\" because a person's skin may turn bluish-gray from extreme loss of fluids.\nFever is rare and should raise suspicion for secondary infection. Patients can be lethargic and might have sunken eyes, dry mouth, cold clammy skin, or wrinkled hands and feet. Kussmaul breathing, a deep and labored breathing pattern, can occur because of acidosis from stool bicarbonate losses and lactic acidosis associated with poor perfusion. Blood pressure drops due to dehydration, peripheral pulse is rapid and thready, and urine output decreases with time. Muscle cramping and weakness, altered consciousness, seizures, or even coma due to electrolyte imbalances are common, especially in children.\nCause.\nTransmission.\nCholera bacteria have been found in shellfish and plankton.\nTransmission is usually through the fecal-oral route of contaminated food or water caused by poor sanitation. Most cholera cases in developed countries are a result of transmission by food, while in developing countries it is more often water. Food transmission can occur when people harvest seafood such as oysters in waters infected with sewage, as \"Vibrio cholerae\" accumulates in planktonic crustaceans and the oysters eat the zooplankton.\nPeople infected with cholera often have diarrhea, and disease transmission may occur if this highly liquid stool, colloquially referred to as \"rice-water\", contaminates water used by others. A single diarrheal event can cause a one-million fold increase in numbers of \"V.\u00a0cholerae\" in the environment. The source of the contamination is typically other people with cholera when their untreated diarrheal discharge is allowed to get into waterways, groundwater or drinking water supplies. Drinking any contaminated water and eating any foods washed in the water, as well as shellfish living in the affected waterway, can cause a person to contract an infection. Cholera is rarely spread directly from person to person.\n\"V. cholerae\" also exists outside the human body in natural water sources, either by itself or through interacting with phytoplankton, zooplankton, or biotic and abiotic detritus. Drinking such water can also result in the disease, even without prior contamination through fecal matter. Selective pressures exist however in the aquatic environment that may reduce the virulence of \"V.\u00a0cholerae\". Specifically, animal models indicate that the transcriptional profile of the pathogen changes as it prepares to enter an aquatic environment. This transcriptional change results in a loss of ability of \"V.\u00a0cholerae\" to be cultured on standard media, a phenotype referred to as 'viable but non-culturable' (VBNC) or more conservatively 'active but non-culturable' (ABNC). One study indicates that the culturability of \"V.\u00a0cholerae\" drops 90% within 24 hours of entering the water, and furthermore that this loss in culturability is associated with a loss in virulence.\nBoth toxic and non-toxic strains exist. Non-toxic strains can acquire toxicity through a temperate bacteriophage.\nSusceptibility.\nAbout 100million bacteria must typically be ingested to cause cholera in a normal healthy adult. This dose, however, is less in those with lowered gastric acidity (for instance those using proton pump inhibitors). Children are also more susceptible, with two- to four-year-olds having the highest rates of infection. Individuals' susceptibility to cholera is also affected by their blood type, with those with type O blood being the most susceptible. Persons with lowered immunity, such as persons with AIDS or malnourished children, are more likely to develop a severe case if they become infected. Any individual, even a healthy adult in middle age, can undergo a severe case, and each person's case should be measured by the loss of fluids, preferably in consultation with a professional health care provider.\nThe cystic fibrosis genetic mutation known as delta-F508 in humans has been said to maintain a selective heterozygous advantage: heterozygous carriers of the mutation (who are not affected by cystic fibrosis) are more resistant to \"V.\u00a0cholerae\" infections. In this model, the genetic deficiency in the cystic fibrosis transmembrane conductance regulator channel proteins interferes with bacteria binding to the intestinal epithelium, thus reducing the effects of an infection.\nMechanism.\nWhen consumed, most bacteria do not survive the acidic conditions of the human stomach. The few surviving bacteria conserve their energy and stored nutrients during the passage through the stomach by shutting down protein production. When the surviving bacteria exit the stomach and reach the small intestine, they must propel themselves through the thick mucus that lines the small intestine to reach the intestinal walls where they can attach and thrive.\nOnce the cholera bacteria reach the intestinal wall, they no longer need the flagella to move. The bacteria stop producing the protein flagellin to conserve energy and nutrients by changing the mix of proteins that they express in response to the changed chemical surroundings. On reaching the intestinal wall, \"V.\u00a0cholerae\" start producing the toxic proteins that give the infected person a watery diarrhea. This carries the multiplying new generations of \"V.\u00a0cholerae\" bacteria out into the drinking water of the next host if proper sanitation measures are not in place.\nThe cholera toxin (CTX or CT) is an oligomeric complex made up of six protein subunits: a single copy of the A subunit (part A), and five copies of the B subunit (part B), connected by a disulfide bond. The five B subunits form a five-membered ring that binds to GM1 gangliosides on the surface of the intestinal epithelium cells. The A1 portion of the A subunit is an enzyme that ADP-ribosylates G proteins, while the A2 chain fits into the central pore of the B subunit ring. Upon binding, the complex is taken into the cell via receptor-mediated endocytosis. Once inside the cell, the disulfide bond is reduced, and the A1 subunit is freed to bind with a human partner protein called ADP-ribosylation factor 6 (Arf6). Binding exposes its active site, allowing it to permanently ribosylate the Gs alpha subunit of the heterotrimeric G protein. This results in constitutive cAMP production, which in turn leads to the secretion of water, sodium, potassium, and bicarbonate into the lumen of the small intestine and rapid dehydration. The gene encoding the cholera toxin was introduced into \"V.\u00a0cholerae\" by horizontal gene transfer. Virulent strains of \"V.\u00a0cholerae\" carry a variant of a temperate bacteriophage called CTX\u03c6.\nMicrobiologists have studied the genetic mechanisms by which the \"V.\u00a0cholerae\" bacteria turn off the production of some proteins and turn on the production of other proteins as they respond to the series of chemical environments they encounter, passing through the stomach, through the mucous layer of the small intestine, and on to the intestinal wall. Of particular interest have been the genetic mechanisms by which cholera bacteria turn on the protein production of the toxins that interact with host cell mechanisms to pump chloride ions into the small intestine, creating an ionic pressure which prevents sodium ions from entering the cell. The chloride and sodium ions create a salt-water environment in the small intestines, which through osmosis can pull up to six liters of water per day through the intestinal cells, creating the massive amounts of diarrhea. The host can become rapidly dehydrated unless treated properly.\nBy inserting separate, successive sections of \"V.\u00a0cholerae\" DNA into the DNA of other bacteria, such as \"E. coli\" that would not naturally produce the protein toxins, researchers have investigated the mechanisms by which \"V.\u00a0cholerae\" responds to the changing chemical environments of the stomach, mucous layers, and intestinal wall. Researchers have discovered a complex cascade of regulatory proteins controls expression of \"V.\u00a0cholerae\" virulence determinants. In responding to the chemical environment at the intestinal wall, the \"V.\u00a0cholerae\" bacteria produce the TcpP/TcpH proteins, which, together with the ToxR/ToxS proteins, activate the expression of the ToxT regulatory protein. ToxT then directly activates expression of virulence genes that produce the toxins, causing diarrhea in the infected person and allowing the bacteria to colonize the intestine. Current research aims at discovering \"the signal that makes the cholera bacteria stop swimming and start to colonize (that is, adhere to the cells of) the small intestine.\"\nGenetic structure.\nAmplified fragment length polymorphism fingerprinting of the pandemic isolates of \"V.\u00a0cholerae\" has revealed variation in the genetic structure. Two clusters have been identified: Cluster I and Cluster II. For the most part, Cluster I consists of strains from the 1960s and 1970s, while Cluster II largely contains strains from the 1980s and 1990s, based on the change in the clone structure. This grouping of strains is best seen in the strains from the African continent.\nAntibiotic resistance.\nIn many areas of the world, antibiotic resistance is increasing within cholera bacteria. In Bangladesh, for example, most cases are resistant to tetracycline, trimethoprim-sulfamethoxazole, and erythromycin. Rapid diagnostic assay methods are available for the identification of multi-drug resistant cases. New generation antimicrobials have been discovered which are effective against cholera bacteria in \"in vitro\" studies.\nDiagnosis.\nA rapid dipstick test is available to determine the presence of \"V.\u00a0cholerae\". In those samples that test positive, further testing should be done to determine antibiotic resistance. In epidemic situations, a clinical diagnosis may be made by taking a patient history and doing a brief examination. Treatment via hydration and over-the-counter hydration solutions can be started without or before confirmation by laboratory analysis, especially where cholera is a common problem.\nStool and swab samples collected in the acute stage of the disease, before antibiotics have been administered, are the most useful specimens for laboratory diagnosis. If an epidemic of cholera is suspected, the most common causative agent is \"V.\u00a0cholerae\" O1. If \"V.\u00a0cholerae\" serogroup O1 is not isolated, the laboratory should test for \"V.\u00a0cholerae\" O139. However, if neither of these organisms is isolated, it is necessary to send stool specimens to a reference laboratory.\nInfection with \"V.\u00a0cholerae\" O139 should be reported and handled in the same manner as that caused by \"V.\u00a0cholerae\" O1. The associated diarrheal illness should be referred to as cholera and must be reported in the United States.\nPrevention.\nThe World Health Organization (WHO) recommends focusing on prevention, preparedness, and response to combat the spread of cholera. They also stress the importance of an effective surveillance system. Governments can play a role in all of these areas.\nWater, sanitation and hygiene.\nAlthough cholera may be life-threatening, prevention of the disease is normally straightforward if proper sanitation practices are followed. In developed countries, due to their nearly universal advanced water treatment and sanitation practices, cholera is rare. For example, the last major outbreak of cholera in the United States occurred in 1910\u20131911. Cholera is mainly a risk in developing countries in those areas where access to WASH (water, sanitation and hygiene) infrastructure is still inadequate.\nEffective sanitation practices, if instituted and adhered to in time, are usually sufficient to stop an epidemic. There are several points along the cholera transmission path at which its spread may be halted:\nHandwashing with soap or ash after using a toilet and before handling food or eating is also recommended for cholera prevention by WHO Africa.\nSurveillance.\nSurveillance and prompt reporting allow for containing cholera epidemics rapidly. Cholera exists as a seasonal disease in many endemic countries, occurring annually mostly during rainy seasons. Surveillance systems can provide early alerts to outbreaks, therefore leading to coordinated response and assist in preparation of preparedness plans. Efficient surveillance systems can also improve the risk assessment for potential cholera outbreaks. Understanding the seasonality and location of outbreaks provides guidance for improving cholera control activities for the most vulnerable. For prevention to be effective, it is important that cases be reported to national health authorities.\nVaccination.\nSpanish physician Jaume Ferran i Clua developed the first successful cholera inoculation in 1885, the first to immunize humans against a bacterial disease. His vaccine and inoculation was rather controversial and was rejected by his peers and several investigation commissions but it ended up demonstrating its effectiveness and being recognized for it: out of the 30 thousand people he vaccinated only 54 died. Russian-French bacteriologist Waldemar Haffkine also developed a human cholera vaccine in July 1892. He conducted a massive inoculation program in British India.\nPersons who survive an episode of cholera have long-lasting immunity for at least 3 years (the period tested). A number of safe and effective oral vaccines for cholera are available. The World Health Organization (WHO) has three prequalified oral cholera vaccines (OCVs): Dukoral, Sanchol, and Euvichol. Dukoral, an orally administered, inactivated whole-cell vaccine, has an overall efficacy of about 52% during the first year after being given and 62% in the second year, with minimal side effects. It is available in over 60 countries. However, it is not currently recommended by the Centers for Disease Control and Prevention (CDC) for most people traveling from the United States to endemic countries. The vaccine that the US Food and Drug Administration (FDA) recommends, Vaxchora, is an oral attenuated live vaccine, that is effective for adults aged 18\u201364 as a single dose.\nOne injectable vaccine was found to be effective for two to three years. The protective efficacy was 28% lower in children less than five years old. However, as of 2010[ [update]], it has limited availability. Work is under way to investigate the role of mass vaccination. The WHO recommends immunization of high-risk groups, such as children and people with HIV, in countries where this disease is endemic. If people are immunized broadly, herd immunity results, with a decrease in the amount of contamination in the environment.\nWHO recommends that oral cholera vaccination be considered in areas where the disease is endemic (with seasonal peaks), as part of the response to outbreaks, or in a humanitarian crisis during which the risk of cholera is high. OCV has been recognized as an adjunct tool for prevention and control of cholera. The WHO has prequalified three bivalent cholera vaccines\u2014Dukoral (SBL Vaccines), containing a non-toxic B-subunit of cholera toxin and providing protection against \"V.\u00a0cholerae\" O1; and two vaccines developed using the same transfer of technology\u2014ShanChol (Shantha Biotec) and Euvichol (EuBiologics Co.), which have bivalent O1 and O139 oral killed cholera vaccines. Oral cholera vaccination could be deployed in a diverse range of situations from cholera-endemic areas and locations of humanitarian crises, but no clear consensus exists.\nSari filtration.\nDeveloped for use in Bangladesh, the \"sari filter\" is a simple and cost-effective appropriate technology method for reducing the contamination of drinking water. Used sari cloth is preferable but other types of used cloth can be used with some effect, though the effectiveness will vary significantly. Used cloth is more effective than new cloth, as the repeated washing reduces the space between the fibers. Water collected in this way has a greatly reduced pathogen count\u2014though it will not necessarily be perfectly safe, it is an improvement for poor people with limited options. In Bangladesh this practice was found to decrease rates of cholera by nearly half. It involves folding a \"sari\" four to eight times. Between uses the cloth should be rinsed in clean water and dried in the sun to kill any bacteria on it. A nylon cloth appears to work as well but is not as affordable.\nTreatment.\nContinued eating speeds the recovery of normal intestinal function. The WHO recommends this generally for cases of diarrhea no matter what the underlying cause. A CDC training manual specifically for cholera states: \"Continue to breastfeed your baby if the baby has watery diarrhea, even when traveling to get treatment. Adults and older children should continue to eat frequently.\"\nFluids.\nThe most common error in caring for patients with cholera is to underestimate the speed\nand volume of fluids required. In most cases, cholera can be successfully treated with oral rehydration therapy (ORT), which is highly effective, safe, and simple to administer. Rice-based solutions are preferred to glucose-based ones due to greater efficiency. In severe cases with significant dehydration, intravenous rehydration may be necessary. Ringer's lactate is the preferred solution, often with added potassium. Large volumes and continued replacement until diarrhea has subsided may be needed. Ten percent of a person's body weight in fluid may need to be given in the first two to four hours. This method was first tried on a mass scale during the Bangladesh Liberation War, and was found to have much success. Despite widespread beliefs, fruit juices and commercial fizzy drinks like cola are not ideal for rehydration of people with serious infections of the intestines, and their excessive sugar content may even harm water uptake.\nIf commercially produced oral rehydration solutions are too expensive or difficult to obtain, solutions can be made. One such recipe calls for 1 liter of boiled water, 1/2 teaspoon of salt, 6 teaspoons of sugar, and added mashed banana for potassium and to improve taste.\nElectrolytes.\nAs there frequently is initially acidosis, the potassium level may be normal, even though large losses have occurred. As the dehydration is corrected, potassium levels may decrease rapidly, and thus need to be replaced. This is best done by Oral Rehydration Solution (ORS).\nAntibiotics.\nAntibiotic treatments for one to three days shorten the course of the disease and reduce the severity of the symptoms. Use of antibiotics also reduces fluid requirements. People will recover without them, however, if sufficient hydration is maintained. The WHO only recommends antibiotics in those with severe dehydration.\nDoxycycline is typically used first line, although some strains of \"V.\u00a0cholerae\" have shown resistance. Testing for resistance during an outbreak can help determine appropriate future choices. Other antibiotics proven to be effective include cotrimoxazole, erythromycin, tetracycline, chloramphenicol, and furazolidone. Fluoroquinolones, such as ciprofloxacin, also may be used, but resistance has been reported.\nAntibiotics improve outcomes in those who are both severely and not severely dehydrated. Azithromycin and tetracycline may work better than doxycycline or ciprofloxacin.\nZinc supplementation.\nIn Bangladesh zinc supplementation reduced the duration and severity of diarrhea in children with cholera when given with antibiotics and rehydration therapy as needed. It reduced the length of disease by eight hours and the amount of diarrhea stool by 10%. Supplementation appears to be also effective in both treating and preventing infectious diarrhea due to other causes among children in the developing world.\nPrognosis.\nIf people with cholera are treated quickly and properly, the mortality rate is less than 1%; however, with untreated cholera, the mortality rate rises to 50\u201360%.\nFor certain genetic strains of cholera, such as the one present during the 2010 epidemic in Haiti and the 2004 outbreak in India, death can occur within two hours of becoming ill.\nEpidemiology.\nCholera affects an estimated 2.8\u00a0million people worldwide, and causes approximately 95,000\u00a0deaths a year (uncertainty range: 21,000\u2013143,000) as of 2015[ [update]]. This occurs mainly in the developing world.\nIn the early 1980s, death rates are believed to have still been higher than three million a year. It is difficult to calculate exact numbers of cases, as many go unreported due to concerns that an outbreak may have a negative impact on the tourism of a country. As of 2004, cholera remained both epidemic and endemic in many areas of the world.\nRecent major outbreaks are the 2010s Haiti cholera outbreak and the 2016\u20132022 Yemen cholera outbreak. In October 2016, an outbreak of cholera began in war-ravaged Yemen. WHO called it \"the worst cholera outbreak in the world\". In 2019, 93% of the reported 923,037 cholera cases were from Yemen (with 1911 deaths reported). Between September 2019 and September 2020, a global total of over 450,000 cases and over 900 deaths was reported; however, the accuracy of these numbers suffer from over-reporting from countries that report suspected cases (and not laboratory confirmed cases), as well as under-reporting from countries that do not report official cases (such as Bangladesh, India and Philippines).\nAlthough much is known about the mechanisms behind the spread of cholera, researchers still do not have a full understanding of what makes cholera outbreaks happen in some places and not others. Lack of treatment of human feces and lack of treatment of drinking water greatly facilitate its spread. Bodies of water have been found to serve as a reservoir of infection, and seafood shipped long distances can spread the disease.\nCholera had disappeared from the Americas for most of the 20th century, but it reappeared toward the end of that century, beginning with a severe outbreak in Peru. This was followed by the 2010s Haiti cholera outbreak and another outbreak of cholera in Haiti amid the 2018\u20132023 Haitian crisis. As of August 2021[ [update]] the disease is endemic in Africa and some areas of eastern and western Asia (Bangladesh, India and Yemen). Cholera is not endemic in Europe; all reported cases had a travel history to endemic areas.\nHistory of outbreaks.\nThe word cholera is from \"kholera\" from \u03c7\u03bf\u03bb\u03ae \"khol\u0113\" \"bile\". Cholera likely has its origins in the Indian subcontinent as evidenced by its prevalence in the region for centuries.\nReferences to cholera appear in the European literature as early as 1642, from the Dutch physician Jakob de Bondt's description in his De Medicina Indorum. (The \"Indorum\" of the title refers to the East Indies. He also gave first European descriptions of other diseases.) But at the time, the word \"cholera\" was historically used by European physicians to refer to any gastrointestinal upset resulting in yellow diarrhea. De Bondt thus used a common word already in regular use to describe the new disease. This was a frequent practice of the time. It was not until the 1830s that the name for severe yellow diarrhea changed in English from \"cholera\" to \"cholera morbus\" to differentiate it from what was then known as \"Asiatic cholera\", or that associated with origins in India and the East.\nEarly outbreaks in the Indian subcontinent are believed to have been the result of crowded, poor living conditions, as well as the presence of pools of still water, both of which provide ideal conditions for cholera to thrive. The disease first spread by travelers along trade routes (land and sea) to Russia in 1817, later to the rest of Europe, and from Europe to North America and the rest of the world, (hence the name \"Asiatic cholera\"). Seven cholera pandemics have occurred since the early 19th century; the first one did not reach the Americas. The seventh pandemic originated in Indonesia in 1961.\nThe first cholera pandemic occurred in the Bengal region of India, near Calcutta starting in 1817 through 1824. The disease dispersed from India to Southeast Asia, the Middle East, Europe, and Eastern Africa. The movement of British Army and Navy ships and personnel is believed to have contributed to the range of the pandemic, since the ships carried people with the disease to the shores of the Indian Ocean, from Africa to Indonesia, and north to China and Japan.\nThe second pandemic lasted from 1826 to 1837 and particularly affected North America and Europe. Advancements in transport and global trade, and increased human migration, including soldiers, meant that more people were carrying the disease more widely.\nThe third pandemic erupted in 1846, persisted until 1860, extended to North Africa, and reached North and South America. It was introduced to North America at Quebec, Canada, via Irish immigrants from the Great Famine. In this pandemic, Brazil was affected for the first time.\nThe fourth pandemic lasted from 1863 to 1875, spreading from India to Naples and Spain, and reaching the United States at New Orleans, Louisiana in 1873. It spread throughout the Mississippi River system on the continent.\nThe fifth pandemic was from 1881 to 1896. It started in India and spread to Europe, Asia, and South America. The sixth pandemic ran from 1899 to 1923. These epidemics had a lower number of fatalities because physicians and researchers had a greater understanding of the cholera bacteria. Egypt, the Arabian peninsula, Persia, India, and the Philippines were hit hardest during these epidemics. Other areas, such as Germany in 1892 (primarily the city of Hamburg, where more than 8,600 people died) and Naples from 1910 to 1911, also had severe outbreaks.\nThe seventh pandemic originated in 1961 in Indonesia and is marked by the emergence of a new strain, nicknamed \"El Tor\", which still persists (as of 2018[ [update]]) in developing countries. This pandemic had initially subsided about 1975 and was thought to have ended, but, as noted, it has persisted. There were a rise in cases in the 1990s and since.\nCholera became widespread in the 19th century. Since then it has killed tens of millions of people. In Russia alone, between 1847 and 1851, more than one million people died from the disease. It killed 150,000 Americans during the second pandemic. Between 1900 and 1920, perhaps eight million people died of cholera in India. Cholera officially became the first reportable disease in the United States due to the significant effects it had on health. John Snow, in England, in 1854 was the first to identify the importance of contaminated water as its source of transmission. Cholera is now no longer considered a pressing health threat in Europe and North America due to filtering and chlorination of water supplies, but it still strongly affects populations in developing countries.\nIn the past, vessels flew a yellow quarantine flag if any crew members or passengers had cholera. No one aboard a vessel flying a yellow flag would be allowed ashore for an extended period, typically 30 to 40 days.\nHistorically many different claimed remedies have existed in folklore. Many of the older remedies were based on the miasma theory, that the disease was transmitted by bad air. Some believed that abdominal chilling made one more susceptible, and flannel and cholera belts were included in army kits. In the 1854\u20131855 outbreak in Naples, homeopathic camphor was used according to Hahnemann. Dr. Hahnemann laid down three main remedies that would be curative in that disease; in early and simple cases camphor; in later stages with excessive cramping, cuprum or with excessive evacuations and profuse cold sweat, veratrum album. These are the Trio Cholera remedies used by homoeopaths around the world.\nT. J. Ritter's \"Mother's Remedies\" book lists tomato syrup as a home remedy from northern America. Elecampane was recommended in the United Kingdom, according to William Thomas Fernie. The first effective human vaccine was developed in 1885, and the first effective antibiotic was developed in 1948.\nCholera cases are much less frequent in developed countries where governments have helped to establish water sanitation practices and effective medical treatments. In the 19th century the United States, for example, had a severe cholera problem similar to those in some developing countries. It had three large cholera outbreaks in the 1800s, which can be attributed to \"Vibrio cholerae\"'s spread through interior waterways such as the Erie Canal and the extensive Mississippi River valley system, as well as the major ports along the Eastern Seaboard and their cities upriver. The island of Manhattan in New York City touches the Atlantic Ocean, where cholera collected from river waters and ship discharges just off the coast. At this time, New York City did not have as effective a sanitation system as it developed in the later 20th century, so cholera spread through the city's water supply.\nCholera morbus is a historical term that was used to refer to gastroenteritis rather than specifically to what is now defined as the disease of cholera.\nResearch.\nOne of the major contributions to fighting cholera was made by the physician and pioneer medical scientist John Snow (1813\u20131858), who in 1854 found a link between cholera and contaminated drinking water. Dr. Snow proposed a microbial origin for epidemic cholera in 1849. In his major \"state of the art\" review of 1855, he proposed a substantially complete and correct model for the cause of the disease. In two pioneering epidemiological field studies, he was able to demonstrate human sewage contamination was the most probable disease vector in two major epidemics in London in 1854. His model was not immediately accepted, but it was increasingly seen as plausible as medical microbiology developed over the next 30 years or so. For his work on cholera, John Snow is often regarded as the \"Father of Epidemiology\".\nThe bacterium was isolated in 1854 by Italian anatomist Filippo Pacini, but its exact nature and his results were not widely known. In the same year, the Catalan Joaquim Balcells i Pascual discovered the bacterium. In 1856 Ant\u00f3nio Augusto da Costa Sim\u00f5es and Jos\u00e9 Ferreira de Macedo Pinto, two Portuguese researchers, are believed to have done the same.\nBetween the mid-1850s and the 1900s, cities in developed nations made massive investment in clean water supply and well-separated sewage treatment infrastructures. This eliminated the threat of cholera epidemics from the major developed cities in the world. In 1883, Robert Koch identified \"V.\u00a0cholerae\" with a microscope as the bacillus causing the disease.\nHemendra Nath Chatterjee, a Bengali scientist, was the first to formulate and demonstrate the effectiveness of oral rehydration salt (ORS) to treat diarrhea. In his 1953 paper, published in \"The Lancet\", he states that promethazine can stop vomiting during cholera and then oral rehydration is possible. The formulation of the fluid replacement solution was 4\u00a0g of sodium chloride, 25\u00a0g of glucose and 1000\u00a0ml of water.\nIndian medical scientist Sambhu Nath De discovered the cholera toxin, the \"animal model of cholera\", and successfully demonstrated the method of transmission of cholera pathogen \"Vibrio cholerae\".\nRobert Allan Phillips, working at US Naval Medical Research Unit Two in Southeast Asia, evaluated the pathophysiology of the disease using modern laboratory chemistry techniques. He developed a protocol for rehydration. His research led the Lasker Foundation to award him its prize in 1967.\nMore recently, in 2002, Alam, \"et al.\", studied stool samples from patients at the International Centre for Diarrhoeal Disease in Dhaka, Bangladesh. From the various experiments they conducted, the researchers found a correlation between the passage of \"V.\u00a0cholerae\" through the human digestive system and an increased infectivity state. Furthermore, the researchers found the bacterium creates a hyperinfected state where genes that control biosynthesis of amino acids, iron uptake systems, and formation of periplasmic nitrate reductase complexes were induced just before defecation. These induced characteristics allow the cholera vibrios to survive in the \"rice water\" stools, an environment of limited oxygen and iron, of patients with a cholera infection.\nGlobal Strategy.\nIn 2017, the WHO launched the \"Ending Cholera: a global roadmap to 2030\" strategy which aims to reduce cholera deaths by 90% by 2030. The strategy was developed by the Global Task Force on Cholera Control (GTFCC) which develops country-specific plans and monitors progress. The approach to achieve this goal combines surveillance, water sanitation, rehydration treatment and oral vaccines. Specifically, the control strategy focuses on three approaches: i) early detection and response to outbreaks to contain outbreaks, ii) stopping cholera transmission through improved sanitation and vaccines in hotspots, and iii) a global framework for cholera control through the GTFCC.\nThe WHO and the GTFCC do not consider global cholera eradication a viable goal. Even though humans are the only host of cholera, the bacterium can persist in the environment without a human host. While global eradication is not possible, elimination of human to human transmission may be possible. Local elimination is possible, which has been underway most recently during the 2010s Haiti cholera outbreak. Haiti aims to achieve certification of elimination by 2022.\nThe GTFCC targets 47 countries, 13 of which have established vaccination campaigns.\nSociety and culture.\nHealth policy.\nIn many developing countries, cholera still reaches its victims through contaminated water sources, and countries without proper sanitation techniques have greater incidence of the disease. Governments can play a role in this. In 2008, for example, the Zimbabwean cholera outbreak was due partly to the government's role, according to a report from the James Baker Institute. The Haitian government's inability to provide safe drinking water after the 2010 earthquake led to an increase in cholera cases as well.\nSimilarly, South Africa's cholera outbreak was exacerbated by the government's policy of privatizing water programs. The wealthy elite of the country were able to afford safe water while others had to use water from cholera-infected rivers.\nAccording to Rita R. Colwell of the James Baker Institute, if cholera does begin to spread, government preparedness is crucial. A government's ability to contain the disease before it extends to other areas can prevent a high death toll and the development of an epidemic or even pandemic. Effective disease surveillance can ensure that cholera outbreaks are recognized as soon as possible and dealt with appropriately. Oftentimes, this will allow public health programs to determine and control the cause of the cases, whether it is unsanitary water or seafood that have accumulated a lot of \"Vibrio cholerae\" specimens. Having an effective surveillance program contributes to a government's ability to prevent cholera from spreading. In the year 2000 in the state of Kerala in India, the Kottayam district was determined to be \"Cholera-affected\"; this pronouncement led to task forces that concentrated on educating citizens with 13,670 information sessions about human health. These task forces promoted the boiling of water to obtain safe water, and provided chlorine and oral rehydration salts. Ultimately, this helped to control the spread of the disease to other areas and minimize deaths. On the other hand, researchers have shown that most of the citizens infected during the 1991 cholera outbreak in Bangladesh lived in rural areas, and were not recognized by the government's surveillance program. This inhibited physicians' abilities to detect cholera cases early.\nAccording to Colwell, the quality and inclusiveness of a country's health care system affects the control of cholera, as it did in the Zimbabwean cholera outbreak. While sanitation practices are important, when governments respond quickly and have readily available vaccines, the country will have a lower cholera death toll. Affordability of vaccines can be a problem; if the governments do not provide vaccinations, only the wealthy may be able to afford them and there will be a greater toll on the country's poor. The speed with which government leaders respond to cholera outbreaks is important.\nBesides contributing to an effective or declining public health care system and water sanitation treatments, government can have indirect effects on cholera control and the effectiveness of a response to cholera. A country's government can impact its ability to prevent disease and control its spread. A speedy government response backed by a fully functioning health care system and financial resources can prevent cholera's spread. This limits cholera's ability to cause death, or at the very least a decline in education, as children are kept out of school to minimize the risk of infection. Inversely, poor government response can lead to civil unrest and cholera riots.\nIn popular culture.\nUnlike tuberculosis (\"consumption\") which in literature and the arts was often romanticized as a disease of denizens of the demimonde or those with an artistic temperament, cholera is a disease which almost entirely affects the poor living in unsanitary conditions. This, and the unpleasant course of the disease \u2013 which includes voluminous \"rice-water\" diarrhea, the hemorrhaging of liquids from the mouth, and violent muscle contractions which continue even after death \u2013 has discouraged the disease from being romanticized, or even being factually presented in popular culture.\nCountry examples.\nZambia.\nIn Zambia, widespread cholera outbreaks have occurred since 1977, most commonly in the capital city of Lusaka. In 2017, an outbreak of cholera was declared in Zambia after laboratory confirmation of \"Vibrio cholerae\" O1, biotype El Tor, serotype Ogawa, from stool samples from two patients with acute watery diarrhea. There was a rapid increase in the number of cases from several hundred cases in early December 2017 to approximately 2,000 by early January 2018. With intensification of the rains, new cases increased on a daily basis reaching a peak on the first week of January 2018 with over 700 cases reported.\nIn collaboration with partners, the Zambia Ministry of Health (MoH) launched a multifaceted public health response that included increased chlorination of the Lusaka municipal water supply, provision of emergency water supplies, water quality monitoring and testing, enhanced surveillance, epidemiologic investigations, a cholera vaccination campaign, aggressive case management and health care worker training, and laboratory testing of clinical samples.\nThe Zambian Ministry of Health implemented a reactive one-dose Oral Cholera Vaccine (OCV) campaign in April 2016 in three Lusaka compounds, followed by a pre-emptive second-round in December.\nNigeria.\nIn June 2024, the Nigeria Centre for Disease Control and Prevention (NCDC) announced a total of 1,141 suspected and 65 confirmed cases of cholera with 30 deaths from 96 Local Government Areas (LGAs) in 30 states of the country. NCDC, in its public health advisory, said Abia, Bayelsa, Bauchi, Cross River, Delta, Imo, Katsina, Lagos, Nasarawa and Zamfara states were the 10 states that contributed 90 percent of the burden of cholera in the country at the time.\nIndia.\nThe city of Kolkata, India, in the state of West Bengal in the Ganges delta, has been described as the \"homeland of cholera\", with regular outbreaks and pronounced seasonality. In India, where the disease is endemic, cholera outbreaks occur every year between dry seasons and rainy seasons. India is also characterized by high population density, unsafe drinking water, open drains, and poor sanitation, which provide an optimal niche for survival, sustenance, and transmission of \"Vibrio cholerae\".\nDemocratic Republic of Congo.\nIn Goma in the Democratic Republic of Congo, cholera has left an enduring mark on human and medical history. Cholera pandemics in the 19th and 20th centuries led to the growth of epidemiology as a science and in recent years it has continued to press advances in the concepts of disease ecology, basic membrane biology, and transmembrane signaling and in the use of scientific information and treatment design.\nExplanatory notes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "7592", "revid": "50768835", "url": "https://en.wikipedia.org/wiki?curid=7592", "title": "Caldera", "text": "Cauldron-like volcanic feature formed by the emptying of a magma chamber\nA caldera ( ) is a large cauldron-like hollow that forms shortly after the emptying of a magma chamber in a volcanic eruption. The ejection of large volumes of magma in a short time can upset the integrity of a magma chamber's structure by in effect removing much of the chamber's filling material. The walls and ceiling of a chamber may now not be able to support its own weight and any substrate or rock resting above. The ground surface then collapses into the emptied or partially emptied magma chamber, leaving a large depression at the surface that may have a diameter of dozens of kilometers. Although sometimes described as a crater, the feature is actually a type of sinkhole, as it is formed through subsidence and collapse rather than an explosion or impact. Compared to the thousands of volcanic eruptions that occur over the course of a century, the formation of a caldera is a rare event, occurring only a few times within a given window of 100 years. Only nine caldera-forming collapses are known to have occurred between 1911 and 2022, with the caldera collapses at K\u012blauea, Hawaii, in 2018 and Hunga Tonga\u2013Hunga Ha\u02bbapai in 2022 being the most recent. Volcanoes that have formed a caldera are sometimes described as \"caldera volcanoes\".\nEtymology.\nThe term \"caldera\" comes from Spanish ', and Latin ', meaning \"cooking pot\". In some texts the English term \"cauldron\" is also used, though in more recent work the term \"cauldron\" refers to a caldera that has been deeply eroded to expose the beds under the caldera floor. The term \"caldera\" was introduced into the geological vocabulary by the German geologist Leopold von Buch when he published his memoirs of his 1815 visit to the Canary Islands, where he first saw the Las Ca\u00f1adas caldera on Tenerife, with Mount Teide dominating the landscape, and then the Caldera de Taburiente on La Palma.\nCaldera formation.\nA collapse is triggered by the emptying of the magma chamber beneath the volcano, sometimes as the result of a large explosive volcanic eruption (see Tambora in 1815), but also during effusive eruptions on the flanks of a volcano (see Piton de la Fournaise in 2007) or in a connected fissure system (see B\u00e1r\u00f0arbunga in 2014\u20132015). If enough magma is ejected, the emptied chamber is unable to support the weight of the volcanic edifice above it. A roughly circular fracture, the \"ring fault\", develops around the edge of the chamber. Ring fractures serve as feeders for fault intrusions, which are also known as ring dikes. Secondary volcanic vents may form above the ring fracture. As the magma chamber empties, the center of the volcano within the ring fracture begins to collapse. The collapse may occur as the result of a single cataclysmic eruption, or it may occur in stages as the result of a series of eruptions. The total area that collapses may be hundreds of square kilometers.\nMineralization in calderas.\nSome calderas are known to host rich ore deposits. Metal-rich fluids can circulate through the caldera, forming hydrothermal ore deposits of metals such as lead, silver, gold, mercury, lithium, and uranium. One of the world's best-preserved mineralized calderas is the Sturgeon Lake Caldera in northwestern Ontario, Canada, which formed during the Neoarchean era about 2.7\u00a0billion years ago. In the San Juan volcanic field, ore veins were emplaced in fractures associated with several calderas, with the greatest mineralization taking place near the youngest and most silicic intrusions associated with each caldera.\nTypes of caldera.\nExplosive caldera eruptions.\nExplosive caldera eruptions are produced by a magma chamber whose magma is rich in silica. Silica-rich magma has a high viscosity, and therefore does not flow easily like basalt. The magma typically also contains a large amount of dissolved gases, up to 7 wt% for the most silica-rich magmas. When the magma approaches the surface of the Earth, the drop in confining pressure causes the trapped gases to rapidly bubble out of the magma, fragmenting the magma to produce a mixture of volcanic ash and other tephra with the very hot gases.\nThe mixture of ash and volcanic gases initially rises into the atmosphere as an eruption column. However, as the volume of erupted material increases, the eruption column is unable to entrain enough air to remain buoyant, and the eruption column collapses into a tephra fountain that falls back to the surface to form pyroclastic flows. Eruptions of this type can spread ash over vast areas, so that ash flow tuffs emplaced by silicic caldera eruptions are the only volcanic product with volumes rivaling those of flood basalts. For example, when Yellowstone Caldera last erupted some 650,000 years ago, it released about 1,000\u00a0km3 of material (as measured in dense rock equivalent (DRE)), covering a substantial part of North America in up to two metres of debris.\nEruptions forming even larger calderas are known, such as the La Garita Caldera in the San Juan Mountains of Colorado, where the Fish Canyon Tuff was blasted out in eruptions about 27.8\u00a0million years ago.\nThe caldera produced by such eruptions is typically filled in with tuff, rhyolite, and other igneous rocks. The caldera is surrounded by an outflow sheet of ash flow tuff (also called an ash flow sheet).\nIf magma continues to be injected into the collapsed magma chamber, the center of the caldera may be uplifted in the form of a \"resurgent dome\" such as is seen at the Valles Caldera, Lake Toba, the San Juan volcanic field, Cerro Gal\u00e1n, Yellowstone, and many other calderas.\nBecause a silicic caldera may erupt hundreds or even thousands of cubic kilometers of material in a single event, it can cause catastrophic environmental effects. Even small caldera-forming eruptions, such as Krakatoa in 1883 or Mount Pinatubo in 1991, may result in significant local destruction and a noticeable drop in temperature around the world. Large calderas may have even greater effects. The ecological effects of the eruption of a large caldera can be seen in the record of the Lake Toba eruption in Indonesia.\nAt some points in geological time, rhyolitic calderas have appeared in distinct clusters. The remnants of such clusters may be found in places such as the Eocene Rum Complex of Scotland, the San Juan Mountains of Colorado (formed during the Oligocene, Miocene, and Pliocene epochs) or the Saint Francois Mountain Range of Missouri (erupted during the Proterozoic eon).\nValles.\nFor their 1968 paper that first introduced the concept of a resurgent caldera to geology, R.L. Smith and R.A. Bailey chose the Valles caldera as their model. Although the Valles caldera is not unusually large, it is relatively young (1.25 million years old) and unusually well preserved, and it remains one of the best studied examples of a resurgent caldera. The ash flow tuffs of the Valles caldera, such as the Bandelier Tuff, were among the first to be thoroughly characterized.\nToba.\nAbout 74,000 years ago, this Indonesian volcano released about dense-rock equivalent of ejecta. This was the largest known eruption during the ongoing Quaternary period (the last 2.6\u00a0million years) and the largest known explosive eruption during the last 25\u00a0million years. In the late 1990s, anthropologist Stanley Ambrose proposed that a volcanic winter induced by this eruption reduced the human population to about 2,000\u201320,000 individuals, resulting in a population bottleneck. More recently, Lynn Jorde and Henry Harpending proposed that the human species was reduced to approximately 5,000\u201310,000 people. There is no direct evidence, however, that either theory is correct, and there is no evidence for any other animal decline or extinction, even in environmentally sensitive species. There is evidence that human habitation continued in India after the eruption.\nNon-explosive calderas.\nSome volcanoes, such as the large shield volcanoes K\u012blauea and Mauna Loa on the island of Hawaii, form calderas in a different fashion. The magma feeding these volcanoes is basalt, which is silica poor. As a result, the magma is much less viscous than the magma of a rhyolitic volcano, and the magma chamber is drained by large lava flows rather than by explosive events. The resulting calderas are also known as subsidence calderas and can form more gradually than explosive calderas. For instance, the caldera atop Fernandina Island collapsed in 1968 when parts of the caldera floor dropped .\nExtraterrestrial calderas.\nSince the early 1960s, it has been known that volcanism has occurred on other planets and moons in the Solar System. Through the use of crewed and uncrewed spacecraft, volcanism has been discovered on Venus, Mars, the Moon, and Io, a satellite of Jupiter. None of these worlds have plate tectonics, which contributes approximately 60% of the Earth's volcanic activity (the other 40% is attributed to hotspot volcanism). Caldera structure is similar on all of these planetary bodies, though the size varies considerably. The average caldera diameter on Venus is . The average caldera diameter on Io is close to , and the mode is ; Tvashtar Paterae is likely the largest caldera with a diameter of . The average caldera diameter on Mars is , smaller than Venus. Calderas on Earth are the smallest of all planetary bodies and vary from as a maximum.\nThe Moon.\nThe Moon has an outer shell of low-density crystalline rock that is a few hundred kilometers thick, which formed due to a rapid creation. The craters of the Moon have been well preserved through time and were once thought to have been the result of extreme volcanic activity, but are currently believed to have been formed by meteorites, nearly all of which took place in the first few hundred million years after the Moon formed. Around 500\u00a0million years afterward, the Moon's mantle was able to be extensively melted due to the decay of radioactive elements. Massive basaltic eruptions took place generally at the base of large impact craters. Also, eruptions may have taken place due to a magma reservoir at the base of the crust. This forms a dome, possibly the same morphology of a shield volcano where calderas universally are known to form. Although caldera-like structures are rare on the Moon, they are not completely absent. The Compton-Belkovich Volcanic Complex on the far side of the Moon is thought to be a caldera, possibly an ash-flow caldera.\nMars.\nThe volcanic activity of Mars is concentrated in two major provinces: Tharsis and Elysium. Each province contains a series of giant shield volcanoes that are similar to what we see on Earth and likely are the result of mantle hot spots. The surfaces are dominated by lava flows, and all have one or more collapse calderas. Mars has the tallest volcano in the Solar System, Olympus Mons, which is more than three times the height of Mount Everest, with a diameter of 520\u00a0km (323 miles). The summit of the mountain has six nested calderas.\nVenus.\nBecause there is no plate tectonics on Venus, heat is mainly lost by conduction through the lithosphere. This causes enormous lava flows, accounting for 80% of Venus' surface area. Many of the mountains are large shield volcanoes that range in size from in diameter and high. More than 80 of these large shield volcanoes have summit calderas averaging across.\nIo.\nIo, unusually, is heated by solid flexing due to the tidal influence of Jupiter and Io's orbital resonance with neighboring large moons Europa and Ganymede, which keep its orbit slightly eccentric. Unlike any of the planets mentioned, Io is continuously volcanically active. For example, the NASA \"Voyager 1\" and \"Voyager 2\" spacecraft detected nine erupting volcanoes while passing Io in 1979. Io has many calderas with diameters tens of kilometers across.\nExplanatory notes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "7593", "revid": "910180", "url": "https://en.wikipedia.org/wiki?curid=7593", "title": "Calculator", "text": "Electronic device used for calculations\nA calculator is typically a portable electronic device used to perform calculations, ranging from basic arithmetic to complex mathematics.\nThe first solid-state electronic calculator was created in the early 1960s. Pocket-sized devices became available in the 1970s, especially after the Intel 4004, the first microprocessor, was developed by Intel for the Japanese calculator company Busicom. Modern electronic calculators vary from cheap, give-away, credit-card-sized models to sturdy desktop models with built-in printers. They became popular in the mid-1970s as the incorporation of integrated circuits reduced their size and cost. By the end of that decade, prices had dropped to the point where a basic calculator was affordable to most and they became common in schools.\nIn addition to general-purpose calculators, there are those designed for specific markets. For example, there are scientific calculators, which include trigonometric and statistical calculations. Some calculators even have the ability to do computer algebra. Graphing calculators can be used to graph functions defined on the real line, or higher-dimensional Euclidean space. As of 2016[ [update]], basic calculators cost little, but scientific and graphing models tend to cost more.\nComputer operating systems as far back as early Unix have included interactive calculator programs such as dc and hoc, and interactive BASIC could be used to do calculations on most 1970s and 1980s home computers. Calculator functions are included in most smartphones, tablets, and personal digital assistant (PDA) type devices. With the very wide availability of smartphones and the like, dedicated hardware calculators, while still widely used, are less common than they once were. In 1986, calculators still represented an estimated 41% of the world's general-purpose hardware capacity to compute information. By 2007, this had diminished to less than 0.05%.\nDesign.\nInput.\nElectronic calculators contain a keyboard with buttons for digits and arithmetical operations; some even contain \"00\" and \"000\" buttons to make larger or smaller numbers easier to enter. Most basic calculators assign only one digit or operation on each button; however, in more specific calculators, a button can perform multi-function working with key combinations.\nDisplay output.\nCalculators usually have liquid-crystal displays (LCD) as output in place of historical light-emitting diode (LED) displays and vacuum fluorescent displays (VFD); details are provided in the section \"Technical improvements\".\nLarge-sized figures are often used to improve readability; while using decimal separator (usually a point rather than a comma) instead of or in addition to vulgar fractions. Various symbols for function commands may also be shown on the display. Fractions such as are displayed as decimal approximations, for example rounded to 0.33333333. Also, some fractions (such as , which is 0.14285714285714; to 14 significant figures) can be difficult to recognize in decimal form; as a result, many scientific calculators are able to work in vulgar fractions or mixed numbers.\nMemory.\nCalculators also have the ability to save numbers into computer memory. Basic calculators usually store only one number at a time; more specific types are able to store many numbers represented in variables. Usually these variables are named ans or ans(0). The variables can also be used for constructing formulas. Some models have the ability to extend memory capacity to store more numbers; the extended memory address is termed an array index.\nPower source.\nPower sources of calculators are batteries, solar cells or mains electricity (for old models), turning on with a switch or button. Some models even have no turn-off button but they provide some way to put off (for example, leaving no operation for a moment, covering solar cell exposure, or closing their lid). Crank-powered calculators were also common in the early computer era.\nKey layout.\nThe following keys are common to most pocket calculators. While the arrangement of the digits is standard, the positions of other keys vary from model to model; the illustration is an example.\nThe arrangement of digits on calculator and other numeric keypads with the -- keys two rows above the -- keys is derived from calculators and cash registers. It is notably different from the layout of telephone Touch-Tone keypads which have the -- keys on top and -- keys on the third row.\nInternal workings.\nIn general, a basic electronic calculator consists of the following components:\nClock rate of a processor chip refers to the frequency at which the central processing unit (CPU) is running. It is used as an indicator of the processor's speed, and is measured in \"clock cycles per second\" or hertz (Hz). For basic calculators, the speed can vary from a few hundred hertz to the kilohertz range.\nExample.\nA basic explanation as to how calculations are performed in a simple four-function calculator:\nTo perform the calculation 25 + 9, one presses keys in the following sequence on most calculators: \u00a0\u00a0\u00a0\u00a0.\n* When \u00a0 is entered, it is picked up by the scanning unit; the number 25 is encoded and sent to the X register;\n* Next, when the key is pressed, the \"addition\" instruction is also encoded and sent to the flag or the status register;\n* The second number is encoded and sent to the X register. This \"pushes\" (shifts) the first number out into the Y register;\n* When the key is pressed, a \"message\" (signal) from the flag or status register tells the permanent or non-volatile memory that the operation to be done is \"addition\";\n* The numbers in the X and Y registers are then loaded into the ALU and the calculation is carried out following instructions from the permanent or non-volatile memory;\n* The answer, 34 is sent (shifted) back to the X register. From there, it is converted by the binary decoder unit into a decimal number (usually binary-coded decimal), and then shown on the display panel.\nOther functions are usually performed using repeated additions or subtractions.\nNumeric representation.\nMost pocket calculators do all their calculations in binary-coded decimal (BCD) rather than binary. BCD is common in electronic systems where a numeric value is to be displayed, especially in systems consisting solely of digital logic, and not containing a microprocessor. By employing BCD, the manipulation of numerical data for display can be greatly simplified by treating each digit as a separate single sub-circuit. This matches much more closely the physical reality of display hardware\u2014a designer might choose to use a series of separate identical seven-segment displays to build a metering circuit, for example. If the numeric quantity were stored and manipulated as pure binary, interfacing to such a display would require complex circuitry. Therefore, in cases where the calculations are relatively simple, working throughout with BCD can lead to a simpler overall system than converting to and from binary. (For example, CDs keep the track number in BCD, limiting them to 99 tracks.)\nThe same argument applies when hardware of this type uses an embedded microcontroller or other small processor. Often, smaller code results when representing numbers internally in BCD format, since a conversion from or to binary representation can be expensive on such limited processors. For these applications, some small processors feature BCD arithmetic modes, which assist when writing routines that manipulate BCD quantities.\nWhere calculators have added functions (such as square root, or trigonometric functions), software algorithms are required to produce high precision results. Sometimes significant design effort is needed to fit all the desired functions in the limited memory space available in the calculator chip, with acceptable calculation time.\nHistory.\nPrecursors to the electronic calculator.\nThe first known tools used to aid arithmetic calculations were: bones (used to tally items), pebbles, and counting boards, and the abacus, known to have been used by Sumerians and Egyptians before 2000\u00a0BC. Except for the Antikythera mechanism (an \"out of the time\" astronomical device), development of computing tools arrived near the start of the 17th century: the geometric-military compass (by Galileo), logarithms and Napier bones (by Napier), and the slide rule (by Edmund Gunter).\nThe Renaissance saw the invention of the mechanical calculator by Wilhelm Schickard in 1623, and later by Blaise Pascal in 1642. A device that was at times somewhat over-promoted as being able to perform all four arithmetic operations with minimal human intervention. Pascal's calculator could add and subtract two numbers directly and thus, if the tedium could be borne, multiply and divide by repetition. Schickard's machine, constructed several decades earlier, used a clever set of mechanised multiplication tables to ease the process of multiplication and division with the adding machine as a means of completing this operation. There is a debate about whether Pascal or Shickard should be credited as the known inventor of a calculating machine due to the differences (like the different aims) of both inventions. Schickard and Pascal were followed by Gottfried Leibniz who spent forty years designing a four-operation mechanical calculator, the stepped reckoner, inventing in the process his leibniz wheel, but who couldn't design a fully operational machine. There were also five unsuccessful attempts to design a calculating clock in the 17th century.\nThe 18th century saw the arrival of some notable improvements, first by Poleni with the first fully functional calculating clock and four-operation machine, but these machines were almost always \"one of a kind\". Luigi Torchi invented the first direct multiplication machine in 1834: this was also the second key-driven machine in the world, following that of James White (1822). It was not until the 19th century and the Industrial Revolution that real developments began to occur. Although machines capable of performing all four arithmetic functions existed prior to the 19th century, the refinement of manufacturing and fabrication processes during the eve of the industrial revolution made large scale production of more compact and modern units possible. The Arithmometer, invented in 1820 as a four-operation mechanical calculator, was released to production in 1851 as an adding machine and became the first commercially successful unit; forty years later, by 1890, about 2,500 arithmometers had been sold plus a few hundreds more from two arithmometer clone makers (Burkhardt, Germany, 1878 and Layton, UK, 1883) and Felt and Tarrant, the only other competitor in true commercial production, had sold 100 comptometers.\nIt wasn't until 1902 that the familiar push-button user interface was developed, with the introduction of the Dalton Adding Machine, developed by James L. Dalton in the United States.\nIn 1921, Edith Clarke invented the \"Clarke calculator\", a simple graph-based calculator for solving line equations involving hyperbolic functions. This allowed electrical engineers to simplify calculations for inductance and capacitance in power transmission lines.\nThe Curta calculator was developed in 1948 and, although costly, became popular for its portability. This purely mechanical hand-held device could do addition, subtraction, multiplication and division. By the early 1970s electronic pocket calculators ended manufacture of mechanical calculators, although the Curta remains a popular collectable item.\nDevelopment of electronic calculators.\nThe first mainframe computers, initially using vacuum tubes and later transistors in the logic circuits, appeared in the 1940s and 1950s. Electronic circuits developed for computers also had application to electronic calculators.\nThe Casio Computer Company, in Japan, released the Model \"14-A\" calculator in 1957, which was the world's first all-electric (relatively) compact calculator. It did not use electronic logic but was based on relay technology, and was built into a desk. The IBM 608 plugboard programmable calculator was IBM's first all-transistor product, released in 1957; this was a console type system, with input and output on punched cards, and replaced the earlier, larger, vacuum-tube IBM 603. \nIn October 1961, the world's first \"all-electronic desktop\" calculator, the British Bell Punch/Sumlock Comptometer ANITA (A New Inspiration To Arithmetic/Accounting) was announced. This machine used vacuum tubes, cold-cathode tubes and Dekatrons in its circuits, with 12 cold-cathode \"Nixie\" tubes for its display. Two models were displayed, the Mk VII for continental Europe and the Mk VIII for Britain and the rest of the world, both for delivery from early 1962. The Mk VII was a slightly earlier design with a more complicated mode of multiplication, and was soon dropped in favour of the simpler Mark VIII. The ANITA had a full keyboard, similar to mechanical comptometers of the time, a feature that was unique to it and the later Sharp CS-10A among electronic calculators. The ANITA weighed roughly due to its large tube system. Bell Punch had been producing key-driven mechanical calculators of the comptometer type under the names \"Plus\" and \"Sumlock\", and had realised in the mid-1950s that the future of calculators lay in electronics. They employed the young graduate Norbert Kitz, who had worked on the early British Pilot ACE computer project, to lead the development. The ANITA sold well since it was the only electronic desktop calculator available, and was silent and quick.\nThe tube technology of the ANITA was superseded in June 1963 by the U.S. manufactured Friden EC-130, which had an all-transistor design, a stack of four 13-digit numbers displayed on a cathode-ray tube (CRT), and introduced Reverse Polish Notation (RPN) to the calculator market for a price of $2200, which was about three times the cost of an electromechanical calculator of the time. Like Bell Punch, Friden was a manufacturer of mechanical calculators that had decided that the future lay in electronics. In 1964 more all-transistor electronic calculators were introduced: Sharp introduced the CS-10A, which weighed and cost 500,000 yen ($), and Industria Macchine Elettroniche of Italy introduced the IME 84, to which several extra keyboard and display units could be connected so that several people could make use of it (but apparently not at the same time). The Victor 3900 was the first to use integrated circuits in place of individual transistors, but production problems delayed sales until 1966.\nThere followed a series of electronic calculator models from these and other manufacturers, including Canon, Mathatronics, Olivetti, SCM (Smith-Corona-Marchant), Sony, Toshiba, and Wang. The early calculators used hundreds of germanium transistors, which were cheaper than silicon transistors, on multiple circuit boards. Display types used were CRT, cold-cathode Nixie tubes, and filament lamps. Memory technology was usually based on the delay-line memory or the magnetic-core memory, though the Toshiba \"Toscal\" BC-1411 appears to have used an early form of dynamic RAM built from discrete components. Already there was a desire for smaller and less power-hungry machines.\nBulgaria's ELKA 6521, introduced in 1965, was developed by the Central Institute for Calculation Technologies and built at the Elektronika factory in Sofia. The name derives from \"ELektronen KAlkulator\", and it weighed around . It is the first calculator in the world which includes the square root function. Later that same year were released the ELKA 22 (with a luminescent display) and the ELKA 25, with an built-in printer. Several other models were developed until the first pocket model, the ELKA 101, was released in 1974. The writing on it was in Roman script, and it was exported to western countries.\nProgrammable calculators.\nThe first desktop \"programmable calculators\" were produced in the mid-1960s. They included the Mathatronics Mathatron (1964) and the Olivetti Programma 101 (late 1965) which were solid-state, desktop, printing, floating point, algebraic entry, programmable, stored-program electronic calculators. Both could be programmed by the end user and print out their results. The Programma 101 saw much wider distribution and had the added feature of offline storage of programs via magnetic cards.\nAnother early programmable desktop calculator (and maybe the first Japanese one) was the Casio (AL-1000) produced in 1967. It featured a nixie tubes display and had transistor electronics and ferrite core memory.\nThe \"Monroe Epic\" programmable calculator came on the market in 1967. A large, printing, desk-top unit, with an attached floor-standing logic tower, it could be programmed to perform many computer-like functions. However, the only \"branch\" instruction was an implied unconditional branch (GOTO) at the end of the operation stack, returning the program to its starting instruction. Thus, it was not possible to include any conditional branch (IF-THEN-ELSE) logic. During this era, the absence of the conditional branch was sometimes used to distinguish a programmable calculator from a computer.\nThe first Soviet programmable desktop calculator ISKRA 123, powered by the power grid, was released at the start of the 1970s.\n1970s to mid-1980s.\nThe electronic calculators of the mid-1960s were large and heavy desktop machines due to their use of hundreds of transistors on several circuit boards with a large power consumption that required an AC power supply. There were great efforts to put the logic required for a calculator into fewer and fewer integrated circuits (chips) and calculator electronics was one of the leading edges of semiconductor development. U.S. semiconductor manufacturers led the world in large scale integration (LSI) semiconductor development, squeezing more and more functions into individual integrated circuits. This led to alliances between Japanese calculator manufacturers and U.S. semiconductor companies: Canon Inc. with Texas Instruments, Hayakawa Electric (later renamed Sharp Corporation) with North-American Rockwell Microelectronics (later renamed Rockwell International), Busicom with Mostek and Intel, and General Instrument with Sanyo.\nPocket calculators.\nReleased in 1947, the first pocket calculator which could perform the four basic arithmetic functions with digital precision was the Curta, a mechanical device operated by a crank, bearing \u201can uncanny resemblance to a pepper grinder\u201d. The readout was digital with eleven digits of precision. For comparison, the contemporaneous ten inch slide rule used analog calculation to approximate answers to only four digits of precision. The Curta remained the finest pocket calculator available for a quarter of a century.\nBy 1970, a calculator could be made using just a few chips of low power consumption, allowing portable models powered from rechargeable batteries. The first handheld calculator was a 1967 prototype called Cal Tech, whose development was led by Jack Kilby at Texas Instruments in a research project to produce a portable calculator. It could add, multiply, subtract, and divide, and its output device was a paper tape. As a result of the \"Cal-Tech\" project, Texas Instruments was granted master patents on portable calculators.\nThe first commercially produced portable calculators appeared in Japan in 1970, and were soon marketed around the world. These included the Sanyo ICC-0081 \"Mini Calculator\", the Canon Pocketronic, and the Sharp QT-8B \"micro Compet\". The Canon Pocketronic was a development from the \"Cal-Tech\" project. It had no traditional display; numerical output was on thermal paper tape.\nSharp put in great efforts in size and power reduction and introduced in January 1971 the Sharp EL-8, also marketed as the Facit 1111, which was close to being a pocket calculator. It weighed 1.59 pounds (721 grams), had a vacuum fluorescent display, rechargeable NiCad batteries, and initially sold for US$395.\nHowever, integrated circuit development efforts culminated in early 1971 with the introduction of the first \"calculator on a chip\", the MK6010 by Mostek, followed by Texas Instruments later in the year. Although these early hand-held calculators were very costly, these advances in electronics, together with developments in display technology (such as the vacuum fluorescent display, LED, and LCD), led within a few years to the cheap pocket calculator available to all.\nIn 1971, Pico Electronics and General Instrument also introduced their first collaboration in ICs, a full single chip calculator IC for the Monroe Royal Digital III calculator. Pico was a spinout by five GI design engineers whose vision was to create single chip calculator ICs. Pico and GI went on to have significant success in the burgeoning handheld calculator market.\nThe first truly pocket-sized electronic calculator was the Busicom LE-120A \"HANDY\", which was marketed early in 1971. Made in Japan, this was also the first calculator to use an LED display, the first hand-held calculator to use a single integrated circuit (then proclaimed as a \"calculator on a chip\"), the Mostek MK6010, and the first electronic calculator to run off replaceable batteries. Using four AA-size cells the LE-120A measures .\nThe first European-made pocket-sized calculator, DB 800 was made in May 1971 by Digitron in Buje, Croatia (former Yugoslavia) with four functions and an eight-digit display and special characters for a negative number and a warning that the calculation has too many digits to display.\nThe first American-made pocket-sized calculator, the Bowmar 901B (popularly termed \"The Bowmar Brain\"), measuring , came out in the autumn of 1971, with four functions and an eight-digit red LED display, for US$, while in August 1972 the four-function Sinclair Executive became the first slimline pocket calculator measuring and weighing . It retailed for around \u00a379 (US$ at the time). By the end of the decade, similar calculators were priced less than \u00a35 ($). Following protracted development over the course of two years including a botched partnership with Texas Instruments, Eldorado Electrodata released five pocket calculators in 1972. One called the Touch Magic was \"no bigger than a pack of cigarettes\" according to \"Administrative Management\".\nThe first Soviet Union made pocket-sized calculator, the \"Elektronika B3-04\" was developed by the end of 1973 and sold at the start of 1974.\nOne of the first low-cost calculators was the Sinclair Cambridge, launched in August 1973. It retailed for \u00a329.95 ($), or \u00a35 ($) less in kit form, and later models included some scientific functions. The Sinclair calculators were successful because they were far cheaper than the competition; however, their design led to slow and less accurate computations of transcendental functions (maximum three decimal places of accuracy).\nScientific pocket calculators.\nMeanwhile, Hewlett-Packard (HP) had been developing a pocket calculator. Launched in early 1972, it was unlike the other basic four-function pocket calculators then available in that it was the first pocket calculator with \"scientific\" functions that could replace a slide rule. The $395 HP-35, along with nearly all later HP engineering calculators, uses reverse Polish notation (RPN), also called postfix notation. A calculation like \"8 plus 5\" is, using RPN, performed by pressing 8, Enter\u2191, 5, and +; instead of the algebraic infix notation: 8, +, 5, . It had 35 buttons and was based on Mostek Mk6020 chip.\nThe first Soviet \"scientific\" pocket-sized calculator the \"B3-18\" was completed by the end of 1975.\nIn 1973, Texas Instruments (TI) introduced the SR-10, (\"SR\" signifying slide rule) an \"algebraic entry\" pocket calculator using scientific notation for $150. Shortly after the SR-11 featured an added key for entering pi (\u03c0). It was followed the next year by the SR-50 which added log and trig functions to compete with the HP-35, and in 1977 the mass-marketed TI-30 line which is still produced.\nIn 1978, a new company, Calculated Industries arose which focused on specialized markets. Their first calculator, the Loan Arranger (1978) was a pocket calculator marketed to the Real Estate industry with preprogrammed functions to simplify the process of calculating payments and future values. In 1985, CI launched a calculator for the construction industry called the Construction Master which came preprogrammed with common construction calculations (such as angles, stairs, roofing math, pitch, rise, run, and feet-inch fraction conversions). This would be the first in a line of construction related calculators.\nProgrammable pocket calculators.\nThe first programmable pocket calculator was the HP-65, in 1974; it had a capacity of 100 instructions, and could store and retrieve programs with a built-in magnetic card reader. Two years later the HP-25C introduced \"continuous memory\", i.e., programs and data were retained in CMOS memory during power-off. In 1979, HP released the first \"alphanumeric\", programmable, \"expandable\" calculator, the HP-41C. It could be expanded with random-access memory (RAM, for memory) and read-only memory (ROM, for software) modules, and peripherals like bar code readers, microcassette and floppy disk drives, paper-roll thermal printers, and miscellaneous communication interfaces (RS-232, HP-IL, HP-IB).\nThe first Soviet pocket battery-powered programmable calculator, Elektronika \"B3-21\", was developed by the end of 1976 and released at the start of 1977. The successor of B3-21, the Elektronika B3-34 wasn't backward compatible with B3-21, even if it kept the reverse Polish notation (RPN). Thus B3-34 defined a new command set, which later was used in a series of later programmable Soviet calculators. Despite very limited abilities (98 bytes of instruction memory and about 19 stack and addressable registers), people managed to write all kinds of programs for them, including adventure games and libraries of calculus-related functions for engineers. Hundreds, perhaps thousands, of programs were written for these machines, from practical scientific and business software, which were used in real-life offices and labs, to fun games for children. The Elektronika MK-52 calculator (using the extended B3-34 command set, and featuring internal EEPROM memory for storing programs and external interface for EEPROM cards and other periphery) was used in Soviet spacecraft program (for Soyuz TM-7 flight) as a backup of the board computer.\nThis series of calculators was also noted for a large number of highly counter-intuitive mysterious undocumented features, somewhat similar to \"synthetic programming\" of the American HP-41, which were exploited by applying normal arithmetic operations to error messages, jumping to nonexistent addresses and other methods. A number of respected monthly publications, including the popular science magazine \"Nauka i Zhizn\" (\"\u041d\u0430\u0443\u043a\u0430 \u0438 \u0436\u0438\u0437\u043d\u044c\", \"Science and Life\"), featured special columns, dedicated to optimization methods for calculator programmers and updates on undocumented features for hackers, which grew into a whole esoteric science with many branches, named \"yeggogology\" (\"\u0435\u0433\u0433\u043e\u0433\u043e\u043b\u043e\u0433\u0438\u044f\"). The error messages on those calculators appear as a Russian word \"YEGGOG\" (\"\u0415\u0413\u0413\u041e\u0413\") which, unsurprisingly, is translated to \"Error\".\nA similar hacker culture in the US revolved around the HP-41, which was also noted for a large number of undocumented features and was much more powerful than B3-34.\nTechnical improvements.\nThrough the 1970s the hand-held electronic calculator underwent rapid development. The red LED and blue/green vacuum fluorescent displays consumed a lot of power and the calculators either had a short battery life (often measured in hours, so rechargeable nickel-cadmium batteries were common) or were large so that they could take larger, higher capacity batteries. In the early 1970s liquid-crystal displays (LCDs) were in their infancy and there was a great deal of concern that they only had a short operating lifetime. Busicom introduced the Busicom \"LE-120A \"HANDY\"\" calculator, the first pocket-sized calculator and the first with an LED display, and announced the Busicom \"LC\" with LCD. However, there were problems with this display and the calculator never went on sale. The first successful calculators with LCDs were manufactured by Rockwell International and sold from 1972 by other companies under such names as: Dataking \"LC-800\", Harden \"DT/12\", Ibico \"086\", Lloyds \"40\", Lloyds \"100\", Prismatic \"500\" (a.k.a. \"P500\"), Rapid Data \"Rapidman 1208LC\". The LCDs were an early form using the \"Dynamic Scattering Mode DSM\" with the numbers appearing as bright against a dark background. To present a high-contrast display these models illuminated the LCD using a filament lamp and solid plastic light guide, which negated the low power consumption of the display. These models appear to have been sold only for a year or two.\nA more successful series of calculators using a reflective DSM-LCD was launched in 1972 by Sharp Inc with the Sharp \"EL-805\", which was a slim pocket calculator. This, and another few similar models, used Sharp's \"Calculator On Substrate\" (COS) technology. An extension of one glass plate needed for the liquid crystal display was used as a substrate to mount the needed chips based on a new hybrid technology. The COS technology may have been too costly since it was only used in a few models before Sharp reverted to conventional circuit boards.\nIn the mid-1970s the first calculators appeared with field-effect, \"twisted nematic\" (TN) LCDs with dark numerals against a grey background, though the early ones often had a yellow filter over them to cut out damaging ultraviolet rays. The advantage of LCDs is that they are passive light modulators reflecting light, which require much less power than light-emitting displays such as LEDs or VFDs. This led the way to the first credit-card-sized calculators, such as the Casio \"Mini Card LC-78\" of 1978, which could run for months of normal use on button cells.\nThere were also improvements to the electronics inside the calculators. All of the logic functions of a calculator had been squeezed into the first \"calculator on a chip\" integrated circuits (ICs) in 1971, but this was leading edge technology of the time and yields were low and costs were high. Many calculators continued to use two or more ICs, especially the scientific and the programmable ones, into the late 1970s.\nThe power consumption of the integrated circuits was also reduced, especially with the introduction of CMOS technology. Appearing in the Sharp \"EL-801\" in 1972, the transistors in the logic cells of CMOS ICs only used any appreciable power when they changed state. The LED and VFD displays often required added driver transistors or ICs, whereas the LCDs were more amenable to being driven directly by the calculator IC itself.\nWith this low power consumption came the possibility of using solar cells as the power source, realised around 1978 by calculators such as the Royal \"Solar 1\", Sharp \"EL-8026\", and Teal \"Photon\".\nMass-market phase.\nAt the start of the 1970s, hand-held electronic calculators were very costly, at two or three weeks' wages, and so were a luxury item. The high price was due to their construction requiring many mechanical and electronic components which were costly to produce, and production runs that were too small to exploit economies of scale. Many firms saw that there were good profits to be made in the calculator business with the margin on such high prices. However, the cost of calculators fell as components and their production methods improved, and the effect of economies of scale was felt.\nBy 1976, the cost of the cheapest four-function pocket calculator had dropped to a few dollars, about 1/20 of the cost five years before. The results of this were that the pocket calculator was affordable, and that it was now difficult for the manufacturers to make a profit from calculators, leading to many firms dropping out of the business or closing. The firms that survived making calculators tended to be those with high outputs of higher quality calculators, or producing high-specification scientific and programmable calculators.\nMid-1980s to present.\nThe first calculator capable of symbolic computing was the HP-28C, released in 1987. It could, for example, solve quadratic equations symbolically. The first graphing calculator was the Casio fx-7000G released in 1985.\nThe two leading manufacturers, HP and TI, released increasingly feature-laden calculators during the 1980s and 1990s. At the turn of the millennium, the line between a graphing calculator and a handheld computer was not always clear, as some very advanced calculators such as the TI-89, the Voyage 200 and HP-49G could differentiate and integrate functions, solve differential equations, run word processing and PIM software, and connect by wire or IR to other calculators/computers.\nThe HP 12c financial calculator is still produced. It was introduced in 1981 and is still being made with few changes. The HP 12c featured the reverse Polish notation mode of data entry. In 2003 several new models were released, including an improved version of the HP 12c, the \"HP 12c platinum edition\" which added more memory, more built-in functions, and the addition of the algebraic mode of data entry.\nCalculated Industries competed with the HP 12c in the mortgage and real estate markets by differentiating the key labeling; changing the \"I\", \"PV\", \"FV\" to easier labeling terms such as \"Int\", \"Term\", \"Pmt\", and not using the reverse Polish notation. However, CI's more successful calculators involved a line of construction calculators, which evolved and expanded in the 1990s to present. According to Mark Bollman, a mathematics and calculator historian and associate professor of mathematics at Albion College, the \"Construction Master is the first in a long and profitable line of CI construction calculators\" which carried them through the 1980s, 1990s, and to the present.\nUse in education.\nIn most countries, students use calculators for schoolwork. There was some initial resistance to the idea out of fear that basic or elementary arithmetic skills would suffer. There remains disagreement about the importance of the ability to perform calculations \"in the head\", with some curricula restricting calculator use until a certain level of proficiency has been obtained, while others concentrate more on teaching estimation methods and problem-solving. Research suggests that inadequate guidance in the use of calculating tools can restrict the kind of mathematical thinking that students engage in. Others have argued that calculator use can even cause core mathematical skills to atrophy, or that such use can prevent understanding of advanced algebraic concepts. In December 2011 the UK's Minister of State for Schools, Nick Gibb, voiced concern that children can become \"too dependent\" on the use of calculators. As a result, the use of calculators is to be included as part of a review of the Curriculum. In the United States, many math educators and boards of education have enthusiastically endorsed the National Council of Teachers of Mathematics (NCTM) standards and actively promoted the use of classroom calculators from kindergarten through high school.\nCalculators may in some circumstances be used within school and college examinations. In the United Kingdom there are limitations on the type of calculator which may be used in an examination to avoid malpractice. Some calculators which offer additional functionality have an \"exam mode\" setting which makes them compliant with examination regulations.\nPersonal computers.\nPersonal computers often come with a calculator utility program that emulates the appearance and functions of a calculator, using the graphical user interface to portray a calculator. Examples include the Windows Calculator, Apple's Calculator, and KDE's KCalc. Most personal data assistants (PDAs) and smartphones also have such a feature.\nCalculators compared to computers.\nThe fundamental difference between a calculator and computer is that a computer can be programmed in a way that allows the program to take different branches according to intermediate results, while calculators are pre-designed with specific functions (such as addition, multiplication, and logarithms) built in. The distinction is not clear-cut: some devices classed as programmable calculators have programming functions, sometimes with support for programming languages (such as RPL or TI-BASIC).\nFor instance, instead of a hardware multiplier, a calculator might implement floating point mathematics with code in read-only memory (ROM), and compute trigonometric functions with the CORDIC algorithm because CORDIC does not require much multiplication. Bit serial logic designs are more common in calculators whereas bit parallel designs dominate general-purpose computers, because a bit serial design minimizes chip complexity, but takes many more clock cycles. This distinction blurs with high-end calculators, which use processor chips associated with computer and embedded systems design, more so the Z80, MC68000, and ARM architectures, and some custom designs specialized for the calculator market.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "7594", "revid": "49426652", "url": "https://en.wikipedia.org/wiki?curid=7594", "title": "Cash register", "text": "Device to register and calculate retail sales\nA cash register, sometimes called a till or automated money handling system, is a mechanical or electronic device for registering and calculating transactions at a point of sale. It is usually attached to a drawer for storing cash and other valuables. A modern cash register is usually attached to a printer that can print out receipts for record-keeping purposes.\nHistory.\nAn early mechanical cash register was invented by James Ritty and John Birch following the American Civil War. James was the owner of a saloon in Dayton, Ohio, US, and believed his employees were embezzling by pocketing cash from customers or from the store's cash box. His solution was a machine that would record each sales transaction, producing a total at the close of the business day that could be compared to the amount of money in the till and the amount left over from the previous day, to determine if any was missing.\nAfter being inspired by a machine on a steamship that counted the number of revolutions made by the propeller, and with the help of his brother John, James Ritty invented and patented his first machine, the Ritty Model I (also known as the Ritty Dial) in 1879. He then went on to produce additional models, including the \"Incorruptible Cashier\".\nEarly registers were entirely mechanical, and did not print receipts. The employee was required to ring up every transaction on the register, and when the total key was pushed, the drawer opened and a bell would ring, alerting the manager to a sale taking place. Those original machines were nothing but simple adding machines. For example, the Rittys' patent application filed in 1879 for their \"improved cash register\" describes the device as follows: \"The machine consists, essentially, of an inclosed case or frame provided with an index dial and indicator operated by a system of levers or keys and connected with a series of co-operating disks marked with numbers on their peripheries, a row of which numbers are disclosed by a transverse opening or openings in the case to show at a glance the sum-total of cash receipts.\"\nSince the registration is done with the process of returning change, according to Bill Bryson odd pricing came about because by charging odd amounts like 49 and 99 cents (or 45 and 95 cents when nickels are more used than pennies), the cashier very probably had to open the till for the penny change and thus announce the sale.\nShortly after the patent, Ritty became overwhelmed with the responsibilities of running two businesses, so he sold all of his interests in the cash register business to Jacob H. Eckert of Cincinnati, a china and glassware salesman, who formed the National Manufacturing Company. In 1884 Eckert sold the company to John H. Patterson, who renamed the company the National Cash Register Company and improved the cash register by adding a paper roll to record sales transactions, thereby creating the journal for internal bookkeeping purposes, and the receipt for external bookkeeping purposes. The original purpose of the receipt was enhanced fraud protection. The business owner could read the receipts to ensure that cashiers charged customers the correct amount for each transaction and did not embezzle the cash drawer. It also prevents a customer from defrauding the business by falsely claiming receipt of a lesser amount of change or a transaction that never happened in the first place. The first evidence of an actual cash register was used in Coalton, Ohio, at the Miners' Supply Co.\nIn 1906, while working at the National Cash Register company, inventor Charles F. Kettering designed a cash register with an electric motor.\nA leading designer, builder, manufacturer, seller and exporter of cash registers from the 1950s until the 1970s was London-based (and later Brighton-based) Gross Cash Registers Ltd., founded by brothers Sam and Henry Gross. Their cash registers were particularly popular around the time of decimalisation in Britain in early 1971, Henry having designed one of the few known models of cash register which could switch currencies from \u00a3sd to \u00a3p so that retailers could easily change from one to the other on or after Decimal Day. Sweda also had decimal-ready registers where the retailer used a special key on Decimal Day for the conversion.\nIn current use.\nIn some jurisdictions the law also requires customers to collect the receipt and keep it at least for a short while after leaving the shop, again to check that the shop records sales, so that it cannot evade sales taxes.\nOften cash registers are attached to scales, barcode scanners, checkstands, and debit card or credit card terminals. Increasingly, dedicated cash registers are being replaced with general purpose computers with POS software.\nToday, point of sale systems scan the barcode (usually EAN or UPC) for each item, retrieve the price from a database, calculate deductions for items on sale (or, in British retail terminology, \"special offer\", \"multibuy\" or \"buy one, get one free\"), calculate the sales tax or VAT, calculate differential rates for preferred customers, actualize inventory, time and date stamp the transaction, record the transaction in detail including each item purchased, record the method of payment, keep totals for each product or type of product sold as well as total sales for specified periods, and do other tasks as well. These POS terminals will often also identify the cashier on the receipt, and carry additional information or offers.\nCurrently, many cash registers are individual computers. They may be running in-house software or general purpose software. Many of the newer ones have touch screens. They may be connected to computerized point of sale networks using any type of protocol. Such systems may be accessed remotely for the purpose of obtaining records or troubleshooting. Many businesses also use tablet computers as cash registers, utilizing the sale system as downloadable app-software.\nCash drawer.\nA cash drawer is usually a compartment underneath a cash register in which the cash from transactions is kept. The drawer typically contains a removable till. The till is usually a plastic or wooden tray divided into compartments used to store each denomination of bank notes and coins separately in order to make counting easier. The removable till allows money to be removed from the sales floor to a more secure location for counting and creating bank deposits. Some modern cash drawers are individual units separate from the rest of the cash register.\nA cash drawer is usually of strong construction and may be integral with the register or a separate piece that the register sits atop. It slides in and out of its lockable box and is secured by a spring-loaded catch. When a transaction that involves cash is completed, the register sends an electrical impulse to a solenoid to release the catch and open the drawer. Cash drawers that are integral to a stand-alone register often have a manual release catch underneath to open the drawer in the event of a power failure. More advanced cash drawers have eliminated the manual release in favor of a cylinder lock, requiring a key to manually open the drawer. The cylinder lock usually has several positions: locked, unlocked, online (will open if an impulse is given), and release. The release position is an intermittent position with a spring to push the cylinder back to the unlocked position. In the \"locked\" position, the drawer will remain latched even when an electric impulse is sent to the solenoid.\nSome cash drawers are designed to store notes upright &amp; facing forward, instead of the traditional flat and front to back position. This allows more varieties of notes to be stored. Some cash drawers are flip top in design, where they flip open instead of sliding out like an ordinary drawer, resembling a cashbox instead.\nA cash register's drawer can only be opened by an instruction from the cash register except when using special keys, generally held by the owner and some employees (e.g. manager). This reduces the amount of contact most employees have with cash and other valuables. It also reduces risks of an employee taking money from the drawer without a record and the owner's consent, such as when a customer does not expressly ask for a receipt but still has to be given change (cash is more easily checked against recorded sales than inventory). Cash registers include a key labeled \"No Sale\", abbreviated \"NS\" on many modern electronic cash registers. Its function is to open the drawer, printing a receipt stating \"No Sale\" and recording in the register log that the register was opened. Some cash registers require a numeric password or physical key to be used when attempting to open the till.\nManagement functions.\nAn often used non-sale function is the aforementioned \"no sale\". In case of needing to correct change given to the customer, or to make change from a neighboring register, this function will open the cash drawer of the register. Where non-management staff are given access, management can scrutinize the count of \"no sales\" in the log to look for suspicious patterns. Generally requiring a management key, besides programming prices into the register, are the report functions. An X-report will read the current sales figures from memory and produce a paper printout. A Z-report will act like an \"X\" report, except that counters will be reset to zero.\nManual input.\nRegisters will typically feature a numerical pad, QWERTY or custom keyboard, touch screen interface, or a combination of these input methods for the cashier to enter products and fees by hand and access information necessary to complete the sale. For older registers as well as at restaurants and other establishments that do not sell barcoded items, the manual input may be the only method of interacting with the register. While customization was previously limited to larger chains that could afford to have physical keyboards custom-built for their needs, the customization of register inputs is now more widespread with the use of touch screens that can display a variety of point of sale software.\nScanner.\nModern cash registers may be connected to a handheld or stationary barcode reader so that a customer's purchases can be more rapidly scanned than would be possible by keying numbers into the register by hand. The use of scanners should also help prevent errors that result from manually entering the product's barcode or pricing. At grocers, the register's scanner may be combined with a scale for measuring product that is sold by weight.\nReceipt printer.\nCashiers are often required to provide a receipt to the customer after a purchase has been made. Registers typically use thermal printers to print receipts, although older dot matrix printers are still in use at some retailers. Alternatively, retailers can forgo issuing paper receipts in some jurisdictions by instead asking the customer for an email to which their receipt can be sent. The receipts of larger retailers tend to include unique barcodes or other information identifying the transaction so that the receipt can be scanned to facilitate returns or other customer services.\nSecurity deactivation.\nIn stores that use electronic article surveillance, a pad or other surface will be attached to the register that deactivates security devices embedded in or attached to the items being purchased. This will prevent a customer's purchase from setting off security alarms at the store's exit.\nRemote peripherals.\nIn settings like a restaurant, remote pheripherals are sometimes used to speed up processing of orders. These include printers or screens in the kitchen to show staff the incoming orders. Waiters often use mobile devices like phones or tablets connected to a central cash register to takes orders and can use small, mobile bluetooth printers to print receipts directly at the table.\nSelf-service cash register.\nSome corporations and supermarkets have introduced self-checkout machines, where the customer is trusted to scan the barcodes (or manually identify uncoded items like fruit), and place the items into a bagging area. The bag is weighed, and the machine halts the checkout when the weight of something in the bag does not match the weight in the inventory database. Normally, an employee is watching over several such checkouts to prevent theft or exploitation of the machines' weaknesses (for example, intentional misidentification of expensive produce or dry goods). Payment on these machines is accepted by debit card/credit card, or cash via coin slot and bank note scanner. Store employees are also needed to authorize \"age-restricted\" purchases, such as alcohol, solvents or knives, which can either be done remotely by the employee observing the self-checkout, or by means of a \"store login\" which the operator has to enter.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "7595", "revid": "494861", "url": "https://en.wikipedia.org/wiki?curid=7595", "title": "Chronometer", "text": "Chronometer is a name for certain types of clock. It may refer to:\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "7597", "revid": "122189", "url": "https://en.wikipedia.org/wiki?curid=7597", "title": "Processor design", "text": "Task of creating a processor\nProcessor design is a subfield of computer science and computer engineering (fabrication) that deals with creating a processor, a key component of computer hardware.\nThe design process involves choosing an instruction set and a certain execution paradigm (e.g. VLIW or RISC) and results in a microarchitecture, which might be described in e.g. VHDL or Verilog. For microprocessor design, this description is then manufactured employing some of the various semiconductor device fabrication processes, resulting in a die which is bonded onto a chip carrier. This chip carrier is then soldered onto, or inserted into a socket on, a printed circuit board (PCB).\nThe mode of operation of any processor is the execution of lists of instructions. Instructions typically include those to compute or manipulate data values using registers, change or retrieve values in read/write memory, perform relational tests between data values and to control program flow.\nProcessor designs are often tested and validated on one or several FPGAs before sending the design of the processor to a foundry for semiconductor fabrication.\nDetails.\nBasics.\nCPU design is divided into multiple components. Information is transferred through datapaths (such as ALUs and pipelines). These datapaths are controlled through logic by control units. Memory components include register files and caches to retain information, or certain actions. Clock circuitry maintains internal rhythms and timing through clock drivers, PLLs, and clock distribution networks. Pad transceiver circuitry which allows signals to be received and sent and a logic gate cell library which is used to implement the logic. Logic gates are the foundation for processor design as they are used to implement most of the processor's components.\nCPUs designed for high-performance markets might require custom (optimized or application-specific (see below)) designs for each of these items to achieve frequency, power-dissipation, and chip-area goals whereas CPUs designed for lower performance markets might lessen the implementation burden by acquiring some of these items by purchasing them as intellectual property. Control logic implementation techniques (logic synthesis using CAD tools) can be used to implement datapaths, register files, and clocks. Common logic styles used in CPU design include unstructured random logic, finite-state machines, microprogramming (common from 1965 to 1985), and programmable logic arrays (common in the 1980s, no longer common).\nImplementation logic.\nDevice types used to implement the logic include:\nA CPU design project generally has these major tasks:\nRe-designing a CPU core to a smaller die area helps to shrink everything (a \"photomask shrink\"), resulting in the same number of transistors on a smaller die. It improves performance (smaller transistors switch faster), reduces power (smaller wires have less parasitic capacitance) and reduces cost (more CPUs fit on the same wafer of silicon). Releasing a CPU on the same size die, but with a smaller CPU core, keeps the cost about the same but allows higher levels of integration within one very-large-scale integration chip (additional cache, multiple CPUs or other components), improving performance and reducing overall system cost.\nAs with most complex electronic designs, the logic verification effort (proving that the design does not have bugs) now dominates the project schedule of a CPU.\nKey CPU architectural innovations include accumulator, index register, general-purpose register, cache, virtual memory, instruction pipelining, superscalar, CISC, RISC, virtual machine, emulators, microprogram, and stack.\nResearch topics.\nA variety of have been proposed,\nincluding reconfigurable logic, clockless CPUs, computational RAM, and optical computing.\nPerformance analysis and benchmarking.\nBenchmarking is a way of testing CPU speed. Examples include SPECint and SPECfp, developed by Standard Performance Evaluation Corporation, and ConsumerMark developed by the Embedded Microprocessor Benchmark Consortium EEMBC.\nSome of the commonly used metrics include:\nThere may be tradeoffs in optimizing some of these metrics. In particular, many design techniques that make a CPU run faster make the \"performance per watt\", \"performance per dollar\", and \"deterministic response\" much worse, and vice versa.\nMarkets.\nThere are several different markets in which CPUs are used. Since each of these markets differ in their requirements for CPUs, the devices designed for one market are in most cases inappropriate for the other markets.\nGeneral-purpose computing.\nAs of 2010[ [update]], in the general-purpose computing market, that is, desktop, laptop, and server computers commonly used in businesses and homes, the Intel IA-32 and the 64-bit version x86-64 architecture dominate the market, with its rivals PowerPC and SPARC maintaining much smaller customer bases. Yearly, hundreds of millions of IA-32 architecture CPUs are used by this market. A growing percentage of these processors are for mobile implementations such as netbooks and laptops.\nSince these devices are used to run countless different types of programs, these CPU designs are not specifically targeted at one type of application or one function. The demands of being able to run a wide range of programs efficiently has made these CPU designs among the more advanced technically, along with some disadvantages of being relatively costly, and having high power consumption.\nHigh-end processor economics.\nIn 1984, most high-performance CPUs required four to five years to develop.\nScientific computing.\nScientific computing is a much smaller niche market (in revenue and units shipped). It is used in government research labs and universities. Before 1990, CPU design was often done for this market, but mass market CPUs organized into large clusters have proven to be more affordable. The main remaining area of active hardware design and research for scientific computing is for high-speed data transmission systems to connect mass market CPUs.\nEmbedded design.\nAs measured by units shipped, most CPUs are embedded in other machinery, such as telephones, clocks, appliances, vehicles, and infrastructure. Embedded processors sell in the volume of many billions of units per year, however, mostly at much lower price points than that of the general purpose processors.\nThese single-function devices differ from the more familiar general-purpose CPUs in several ways:\nEmbedded processor economics.\nThe embedded CPU family with the largest number of total units shipped is the 8051, averaging nearly a billion units per year. The 8051 is widely used because it is very inexpensive. The design time is now roughly zero, because it is widely available as commercial intellectual property. It is now often embedded as a small part of a larger system on a chip. The silicon cost of an 8051 is now as low as US$0.001, because some implementations use as few as 2,200 logic gates and take 0.4730 square millimeters of silicon.\nAs of 2009, more CPUs are produced using the ARM architecture family instruction sets than any other 32-bit instruction set.\nThe ARM architecture and the first ARM chip were designed in about one and a half years and 5 human years of work time.\nThe 32-bit Parallax Propeller microcontroller architecture and the first chip were designed by two people in about 10 human years of work time.\nThe 8-bit AVR architecture and first AVR microcontroller was conceived and designed by two students at the Norwegian Institute of Technology.\nThe 8-bit 6502 architecture and the first MOS Technology 6502 chip were designed in 13 months by a group of about 9 people.\nResearch and educational CPU design.\nThe 32-bit Berkeley RISC I and RISC II processors were mostly designed by a series of students as part of a four quarter sequence of graduate courses.\nThis design became the basis of the commercial SPARC processor design.\nFor about a decade, every student taking the 6.004 class at MIT was part of a team\u2014each team had one semester to design and build a simple 8 bit CPU out of 7400 series integrated circuits.\nOne team of 4 students designed and built a simple 32 bit CPU during that semester.\nSome undergraduate courses require a team of 2 to 5 students to design, implement, and test a simple CPU in a FPGA in a single 15-week semester.\nThe MultiTitan CPU was designed with 2.5 man years of effort, which was considered \"relatively little design effort\" at the time.\n24 people contributed to the 3.5 year MultiTitan research project, which included designing and building a prototype CPU.\nSoft microprocessor cores.\nFor embedded systems, the highest performance levels are often not needed or desired due to the power consumption requirements. This allows for the use of processors which can be totally implemented by logic synthesis techniques. These synthesized processors can be implemented in a much shorter amount of time, giving quicker time-to-market.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "7598", "revid": "46808506", "url": "https://en.wikipedia.org/wiki?curid=7598", "title": "Carinatae", "text": "Group of birds\nCarinatae is the group of all birds and their extinct relatives to possess a keel, or \"carina\", on the underside of the breastbone used to anchor large flight muscles.\nDefinition.\nTraditionally, Carinatae were defined as all birds whose sternum (breast bone) has a keel (\"carina\"). The keel is a strong median ridge running down the length of the sternum. This is an important area for the attachment of flight muscles. Thus, all flying birds have a pronounced keel. Ratites, all of which are flightless, lack a strong keel. Thus, living birds were divided into carinatae (keeled) and ratites (from \"ratis\", \"raft\", referring to the flatness of the sternum). The difficulty with this scheme phylogenetically was that some flightless birds, without strong keels, are descended directly from ordinary flying birds possessing one. Examples include the k\u0101k\u0101p\u014d, a flightless parrot, and the dodo, a columbiform (the pigeon family). Neither of these birds are a ratite. Thus, this supposedly distinctive feature was easy to use, but had nothing to do with actual phylogenetic relationship.\nBeginning in the 1980s, Carinatae was given several phylogenetic definitions. The first was as a node-based clade uniting \"Ichthyornis\" with modern birds. However, in many analyses, this definition would be synonymous with the more widely used name Ornithurae. An alternate definition was provided in 2001, naming Carinatae an apomorphy-based clade defined by the presence of a keeled sternum.\nThe most primitive known bird relative with a keeled breastbone is \"Confuciusornis\". While some specimens of this stem-bird have flat breastbones, some show a small ridge that could have supported a cartilaginous keel.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "7599", "revid": "34119928", "url": "https://en.wikipedia.org/wiki?curid=7599", "title": "Cocktail", "text": "Combination of spirits and alcohol\nA cocktail is a mixed drink, usually alcoholic. Most commonly, a cocktail is a combination of one or more spirits mixed with other ingredients, such as juices, flavored syrups, tonic water, shrubs, and bitters. Cocktails vary widely across regions of the world, and many websites publish both original recipes and their own interpretations of older and more famous cocktails.\nHistory.\nA well-known \"cocktail\" in ancient Greece was named kykeon. It is mentioned in the Homeric texts and was used in the Eleusinian Mysteries. \"Cocktail\" accessories are exposed in the Museum of the Royal Tombs of Aigai (Greece). They were used in the court of Philip II of Macedon to prepare and serve mixtures of wine, water, honey as well as extracts of aromatic herbs and flowers, during the banquets. \nIn the United States, a written mention of \"cocktail\" as a beverage appeared in \"The Farmers Cabinet,\" 1803. The first definition of a cocktail as an alcoholic beverage appeared three years later in \"The Balance and Columbian Repository\" (Hudson, New York) May 13, 1806. Traditionally, cocktail ingredients included spirits, sugar, water and bitters; however, this definition evolved throughout the 1800s to include the addition of a liqueur.\nIn 1862, Jerry Thomas published a bartender's guide called \"How to Mix Drinks; or, The Bon Vivant's Companion\" which included 10 cocktail recipes using bitters, to differentiate from other drinks such as punches and cobblers.\nCocktails continued to evolve and gain popularity throughout the 1900s, with the term eventually expanding to cover all mixed drinks. In 1917, the term \"cocktail party\" was coined by Julius S. Walsh Jr. of St. Louis, Missouri. With wine and beer being less available during the Prohibition in the United States (1920\u20131933), liquor-based cocktails became more popular due to accessibility, followed by a decline in popularity during the late 1960s. The early to mid-2000s saw the rise of cocktail culture through the style of mixology which mixes traditional cocktails and other novel ingredients. By 2023, the so-called \"cocktail in a can\" had proliferated (at least in the United States) to become a common item in liquor stores.\nIn the modern world and the Information Age, cocktail recipes are widely shared online on websites. Cocktails and restaurants that serve them are frequently covered and reviewed in tourism magazines and guides. Some cocktails, such as the Mojito, Manhattan, and Martini, have become staples in restaurants and pop culture.\nComponents.\nIn general terms the most important elements consist of the base, a modifying, smoothing or aromatizing agent, and an additional special flavouring or coloring agent.\nThe base will always be the most dominant ingredient. It constitutes at least 50% of the entire volume of the cocktail, and always consists of spirit based liquors or wine based liquors. The type of base will determine the style of liquor, thus gin based cocktails, such as the Martini, will differ from whisky based cocktails, such as the Manhattan. It is possible to mix a cocktail combining a number of bases, as long as they share essential characteristics, though it is considered \"dangerous\".\nThe modifying agent functions as a buffer for the sharp bite of the base, and adds character to its natural flavour. Modifiers can be classified into the three categories of aromatics and bitters, fruit juices (with or without sugar), and smoothing agents (such as cream, sugar, eggs, or aquafaba). Modifiers are often used sparingly so as not to overpower the base, Embury suggested a maximum of half an egg white, one quarter of a whole egg, one tablespoon of heavy cream or one teaspoon of sugar per drink.\nSpecial flavouring agents, including not only non-alcoholic syrups but also various liqueurs and cordials, as well as other ingredients which could also be used as modifiers. Like the modifiers, special care must be taken so that the special flavouring agent does not overpower the base. For this reason quantities are often limited to drops and dashes.\nUsage and related terms.\nThe term \"cocktail\" can refer to a wide variety of drinks; it is typically a mixed drink containing alcohol.\nWhen a combined drink contains only a distilled spirit and a mixer, such as soda or fruit juice, it is a highball. Many of the International Bartenders Association Official Cocktails are highballs. When a mixed drink contains only a distilled spirit and a liqueur, it is a duo, and when it adds cream or a cream-based liqueur, it is a trio. Additional ingredients may be sugar, honey, milk, cream, and various herbs.\nMixed drinks without alcohol that resemble cocktails can be known as \"zero-proof\" or \"virgin\" cocktails or \"mocktails\".\nEtymology.\nThe origin of the word \"cocktail\" is disputed. It is presumably from \"cock-tail\", meaning \"with tail standing up, like a cock's\", in particular of a horse, but how this came to be applied to alcoholic mixed drinks is unclear. The most prominent theories are that it refers to a stimulant, hence a \"stimulating\" drink, or to a non-purebred horse, hence a \"mixed\" drink.\nCocktail historian David Wondrich speculates that \"cocktail\" is a reference to gingering, a practice for perking up an old horse by means of a ginger suppository so that the animal would \"cock its tail up and be frisky\", hence by extension a stimulating drink, like \"pick-me-up\". This agrees with usage in early citations (1798: \"'cock-tail' (vulgarly called ginger)\", 1803: drink at 11 a.m. to clear the head, 1806: \"stimulating liquor\"), and suggests that a cocktail was initially considered a medicinal drink, which accords with the use of bitters.\nEtymologist Anatoly Liberman endorses as \"highly probable\" the theory advanced by L\u00e5ftman (1946), which Liberman summarizes as follows:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nCitations.\nThe first recorded use of cocktail not referring to a horse is found in \"The Morning Post and Gazetteer\" in London, England, March 20, 1798:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nThe \"Oxford English Dictionary\" cites the word as originating in the U.S. The first recorded use of \"cocktail\" as a beverage (possibly non-alcoholic) in the United States appears in \"The Farmer's Cabinet\", April 28, 1803:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;11. [a.m.] Drank a glass of cocktail\u2014excellent for the head...Call'd at the Doct's. found Burnham\u2014he looked very wise\u2014drank another glass of cocktail.\nThe first definition of cocktail known to be an alcoholic beverage appeared in \"The Balance and Columbian Repository\" (Hudson, New York) May 13, 1806; editor Harry Croswell answered the question, \"What is a cocktail?\":\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\"Cock-tail\" is a stimulating liquor, composed of spirits of any kind, sugar, water, and bitters\u2014it is vulgarly called \"bittered sling\", and is supposed to be an excellent electioneering potion, in as much as it renders the heart stout and bold, at the same time that it fuddles the head. It is said, also to be of great use to a democratic candidate: because a person, having swallowed a glass of it, is ready to swallow any thing else.\nFolk etymologies.\nOther origins have been suggested, as corruptions of other words or phrases. These can be dismissed as folk etymologies, given the well-attested term \"cock-tail\" for a horse.\nDale DeGroff hypothesizes that the word evolved from the French , for an eggcup in which Antoine A. Peychaud, creator of Peychaud's Bitters, allegedly used to serve his guests a mix of cognac with a dash of his bitters.\nSeveral authors have theorized that \"cocktail\" may be a corruption of \"cock ale\".\nDevelopment.\nThere is a lack of clarity on the origins of cocktails. Traditionally cocktails were a mixture of spirits, sugar, water, and bitters. By the 1860s, however, a cocktail frequently included a liqueur.\nThe first publication of a bartenders' guide which included cocktail recipes was in 1862 \u2013 \"How to Mix Drinks; or, The Bon Vivant's Companion\", by \"Professor\" Jerry Thomas. In addition to recipes for punches, sours, slings, cobblers, shrubs, toddies, flips, and a variety of other mixed drinks were 10 recipes for \"cocktails\". A key ingredient distinguishing cocktails from other drinks in this compendium was the use of bitters. Mixed drinks popular today that conform to this original meaning of \"cocktail\" include the Old Fashioned whiskey cocktail, the Sazerac cocktail, and the Manhattan cocktail.\nThe ingredients listed (spirits, sugar, water, and bitters) match the ingredients of an Old Fashioned, which originated as a term used by late 19th-century bar patrons to distinguish cocktails made the \"old-fashioned\" way from newer, more complex cocktails.\nIn the 1869 recipe book \"Cooling Cups and Dainty Drinks\", by William Terrington, cocktails are described as:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Cocktails are compounds very much used by \"early birds\" to fortify the inner man, and by those who like their consolations hot and strong.\nThe term highball appears during the 1890s to distinguish a drink composed only of a distilled spirit and a mixer.\nPublished in 1902 by Farrow and Jackson, \"Recipes of American and Other Iced Drinks\" contains recipes for nearly two dozen cocktails, some still recognizable today.\nThe first \"cocktail party\" ever thrown was allegedly by Julius S. Walsh Jr. of St. Louis, Missouri, in May 1917. Walsh invited 50 guests to her home at noon on a Sunday. The party lasted an hour until lunch was served at 1p.m. The site of this first cocktail party still stands. In 1924, the Roman Catholic Archdiocese of St. Louis bought the Walsh mansion at 4510 Lindell Boulevard, and it has served as the local archbishop's residence ever since.\nDuring Prohibition in the United States (1920\u20131933), when alcoholic beverages were illegal, cocktails were still consumed illegally in establishments known as speakeasies. The quality of the liquor available during Prohibition was much worse than previously. There was a shift from whiskey to gin, which does not require aging and is, therefore, easier to produce illicitly. Honey, fruit juices, and other flavorings served to mask the foul taste of the inferior liquors. Sweet cocktails were easier to drink quickly, an important consideration when the establishment might be raided at any moment. With wine and beer less readily available, liquor-based cocktails took their place, even becoming the centerpiece of the new cocktail party.\nCocktails became less popular in the late 1960s and through the 1970s, until resurging in the 1980s with vodka often substituting for the original gin in drinks such as the martini. Traditional cocktails began to make a comeback in the 2000s, and by the mid-2000s there was a renaissance of cocktail culture in a style typically referred to as mixology that draws on traditional cocktails for inspiration but uses novel ingredients and often complex flavors.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "7601", "revid": "47033271", "url": "https://en.wikipedia.org/wiki?curid=7601", "title": "Coptic Orthodox Church", "text": "Christian denomination based in Egypt\nThe Coptic Orthodox Church (; ), also known as the Coptic Orthodox Patriarchate of Alexandria, is an Oriental Orthodox Christian church based in Egypt. The head of the church and the See of Alexandria is the pope of Alexandria on the Holy Apostolic See of Saint Mark, who also carries the title of Father of fathers, Shepherd of shepherds, Ecumenical Judge and the 13th among the Apostles.\nThe See of Alexandria is titular. The Coptic pope presides from Saint Mark's Coptic Orthodox Cathedral in the Abbassia District in Cairo. The church follows the Coptic Rite for its liturgy, prayer and devotional patrimony. Adherents of the Coptic Orthodox Church make up Egypt's largest and most significant minority population, and the largest population of Christians in the Middle East and North Africa (MENA). They make up the largest share of the approximately 10 million Christians in Egypt.\nThe Coptic Orthodox Church was established by Saint Mark, an apostle and evangelist, during the middle of the 1st century (c.\u2009AD 42). Due to disputes concerning the nature of Christ, the Oriental Orthodox Churches were in schism after the Council of Chalcedon in AD 451.\nAfter AD 639, Egypt was ruled by its Islamic conquerors from Arabia. In the 12th century, the church relocated its seat from Alexandria to Cairo. The same century also saw the Copts become a religious minority. During the 14th and 15th centuries, Nubian Christianity was supplanted by Islam. In the 19th and 20th centuries, the larger body of ethnic Egyptian Christians began to call themselves Coptic Orthodox, to distinguish themselves from the Catholic Copts and from the Eastern Orthodox, who are mostly Greek. In 1959, the Ethiopian Orthodox Tewahedo Church was granted autocephaly. This was extended to the Eritrean Orthodox Tewahedo Church in 1998 following the successful Eritrean War of Independence from Ethiopia. Since the 2011 Egyptian revolution, Coptic Christians have suffered increased religious discrimination and violence.\nHistory.\nApostolic foundation.\nAccording to tradition, the Coptic Church was founded by St. Mark the Evangelist c.\u2009AD 42; it regards itself as the subject of many prophecies in the Old Testament.\nCoptic language in the church.\nThe Coptic language is a universal language used in Coptic churches in every country. It descends from Ancient Egyptian and uses the Coptic alphabet, a script descended from the Greek alphabet with added characters derived from the Demotic script. Today, the Bohairic dialect of Coptic is used primarily for liturgical purposes. Many of the hymns in the liturgy are in Coptic and have been passed down for many centuries. The language is used to preserve Egypt's original language, which was banned by the Arab invaders, who ordered the use of Arabic instead. However, most Copts speak Arabic, the official language of Egypt. Hence, Arabic is also used in church services nowadays. The service books, though written in Coptic, have Arabic text in parallel columns.\nCatechetical School of Alexandria.\nThe Catechetical School of Alexandria is the oldest catechetical school in the world. Jerome records that the Christian School of Alexandria was founded by Mark himself.\nThe theological college of the catechetical school was re-established in 1893.\nThe school became a leading center of the allegorical method of biblical interpretation, espoused rapprochement between Greek culture and the Christian faith, and attempted to assert orthodox Christian teachings against heterodox views in an era of doctrinal flux.\nCouncil of Nicaea.\nIn the 4th century, an Alexandrian presbyter named Arius began a theological dispute about the nature of Christ that spread throughout the Christian world and is now known as Arianism. The Council of Nicea in AD\u00a0325 was convened by Emperor Constantine I after Pope Alexander I of Alexandria proposed holding a council to respond to heresies. A council under the presidency of Hosius of Cordova attempted to resolve the dispute. This eventually led to the formulation of the Symbol of Faith, also known as the Nicene Creed.\nCouncil of Constantinople.\nIn AD\u00a0381, Pope Timothy I of Alexandria presided over the second ecumenical council known as the First Council of Constantinople, to judge Macedonius, who denied the Divinity of the Holy Spirit. This council completed the Nicene Creed with this confirmation of the divinity of the Holy Spirit:\nWe believe in the Holy Spirit, the Lord, the Giver of Life, who proceeds from the Father, who with the Father and the Son is worshiped and glorified who spoke by the Prophets and in One, Holy, Catholic, and Apostolic church. We confess one Baptism for the remission of sins and we look for the resurrection of the dead and the life of the coming age, Amen\nCouncil of Ephesus.\nAnother theological dispute in the 5th century occurred over the teachings of Nestorius, the patriarch of Constantinople who taught that God the Word was not hypostatically joined with human nature, but rather dwelt in the man Jesus. As a consequence of this, he denied the title \"Mother of God\" (Theotokos) to the Virgin Mary, declaring her instead to be \"Mother of Christ\" \"Christotokos\".\nThe council confirmed the teachings of Athanasius and confirmed the title of Mary as \"Mother of God\". It also clearly stated that anyone who separated Christ into two hypostases was anathema, as Cyril had said that there is \"One Nature for God the Word Incarnate\" (\"Mia Physis tou Theou Logou Sesark\u014dmen\u0113\"). The introduction to the creed is formulated as follows:\nWe magnify you O Mother of the True Light and we glorify you O saint and Mother of God \"(Theotokos)\" for you have borne unto us the Saviour of the world. Glory to you O our Master and King: Christ, the pride of the Apostles, the crown of the martyrs, the rejoicing of the righteous, firmness of the churches and the forgiveness of sins. We proclaim the Holy Trinity in One Godhead: we worship Him, we glorify Him, Lord have mercy, Lord have mercy, Lord bless us, Amen.\nCouncil of Chalcedon.\nThe church of Alexandria was part in communion with the rest of Christendom until the Council of Chalcedon. When, in AD\u00a0451, Emperor Marcian attempted to heal divisions in the church, the response of Pope Dioscorus\u2013the Pope of Alexandria who was later exiled\u2013was that the emperor should not intervene in the affairs of the church. It was at Chalcedon that the emperor, through the imperial delegates, enforced harsh disciplinary measures against Pope Dioscorus in response to his boldness. In AD\u00a0449, Pope Dioscorus headed the 2nd Council of Ephesus, called the \"Robber Council\" by Chalcedonian historians. It held to the Miaphysite formula which upheld the Christology of \"One Incarnate Nature of God the Word\" (Greek: \u03bc\u03af\u03b1 \u03c6\u03cd\u03c3\u03b9\u03c2 \u0398\u03b5\u03bf\u1fe6 \u039b\u03cc\u03b3\u03bf\u03c5 \u03c3\u03b5\u03c3\u03b1\u03c1\u03ba\u03c9\u03bc\u03ad\u03bd\u03b7 (\"mia physis Theou Logou sesark\u014dmen\u0113\")).\nIn terms of Christology, the Oriental Orthodox (Non-Chalcedonians) understanding is that Christ is \"One Nature\u2014the Logos Incarnate,\" \"of\" the full humanity and full divinity. The Chalcedonians' understanding is that Christ is \"recognized in\" two natures, full humanity and full divinity. Oriental Orthodoxy contends that such a formulation is no different from what the Nestorians teach.\nFrom that point onward, Alexandria would have two patriarchs: the non-Chalcedonian native Egyptian one, now known as the Coptic pope of Alexandria and patriarch of All Africa on the Holy Apostolic See of St. Mark, and the Melkite or Imperial patriarch, now known as the Greek Orthodox patriarch of Alexandria.\nAlmost the entire Egyptian population rejected the terms of the Council of Chalcedon and remained faithful to the native Egyptian Church (now known as the Coptic Orthodox Church).\nBy anathematizing Pope Leo because of the tone and content of his tome, as per Alexandrine Theology perception, Pope Dioscorus was found guilty of doing so without due process; in other words, the Tome of Leo was not a subject of heresy in the first place, but it was a question of questioning the reasons behind not having it either acknowledged or read at the Second Council of Ephesus in AD\u00a0449. Pope Dioscorus of Alexandria was never labeled as a heretic by the council's canons.\nCopts also believe that the pope of Alexandria was forcibly prevented from attending the third congregation of the council from which he was ousted, apparently the result of a conspiracy tailored by the Roman delegates.\nBefore the current positive era of Eastern and Oriental Orthodox dialogues, Chalcedonians sometimes used to call the non-Chalcedonians \"Monophysites\", though the Coptic Orthodox Church in reality regards Monophysitism as a heresy. The Chalcedonian doctrine in turn came to be known as \"Dyophysite\". A term that comes closer to Coptic Orthodoxy is Miaphysite, which refers to a conjoined nature for Christ, both human and divine, united indivisibly in the Incarnate Logos.\nMuslim conquest of Egypt.\nThe Muslim invasion of Egypt took place in AD\u00a0639. Relying on eyewitness testimony, Bishop John of Nikiu in his Chronicle provides a graphic account of the invasion from a Coptic perspective. Although the Chronicle has only been preserved in an Ethiopic (Ge'ez) text, some scholars believe that it was originally written in Coptic. John's account is critical of the invaders who he says \"despoiled the Egyptians of their possessions and dealt cruelly with them\", and he details the atrocities committed by the Muslims against the native population during the conquest:And when with great toil and exertion they had cast down the walls of the city, they forthwith made themselves masters of it, and put to the sword thousands of its inhabitants and of the soldiers, and they gained an enormous booty, and took the women and children captive and divided them amongst themselves, and they made that city a desolation.\nThough critical of the Muslim commander (Amr ibn al-As), who, during the campaign, he says \"had no mercy on the Egyptians, and did not observe the covenant they had made with him, for he was of a barbaric race\", he does note that following the completion of the conquest, Amr \"took none of the property of the Churches, and he committed no act of spoilation or plunder, and he preserved them throughout all his days.\"\nDespite the political upheaval, the Egyptian population remained mainly Christian. However, gradual conversions to Islam over the centuries had changed Egypt from a Christian to a largely Muslim country by the end of the 12th century. Another scholar writes that a combination of \"repression of Coptic revolts\", Arab-Muslim immigration, and Coptic conversion to Islam resulted in the demographic decline of the Copts. Egypt's Umayyad rulers taxed Christians at a higher rate than Muslims, driving merchants towards Islam and undermining the economic base of the Coptic Church. Although the Coptic Church did not disappear, the Umayyad tax policies made it difficult for the church to retain the Egyptian elites.\nUnder Islamic rule (640\u20131800).\nIn 969, Egypt entered the Fatimid dynasty (in Egypt from 969 to 1171), who adopted a largely favorable attitude toward the Christians. The major exception to this was the persecution led by Caliph al-Hakim between 1004 and 1013, which included clothing regulations, prohibition of publicly celebrating Christian festivals, and dismissal of Christian and Jewish functionaries. However, at the end of his reign al-Hakim rescinded these measures, allowing the Copts to regain privileged positions within the administration.\nThe Coptic patriarchal residence moved from Alexandria to Cairo during the patriarchate of Cyril II (1078\u201392). This move was at the demand of the grand vizier Badr al-Jamali, who insisted that the pope establish himself in the capital. When Saladin entered Egypt in 1163, this ushered in a government focused on defending Sunni Islam. Christians were again discriminated against, and meant to show modesty in their religious ceremonies and buildings.\nDuring the Ottoman period, Copts were classified alongside other Oriental Orthodox and Nestorian peoples under the Armenian millet.\nIn 1798, the French invaded Egypt unsuccessfully and the British helped the Turks to regain power over Egypt under the Muhammad Ali dynasty.\nFrom the 19th century-1952 revolution.\nThe position of Copts began to improve early in the 19th century under the stability and tolerance of the Muhammad Ali Dynasty. The Coptic community ceased to be regarded by the state as an administrative unit. In 1855 the jizya tax was abolished by Sa'id Pasha. Shortly thereafter, the Copts started to serve in the Egyptian army.\nTowards the end of the 19th century, the Coptic Church underwent phases of new development. In 1853, Pope Cyril IV established the first modern Coptic schools, including the first Egyptian school for girls. He also founded a printing press, which was only the second national press in the country. The pope established very friendly relations with other denominations, to the extent that when the Greek Patriarch in Egypt had to absent himself from the country for a long period of time, he left his church under the guidance of the Coptic patriarch.\nThe Theological College of the School of Alexandria was reestablished in 1893. It began its new history with five students, one of whom was later to become its dean. Today it has campuses in Alexandria and Cairo, and in various dioceses throughout Egypt, as well as outside Egypt. It has campuses in New Jersey, Los Angeles, Sydney, Melbourne, and London, where potential clergymen and other qualified men and women study many subjects, including theology, church history, missionary studies, and the Coptic language.\nFrom the mid 20th-early 21st centuries.\nIn 1959, the Ethiopian Orthodox Tewahedo Church was granted its first own patriarch Abuna Basilios by Pope Cyril VI. Furthermore, the Eritrean Orthodox Tewahedo Church similarly became independent of the Ethiopian Orthodox Tewahedo Church in 1994, when four bishops were consecrated by Pope Shenouda III of Alexandria to form the basis of a local Holy Synod of the Eritrean Church. In 1998, the Eritrean Orthodox Tewahedo Church gained its autocephaly from the Coptic Orthodox Church when its first patriarch was enthroned by Pope Shenouda III.\nSince the 1980s theologians from the Oriental (non-Chalcedonian) Orthodox and Eastern (Chalcedonian) Orthodox churches have been meeting in a bid to resolve theological differences, and have concluded that many of the differences are caused by the two groups using different terminology to describe the same thing.\nIn the 1990s, the Orthodox Church of the British Isles (formerly the Catholicate of the West) joined the Coptic Orthodox Church as a diocese named the British Orthodox Church. By 2015, it formally separated with the Coptic Orthodox Church as a non-canonical, autocephalous church.\nIn the summer of 2001, the Coptic Orthodox and Greek Orthodox patriarchates of Alexandria agreed to mutually recognize baptisms performed in each other's churches, making re-baptisms unnecessary, and to recognize the sacrament of marriage as celebrated by the other.\nIn Tahrir Square, Cairo, on Wednesday 2 February 2011, Coptic Christians joined hands to provide a protective cordon around their Muslim neighbors during salat (prayers) in the midst of the 2011 Egyptian Revolution.\nContinued persecution into the 21st century.\nWhile Copts have cited instances of persecution throughout their history, Human Rights Watch has noted growing religious intolerance and sectarian violence against Coptic Christians in recent years, and a failure by the Egyptian government to effectively investigate properly and prosecute those responsible. More than a hundred Egyptian copts were killed in sectarian clashes from 2011 to 2017, and many homes and businesses destroyed. In Minya, 77 cases of sectarian attacks on Copts between 2011 and 2016 were documented by the Egyptian Initiative for Personal Rights. Coptic Christian women and girls are often abducted and disappear.\nIn 2015, 21 men traveled to Libya to support their families. There, they would be kidnapped and beheaded by the Islamic State in Libya.\nContinued church reforms.\nUnder Pope Shenouda III, from 1971 to 2012, the church underwent a large transformation. Writing in 2013, the theologian Samuel Tadros stated \"Today's Coptic Church as an institution is built solely on his vision\". For the first time in its history, the synod codified its internal laws. It also established numerous coptic institutions within and outside of Egypt. Shenouda raised the number of bishops from 26 to 117 and ordained hundreds of priests, which greatly reduced the influence of any one bishop. Shenouda also instituted a yearly meeting of the synod, which greatly expanded the number of laws governing the church. This included instituting church curriculums for the education of new priests, new deacons, and newly weds. For the first time in the Coptic Church's modern history, women could become ordained as deacons. The synod also adopted a model for community development, dramatically increasing the scope of community services provided by the church, including: hospitals, adult literacy schools, orphanages, libraries, and community centres. Much of this work was fuelled by donations from wealthy Coptic industrialists and Copts from abroad. Shenouda also held talks with the Eastern Orthodox and Roman Catholic churches, in an effort to promote ecumenism . On 10 May 1973, Shenouda visited the Vatican, where a joint Christological declaration was issued jointly by the Coptic Orthodox and Catholic churches.\nPope Shenouda also increased the church's involvement in politics, seeing it as a way to advocate for the interest of Copts, during the rise of Islamism in Egypt and increase in terrorist attacks. The president of Egypt, Anwar Sadat ordered that Shenouda be put into exile in a Coptic Monastery far away from Cairo in 1981. This exile was short lived, ending when Sadat was assassinated by Muslim extremists a few months later. Under president Hosni Mubarak, Shenouda continued his political stance and often protested persecution of Copts by leaving Cairo and staying in seclusion, which often caused the regime to quickly address issues. Shenouda's political involvement drew criticism from some church members, including the prominent monk Father Matta El Meskeen.\nOn 17 March 2012, Pope Shenouda died, leaving many Copts mourning and worrying as tensions rose with Muslims. Shenouda constantly met with Muslim leaders in order to create peace, his death resulting in concerns that without his mediation good relations would break down. Many were worried about increased Islamic control of Egypt as the Muslim Brotherhood won 70% of the parliamentary elections. Shenouda's approach to church leadership has, in part, been adopted by the current patriarch. Pope Tawadros II of Alexandria maintains relations with the Egyptian government and other churches. However, while Shenouda was critical of the expanded influence of Protestant teaching and books in Coptic churches, Tawadros has increased ecumenical dialogue with several Protestant churches. In 2013, Tawadros supported the movement demanding the removal of Egyptian Islamist president Mohamed Morsi. However, Tawadros has been a relatively less political figure than his predecessor and has expressed support for the Egyptian government's institutions during crises.\nIn 2020, a woman in Florida accused a former priest of sexual assault when she was a minor. She claimed that he was defrocked in 2014, but continued presenting himself as a priest. In response, the synod issued a public statement disavowing him and instituted anti-abuse measures. Several dioceses in North America and Europe issued statements in support of sexual assault survivors.\nOn 10 May 2023, Pope Tawadros visited the Vatican to celebrate Coptic-Catholic Friendship day and the 50 year anniversary of the meeting between Pope Paul VI and Pope Shenouda III. In this same year Pope Francis announced that the 21 Coptic Martyrs killed by ISIS in Libya in 2015 would be added to the Catholic Roman Martyrology, and Pope Tawadros gifted relics from each of the 21 martyrs to the Vatican.\nFasts, feasts, liturgy and canonical hours.\nCommunicants of the Coptic Orthodox Church use a breviary known as the Agpeya to pray the canonical hours at seven fixed prayer times while facing in the eastward direction, in anticipation of the Second Coming of Jesus; this Christian practice has its roots in Psalm 119:164, in which the prophet David prays to God seven times a day. Church bells enjoin Christians to pray at these hours. Before praying, they wash their hands and face to be clean before and present their best to God; shoes are removed to acknowledge that one is offering prayer before a holy God. During each of the seven fixed prayer times, Coptic Orthodox Christians pray \"prostrating three times in the name of the Trinity; at the end of each Psalm ... while saying the 'Alleluia';\" and 41 times for each of the Kyrie eleisons present in a canonical hour. In the Coptic Orthodox Church, it is customary for women to wear a Christian headcovering when praying. The Coptic Orthodox Church observes days of ritual purification. However, while meat that still contains blood after cooking is discouraged from being eaten, the Coptic Church does not forbid its members from consuming any particular type of food, unlike in Islam or Judaism.\nAll churches of the Coptic Orthodox Church are designed to face the eastward direction of prayer and efforts are made to remodel churches obtained from other Christian denominations that are not built in this fashion.\nIn Coptic Orthodox Christianity, fasting is defined as going without meat or dairy. With respect to Eucharistic discipline, Coptic Orthodox Christians fast from midnight onwards (or at least nine hours) prior to receiving the sacrament of Holy Communion. They fast every Wednesday and Friday of the year (Wednesdays in remembrance of the betrayal of Christ, and on Fridays in remembrance of His crucifixion and death). In total, fast days in a year for Coptic Orthodox Christians numbers between 210 and 240. This means that Copts abstain from all animal products for up to two-thirds of each year. The fasts for Advent and Lent are 43 days and 55 days, respectively. In August, before the celebration of the Dormition of the Mother of God, Coptic Christians fast 15 days; fasting is also done before the feast of Feast of Saints Peter and Paul, starting from the day of Pentecost. Married couples refrain from sexual relations during Lent \"to give themselves time for fasting and prayer\".\nChristmas has been a national holiday in Egypt since 2003. It is the only Christian holiday in Egypt. Coptic Christmas, which usually falls on January 6 or 7 is a major feast. Other major feasts are Epiphany, Palm Sunday, Easter, Pentecost, Ascension, and Annunciation. These are known in the Coptic world as the Seven Major Feasts. Major feasts are always preceded by fasts. Additionally, the Coptic Orthodox Church also has Seven Minor Feasts: the Circumcision of the Lord, Entrance into the Temple, Entrance into Egypt, Transfiguration, Maundy Thursday, Thomas Sunday, and Great Lent. Furthermore, there are several indigenous feasts of the Theotokos. There are also other feasts commemorating the martyrdom of important saints from Coptic history.\nDemographics.\nAvailable Egyptian census figures and other third-party survey reports have not reported more than 4 million Coptic Orthodox Christians in Egypt. However media and other agencies, sometimes taking into account the claims of the church itself, generally approximate the Coptic Orthodox population at 10% of the Egyptian population or 10 million people. Egyptian Copts are the biggest Christian community in the Arab world. Estimates of their numbers vary, but generally range between 4.7 and 7.1 million. The majority of them live in Egypt under the jurisdiction of the Coptic Orthodox Church. Since 2006, Egyptian censuses have not reported on religion and church leaders have alleged that Christians were under-counted in government surveys. In 2017, a government owned newspaper Al Ahram estimated the percentage of Copts at 10 to 15% and the membership claimed by the Coptic Orthodox Church is in the range of 20 to 25 million.\nThere are also significant numbers in the diaspora outside Africa in countries such as the United States, Canada, Australia, France, and Germany. The exact number of Egyptian born Coptic Orthodox Christians in the diaspora is hard to determine and is roughly estimated to be close to 1 million.\nThere are between 150,000 and 200,000 adherents in Sudan.\nJurisdiction outside Egypt.\nBesides Egypt, the Church of Alexandria has jurisdiction over all of Africa. The following autocephalous churches have strong historical ties to the Coptic Orthodox Church.\nEthiopian Orthodox Tewahedo Church.\nTradition holds that Ethiopia was first evangelized by St. Matthew and St. Bartholomew in the 1st century ce, and the first Ethiopian convert is thought to have been the eunuch in Jerusalem mentioned in The Acts of the Apostles (8:27\u201340). Ethiopia was further Christianized in the 4th century ce by two men (likely brothers) from Tyre\u2014St. Frumentius. Ever since the conversion of Ezana of Axum to Christianity by Frumentius in 325 AD, the Ethiopian Orthodox Tewahedo Church has received its archbishops from the Coptic Orthodox Church. Until the mid-twentieth century, the metropolitans of the Ethiopian church were ethnic Copts. Joseph II consecrated Archbishop Abuna Basilios as the first native head of the Ethiopian Church on 14 January 1951. In 1959, Pope Cyril VI of Alexandria crowned Abuna Basilios as the first Patriarch of Ethiopia.\nEritrean Orthodox Tewahedo Church.\nFollowing the independence of Eritrea from Ethiopia in 1993, the newly independent Eritrean government appealed to Pope Shenouda III of Alexandria for Eritrean Orthodox autocephaly. In 1994, Pope Shenouda ordained Abune Phillipos as first Archbishop of Eritrea.\nAdministration.\nThe Coptic Orthodox Patriarchate of Alexandria is governed by its Holy Synod, which is headed by the Patriarch of Alexandria. Under his authority are the metropolitan archbishops, metropolitan bishops, diocesan bishops, patriarchal exarchs, missionary bishops, auxiliary bishops, suffragan bishops, assistant bishops, chorbishops and the patriarchal vicars for the Church of Alexandria. They are organized as follows:\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nBibliography.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "7602", "revid": "26202925", "url": "https://en.wikipedia.org/wiki?curid=7602", "title": "The Family International", "text": "1968 American new religious movement\nThe Family International (TFI) is an American new religious movement founded in 1968 by David Brandt Berg. The group has gone under a number of different names since its inception, including Teens for Christ, The Children of God (COG), The Family of Love, or simply The Family.\nA British court case found the group was an authoritarian cult which engaged in the systematic physical and sexual abuse of children, resulting in lasting trauma among survivors. The group has also been accused of targeting vulnerable people.\nOverview.\nAccording to the Canadian Broadcasting Corporation, \"at its height\" the Family movement had \"tens of thousands of members, including River and Joaquin Phoenix, Rose McGowan, and Jeremy Spencer\".\nTFI initially spread a message of salvation, apocalypticism, spiritual \"revolution and happiness\", and distrust of the outside world, which the members called \"The System\". Like some other evangelical Christian groups, it \"foretold the coming of a dictator called the anti-Christ, the rise of a brutal One World Government, and its eventual overthrow by Jesus Christ, in the Second Coming\".\nIn 1976, TFI began a method of evangelism called Flirty Fishing that used sex to \"show God's love and mercy\" and win converts, resulting in controversy. TFI's founder and prophetic leader, David Berg\u2014who adopted the name \"Moses David\" while in the Laurentides in Canada, and was also referred to \"Father David\" by members\u2014gave himself the titles of \"King\", \"The Last Endtime Prophet\", \"Moses\", and \"David\".\nBerg communicated with his followers via \"Mo Letters\"\u2014letters of instruction and counsel on myriad spiritual and practical subjects\u2014until his death in late 1994. After his death, his widow Karen Zerby became the leader of TFI, taking the titles of \"Queen\" and \"Prophetess\". Zerby married Steve Kelly (also known as Peter Amsterdam), an assistant of Berg's whom Berg had handpicked as her \"consort\". Kelly took the title of \"King Peter\" and became the face of TFI, speaking in public more often than either Berg or Zerby. There have been multiple allegations of child sexual abuse made by past members, including against Zerby.\nBerg preached a combination of traditional Christian evangelism, with elements popular with the counterculture of the 1960s. There was much \"end-of-the-world imagery\" found in the Book of Revelation of the New Testament, preaching of impending doom for America and the ineffectiveness of established churches. Berg \"urged a return to the early Christian community described in the Bible's Book of Acts, in which believers lived together and shared all,\" resembling the communal living of late 1960s hippies.\nHistory.\nThe Children of God (1968\u20131977).\nThe founder of the movement, David Brandt Berg (1919\u20131994), was a former Christian and Missionary Alliance pastor (an evangelical Protestant organization). Berg started in 1968 as an evangelical preacher with a following of \"born-again hippies\" who gathered at a coffeehouse in Huntington Beach, in Orange County, California. In 1969, after having a revelation \"that California would be hit by a major earthquake\", he left Huntington Beach and \"took his followers on the road\".\nThey would proselytize in the streets and distribute pamphlets. Leaders within The Children of God (COG) were referred to as \"The Chain\". Members of COG founded communes, first called colonies (now referred to as homes), in various cities.\nBerg communicated with his followers by writing letters. He published nearly 3,000 letters over a period of 24 years, referred to as the \"Mo Letters\". In a letter written in January 1972, Berg stated that he was God's prophet for the contemporary world, attempting to further solidify his spiritual authority within the group. Berg's letters also contained public acknowledgement of his own failings and weaknesses, for example, he issued a Mo Letter entitled \"My confession -- I was an alcoholic!\" (ML #1406 Summer 1982) relating his depression after some of his closest supporters quit in 1978.\nIn 1972, a Mo Letter reportedly entitled \"Flee as a Bird to Your Mountain\" was interpreted by some members, including Ruth Gordon, author of \"Children of Darkness\" about the cult, as a warning to leave America. \"God was going to destroy the U.S. ... and we had to get out.\" This, along with the pressure members felt that parents were trying to \"rescue\" children who had joined CoG, encouraged members to \"[migrate] abroad\u2014first to Europe, eventually to Latin America and East Asia\".\nBy 1972, COG stated it had 130 communities around the world, and by the mid-1970s, it had \"colonies\" in an estimated 70 countries. BBC reported 10,000 full-time COG members in the 1970s.\nIn 1976, Berg had introduced a new proselytizing method called Flirty Fishing (or FFing), which encouraged female members to \"show God's love\" through sexual relationships (religious prostitution) with potential converts. Flirty Fishing was practiced by members of Berg's inner circle starting in 1973, and was introduced to the general membership in 1976.\nThe Family of Love (1978\u20131981).\nThe Children of God was abolished in February 1978, and Berg renamed his group \"The Family of Love\" In what Berg called the \"Re-organization Nationalization Revolution\" (or RNR). Berg reorganized the movement, dismissing \"more than 300 leading members after hearing unspecified 'reports of serious misconduct and abuse of their positions.\" Reportedly involved were The Chain's abuse of authority, and disagreements within it about the continued use of Flirty Fishing. The group was also accused of sexually abusing and raping minors within the organization, with considerable evidence to support this claim. One eighth of the total membership left the movement. Those who remained became part of a reorganized movement called the Family of Love, and later, The Family. The majority of the group's beliefs remained the same.\nThe Family of Love era was characterized by international expansion.\nAfter 1978 Flirty Fishing \"increased drastically\" and became common practice within the group. A Mo Letter from 1980 (ML #999 May 1980) for example was headlined \"The Devil Hates Sex! --- But God Loves It!\". \nIn some areas flirty fishers used escort agencies to meet potential converts. According to TFI \"over 100,000 received God's gift of salvation through Jesus, and some chose to live the life of a disciple and missionary\" as a result of Flirty Fishing. Researcher Bill Bainbridge obtained data from TFI suggesting that, from 1974 until 1987, members had sexual contact with 223,989 people while practicing Flirty Fishing.\nThe Family (1982\u20131994).\nAccording to the Family's official history, the group had \"far fewer common standards of conduct\" during The Family of Love stage than it had previously. In the late 1980s the group \"tightened its standards\" \"to ensure that all member communities provide a very wholesome environment for all, particularly the children\", and changed its name to \"The Family\". In March 1989, TF issued a statement that, in \"early 1985\", an urgent memorandum had been sent to all members \"reminding them that any such activities [adult\u2013child sexual contact] are strictly forbidden within our group\" (emphasis in original), and such activities were grounds for immediate excommunication from the group. In January 2005, Claire Borowik, a spokesperson for TFI, stated:\n Due to the fact that our current zero-tolerance policy regarding sexual interaction between adults and underage minors was not in our literature published before 1986, we came to the realization that during a transitional stage of our movement, from 1978 until 1986, there were cases when some minors were subject to sexually inappropriate advances\u00a0... This was corrected officially in 1986, when any contact between an adult and minor (any person under 21 years of age) was declared an excommunicable offense.\nAfter a 1993 expose in the \"Los Angeles Times\", the group broke \"years of virtual silence\" and began \"inviting reporters and religious scholars\" to visit its commune in La Habra, California, where at least a \"Washington Post\" journalist (Gustav Niebuhr) found its members to be \"a clean-cut bunch, friendly and courteous\". At that time The Family claimed to have \"about 9,000 members worldwide, with about 750 scattered across the United States\". The group emphasized its mainstream Christian opposition to abortion, homosexuality, drugs and drunkenness and its respect for Rev. Billy Graham.\nThe Family (1995\u20132003).\nAfter Berg's death in October 1994, Karen Zerby (known in the group as Mama Maria, Queen Maria, Maria David, or Maria Fontaine) assumed leadership of the group.\nIn February 1995, the group introduced the \"Love Charter\", which defined the rights and responsibilities of Charter Members and Homes. The Charter also included the \"Fundamental Family Rules\", a summary of rules and guidelines from past TF publications which were still in effect.\nIn the 1994\u201395 British court case, the Rt. Hon. Lord Justice Alan Ward ruled that the group, including some of its top leaders, had in the past engaged in abusive sexual practices involving minors and had also used severe corporal punishment and sequestration of minors. He found that by 1995 TF had abandoned these practices and concluded that they were a safe environment for children. Nevertheless, he did require that the group cease all corporal punishment of children in the United Kingdom and denounce any of Berg's writings that were \"responsible for children in TF having been subjected to sexually inappropriate behaviour\".\nThe Family International (2004\u2013present).\nThe Love Charter is The Family's set governing document that entails each member's rights, responsibilities and requirements, while the \"Missionary Member Statutes\" and \"Fellow Member Statutes\" were written for the governance of TFI's Missionary member and Fellow Member circles, respectively. FD Homes were reviewed every six months against a published set of criteria. The Love Charter increased the number of single family homes as well as homes that relied on jobs such as self-employment.\nRecent teachings.\nTFI's recent teachings are based on beliefs which they term the \"new [spiritual] weapons\". TFI members believe that they are soldiers in the spiritual war of good versus evil for the souls and hearts of men.\nSpirit Helpers.\n\"Spirit Helpers\" include angels, other religious and mythical figures, and departed humans, including celebrities; for example the goddess Aphrodite, the Snowman, Merlin, the Sphinx, Elvis, Marilyn Monroe, Audrey Hepburn, Richard Nixon, and Winston Churchill.\nThe Keys of the Kingdom.\nTFI believes that the Biblical passage \"I will give you the keys of the kingdom of heaven, and whatsoever you bind on earth will be bound in heaven, and whatsoever you loose on earth will be loosed in heaven\" (Matthew 16:19), refers to an increasing amount of spiritual authority that was given to Peter and the early disciples. According to TFI beliefs, this passage refers to keys that were hidden and unused in the centuries that followed, but were again revealed through Karen Zerby as more power to pray and obtain miracles. TFI members call on the various Keys of the Kingdom for extra effect during prayer. The Keys, like most TFI beliefs, were published in magazines that looked like comic-books in order to make them teachable to children.\nLoving Jesus.\n\"Loving Jesus\" is a term TFI members use to describe their intimate, sexual relationship with Jesus. TFI describes its \"Loving Jesus\" teaching as a radical form of bridal theology. They believe the church of followers is Christ's bride, called to love and serve him with wifely fervor; however, this bridal theology is taken further, encouraging members to imagine Jesus is joining them during sexual intercourse and masturbation. Male members are cautioned to visualize themselves as women, in order to avoid a homosexual relationship with Jesus. Many TFI publications, and spirit messages claimed to be from Jesus himself, elaborate this intimate, sexual relation they believe Jesus desires and needs. TFI imagines itself as his special \"bride\" in graphic poetry, guided visualizations, artwork, and songs. Some TFI literature is not brought into conservative countries for fear it may be classified at customs as pornography. The literature outlining this view of Jesus and his desire for a sexual relationship with believers was edited for younger teens, then further edited for children.\nCriticism and accusations of sexual assault.\nThe Family has been found liable in a British court, and also criticized by the press and the anti-cult movement. Ex-members have accused the Family's leadership of following \"a policy of lying to outsiders\", being \"steeped in a history of sexual deviance\" and even meddling \"in Third World politics\". The Family replies that it is a victim of \"persecution\".\nAllegations of abuse and mistreatment have been publicly expressed by some of those who have left the group; examples include sisters Celeste Jones, Kristina Jones, and Juliana Buhring and Daniella Mestyanek Young, who both wrote books on their lives in TFI.\nIn 1971, an organization called FREECOG was founded by concerned parents and others, including deprogrammer Ted Patrick to free members of the COG from their involvement in the group.\nAt least one individual growing up in the family (Verity Carter) during the Children of God era described being sexually abused \"from the age of four by members of the... cult, including her own father\". She blames the philosophy of David Berg, who told members that \"God was love and love was sex\", so that sex should not be limited by age or relationship. Carter also complains of being \"repeatedly beaten and whipped for the smallest of transgressions\", being denied \"music or television or culture\", or other \"contact with the outside world\", so that she had \"no idea how the world worked\" other than how to manipulate the \"systemites\" (outsiders), like social workers.\nAuthor Don Lattin interviewed numerous members of the Family for his book \"Jesus Freaks\". In a review of his book, Paul Burgarino describes Berg as \"drawing from the remnants of hippie life\u2014people with nothing to lose, nowhere to go, and no Christian background\" to alert them to deviations in Berg's preaching. One ex\u2013Children of God member, Jerry Golland, describes himself at the time of joining the group as penniless and so depressed that the Children of God scraped him \"off the street\". Members would \"learn to spot, you know... a vulnerable person. We called them sheep\", Golland told the Canadian Broadcasting Corporation.\nPressure to raise money could also be intense. Ex-member Golland says that members who were good at raising money and distributing the pamphlets were called \"Shiners\". Those with poor sales were called \"Shamers\". \"If you missed your quota you could not come home for dinner\", he said.\nMedia produced by the group.\nThe Family International produced multiple pop songs along with music videos. One notable song released in 1985 was \"Cathy Don't Go\", about a woman who goes to the supermarket where customers have barcodes on their hands and foreheads, and who almost gets implanted with a 666 microchip. The cult also created children's shows, with an example being \"Life With Grandpa\", which had characters based on Berg and his family, and featured sexual themes alongside Christianity-related life lessons.\nAutobiographical accounts.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\nAcademic.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nJournalistic and popular.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "7603", "revid": "50404588", "url": "https://en.wikipedia.org/wiki?curid=7603", "title": "CIT", "text": "CIT or cit may refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "7604", "revid": "2179844", "url": "https://en.wikipedia.org/wiki?curid=7604", "title": "Code of Hammurabi", "text": "Babylonian legal text\nThe Code of Hammurabi is a Babylonian legal text composed during 1755\u20131750 BC. It is the longest, best-organized, and best-preserved legal text from the ancient Near East. It is written in the Old Babylonian dialect of Akkadian, purportedly by Hammurabi, sixth king of the First Dynasty of Babylon. The primary copy of the text is inscribed on a basalt stele tall.\nThe stele was rediscovered in 1901 at the site of Susa in present-day Iran, where it had been taken as plunder six hundred years after its creation. The text itself was copied and studied by Mesopotamian scribes for over a millennium. The stele now resides in the Louvre Museum.\nThe top of the stele features an image in relief of Hammurabi with Shamash, the Babylonian sun god and god of justice. Below the relief are about 4,130 lines of cuneiform text: one fifth contains a prologue and epilogue in poetic style, while the remaining four fifths contain what are generally called the laws. In the prologue, Hammurabi claims to have been granted his rule by the gods \"to prevent the strong from oppressing the weak\". The laws are casuistic, expressed as \"if... then\" conditional sentences. Their scope is broad, including, for example, criminal law, family law, property law, and commercial law.\nModern scholars responded to the Code with admiration at its perceived fairness and respect for the rule of law, and at the complexity of Old Babylonian society. There was also much discussion of its influence on the Mosaic Law. Scholars quickly identified \u2014the \"eye for an eye\" principle\u2014underlying the two collections. Debate among Assyriologists has since centred around several aspects of the Code: its purpose, its underlying principles, its language, and its relation to earlier and later law collections.\nDespite the uncertainty surrounding these issues, Hammurabi is regarded outside Assyriology as an important figure in the history of law and the document as a true legal code. The U.S. Capitol has a relief portrait of Hammurabi alongside those of other historic lawgivers. There are replicas of the stele in numerous institutions, including the headquarters of the United Nations in New York City, the Pergamon Museum in Berlin and the University of Chicago's Institute for the Study of Ancient Cultures.\n&lt;templatestyles src=\"Template:TOC limit/styles.css\" /&gt;\nBackground.\nHammurabi.\nHammurabi (or Hammurapi), the sixth king of the Amorite First Dynasty of Babylon, ruled from 1792 to 1750 BC (middle chronology). He secured Babylonian dominance over the Mesopotamian plain through military prowess, diplomacy, and treachery. When Hammurabi inherited his father Sin-Muballit's throne, Babylon held little local sway; the local hegemon was Rim-Sin of Larsa. Hammurabi waited until Rim-Sin grew old, then conquered his territory in one swift campaign, leaving his organisation intact. Later, Hammurabi betrayed allies in Eshnunna, Elam, and Mari to gain their territories.\nHammurabi had an aggressive foreign policy, but his letters suggest he was concerned with the welfare of his many subjects and was interested in law and justice. He commissioned extensive construction works, and in his letters, he frequently presents himself as his people's shepherd. Justice is also a theme of the prologue to the Code, and \"the word translated 'justice' []... is one whose root runs through both prologue and epilogue\".\nEarlier law collections.\nAlthough Hammurabi's Code was the first Mesopotamian law collection to be discovered, it was not the first written; several earlier collections survive. These collections were written in Sumerian and Akkadian. They also purport to have been written by rulers. There were almost certainly more such collections, as statements of other rulers suggest the custom was widespread. The similarities between these law collections make it tempting to assume a consistent underlying legal system. As with the Code of Hammurabi, however, it is difficult to interpret the purpose and underlying legal systems of these earlier collections, prompting numerous scholars to question whether this should be attempted. Extant collections include:\nThere are additionally thousands of documents from the practice of law, from before and during the Old Babylonian period. These documents include contracts, judicial rulings, letters on legal cases, and reform documents such as that of Urukagina, king of Lagash in the mid-3rd millennium BC, whose reforms combatted corruption. Mesopotamia has the most comprehensive surviving legal corpus from before the \" Digest\" of Justinian, even compared to those from ancient Greece and Rome.\nCopies.\nLouvre stele.\nThe first copy of the text found, and still the most complete, is on a stele. The stele is now displayed on the ground floor of the Louvre, in Room 227 of the Richelieu wing. At the top is an image of Hammurabi with Shamash, the Babylonian sun god and god of justice. Below the image are about 4,130 lines of cuneiform text: One-fifth contains a prologue and epilogue, while the remaining four-fifths contain what are generally called the laws. Near the bottom, seven columns of the laws, each with more than eighty lines, were polished and erased in antiquity. The stele was found in three large fragments and reconstructed. It is high, with a circumference is at the summit and at the base. Hammurabi's image is high and wide.\nThe Louvre stele was found at the site of the ancient Elamite city of Susa. Susa is in modern-day Khuzestan Province, Iran (Persia at the time of excavation). The stele was excavated by the French Archaeological Mission under the direction of Jacques de Morgan. Father Jean-Vincent Scheil published the initial report in the fourth volume of the \"Reports of the Delegation to Persia\" (). According to Scheil, the stele's fragments were found on the tell of the Susa acropolis (), between December 1901 and January 1902. The few, large fragments made assembly easy.\nScheil hypothesised that the stele had been taken to Susa by the Elamite king Shutruk-Nakhunte and that he had commissioned the erasure of several columns of laws to write his legend there. It has been proposed that the relief portion of the stele, especially the beards of Hammurabi and Shamash, was reworked at the same time. Roth suggests the stele was taken as plunder from Sippar, where Hammurabi lived towards the end of his reign.\nOther copies.\nFragments of a second and possibly third stele recording the Code were found along with the Louvre stele at Susa. Over fifty manuscripts containing the laws are known. They were found not only in Susa but also in Babylon, Nineveh, Assur, Borsippa, Nippur, Sippar, Ur, Larsa, and more. Copies were created during Hammurabi's reign, and also after it, since the text became a part of the scribal curriculum. Copies have been found dating from one thousand years after the stele's creation, and a catalog from the library of Neo-Assyrian king Ashurbanipal (685\u2013631 BC) lists a copy of the \"judgments of Hammurabi\". The additional copies fill in most of the stele's original text, including much of the erased section.\nEarly scholarship.\nThe of the Code was published by Father Jean-Vincent Scheil in 1902, in the fourth volume of the \"Reports of the Delegation to Persia\" (). After a brief introduction with details of the excavation, Scheil gave a transliteration and a free translation into French, as well as a selection of images. Editions in other languages soon followed: in German by Hugo Winckler in 1902, in English by C. H. W. Johns in 1903, and in Italian by Pietro Bonfante, also in 1903.\nThe Code was thought to be the earliest Mesopotamian law collection when it was rediscovered in 1902\u2014for example, C. H. W. Johns' 1903 book was titled \"The Oldest Code of Laws in the World\". The English writer H. G. Wells included Hammurabi in the first volume of \"The Outline of History\", and to Wells too the Code was \"the earliest known code of law\". However, three earlier collections were rediscovered afterwards: the Code of Lipit-Ishtar in 1947, the Laws of Eshnunna in 1948, and the Code of Ur-Nammu in 1952. Early commentators dated Hammurabi and the stele to the 23rd century BC. However, this is an earlier estimate than even the \"ultra-long chronology\" would support. The Code was compiled near the end of Hammurabi's reign. This was deduced partly from the list of his achievements in the prologue.\nScheil enthused about the stele's importance and perceived fairness, calling it \"a moral and political masterpiece\". C. H. W. Johns called it \"one of the most important monuments in the history of the human race\". He remarked that \"there are many humanitarian clauses and much protection is given the weak and the helpless\", and even lauded a \"wonderful modernity of spirit\". John Dyneley Prince called the Code's rediscovery \"the most important event which has taken place in the development of Assyriological science since the days of Rawlinson and Layard\". Charles Francis Horne commended the \"wise law-giver\" and his \"celebrated code\". James Henry Breasted noted the Code's \"justice to the widow, the orphan, and the poor\", but remarked that it \"also allows many of the old and na\u00efve ideas of justice to stand\". Commentators praised the advanced society they believed the Code evinced. Several singled out perceived secularism: Owen Jenkins, for example, but even Charles Souvay for the \"Catholic Encyclopedia\", who opined that unlike the Mosaic Law the Code was \"founded upon the dictates of reason\". The question of the Code's influence on the Mosaic Law received much early attention. Scholars also identified Hammurabi with the Biblical figure Amraphel, but this proposal has since been abandoned.\nFrame.\nRelief.\nThe relief appears to show Hammurabi standing before a seated Shamash. Shamash wears the horned crown of divinity and has a solar attribute, flames, spouting from his shoulders. Contrastingly, Scheil, in his , identified the seated figure as Hammurabi and the standing figure as Shamash. Scheil also held that the scene showed Shamash dictating to Hammurabi while Hammurabi held a scribe's stylus, gazing attentively at the god. Martha Roth lists other interpretations: \"that the king is offering the laws to the god; that the king is accepting or offering the emblems of sovereignty of the rod and ring; or\u2014most probably\u2014that these emblems are the measuring tools of the rod-measure and rope-measure used in temple-building\". Hammurabi may even be imitating Shamash. It is certain, though, that the draughtsman showed Hammurabi's close links to the divine realm, using composition and iconography.\nPrologue.\nThe prologue and epilogue together occupy one-fifth of the text. Out of around 4,130 lines, the prologue occupies 300 lines and the epilogue occupies 500. They are in ring composition around the laws, though there is no visual break distinguishing them from the laws. Both are written in poetic style, and, as William W. Davies wrote, \"contain much... which sounds very like braggadocio\".\nThe 300-line prologue begins with an etiology of Hammurabi's royal authority (1\u201349). Anum, the Babylonian sky god and king of the gods, granted rulership over humanity to Marduk. Marduk chose the centre of his earthly power to be Babylon, which in the real world worshipped him as its tutelary god. Marduk established the office of kingship within Babylon. Finally, Anum, along with the Babylonian wind god Enlil, chose Hammurabi to be Babylon's king. Hammurabi was to rule \"to prevent the strong from oppressing the weak\" (37\u201339: ). He was to rise like Shamash over the Mesopotamians (the , literally the \"black-headed people\") and illuminate the land (40\u201344).\nHammurabi then lists his achievements and virtues (50\u2013291). These are expressed in noun form, in the Akkadian first person singular nominal sentence construction \"[noun]... \" (\"I am [noun]\"). The first nominal sentence (50\u201353) is short: \"I am Hammurabi, the shepherd, selected by the god Enlil\" (). Then Hammurabi continues for over 200 lines in a single nominal sentence with the delayed to the very end (291).\nHammurabi repeatedly calls himself , \"pious\" (lines 61, 149, 241, and 272). The metaphor of Hammurabi as his people's shepherd also recurs. It was a common metaphor for ancient Near Eastern kings, but is perhaps justified by Hammurabi's interest in his subjects' affairs. His affinities with many different gods are stressed throughout. He is portrayed as dutiful in restoring and maintaining temples and peerless on the battlefield. The list of his accomplishments has helped establish that the text was written late in Hammurabi's reign. After the list, Hammurabi explains that he fulfilled Marduk's request to establish \"truth and justice\" () for the people (292\u2013302), although the prologue never directly references the laws. The prologue ends \"at that time:\" (303: ) and the laws begin.\nEpilogue.\nUnlike the prologue, the 500-line epilogue is explicitly related to the laws. The epilogue begins (3144'\u20133151'): \"These are the just decisions which Hammurabi... has established\" (). He exalts his laws and his magnanimity (3152'\u20133239'). He then expresses a hope that \"any wronged man who has a lawsuit\" () may have the laws of the stele read aloud to him and know his rights (3240'\u20133256'). This would bring Hammurabi praise (3257'\u20133275') and divine favour (3276'\u20133295'). Hammurabi wishes for good fortune for any ruler who heeds his pronouncements and respects his stele (3296'\u20133359'). However, he invokes the wrath of the gods on any man who disobeys or erases his pronouncements (3360'\u20133641', the end of the text).\nThe epilogue contains much legal imagery, and the phrase \"to prevent the strong from oppressing the weak\" (3202'\u20133203': ) is reused from the prologue. However, the king's main concern appears to be ensuring that his achievements are not forgotten and his name not sullied. The list of curses heaped upon any future defacer is 281 lines long and extremely forceful. Some of the curses are very vivid: \"may the god Sin... decree for him a life that is no better than death\" (3486'\u20133508': ); \"may he [the future defacer] conclude every day, month, and year of his reign with groaning and mourning\" (3497'\u20133501': ); may he experience \"the spilling of his life force like water\" (3435'\u20133436': ). Hammurabi implores a variety of gods individually to turn their particular attributes against the defacer. For example: \"may the [storm] god Adad... deprive him of the benefits of rain from heaven and flood from the springs\" (3509'\u20133515': ); \"may the god [of wisdom] Ea... deprive him of all understanding and wisdom, and may he lead him into confusion\" (3440'\u20133451': ). Gods and goddesses are invoked in this order:\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nLaws.\nThe Code of Hammurabi is the longest and best-organised legal text from the ancient Near East, as well as the best-preserved. The classification below (columns 1\u20133) is Driver &amp; Miles', with several amendments, and Roth's translation is used. Laws represented by letters are those reconstructed primarily from documents other than the Louvre stele.\nTheories of purpose.\nThe purpose and legal authority of the Code have been disputed since the mid-20th century. Theories fall into three main categories: that it is legislation, whether a code of law or a body of statutes; that it is a sort of law report, containing records of past cases and judgments; and that it is an abstract work of jurisprudence. The jurisprudence theory has gained much support within Assyriology.\nLegislation.\nThe term \"code\" presupposes that the document was intended to be enforced as legislation. It was used by Scheil in his , and widely adopted afterwards. C. H. W. Johns, one of the most prolific early commentators on the document, proclaimed that \"the Code well deserves its name\". Recent Assyriologists have used the term without comment, as well as scholars outside Assyriology. However, only if the text was intended as enforced legislation can it truly be called a code of law and its provisions laws.\nThe document, on first inspection, resembles a highly organised code similar to the Code of Justinian and the Napoleonic Code. There is also evidence that , which in the Code of Hammurabi sometimes denote individual \"laws\", were enforced. One copy of the Code calls it a , \"royal decree\", which denotes a kind of enforced legislation.\nHowever, the arguments against this view are strong. Firstly, it would make a very unusual code\u2014Reuven Yaron called the designation \"Code\" a \"persistent misnomer\". Vital areas of society and commerce are omitted. For example, Marc Van De Mieroop observes that the Code \"deals with cattle and agricultural fields, but it almost entirely ignores the work of shepherds, vital to Babylonia's economy\". Then, against the legislation theory more generally, highly implausible circumstances are covered, such as threshing with goats, animals far too unruly for the task (law 270). The laws are also strictly casuistic (\"if... then\"); unlike in the Mosaic Law, there are no apodictic laws (general commands). These would more obviously suggest prescriptive legislation. The strongest argument against the legislation theory, however, is that most judges appear to have paid the Code no attention. This line of criticism originated with Benno Landsberger in 1950. No Mesopotamian legal document explicitly references the Code or any other law collection, despite the great scale of the corpus. Two references to prescriptions on \"a stele\" () come closest. In contrast, numerous judgments cite royal -decrees. Raymond Westbrook held that this strengthened the argument from silence that ancient Near Eastern legal \"codes\" had legal import. Furthermore, many Old Babylonian judgments run entirely counter to the Code's prescriptions.\nLaw report.\nA second theory is that the Code is a sort of law report, and as such contains records of past cases and judgments, albeit phrased abstractly. This would provide one explanation for the casuistic format of the \"laws\"; indeed, Jean Bott\u00e9ro believed he had found a record of a case that inspired one. However, such finds are inconclusive and very rare, despite the scale of the Mesopotamian legal corpus. Furthermore, legal judgments were frequently recorded in Mesopotamia, and they recount the facts of the case without generalising them. These judgments were concerned almost exclusively with points of fact, prompting Martha Roth to comment: \"I know of only one case out of thousands extant that might be said to revolve around a point of law\".\nJurisprudence.\nA third theory, which has gained traction within Assyriology, is that the Code is not a true code but an abstract treatise on how judgments should be formulated. This led Fritz Rudolf Kraus, in an early formulation of the theory, to call it jurisprudence (). Kraus proposed that it was a work of Mesopotamian scholarship in the same category as omen collections like and . Others have provided their own versions of this theory. A. Leo Oppenheim remarked that the Code of Hammurabi and similar Mesopotamian law collections \"represent an interesting formulation of social criticism and should not be taken as normative directions\".\nThis interpretation bypasses the problem of low congruence between the Code and actual legal judgments. Secondly, the Code does bear striking similarities to other works of Mesopotamian scholarship. Key points of similarity are the list format and the order of the items, which Ann Guinan describes as a complex \"serial logic\". Marc Van De Mieroop explains that, in common with other works of Mesopotamian scholarship such as omen lists, king lists, and god lists, the entries of the Code of Hammurabi are arranged according to two principles. These are \"opposition\"\u2014whereby a variable in one entry is altered to make another entry\u2014and \"pointillism\"\u2014whereby new conditions are added to an entry, or paradigmatic series pursued, to generate a sequence. Van De Mieroop provides the following examples:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;If a physician performs major surgery with a bronze lancet upon an [] and thus heals the [], or opens an []'s temple with a bronze lancet and thus heals the []'s eye, he shall take ten shekels of silver (as his fee).\u2014\u200a\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;If a physician performs major surgery with a bronze lancet upon an [] and thus causes the []'s death, or opens an []'s temple with a bronze lancet and thus blinds the []'s eye, they shall cut off his hand.\u2014\u200a\nLaws 215 and 218 illustrate the principle of opposition: one variable of the first law, the outcome of the operations, is altered to create the second.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;If there is either a soldier or [an auxiliary] who is taken captive while serving in a royal fortress [...] if he should [...] return and get back to his city, they shall return to him his field and orchard and he himself shall perform his service obligation.\nIf there is either a soldier or [an auxiliary] who is taken captive in a royal fortress, and his son is able to perform the service obligation, the field and orchard shall be given to him, and he shall perform his father's service obligation.\nIf his son is young and is unable to perform his father's service obligation, one third of the field and orchard shall be given to his mother, and his mother shall raise him.\u2014\u200a\nHere, following the principle of pointillism, circumstances are added to the first entry to create more entries. Pointillism also lets list entries be generated by following paradigmatic series common to multiple branches of scholarship. It can thus explain the implausible entries. For example, in the case of the goat used for threshing (law 270), the previous laws concern other animals that \"were\" used for threshing. The established series of domesticated beasts dictated that a goat come next.\nWolfram von Soden, who decades earlier called this way of thinking (\"list science\"), often denigrated it. However, more recent writers, such as Marc Van De Mieroop, Jean Bott\u00e9ro, and Ann Guinan, have either avoided value judgments or expressed admiration. Lists were central to Mesopotamian science and logic, and their distinctive structural principles let entries be generated infinitely. Linking the Code to the scribal tradition within which \"list science\" emerged also explains why trainee scribes copied and studied it for over a millennium. The Code appears in a late Babylonian (7th\u20136th century BC) list of literary and scholarly texts. No other law collection became so entrenched in the curriculum. Rather than a code of laws, then, it may be a scholarly treatise.\nMuch has been written on what the Code suggests about Old Babylonian society and its legal system. For example, whether it demonstrates that there were no professional advocates, or that there were professional judges. Scholars who approach the Code as a self-contained document renounce such claims.\nUnderlying principles.\nOne principle widely accepted to underlie the Code is , or \"eye for an eye\". Laws 196 and 200 respectively prescribe an eye for an eye and a tooth for a tooth when one man destroys another's. Punishments determined by could be transferred to the sons of the wrongdoer. For example, law 229 states that the death of a homeowner in a house collapse necessitates the death of the house's builder. The following law 230 states that if the homeowner's son died, the builder's son must die also.\nPersons were not equal before the law; not just age and profession but also class and gender dictated the punishment or remedy they received. Three main kinds of person, , , and (male)/ (female), are mentioned throughout the Code. A / was a male/female slave. As for and , though contentious, it seems likely that the difference was one of social class, with meaning something like \"gentleman\" and something like \"commoner\". The penalties were not necessarily stricter for a than an : a 's life may have been cheaper, but so were some of his fines. There was also inequality within these classes: laws 200 and 202, for example, show that one could be of higher rank than another.\nThe above principles are distant in spirit from modern systems of common and civil law, but some may be more familiar. One such principle is the presumption of innocence; the first two laws of the stele prescribe punishments, determined by , for unsubstantiated accusations. Written evidence was valued highly, especially in matters of contract. One crime was given only one punishment. The laws also recognized the importance of the intentions of a defendant. Lastly, the Code's establishment on public stelae was supposedly intended to increase access to justice. Whether or not this was true, suggesting that a wronged man have the stele read aloud to him (lines 3240'\u20133254') is a concrete measure in this direction, given the inaccessibility of scribal education in the Old Babylonian period.\nThe prologue asserts that Hammurabi was chosen by the gods. Raymond Westbrook observed that in ancient Near Eastern law, \"the king was the primary source of legislation\". However, they could delegate their god-given legal authority to judges. However, as Owen B. Jenkins observed, the prescriptions themselves bear \"an astonishing absence... of all theological or even ceremonial law\".\nLanguage.\nThe laws are written in the Old Babylonian dialect of Akkadian. Their style is regular and repetitive, and today they are a standard set text for introductory Akkadian classes. However, as A. Leo Oppenheim summarises, the cuneiform signs themselves are \"vertically arranged... within boxes placed in bands side by side from right to left\", an arrangement already antiquated by Hammurabi's time.\nThe laws are expressed in casuistic format: they are conditional sentences with the case detailed in the protasis (\"if\" clause) and the remedy given in the apodosis (\"then\" clause). The protasis begins , \"if\", except when it adds to circumstances already specified in a previous law (e.g. laws 36, 38, and 40). The preterite is used for simple past verbs in the protasis, or possibly for a simple conditional. The perfect often appears at the end of the protasis after one or more preterites to convey sequence of action, or possibly a hypothetical conditional. The durative, sometimes called the \"present\" in Assyriology, may express intention in the laws. For ease of English reading, some translations give preterite and perfect verbs in the protasis a present sense. In the apodosis, the verbs are in the durative, though the sense varies between permissive\u2014\"it is permitted that \"x\" happen\"\u2014and instructive\u2014\"\"x\" must/will happen\". In both protasis and apodosis, sequence of action is conveyed by suffixing verbs with , \"and\". can also have the sense \"but\".\nThe Code is relatively well-understood, but some items of its vocabulary are controversial. As mentioned, the terms and have proved difficult to translate. They probably denote respectively a male member of a higher and lower social class. Wolfram von Soden, in his \"Akkadisches Handw\u00f6rterbuch\", proposed that was derived from , \"to bow down/supplicate\". As a word for a man of low social standing, it has endured, possibly from a Sumerian root, into Arabic (), Italian (), Spanish (), and French (). However, some earlier translators, also seeking to explain the 's special treatment, translated it as \"leper\" and even \"noble\". Some translators have supplied stilted readings for , such as \"seignior\", \"elite man\", and \"member of the aristocracy\"; others have left it untranslated. Certain legal terms have also proved difficult to translate. For example, and can denote the law in general as well as individual laws, verdicts, divine pronouncements and other phenomena. can likewise denote the law in general as well as a kind of royal decree.\nRelation to other law collections.\nOther Mesopotamian.\nThe Code of Hammurabi bears strong similarities to earlier Mesopotamian law collections. Many purport to have been written by rulers, and this tradition was probably widespread. Earlier law collections express their god-given legitimacy similarly. Like the Code of Hammurabi, they feature prologues and epilogues: the Code of Ur-Nammu has a prologue, the Code of Lipit-Ishtar a prologue and an epilogue, and the Laws of Eshnunna an epilogue. Also, like the Code of Hammurabi, they uphold the \"one crime, one punishment\" principle. The cases covered and language used are, overall, strikingly similar. Scribes were still copying earlier law collections, such as the Code of Ur-Nammu, when Hammurabi produced his own Code. This suggests that earlier collections may have not only resembled the Code but influenced it. Raymond Westbrook maintained that there was a fairly consistent tradition of \"ancient Near Eastern law\" which included the Code of Hammurabi, and that this was largely customary law. Nonetheless, there are differences: for example, Stephen Bertman has suggested that where earlier collections are concerned with compensating victims, the Code is concerned with physically punishing offenders. Additionally, the above conclusions of similarity and influence apply only to the law collections themselves. The actual legal practices from the context of each code are mysterious.\nThe Code of Hammurabi also bears strong similarities to later Mesopotamian law collections: to the casuistic Middle Assyrian Laws and to the Neo-Babylonian Laws, whose format is largely relative (\"a man who...\"). It is easier to posit direct influence for these later collections, given the Code's survival through the scribal curriculum. Lastly, although influence is more difficult to trace, there is evidence that the Hittite laws may have been part of the same tradition of legal writing outside Mesopotamia proper.\nMosaic, Graeco-Roman, and modern.\nThe relationship of the Code of Hammurabi to the Mosaic Law, specifically the Covenant Code of Exodus 20:22\u201323:19, has been a subject of discussion since its discovery. Friedrich Delitzsch argued the case for strong influence in a 1902 lecture, in one episode of the \"\" (\"Babel and Bible\", or \"Panbabylonism\") debate on the influence of ancient Mesopotamian cultures on ancient Israel. However, he was met with strong resistance. There was cultural contact between Mesopotamia and the Levant, and Middle Bronze Age tablets of casuistic cuneiform law have been found at Hazor. There are also similarities between the Code of Hamurabi and the Covenant Code: in the casuistic format, in principles such as (\"eye for an eye\"), and in the content of the provisions. Some similarities are striking, such as in the provisions concerning a man-goring ox (Code of Hammurabi laws 250\u2013252, Exodus 21:28\u201332). Certain writers have posited direct influence: David P. Wright, for example, asserts that the Covenant Code is \"directly, primarily, and throughout dependent upon the Laws of Hammurabi\", \"a creative rewriting of Mesopotamian sources... to be viewed as an academic abstraction rather than a digest of laws\". Others posit indirect influence, such as via Aramaic or Phoenician intermediaries. The consensus, however, is that the similarities are a result of inheriting common traditions. In 1916, George A. Barton cited \"a similarity of antecedents and of general intellectual outlook\". More recently, David Winton Thomas has stated: \"There is no ground for assuming any direct borrowing by the Hebrew from the Babylonian. Even where the two sets of laws differ little in the letter, they differ much in the spirit\".\nThe influence of the Code of Hammurabi on later law collections is difficult to establish. Marc Van De Mieroop suggests that it may have influenced the Greek Gortyn Code and the Roman Twelve Tables. However, even Van De Mieroop acknowledges that most Roman law is not similar to the Code, or likely to have been influenced by it.\nKnowing the Code's influence on modern law requires knowing its influence on Mosaic and Graeco-Roman law. Since this is contentious, commentators have restricted themselves to observing similarities and differences between the Code and, e.g., United States law and medieval law. Some have remarked that the punishments found in the Code are no more severe, and, in some cases, less so.\nLaw 238 stipulates that a sea captain, ship-manager, or ship charterer that saved a ship from total loss was only required to pay one-half the value of the ship to the ship-owner. In the \"Digesta seu Pandectae\" (533), the second volume of the codification of laws ordered by Justinian I (527\u2013565) of the Eastern Roman Empire, a legal opinion written by the Roman jurist Paulus at the beginning of the Crisis of the Third Century in 235 AD was included about the \"Lex Rhodia\" (\"Rhodian law\") that articulates the general average principle of marine insurance established on the island of Rhodes in approximately 1000 to 800 BC as a member of the Doric Hexapolis, plausibly by the Phoenicians during the proposed Dorian invasion and emergence of the purported Sea Peoples during the Greek Dark Ages (c.\u00a01100 \u2013 c.\u00a0750) that led to the proliferation of the Doric Greek dialect. The law of general average constitutes the fundamental principle that underlies all insurance.\nReception outside Assyriology.\nThe Code is often referred to in legal scholarship, where its provisions are assumed to be laws, and the document is assumed to be a true code of laws. This is also true outside academia.\nThere is a relief portrait of Hammurabi over the doors to the House Chamber of the U.S. Capitol, along with portraits of 22 others \"noted for their work in establishing the principles that underlie American law\". There are replicas of the Louvre stele in institutions around the world, including the Headquarters of the United Nations in New York City and the Peace Palace in The Hague (seat of the International Court of Justice).\nMedico-legal legacy and political implications.\nHammurabi's Code is notable for its comprehensive approach to law, covering subjects from criminal acts to medical practices. The Code includes specific rules that regulate medical treatments, set surgery fees, and punish malpractice. For instance, if a physician caused the death of a noble during surgery, they would be severely punished, sometimes having their hand cut off. This harshness portrays how seriously medical responsibility was taken even in ancient times.\nFrom a political science perspective, Hammurabi's Code is valuable and fundamental because it demonstrates how law was used to reinforce social hierarchies and maintain control. writes that the Code's laws were applied differently depending on a person's social class, so nobles received greater protection than commoners and enslaved people. This legal stratification reflects the power dynamic of Babylonian society and shows how law was used not just to govern but also to preserve the social order.\nFinally, the Hammurabi's Code could be considered impressive by its power (despite its modern irrelevancy) and severity. The harsh punishments may seem extreme by modern standards, but they were likely necessary to maintain order in a society where survival depended on strict adherence to rules. At the same time, Hammurabi's Code represents a significant step forward in the development of law, medicine and the medico-legal system. By codifying laws and making them public, Hammurabi established a system that would influence generations so that the principles of justice, fairness, and accountability that underpin the Code continue to resonate today.\nReferences.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nSources.\nBooks and journals.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nWeb.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "7605", "revid": "196153", "url": "https://en.wikipedia.org/wiki?curid=7605", "title": "Rum and Coke", "text": "Highball cocktail\nRum and Coke, or the Cuba libre ( , ; literally \"Free Cuba\"), is a highball cocktail consisting of cola, rum, and in many recipes lime juice on ice. Traditionally, the cola ingredient is Coca-Cola (\"Coke\") and the alcohol is a light rum such as Bacardi; however, the drink may be made with various types of rums and cola brands, and lime juice may or may not be included.\nThe cocktail originated in the early 20th century in Cuba, after the country won independence in the Spanish\u2013American War. It subsequently became popular across Cuba, the United States, and other countries. Its simple recipe and inexpensive, ubiquitous ingredients have made it one of the world's most popular alcoholic drinks. Drink critics often consider the drink mediocre, but it has been noted for its historical significance.\nHistory.\nThe drink was created in Cuba in the early 1900s, but its exact origins are not certain. It became popular shortly after 1900, when bottled Coca-Cola was first imported into Cuba from the United States. Its origin is associated with the heavy U.S. presence in Cuba following the Spanish\u2013American War of 1898; the drink's traditional name, \"Cuba libre\" (Free Cuba), was the slogan of the Cuban independence movement. The Cuba libre is sometimes said to have been created during the Spanish\u2013American War. However, this predates the first distribution of Coca-Cola to Cuba in 1900. A drink called a \"Cuba libre\" was indeed known in 1898, but this was a mix of water and brown sugar.\nFausto Rodriguez, a Bacardi advertising executive, claimed to have been present when the drink was first poured, and produced a notarized affidavit to that effect in 1965. According to Rodriguez, this took place in August 1900, when he was a 14-year-old messenger working for a member of the U.S. Army Signal Corps in Havana. One day at a local bar, Rodriguez's employer ordered Bacardi rum mixed with Coca-Cola. This intrigued a nearby group of American soldiers, who ordered a round for themselves, giving birth to a popular new drink. Bacardi published Rodriguez's affidavit in a \"Life\" magazine ad in 1966. However, Rodriguez's status as a Bacardi executive has led some commentators to doubt the veracity of his story. Another story states that the drink was first created in 1902 at Havana's El Floridita restaurant to celebrate the anniversary of Cuban independence.\nThe drink became a staple in Cuba, catching on due to the pervasiveness of its ingredients. Havana was already known for its iced drinks in the 19th century, as it was one of the few warm-weather cities that had abundant stores of ice shipped down from colder regions. Bacardi and other Cuban rums also boomed after independence brought in large numbers of foreign tourists and investors, as well as new opportunities for exporting alcohol. Light rums such as Bacardi became favored for cocktails as they were considered to mix well. Coca-Cola had been a common mixer in the United States ever since it was first bottled in 1886, and it became a ubiquitous drink in many countries after it was first exported in 1900.\nRum and Coke quickly spread from Cuba to the United States. In the early 20th century the cocktail, like Coca-Cola itself, was most popular in the Southern United States. During the Prohibition era from 1922 to 1933, Coca-Cola became a favored mixer for disguising the taste of low-quality rums, as well as other liquors. In 1921 H. L. Mencken jokingly wrote of a South Carolina variant called the \"jump stiddy\", which consisted of Coca-Cola mixed with denatured alcohol drained from automobile radiators. After Prohibition, rum and Coke became prevalent in the northern and western U.S. as well, and in both high-brow and low-brow circles.\nRum and Coke achieved a new level of popularity during World War II. Starting in 1940, the United States established a series of outposts in the British West Indies to defend against the German Navy. The American presence created cross-cultural demand, with American servicemen and the locals developing tastes for each other's products. In particular, American military personnel took to Caribbean rum due to its inexpensiveness, while Coca-Cola became especially prevalent in the islands thanks to the company shipping it out with the military. Within the United States, imported rum became increasingly popular, as government quotas for industrial alcohol reduced the output of American distillers of domestic liquors.\nIn 1943, Lord Invader's Calypso song \"Rum and Coca-Cola\" drew further attention to the drink in Trinidad. The song was an adaptation of Lionel Belasco's 1904 composition \"L'Ann\u00e9e Pass\u00e9e\" with new lyrics about American soldiers in Trinidad cavorting with local girls and drinking rum and Coke. Comedian Morey Amsterdam plagiarized \"Rum and Coca-Cola\" and licensed it to the Andrews Sisters as his own work. The Andrews Sisters' version was a major hit in 1945 and further boosted the popularity of rum and Coke, especially in the military. Lord Invader and the owners of Belasco's composition successfully sued Amsterdam for the song's rights.\nDuring the Cuban Revolution in 1959, Bacardi fled to Puerto Rico. The following year, the U.S. placed an embargo against Cuba, which made Cuban-made rum unavailable in the U.S. and Coca-Cola largely unavailable in Cuba. As such, it became difficult to make a rum and Coke with its traditional ingredients in either country.\nPopularity and reception.\nThe rum and Coke is very popular; Bacardi says that it is the world's second-most-popular alcoholic drink. Its popularity derives from the ubiquity and low cost of the main ingredients, and the fact that it is very easy to make. As it can be made with any quantity or style of rum, it is simple to prepare and difficult to ruin.\nDrink critics often have a low opinion of the cocktail. Writer Wayne Curtis called it \"a drink of inspired blandness\", while Jason Wilson of \"The Washington Post\" called it \"a lazy person's drink\". Troy Patterson of \"Slate\" called it \"the classic mediocre Caribbean-American highball\", which \"became a classic despite not being especially good\".\nCharles A. Coulombe considers the Cuba libre a historically important drink, writing that it is \"a potent symbol of a changing world order \u2013 the marriage of rum, lubricant of the old colonial empires, and Coca-Cola, icon of modern American global capitalism\". Additionally, both rum and Coca-Cola are made from Caribbean ingredients and became global commodities through European and American commerce. According to Coulombe, the drink \"seems to reflect perfectly the historical elements of the modern world\".\nRecipe and variations.\nRecipes vary somewhat in measures and additional ingredients, but the main ingredients are always rum and cola. The International Bartenders Association Cuba Libre recipe calls for 5 centiliters of light rum, 12\u00a0cl of cola, and 1\u00a0cl of fresh lime juice on ice. However, any amount and proportion of rum and cola may be used. Additionally, while light rum is traditional, dark rums and other varieties are also common.\nCoca-Cola is the conventional cola in the drink, to the point that customers rarely order anything else. This dates back to the origin of the drink in Cuba and was solidified in the 1920s when Coca-Cola emerged as the primary cola brand following the bankruptcy of Pepsi and Chero-Cola, and therefore the preferred cola mixer in alcoholic drinks. Pepsi's later attempts to enter the cocktail market were unsuccessful, especially after the song \"Rum and Coca-Cola\" solidified the association in the public imagination.\nNonetheless, different colas are sometimes used. In Cuba, as Coca-Cola has not been imported since the U.S. embargo of 1960, the domestic TuKola is used in Cuba libres. Other common variants call for Mexican Coke (which uses cane sugar instead of high-fructose corn syrup), Moxie, Diet Coke (the Cuba Lite or rum and Diet) and Dr. Pepper (the Captain and Pepper, featuring Captain Morgan spiced rum).\nLime is traditionally included in the drink, though it is often left out, especially when the order is for just \"rum and Coke\". Some early recipes called for lime juice to be mixed in; others included lime only as a garnish. Other early recipes called for additional ingredients such as gin and bitters. Some sources consider lime essential for a drink to be a true Cuba libre, which they distinguish from a mere rum and Coke. However, lime is frequently included even in orders for \"rum and Coke\".\nWhen aged a\u00f1ejo rum is used, the drink is sometimes called a \"Cubata\", a name also used informally in Spain for any Cuba libre. Some modern recipes inspired by older ones include additional ingredients such as bitters. More elaborate variants with further ingredients include the cinema highball, which uses rum infused with buttered popcorn and mixed with cola. Another is the Mandeville cocktail, which includes light and dark rum, cola, and citrus juice along with Pernod absinthe and grenadine.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "7607", "revid": "1461430", "url": "https://en.wikipedia.org/wiki?curid=7607", "title": "Collagen helix", "text": "Main protein structure of fibrous collagen\nIn molecular biology, the collagen triple helix or type-2 helix is the main secondary structure of various types of fibrous collagen, including type I collagen. In 1954, Ramachandran &amp; Kartha (13, 14) advanced a structure for the collagen triple helix on the basis of fiber diffraction data. It consists of a triple helix made of the repetitious amino acid sequence glycine-X-Y, where X and Y are frequently proline or hydroxyproline. Collagen folded into a triple helix is known as tropocollagen. Collagen triple helices are often bundled into fibrils which themselves form larger fibres, as in tendons.\nStructure.\nGlycine, proline, and hydroxyproline must be in their designated positions with the correct configuration. For example, hydroxyproline in the Y position increases the thermal stability of the triple helix, but not when it is located in the X position. The thermal stabilization is also hindered when the hydroxyl group has the wrong configuration. Due to the high abundance of glycine and proline contents, collagen fails to form a regular \u03b1-helix and \u03b2-sheet structure. Three left-handed helical strands twist to form a right-handed triple helix. A collagen triple helix has 3.3 residues per turn.\nEach of the three chains is stabilized by the steric repulsion due to the pyrrolidine rings of proline and hydroxyproline residues. The pyrrolidine rings keep out of each other's way when the polypeptide chain assumes this extended helical form, which is much more open than the tightly coiled form of the alpha helix.\nThe three chains are hydrogen bonded to each other. The hydrogen bond donors are the peptide NH groups of glycine residues. The hydrogen bond acceptors are the CO groups of residues on the other chains. The OH group of hydroxyproline does not participate in hydrogen bonding but stabilises the trans isomer of proline by stereoelectronic effects, therefore stabilizing the entire triple helix.\nThe rise of the collagen helix (superhelix) is 2.9 \u00c5 (0.29\u00a0nm) per residue. The center of the collagen triple helix is very small and hydrophobic, and every third residue of the helix must have contact with the center. Due to the very tiny and tight space at the center, only the small hydrogen of the glycine side chain is capable of interacting with the center. This contact is impossible even when a slightly bigger amino acid residue is present other than glycine.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "7609", "revid": "49662468", "url": "https://en.wikipedia.org/wiki?curid=7609", "title": "Cosmic censorship hypothesis", "text": "Mathematical conjecture in physics\nThe weak and the strong cosmic censorship hypotheses are two mathematical conjectures about the structure of gravitational singularities arising in general relativity.\nSingularities that arise in the solutions of Einstein's equations are typically hidden within event horizons, and therefore cannot be observed from the rest of spacetime. Singularities that are not so hidden are called \"naked\". The weak cosmic censorship hypothesis was conceived by Roger Penrose in 1969 and posits that no naked singularities exist in the universe.\nBasics.\nSince the physical behavior of singularities is unknown, if singularities can be observed from the rest of spacetime, causality may break down, and physics may lose its predictive power. The issue cannot be avoided, since according to the Penrose\u2013Hawking singularity theorems, singularities are inevitable in physically reasonable situations. Still, in the absence of naked singularities, the universe, as described by the general theory of relativity, is deterministic: it is possible to predict the entire evolution of the universe (possibly excluding some finite regions of space hidden inside event horizons of singularities), knowing only its condition at a certain moment of time (more precisely, everywhere on a spacelike three-dimensional hypersurface, called the Cauchy surface). Failure of the cosmic censorship hypothesis leads to the failure of determinism, because it is yet impossible to predict the behavior of spacetime in the causal future of a singularity. Cosmic censorship is not merely a problem of formal interest; some form of it is assumed whenever black hole event horizons are mentioned.\nThe hypothesis was first formulated by Roger Penrose in 1969, and it is not stated in a completely formal way. In a sense it is more of a research program proposal: part of the research is to find a proper formal statement that is physically reasonable, falsifiable, and sufficiently general to be interesting. Because the statement is not a strictly formal one, there is sufficient latitude for (at least) two independent formulations: a weak form, and a strong form.\nWeak and strong cosmic censorship hypothesis.\nThe weak and the strong cosmic censorship hypotheses are two conjectures concerned with the global geometry of spacetimes.\nThe weak cosmic censorship hypothesis asserts there can be no singularity visible from future null infinity. In other words, singularities need to be hidden from an observer at infinity by the event horizon of a black hole. Mathematically, the conjecture states that, for generic initial data, the causal structure is such that the maximal Cauchy development possesses a complete future null infinity.\nThe strong cosmic censorship hypothesis asserts that, generically, general relativity is a deterministic theory, in the same sense that classical mechanics is a deterministic theory. In other words, the classical fate of all observers should be predictable from the initial data. Mathematically, the conjecture states that the maximal Cauchy development of generic compact or asymptotically flat initial data is locally inextendible as a regular Lorentzian manifold. Taken in its strongest sense, the conjecture suggests locally inextendibility of the maximal Cauchy development as a continuous Lorentzian manifold [very strong cosmic censorship]. This strongest version was disproven in 2018 by Mihalis Dafermos and Jonathan Luk for the Cauchy horizon of an uncharged, rotating black hole. \nThe two conjectures are mathematically independent, as there exist spacetimes for which weak cosmic censorship is valid but strong cosmic censorship is violated and, conversely, there exist spacetimes for which weak cosmic censorship is violated but strong cosmic censorship is valid.\nExample.\nThe Kerr metric, corresponding to a black hole of mass formula_1 and angular momentum formula_2, can be used to derive the effective potential for particle orbits restricted to the equator (as defined by rotation). This potential looks like:\nformula_3\nwhere formula_4 is the coordinate radius, formula_5 and formula_6 are the test-particle's conserved energy and angular momentum respectively (constructed from the Killing vectors).\nTo preserve \"cosmic censorship\", the black hole is restricted to the case of formula_7. For there to exist an event horizon around the singularity, the requirement formula_7 must be satisfied. This amounts to the angular momentum of the black hole being constrained to below a critical value, outside of which the horizon would disappear. \nThe following thought experiment is reproduced from Hartle's \"Gravity\":\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nProblems with the concept.\nThere are a number of difficulties in formalizing the hypothesis:\nIn 1991, John Preskill and Kip Thorne bet against Stephen Hawking that the hypothesis was false. Hawking conceded the bet in 1997, due to the discovery of the special situations just mentioned, which he characterized as \"technicalities\". Hawking later reformulated the bet to exclude those technicalities. The revised bet is still open (although Hawking died in 2018), the prize being \"clothing to cover the winner's nakedness\".\nCounter-example.\nAn exact solution to the scalar-Einstein equations formula_11 which forms a counterexample to many formulations of the \ncosmic censorship hypothesis was found by Mark D. Roberts in 1985:\nformula_12\nwhere formula_13 is a constant.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "7610", "revid": "58947", "url": "https://en.wikipedia.org/wiki?curid=7610", "title": "Catholic (term)", "text": "Term in Christianity\nThe word catholic (derived via Late Latin , from the ancient Greek adjective () 'universal') comes from the Greek phrase () 'on the whole, according to the whole, in general', and is a combination of the Greek words () 'about' and () 'whole'. The first known use of \"Catholic\" was by the church father Ignatius of Antioch in his \"Letter to the Smyrnaeans\" (circa 110\u00a0AD). In the context of Christian ecclesiology, it has a rich history and several usages. \nThe word in English can mean either \"of the Catholic faith\" or \"relating to the historic doctrine and practice of the Western Church\". \"Catholicos\", the title used for the head of some churches in Eastern Christian traditions, is derived from the same linguistic origin.\nIn non-ecclesiastical use, it derives its English meaning directly from its root, and is currently used to mean the following: \nThe term has been incorporated into the name of the largest Christian communion, the Roman Catholic Church. All of the three main branches of Christianity in the East \u2013 Eastern Orthodox Church, Oriental Orthodox Church and Church of the East \u2013 had always identified themselves as \"Catholic\" in accordance with apostolic traditions and the Nicene Creed. Lutherans, Reformed, Anglicans and Methodists also believe that their churches are \"Catholic\" in the sense that they too are in continuity with the original universal church founded by the Apostles. However, each church defines the scope of the \"Catholic Church\" differently. The Roman Catholic, Eastern Orthodox, Oriental Orthodox churches, and Church of the East, all maintain that their own denomination is identical with the original universal church, from which all other denominations broke away.\nAn early definition for what is \"catholic\" was summarized in what is known as the Vincentian Canon in the 5th century \"Commonitory\": \"what has been believed everywhere, always, and by all.\" Distinguishing beliefs of Catholicity, the beliefs of most Christians who call themselves \"Catholic\", include the episcopal polity, that bishops are considered the highest order of ministers within the Christian religion, as well as the Nicene Creed of AD 381. In particular, along with unity, sanctity, and apostolicity, catholicity is considered one of Four Marks of the Church, found in the line of the Nicene Creed: \"I believe in one holy catholic and apostolic Church.\" Some denominations using other forms of church polity, however, still define themselves as catholic under an interpretation of apostolic succession which does not require bishops.\nDuring the medieval and modern times, additional distinctions arose regarding the use of the terms \"Western Catholic\" and \"Eastern Catholic\". Before the East\u2013West Schism of 1054, those terms had just the basic geographical meanings, since only one undivided Catholicity existed, uniting the Latin-speaking Christians of West and the Greek-speaking Christians of the East. After the Schism, terminology became much more complicated, resulting in the creation of parallel and conflicting terminological systems.\nEtymology.\nThe Greek adjective \"katholikos\", the origin of the term \"catholic\", means 'universal'. Directly from the Greek, or via Late Latin \"catholicus\", the term \"catholic\" entered many other languages, becoming the base for the creation of various theological terms such as \"catholicism\" and \"catholicity\" (Late Latin \"catholicismus\", \"catholicitas\").\nThe term \"catholicism\" is the English form of Late Latin \"catholicismus\", an abstract noun based on the adjective \"catholic\". The Modern Greek equivalent \"\" is back-formed and usually refers to the Catholic Church. The terms \"catholic\", \"catholicism\", and \"catholicity\" are closely related to the use of the term \"Catholic Church\". (See Catholic Church (disambiguation) for more uses.)\nThe earliest evidence of the use of that term is the \"Letter to the Smyrnaeans\" that Ignatius of Antioch wrote in about 107 to Christians in Smyrna. Exhorting Christians to remain closely united with their bishop, he wrote: \"Wherever the bishop shall appear, there let the multitude [of the people] also be; even as, wherever Jesus Christ is, there is the Catholic Church.\"\nFrom the second half of the second century, the word \"catholic\" began to be used to mean \"orthodox\" (non-heretical), \"because Catholics claimed to teach the whole truth, and to represent the whole Church, while heresy arose out of the exaggeration of some one truth and was essentially partial and local\". In 380, Emperor Theodosius I limited use of the term \"Catholic Christian\" exclusively to those who followed the same faith as Pope Damasus I of Rome and Pope Peter of Alexandria. Numerous other early writers including Cyril of Jerusalem (c. 315\u2013386), Augustine of Hippo (354\u2013430) further developed the use of the term \"catholic\" in relation to Christianity. The 5th century Vincentian Canon, published in \"Commonitory\", defined \"catholic\" as \"what has been believed everywhere, always, and by all.\"\nHistorical use.\nIgnatius of Antioch.\nThe earliest recorded evidence of the use of the term \"Catholic Church\" is the \"Letter to the Smyrnaeans\" that Ignatius of Antioch wrote in about 107 AD to Christians in Smyrna. Exhorting Christians to remain closely united with their bishop, he wrote:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nOf the meaning for Ignatius of this phrase J.H. Srawley wrote:\nThis is the earliest occurrence in Christian literature of the phrase 'the Catholic Church' (\u1f21 \u03ba\u03b1\u03b8\u03bf\u03bb\u03b9\u03ba\u1f74 \u1f10\u03ba\u03ba\u03bb\u03b7\u03c3\u03af\u03b1). The original sense of the word is 'universal'. Thus Justin Martyr (\"Dial\". 82) speaks of the 'universal or general resurrection', using the words \u1f21 \u03ba\u03b1\u03b8\u03bf\u03bb\u03b9\u03ba\u1f74 \u1f00\u03bd\u03ac\u03c3\u03c4\u03b1\u03c3\u03b9\u03c2. Similarly here the Church universal is contrasted with the particular Church of Smyrna. Ignatius means by the Catholic Church 'the aggregate of all the Christian congregations' (Swete, \"Apostles Creed\", p. 76). So too the letter of the Church of Smyrna is addressed to all the congregations of the Holy Catholic Church in every place. And this primitive sense of 'universal' the word has never lost, although in the latter part of the second century it began to receive the secondary sense of 'orthodox' as opposed to 'heretical'. Thus it is used in an early Canon of Scripture, the Muratorian fragment (\"circa\" 170 A.D.), which refers to certain heretical writings as 'not received in the Catholic Church'. So too Cyril of Jerusalem, in the fourth century, says that the Church is called Catholic not only 'because it is spread throughout the world', but also 'because it teaches completely and without defect all the doctrines which ought to come to the knowledge of men'. This secondary sense arose out of the original meaning because Catholics claimed to teach the whole truth, and to represent the whole Church, while heresy arose out of the exaggeration of some one truth and was essentially partial and local.\nBy \"Catholic Church\" Ignatius designated the universal church. Ignatius considered that certain heretics of his time, who disavowed that Jesus was a material being who actually suffered and died, saying instead that \"he only seemed to suffer\" (Smyrnaeans, 2), were not really Christians.\nMartyrdom of Polycarp.\nThe term is also used in the \"Martyrdom of Polycarp\" (AD 156):\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The Church of God which sojourns at Smyrna, to the Church of God sojourning in Philomelium, and to all the congregations of the Holy and Catholic Church in every place: Mercy, peace, and love from God the Father, and our Lord Jesus Christ, be multiplied.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;For, [Polycarp] having through patience overcome the unjust governor, and thus acquired the crown of immortality, he now, with the apostles and all the righteous [in heaven], rejoicingly glorifies God, even the Father, and blesses our Lord Jesus Christ, the Saviour of our souls, the Governor of our bodies, and the Shepherd of the Catholic Church throughout the world.\nMuratorian fragment.\nThe Muratorian fragment (AD 177) mentions:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;[Paul] wrote, besides these, one to Philemon, and one to Titus, and two to Timothy, in simple personal affection and love indeed; but yet these are hallowed in the esteem of the Catholic Church, and in the regulation of ecclesiastical discipline. There are also in circulation one to the Laodiceans, and another to the Alexandrians, forged under the name of Paul, and addressed against the heresy of Marcion; and there are also several others which cannot be received into the Catholic Church, for it is not suitable for gall to be mingled with honey.\nTertullian.\nThe term is employed by Tertullian (AD 200):\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Where was Marcion then, that shipmaster of Pontus, the zealous student of Stoicism? Where was Valentinus then, the disciple of Platonism? For it is evident that those men lived not so long ago \u2014 in the reign of Antoninus for the most part, \u2014 and that they at first were believers in the doctrine of the Catholic Church, in the church of Rome under the episcopate of the blessed Eleutherus, until on account of their ever restless curiosity, with which they even infected the brethren, they were more than once expelled.\nClement of Alexandria.\nClement of Alexandria (AD 202) cites:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Therefore in substance and idea, in origin, in pre-eminence, we say that the ancient and Catholic Church is alone, collecting as it does into the unity of the one faith.\nCyprian of Carthage.\nCyprian of Carthage (AD 254) wrote a large number of epistles where he makes use of the term:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Marcianus, who abides at Aries, has associated himself with Novatian, and has departed from the unity of the Catholic Church. [...] While the Bishop Cornelius was ordained in the Catholic Church by the judgment of God, and by the suffrages of the clergy and people.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;When we were together in council, dearest brethren, we read your letter which you wrote to us concerning those who seem to be baptized by heretics and schismatics, (asking) whether, when they, come to the Catholic Church, which is one, they ought to be baptized.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;They strive to set before and prefer the sordid and profane washing of heretics to the true and only and legitimate baptism of the Catholic Church. [...] We ought by all means to maintain the unity of the Catholic Church, and not to give way to the enemies of faith and truth in any respect. [...] Whose opinion, as being both religious and lawful and salutary, and in harmony with the Catholic faith and Church, we also have followed.\nIn addition to epistles 66, 69 and 70, the term is also found in the epistles 19, 40, 41, 42, 43, 44, 45, 46, 50, 51, 54, 63, 68, 71, 72, 74, 75.\nCyril of Jerusalem.\nAs mentioned in the above quotation from J.H. Srawley, Cyril of Jerusalem (c. 315\u2013386), who is venerated as a saint by the Roman Catholic Church, the Eastern Orthodox Church, and the Anglican Communion, distinguished what he called the \"Catholic Church\" from other groups who could also refer to themselves as an \u1f10\u03ba\u03ba\u03bb\u03b7\u03c3\u03af\u03b1 (assembly or church):\nSince the word Ecclesia is applied to different things (as also it is written of the multitude in the theatre of the Ephesians, \"And when he had thus spoken, he dismissed the Assembly\" (Acts 19:41), and since one might properly and truly say that there is a \"Church of evil doers\", I mean the meetings of the heretics, the Marcionists and Manichees, and the rest, for this cause the Faith has securely delivered to you now the Article, \"And in one Holy Catholic Church\"; that you may avoid their wretched meetings, and ever abide with the Holy Church Catholic in which you were regenerated. And if ever you are sojourning in cities, inquire not simply where the Lord's House is (for the other sects of the profane also attempt to call their own dens houses of the Lord), nor merely where the Church is, but where is the Catholic Church. For this is the peculiar name of this Holy Church, the mother of us all, which is the spouse of our Lord Jesus Christ, the Only-begotten Son of God (Catechetical Lectures, XVIII, 26).\nTheodosius I.\nTheodosius I, Emperor from 379 to 395, declared \"Catholic\" Christianity the official religion of the Roman Empire, declaring in the Edict of Thessalonica of 27 February 380:\nIt is our desire that all the various nations which are subject to our clemency and moderation, should continue the profession of that religion which was delivered to the Romans by the divine Apostle Peter, as it has been preserved by faithful tradition and which is now professed by the Pontiff Damasus and by Peter, Bishop of Alexandria, a man of apostolic holiness. According to the apostolic teaching and the doctrine of the Gospel, let us believe in the one Deity of the Father, Son and Holy Spirit, in equal majesty and in a holy Trinity. We authorize the followers of this law to assume the title \"Catholic\" Christians; but as for the others, since in our judgment they are foolish madmen, we decree that they shall be branded with the ignominious name of heretics, and shall not presume to give their conventicles the name of churches. They will suffer in the first place the chastisement of the divine condemnation, and in the second the punishment which our authority, in accordance with the will of heaven, will decide to inflict. Theodosian Code XVI.i.2\nJerome.\nJerome wrote to Augustine of Hippo in 418: \"You are known throughout the world; Catholics honour and esteem you as the one who has established anew the ancient Faith\"\nAugustine of Hippo.\nOnly slightly later, Augustine of Hippo (354\u2013430) also used the term \"Catholic\" to distinguish the \"true\" church from heretical groups:\nIn the Catholic Church, there are many other things which most justly keep me in her bosom. The consent of peoples and nations keeps me in the Church; so does her authority, inaugurated by miracles, nourished by hope, enlarged by love, established by age. The succession of priests keeps me, beginning from the very seat of the Apostle Peter, to whom the Lord, after His resurrection, gave it in charge to feed His sheep (Jn 21:15\u201319), down to the present episcopate.\nAnd so, lastly, does the very name of Catholic, which, not without reason, amid so many heresies, the Church has thus retained; so that, though all heretics wish to be called Catholics, yet when a stranger asks where the Catholic Church meets, no heretic will venture to point to his own chapel or house.\nSuch then in number and importance are the precious ties belonging to the Christian name which keep a believer in the Catholic Church, as it is right they should ... With you, where there is none of these things to attract or keep me... No one shall move me from the faith which binds my mind with ties so many and so strong to the Christian religion... For my part, I should not believe the gospel except as moved by the authority of the Catholic Church.\u00a0\u2014St. Augustine (354\u2013430): \"Against the Epistle of Manichaeus called Fundamental\", chapter 4: Proofs of the Catholic Faith.\n\u2014 St. Augustine (354\u2013430): \"Against the Epistle of Manichaeus called Fundamental\", chapter 4: Proofs of the Catholic Faith.\nVincent of Lerins.\nA contemporary of Augustine, Vincent of Lerins, wrote in 434 (under the pseudonym Peregrinus) a work known as the \"Commonitoria\" (\"Memoranda\"). While insisting that, like the human body, church doctrine develops while truly keeping its identity (sections 54\u201359, chapter XXIII), he stated:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;In the Catholic Church itself, all possible care must be taken, that we hold that faith which has been believed everywhere, always, by all. For that is truly and in the strictest sense 'catholic,' which, as the name itself and the reason of the thing declare, comprehends all universally. This rule we shall observe if we follow universality, antiquity, consent. We shall follow universality if we confess that one faith to be true, which the whole church throughout the world confesses; antiquity, if we in no wise depart from those interpretations which it is manifest were notoriously held by our holy ancestors and fathers; consent, in like manner, if in antiquity itself we adhere to the consentient definitions and determinations of all, or at the least of almost all priests and doctors.\u2014\u200a\nCatholic Church and Eastern Orthodox Church.\nIn the early centuries of Christian history, the majority of Christians who followed doctrines represented in Nicene Creed were bound by one common and undivided Catholicity that united the Latin-speaking Christians of the west and the Greek-speaking Christians of the east. In those days, the terms \"eastern Catholic\" and \"western Catholic\" had geographical meanings, generally corresponding to existing linguistic distinctions between Greek east and Latin west. In spite of various theological and ecclesiastical disagreements between Christian sees, a common Catholicity was preserved. A great dispute arose between the 9th and 11th century. After the East\u2013West Schism, the notion of common Catholicity was broken and each side started to develop its own terminological practice.\nAll major theological and ecclesiastical disputes in the Christian East or West have been commonly accompanied by attempts of arguing sides to deny each other the right to use the word \"Catholic\" as term of self-designation. After the acceptance of Filioque clause into the Nicene Creed by the Rome, Orthodox Christians in the East started to refer to adherents of Filioquism in the West just as \"Latins\" considering them no longer to be \"Catholics\".\nThe dominant view in the Eastern Orthodox Church, that all Western Christians who accepted Filioque interpolation and unorthodox Pneumatology ceased to be Catholics, was held and promoted by famous Eastern Orthodox canonist Theodore Balsamon who was patriarch of Antioch. He wrote in 1190:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;For many years the once illustrious congregation of the Western Church, that is to say, the Church of Rome, has been divided in spiritual communion from the other four Patriarchates, and has separated itself by adopting customs and dogmas alien to the Catholic Church and to the Orthodox ... So no Latin should be sanctified by the hands of the priests through divine and spotless Mysteries unless he first declares that he will abstain from Latin dogmas and customs, and that he will conform to the practice of the Orthodox.\nOn the other side of the widening rift, Eastern Orthodox were considered by western theologians to be \"Schismatics\". Relations between East and West were further estranged by the tragic events of the Massacre of the Latins in 1182 and Sack of Constantinople in 1204. Those bloody events were followed by several failed attempts to reach reconciliation (see: Second Council of Lyon, Council of Florence, Union of Brest, Union of Uzhhorod). During the late medieval and early modern period, terminology became much more complicated, resulting in the creation of parallel and confronting terminological systems that exist today in all of their complexity.\nDuring the Early Modern period, a special term \"Acatholic\" was widely used in the West to mark all those who were considered to hold heretical theological views and irregular ecclesiastical practices. In the time of Counter-Reformation the term \"Acatholic\" was used by zealous members of the Catholic Church to designate Protestants as well as Eastern Orthodox Christians. The term was considered to be so insulting that the Council of the Serbian Orthodox Church, held in Temeswar in 1790, decided to send an official plea to emperor Leopold II, begging him to ban the use of the term \"Acatholic\".\nLutheranism.\nThe Augsburg Confession found within the Book of Concord, a compendium of belief of the Lutheranism, teaches that \"the faith as confessed by Luther and his followers is nothing new, but the true catholic faith, and that their churches represent the true catholic or universal church\". When the Lutherans presented the Augsburg Confession to Charles V, Holy Roman Emperor in 1530, they believe to have \"show[n] that each article of faith and practice was true first of all to Holy Scripture, and then also to the teaching of the church fathers and the councils\".\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nNotes and references.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "7611", "revid": "4796325", "url": "https://en.wikipedia.org/wiki?curid=7611", "title": "Crystal Eastman", "text": "American lawyer, activist, feminist, and journalist (1881\u20131928)\nCrystal Catherine Eastman (June 25, 1881 \u2013 July 28, 1928) was an American lawyer, antimilitarist, feminist, socialist, and journalist. She was a leader in the fight for women's suffrage, a co-founder and co-editor with her brother Max Eastman of the radical arts and politics magazine \"The Liberator,\" co-founder of the Women's International League for Peace and Freedom, and co-founder in 1920 of the American Civil Liberties Union. In 2000, she was inducted into the National Women's Hall of Fame in Seneca Falls, New York.\nEarly life and education.\nCrystal Eastman was born in Marlborough, Massachusetts, on June 25, 1881, the third of four children. Her oldest brother, Morgan, was born in 1878 and died in 1884. The second brother, Anstice Ford Eastman, who became a general surgeon, was born in 1878 and died in 1937. Max was the youngest, born in 1883.\nIn 1883, their parents, Samuel Elijah Eastman and Annis Bertha Ford, moved the family to Canandaigua, New York. In 1889, their mother became one of the first women ordained as a Protestant minister in America when she became a minister of the Congregational church. Her father was also a Congregational minister, and the two served as pastors at the church of Thomas K. Beecher near Elmira. Mark Twain's family also attended the church and it was this shared association that young Crystal also became acquainted with him.\nThis part of New York was in the so-called \"Burnt Over District.\" During the Second Great Awakening earlier in the 19th century, its frontier had been a center of evangelizing and much religious excitement, which resulted in the founding of such beliefs as Millerism and Mormonism. During the antebellum period, some were inspired by religious ideals to support such progressive social causes as abolitionism and the Underground Railroad.\nThis humanitarian tradition influenced Crystal and her brother Max Eastman. He became a socialist activist early on, and Crystal had several common causes with him. They were close throughout her life, even after he had become more conservative.\nThe siblings lived together on 11th Street in New York City's Greenwich Village among other radical activists for several years. The group, including Ida Rauh, Inez Milholland, Floyd Dell, and Doris Stevens, also spent summers and weekends in Croton-on-Hudson, where Max bought a house in 1916.\nEastman graduated from Vassar College in 1903 and received a Master of Arts degree in sociology (then a relatively new field) from Columbia University in 1904. She then attended New York University Law School, graduating in 1907 as the second in her class. While pursuing her graduate degree, Eastman worked nights as a recreation leader at the Greenwich House Settlement, where she encountered Paul Underwood Kellogg.\nSocial efforts.\nSocial work pioneer and journal editor Paul Kellogg offered Eastman her first job: investigating labor conditions for \"The Pittsburgh Survey\". Her report, \"Work Accidents and the Law\" (1910), became a crucial tool in the fight for occupation health and safety and an early weapon in the ongoing battle. In 1909, Justice Hughes, who at the time was governor of New York, appointed Eastman to the New York State Commission of Employee's Liability and Causes of Industrial Accidents, Unemployment and Lack of Farm Labor. The first woman to be appointed a commission member, she drafted the inaugural workers' compensation law. This model became the standard for the U.S. During Woodrow Wilson's presidency, she continued to campaign for occupational safety and health while working as an investigating attorney for the U.S. Commission on Industrial Relations from 1913 to 1914. She advocated for \"motherhood endowments\" whereby mothers of young children would receive monetary benefits. She argued it would reduce forced dependence of mothers on men, as well as economically empower women.\nEmancipation.\nWallace J. Benedict was an insurance agent in Milwaukee, Wisconsin, and so when Eastman married him in 1911, she moved there after the wedding. There she managed the unsuccessful 1912 Wisconsin suffrage campaign.\nDivorcing in 1913, she returned east where she joined Alice Paul, Lucy Burns, and others in founding the militant Congressional Union for Woman Suffrage, which became the National Woman's Party. After the passage of the 19th Amendment gave women the right to vote in 1920, Eastman and Paul wrote the Equal Rights Amendment (ERA), first introduced in 1923. One of the few socialists to endorse the ERA, Eastman warned that protective legislation for women would mean only discrimination against women. Eastman claimed that one could assess the importance of the ERA by the intensity of the opposition to it. However, she felt that it was still a struggle worth fighting. She also delivered the speech \"Now We Can Begin\" after the ratification of the Nineteenth Amendment;it outlined the work that needed to be done in the political and economic spheres to achieve gender equality.\nPeace efforts.\nDuring World War I, Eastman was one of the founders of the Woman's Peace Party, soon joined by Jane Addams, Lillian D. Wald, and others. She served as president of the New York City branch. Renamed the Women's International League for Peace and Freedom in 1921, it remains the oldest extant women's peace organization. Eastman also became executive director of the American Union Against Militarism, which lobbied against America's entrance into the European war and more successfully against war with Mexico in 1916. This group sought to remove profiteering from arms manufacturing and campaigned against conscription, imperial adventures, and military intervention.\nWhen the United States entered World War I, Eastman, together with Roger Baldwin and Norman Thomas organized the National Civil Liberties Bureau (NCLB) to protect conscientious objectors or, in her words: \"To maintain something over here that will be worth coming back to when the weary war is over.\" The NCLB grew into the American Civil Liberties Union(ACLU), with Baldwin at the head and Eastman functioning as attorney-in-charge. Eastman is credited as a founding member of the ACLU, but her role as founder of the NCLB may have been largely ignored by posterity because of her personal differences with Baldwin.\nMarriage and family.\nIn 1916, Eastman married the British editor and antiwar activist Walter Fuller, who had come to the United States to direct his sisters' singing of folksongs. They had two children, Jeffrey Fuller born in 1917 and Annis Fuller born in 1921. Choosing to keep her last name, Eastman explored family practices aimed at fostering gender equality within the realms of marriage and family life. The publication of her 1923 confessional article titled \"Marriage Under Two Roofs\" caused an uproar as Eastman revealed the specifics of their unconventional living arrangement. She argues that residing in two separate residences is better than in one because by ultimately leading to an authentic expression of sexual desire and marital love, which in turn contributes to the overall happiness of the family unit. Eastman and Walter worked together as activists until the end of the war, when he worked as the managing editor of \"The Freeman\" until 1922, when he returned to London, England. For eight years, Eastman traveled by ship between London and New York to be with her husband. Walter died in 1927 from a stroke, which ended his career of editing \"Radio Times\" for the BBC.\nAfter Max Eastman's periodical \"The Masses\" was forced to close by government censorship in 1917, he and Crystal co-founded a radical journal of politics, art, and literature: the \"Liberator\", in early 1918. She and Max co-edited it until they put it in the hands of faithful friends in 1922.\nPost-War.\nAfter the war, Eastman organized the First Feminist Congress in 1919. In New York, her activities led to her being blacklisted during the Red Scare of 1919\u20131920. During the 1920s, Eastman was a columnist for Alice Paul's feminist journal, \"Equal Rights,\" and the British feminist weekly publication \"Time and Tide\". Eastman claimed that \"life was a big battle for the complete feminist,\" but she was convinced that the complete feminist would someday achieve total victory.\nDeath.\nCrystal Eastman died at age 47, on July 8, 1928, of nephritis, a year after her husband had passed. Friends were entrusted with their two orphaned children, then seven and eleven years old, to rear them until adulthood.\nLegacy.\nEastman has been called one of the most neglected leaders in the United States because although she wrote pioneering legislation and created long-lasting political organizations, she disappeared from history for 50 years. Freda Kirchwey, the editor of \"The Nation\", wrote at the time of her death, \"When she spoke to people\u2014whether it was to a small committee or a swarming crowd\u2014hearts beat faster. She was for thousands a symbol of what the free woman might be.\"\nIn 2000, Eastman was inducted into the (American) National Women's Hall of Fame in Seneca Falls, New York.\nIn 2018, \"The Socialist\", the official publication of the Socialist Party USA, published the article \"Remembering Socialist Feminist Crystal Eastman\" by Lisa Petriello, which was written \"on the 90th-year anniversary of her [Eastman's] death to bring her life and legacy once again to the public eye.\"\nWorks.\nPapers.\nEastman's papers are housed at Harvard University.\nPublications.\nThe Library of Congress has the following publications by Eastman in its collection, many of them published posthumously:\nSee also.\nPeople.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nPolitical groups.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nOther.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nFootnotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "7612", "revid": "50857730", "url": "https://en.wikipedia.org/wiki?curid=7612", "title": "Christopher Alexander", "text": "British-American architect (1936\u20132022)\nChristopher Wolfgang John Alexander (4 October 1936 \u2013 17 March 2022) was an Austrian-born British-American architect and design theorist. He was an emeritus professor at the University of California, Berkeley. His theories about the nature of human-centered design have affected fields beyond architecture, including urban design, software design, and sociology. Alexander designed and personally built over 100 buildings, both as an architect and a general contractor.\nIn software, Alexander is regarded as the father of the pattern language movement. According to creator Ward Cunningham, the first wiki\u2014the technology behind Wikipedia\u2014led directly from Alexander's work. Alexander's work has also influenced the development of agile software development.\nIn architecture, Alexander's work is used by a number of different contemporary architectural communities of practice, including the New Urbanist movement, to help people to reclaim control over their own built environment. However, Alexander was controversial among some mainstream architects and critics, in part because his work was often harshly critical of much of contemporary architectural theory and practice.\nAlexander is best known for his 1977 book \"A Pattern Language,\" a perennial seller some four decades after publication. Reasoning that users are more sensitive to their needs than any architect could be, he collaborated with his students Sara Ishikawa, Murray Silverstein, Max Jacobson, Ingrid King, and Shlomo Angel to produce a pattern language that would empower anyone to design and build at any scale.\nHis other books include \"Notes on the Synthesis of Form, A City is Not a Tree\" (first published as a paper and re-published in book form in 2015), \"The Timeless Way of Building, A New Theory of Urban Design,\" \"The Oregon Experiment,\" the four-volume \",\" about his theories of \"morphogenetic\" processes, and \"The Battle for the Life and Beauty of the Earth\", about the implementation of his theories in a large building project in Japan.\nPersonal life.\nAlexander was born in Vienna, Austria to his Catholic father, Ferdinand Johann Alfred Alexander, and Jewish mother, Lilly Edith Elizabeth (n\u00e9e Deutsch) Alexander. As a young child, Alexander emigrated in fall 1938 with his parents from Austria to England, when his parents were forced to flee the Nazi regime. In England, his parents worked as German language teachers. Alexander spent much of his childhood in Chichester and Oxford, England, where he began his education in the sciences. He moved from England to the United States in 1958 to study at Harvard University and Massachusetts Institute of Technology. He moved to Berkeley, California in 1963 to accept an appointment as Professor of Architecture, a position he would hold for almost 40 years. In 2002, after his retirement, Alexander moved to Arundel, England, where he continued to write, teach and build up to the time of his illness and death. Alexander was married to Margaret Moore Alexander, and he had two daughters, Sophie and Lily, by his former wife Pamela Patrick. Alexander held both British and American citizenship.\nOn 17 March 2022, Alexander died of pneumonia in his home in Binsted, England.\nEducation.\nAlexander attended the Dragon School in Oxford and then Oundle School. In 1954, he was awarded the top open scholarship to Trinity College, Cambridge, in chemistry and physics, and went on to read mathematics. He earned a Bachelor's degree in Architecture and a master's degree in mathematics. He took his doctorate at Harvard (the first PhD in Architecture ever awarded at Harvard University). His dissertation \"The Synthesis of Form: Some Notes on a Theory\" was completed in 1962. He was elected fellow at Harvard. During the same period he worked at MIT in transportation theory and computer science, and worked at Harvard in cognition and cognitive studies.\nHonors.\nAlexander was elected to the Society of Fellows, Harvard University 1961\u201364; awarded the First Medal for Research by the American Institute of Architects, 1972; (FAIA) elected member of the Swedish Royal Academy of Arts, 1980; winner of the Best Building in Japan award, 1985; winner of the ACSA (Association of Collegiate Schools of Architecture) Distinguished Professor Award, 1986 and 1987; invited to present the Louis Kahn Memorial Lecture, 1992; elected a Fellow of the American Academy of Arts and Sciences, 1996; one of the two inaugural recipients of the Athena Medal, given by the Congress for the New Urbanism (CNU), 2006;. awarded (\"in absentia\") the Vincent Scully Prize by the National Building Museum, 2009; awarded the lifetime achievement award by the Urban Design Group, 2011; winner of the Global Award for Sustainable Architecture, 2014 and 1994 Seaside Prize recipient.\nCareer.\nAuthor.\n\"The Timeless Way of Building\" (1979) described the perfection of use to which buildings could aspire: \n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;There is one timeless way of building. It is a thousand years old, and the same today as it has ever been. The great traditional buildings of the past, the villages and tents and temples in which man feels at home, have always been made by people who were very close to the center of this way. It is not possible to make great buildings, or great towns, beautiful places, places where you feel yourself, places where you feel alive, except by following this way. And, as you will see, this way will lead anyone who looks for it to buildings which are themselves as ancient in their form, as the trees and hills, and as our faces are.\n\"A Pattern Language: Towns, Buildings, Construction\" (1977), co-authored with Sara Ishikawa and Murray Silverstein, described a practical architectural system in a form that a theoretical mathematician or computer scientist might call a generative grammar. The work originated from an observation that many medieval cities are attractive and harmonious. The authors said that this occurs because they were built to local regulations that required specific features, but freed the architect to adapt them to particular situations. The book had its beginnings with an early version of Alexander's PhD dissertation based on fieldwork in the Bavra village in Gujarat, India.\nThe book provides rules and pictures, and leaves decisions to be taken from the precise environment of the project. It describes exact methods for constructing practical, safe, and attractive designs at every scale, from entire regions, through cities, neighborhoods, gardens, buildings, rooms, built-in furniture, and fixtures down to the level of doorknobs. A notable value is that the architectural system consists only of classic patterns tested in the real world and reviewed by multiple architects for beauty and practicality.\nThe book includes all needed surveying and structural calculations, and a novel simplified building system that copes with regional shortages of wood and steel, uses easily stored inexpensive materials, and produces long-lasting classic buildings with small amounts of materials, design and labor. It first has users prototype a structure on-site in temporary materials. Once accepted, these are finished by filling them with very-low-density concrete. It uses vaulted construction to build as high as three stories, permitting very high densities.\nThis book's method was adopted by the University of Oregon as described in \"The Oregon Experiment\" (1975), and remains the official planning instrument. It has also been adopted in part by some cities as a building code.\nThe idea of a pattern language appears to apply to any complex engineering task, and has been applied to some of them. It has been especially influential in software engineering where patterns have been used to document collective knowledge in the field.\n\"A New Theory of Urban Design\" (1987) coincided with a renewal of interest in urbanism among architects, but stood apart from most other expressions of this by assuming a distinctly anti-masterplanning stance. An account of a design studio conducted with University of California Berkeley students on a site in San Francisco, it shows how convincing urban networks can be generated by requiring individual actors to respect only \"local\" rules, in relation to neighbours. A vastly undervalued part of the Alexander canon, \"A New Theory\" is important in understanding the generative processes which give rise to the shanty towns latterly championed by Stewart Brand, Robert Neuwirth, and Charles III, the then Prince of Wales (2001). There have been critical reconstructions of Alexander's design studio based on the theories put forward in \"A New Theory of Urban Design\".\n\"The Nature of Order: An Essay on the Art of Building and the Nature of the Universe\" (2003\u201304), which includes The \"Phenomenon of Life\", \"The Process of Creating Life\", \"A Vision of a Living World\" and \"The Luminous Ground\", is Alexander's most comprehensive and elaborate work. In it, he put forth a new theory about the nature of space and described how this theory influences thinking about architecture, building, planning, and the way in which we view the world in general. The mostly static patterns from \"A Pattern Language\" were amended by more dynamic sequences, which describe how to work towards patterns (which can roughly be seen as the result of sequences). Sequences, like patterns, promise to be tools of wider scope than building (just as his theory of space goes beyond architecture).\nThe online publication \"Katarxis 3\" (September 2004) includes several essays by Christopher Alexander, as well as a debate between Alexander and Peter Eisenman from 1982.\nAlexander's final book published while he was alive, \"The Battle for the Life and Beauty of the Earth: A Struggle Between Two World-Systems\" (2012), is the story of the largest project he and his colleagues had ever tackled, the construction of a new High School/College campus in Japan. He also used the project to connect with themes in his four-volume series. He contrasted his approach, (System A) with the construction processes endemic in the U.S. and Japanese economies (System B). As Alexander describes it, System A is focused on enhancing the life/spirit of spaces within given constraints (land, budget, client needs, etc.) (drawings are sketches \u2013 decisions on placing buildings, materials used, finish and such are made in the field as construction proceeds, with adjustments as needed to meet overall budget); System B ignores, and tends to diminish or destroy that quality because there is an inherent flaw: System A is a generally a product of a different Economic System than we live in now. When the architect is only responsible for concept and casual field drawings (which the builder uses to build structures at the lowest possible [competitive] cost), the builder finds that System A can not produce acceptable results at the lowest market cost. Except for a culture where land and material costs are low or first world clients who are sensitive, patient and wealthy. In most cases, the economically motivated builder must use a hybrid system. In the best case, System AB, the builder uses the processes of System A to differentiate, improve and inform his work. Or there are no economic considerations and the builder is the architect and is building for himself. In the last few chapters he described \"centers\" as a way of thinking about the connections among spaces, and about what brings more wholeness and life to a space.\nWorks of architecture.\nAmong Alexander's most notable built works are the Eishin Campus near Tokyo (the building process of which is outlined in his 2012 book \"The Battle for the Life and Beauty of the Earth\"); the West Dean Visitors Centre in West Sussex, England; the Julian Street Inn (a homeless shelter) in San Jose, California (both described in \"Nature of Order\"); the Sala House and the Martinez House (experimental houses in Albany and Martinez, California made of lightweight concrete); the low-cost housing in Mexicali, Mexico (described in \"The Production of Houses\"); and several private houses (described and illustrated in \"The Nature of Order\"). Alexander's built work is characterized by a special quality (which he used to call \"the quality without a name\", but named \"wholeness\" in \"Nature of Order\") that relates to human beings and induces feelings of belonging to the place and structure. This quality is found in the most loved traditional and historic buildings and urban spaces, and is precisely what Alexander has tried to capture with his sophisticated mathematical design theories. Paradoxically, achieving this connective human quality has also moved his buildings away from the abstract imageability valued in contemporary architecture, and this is one reason why his buildings are under-appreciated at present.\nHis former student and colleague Michael Mehaffy wrote an introductory essay on Alexander's built work in the online publication \"Katarxis 3\", which includes a gallery of Alexander's major built projects through September 2004.\nTeaching.\nIn addition to his lengthy teaching career as a professor at UC Berkeley (during which a number of international students began to appreciate and apply his methods), Alexander was a key faculty member at both The Prince of Wales's Summer Schools in Civil Architecture (1990\u20131994) and The Prince's Foundation for the Built Environment. He also initiated the process which led to the international Building Beauty post-graduate school for architecture, which launched in Sorrento, Italy for the 2017\u201318 academic year.\nInfluence.\nAlexander has been influential both in architecture and in a wide variety of other areas of study.\nArchitecture.\nAlexander's work has widely influenced architects; among those who acknowledge his influence are Sarah Susanka, Andres Duany, and Witold Rybczynski. Robert Campbell, the Pulitzer Prize-winning architecture critic for the \"Boston Globe\", stated that Alexander \"has had an enormous critical influence on my life and work, and I think that's true of a whole generation of people.\"\nArchitecture critic Peter Buchanan, in an essay for \"The Architectural Review\"'s 2012 campaign \"The Big Rethink\", argues that Alexander's work as reflected in \"A Pattern Language\" is \"thoroughly subversive and forward looking rather than regressive, as so many misunderstand it to be.\" He continues:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nMany urban development projects continue to incorporate Alexander's ideas. Alexander is one of the biggest influencers of the Metamodernist movement in architecture, which is part of the broader Post-postmodern movement of the 21st century. In the UK the developers Living Villages have been highly influenced by Alexander's work and used \"A Pattern Language\" as the basis for the design of The Wintles in Bishops Castle, Shropshire. Sarah Susanka's \"Not So Big House\" movement adapts and popularizes Alexander's patterns and outlook.\nComputer science.\nAlexander's \"Notes on the Synthesis of Form\" has been cited by researchers in computer science since the late 1960s. It had an influence in the 1960s and 1970s on programming language design, modular programming, object-oriented programming, software engineering and other design methodologies. Alexander's mathematical concepts and orientation were similar to Edsger Dijkstra's influential \"A Discipline of Programming\".\nThe greatest influence of \"A Pattern Language\" in computer science is the design patterns movement. Alexander's philosophy of incremental, organic, coherent design also influenced the extreme programming movement. The Wiki was invented to allow the Hillside Group to work collaboratively on programming design patterns. More recently the \"deep geometrical structures\" as discussed in \"The Nature of Order\" have been cited as having importance for object-oriented programming, particularly in C++.\nWill Wright wrote that Alexander's work was influential in the origin of the \"SimCity\" computer games, and in his later game \"Spore\".\nAlexander often led his own software research, such as the 1996 Gatemaker project with Greg Bryant.\nAlexander discovered and conceived a recursive structure, so called wholeness, which is defined mathematically, exists in space and matter physically, and reflects in our minds and cognition psychologically. He had his idea of wholeness back to early 1980s when he finished his first version of \"The Nature of Order\". His idea of wholeness or degree of wholeness relying on a recursive structure of centers resemble aspects of Google's PageRank.\nReligion.\nThe fourth volume of \"The Nature of Order\" approaches religious questions from a scientific and philosophical rather than mystical direction, focusing in human feelings, well-being and nature interaction rather than metaphysics. In it, Alexander describes deep ties between the nature of matter, human perception of the universe, and the geometries people construct in buildings, cities, and artifacts. He suggests a crucial link between traditional practices and beliefs, and recent scientific advances. Despite his leanings toward Deism, and his naturalistic and anthropologic approach to religion, Alexander maintained that he was a practicing member of the Catholic Church, which he believed to have accumulated, within its knowledge, a great deal of human truth.\nDesign science.\nThe life's work of Alexander is dedicated to turn design from unselfconscious behavior to selfconscious behavior, so called design science. In his very first book \"Notes on the Synthesis of Forms\", he set what he wanted to do. He was inspired by traditional buildings, and tried to derive some 253 patterns for architectural design. Later on, he further distilled 15 geometric properties to characterize living structure in \"The Nature of Order\". The design principles are differentiation and adaptation.\nPublished works.\nAlexander's published works include: \nUnpublished: \nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "7614", "revid": "39191556", "url": "https://en.wikipedia.org/wiki?curid=7614", "title": "Clabbers", "text": "Variation of Scrabble\nClabbers is a game played by tournament Scrabble players for fun, or occasionally at Scrabble variant tournaments. The name derives from the fact that the words CLABBERS and SCRABBLE form an anagram pair.\nRules.\nThe rules are identical to those of Scrabble, except that valid plays are only required to form anagrams of acceptable words; in other words, the letters in a word do not need to be placed in the correct order. If a word is challenged, the player who played the word must then name an acceptable word that anagrams to the tiles played.\nBecause the number of \"words\" that can be formed is vastly larger than in standard English, the board usually ends up tightly packed in places, and necessarily quite empty in others. Game scores will often be much higher than in standard Scrabble, due to the relative ease of making high-scoring overlap plays and easier access to premium squares.\nWeb version.\nThe Internet Scrabble Club offers the ability to play Clabbers online.\nExample game (SOWPODS).\nHorizontal words from top to bottom (# denotes words that exist in the Collins English Dictionary but not the TWL). Some of the words below have multiple anagrams:\nVertical words from left to right\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "7616", "revid": "27335766", "url": "https://en.wikipedia.org/wiki?curid=7616", "title": "Canopus (disambiguation)", "text": "Canopus (or Alpha Carinae) is the brightest star in the southern constellation of Carina.\nCanopus may also refer to:\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "7617", "revid": "49877262", "url": "https://en.wikipedia.org/wiki?curid=7617", "title": "Corum Jhaelen Irsei", "text": "Fictional character created by Michael Moorcock\nCorum Jhaelen Irsei (known also as \"the Prince in the Scarlet Robe\" and \"Corum of the Silver Hand\") is a fictional fantasy hero in a series of novels written by Michael Moorcock. The character was introduced in the novel \"The Knight of Swords\", published in 1971. This was followed by two other books published during the same year, \"The Queen of Swords\" and \"The King of Swords\". The three novels are collectively known as the \"Corum Chronicles trilogy\" or \"the Chronicles of Corum\". Both \"The Knight of the Swords\" and \"The King of the Swords\" won the August Derleth Award in 1972 and 1973 respectively. The character then starred in three books making up the \"Silver Hand trilogy\", and has appeared in other stories taking place in Moorcock's multiverse.\nCorum is a hero with disabilities, losing his left hand and right eye early in his first story. The hand and eye are later replaced by the Eye of Rhynn and the six-fingered Hand of Kwll, powerful artifacts that help Corum against his enemies. Corum is usually reluctant to use these two artifacts, as they involve methods and dark forces that conflict with his personal morality. Since the Eye of Rhynn causes Corum to see multiple planes of reality simultaneously, he often wears an eye patch over it to keep from being overwhelmed. After he loses both artifacts, Corum relies on a normal eyepatch and a silver prosthetic hand.\nCorum is one of many incarnations of Michael Moorcock's \"Eternal Champion\", a soul who is reborn frequently throughout the multiverse and usually fights to restore or maintain the Cosmic Balance between Chaos and Law. In some stories, Corum's adventures allow him to meet other aspects of the Eternal Champion, such as Elric of Melnibon\u00e9, Erekos\u00eb, and Dorian Hawkmoon. While Elric famously owes allegiance to the chaos god Arioch, Corum follows the cause of Law and begins his adventures by opposing the plans of Arioch (or his universe's version of the same being).\nFictional character biography.\nCorum lives during an age before recorded history, when human beings are rising on Earth and beginning to war with the planet's older societies. Corum's race, the Vadhagh, understands advanced science regarding the nature of reality. Through force of will, they are able to perceive and even shift through different dimensional planes for different purposes. The primitive humans of the age mistake these scientific tricks for sorcery and believe the Vadhagh engage in demonic rituals and witchcraft.\nCorum's people are long-lived and believe they have nothing to fear from humans. Over the centuries, they become complacent and ignorant of the world around them. As a result, they are taken by surprise when a human tribe hunts them down and slaughters them. The last survivor as far as he knows, Corum is tortured and mutilated by the human barbarians, losing an eye and a hand before he escapes. He wants vengeance against all humanity, but later learns humans make up many societies of different beliefs and moralities. After encountering sorcerers and god-like beings, Corum learns all reality is influenced by the forces of Chaos and Law. Corum dedicates himself to maintaining balance between both forces, as disaster and death occur if either side holds too much influence.\nCollections.\n\"The Swords\" Trilogy.\nThis trilogy consists of \"The Knight of the Swords\" (1971), \"The Queen of the Swords\" (1971), and \"The King of the Swords\" (1971). In the United Kingdom it has been collected as an omnibus edition titled \"Corum\", \"Swords of Corum\" and most recently \"Corum: The Prince in the Scarlet Robe\" (vol. 30 of Orion's Fantasy Masterworks series). In the United States the first trilogy has been published as \"Corum: The Coming of Chaos\".\nPlot.\nPrince Corum is a Vadhagh, one of a race of long-lived beings with limited magical abilities dedicated to peaceful pursuits such as art and poetry. Corum's father sends him away from their home, Castle Erorn, on a quest to learn the fate of their kinsmen. Corum eventually discovers that a group of \"Mabden\" (men), led by the savage Earl Glandyth-a-Krae, have raided all of the Vadhaugh's castles, and raped and slaughtered all of the Vadhaugh therein, including Corum's entire family. Arming himself, Corum attacks and kills several of the Mabden before being captured and tortured. After having his left hand cut off and right eye put out, Corum escapes by moving into another plane of existence, becoming invisible to the Mabden. They depart, and Corum is found by The Brown Man, a dweller of the forest of Laahr able to see Corum while out of phase. The Brown Man takes Corum to a being called The Giant of Laahr, who treats his wounds and explains he has a higher purpose.\nTravelling to Moidel's Castle (a likely incarnation of Mont-Saint-Michel), Corum encounters his future lover, the Margravine Rhalina, a Mabden woman of the civilized land of Lwym an Esh. Having found out Corum's location by torturing and killing the Brown Man of Laahr, Glandyth-a-Krae marshalled his allies to Moidel's Castle. Glandyth had kept Corum's former hand and eye as souvenirs, and showed them to Corum to provoke a reaction. Rhalina uses sorcery (a ship summoned from the depths of the ocean and manned by her drowned dead husband and crew) to ward off an attack by Glandyth-a-Krae. Determined to restore himself, Corum and Rhalina travel to the island of Shool, a near immortal and mad sorcerer. During the journey Corum observes the Wading God, a mysterious giant who trawls the ocean with a net. Upon arriving at the island, Shool takes Rhalina hostage, and then provides Corum with two artifacts to replace his lost hand and eye: the Hand of Kwll and the Eye of Rhynn. The Eye of Rhynn allows Corum to see into an undead netherworld where the last beings killed by Corum exist until summoned by the Hand of Kwll.\nShool then explains that Corum's ill fortune has been caused by the Chaos God Arioch, the Knight of the Swords. When Arioch and his fellow Chaos Lords conquered the Fifteen Planes, the balance between the forces of Law and Chaos tipped in favor of Chaos, and their minions - such as Glandyth-a-Krae - embarked on a bloody rampage. Shool sends Corum to Arioch's fortress to steal the Heart of Arioch, which the sorcerer intends to use to attain greater power. Corum confronts Arioch, and learns Shool is nothing more than a pawn of the Chaos God. Arioch then ignores Corum, who discovers the location of the Heart. Corum is then attacked by Arioch, but the Hand of Kwll crushes the Heart and banishes the Chaos God forever. Before fading from existence, Arioch warns Corum that he has now earned the enmity of the Sword Rulers. Corum then meets with The Giant of Laahr, who reveals himself to be Lord Arkyn, the godlike Lord of Law whose realm had been taken over by Arioch. Arkyn tells Corum the destruction of Arioch is the first step towards Law regaining control of the Fifteen Planes. Corum returns to the island to rescue Rhalina, and discovers Shool has become a powerless moron. Shool is devoured by his own creations soon afterwards.\nOn another five planes, the forces of Chaos - led by Xiombarg, Queen of the Swords - reign supreme and are on the verge on eradicating the last resistance from the forces of Law. The avatars of the Bear and Dog gods plot with Earl Glandyth-a-Krae to murder Corum and return Arioch to the Fifteen Planes. Guided by Arkyn, Corum, Rhalina and companion Jhary-a-Conel cross the planes and encounter the King Without A Country, the last of his people who in turn is seeking the City in the Pyramid. The group locate the City, which is in fact a floating arsenal powered by advanced technology and inhabited by a people originally from Corum's world and his distant kin.\nBesieged by the forces of Chaos, the City requires certain rare minerals to continue to power their weapons. Corum and Jhary attempt to locate the minerals and also encounter Xiombarg, who learns of Corum's identity. Corum slows Xiombarg's forces by defeating their leader, Prince Gaynor the Damned. Xiombarg is goaded into attacking the City directly in revenge for Arioch's banishment. Arkyn provides the minerals and confronts Xiombarg, who has manifested in a vulnerable state. As Arkyn banishes Xiombarg, Corum and his allies devastate the forces of Chaos. Glandyth-a-Krae, however, escapes and seeks revenge.\nA spell - determined to have been cast by the forces of Chaos - forces the inhabitants of Corum's plane to war with each other (including the City in the Pyramid). Desperate to stop the slaughter, Corum, Rhalina and Jhary-a-Conel travel to the last five planes, ruled by Mabelode, the King of the Swords. Rhalina is taken hostage by the forces of Chaos and Corum has several encounters with the forces of Chaos, including Earl Glandyth-a-Krae.\nCorum also meets two other aspects of the Eternal Champion: Elric and Erekos\u00eb, with all three seeking the mystical city of Tanelorn for their own purposes. After a brief adventure in the \"Vanishing Tower\", the other heroes depart and Corum and Jhary arrive at their version of Tanelorn. Corum discovers one of the \"Lost Gods\", the being Kwll, who is imprisoned and cannot be freed until whole. Corum offers Kwll his hand, on the condition that he aid them against Mabelode. Kwll accepts the terms, but reneges on the bargain until persuaded to assist. Corum is also stripped of his artificial eye, which belongs to Kwll's brother, the Lost God Rhynn. Kwll transports Corum and Jhary to the court of Mabelode, with the pair fleeing with Rhalina when Kwll directly challenges the Chaos God. On Kwll's instruction, Corum tosses the eye into the sea. It is recovered by the mysterious Wading God Corum had previously encountered, who is revealed to be Rhynn, which distracts Glandyth-a-Krae during his duel with Corum.\nIn a final battle, Corum avenges his family by killing Glandyth-a-Krae and decimating the last of Chaos' mortal forces. Kwll later appears to Corum and reveals that all the gods - of both Chaos and Law - have been slain in order to free humanity and allow it to shape its own destiny.\n\"The Silver Hand\" Trilogy.\nThis trilogy consists of \"The Bull and the Spear\" (1973), \"The Oak and the Ram\" (1973), and \"The Sword and the Stallion\" (1974). It was titled \"The Prince with the Silver Hand\" in the United Kingdom and \"The Chronicles of Corum\" in the United States respectively. The previous trilogy hinted at a Celtic or proto-Celtic setting for the stories - the terms \"mabden\" (human beings) and \"shefanhow\" (demons) occurring in these books are both Cornish language words. The Silver Hand trilogy is more explicit in its Celtic connections, with overt borrowings from Celtic mythology.\nPlot.\nSet eighty years after the defeat of the Sword Rulers, Corum has become despondent and alone since the death of his Mabden bride Rhalina. Plagued by voices at night, Corum believes he has gone insane until old friend Jhary-a-Conel advises Corum it is in fact a summons from another world. Listening to the voices allows Corum to pass to the other world, which is in fact the distant future. The descendants of Rhalina's folk, the Tuha-na-Cremm Croich (see: Crom Cruach), who call Corum \"Corum Llew Ereint\" (see: Lludd Llaw Eraint), face extinction by the Fhoi Myore (Fomorians). The Fhoi Myore, seven powerful but diseased and barely sentient giants, with the aid of their allies have conquered the land and plunged it into eternal winter. Allying himself with King Mannach, ruler of the Tuha-na-Cremm Croich, Corum falls in love with his daughter Medhbh (see: Medb).\nCorum also hears the prophecy of a seeress, who claims Corum should fear a brother (who will apparently slay him), a harp and above all, beauty. Corum seeks the lost artifacts of the Tuha-na-Cremm Croich - a sacred Bull, a spear, an oak, a ram, a sword and a stallion - which will restore the land. Corum gains new allies, Goffanon (a blacksmith and diminutive giant, a member of the Sidhe race) and Goffanon's cousin and true giant Illbrec. They battle the Fhoi Myore, who themselves have allies: a returned Prince Gaynor, the wizard Calatin and his clone of Corum, the Brothers of the Pine, the undead Ghoolegh and a host of giant demonic dogs. After being instrumental in the death of two of the Fhoi Myore and restoring to his senses the encircled Amergin, the High King and Chief Druid of the Tuha-na-Cremm Croich, Corum and his allies fight a final battle in which all their foes are destroyed.\nCorum decides not to return his own world, and is attacked by his clone, whom he defeats with the aid of a spell placed on his silver hand by Medhbh. Medhbh, however, attacks and wounds Corum, having been told by the being the Dagdah that their world must be free of all gods and demi-gods if they are to flourish as a people. Corum is then killed with his own sword by his animated silver hand, thereby fulfilling the prophecy.\nBibliography.\n\"The Swords\" trilogy:\n\"The Silver Hand\" trilogy:\nAdditional appearances:\nAwards.\nThe August Derleth Award won by:\nIn other media.\nComics.\nFirst Comics published \"The Chronicles of Corum\", a twelve issue limited series (Jan. 1986 - Dec. 1988) that adapted the \"Swords Trilogy\", and was followed by the four issue limited series \"Corum: The Bull and the Spear\" (Jan. - July (bi-monthly) 1989), which adapted the first book in the second trilogy.\nThese have been reprinted in 4 hardcover volumes by Titan Comics.\nRole-playing game.\nDarcsyde Productions produced a supplement for use with Chaosium's \"Stormbringer\" (2001) role-playing game adapting the characters and settings from the \"Corum\" series for role-playing.\neBooks.\nGollancz released the entire Corum stories in both print and ebook form, commencing in 2013. The ebooks are available via Gollancz's SF Gateway site.\nAudiobooks.\nIn 2016, GraphicAudio produced dramatized audiobook versions of Corum. \"AudioFile\" magazine criticised this audiobook for depicting Corum's \"inconsistent accent\", but otherwise commended its \"well-placed sound effects\", \"light musical score\" and \"strong selection of narrators\".\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "7618", "revid": "6056090", "url": "https://en.wikipedia.org/wiki?curid=7618", "title": "Cumberland (disambiguation)", "text": "Cumberland is one of the historic counties of England.\nCumberland may also refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nOther uses.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "7619", "revid": "1301414911", "url": "https://en.wikipedia.org/wiki?curid=7619", "title": "Capella (disambiguation)", "text": "Capella is a bright star in the constellation of Auriga.\nCapella may also refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "7621", "revid": "1559905", "url": "https://en.wikipedia.org/wiki?curid=7621", "title": "Clifford Adams", "text": ""}
{"id": "7622", "revid": "50835511", "url": "https://en.wikipedia.org/wiki?curid=7622", "title": "Complex instruction set computer", "text": "Processor with instructions capable of multi-step operations\nA complex instruction set computer (CISC ) is a computer architecture in which single instructions can execute several low-level operations (such as a load from memory, an arithmetic operation, and a memory store) or are capable of multi-step operations or addressing modes within single instructions. The term was retroactively coined in contrast to reduced instruction set computer (RISC) and has therefore become something of an umbrella term for everything that is not RISC, where some of the most common differentiating factors of a RISC architecture are uniform instruction length, and strictly separate memory access instructions. \nExamples of CISC architectures include complex mainframe computers to simplistic microcontrollers where memory load and store operations are not separated from arithmetic instructions. Specific instruction set architectures that have been retroactively labeled CISC are System/360 through z/Architecture, the PDP-11 and VAX architectures, and many others. Well known microprocessors and microcontrollers that have also been labeled CISC in many academic publications include the Motorola 6800, 6809 and 68000 families; the Intel 8080, iAPX 432, x86 and 8051 families; the Zilog Z80, Z8 and Z8000 families; the National Semiconductor NS320xx family; the MOS Technology 6502 family; and others.\nSome designs have been regarded as borderline cases by some writers. For instance, the Microchip Technology PIC has been labeled RISC in some circles and CISC in others.\nIncitements and benefits.\nBefore the RISC philosophy became prominent, many computer architects tried to bridge the so-called semantic gap, i.e., to design instruction sets that directly support high-level programming constructs such as procedure calls, loop control, and complex addressing modes, allowing data structure and array accesses to be combined into single instructions. Instructions are also typically highly encoded in order to further enhance the code density. The compact nature of such instruction sets results in smaller program sizes and fewer main memory accesses (which were often slow), which at the time (early 1960s and onwards) resulted in a tremendous saving on the cost of computer memory and disc storage, as well as faster execution. It also meant good programming productivity even in assembly language, as high level languages such as Fortran or Algol were not always available or appropriate. Indeed, microprocessors in this category are sometimes still programmed in assembly language for certain types of critical applications.\nNew instructions.\nIn the 1970s, analysis of high-level languages indicated compilers produced some complex corresponding machine language. It was determined that new instructions could improve performance. Some instructions were added that were never intended to be used in assembly language but fit well with compiled high-level languages. Compilers were updated to take advantage of these instructions. The benefits of semantically rich instructions with compact encodings can be seen in modern processors as well, particularly in the high-performance segment where caches are a central component (as opposed to most embedded systems). This is because these fast, but complex and expensive, memories are inherently limited in size, making compact code beneficial. Of course, the fundamental reason they are needed is that main memories (i.e., dynamic RAM today) remain slow compared to a (high-performance) CPU core.\nDesign issues.\nWhile many designs achieved the aim of higher throughput at lower cost and also allowed high-level language constructs to be expressed by fewer instructions, it was observed that this was not \"always\" the case. For instance, low-end versions of complex architectures (i.e. using less hardware) could lead to situations where it was possible to improve performance by \"not\" using a complex instruction (such as a procedure call or enter instruction) but instead using a sequence of simpler instructions.\nOne reason for this was that architects (microcode writers) sometimes \"over-designed\" assembly language instructions, including features that could not be implemented efficiently on the basic hardware available. There could, for instance, be \"side effects\" (above conventional flags), such as the setting of a register or memory location that was perhaps seldom used; if this was done via ordinary (non duplicated) internal buses, or even the external bus, it would demand extra cycles every time, and thus be quite inefficient.\nEven in balanced high-performance designs, highly encoded and (relatively) high-level instructions could be complicated to decode and execute efficiently within a limited transistor budget. Such architectures therefore required a great deal of work on the part of the processor designer in cases where a simpler, but (typically) slower, solution based on decode tables and/or microcode sequencing is not appropriate. At a time when transistors and other components were a limited resource, this also left fewer components and less opportunity for other types of performance optimizations.\nThe RISC idea.\nThe circuitry that performs the actions defined by the microcode in many (but not all) CISC processors is, in itself, a processor which in many ways is reminiscent in structure to very early CPU designs. In the early 1970s, this gave rise to ideas to return to simpler processor designs in order to make it more feasible to cope without (\"then\" relatively large and expensive) ROM tables and/or PLA structures for sequencing and/or decoding.\nAn early (retroactively) RISC-\"labeled\" processor (IBM 801\u00a0\u2013 IBM's Watson Research Center, mid-1970s) was a tightly pipelined simple machine originally intended to be used as an internal microcode kernel, or engine, in CISC designs, but also became the processor that introduced the RISC idea to a somewhat larger audience. Simplicity and regularity also in the visible instruction set would make it easier to implement overlapping processor stages (pipelining) at the machine code level (i.e. the level seen by compilers). However, pipelining at that level was already used in some high-performance CISC \"supercomputers\" in order to reduce the instruction cycle time (despite the complications of implementing within the limited component count and wiring complexity feasible at the time). Internal microcode execution in CISC processors, on the other hand, could be more or less pipelined depending on the particular design, and therefore more or less akin to the basic structure of RISC processors.\nThe CDC 6600 supercomputer, first delivered in 1965, has also been retroactively described as RISC. It had a load\u2013store architecture which allowed up to five loads and two stores to be in progress simultaneously under programmer control. It also had multiple function units which could operate at the same time.\nSuperscalar.\nIn a more modern context, the complex variable-length encoding used by some of the typical CISC architectures makes it complicated, but still feasible, to build a superscalar implementation of a CISC programming model \"directly\"; the in-order superscalar original Pentium and the out-of-order superscalar Cyrix 6x86 are well-known examples of this. The frequent memory accesses for operands of a typical CISC machine may limit the instruction-level parallelism that can be extracted from the code, although this is strongly mediated by the fast cache structures used in modern designs, as well as by other measures. Due to inherently compact and semantically rich instructions, the average amount of work performed per machine code unit (i.e. per byte or bit) is higher for a CISC than a RISC processor, which may give it a significant advantage in a modern cache-based implementation.\nTransistors for logic, PLAs, and microcode are no longer scarce resources; only large high-speed cache memories are limited by the maximum number of transistors today. Although complex, the transistor count of CISC decoders do not grow exponentially like the total number of transistors per processor (the majority typically used for caches). Together with better tools and enhanced technologies, this has led to new implementations of highly encoded and variable-length designs without load\u2013store limitations (i.e. non-RISC). This governs re-implementations of older architectures such as the ubiquitous x86 (see below) as well as new designs for microcontrollers for embedded systems, and similar uses. The superscalar complexity in the case of modern x86 was solved by converting instructions into one or more micro-operations and dynamically issuing those micro-operations, i.e. indirect and dynamic superscalar execution; the Pentium Pro and AMD K5 are early examples of this. It allows a fairly simple superscalar design to be located after the (fairly complex) decoders (and buffers), giving, so to speak, the best of both worlds in many respects. This technique is also used in IBM z196 and later z/Architecture microprocessors.\nCISC and RISC terms.\nBy the mid-1980s the computer industry's consensus was that RISC was more efficient than CISC. Digital Equipment Corporation estimated that RISC had a price/performance ratio at least twice that of CISC. Two possible responses from CISC vendors were:\nIntel was successful in improving x86 to match RISC's performance. The terms CISC and RISC have become less meaningful with the continued evolution of both CISC and RISC designs and implementations. The first highly (or tightly) pipelined x86 implementations, the 486 designs from Intel, AMD, Cyrix, and IBM, supported every instruction that their predecessors did, but achieved \"maximum efficiency\" only on a fairly simple x86 subset that was only a little more than a typical RISC instruction set (i.e., without typical RISC \"load\u2013store\" limits). The Intel P5 Pentium generation was a superscalar version of these principles. However, modern x86 processors also (typically) decode and split instructions into dynamic sequences of internally buffered micro-operations, which helps execute a larger subset of instructions in a pipelined (overlapping) fashion, and facilitates more advanced extraction of parallelism out of the code stream, for even higher performance.\nContrary to popular simplifications (present also in some academic texts,) not all CISCs are microcoded or have \"complex\" instructions. As CISC became a catch-all term meaning anything that's not a load\u2013store (RISC) architecture, it's not the number of instructions, nor the complexity of the implementation or of the instructions, that define CISC, but that arithmetic instructions also perform memory accesses. Compared to a small 8-bit CISC processor, a RISC floating-point instruction is complex. CISC does not even need to have complex addressing modes; 32- or 64-bit RISC processors may well have more complex addressing modes than small 8-bit CISC processors.\nA PDP-10, a PDP-8, an x86 processor, an Intel 4004, a Motorola 68000-series processor, a IBM Z mainframe, a Burroughs B5000, a VAX, a Zilog Z80000, and a MOS Technology 6502 all vary widely in the number, sizes, and formats of instructions, the number, types, and sizes of registers, and the available data types. Some have hardware support for operations like scanning for a substring, arbitrary-precision BCD arithmetic, or transcendental functions, while others have only 8-bit addition and subtraction. But they are all in the CISC category. because they have \"load-operate\" instructions that load and/or store memory contents within the same instructions that perform the actual calculations. For instance, the PDP-8, having only 8 fixed-length instructions and no microcode at all, is a CISC because of \"how\" the instructions work, PowerPC, which has over 230 instructions (more than some VAXes), and complex internals like register renaming and a reorder buffer, is a RISC, while Minimal CISC has 8 instructions, but is clearly a CISC because it combines memory access and computation in the same instructions.\nReferences.\nGeneral references.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt; "}
{"id": "7624", "revid": "5795695", "url": "https://en.wikipedia.org/wiki?curid=7624", "title": "CISC", "text": "CISC may refer to:\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "7626", "revid": "49843479", "url": "https://en.wikipedia.org/wiki?curid=7626", "title": "Cetacean", "text": "Infraorder of mammals\nCetaceans (; from la \" cetus\"\u00a0'whale', from grc \" \"\u03ba\u1fc6\u03c4\u03bf\u03c2\" ()\"\u00a0'huge fish, sea monster') are aquatic mammals belonging to the infraorder Cetacea, in the order Artiodactyla. Cetaceans include whales, dolphins and porpoises. Key characteristics are their fully aquatic lifestyle, streamlined body shape, often large size and exclusively carnivorous diet. They propel themselves through the water with powerful up-and-down movements of their tail, which ends in a paddle-like fluke, using their flipper-shaped forelimbs to steer.\nWhile the majority of cetaceans live in marine environments, a small number reside solely in brackish or fresh water. Having a cosmopolitan distribution, they can be found in some rivers and all of Earth's oceans, and many species migrate throughout vast ranges with the changing of the seasons.\nCetaceans are famous for their high intelligence, complex social behaviour, and the enormous size of some of the group's members. For example, the blue whale reaches a maximum confirmed length of and a weight of 173 tonnes (190 short tons), making it the largest animal ever known to have existed.\nThere are approximately 90 living species split into two parvorders: the Odontoceti or toothed whales, which contains 75 species including porpoises, dolphins, other predatory whales like the beluga and sperm whale, and the beaked whales and the filter feeding Mysticeti or baleen whales, which contains 15 species and includes the blue whale, the humpback whale and the bowhead whale, among others. Despite their highly modified bodies and carnivorous lifestyle, genetic and fossil evidence places cetaceans within the even-toed ungulates, most closely related to hippopotamus.\nCetaceans have been extensively hunted for their meat, blubber and oil by commercial operations. Although the International Whaling Commission has agreed on putting a halt to commercial whaling, whale hunting is still ongoing, either under IWC quotas to assist the subsistence of Arctic native peoples or in the name of scientific research, although a large spectrum of non-lethal methods are now available to study marine mammals in the wild. Cetaceans also face severe environmental hazards from underwater noise pollution, entanglement in ropes and nets, ship strikes, build-up of plastics and heavy metals, and anthropogenic climate change, but how much they are affected varies widely from species to species, from minimally in the case of the southern bottlenose whale to the baiji (Chinese river dolphin) which is considered to be functionally extinct due to human activity.\nBaleen whales and toothed whales.\nBaleen whales (Mysticeti) and toothed whales (Odontoceti) are thought to have diverged from one another around thirty-four million years ago. Ninety extant (currently living) species of whale are currently accepted, with 75 being toothed whales and the remaining 15 baleen whales.\nBaleen whales have bristles made of keratin instead of teeth. Gray whales (Eschrichtiidae) feed on bottom-dwelling mollusks. Baleen whales belonging to the rorqual family (Balaenopteridae) use throat pleats to expand their mouths to take in small invertebrates like krill and sieve out the water. Right whales and bowhead whales (family Balaenidae) have massive heads that can make up 40% of their body mass. Most mysticetes prefer the food-rich colder waters around the poles of the Northern and Southern Hemispheres, migrating to the Equator to give birth. During this process, they are capable of fasting for several months, relying on their fat reserves.\nThe toothed whales include sperm whales, beaked whales, dolphins and porpoises. These whales have teeth evolved to catch fish, squid or other marine invertebrates and swallow their prey whole instead of chewing it. Tooth shape can vary between groups, with cone-shaped teeth in dolphins and sperm whales, spade-shaped teeth in porpoises, peg-like teeth in belugas, tusks in narwhals and many different shapes in the ornamental teeth of male beaked whales. The teeth of female beaked whales are hidden in the gums and are not visible, and most male beaked whales have only two short tusks. Narwhals have vestigial teeth alongside their tusk, which is present on males and 15% of females. A few toothed whales, such as some orcas, feed on marine mammals such as pinnipeds and other whales.\nToothed whales have well-developed senses. Their eyesight and hearing are adapted for both air and water, and they can echolocate by producing sounds and using their melon. Some species\u2014such as sperm whales and beaked whales\u2014are well adapted for diving to great depths. Several species of toothed whales show sexual dimorphism, in which the males differ from the females, usually for purposes of sexual display or aggression.\nAnatomy.\nCetacean bodies are generally similar to those of fish, which can be attributed to their lifestyle and similar habitat conditions. Their body is well-adapted to their habitat, although they share essential characteristics with other higher mammals (Eutheria). Most notably, whales have a streamlined shape, and their forelimbs are flippers. Almost all have a dorsal fin on their backs, but this can take on many forms, depending on the species. A few species, such as the beluga whale, lack them. Both the flipper and the fin are for stabilization and steering in the water. The body is wrapped in a thick layer of fat, known as blubber. This provides thermal insulation and gives cetaceans their smooth, streamlined body shape. In larger species, it can reach a thickness up to . Hind legs are not present in cetaceans, nor are any other external body attachments such as a pinna.\nThe reproductive organs of both sexes and the mammary glands of females are sunken into the body. The male genitals are attached to a vestigial pelvis.\nSexual dimorphism is prominent in many species of toothed whale, including sperm whales, narwhals, many members of the beaked whale family and several species of the porpoise and dolphin families. In some of these species, males have developed external features absent in females that are advantageous in combat or display. For example, many male beaked whales possess tusks which are used in competition and absent in females.\nHead.\nWhales have an elongated head, especially baleen whales, due to the wide overhanging jaw. The jaws contain either teeth or baleen in species of the respective groups. Baleen is made up of long, fibrous strands of keratin. Located in place of the teeth of the upper jaw, it has the appearance of a huge fringe and is used to sieve the water for prey items. When present, the teeth or baleen in the upper jaw sit exclusively on the maxilla.\nTheir nostril(s) make up the blowhole, which has one opening in toothed whales and two in baleen whales. The nostrils are located on top of the head above the eyes so that the rest of the body can remain submerged while surfacing for air. By shifting the nostrils to the top of the head, the nasal passages extend perpendicularly through the skull. The back of the skull is significantly shortened and deformed, and the braincase is concentrated forwards through the nasal passage and is heightened, with individual cranial bones overlapping. Most cetaceans have fused neck vertebrae and are unable to turn their head at all, but river dolphins retain this ability.\nMany toothed whales show a depression in the front of their skull, which houses a large mass of fat known as a melon and multiple asymmetric air bags. These soft tissues aid in biosonar and buoyancy, respectively. The sperm whale has a particularly pronounced melon and the shape of their head is further changed by the presence of the spermaceti organ, which contains the eponymous spermaceti, hence the name \"sperm whale\".\nSkeleton.\nThe cetacean skeleton is largely made up of dense cortical bone, which stabilizes the animal in the water. For this reason, the usual terrestrial compact bones, which are finely woven cancellous bone, are replaced with lighter and more elastic material. In many places, bone elements are replaced by cartilage and even fat, thereby improving their hydrostatic qualities. The ear and parts of the snout contain a high-density bone structure that is exclusive to cetaceans and resembles porcelain. This conducts sound better than other bones, thus aiding biosonar.\nThe number of vertebrae that make up the spine varies by species, ranging from 40 to 93. The neck consists of seven vertebrae which are reduced or fused, providing stability during swimming at the expense of mobility. The fins are carried by the thoracic vertebrae, ranging from nine to seventeen individual vertebrae. The sternum is cartilaginous. The last two to three pairs of ribs are not connected and hang freely in the body. The stable lumbar and tail include the other vertebrae. The caudal vertebrae can be identified by the chevron bone, which hangs underneath them.\nThe front limbs are paddle-shaped with shortened arms and elongated finger bones, to support movement. They are connected by cartilage. The second and third fingers display a proliferation of the finger members, a so-called hyperphalangy. The shoulder joint is the only functional joint in all cetaceans except for the Amazon river dolphin. The collarbone is completely absent.\nFluke.\nCetaceans have a cartilaginous fluke at the end of their tails that is used for propulsion. The fluke is set horizontally on the body and used with vertical movements, unlike fish, which have vertical tail flukes that move horizontally.\nPhysiology.\nBrain.\nIn cetaceans, evolution in the water has caused changes to the head that have modified brain shape such that the brain folds around the insula and expands more laterally than in terrestrial mammals. As a result, the cetacean prefrontal cortex (compared to that in humans) rather than frontal is laterally positioned. The neocortex of many cetaceans is home to elongated spindle neurons that, prior to 2019, were known only in hominids. In humans, these cells are thought to be involved in social conduct, emotions, judgment and theory of mind. Cetacean spindle neurons are found in the same areas of the brain where they are found in humans, suggesting they perform a similar function.\nThe brain to body mass ratio in some odontocetes, such as belugas and narwhals, is second only to that seen in humans. In some whales, however, it is less than half that of humans: 0.9% versus 2.1%. Sperm whales have the largest brain mass of any animal on Earth, averaging and in mature males. Brain size was previously considered a major indicator of intelligence. Since most of the brain is used for maintaining bodily functions, greater ratios of brain to body mass (weight) may increase the amount of brain mass available for cognitive tasks. Allometric analysis of the relationship between mammalian brain and body mass for different species of mammals shows that larger species generally have larger brains. However, this increase is not fully proportional. Typically the brain mass only increases in proportion to somewhere between the two-thirds power (or the square of the cube root) and the three-quarters power (or the cube of the fourth root) of the body mass. \"m\"\"brain\" \u221d (\"m\"\"body\")\"k\" where \"k\" is between two-thirds and three-quarters. Thus if Species B is twice the size of Species A, its brain size will typically be somewhere between 60% and 70% higher. Comparison of a particular animal's brain size with the expected brain size based on such an analysis provides an encephalization quotient that can be used as an indication of animal intelligence.\nSenses.\nVision.\nCetacean eyes are set on the sides rather than the front of the head. This means only species with pointed 'beaks' (such as dolphins) have good binocular vision forward and downward. Tear glands secrete greasy tears, which protect the eyes from the salt in the water. The lens is almost spherical, which is most efficient at focusing the minimal light that reaches deep water.\nChemical senses.\nOdontocetes have little to no ability to taste or smell, while mysticetes are believed to have some ability to smell because of their reduced, but functional olfactory system.\nElectroreception.\nAt least one species, the tucuxi or Guiana dolphin, is able to use electroreception to sense prey.\nEcholocation.\nToothed whales are generally capable of echolocation. They can discern the size, shape, surface characteristics, distance and movement of an object. Because of this they can search for, chase and catch fast-swimming prey in total darkness. Echolocation clicks also contain characteristic details unique to each animal, which may suggest that toothed whales can discern between their own clicks from those of others.\nWhile differences in ear structure associated with echolocating abilities are found amongst Cetacea, cranial asymmetry has also been found to be a factor in the ability to produce sounds used in echolocation. Mysticeti, who don't have the ability to echolocate, possess general symmetry of the skull and facial region, while Odontoceti display a nasofacial asymmetry that is linked to their echolocating abilities. Differences in the level of asymmetry also seem to correlate with differences in the types of sounds produced.\nEars.\nCetaceans are known to possess excellent hearing.\nThe external ear has lost the pinna (visible ear), but still retains a narrow ear canal. The three small bones or ossicles that transmit sound within each ear are dense and compact, and differently shaped from those of land mammals. The semicircular canals are much smaller relative to body size than in other mammals.\nA bony structure of the middle and inner ear, the auditory bulla, is composed of two compact and dense bones (the periotic and tympanic). It is housed in a cavity in the middle ear; in all toothed whales, with the exception of sperm whales, this cavity is filled with dense foam and completely surrounds the bulla, which is connected to the skull only by ligaments. This may isolate the ear from sounds transmitted through the bones of the skull, something that also happens in bats. Baleen whales have exceptionally thin, wide basilar membranes in their cochleae without stiffening agents, making their ears adapted for processing low to infrasonic frequencies.\nCetaceans use sound to communicate, using groans, moans, whistles, clicks or the 'singing' of the humpback whale.\nCirculation.\nCetaceans have powerful hearts. Blood oxygen is distributed effectively throughout the body. They are warm-blooded, meaning that they hold a nearly constant internal body temperature.\nRespiration.\nCetaceans have lungs, which means that they breathe air. An individual can last without a breath from a few minutes to over two hours depending on the species. Whales are deliberate breathers: they must be awake to inhale and exhale. When stale air, warmed from the lungs, is exhaled, it condenses as it meets colder external air. As with a terrestrial mammal breathing out on a cold day, a small cloud of 'steam' appears. This is called the 'spout' and varies across species in shape, angle and height. Species can be identified at a distance using this characteristic.\nThe structure of the respiratory and circulatory systems is of particular importance for the life of marine mammals. The oxygen balance is effective. Each breath can replace up to 90% of the total lung volume. For land mammals, in comparison, this value is usually about 15%. During inhalation, about twice as much oxygen is absorbed by the lung tissue as in a land mammal. As with all mammals, the oxygen is stored in the blood and the lungs, but in cetaceans, it is also stored in various tissues, mainly in the muscles. Here, this happens through the muscle pigment, myoglobin, provides an effective bond. This additional oxygen storage is vital for deep diving, since beyond a depth around , the lung tissue is almost completely compressed by the water pressure.\nAbdominal organs.\nThe stomach consists of three chambers. The first region is formed by a loose gland and a muscular forestomach (missing in beaked whales); this is followed by the main stomach and the pylorus. Both are equipped with glands to help digestion. A bowel adjoins the stomachs, whose individual sections can only be distinguished histologically. The liver is large and separate from the gall bladder. The kidneys are long and flattened. The salt concentration in cetacean blood is lower than that in seawater, requiring kidneys to excrete salt. This allows the animals to drink seawater. The urinary bladder is proportionally smaller in cetaceans than in land mammals. The testes are located internally, without an external scrotum. The uterus is bicornuate.\nChromosomes.\nThe initial karyotype includes a set of chromosomes from 2n = 44. They have four pairs of telocentric chromosomes (whose centromeres sit at one of the telomeres), two to four pairs of subtelocentric and one or two large pairs of submetacentric chromosomes. The remaining chromosomes are metacentric\u2014the centromere is approximately in the middle\u2014and are rather small. All cetaceans have chromosomes 2n = 44, except the sperm whales and pygmy sperm whales, which have 2n = 42.\nEcology.\nRange and habitat.\nCetaceans are found in many aquatic habitats. While many marine species, such as the blue whale, the humpback whale and the orca, have a distribution area that includes nearly the entire ocean, some species occur only locally or in broken populations. These include the vaquita, which inhabits a small part of the Gulf of California and Hector's dolphin, which lives in some coastal waters in New Zealand. Most river dolphin species live exclusively in fresh water.\nMany species inhabit specific latitudes, often in tropical or subtropical waters, such as Bryde's whale or Risso's dolphin. Others are found only in a specific body of water. The southern right whale dolphin and the hourglass dolphin live only in the Southern Ocean. The narwhal and the beluga live only in the Arctic Ocean. Sowerby's beaked whale and the Clymene dolphin exist only in the Atlantic and the Pacific white-sided dolphin and the northern straight dolphin live only in the North Pacific.\nCosmopolitan species may be found in the Pacific, Atlantic and Indian Oceans. However, northern and southern populations become genetically separated over time. In some species, this separation leads eventually to a divergence of the species, such as produced the southern right whale, North Pacific right whale and North Atlantic right whale. Migratory species' reproductive sites often lie in the tropics and their feeding grounds in polar regions.\nThirty-two species are found in European waters, including twenty-five toothed and seven baleen species.\nWhale migration.\nMany species of whales migrate on a latitudinal basis to move between seasonal habitats. For example, the gray whale migrates round trip. The journey begins at winter birthing grounds in warm lagoons along Baja California, and traverses of coastline to summer feeding grounds in the Bering, Chuckchi and Beaufort seas off the coast of Alaska.\nBehaviour.\nSleep.\nConscious breathing cetaceans sleep but cannot afford to be unconscious for long, because they may drown. While knowledge of sleep in wild cetaceans is limited, toothed cetaceans in captivity have been recorded to exhibit unihemispheric slow-wave sleep (USWS), which means they sleep with one side of their brain at a time, so that they may swim, breathe consciously and avoid both predators and social contact during their period of rest.\nA 2008 study found that sperm whales sleep in vertical postures just under the surface in passive shallow 'drift-dives', generally during the day, during which whales do not respond to passing vessels unless they are in contact, leading to the suggestion that whales possibly sleep during such dives.\nDiving.\nWhile diving, the animals reduce their oxygen consumption by lowering the heart activity and blood circulation; individual organs receive no oxygen during this time. Some rorquals can dive for up to 40 minutes, sperm whales between 60 and 90 minutes and bottlenose whales for two hours. Diving depths average about . Species such as sperm whales can dive to , although more commonly .\nSocial relations.\nMost cetaceans are social animals, although a few species live in pairs or are solitary. A group, known as a pod, usually consists of ten to fifty animals, but on occasion, such as mass availability of food or during mating season, groups may encompass more than one thousand individuals. Inter-species socialization can occur.\nPods have a fixed hierarchy, with the priority positions determined by biting, pushing or ramming. The behavior in the group is aggressive only in situations of stress such as lack of food, but usually it is peaceful. Contact swimming, mutual fondling and nudging are common. The playful behavior of the animals, which is manifested in air jumps, somersaults, surfing, or fin hitting, occurs more often than not in smaller cetaceans, such as dolphins and porpoises.\nWhale song.\nMales in some baleen species communicate via whale song, sequences of high pitched sounds. These \"songs\" can be heard for hundreds of kilometers. Each population generally shares a distinct song, which evolves over time. Sometimes, an individual can be identified by its distinctive vocals, such as the 52-hertz whale that sings at a higher frequency than other whales. Some individuals are capable of generating over 600 distinct sounds. In baleen species such as humpbacks, blues and fins, male-specific song is believed to be used to attract and display fitness to females.\nHunting.\nPod groups also hunt, often with other species. Many species of dolphins accompany large tunas on hunting expeditions, following large schools of fish. The orca hunts in pods and targets belugas and even larger whales. Humpback whales, among others, form in collaboration bubble carpets to herd krill or plankton into bait balls before lunging at them.\nIntelligence.\nCetacea are known to teach, learn, cooperate, scheme and grieve.\nSmaller cetaceans, such as dolphins and porpoises, engage in complex play behavior, including such things as producing stable underwater toroidal air-core vortex rings or \"bubble rings\". The two main methods of bubble ring production are rapid puffing of air into the water and allowing it to rise to the surface, forming a ring, or swimming repeatedly in a circle and then stopping to inject air into the helical vortex currents thus formed. They also appear to enjoy biting the vortex rings, so that they burst into many separate bubbles and then rise quickly to the surface. Whales produce bubble nets to aid in herding prey.\nLarger whales are also thought to engage in play. The southern right whale elevates its tail fluke above the water, remaining in the same position for a considerable time. This is known as \"sailing\". It appears to be a form of play and is most commonly seen off the coast of Argentina and South Africa. Humpback whales also display this behaviour.\nSelf-awareness appears to be a sign of abstract thinking. Self-awareness, although not well-defined, is believed to be a precursor to more advanced processes such as metacognitive reasoning (thinking about thinking) that humans exploit. Dolphins appear to possess self-awareness. The most widely used test for self-awareness in animals is the mirror test, in which a temporary dye is placed on an animal's body and the animal is then presented with a mirror. Researchers then explore whether the animal shows signs of self-recognition.\nCritics claim that the results of these tests are susceptible to the Clever Hans effect. This test is much less definitive than when used for primates. Primates can touch the mark or the mirror, while dolphins cannot, making their alleged self-recognition behavior less certain. Skeptics argue that behaviors said to identify self-awareness resemble existing social behaviors, so researchers could be misinterpreting self-awareness for social responses. Advocates counter that the behaviors are different from normal responses to another individual. Dolphins show less definitive behavior of self-awareness, because they have no pointing ability.\nIn 1995, Marten and Psarakos used video to test dolphin self-awareness. They showed dolphins real-time footage of themselves, recorded footage and another dolphin. They concluded that their evidence suggested self-awareness rather than social behavior. While this particular study has not been replicated, dolphins later \"passed\" the mirror test.\nDecision-making.\nCollective decisions are an important part of life as a cetacean for the many species that spend time in groups (whether these be temporary such as the fission-fusion dynamics of many smaller dolphin species or long-term stable associations as are seen in killer whale and sperm whale matrilines). Little is known about how these decisions work, though studies have found evidence messy consensus decisions in groups of sperm whales and leadership in other species like bottlenose dolphins and killer whales.\nLife history.\nReproduction and brooding.\nMost cetaceans sexually mature at seven to 10 years. An exception to this is the La Plata dolphin, which is sexually mature at two years, but lives only to about 20. The sperm whale reaches sexual maturity within about 20 years and has a lifespan between 50 and 100 years.\nFor most species, reproduction is seasonal. Ovulation coincides with male fertility. This cycle is usually coupled with seasonal movements that can be observed in many species. Most toothed whales have no fixed bonds. In many species, females choose several partners during a season. Although traditionally thought to be monogamous, research has shown that Baleen whales are promiscuous, with none showing pair bonds.\nGestation ranges from 9 to 16 months. Duration is not necessarily a function of size. Porpoises and blue whales gestate for about 11 months. As with all mammals other than marsupials and monotremes, the embryo is fed by the placenta, an organ that draws nutrients from the mother's bloodstream. Mammals without placentas either lay minuscule eggs (monotremes) or bear minuscule offspring (marsupials).\nCetaceans usually bear one calf. In the case of twins, one usually dies, because the mother cannot produce sufficient milk for both. In modern cetaceans, the fetus is usually positioned for a tail-first delivery. Contrary to popular belief, this is not to minimize the risk of drowning during delivery. More likely it has to do with the mechanics of birthing and the shape of the fetus. After birth, the mother carries the infant to the surface for its first breath. At birth, they are about one-third of their adult length and tend to be independently active, comparable to terrestrial mammals.\nSuckling.\nLike other placental mammals, cetaceans give birth to well-developed calves and nurse them with milk from their mammary glands. When suckling, the mother actively splashes milk into the mouth of the calf, using the muscles of her mammary glands, as the calf has no lips. This milk usually has a high-fat content, ranging from 16 to 46%, causing the calf to increase rapidly in size and weight.\nIn many small cetaceans, suckling lasts for about four months. In large species, it lasts for over a year and involves a strong bond between mother and offspring.\nIn several species of both whales and dolphins, alloparenting has been observed.\nThis reproductive strategy provides a few offspring that have a high survival rate.\nLifespan.\nAmong cetaceans, whales are distinguished by an unusual longevity compared to other higher mammals. Some species, such as the bowhead whale (\"Balaena mysticetus\"), can reach over 200 years. Based on the annual rings of the bony otic capsule, the age of the oldest known specimen is a male determined to be 211 years at the time of death.\nDeath.\nUpon death, whale carcasses fall to the deep ocean and provide a substantial habitat for marine life. Evidence of whale falls in present-day and fossil records shows that deep-sea whale falls support a rich assemblage of creatures, with a global diversity of 407 species, comparable to other neritic biodiversity hotspots, such as cold seeps and hydrothermal vents.\nDeterioration of whale carcasses happens through three stages. Initially, organisms such as sharks and hagfish scavenge the soft tissues at a rapid rate over a period of months and as long as two years. This is followed by the colonization of bones and surrounding sediments (which contain organic matter) by enrichment opportunists, such as crustaceans and polychaetes, throughout a period of years. Finally, sulfophilic bacteria reduce the bones releasing hydrogen sulfide enabling the growth of chemoautotrophic organisms, which in turn, support organisms such as mussels, clams, limpets and sea snails. This stage may last for decades and supports a rich assemblage of species, averaging 185 per site.\nDisease.\nBrucellosis affects almost all mammals. It is distributed worldwide, while fishing and pollution have caused porpoise population density pockets, which risks further infection and disease spreading. \"Brucella ceti\", most prevalent in dolphins, has been shown to cause chronic disease, increasing the chance of failed birth and miscarriages, male infertility, neurobrucellosis, cardiopathies, bone and skin lesions, strandings and death. Until 2008, no case had ever been reported in porpoises, but isolated populations have an increased risk and consequentially a high mortality rate.\nEvolution.\nFossil history.\nOrigins.\nThe direct ancestors of today's cetaceans are probably found within the Dorudontidae whose most famous member, \"Dorudon\", lived at the same time as \"Basilosaurus\". Both groups had already developed some of the typical anatomical features of today's whales, such as the fixed bulla, which replaces the mammalian eardrum, as well as sound-conducting elements for submerged directional hearing. Their wrists were stiffened and probably contributed to the typical build of flippers. The hind legs existed, however, but were significantly reduced in size and with a vestigial pelvis connection.\nTransition from land to sea.\nThe fossil record traces the gradual transition from terrestrial to aquatic life. The regression of the hind limbs allowed greater flexibility of the spine. This made it possible for whales to move around with the vertical tail hitting the water. The front legs transformed into flippers, costing them their mobility on land.\nOne of the oldest members of ancient cetaceans (Archaeoceti) is \"Pakicetus\" from the Middle Eocene of Pakistan. This is an animal the size of a wolf, whose skeleton is known only partially. It had functioning legs and lived near the shore. This suggests the animal could still move on land. The long snout had carnivorous dentition.\nThe transition from land to sea dates to about 49 million years ago, with the \"Ambulocetus\" (\"running whale\"), also discovered in Pakistan. It was up to long. The limbs of this archaeocete were leg-like, but it was already fully aquatic, indicating that a switch to a lifestyle independent from land happened extraordinarily quickly. The snout was elongated with overhead nostrils and eyes. The tail was strong and supported movement through water. \"Ambulocetus\" probably lived in mangroves in brackish water and fed in the riparian zone as a predator of fish and other vertebrates.\nDating from about 45 million years ago are species such as \"Indocetus\", \"Kutchicetus\", \"Rodhocetus\" and \"Andrewsiphius\", all of which were adapted to life in water. The hind limbs of these species were regressed and their body shapes resemble modern whales. Protocetidae family member \"Rodhocetus\" is considered the first to be fully aquatic. The body was streamlined and delicate with extended hand and foot bones. The merged pelvic lumbar spine was present, making it possible to support the floating movement of the tail. It was likely a good swimmer, but could probably move only clumsily on land, much like a modern seal.\nMarine animals.\nSince the late Eocene, about 40 million years ago, cetaceans populated the subtropical oceans and no longer emerged on land. An example is the 18 metre long \"Basilosaurus\", sometimes called \"Zeuglodon\". The transition from land to water was completed in about 10 million years. The Wadi Al-Hitan (\"Whale Valley\") in Egypt contains numerous skeletons of \"Basilosaurus\", as well as other marine vertebrates.\nExternal phylogeny.\nMolecular biology, immunology, and fossils show that cetaceans are phylogenetically closely related with the even-toed ungulates (Artiodactyla). Whales' direct lineage began in the early Eocene, around 55.8 million years ago, with early artiodactyls. Most molecular biological evidence suggests that hippos are the closest living relatives. Common anatomical features include similarities in the morphology of the posterior molars, and the bony ring on the temporal bone (bulla) and the involucre, a skull feature that was previously associated only with cetaceans. Since the fossil record suggests that the morphologically distinct hippo lineage dates back only about 15 million years, Cetacea and hippos apparently diverged from a common ancestor that was morphologically distinct from either. The most striking common feature is the talus, a bone in the upper ankle. Early cetaceans, archaeocetes, show double castors, which occur only in even-toed ungulates. Corresponding findings are from Tethys Sea deposits in northern India and Pakistan. The Tethys Sea was a shallow sea between the Asian continent and northward-bound Indian plate.\nMolecular and morphological evidence suggests that artiodactyls as traditionally defined are paraphyletic with respect to cetaceans. Cetaceans are deeply nested within the artiodactyls; the two groups together form a clade, a natural group with a common ancestor, for which the name Cetartiodactyla is sometimes used. Modern nomenclature divides Artiodactyla (or Cetartiodactyla) into four subordinate taxa: camelids (Tylopoda), pigs and peccaries (Suina), ruminants (Ruminantia), and hippos plus whales (Whippomorpha). The Cetacea's presumed location within Artiodactyla can be represented in the following cladogram:\nInternal phylogeny.\nWithin Cetacea, the two parvorders are baleen whales (Mysticeti) which owe their name to their baleen, and toothed whales (Odontoceti), which have teeth shaped like cones, spades, pegs, or tusks, and can perceive their environment through biosonar.\nThe terms \"whale\" and \"dolphin\" are informal:\n*Whales, with four families: Balaenidae (right and bowhead whales), Cetotheriidae (pygmy right whales), Balaenopteridae (rorquals), Eschrichtiidae (grey whales)\n*Whales: with four families: Monodontidae (belugas and narwhals), Physeteridae (sperm whales), Kogiidae (dwarf and pygmy sperm whales), and Ziphiidae (beaked whales)\n*Dolphins, with five families: Delphinidae (oceanic dolphins), Platanistidae (South Asian river dolphins), Lipotidae (old world river dolphins) Iniidae (new world river dolphins), and Pontoporiidae (La Plata dolphins)\n*Porpoises, with one family: Phocoenidae\nThe term 'great whales' covers those currently regulated by the International Whaling Commission: the Odontoceti families Physeteridae (sperm whales), Ziphiidae (beaked whales), and Kogiidae (pygmy and dwarf sperm whales); and Mysticeti families Balaenidae (right and bowhead whales), Cetotheriidae (pygmy right whales), Eschrichtiidae (grey whales), as well as part of the family Balaenopteridae (minke, Bryde's, sei, blue and fin; not Eden's and Omura's whales).\nThreats.\nThe primary threats to cetaceans come from people, both directly from whaling or drive hunting and indirect threats from fishing and pollution.\nWhaling.\nWhaling is the practice of hunting whales, mainly baleen and sperm whales. This activity has gone on since the Stone Age.\nIn the Middle Ages, reasons for whaling included their meat, oil usable as fuel and the jawbone, which was used in house construction. At the end of the Middle Ages, early whaling fleets aimed at baleen whales, such as bowheads. In the 16th and 17th centuries, the Dutch fleet had about 300 whaling ships with 18,000 crewmen.\nIn the 18th and 19th centuries, baleen whales especially were hunted for their baleen, which was used as a replacement for wood, or in products requiring strength and flexibility such as corsets and crinoline skirts. In addition, the spermaceti found in the sperm whale was used as a machine lubricant and the ambergris as a material for pharmaceutical and perfume industries. In the second half of the 19th century, the explosive harpoon was invented, leading to a massive increase in the catch size.\nLarge ships were used as \"mother\" ships for the whale handlers. In the first half of the 20th century, whales were of great importance as a supplier of raw materials. Whales were intensively hunted during this time; in the 1930s, 30,000 whales were killed. This increased to over 40,000 animals per year up to the 1960s, when stocks of large baleen whales collapsed.\nMost hunted whales are now threatened, with some great whale populations exploited to the brink of extinction. Atlantic and Korean gray whale populations were completely eradicated and the North Atlantic right whale population fell to some 300\u2013600. The blue whale population is estimated to be around 14,000.\nThe first efforts to protect whales came in 1931. Some particularly endangered species, such as the humpback whale (which then numbered about 100 animals), were placed under international protection and the first protected areas were established. In 1946, the International Whaling Commission (IWC) was established, to monitor and secure whale stocks. Whaling of 14 large species for commercial purposes was prohibited worldwide by this organization from 1985 to 2005, though some countries do not honor the prohibition.\nThe stocks of species such as humpback and blue whales have recovered, though they are still threatened. The United States Congress passed the Marine Mammal Protection Act of 1972 sustain the marine mammal population. It prohibits the taking of marine mammals except for several hundred per year taken in Alaska. Japanese whaling ships are allowed to hunt whales of different species for ostensibly scientific purposes.\nAboriginal whaling is still permitted. About 1,200 pilot whales were taken in the Faroe Islands in 2017, and about 900 narwhals and 800 belugas per year are taken in Alaska, Canada, Greenland, and Siberia. About 150 minke are taken in Greenland per year, 120 gray whales in Siberia and 50 bowheads in Alaska, as aboriginal whaling, besides the 600 minke taken commercially by Norway, 300 minke and 100 sei taken by Japan and up to 100 fin whales taken by Iceland. Iceland and Norway do not recognize the ban and operate commercial whaling. Norway and Japan are committed to ending the ban.\nDolphins and other smaller cetaceans are sometimes hunted in an activity known as dolphin drive hunting. This is accomplished by driving a pod together with boats, usually into a bay or onto a beach. Their escape is prevented by closing off the route to the ocean with other boats or nets. Dolphins are hunted this way in several places around the world, including the Solomon Islands, the Faroe Islands, Peru and Japan (the most well-known practitioner). Dolphins are mostly hunted for their meat, though some end up in dolphinaria. Despite the controversy thousands of dolphins are caught in drive hunts each year.\nFishing.\nDolphin pods often reside near large tuna shoals. This is known to fishermen, who look for dolphins to catch tuna. Dolphins are much easier to spot from a distance than tuna, since they regularly breathe. The fishermen pull their nets hundreds of meters wide in a circle around the dolphin groups, in the expectation that they will net a tuna shoal. When the nets are pulled together, the dolphins become entangled under water and drown. Line fisheries in larger rivers are threats to river dolphins.\nA greater threat than by-catch for small cetaceans is targeted hunting. In Southeast Asia, they are sold as fish-replacement to locals, since the region's edible fish promise higher revenues from exports. In the Mediterranean, small cetaceans are targeted to ease pressure on edible fish.\nStrandings.\nA stranding is when a cetacean leaves the water to lie on a beach. In some cases, groups of whales strand together. The best known are mass strandings of pilot whales and sperm whales. Stranded cetaceans usually die, because their as much as body weight compresses their lungs or breaks their ribs. Smaller whales can die of heatstroke because of their thermal insulation.\nThe causes are not clear. Possible reasons for mass beachings are:\nSince 2000, whale strandings frequently occurred following military sonar testing. In December 2001, the US Navy admitted partial responsibility for the beaching and the deaths of several marine mammals in March 2000. The coauthor of the interim report stated that animals killed by active sonar of some Navy ships were injured. Generally, underwater noise, which is still on the increase, is increasingly tied to strandings; because it impairs communication and sense of direction.\nClimate change influences the major wind systems and ocean currents, which also lead to cetacean strandings. Researchers studying strandings on the Tasmanian coast from 1920 to 2002 found that greater strandings occurred at certain time intervals. Years with increased strandings were associated with severe storms, which initiated cold water flows close to the coast. In nutrient-rich, cold water, cetaceans expect large prey animals, so they follow the cold water currents into shallower waters, where the risk is higher for strandings. Whales and dolphins who live in pods may accompany sick or debilitated pod members into shallow water, stranding them at low tide.\nEnvironmental hazards.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\nWorldwide, use of active sonar has been linked to about 50 marine mammal strandings between 1996 and 2006. In all of these occurrences, there were other contributing factors, such as unusual (steep and complex) underwater geography, limited egress routes, and a specific species of marine mammal\u2014beaked whales\u2014that are suspected to be more sensitive to sound than other marine mammals.\n\u2014Rear Admiral Lawrence Rice\nHeavy metals, residues of many plant and insect venoms and plastic waste flotsam are not biodegradable. Sometimes, cetaceans consume these hazardous materials, mistaking them for food items. As a result, the animals are more susceptible to disease and have fewer offspring.\nDamage to the ozone layer reduces plankton reproduction because of its resulting radiation. This shrinks the food supply for many marine animals, but the filter-feeding baleen whales are most impacted. Even the Nekton is, in addition to intensive exploitation, damaged by the radiation.\nFood supplies are also reduced long-term by ocean acidification due to increased absorption of increased atmospheric carbon dioxide. The CO2 reacts with water to form carbonic acid, which reduces the construction of the calcium carbonate skeletons of food supplies for zooplankton that baleen whales depend on.\nThe military and resource extraction industries operate strong sonar and blasting operations. Marine seismic surveys use loud, low-frequency sound that show what is lying underneath the Earth's surface. Vessel traffic also increases noise in the oceans. Such noise can disrupt cetacean behavior such as their use of biosonar for orientation and communication. Severe instances can panic them, driving them to the surface. This leads to bubbles in blood gases and can cause decompression sickness. Naval exercises with sonar regularly results in fallen cetaceans that wash up with fatal decompression. Sounds can be disruptive at distances of more than . Damage varies across frequency and species.\nRelationship to humans.\nResearch history.\nIn Aristotle's time, the fourth century BCE, whales were regarded as fish due to their superficial similarity. Aristotle, however, observed many physiological and anatomical similarities with the terrestrial vertebrates, such as blood (circulation), lungs, uterus and fin anatomy. His detailed descriptions were assimilated by the Romans, but mixed with a more accurate knowledge of the dolphins, as mentioned by Pliny the Elder in his \"Natural history\". In the art of this and subsequent periods, dolphins are portrayed with a high-arched head (typical of porpoises) and a long snout. The harbour porpoise was one of the most accessible species for early cetologists; because it could be seen close to land, inhabiting shallow coastal areas of Europe. Much of the findings that apply to all cetaceans were first discovered in porpoises. One of the first anatomical descriptions of the airways of a harbor porpoise dates from 1671 by John Ray. It nevertheless referred to the porpoise as a fish.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The tube in the head, through which this kind fish takes its breath and spitting water, located in front of the brain and ends outwardly in a simple hole, but inside it is divided by a downward bony septum, as if it were two nostrils; but underneath it opens up again in the mouth in a void.\u2014\u200a\nIn the 10th edition of Systema Naturae (1758), Swedish biologist and taxonomist Carl Linnaeus asserted that cetaceans were mammals and not fish. His groundbreaking binomial system formed the basis of modern whale classification.\nCulture.\nStone Age petroglyphs, such as those in Roddoy and Reppa (Norway), and the Bangudae Petroglyphs in South Korea, depict them. Whale bones were used for many purposes. In the Neolithic settlement of Skara Brae on Orkney sauce pans were made from whale vertebrae. The whale was first mentioned in ancient Greece by Homer. There, it is called Ketos, from which was derived the Roman word for whale, Cetus. In the Bible especially, the leviathan plays a role as a sea monster. The prophet Jonah, on his flight from the city of Nineveh, is swallowed by a whale.\nDolphins are mentioned far more often than whales. Aristotle discusses the sacred animals of the Greeks in his \"Historia Animalium\". The Greeks admired the dolphin as a \"king of the aquatic animals\" and referred to them erroneously as fish. Dolphins appear in Greek mythology. Because of their intelligence, they rescued multiple people from drowning. They were said to love music, probably because of their own song, and in the legends they saved famous musicians, such as Arion of Lesbos from Methymna. Dolphins belong to the domain of Poseidon and led him to his wife Amphitrite. Dolphins are associated with other gods, such as Apollo, Dionysus and Aphrodite. The Greeks paid tribute to both whales and dolphins with their own constellation. The constellation of the Whale (Ketos, lat. Cetus) is located south of the Dolphin (Delphi, lat. Delphinus) north of the zodiac. Ancient art often included dolphin representations, including the Cretan Minoans. A particularly popular representation is that of Arion or Taras riding on a dolphin. In early Christian art, the dolphin is a popular motif, at times used as a symbol of Christ.\nMiddle Ages to the 19th century.\nSt. Brendan described in his travel story \"Navigatio Sancti Brendani\" an encounter with a whale, between the years 565\u2013573. Most descriptions of large whales from the Middle Ages until the whaling era, beginning in the 17th century, were of beached whales. Raymond Gilmore documented seventeen sperm whales in the estuary of the Elbe from 1723 to 1959 and thirty-one animals on the coast of Great Britain in 1784. In 1827, a blue whale beached itself off the coast of Ostend. Whales were used as attractions in museums and traveling exhibitions.\nWhalers from the 17th to 19th centuries depicted whales in drawings and recounted tales of their occupation. Although they knew that whales were harmless giants, they described battles with harpooned animals. These included descriptions of sea monsters, including huge whales, sharks, sea snakes, giant squid and octopuses. Among the first whalers who described their experiences on whaling trips was Captain William Scoresby from Great Britain, who published the book \"Northern Whale Fishery\", describing the hunt for northern baleen whales. This was followed by Thomas Beale, a British surgeon, in his book \"Some observations on the natural history of the sperm whale\" in 1835; and Frederick Debell Bennett's \"The tale of a whale hunt\" in 1840. Whales were described in narrative literature and paintings, most famously in the novels \"Moby Dick\" by Herman Melville and \"Twenty Thousand Leagues Under the Seas\" by Jules Verne.\nBaleen was used to make vessel components such as the bottom of a bucket in the Scottish National Museum. The Norsemen crafted ornamented plates from baleen. In the Canadian Arctic (east coast) in Punuk and Thule culture (1000\u20131600 C.E.), baleen was used to construct houses in place of wood as roof support for winter houses.\nModern culture.\nIn the 20th century, perceptions of cetaceans changed. They transformed from monsters into creatures of wonder, as science revealed them to be intelligent and peaceful animals. Hunting was replaced by whale and dolphin tourism. This change is reflected in films and novels. For example, the protagonist of the series \"Flipper\" was a bottle-nose dolphin. The TV series \"SeaQuest DSV\" (1993\u20131996), the movies \"Free Willy\" and \"\", and the book series \"The Hitchhiker's Guide to the Galaxy\" by Douglas Adams are examples.\nThe study of whale songs also produced a popular album, \"Songs of the Humpback Whale\".\nCaptivity.\nWhales and dolphins have been kept in captivity for use in education, research and entertainment since the 19th century.\nBelugas.\nBeluga whales were the first whales to be kept in captivity. Other species were too rare, too shy or too big. The first was shown at Barnum's Museum in New York City in 1861. For most of the 20th century, Canada was the predominant source. They were taken from the St. Lawrence River estuary until the late 1960s, after which they were predominantly taken from the Churchill River estuary until capture was banned in 1992. Russia then became the largest provider. Belugas are caught in the Amur Darya delta and their eastern coast and are transported domestically to aquaria or dolphinaria in Moscow, St. Petersburg and Sochi, or exported to countries such as Canada. They have not been domesticated.\nAs of 2006, 30 belugas lived in Canada and 28 in the United States. 42 deaths in captivity had been reported. A single specimen can reportedly fetch up to US$100,000 (\u00a364,160). The beluga's popularity is due to its unique color and its facial expressions. The latter is possible because while most cetacean \"smiles\" are fixed, the extra movement afforded by the beluga's unfused cervical vertebrae allows a greater range of apparent expression.\nOrcas.\nThe orca's intelligence, trainability, striking appearance, playfulness in captivity and sheer size have made it a popular exhibit at aquaria and aquatic theme parks. From 1976 to 1997, fifty-five whales were taken from the wild in Iceland, nineteen from Japan and three from Argentina. These figures exclude animals that died during capture. Live captures fell dramatically in the 1990s and by 1999, about 40% of the forty-eight animals on display in the world were captive-born.\nOrganizations such as World Animal Protection and the Whale and Dolphin Conservation campaign against the practice of keeping them in captivity.\nIn captivity, they often develop pathologies, such as the dorsal fin collapse seen in 60\u201390% of captive males. Captives have reduced life expectancy, on average only living into their 20s, although some live longer, including several over 30 years old and two, Corky II and Lolita, in their mid-40s. In the wild, females who survive infancy live 46 years on average and up to 70\u201380 years. Wild males who survive infancy live 31 years on average and can reach 50\u201360 years.\nCaptivity usually bears little resemblance to wild habitat and captive whales' social groups are foreign to those found in the wild. Critics claim captive life is stressful due to these factors and the requirement to perform circus tricks that are not part of wild orca behavior. Wild orca may travel up to in a day and critics say the animals are too big and intelligent to be suitable for captivity. Captives occasionally act aggressively towards themselves, their tankmates, or humans, which critics say is a result of stress. Orcas are well known for their performances in shows, but the number of orcas kept in captivity is small, especially when compared to the number of bottlenose dolphins, with only forty-four captive orcas being held in aquaria as of 2012.\nEach country has its own tank requirements; in the US, the minimum enclosure size is set by the Code of Federal Regulations, 9 CFR E \u00a7\u00a03.104, under the \"Specifications for the Humane Handling, Care, Treatment and Transportation of Marine Mammals\".\nAggression among captive orcas is common. They attack each other and their trainers as well. In 2013, SeaWorld's treatment of orcas in captivity was the basis of the movie \"Blackfish\", which documents the history of Tilikum, an orca at SeaWorld Orlando, who had been involved in the deaths of three people. The film led to proposals by some lawmakers to ban captivity of cetaceans, and led SeaWorld to announce in 2016 that it would phase out its orca program.\nOthers.\nDolphins and porpoises are kept in captivity. Bottlenose dolphins are the most common, as they are relatively easy to train, have a long lifespan in captivity and have a friendly appearance. Bottlenose dolphins live in captivity across the world, though exact numbers are hard to determine. Other species kept in captivity are spotted dolphins, false killer whales and common dolphins, Commerson's dolphins, as well as rough-toothed dolphins, but all in much lower numbers. There are also fewer than ten pilot whales, Amazon river dolphins, Risso's dolphins, spinner dolphins, or tucuxi in captivity. Two unusual and rare hybrid dolphins, known as wolphins, are kept at Sea Life Park in Hawaii, which is a cross between a bottlenose dolphin and a false killer whale. Also, two common/bottlenose hybrids reside in captivity at Discovery Cove and SeaWorld San Diego.\nIn repeated attempts in the 1960s and 1970s, narwhals kept in captivity died within months. A breeding pair of pygmy right whales were retained in a netted area. They were eventually released in South Africa. In 1971, SeaWorld captured a California gray whale calf in Mexico at Scammon's Lagoon. The calf, later named Gigi, was separated from her mother using a form of lasso attached to her flukes. Gigi was displayed at SeaWorld San Diego for a year. She was then released with a radio beacon affixed to her back; however, contact was lost after three weeks. Gigi was the first captive baleen whale. JJ, another gray whale calf, was kept at SeaWorld San Diego. JJ was an orphaned calf that beached itself in April 1997 and was transported two miles to SeaWorld. The calf was a popular attraction and behaved normally, despite separation from his mother. A year later, the then whale though smaller than average, was too big to keep in captivity, and was released on April 1, 1998. A captive Amazon river dolphin housed at Acuario de Valencia is the only trained river dolphin in captivity.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "7627", "revid": "6036800", "url": "https://en.wikipedia.org/wiki?curid=7627", "title": "The Canterbury Tales", "text": "Story collection by Geoffrey Chaucer\nThe Canterbury Tales () are an anthology of twenty-four short stories written in Middle English by Geoffrey Chaucer between 1387 and 1400. They are mostly in verse, and are presented as part of a fictional storytelling contest held by a group of pilgrims travelling from London to Canterbury to visit the shrine of Saint Thomas Becket at Canterbury Cathedral.\nThe \"Tales\" are widely regarded as Chaucer's \"magnum opus\". They had a major effect upon English literature and may have been responsible for the popularisation of the English vernacular in mainstream literature, as opposed to French or Latin. English had, however, been used as a literary language centuries before Chaucer's time, and several of Chaucer's contemporaries\u2014John Gower, William Langland, the Gawain Poet, and Julian of Norwich\u2014also wrote major literary works in English. It is unclear to what extent Chaucer was seminal in this evolution of literary preference.\nRevered as one of the paramount works of English literature, \"The Canterbury Tales\" are generally thought to have been incomplete at the end of Chaucer's life. In the General Prologue, some thirty pilgrims are introduced. According to the Prologue, Chaucer's intention was to write four stories from the perspective of each pilgrim, two each on the way to and from their ultimate destination, Saint Thomas Becket's shrine (making for a total of about 120 stories).\nText.\nThe question of whether \"The Canterbury Tales\" is a finished work has not been answered to date. There are 84 manuscripts and four incunabula (printed before 1500) editions of the work, which is more than for any other vernacular English literary text with the exception of \"Prick of Conscience\". This comparison should not be taken as evidence of the \"Tales\"' popularity in the century after Chaucer's death, because, according to Derek Pearsall, it is unfair considering that \"Prick of Conscience\" had all the benefit of the \"preservation of a dogmatic religious subject-matter\". Fifty-five of these manuscripts are thought to have been originally complete, while 28 are so fragmentary that it is difficult to ascertain whether they were copied individually or as part of a set. The \"Tales\" vary in both minor and major ways from manuscript to manuscript; many of the minor variations are due to copyists' errors, while it is suggested that in other cases Chaucer both added to his work and revised it as it was being copied and possibly as it was being distributed.\nThere are no manuscripts of the \"Canterbury Tales\" surviving in Chaucer's own hand. The two earliest known manuscripts, which both appear to have been copied by the same scribe, are MS Peniarth 392 D (called \"Hengwrt\"), and the Ellesmere Manuscript, a deluxe, illustrated manuscript. Until the 1940s, scholars tended to prefer the Ellesmere manuscript as closer to Chaucer's intentions; following John M. Manly and Edith Rickert, scholars increasingly favoured Hengwrt. The first version of \"The Canterbury Tales\" to be published in print was William Caxton's 1476 edition. It was one of the first books to be printed by Caxton, the first person in England to print books using a printing press. Only 10 copies of this edition are known to exist, including one held by the British Library and one held by the Folger Shakespeare Library.\nThe copyist of the Hengwrt and Ellesmere manuscripts has been identified as a scrivener named Adam Pinkhurst. Since a poem, apparently by Chaucer, identifies his scribe as a man named \"Adam\", this has led to the hypothesis that the scribe who copied these two important manuscripts worked with Chaucer and knew him personally. This identification has been the subject of much controversy in the field of Middle English palaeography, though it is widely accepted as plausible.\nOrder.\nThere is no consensus as to whether a complete version of the \"Tales\" exists, and also no consensus regarding Chaucer's intended order of the stories. Textual and manuscript clues have been adduced to support the two most popular modern methods of ordering the tales.\nSome scholarly editions divide the \"Tales\" into ten \"Fragments\". The tales that make up a Fragment are closely related and contain internal indications of their order of presentation, usually with one character speaking to and then stepping aside for another character. However, between Fragments, the connection is less obvious. Consequently, there are several possible orders; the one most frequently seen in modern editions follows the numbering of the Fragments (ultimately based on the Ellesmere order).\nIn the Victorian era, it was common to use the nine \"Groups\" identified by F. J. Furnivall (1868) under the auspices of the Chaucer Society (which Furnivall himself had founded). For example, Walter William Skeat followed this ordering in his \"Chaucer: Complete Works\", which was used by Oxford University Press for most of the twentieth century. However, Furnivall's ordering is seldom followed today; the position of its \"Group C\" matches none of the extant manuscripts, its only \"raison d'etre\" being that Furnivall did not consider the three tales in Group D \"sufficient for the 10 miles between Rochester and Sittingbourne.\"\nAn alternative ordering (seen in the early 15th-century manuscript Harley MS. 7334) places Fragment VIII before VI. Fragments I and II almost always follow each other, just as VI and VII, IX and X do in the oldest manuscripts. Fragments IV and V, by contrast, vary in location from manuscript to manuscript.\nLanguage.\nChaucer mainly wrote in a London dialect of late Middle English, which has clear differences from Modern English. From philological research, some facts are known about the pronunciation of English during the time of Chaucer. Chaucer pronounced \"-e\" at the end of many words, so that \"care\" (except when followed by a vowel sound) was , not as in Modern English. Other nowadays silent letters were also pronounced, so that the word \"knight\" was , with both the \"k\" and the \"gh\" pronounced, not . In some cases, vowel letters in Middle English were pronounced very differently from Modern English, because the Great Vowel Shift had not yet happened. For instance, the long \"e\" in \"wepyng\" \"weeping\" was pronounced as , as in modern German or Italian, not as . Below is an IPA transcription of the opening lines of \"The Merchant's Prologue\":\n&lt;templatestyles src=\"Col-begin/styles.css\"/&gt;\nNo manuscript exists in Chaucer's own hand; all extant copies were made by scribes. Because the final \"-e\" sound was lost soon after Chaucer's time, scribes did not accurately copy it, and this gave scholars the impression that Chaucer himself was inconsistent in using it. It has now been established, however, that \"-e\" was an important part of Chaucer's grammar, and helped to distinguish singular adjectives from plural and subjunctive verbs from indicative.\nSources.\nNo other work prior to Chaucer's is known to have set a collection of tales within the framework of pilgrims on a pilgrimage. It is obvious, however, that Chaucer borrowed portions, sometimes very large portions, of his stories from earlier stories, and that his work was influenced by the general state of the literary world in which he lived. Storytelling was the main entertainment in England at the time, and storytelling contests had been around for hundreds of years. In 14th-century England, the English Pui was a group with an appointed leader who would judge the songs of the group. The winner received a crown and, as with the winner of \"The Canterbury Tales\", a free dinner. It was common for pilgrims on a pilgrimage to have a chosen \"master of ceremonies\" to guide them and organise the journey. Harold Bloom suggests that the structure is mostly original, but inspired by the \"pilgrim\" figures of Dante and Virgil in \"The Divine Comedy\". New research suggests that the General Prologue, in which the innkeeper and host Harry Bailey introduces each pilgrim, is a pastiche of the historical Harry Bailey's surviving 1381 poll-tax account of Southwark's inhabitants.\n\"The Canterbury Tales\" contains more parallels to the \"Decameron\", by Giovanni Boccaccio, than any other work. Like the \"Tales\", the \"Decameron\" features a frame tale in which several different narrators tell a series of stories. In the \"Decameron\", the characters have fled to the countryside to escape the Black Death. It ends with an apology by Boccaccio, much like Chaucer's Retraction to the \"Tales\". A quarter of the tales in \"The Canterbury Tales\" parallel a tale in the \"Decameron\", although most of them have closer parallels in other stories. Some scholars thus find it unlikely that Chaucer had a copy of the work on hand, surmising instead that he may have merely read the \"Decameron\" at some point. Chaucer may have read the \"Decameron\" during his first diplomatic mission to Italy in 1372. Chaucer used a wide variety of sources, but some, in particular, were used frequently over several tales, among them the Bible, Classical poetry by Ovid, and the works of contemporary Italian writers Petrarch and Dante. Chaucer was the first author to use the work of these last two. Boethius' \"Consolation of Philosophy\" appears in several tales, as do the works of John Gower, a friend of Chaucer's. Chaucer also seems to have borrowed from numerous religious encyclopaedias and liturgical writings, such as John Bromyard's \"Summa praedicantium\", a preacher's handbook, and Jerome's \"Adversus Jovinianum\". Many scholars say there is a good possibility Chaucer met Petrarch or Boccaccio.\nGenre and structure.\n\"The Canterbury Tales\" is a collection of stories built around a frame tale, a common and already long established genre in this period. Chaucer's \"Tales\" differs from most other story \"collections\" in this genre chiefly in its intense variation. Most story collections focused on a theme, usually a religious one. Even in the \"Decameron\", storytellers are encouraged to stick to the theme decided on for the day. The idea of a pilgrimage to get such a diverse collection of people together for literary purposes was also unprecedented, though \"the association of pilgrims and storytelling was a familiar one\". Introducing a competition among the tales encourages the reader to compare the tales in all their variety, and allows Chaucer to showcase the breadth of his skill in different genres and literary forms.\nWhile the structure of the \"Tales\" is largely linear, with one story following another, it is also much more than that. In the \"General Prologue\", Chaucer describes not the tales to be told, but the people who will tell them, making it clear that structure will depend on the characters rather than a general theme or moral. This idea is reinforced when the Miller interrupts to tell his tale after the Knight has finished his. Having the Knight go first gives one the idea that all will tell their stories by class, with the Monk following the Knight. However, the Miller's interruption makes it clear that this structure will be abandoned in favour of a free and open exchange of stories among all classes present. General themes and points of view arise as the characters tell their tales, which are responded to by other characters in their own tales, sometimes after a long lapse in which the theme has not been addressed.\nLastly, Chaucer does not pay much attention to the progress of the trip, to the time passing as the pilgrims travel, or to specific locations along the way to Canterbury. His writing of the story seems focused primarily on the stories being told, and not on the pilgrimage itself.\nStyle.\nThe variety of Chaucer's tales shows the breadth of his skill and his familiarity with many literary forms, linguistic styles, and rhetorical devices. Medieval schools of rhetoric at the time encouraged such diversity, dividing literature (as Virgil suggests) into high, middle, and low styles as measured by the density of rhetorical forms and vocabulary. Another popular method of division came from St. Augustine, who focused more on audience response and less on subject matter (a Virgilian concern). Augustine divided literature into \"majestic persuades\", \"temperate pleases\", and \"subdued teaches\". Writers were encouraged to write in a way that kept in mind the speaker, subject, audience, purpose, manner, and occasion. Chaucer moves freely between all of these styles, showing favouritism to none. He not only considers the readers of his work as an audience, but the other pilgrims within the story as well, creating a multi-layered rhetoric.\nWith this, Chaucer avoids targeting any specific audience or social class of readers, focusing instead on the characters of the story and writing their tales with a skill proportional to their social status and learning. However, even the lowest characters, such as the Miller, show surprising rhetorical ability, although their subject matter is more lowbrow. Vocabulary also plays an important part, as those of the higher classes refer to a woman as a \"lady\", while the lower classes use the word \"wenche\", with no exceptions. At times the same word will mean entirely different things between classes. The word \"pitee\", for example, is a noble concept to the upper classes, while in the \"Merchant's Tale\" it refers to sexual intercourse. Again, however, tales such as the \"Nun's Priest's Tale\" show surprising skill with words among the lower classes of the group, while the \"Knight's Tale\" is at times extremely simple.\nChaucer uses the same meter throughout almost all of his tales, with the exception of \"Sir Thopas\" and his prose tales. This is a line characterised by five stressed syllables, usually alternating with unstressed syllables to produce lines usually of ten syllables, but often eleven and occasionally nine; occasionally a caesura can be identified around the middle of a line. This metre was probably inspired by French and Italian forms. Chaucer's meter would later develop into the heroic meter of the 15th and 16th centuries sometimes known as riding rhyme, and is an ancestor of iambic pentameter. Chaucer's verse is usually also characterised by couplet rhyme, but he avoided allowing couplets to become too prominent in \"The Canterbury Tales\", and four of the tales (the Man of Law's, Clerk's, Prioress', and Second Nun's) use rhyme royal.\nHistorical context and themes.\nIn 1386, Chaucer became Controller of Customs and Justice of the Peace and, in 1389, Clerk of the King's Works. It was during these years that Chaucer began working on \"The Canterbury Tales\".\nThe end of the fourteenth century was a turbulent time in English history. The Catholic Church was in the midst of the Western Schism and, although it was still the only Christian authority in Western Europe, it was the subject of heavy controversy. Lollardy, an early English religious movement led by John Wycliffe, is mentioned in the \"Tales\", which also mention a specific incident involving pardoners (sellers of indulgences, which were believed to relieve the temporal punishment due for sins that were already forgiven in the Sacrament of Confession) who nefariously claimed to be collecting for St. Mary Rouncesval hospital in England. \"The Canterbury Tales\" is among the first English literary works to mention paper, a relatively new invention that allowed dissemination of the written word never before seen in England. Political clashes, such as the 1381 Peasants' Revolt and clashes ending in the deposing of King Richard II, further reveal the complex turmoil surrounding Chaucer in the time of the \"Tales\"' writing. Many of his close friends were executed and he himself moved to Kent to get away from events in London.\nWhile some readers look to interpret the characters of \"The Canterbury Tales\" as historical figures, other readers choose to interpret its significance in less literal terms. After analysis of Chaucer's diction and historical context, his work appears to develop a critique of society during his lifetime. Within a number of his descriptions, his comments can appear complimentary in nature, but through clever language, the statements are ultimately critical of the pilgrim's actions. It is unclear whether Chaucer would intend for the reader to link his characters with actual persons. Instead, it appears that Chaucer creates fictional characters to be general representations of people in such fields of work. With an understanding of medieval society, one can detect subtle satire at work.\nReligion.\nThe \"Tales\" reflect diverse views of the Church in Chaucer's England. After the Black Death, many Europeans began to question the authority of the established Church. Some turned to Lollardy, while others chose less extreme paths, starting new monastic orders or smaller movements exposing church corruption in the behaviour of the clergy, false church relics or abuse of indulgences. Several characters in the \"Tales\" are religious figures, and the very setting of the pilgrimage to Canterbury is religious (although the prologue comments ironically on its merely seasonal attractions), making religion a significant theme of the work.\nTwo characters, the Pardoner and the Summoner, whose roles apply the Church's secular power, are both portrayed as deeply corrupt, greedy, and abusive. Pardoners in Chaucer's day were those people from whom one bought Church \"indulgences\" for forgiveness of sins, who were guilty of abusing their office for their own gain. Chaucer's Pardoner openly admits the corruption of his practice while hawking his wares. Summoners were Church officers who brought sinners to the Church court for possible excommunication and other penalties. Corrupt summoners would write false citations and frighten people into bribing them to protect their interests. Chaucer's Summoner is portrayed as guilty of the very kinds of sins for which he is threatening to bring others to court, and is hinted as having a corrupt relationship with the Pardoner. In The Friar's Tale, one of the characters is a summoner who is shown to be working on the side of the devil, not God.\nChurchmen of various kinds are represented by the Monk, the Prioress, the Nun's Priest, and the Second Nun. Monastic orders, which originated from a desire to follow an ascetic lifestyle separated from the world, had by Chaucer's time become increasingly entangled in worldly matters. Monasteries frequently controlled huge tracts of land on which they made significant sums of money, while peasants worked in their employ. The Second Nun is an example of what a Nun was expected to be: her tale is about a woman whose chaste example brings people into the church. The Monk and the Prioress, on the other hand, while not as corrupt as the Summoner or Pardoner, fall far short of the ideal for their orders. Both are expensively dressed, show signs of lives of luxury and flirtatiousness and show a lack of spiritual depth. The Prioress's Tale is an account of Jews murdering a deeply pious and innocent Christian boy, a blood libel against Jews that became a part of English literary tradition. The story did not originate in the works of Chaucer and was well known in the 14th century.\nPilgrimage was a very prominent feature of medieval society. The ultimate pilgrimage destination was Jerusalem, but within England Canterbury was a popular destination. Pilgrims would journey to cathedrals that preserved relics of saints, believing that such relics held miraculous powers. Saint Thomas Becket, Archbishop of Canterbury, had been murdered in Canterbury Cathedral by knights of Henry II during a disagreement between Church and Crown. Miracle stories connected to his remains sprang up soon after his death, and the cathedral became a popular pilgrimage destination. The pilgrimage in the work ties all of the stories together and may be considered a representation of Christians' striving for heaven, despite weaknesses, disagreement, and diversity of opinion.\nSocial class and convention.\nThe upper class or nobility, represented chiefly by the Knight and his Squire, was in Chaucer's time steeped in a culture of chivalry and courtliness. Nobles were expected to be powerful warriors who could be ruthless on the battlefield yet mannerly in the King's Court and Christian in their actions. Knights were expected to form a strong social bond with the men who fought alongside them, but an even stronger bond with a woman whom they idealised to strengthen their fighting ability. Though the aim of chivalry was to noble action, its conflicting values often degenerated into violence. Church leaders frequently tried to place restrictions on jousts and tournaments, which at times ended in the death of the loser. The Knight's Tale shows how the brotherly love of two fellow knights turns into a deadly feud at the sight of a woman whom both idealise. To win her, both are willing to fight to the death. Chivalry was on the decline in Chaucer's day, and it is possible that The Knight's Tale was intended to show its flaws, although this is disputed. Chaucer himself had fought in the Hundred Years' War under Edward III, who heavily emphasised chivalry during his reign. Two tales, \"Sir Topas\" and \"The Tale of Melibee\", are told by Chaucer himself, who is travelling with the pilgrims in his own story. Both tales seem to focus on the ill-effects of chivalry\u2014the first making fun of chivalric rules and the second warning against violence.\nThe \"Tales\" constantly reflect the conflict between classes. For example, the division of the three estates: the characters are all divided into three distinct classes, the classes being \"those who pray\" (the clergy), \"those who fight\" (the nobility), and \"those who work\" (the commoners and peasantry). Most of the tales are interlinked by common themes, and some \"quit\" (reply to or retaliate against) other tales. Convention is followed when the Knight begins the game with a tale, as he represents the highest social class in the group. But when he is followed by the Miller, who represents a lower class, it sets the stage for the \"Tales\" to reflect both a respect for and a disregard for upper class rules. Helen Cooper, as well as Mikhail Bakhtin and Derek Brewer, call this opposition \"the ordered and the grotesque, Lent and Carnival, officially approved culture and its riotous, and high-spirited underside.\" Several works of the time contained the same opposition.\nRelativism versus realism.\nChaucer's characters each express different\u2014sometimes vastly different\u2014views of reality, creating an atmosphere of testing, empathy, and relativism. As Helen Cooper says, \"Different genres give different readings of the world: the fabliau scarcely notices the operations of God, the saint's life focuses on those at the expense of physical reality, tracts and sermons insist on prudential or orthodox morality, romances privilege human emotion.\" The sheer number of varying persons and stories renders the \"Tales\" as a set unable to arrive at any definite truth or reality.\nLiminality.\nThe concept of liminality figures prominently within \"The Canterbury Tales\". A liminal space, which can be both geographical as well as metaphorical or spiritual, is the transitional or transformational space between a \"real\" (secure, known, limited) world and an unknown or imaginary space of both risk and possibility. The notion of a pilgrimage is itself a liminal experience, because it centres on travel between destinations and because pilgrims undertake it hoping to become more holy in the process. Thus, the structure of \"The Canterbury Tales\" itself is liminal; it not only covers the distance between London and Canterbury, but the majority of the tales refer to places entirely outside the geography of the pilgrimage. Jean Jost summarises the function of liminality in \"The Canterbury Tales\",\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Both appropriately and ironically in this raucous and subversive liminal space, a ragtag assembly gather together and tell their equally unconventional tales. In this unruly place, the rules of tale telling are established, themselves to be both disordered and broken; here the tales of game and earnest, solas and sentence, will be set and interrupted. Here the sacred and profane adventure begins, but does not end. Here, the condition of peril is as prominent as that of protection. The act of pilgrimaging itself consists of moving from one urban space, through liminal rural space, to the next urban space with an ever fluctuating series of events and narratives punctuating those spaces. The goal of pilgrimage may well be a religious or spiritual space at its conclusion, and reflect a psychological progression of the spirit, in yet another kind of emotional space.\nLiminality is also evident in the individual tales. An obvious instance of this is The Friar's Tale in which the yeoman devil is a liminal figure because of his transitory nature and function; it is his purpose to issue souls from their current existence to hell, an entirely different one. The Franklin's Tale is a Breton Lai tale, which takes the tale into a liminal space by invoking not only the interaction of the supernatural and the mortal, but also the relation between the present and the imagined past.\nReception.\nWhile Chaucer clearly states the addressees of many of his poems (the \"Book of the Duchess\" is believed to have been written for John of Gaunt on the occasion of his wife's death in 1368), the intended audience of \"The Canterbury Tales\" is more difficult to determine. Chaucer was a courtier, leading some to believe that he was mainly a court poet who wrote exclusively for the nobility. He is referred to as a noble translator and poet by Eustache Deschamps and by his contemporary John Gower. It has been suggested that the poem was intended to be read aloud, which is probable as this was a common activity at the time. However, it also seems to have been intended for private reading, since Chaucer frequently refers to himself as the writer, rather than the speaker, of the work. Determining the intended audience directly from the text is even more difficult, since the audience is part of the story. This makes it difficult to tell when Chaucer is writing to the fictional pilgrim audience or the actual reader.\nChaucer's works may have been distributed in some form during his lifetime in part or in whole. Scholars speculate that manuscripts were circulated among his friends, but likely remained unknown to most people until after his death. However, the speed with which copyists strove to write complete versions of his tale in manuscript form shows that Chaucer was a famous and respected poet in his own day. The Hengwrt and Ellesmere manuscripts are examples of the care taken to distribute the work. More manuscript copies of the poem exist than for any other poem of its day except \"The Prick of Conscience\", causing some scholars to give it the medieval equivalent of bestseller status. Even the most elegant of the illustrated manuscripts, however, is not nearly as highly decorated as the work of authors of more respectable works such as John Lydgate's religious and historical literature.\n15th century.\nJohn Lydgate and Thomas Occleve were among the first critics of Chaucer's \"Tales\", praising the poet as the greatest English poet of all time and the first to show what the language was truly capable of poetically. This sentiment was universally agreed upon by later critics into the mid-15th century. Glosses included in \"The Canterbury Tales\" manuscripts of the time praised him highly for his skill with \"sentence\" and rhetoric, the two pillars by which medieval critics judged poetry. The most respected of the tales was at this time the Knight's, as it was full of both.\nLiterary additions and supplements.\n \"Canterbury Tales\", William Caxton edition\nThe incompleteness of the \"Tales\" led several medieval authors to write additions and supplements to the tales to make them more complete. Some of the oldest existing manuscripts of the tales include new or modified tales, showing that even early on, such additions were being created. These emendations included various expansions of the \"Cook's Tale\", which Chaucer never finished, \"The Plowman's Tale\", \"The Tale of Gamelyn\", the \"Siege of Thebes\", and the \"Tale of Beryn\".\nThe \"Tale of Beryn\", written by an anonymous author in the 15th century, is preceded by a lengthy prologue in which the pilgrims arrive at Canterbury and their activities there are described. While the rest of the pilgrims disperse throughout the town, the Pardoner seeks the affections of Kate the barmaid, but faces problems dealing with the man in her life and the innkeeper Harry Bailey. As the pilgrims turn back home, the Merchant restarts the storytelling with \"Tale of Beryn\". In this tale, a young man named Beryn travels from Rome to Egypt to seek his fortune only to be cheated by other businessmen there. He is then aided by a local man in getting his revenge. The tale comes from the French tale \"B\u00e9rinus\" and exists in a single early manuscript of the tales, although it was printed along with the tales in a 1721 edition by John Urry.\nJohn Lydgate wrote \"The Siege of Thebes\" in about 1420. Like the \"Tale of Beryn\", it is preceded by a prologue in which the pilgrims arrive in Canterbury. Lydgate places himself among the pilgrims as one of them and describes how he was a part of Chaucer's trip and heard the stories. He characterises himself as a monk and tells a long story about the history of Thebes before the events of the \"Knight's Tale\". John Lydgate's tale was popular early on and exists in old manuscripts both on its own and as part of the \"Tales\". It was first printed as early as 1561 by John Stow, and several editions for centuries after followed suit.\nThere are actually two versions of \"The Plowman's Tale\", both of which are influenced by the story \"Piers Plowman\", a work written during Chaucer's lifetime. Chaucer describes a Plowman in the \"General Prologue\" of his tales, but never gives him his own tale. One tale, written by Thomas Occleve, describes the miracle of the Virgin and the Sleeveless Garment. Another tale features a pelican and a griffin debating church corruption, with the pelican taking a position of protest akin to John Wycliffe's ideas.\n\"The Tale of Gamelyn\" was included in an early manuscript version of the tales, Harley 7334, which is notorious for being one of the lower-quality early manuscripts in terms of editor error and alteration. It is now widely rejected by scholars as an authentic Chaucerian tale, although some scholars think he may have intended to rewrite the story as a tale for the Yeoman. Dates for its authorship vary from 1340 to 1370.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nExternal links.\nGeneral\nOnline texts\nFacsimiles"}
{"id": "7628", "revid": "11096", "url": "https://en.wikipedia.org/wiki?curid=7628", "title": "Christine de Pizan", "text": "Italian-born French author (1364 \u2013 c. 1430)\nChristine de Pizan or Pisan (, ; born Cristina da Pizzano; September 1364 \u2013 c.\u20091430), was an Italian-born French court writer for King Charles VI of France and several French royal dukes, in both prose and poetry.\nChristine de Pizan served as a court writer in medieval France after the death of her husband. Christine's patrons included dukes Louis I of Orleans, Philip the Bold of Burgundy, and his son John the Fearless. Considered to be some of the earliest feminist writings, her work includes novels, poetry, and biography, and she also penned literary, historical, philosophical, political, and religious reviews and analyses. Her best known works are \"The Book of the City of Ladies\" and \"The Treasure of the City of Ladies\", both prose works written when she worked for John the Fearless of Burgundy. Her books of advice to princesses, princes, and knights remained in print until the 16th century.\nLife.\nEarly life and family (1364\u20131389).\nChristine de Pizan was born in 1364 in the Republic of Venice, Italy. She was the daughter of Tommaso di Benvenuto da Pizzano. Her father became known as Thomas de Pizan, named for the family's origins in the village of Pizzano (currently part of the municipality of Monterenzio), southeast of Bologna. Her father worked as a physician, court astrologer and Councillor of the Republic of Venice. Thomas de Pizan accepted an appointment to the court of Charles V of France as the king's astrologer and in 1368 Christine moved to Paris. In 1379 Christine de Pizan married the notary and royal secretary Etienne du Castel.\nShe had three children. Her daughter became a nun at the Dominican convent of Poissy in 1397 as a companion to the King's daughter Marie. Christine's husband died of the plague in 1389, a year after her father had died. On 4 June 1389, in a judgment concerning a lawsuit filed against her by the archbishop of Sens and Fran\u00e7ois Chanteprime, councillors of the King, Christine was called \"damoiselle\" and \"widow of Estienne du Castel\".\nWriting career (1389\u20131405).\nAfter her husband Etienne died, Christine was left to support her mother and her children. When she tried to collect money from her husband's estate, she faced complicated lawsuits regarding the recovery of salaries still owed to her husband. Through this, Christine became a court writer. By 1393, she was writing love ballads, which caught the attention of wealthy patrons within the court. Christine became a prolific writer. Her involvement in the production of her books and her skillful use of patronage in turbulent political times has earned her the title of the first professional woman of letters in Europe.\nAlthough Venetian by birth, Christine expressed a fervent nationalism for France. Affectively and financially she became attached to the French royal family, donating or dedicating her early ballads to its members, including Isabeau of Bavaria, Louis I, Duke of Orl\u00e9ans, and Marie of Berry. Patronage changed in the late Middle Ages. Texts were still produced and circulated as continuous roll manuscripts, but were increasingly replaced by the bound codex. Members of the royal family became patrons of writers by commissioning books. As materials became cheaper a book trade developed, so writers and bookmakers produced books for the French nobility, who could afford to establish their own libraries. Christine thus had no single patron who consistently supported her financially and became associated with the royal court and the different factions of the royal family \u2013 the Burgundy, Orleans and Berry \u2013 each having their own respective courts. Throughout her career Christine undertook concurrent paid projects for individual patrons and subsequently published these works for dissemination among the nobility of France.\nFrance was ruled by Charles VI who since 1392 experienced a series of mental breakdowns, causing a crisis of leadership for the French monarchy. He was often absent from court and could eventually only make decisions with the approval of a royal council. Queen Isabeau was nominally in charge of governance when her husband was absent from court but could not extinguish the quarrel between members of the royal family. In the past, Blanche of Castile had played a central role in the stability of the royal court and had acted as regent of France. Christine published a series of works on the virtues of women, referencing Queen Blanche and dedicating them to Queen Isabeau. In 1402 she described Queen Isabeau as \"High, excellent crowned Queen of France, very redoubtable princess, powerful lady, born at a lucky hour\".\nChristine believed that France had been founded by the descendants of the Trojans and that its governance by the royal family adhered to the Aristotelian ideal. In 1400 Christine published \"L'\u00c9pistre de Oth\u00e9a a Hector\" (\"Letter of Othea to Hector\"). When first published, the book was dedicated to Louis of Orl\u00e9ans, the brother of Charles VI, who was at court seen as potential regent of France. In \"L'\u00c9pistre de Oth\u00e9a a Hector\" Hector of Troy is tutored in statecraft and the political virtues by the goddess of wisdom Oth\u00e9a. Christine produced richly illustrated luxury editions of \"L'\u00c9pistre de Oth\u00e9a a Hector\" in 1400. Between 1408 and 1415 Christine produced further editions of the book. Throughout her career she produced rededicated editions of the book with customised prologues for patrons, including an edition for Philip the Bold in 1403, and editions for Jean of Berry and Henry IV of England in 1404.\nIn 1402, Christine became involved in a renowned literary controversy, the \"Querelle du Roman de la Rose\". Christine questioned the literary merits of Jean de Meun's popular \"Romance of the Rose\", which satirizes the conventions of courtly love while critically depicting women as nothing more than seducers. In the midst of the Hundred Years' War between French and English kings, Christine wrote the dream allegory \"Le Chemin de long estude\" in 1403. Writing in the first-person, she and the Cumaean Sibyl travel together and witness a debate on the state of the world between the four allegories \u2013 Wealth, Nobility, Chivalry and Wisdom. Christine suggests that justice could be brought to earth by a single monarch who had the necessary qualities.\nIn 1404, Christine chronicled the life of Charles V, portraying him as the ideal king and political leader, in \"Le Livre des fais et bonnes meurs du sage roy Charles V\". The chronicle had been commissioned by Philip the Bold of Burgundy and in the chronicle, Christine passed judgment on the state of the royal court. When praising the efforts of Charles V in studying Latin, Christine lamented that her contemporaries had to resort to strangers to read the law to them. Before the book was completed, Philip the Bold died, and Christine offered the book to Jean, Duke of Berry in 1405 in an attempt to find a new patron. She was paid 100 livres for the book by Philip the Bold's successor John the Fearless in 1406 and would receive payments from his court for books until 1412.\nIn 1405, Christine published \"Le Livre de la cit\u00e9 des dames\" (\"The Book of the City of Ladies\") and \"Le Livre des trois vertus\" (\"Book of Three Virtues\", known as \"The Treasure of the City of Ladies\"). In \"Le Livre de la cit\u00e9 des dames\" Christine presented intellectual and royal female leaders, such as Queen Zenobia. Christine dedicated \"Le Livre des trois vertus\" to the dauphine Margaret of Nevers, advising the young princess on what she had to learn. As Queen Isabeau's oldest son Louis of Guyenne came of age Christine addressed three works to him with the intention of promoting wise and effective government. The earliest of the three works has been lost. In \"Livre du Corps de policie\" (\"The Book of the Body Politic\"), published in 1407 and dedicated to the dauphin, Christine set out a political treatise which analysed and described the customs and governments of late medieval European societies. Christine favoured hereditary monarchies, arguing in reference to Italian city-states that were governed by princes or trade guilds, that \"such governance is not profitable at all for the common good\". Christine also devoted several chapters to the duties of a king as a military leader and she described in detail the role of the military class in society.\nCivil war (1405\u20131430).\nIn the beginning of 1405, France was on the verge of a full-scale civil war. In 1407 John I of Burgundy, also known as John the Fearless, plunged France into a crisis when he ordered the assassination of Louis of Orl\u00e9ans. The Duke of Burgundy fled Paris when his complicity in the assassination became known, but was appointed regent of France on behalf of Charles VI in late 1408 after his military victory in the Battle of Othee. It is not certain who commissioned Christine to write a treatise on military warfare, but in 1410 Christine published the manual on chivalry, entitled \"Livre des fais d'armes et de chevalerie\" (\"The Book of Feats of Arms and of Chivalry\"). In early 1411, Christine was paid 200 livres from the royal reasury for the book. In the preface Christine explained that she published the manual in French so that it could be read by practitioners of war not well versed in Latin. The book opened with a discussion of the just war theory advanced by Honor\u00e9 Bonet. Christine also referenced classical writers on military warfare, such as Vegetius, Frontinus and Valerius Maximus. Christine discussed contemporary matters relating to what she termed the \"Laws of War\", such as capital punishment, the payment of troops, as well as the treatment of noncombatants and prisoners of war. Christine opposed trial by combat, but articulated the medieval belief that God is the lord and governor of battle and that wars are the proper execution of justice. Nevertheless, she acknowledged that in a war \"many great wrongs, extortions, and grievous deeds are committed, as well as raping, killings, forced executions, and arsons\". Christine limited the right to wage war to sovereign kings because as head of states they were responsible for the welfare of their subjects. In 1411 the royal court published an edict prohibiting nobles from raising an army.\nAfter civil war had broken out in France, Christine in 1413 offered guidance to the young dauphin on how to govern well, publishing \"Livre de la paix\" (\"The Book of Peace\"). \"Livre de la paix\" was to be Christine's last major work and contained detailed formulations of her thoughts on good governance. The period was marked by bouts of civil war and failed attempts to bring John the Fearless to justice for assassinating his cousin. Christine addressed Louis of Guyenne directly, encouraging him to continue the quest for peace in France. She argued that \"Every kingdom divided in itself will be made desolate, and every city and house divided against itself will not stand\". Christine was acquainted with William of Tignonville, an ambassador to the royal court, and referenced Tignonville's speeches on the Armagnac\u2013Burgundian Civil War. Christine drew a utopian vision of a just ruler, who could take advice from those older or wiser. In arguing that peace and justice were possible on earth as well as in heaven, Christine was influenced by Dante, whom she had referenced in \"Le Chemin de long estude\". Christine encouraged the dauphin to deserve respect, by administering justice promptly and living by worthy example. Christine urged young princes to make themselves available to their subjects, avoid anger and cruelty, to act liberally, mercifully and truthfully. Christine's interpretation of the virtuous Christian prince built on the advice to rulers by St Benedict, Peter Abelard and Cicero.\nIn 1414, Christine presented Queen Isabeau with a lavishly decorated collection of her works (now known as \"British Library Harley 4431\"). The bound book contained 30 of Christine's writings and 130 miniatures. She had been asked by the queen to produce the book. The work is noted for its quality miniature illuminations; Christine herself and her past royal patrons are depicted. As a mark of ownership and authorship the opening frontispiece depicts Queen Isabeau being presented with the book by Christine.\nIn 1418, Christine published a consolation for women who had lost family members in the Battle of Agincourt under the title \"Epistre de la prison de vie Humaine\" (\"Letter Concerning the Prison of Human Life\"). In it, Christine did not express any optimism or hope that peace could be found on earth; instead, she expressed the view that the soul was trapped in the body and imprisoned in hell. The previous year she had presented the \"Epistre de la prison de vie Humaine\" to Marie of Berry, the administrator of the Duchy of Bourbon whose husband was held in English captivity.\nHistorians assume that Christine spent the last ten years of her life in the Dominican convent of Poissy because of the civil war and the occupation of Paris by the English. Away from the royal court her literary activity ceased. However, in 1429, after Joan of Arc's military victory over the English, Christine published the poem \"Diti\u00e9 de Jehanne d'Arc\" (\"The Tale of Joan of Arc\"). Published just a few days after the coronation of Charles VII, Christine expressed renewed optimism. She cast Joan as the fulfilment of prophecies by Merlin, the Cumaean Sibyl and Saint Bede, helping Charles VII to fulfill the predictions of Charlemagne.\nChristine is believed to have died in 1430, before Joan was tried and executed by the English. After her death the political crisis in France was resolved when Queen Isabeau's only surviving son Charles VII and John the Fearless' successor as Duke of Burgundy, Philip the Good, signed the Peace of Arras in 1435.\nWorks.\nChristine produced a large number of vernacular works, in both prose and verse. Her works include political treatises, mirrors for princes, epistles, and poetry. Christine's book \"Le Dit de la Rose\" (\"The Tale of the Rose\") was published in 1402 as a direct attack on Jean de Meun's extremely popular book \"Romance of the Rose\" which was a continuation of the version by Guillaume de Lorris and characterised women as seducers. Christine claimed that Meun's views were misogynistic, vulgar, immoral, and slanderous to women. Christine sparked a debate over the literary merits of the work when she confronted the royal secretary, Jean de Montreuil, who had written a short treatise praising the work. The debate continued between Christine and two other male royal secretaries who defended Jean in a heated exchange. At the height of the exchange Christine published \"Querelle du Roman de la Rose\" (\"Letters on the Debate of the Rose\"). In this particular apologetic response, Christine belittles her own writing style, employing a rhetorical strategy by writing against the grain of her meaning, also known as antiphrasis.\nBy 1405, Christine had completed her most famous literary works, \"The Book of the City of Ladies\" (\"Le Livre de la cit\u00e9 des dames\") and \"The Treasure of the City of Ladies\" (\"Le Livre des trois vertus\"). The first of these shows the importance of women's past contributions to society, and the second strives to teach women of all estates how to cultivate useful qualities.\nIn \"The Book of the City of Ladies\" Christine created a symbolic city in which women are appreciated and defended. She constructed three allegorical figures \u2013 Reason, Justice, and Rectitude \u2013 in the common pattern of literature in that era when many books and poetry used stock allegorical figures to express ideas or emotions. She enters into a dialogue, a movement between question and answer, with these allegorical figures that is from a completely female perspective. Together, they create a forum to speak on issues of consequence to all women. Only female voices, examples and opinions provide evidence within this text. Through Lady Reason in particular Christine argues that stereotypes of women can be sustained only if women are prevented from entering into the conversation.\nIn \"City of Ladies\" Christine deliberated on the debate of whether the virtues of men and women differ, a frequently debated topic in late medieval Europe, particularly in the context of Aristotelian virtue ethics and his views on women. Christine repeatedly used the theological argument that men and women are created in God's image and both have souls capable of embracing God's goodness. Among the inhabitants of the \"City of Ladies\" are female saints, women from the Old Testament and virtuous women from the pagan antiquity as portrayed by Giovanni Boccaccio. Within her allegorical city of illustrious ladies, she reimagines the mythological figure, Medusa. Christine de Pizan's Medusa, in stark contrast to the typical portrayal in classical texts, is not a monstrous and deadly creature, but a woman deserving of safety from male harm. De Pizan is the first to provide a feminist revisionist perspective of the ancient myth.\nIn \"The Treasure of the City of Ladies\" Christine addressed the \"community\" of women with the stated objective of instructing them on the means of achieving virtue. She took the position that all women were capable of humility, diligence and moral rectitude, and that duly educated women could become worthy residents of the imaginary \"City of Ladies\". Drawing on her own life, Christine advised women on how to navigate the perils of early 15th-century French society. She was a strong advocate of education for women, having said \"If it were customary to send little girls to school and to teach them the same subjects as are taught boys, they would learn just as fully and would understand the subtleties of all arts and sciences\". With reference to Augustine of Hippo and other saints Christine offered advice on how the noble lady could achieve the love of God. Christine speaks through the allegorical figures of God's daughters \u2013 Reason, Rectitude and Justice \u2013 who represent the Three Virtues most important to women's success. Through secular examples of these three virtues, Christine urged women to discover meaning and achieve worthy acts in their lives. Christine argued that women's success depends on their ability to manage and mediate by speaking and writing effectively.\nChristine specifically sought out other women to collaborate in the creation of her work. She makes special mention of a manuscript illustrator we know only as Anastasia, whom she described as the most talented of her day.\nLegacy.\nEarly French influence.\nChristine published 41 known pieces of poetry and prose in her lifetime and she gained fame across Europe as the first professional woman writer. She achieved such credibility that royalty commissioned her prose and contemporary intellectuals kept copies of her works in their libraries.\nAfter her death in 1430, Christine's influence was acknowledged by a variety of authors and her writings remained popular. While de Pizan's mixture of classical philosophy and humanistic ideals was in line with the style of other popular authors at the time, her outspoken defence of women was an anomaly. In her works she vindicated women against popular misogynist texts, such as Ovid's \"Art of Love\", Jean de Meun's \"Romance of the Rose\" and Matheolus's \"Lamentations\". Her book \"Le Livre de la cit\u00e9 des dames\" remained in print. Christine's \"Le Livre des trois vertus\" (\"The Treasure of the City of Ladies\") became an important reference point for royal women in the 15th and 16th centuries; French editions were still being printed in 1536. Anne of France, who acted as regent of France, used it as a basis for her 1504 book of \"Enseignemens\", written for her daughter Suzanne Duchess of Bourbon, who as agnatic heir to the Bourbon lands became co-regent. Christine's advice to princesses was translated and circulated as manuscripts or printed books among the royal families of France and Portugal. The \"City of Ladies\" was acknowledged and referenced by 16th century French women writers, including Anne de Beaujeu, Gabrielle de Bourbon, Marguerite de Navarre and Georgette de Montenay.\nChristine's political writings received some attention too. \"Livre de la paix\" was referenced by the humanist Gabriel Naud\u00e9 and Christine was given large entries in encyclopedias by Denis Diderot, Louis Mor\u00e9ri and Prosper Marchand. In 1470 Jean V de Bueil reproduced Christine's detailed accounts of the armies and material needed to defend a castle or town against a siege in \"Le Jouvence\". \"Livre des fais d'armes et de chevalerie\" was published in its entirety by the book printer Antoine V\u00e9rard in 1488, but V\u00e9rard claimed that it was his translation of Vegetius. Philippe Le Noir authored an abridged version of Christine's book in 1527 under the title \"L'Arbre des Batailles et fleur de chevalerie\" (\"The tree of battles and flower of chivalry\").\nOutside France.\nA Dutch edition of \"Le Livre de la cit\u00e9 des dames\" exists from the 15th century. In 1521 \"The Book of the City of Ladies\" was published in English. \"Livre des fais d'armes et de chevalerie\" was translated into English by William Caxton for Henry VII in 1489 and was published under the title \"The Book of Feats of Arms and of Chivalry\" as print one year later, attributing Christine as author. English editions of \"The Book of the City of Ladies\" and \"Livre du corps de policie\" (\"The Book of the Body Politic\") were printed in 1521 without referencing Christine as the author. Elizabeth I had in her court library copies of \"The Book of the City of Ladies\", \"L'\u00c9pistre de Oth\u00e9a a Hector\" (\"Letter of Othea to Hector\") and \"The Book of Feats of Arms and of Chivalry\". Among the possessions of the English queen were tapestries with scenes from the \"City of Ladies\".\n19th to 21st centuries.\nIn the early 19th century Raimond Thomassy published an overview of Christine's political writings and noted that modern editions of these writings were not published and that as a political theorist Christine was descending into obscurity. Similarly, Mathilde Laigle and Marie-Josephe Pinet are credited with reviving the work of de Pizan in the early 20th century, as a writer who had been forgotten in France but noted elsewhere. Laigle noticed for instance that Spanish writers had borrowed extensively from de Pizan's work, even though it had not been translated into that language.\nHer activism has also drawn the fascination of modern feminists. Simone de Beauvoir wrote in 1949 that \"\u00c9p\u00eetre au Dieu d'Amour\" was \"the first time we see a woman take up her pen in defence of her sex\". Beginning in the 1950s, scholarly work by Suzanne Solente further bolstered Christine's reputation.\nJudy Chicago's 1979 artwork \"The Dinner Party\" features a place setting for Christine de Pizan. In the 1980s Sandra Hindman published a study of the political events referenced in the illuminations of Christine's published works. In recent decades, Christine's work has continued to grow in reputation by the efforts of scholars such as Charity Cannon Willard and Earl Jeffrey Richards.\nIn the opening ceremony of the 2024 Summer Olympics in Paris, Christine was one of the 10 pioneering female contributors to French history honoured by gold-coloured statues which rose from giant pedestals along the river Seine.\nNotes.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "7630", "revid": "50596675", "url": "https://en.wikipedia.org/wiki?curid=7630", "title": "Catharism", "text": "Medieval southern European Christian dualist movement\nCatharism ( ; from the , \"the pure ones\") was a Christian quasi-dualist and pseudo-Gnostic movement which thrived in northern Italy and southern France between the 12th and 14th centuries.\nDenounced as a heretical sect by the Catholic Church, its followers were attacked first by the Albigensian Crusade and later by the Medieval Inquisition, which eradicated them by 1350. Thousands were slaughtered, hanged, or burned at the stake.\nFollowers were known as Cathars or Albigensians, after the French city Albi where the movement first took hold, but referred to themselves as Good Christians. They believed that there were not one, but two Gods\u2014the good God of Heaven and the evil god of this age (). According to tradition, Cathars believed that the good God was the God of the New Testament faith and creator of the spiritual realm. Many Cathars identified the evil god as Satan, the master of the physical world, who was the same as the God of the Old Testament. The Cathars believed that human souls were the sexless spirits of angels trapped in the material realm of the evil god. They thought these souls were destined to be reincarnated until they achieved salvation through the \"consolamentum\", a form of baptism performed when death is imminent. At that moment, they believed they would return to the good God as \"Cathar Perfect\". Catharism was initially taught by ascetic leaders who set few guidelines, leading some Catharist practices and beliefs to vary by region and over time.\nThe first mention of Catharism by chroniclers was in 1143; four years later, the Catholic Church denounced Cathar practices, particularly the \"consolamentum\" ritual. From the beginning of his reign, Pope Innocent III attempted to end Catharism by sending missionaries and persuading the local authorities to act against the Cathars. In 1208, Pierre de Castelnau, Innocent's papal legate, was murdered while returning to Rome after excommunicating Count Raymond VI of Toulouse, who, in his view, was too lenient with the Cathars. Pope Innocent III then declared de Castelnau a martyr and launched the Albigensian Crusade in 1209. The nearly twenty-year campaign succeeded in vastly weakening the movement. The Medieval Inquisition that followed ultimately eradicated Catharism.\nThere is academic controversy about whether Catharism was an organized religion or whether the medieval Church imagined or exaggerated it. The lack of any central organisation among Cathars and regional differences in beliefs and practices has prompted some scholars to question whether the Church exaggerated its threat while others wonder whether it even existed.\nTerm.\nThough the term \"Cathar\" () has been used for centuries to identify the movement; whether it identified itself with the name is debated. In Cathar texts, the terms \"Good Men\" (), \"Good Women\" (), or \"Good Christians\" () are the common terms of self-identification.\nIn the testimony of suspects who were put to the question by the Inquisition, the term 'Cathar' was not used amongst the group of accused heretics themselves. The word 'Cathar' (aka. Gazarri etc.) was coined by Catholic theologians and used exclusively by the inquisition or by authors otherwise identified with the Orthodox church\u2014for example in the anonymous pamphlet of 1430, \"Errores Gazariorum\" (Re: \"Errors of the Cathars\"). The full title of this treatise in English is, \"The errors of the Gazarri, or of those who travel riding a broom or a stick.\"\nHowever, the presence of a variety of beliefs and spiritual practices in the French countryside of the 12th and 13th centuries that came to be seen as heterodox relative to the Church in Rome is not actually in question, as the primary documents of the period exhaustively demonstrate.\nSeveral of these groups under other names, such as the Waldensians or Valdeis, bear a close similarity to the 'creed' or matrix of beliefs and folk-traditions pieced together under the umbrella of the term 'Catharism.' The fact that there was clearly a spiritual and communal movement of some sort can scarcely be denied, since legions of people were willing to part with their lives to defend it. Whether they acted in defense of the doctrine or in defense of the human community who held these beliefs, the fact that many gave themselves up willingly to the flames when the option to recant was given to them in many or most cases is significant.\nAs the scholar Claire Taylor puts it, in arguing against Pegg and Moore, two scholars questioning whether or not the Cathars exist, this issue matters at an ethical level, because by being cleverly iconoclastic and populist in suggesting that those using 'Cathar' have made 2+2=5, Pegg and Moore make 2+2=3 by denying the existence of the persecuted group. The missing element is a dissident religious doctrine, for which historians using a fuller range of sources believe thousands of people were prepared to suffer extreme persecution and an agonising death.\"\nOrigins.\nThe origins of the Cathars' beliefs are unclear, but most theories agree they came from the Byzantine Empire, mostly by the trade routes, and spread from the First Bulgarian Empire to the Netherlands. The movement was greatly influenced by the Bogomils of the First Bulgarian Empire, and may have originated in the Byzantine Empire, namely through adherents of the Paulician movement in Armenia and eastern Anatolia who were resettled in Thrace (Philippopolis).\nThe name of Bulgarians () was also applied to the Albigensians, and they maintained an association with the similar Christian movement of the Bogomils (\"Friends of God\") of Thrace. \"That there was a substantial transmission of ritual and ideas from Bogomilism to Catharism is beyond reasonable doubt.\" Their doctrines have numerous resemblances to those of the Bogomils and the Paulicians, who influenced them, as well as the earlier Marcianists, who were found in the same areas as the Paulicians, the Manicheans and the Christian Gnostics of the first few centuries AD, although, as many scholars, most notably Mark Pegg, have pointed out, it would be erroneous to extrapolate direct, historical connections based on theoretical similarities perceived by modern scholars.\nThe writings of the Cathars were mostly destroyed because of the doctrine's threat perceived by the Papacy; thus, the historical record of the Cathars is derived primarily from their opponents. Cathar ideology continues to be debated, with commentators regularly accusing opposing perspectives of speculation, distortion and bias. Only a few texts of the Cathars remain, as preserved by their opponents (such as the ) which give a glimpse into the ideologies of their faith. One large text has survived, \"The Book of Two Principles\" (), which elaborates the principles of dualistic theology from the point of view of some Albanenses Cathars.\nIt is now generally agreed by most scholars that identifiable historical Catharism did not emerge until at least 1143, when the first confirmed report of a group espousing similar beliefs is reported being active at Cologne by the cleric Eberwin of Steinfeld. A landmark in the \"institutional history\" of the Cathars was the Council, held in 1167 at Saint-F\u00e9lix-Lauragais, attended by many local figures and also by the Bogomil \"papa\" Nicetas, the Cathar bishop of (northern) France and a leader of the Cathars of Lombardy.\nThe Cathars were a largely local, Western European/Latin Christian phenomenon, springing up in the Rhineland cities, particularly Cologne, in the mid-12th century, northern France around the same time, and particularly the Languedoc\u2014and the northern Italian cities in the mid-late 12th century. In the Languedoc and northern Italy, the Cathars attained their greatest popularity, surviving in the Languedoc, in much reduced form, up to around 1325 and in the Italian cities until the Inquisitions of the 14th century extirpated them.\nCatharism is generally believed to be a syncretic form of Zoroastrianism and Gnosticism and the heir to Manichaeism.\nBeliefs.\nCosmology.\nGnostic cosmology identified two creator deities. The first was the creator of the spiritual realm contained in the New Testament, while the second was the demiurge depicted in the Old Testament who created the physical universe. The demiurge was often called (\"King of the World\").\nSome gnostic belief systems including Catharism began to characterise the duality of creation as a relationship between hostile opposing forces of good and evil. Although the demiurge was sometimes conflated with Satan or considered Satan's father, creator or seducer, these beliefs were far from unanimous. Some Cathar communities believed in a mitigated dualism similar to their Bogomil predecessors, stating that the evil god Satan had previously been the true God's servant before rebelling against him. Others, likely a majority over time given the influence reflected on the \"Book of the Two Principles\", believed in an absolute dualism, where the two gods were twin entities of the same power and importance.\nAll visible matter, including the human body, was created or crafted by this ; matter was therefore tainted with sin. Under this view, humans were actually angels seduced by Satan before a war in heaven against the army of Michael, after which they would have been forced to spend an eternity trapped in the evil God's material realm. The Cathars taught that to regain angelic status one had to renounce the material self completely. Until one was prepared to do so, they would be stuck in a cycle of reincarnation, condemned to suffer endless human lives on the corrupt Earth.\nZo\u00e9 Oldenbourg compared the Cathars to \"Western Buddhists\" because she considered that their view of the doctrine of \"resurrection\" in Christianity was similar to the Buddhist doctrine of rebirth.\nChristology.\nCathars venerated Jesus Christ and followed what they considered to be his true teachings, labelling themselves as \"Good Christians\". However, they denied his physical incarnation and Resurrection. Authors believe that their conception of Jesus resembled Docetism, believing him the human form of an angel, whose physical body was only an appearance. This illusory form would have possibly been given by the Virgin Mary, another angel in human form, or possibly a human born of a woman with no involvement of a man.\nThey firmly rejected the Resurrection of Jesus, seeing it as representing reincarnation, and the Christian symbol of the cross, considering it to be no more than a material instrument of torture and evil. They also saw John the Baptist, identified as the same entity as the prophet Elijah, as an evil being sent to hinder Jesus's teaching through the false sacrament of baptism. For the Cathars, the \"resurrection\" mentioned in the New Testament was only a symbol of re-incarnation.\nMost Cathars did not accept the normative Trinitarian understanding of Jesus, instead resembling nontrinitarian modalistic Monarchianism (Sabellianism) in the West and adoptionism in the East, which might or might not be combined with the mentioned Docetism. Bernard of Clairvaux's biographer and other sources accuse some Cathars of Arianism, and some scholars see Cathar Christology as having traces of earlier Arian roots.\nSome communities might have believed in the existence of a spirit realm created by the good God, the \"Land of the Living\", whose history and geography would have served as the basis for the evil god's corrupt creation. Under this view, the history of Jesus would have happened roughly as told, only in the spirit realm. The physical Jesus from the material world would have been evil, a false messiah and a lustful lover of the material Mary Magdalene. However, the true Jesus would have influenced the physical world in a way similar to the Harrowing of Hell, only by inhabiting the body of Paul. 13th century chronicler Pierre des Vaux-de-Cernay recorded those views.\nOther beliefs.\nSome Cathars told a version of the Enochian narrative, according to which Eve's daughters copulated with Satan's demons and bore giants. The Deluge would have been provoked by Satan, who disapproved of the demons revealing he was not the real god, or alternatively, an attempt by the Invisible Father to destroy the giants. The Holy Spirit was sometimes counted as one single entity, but to others it was considered the collective groups of unfallen angels who had not followed Satan in his rebellion.\nCathars believed that the sexual allure of women impeded a man's ability to reject the material world. Despite this stance on sex and reproduction, some Cathar communities made exceptions. In one version, the Invisible Father had two spiritual wives, Collam and Hoolibam (identified with Oholah and Oholibah), and would himself have provoked the war in heaven by seducing the wife of Satan, or perhaps the reverse. Cathars adhering to this story would believe that having families and sons would not impede them from reaching God's kingdom.\nSome communities also believed in a Day of Judgment that would come when the number of the just equalled that of angels who fell, when the believers would ascend to the spirit realm, while the sinners would be thrown to everlasting fire along with Satan.\nThe Cathars ate a pescatarian diet. They did not eat cheese, eggs, meat, or milk because these are all by-products of sexual intercourse. The Cathars believed that animals were carriers of reincarnated souls, and forbade the killing of all animal life, apart from fish, which they believed were produced by spontaneous generation.\nThe Cathars could be seen as prefiguring Protestantism in that they denied transubstantiation, purgatory, prayers for the dead and prayers to saints. They also believed that the scriptures should be read in the vernacular.\nTexts.\nThe alleged sacred texts of the Cathars, besides the New Testament, included the Bogomil text \"The Gospel of the Secret Supper\" (also called \"John's Interrogation\"), a modified version of \"Ascension of Isaiah\", and the Cathar original work \"The Book of the Two Principles\" (possibly penned by Italian Cathar John Lugio of Bergamo). They regarded the Old Testament as written by Satan, except for a few books which they accepted, and considered the Book of Revelation not a prophecy about the future, but an allegorical chronicle of what had transpired in Satan's rebellion. Their reinterpretation of those texts contained numerous elements characteristic of Gnostic literature.\nOrganization.\nSacraments.\nCathars, in general, formed an anti-sacerdotal party in opposition to the pre-Reformation Catholic Church, protesting against what they perceived to be the moral, spiritual and political corruption of the Church. In contrast, the Cathars had but one central rite, the Consolamentum, or Consolation. This involved a brief spiritual ceremony to remove all sin from the believer and to induct him into the next higher level as a Perfect.\nMany believers would receive the Consolamentum as death drew near, performing the ritual of liberation at a moment when the heavy obligations of purity required of Perfecti would be temporally short. Some of those who received the sacrament of the consolamentum upon their death-beds may thereafter have shunned further food with an exception of cold water until death. This has been termed the . It was claimed by some of the church writers that when a Cathar, after receiving the Consolamentum, began to show signs of recovery he or she would be smothered in order to ensure his or her entry into paradise. Other than extreme cases, little evidence exists to suggest this was a common Cathar practice.\nThe Cathars also refused the sacrament of the eucharist, saying that it could not possibly be the body of Christ. They also refused to partake in the practice of Baptism by water. The following two quotes are taken from the Inquisitor Bernard Gui's experiences with the Cathar practices and beliefs:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Then they attack and vituperate, in turn, all the sacraments of the Church, especially the sacrament of the eucharist, saying that it cannot contain the body of Christ, for had this been as great as the largest mountain Christians would have entirely consumed it before this. They assert that the host comes from straw, that it passes through the tails of horses, to wit, when the flour is cleaned by a sieve (of horse hair); that, moreover, it passes through the body and comes to a vile end, which, they say, could not happen if God were in it.\nOf baptism, they assert that the water is material and corruptible and is therefore the creation of the evil power, and cannot sanctify the spirit, but that the churchmen sell this water out of avarice, just as they sell earth for the burial of the dead, and oil to the sick when they anoint them, and as they sell the confession of sins as made to the priests.\nSocial relationships.\nKilling was abhorrent to the Cathars. Consequently, abstention from all animal food, sometimes exempting fish, was enjoined of the Perfecti. The Perfecti avoided eating anything considered to be a by-product of sexual reproduction. War and capital punishment were condemned\u2014an abnormality in Medieval Europe, despite the fact that the sect had armed combatants prepared to engage in combat and commit murder on its behalf. For example, the Papal Legate, Pierre de Castelnau, was assassinated in January 1208 in Provence.\nTo the Cathars, reproduction was a moral evil to be avoided, as it continued the chain of reincarnation and suffering in the material world. Such was the situation that a charge of heresy levelled against a suspected Cathar was usually dismissed if the accused could show that he was legally married.\nDespite the implicit anti-Semitism of their views on the Old Testament God, the Cathars had little hostility to Jews as an ethnic group: probably, Jews had a higher status in Cathar territories than they had elsewhere in Europe at the time. Cathars appointed Jews as bailiffs and to other roles as public officials, which further increased the Catholic Church's anger at the Cathars.\nDespite their condemnation of reproduction, the Cathars grew in numbers in southeastern France. By 1207, shortly before the murder of the Papal Legate Castelnau, many towns in that region, i.e., Provence and its vicinity, were almost completely populated by Cathari, and the Cathari population had many ties to nearby communities. When Bishop Fulk of Toulouse, a key leader of the anti-Cathar persecutions, excoriated the Languedoc Knights for not pursuing the heretics more diligently, he received the reply, \"We cannot. We have been reared in their midst. We have relatives among them and we see them living lives of perfection.\"\nHierarchy.\nIt has been alleged that the Cathar Church of the Languedoc had a relatively flat structure, distinguishing between the baptised (a term they did not use; instead, ) and ordinary unbaptised believers (). By about 1140, liturgy and a system of doctrine had been established. They created a number of bishoprics, first at Albi around 1165 and after the 1167 Council at Saint-F\u00e9lix-Lauragais sites at Toulouse, Carcassonne, and Agen, so that four bishoprics were in existence by 1200.\nIn about 1225, during a lull in the Albigensian Crusade, the bishopric of Raz\u00e8s was added. Bishops were supported by their two assistants: a (typically the successor) and a , who were further assisted by deacons. The were the spiritual elite, highly respected by many of the local people, leading a life of austerity and charity. In the apostolic fashion, they ministered to the people and travelled in pairs.\nRole of women.\nCatharism has been seen as giving women the greatest opportunities for independent action, since women were found as being believers as well as Perfecti, who were able to administer the sacrament of the \"consolamentum\".\nCathars believed that a person would be repeatedly reincarnated until they committed to self-denial of the material world. A man could be reincarnated as a woman and vice versa. The spirit was of utmost importance to the Cathars and was described as being immaterial and sexless. Because of this belief, the Cathars saw women as equally capable of being spiritual leaders.\nWomen accused of being heretics in early medieval Christianity included those labelled Gnostics, Cathars, and, later, the Beguines, as well as several other groups that were sometimes \"tortured and executed\". Cathars, like the Gnostics who preceded them, assigned more importance to the role of Mary Magdalene in the spread of early Christianity than the Church previously did. Her vital role as a teacher contributed to the Cathar belief that women could serve as spiritual leaders. Women were included in the Perfecti in significant numbers, with numerous receiving the after being widowed. Having reverence for the Gospel of John, the Cathars saw Mary Magdalene as perhaps even more important than Saint Peter, the founder of the Church.\nCatharism attracted numerous women with the promise of a leadership role that the Catholic Church did not allow. Catharism let women become a Perfect. These female Perfects were required to adhere to a strict and ascetic lifestyle, but were still able to have their own houses. Although many women found something attractive in Catharism, not all found its teachings convincing. A notable example is Hildegard of Bingen, who in 1163 gave a rousing exhortation against the Cathars in Cologne. During this discourse, Hildegard announced God's eternal damnation on all who accepted Cathar beliefs.\nWhile women Perfects rarely travelled to preach the faith, they still played a vital role in the spreading of Catharism by establishing group homes for women. Though it was extremely uncommon, there were isolated cases of female Cathars leaving their homes to spread the faith. In Cathar communal homes (ostals), women were educated in the faith. These women would go on to bear children who would then become believers. Through this pattern, the faith grew exponentially through the efforts of women, as each generation passed.\nDespite women having a role in the growth of the faith, Catharism was not completely equal. For example, the belief that one's last incarnation had to be experienced as a man to break the cycle. This belief was inspired by later French Cathars, who taught that women must be reborn as men in order to achieve salvation. Toward the end of the Cathar movement, Catharism became less equal and started the practice of excluding women Perfects. However, this trend remained limited. For example, later on, Italian Perfects still included women.\nSuppression.\nIn 1147, Pope Eugene III sent a legate to the Cathar district in order to arrest the progress of the Cathars. The few isolated successes of Bernard of Clairvaux could not obscure the poor results of this mission, which clearly showed the power of the sect in the Languedoc at that period. The missions of Cardinal Peter of Saint Chrysogonus to Toulouse and the Toulousain in 1178, and of Henry of Marcy, cardinal-bishop of Albano, in 1180\u201381, obtained merely momentary successes. Henry's armed expedition, which took the stronghold at Lavaur, did not extinguish the movement.\nDecisions of Catholic Church councils\u2014in particular, those of the Council of Tours (1163) and of the Third Council of the Lateran (1179)\u2014had scarcely more effect upon the Cathars. When Pope Innocent III came to power in 1198, he was resolved to deal with them.\nAt first, Innocent tried peaceful conversion, and sent a number of legates into the Cathar regions. They had to contend not only with the Cathars, the nobles who protected them, and the people who respected them, but also with many of the bishops of the region, who resented the considerable authority the Pope had conferred upon his legates. In 1204, Innocent III suspended a number of bishops in Occitania. In 1205, he appointed a new and vigorous bishop of Toulouse, the former troubadour Foulques. In 1206, Diego of Osma and his canon, the future Saint Dominic, began a programme of conversion in Languedoc. As part of this, Catholic\u2013Cathar public debates were held at Verfeil, Servian, Pamiers, Montr\u00e9al and elsewhere.\nDominic met and debated with the Cathars in 1203 during his mission to the Languedoc. He concluded that only preachers who displayed real sanctity, humility and asceticism could win over convinced Cathar believers. The institutional Church as a general rule did not possess these spiritual warrants. His conviction eventually led to the establishment of the Dominican Order in 1216. The order was to live up to the terms of his rebuke, \"Zeal must be met by zeal, humility by humility, false sanctity by real sanctity, preaching falsehood by preaching truth.\" However, even Dominic managed only a few converts among the Cathars.\nAlbigensian Crusade.\nIn January 1208, the papal legate, Pierre de Castelnau, a Cistercian monk, theologian and canon lawyer, was sent to meet the ruler of the area, Raymond VI, Count of Toulouse. Known for excommunicating noblemen who protected the Cathars, Castelnau excommunicated Raymond for abetting heresy, following an allegedly fierce argument during which Raymond supposedly threatened Castelnau with violence. Shortly thereafter, Castelnau was murdered as he returned to Rome, allegedly by a knight in the service of Count Raymond. His body was returned and laid to rest in the Abbey of Saint-Gilles.\nAs soon as he heard of the murder, the Pope ordered the legates to preach a crusade against the Cathars, and wrote a letter to Philip Augustus, King of France, appealing for his intervention\u2014or an intervention led by his son, Louis. This was not the first appeal, but some see the murder of the legate as a turning point in papal policy, which had hitherto refrained from the use of military force. Raymond of Toulouse was excommunicated, the second such instance, in 1209.\nKing Philip II of France refused to lead the crusade himself, and could not spare his son, Prince Louis VIII, to do so either\u2014despite his victory against John, King of England, as there were still pressing issues with Flanders and the empire along with the threat of an Angevin revival. While King Philip II could not lead the crusade nor spare his son, he sanctioned the participation of some of his barons, notably Simon de Montfort and Bouchard de Marly. The twenty years of war against the Cathars and their allies in the Languedoc that followed were called the Albigensian Crusade, derived from Albi, the capital of the Albigensian district, the district corresponding to the present-day French department of Tarn.\nThis war pitted the nobles of France against those of the Languedoc. The widespread northern enthusiasm for the Crusade was partially inspired by a papal decree that permitted the confiscation of lands owned by Cathars and their supporters. This angered not only the lords of the south, but also the King Philip II of France, who was at least nominally the suzerain of the lords whose lands were now open to seizure. King Philip II wrote to Pope Innocent in strong terms to point this out\u2014but Pope Innocent refused to change his decree. As the Languedoc was supposedly teeming with Cathars and Cathar sympathisers, this made the region a target for northern French noblemen looking to acquire new fiefs.\nThe first target for the barons of the North were the lands of the Trencavel, powerful lords of Carcassonne, B\u00e9ziers, Albi, and the Razes. Little was done to form a regional coalition, and the crusading army was able to take Carcassonne, the Trencavel capital, incarcerating Raymond Roger Trencavel in his own citadel, where he died within three months. Champions of the Occitan cause claimed that he was murdered. Simon de Montfort was granted the Trencavel lands by Pope Innocent, thus incurring the enmity of Peter II of Aragon, who previously had been aloof from the conflict, even acting as a mediator at the time of the siege of Carcassonne.\nThe remainder of the first of the two Cathar wars now focused on Simon de Monfort's attempt to hold on to his gains through the winters. With a small force of confederates operating from the main winter camp at Fanjeaux, he was faced with the desertion of local lords who had sworn fealty to him out of necessity\u2014and attempts to enlarge his newfound domain during the summer. His forces were then greatly augmented by reinforcements from northern France, Germany, and elsewhere.\nDe Montfort's summer campaigns recaptured losses sustained in winter months, in addition to attempts to widen the crusade's sphere of operation. Notably he was active in the Aveyron at St. Antonin and on the banks of the Rh\u00f4ne at Beaucaire. Simon de Monfort's greatest triumph was the victory against superior numbers at the Battle of Muret in 1213\u2014a battle in which de Montfort's much smaller force, composed entirely of cavalry, decisively defeated the much-larger, by some estimates 5\u201310 times larger and combined-force allied armies of Raymond of Toulouse, his Occitan allies, and Peter II of Aragon. The battle saw the death of Peter II, which effectively ended the ambitions and influence of the house of Aragon/Barcelona in the Languedoc.\nIn 1214, Philip II's victory at Bouvines near Lille ended the Anglo-French War of 1213\u20131214, dealt a death blow to the Angevin Empire, and freed Philip II to concentrate more of his attentions to the Albigensian Crusade underway in the south of France. In addition, the victory at Bouvines was against an Anglo-German force that was attempting to undermine the power of the French crown. An Anglo-German victory would have been a serious setback to the crusade. Full French royal intervention in support of the crusade occurred in early 1226, when Louis VIII of France led a substantial force into southeastern France.\nMassacre.\nThe crusader army came under the command, both spiritually and militarily, of the papal legate Arnaud Amalric, Abbot of C\u00eeteaux. In the first significant engagement of the war, the town of B\u00e9ziers was besieged on 22 July 1209. The Catholic inhabitants of the city were granted the freedom to leave unharmed, but many refused and opted to stay and fight alongside the Cathars.\nThe townsmen spent much of 1209 fending off the crusaders. The B\u00e9ziers army attempted a sortie but was quickly defeated, then pursued by the crusaders back through the gates and into the city. Arnaud Amalric, the Cistercian abbot-commander, wrote to Pope Innocent III, that during negotiations his soldiers had taken the initiative without waiting for orders. The doors of the church of St Mary Magdalene were broken down and the refugees dragged out and slaughtered. Reportedly, at least 7,000 men, women and children were killed there by Catholic forces, though some scholars dispute this number. Elsewhere in the town, many more thousands were mutilated and killed. Prisoners were blinded, dragged behind horses, and used for target practice. What remained of the city was razed by fire.\nArnaud Amalric wrote \"Today your Holiness, twenty thousand heretics were put to the sword, regardless of rank, age, or sex.\" The permanent population of B\u00e9ziers at that time was then between 10,000 and 14,500, but local refugees seeking shelter within the city walls could conceivably have increased the number to 20,000, though scholars dispute the figure as figurative.\nAccording to a report thirty years later by a non-witness, Arnaud Amalric is supposed to have been asked how to tell Cathars from Catholics. His alleged reply, according to Caesarius of Heisterbach, a fellow Cistercian, was \u2014\"Kill them all, the Lord will recognise His own\".\nAfter the success of his siege of Carcassonne, which followed the massacre at B\u00e9ziers in 1209, Simon de Montfort was designated as leader of the Crusader army. Prominent opponents of the Crusaders were Raymond Roger Trencavel, viscount of Carcassonne, and his feudal overlord Peter II of Aragon, who held fiefdoms and had a number of vassals in the region. Peter died fighting against the crusade on 12 September 1213 at the Battle of Muret. Simon de Montfort was killed on 25 June 1218 after maintaining a siege of Toulouse for nine months.\nTreaty and persecution.\nThe official war ended in the Treaty of Paris (1229), by which the king of France dispossessed the House of Toulouse of the greater part of its fiefs, and the house of the Trencavels of the whole of their fiefs. The independence of the princes of the Languedoc was at an end. In spite of the wholesale massacre of Cathars during the war, Catharism was not yet extinguished, and Catholic forces would continue to pursue Cathars.\nIn 1215, the bishops of the Catholic Church met at the Fourth Council of the Lateran under Pope Innocent III. Part of the agenda was combating the Cathar heresy.\nThe Inquisition was established in 1233 to uproot the remaining Cathars. Operating in the south at Toulouse, Albi, Carcassonne and other towns during the whole of the 13th century, and a great part of the 14th, it succeeded in crushing Catharism as a popular movement, driving its remaining adherents underground. Cathars who refused to recant or relapsed were hanged, or burnt at the stake.\nOn Friday 13 May 1239, in Champagne, 183 men and women convicted of Catharism were burned at the stake on the orders of the Dominican inquisitor and former Cathar Perfect Robert le Bougre. Mount Guimar, in northeastern France, had already been denounced as a place of heresy in a letter of the Bishop of Li\u00e8ge to Pope Lucius II in 1144.\nFrom May 1243 to March 1244, the Cathar fortress of Monts\u00e9gur was besieged by the troops of the seneschal of Carcassonne and the archbishop of Narbonne. On 16 March 1244, a large and symbolically important massacre took place, wherein over 200 Cathar Perfects were burnt in an enormous pyre at the (\"field of the burned\") near the foot of the castle. The Church, at the 1235 Council of Narbonne, decreed lesser chastisements against laymen suspected of sympathy with Cathars.\nA popular though as yet unsubstantiated belief holds that a small party of Cathar Perfects escaped from the fortress prior to the massacre at . It is widely held in the Cathar region to this day that the escapees took with them \"the Cathar treasure\". What this treasure consisted of has been a matter of considerable speculation: claims range from sacred Gnostic texts to the Cathars' accumulated wealth, which might have included the Holy Grail (see below).\nHunted by the Inquisition and deserted by the nobles of their districts, the Cathars became more and more scattered fugitives, meeting surreptitiously in forests and mountain wilds. Later insurrections broke out under the leadership of Roger-Bernard II, Count of Foix, Aimery III of Narbonne, and Bernard D\u00e9licieux, a Franciscan friar later prosecuted for his adherence to another heretical movement, that of the Spiritual Franciscans at the beginning of the 14th century. By this time, the Inquisition had grown very powerful. Consequently, many presumed to be Cathars were summoned to appear before it.\nPrecise indications of this are found in the registers of the Inquisitors Bernard of Caux, Jean de St Pierre, Geoffroy d'Ablis, and others. The \"perfects\", it was said, only rarely recanted, and hundreds were burnt. Repentant lay believers were punished, but their lives were spared as long as they did not relapse. Having recanted, they were obliged to sew yellow crosses onto their outdoor clothing and to live apart from other Catholics, at least for a time.\nAnnihilation.\nAfter several decades of harassment and re-proselytising, and, perhaps even more important, the systematic destruction of their religious texts, the sect was exhausted and could find no more adepts. In April 1310, the leader of a Cathar revival in the Pyrenean foothills, Peire Autier, was captured and executed in Toulouse. After 1330, the records of the Inquisition contain very few proceedings against Cathars. In the autumn of 1321, the last known Cathar \"perfect\" in the Languedoc, Guillaume B\u00e9libaste, was executed.\nFrom the mid-12th century onwards, Italian Catharism came under increasing pressure from the Pope and the Inquisition, \"spelling the beginning of the end.\" Other movements, such as the Waldensians and the pantheistic Brethren of the Free Spirit, which suffered persecution in the same area, survived in remote areas and in small numbers through the 14th and 15th centuries. The Waldensian movement continues today. Waldensian ideas influenced other proto-Protestant sects, such as the Hussites, Lollards, and the Moravian Church.\nLater history.\nAfter the suppression of Catharism, the descendants of Cathars were discriminated against; at times, they were also required to live outside towns and their defences. They retained their Cathar identity, despite their reintegration into Catholicism. As such, any use of the term \"Cathar\" to refer to people after the suppression of Catharism in the 14th century is a cultural or ancestral reference and has no religious implication. Nevertheless, interest in the Cathars and their history, legacy and beliefs continues.\nThe term , French meaning \"Cathar Country\", is used to highlight the Cathar heritage and history of the region in which Catharism was traditionally strongest. The area is centered around fortresses such as Monts\u00e9gur and Carcassonne; also, the French d\u00e9partement of the Aude uses the title in tourist brochures. The areas have ruins from the wars against the Cathars that are still visible today.\nInterrogation of heretics.\nIn an effort to find the few remaining heretics in and around the village of Montaillou, Jacques Fournier, Bishop of Pamiers, future Pope Benedict XII, had those suspected of heresy interrogated in the presence of scribes who recorded their conversations. The late 13th- to early-14th-century document, the Fournier Register, discovered in the Vatican archives in the 1960s and edited by Jean Duvernoy, is the basis for Emmanuel Le Roy Ladurie's work \"Montaillou: The Promised Land of Error\".\nHistorical and current scholarship.\nThe publication of the early scholarly book \"Crusade Against the Grail,\" by the young German and later SS officer, Otto Rahn in the 1930s, rekindled interest in the connection between the Cathars and the Holy Grail, especially in Germany. Rahn was convinced that the 13th-century work \"Parzival\" by Wolfram von Eschenbach was a veiled account of the Cathars. The philosopher and Nazi government official Alfred Rosenberg speaks favourably of the Cathars in \"The Myth of the Twentieth Century.\"\nAcademic books in English first appeared at the beginning of the 21st century: for example, Malcolm Lambert's \"The Cathars\" and Malcolm Barber's \"The Cathars.\"\nDebate on the nature and existence of Catharism.\nStarting in the 1990s and continuing to the present day, historians like R.\u00a0I. Moore have challenged the extent to which Catharism, as an institutionalised religion, actually existed. Building on the work of French historians such as Monique Zerner and Uwe Brunn, Moore's \"The War on Heresy\" argues that Catharism was \"contrived from the resources of [the] well-stocked imaginations\" of churchmen, \"with occasional reinforcement from miscellaneous and independent manifestations of local anticlericalism or apostolic enthusiasm.\" In short, Moore claims that the men and women persecuted as Cathars were not the followers of a secret religion imported from the East. Instead, they were part of a broader spiritual revival taking place in the later twelfth and early thirteenth centuries. Moore's work is indicative of a larger historiographical trend towards examining how heresy was constructed by the church.\nScholars since the 1990s have referred to the fearful rumours of Cathars as a moral panic. The crusade against Cathars as a possibly-imaginary enemy has been compared to European witch-hunts, anti-Semitic persecution, and the Satanic Panic.\nIn 2016, \"Cathars in Question,\" edited by Antonio Sennis, presented a range of conflicting views by academics of medieval heresy, including Feuchter, Stoyanov, Sackville, Taylor, D'Avray, Biller, Moore, Bruschi, Pegg, Hamilton, Arnold, and Th\u00e9ry-Astruc, who had met at University College London and the Warburg Institute in London in April 2013. Sennis describes the debate as about \"an issue which is highly controversial and hotly debated among scholars: the existence of a medieval phenomenon which we can legitimately call 'Catharism.'\"\nDr. Andrew Roach in \"The English Historical Review\" commented that \"Reconciliation still seems some distance away [among the] distinguished, if sometimes cantankerous, scholars\" who contributed to the volume. He said:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The debate is a now familiar one which has been rehearsed for a number of periods and contexts, namely, given that the overwhelming majority of sources about medieval heresy come not from \"heretics\" themselves but from their persecutors, is there any way historians can be sure that this classification is not just a result of mindsets driven by pre-conceptions of what is correct or the conscious \"fitting up\" of opponents?\nProfessor Rebecca Rist describes the academic controversy as the \"heresy debate\"\u2014\"some of it very heated\"\u2014about whether Catharism was a \"real heresy with Balkans origins, or rather a construct of western medieval culture, whose authorities wanted to persecute religious dissidents.\" Rist adds that some historians say the group was an invention of the medieval Church, so there never was a Cathar heresy; while she agrees that the medieval Church exaggerated its threat, she says there is evidence of the heresy's existence.\nProfessor Claire Taylor has called for a \"post-revisionism\" in the debate, saying that legacy historians assumed the heresy was a form of dualism and therefore a form of Bogomilism, whereas \"revisionists\" have focused on social origins to explain the dissent. Lucy Sackville has argued that while the revisionists rightly point to the Cathars' opaque origins and their branding as 'Manichaeans,' this does not mean we should disregard all evidence that their heresy had an organised theology.\nIn art and music.\nThe principal legacy of the Cathar movement is in the poems and songs of the Cathar troubadours, though this artistic legacy is only a smaller part of the wider Occitan linguistic and artistic heritage. The Occitan song \"Lo Boi\u00e8r\" is particularly associated with Catharism. Recent artistic projects concentrating on the Cathar element in Proven\u00e7al and troubadour art include commercial recording projects by Thomas Binkley, electric hurdy-gurdy artist Valentin Clastrier, La Nef, and Jordi Savall.\nIn popular culture, Catharism has been linked with the Knights Templar, an active order of monks founded after the First Crusade (1095\u20131099). This link has caused fringe theories about the Cathars and the possibility of their possession of the Holy Grail, such as in the pseudohistorical \"The Holy Blood and the Holy Grail.\"\nReinterpretations.\nProtestants.\nProtestants such as John Foxe, in the 16th century, and Jean Duvernoy, in the 20th century, argued that Cathars followed Proto-Protestant theology, though they were criticised by many historians. Foxe argued that they followed Calvinist soteriology. Such have argued that Cathars did not follow dualism but instead argued that such accusations were either misinterpretations of Cathar theology, wrongly attributed to Cathars or merely hostile claims.\nOther historians have also argued that Cathars instead followed Protestant theology because the Reformation spread rapidly to the land in which Cathars mainly existed. They argued that the people \"held Protestant ideas\" well before the Reformation. However, such arguments are generally viewed as weak, for instance because of the need to downplay the dualism not present in Protestantism.\nBaptists.\nTwentieth-century Baptists have argued that the Cathars are part of Baptist successionism, placing the Cathars as forerunners of Baptist theology. James Milton Carroll claimed in his book \"The Trail of Blood\" that the Novatianists, or Cathari, were ascendants of Baptist groups. Writing for Catholic Answers, Dwight Longenecker, says there is no historical proof for Baptist successionism.\nHisel Berlin, advocating for the Baptist successionist theory, argued that claims about the Cathars were mainly false and that they denied things such as infant baptism. Since the end of the 19th century, the trend in academic Baptist historiography has been away from the successionist viewpoint to the view that modern day Baptists are an outgrowth of 17th-century English Separatism.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nSources.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "7632", "revid": "7903804", "url": "https://en.wikipedia.org/wiki?curid=7632", "title": "Cerebrospinal fluid", "text": "Clear, colorless bodily fluid found in the brain and spinal cord\nCerebrospinal fluid (CSF) is a clear, colorless transcellular body fluid found within the meningeal tissue that surrounds the vertebrate brain and spinal cord, and in the ventricles of the brain.\nCSF is mostly produced by specialized ependymal cells in the choroid plexuses of the ventricles of the brain, and absorbed in the arachnoid granulations. It is also produced by ependymal cells in the lining of the ventricles. In humans, there is about 125\u00a0mL of CSF at any one time, and about 500\u00a0mL is generated every day. CSF acts as a shock absorber, cushion or buffer, providing basic mechanical and immunological protection to the brain inside the skull. CSF also serves a vital function in the cerebral autoregulation of cerebral blood flow.\nCSF occupies the subarachnoid space (between the arachnoid mater and the pia mater) and the ventricular system around and inside the brain and spinal cord. It fills the ventricles of the brain, cisterns, and sulci, as well as the central canal of the spinal cord. There is also a connection from the subarachnoid space to the bony labyrinth of the inner ear via the perilymphatic duct where the perilymph is continuous with the cerebrospinal fluid. The ependymal cells of the choroid plexus have multiple motile cilia on their apical surfaces that beat to move the CSF through the ventricles.\nA sample of CSF can be taken from around the spinal cord via lumbar puncture. This can be used to test the intracranial pressure, as well as indicate diseases including infections of the brain or the surrounding meninges.\nAlthough noted by Hippocrates, it was forgotten for centuries, though later was described in the 18th century by Emanuel Swedenborg. In 1914, Harvey Cushing demonstrated that CSF is secreted by the choroid plexus.\nStructure.\nCirculation.\nIn humans, there is about 125\u2013150\u00a0mL of CSF at any one time. This CSF circulates within the ventricular system of the brain. The ventricles are a series of cavities filled with CSF. The majority of CSF is produced from within the two lateral ventricles. From here, CSF passes through the interventricular foramina to the third ventricle, then the cerebral aqueduct to the fourth ventricle. From the fourth ventricle, the fluid passes into the subarachnoid space through four openings\u00a0\u2013 the central canal of the spinal cord, the median aperture, and the two lateral apertures. CSF is present within the subarachnoid space, which covers the brain and spinal cord, and stretches below the end of the spinal cord to the sacrum. There is a connection from the subarachnoid space to the bony labyrinth of the inner ear making the cerebrospinal fluid continuous with the perilymph in 93% of people.\nCSF moves in a single outward direction from the ventricles, but multidirectionally in the subarachnoid space. The flow of cerebrospinal fluid is pulsatile, driven by the cardiac cycle. The flow of CSF through perivascular spaces in the brain (surrounding the cerebral arteries) is obtained through the pumping movements of the walls of the arteries.\nContents.\nCSF is derived from blood plasma and is largely similar to it, except that CSF is nearly protein-free compared with plasma and has some different electrolyte levels. Due to the way it is produced, CSF has a lower chloride level than plasma, and a higher sodium level.\nCSF contains approximately 0.59% plasma proteins, or approximately 15 to 40\u00a0mg/dL, depending on sampling site. In general, globular proteins and albumin are in lower concentration in ventricular CSF compared to lumbar or cisternal fluid. This continuous flow into the venous system dilutes the concentration of larger, lipid-insoluble molecules penetrating the brain and CSF. CSF is normally free of red blood cells and at most contains fewer than 5 white blood cells per mm3 (if the white cell count is higher than this it constitutes pleocytosis and can indicate inflammation or infection).\nDevelopment.\nAt around the fifth week of its development, the embryo is a three-layered disc, covered with ectoderm, mesoderm and endoderm. A tube-like formation develops in the midline, called the notochord. The notochord releases extracellular molecules that affect the transformation of the overlying ectoderm into nervous tissue. The neural tube, forming from the ectoderm, contains CSF prior to the development of the choroid plexuses. The open neuropores of the neural tube close after the first month of development, and CSF pressure gradually increases.\nBy the fourth week of embryonic development the brain has begun to develop. Three swellings (primary brain vesicles), have formed within the embryo around the canal, near to where the head will develop. These swellings represent different components of the central nervous system: the prosencephalon (forebrain), mesencephalon (midbrain), and rhombencephalon (hindbrain). Subarachnoid spaces are first evident around the 32nd day of development near the rhombencephalon; circulation is visible from the 41st day. At this time, the first choroid plexus can be seen, found in the fourth ventricle, although the time at which they first secrete CSF is not yet known.\nThe developing forebrain surrounds the neural cord. As the forebrain develops, the neural cord within it becomes a ventricle, ultimately forming the lateral ventricles. Along the inner surface of both ventricles, the ventricular wall remains thin, and a choroid plexus develops, producing and releasing CSF. CSF quickly fills the neural canal. Arachnoid villi are formed around the 35th week of development, with arachnoid granulations noted around the 39th, and continuing developing until 18 months of age.\nThe subcommissural organ secretes SCO-spondin, which forms Reissner's fiber within CSF assisting movement through the cerebral aqueduct. It is present in early intrauterine life but disappears during early development.\nPhysiology.\nFunction.\nCSF serves several purposes:\nProduction.\nThe brain produces roughly 500\u00a0mL of cerebrospinal fluid per day at a rate of about 20\u00a0mL an hour. This transcellular fluid is constantly reabsorbed, so that only 125\u2013150\u00a0mL is present at any one time.\nCSF volume is higher on a mL per kg body weight basis in children compared to adults. Infants have a CSF volume of 4\u00a0mL/kg, children have a CSF volume of 3\u00a0mL/kg, and adults have a CSF volume of 1.5\u20132\u00a0mL/kg. A high CSF volume is why a larger dose of local anesthetic, on a mL/kg basis, is needed in infants. Additionally, the larger CSF volume may be one reason as to why children have lower rates of postdural puncture headache.\nMost (about two-thirds to 80%) of CSF is produced by the choroid plexus. The choroid plexus is a network of blood vessels present within sections of the four ventricles of the brain. It is present throughout the ventricular system except for the cerebral aqueduct, and the frontal and occipital horns of the lateral ventricles. CSF is mostly produced by the lateral ventricles. CSF is also produced by the single layer of column-shaped ependymal cells which line the ventricles; by the lining surrounding the subarachnoid space; and a small amount directly from the tiny spaces surrounding blood vessels around the brain.\nCSF is produced by the choroid plexus in two steps. Firstly, a filtered form of plasma moves from fenestrated capillaries in the choroid plexus into an interstitial space, with movement guided by a difference in pressure between the blood in the capillaries and the interstitial fluid. This fluid then needs to pass through the epithelium cells lining the choroid plexus into the ventricles, an active process requiring the transport of sodium, potassium and chloride that draws water into CSF by creating osmotic pressure. Unlike blood passing from the capillaries into the choroid plexus, the epithelial cells lining the choroid plexus contain tight junctions between cells, which act to prevent most substances flowing freely into CSF. Cilia on the apical surfaces of the ependymal cells beat to help transport the CSF.\nWater and carbon dioxide from the interstitial fluid diffuse into the epithelial cells. Within these cells, carbonic anhydrase converts the substances into bicarbonate and hydrogen ions. These are exchanged for sodium and chloride on the cell surface facing the interstitium. Sodium, chloride, bicarbonate and potassium are then actively secreted into the ventricular lumen. This creates osmotic pressure and draws water into CSF, facilitated by aquaporins. CSF contains many fewer protein anions than blood plasma. Protein in the blood is primarily composed of anions where each anion has many negative charges on it. \nAs a result, to maintain electroneutrality blood plasma has a much lower concentration of chloride anions than sodium cations. CSF contains a similar concentration of sodium ions to blood plasma but fewer protein cations and therefore a smaller imbalance between sodium and chloride resulting in a higher concentration of chloride ions than plasma. This creates an osmotic pressure difference with the plasma. CSF has less potassium, calcium, glucose and protein. Choroid plexuses also secrete growth factors, iodine, vitamins B1, B12, C, folate, beta-2 microglobulin, arginine vasopressin and nitric oxide into CSF. A Na-K-Cl cotransporter and Na/K ATPase found on the surface of the choroid endothelium, appears to play a role in regulating CSF secretion and composition.\nIt has been hypothesised that CSF is not primarily produced by the choroid plexus, but is being permanently produced inside the entire CSF system, as a consequence of water filtration through the capillary walls into the interstitial fluid of the surrounding brain tissue, regulated by AQP-4.\nThere are circadian variations in CSF secretion, with the mechanisms not fully understood, but potentially relating to differences in the activation of the autonomic nervous system over the course of the day.\nChoroid plexus of the lateral ventricle produces CSF from the arterial blood provided by the anterior choroidal artery. In the fourth ventricle, CSF is produced from the arterial blood from the anterior inferior cerebellar artery (cerebellopontine angle and the adjacent part of the lateral recess), the posterior inferior cerebellar artery (roof and median opening), and the superior cerebellar artery.\nReabsorption.\nCSF returns to the vascular system by entering the dural venous sinuses via arachnoid granulations. These are outpouchings of the arachnoid mater into the venous sinuses around the brain, with valves to ensure one-way drainage. This occurs because of a pressure difference between the arachnoid mater and venous sinuses. CSF has also been seen to drain into lymphatic vessels, particularly those surrounding the nose via drainage along the olfactory nerve through the cribriform plate. The pathway and extent are currently not known, but may involve CSF flow along some cranial nerves and be more prominent in the neonate. CSF turns over at a rate of three to four times a day. CSF has also been seen to be reabsorbed through the sheathes of cranial and spinal nerve sheathes, and through the ependyma.\nRegulation.\nThe composition and rate of CSF generation are influenced by hormones and the content and pressure of blood and CSF. For example, when CSF pressure is higher, there is less of a pressure difference between the capillary blood in choroid plexuses and CSF, decreasing the rate at which fluids move into the choroid plexus and CSF generation. The autonomic nervous system influences choroid plexus CSF secretion, with activation of the sympathetic nervous system decreasing secretion and the parasympathetic nervous system increasing it. Changes in the pH of the blood can affect the activity of carbonic anhydrase, and some drugs (such as furosemide, acting on the Na-K-Cl cotransporter) have the potential to impact membrane channels.\nClinical significance.\nPressure.\nCSF pressure, as measured by lumbar puncture, is 10\u201318\u00a0cmH2O (8\u201315\u00a0mmHg or 1.1\u20132\u00a0kPa) with the patient lying on the side and 20\u201330 cmH2O (16\u201324\u00a0mmHg or 2.1\u20133.2\u00a0kPa) with the patient sitting up. In newborns, CSF pressure ranges from 8 to 10 cmH2O (4.4\u20137.3\u00a0mmHg or 0.78\u20130.98\u00a0kPa). Most variations are due to coughing or internal compression of jugular veins in the neck. When lying down, the CSF pressure as estimated by lumbar puncture is similar to the intracranial pressure.\nHydrocephalus is an abnormal accumulation of CSF in the ventricles of the brain. Hydrocephalus can occur because of obstruction of the passage of CSF, such as from an infection, injury, mass, or congenital abnormality. Hydrocephalus without obstruction associated with normal CSF pressure may also occur. Symptoms can include problems with gait and coordination, urinary incontinence, nausea and vomiting, and progressively impaired cognition. In infants, hydrocephalus can cause an enlarged head, as the bones of the skull have not yet fused, seizures, irritability and drowsiness. A CT scan or MRI scan may reveal enlargement of one or both lateral ventricles, or causative masses or lesions, and lumbar puncture may be used to demonstrate and in some circumstances relieve high intracranial pressure. Hydrocephalus is usually treated through the insertion of a shunt, such as a ventriculo-peritoneal shunt, which diverts fluid to another part of the body.\nIdiopathic intracranial hypertension is a condition of unknown cause characterized by a rise in CSF pressure. It is associated with headaches, double vision, difficulties seeing, and a swollen optic disc. It can occur in association with the use of vitamin A and tetracycline antibiotics, or without any identifiable cause at all, particularly in younger obese women. Management may include ceasing any known causes, a carbonic anhydrase inhibitor such as acetazolamide, repeated drainage via lumbar puncture, or the insertion of a shunt such as a ventriculo-peritoneal shunt.\nCSF leak.\nCSF can leak from the dura as a result of different causes such as physical trauma or a lumbar puncture, or from no known cause when it is termed a spontaneous cerebrospinal fluid leak. It is usually associated with intracranial hypotension: low CSF pressure. It can cause headaches, made worse by standing, moving and coughing, as the low CSF pressure causes the brain to \"sag\" downwards and put pressure on its lower structures. If a leak is identified, a beta-2 transferrin test of the leaking fluid, when positive, is highly specific and sensitive for the detection for CSF leakage. Medical imaging such as CT scans and MRI scans can be used to investigate for a presumed CSF leak when no obvious leak is found but low CSF pressure is identified. Caffeine, given either orally or intravenously, often offers symptomatic relief. Treatment of an identified leak may include injection of a person's blood into the epidural space (an epidural blood patch), spinal surgery, or fibrin glue.\nLumbar puncture.\nCSF can be tested for the diagnosis of a variety of neurological diseases, usually obtained by a procedure called lumbar puncture. Lumbar puncture is carried out under sterile conditions by inserting a needle into the subarachnoid space, usually between the third and fourth lumbar vertebrae. CSF is extracted through the needle, and tested. About one third of people experience a headache after lumbar puncture, and pain or discomfort at the needle entry site is common. Rarer complications may include bruising, meningitis or ongoing post lumbar-puncture leakage of CSF.\nTesting often includes observing the colour of the fluid, measuring CSF pressure, and counting and identifying white and red blood cells within the fluid; measuring protein and glucose levels; and culturing the fluid. The presence of red blood cells and xanthochromia may indicate subarachnoid hemorrhage; whereas central nervous system infections such as meningitis, may be indicated by elevated white blood cell levels. A CSF culture may yield the microorganism that has caused the infection, or PCR may be used to identify a viral cause. Investigations to the total type and nature of proteins reveal point to specific diseases, including multiple sclerosis, paraneoplastic syndromes, systemic lupus erythematosus, neurosarcoidosis, cerebral angiitis; and specific antibodies such as aquaporin-4 may be tested for to assist in the diagnosis of autoimmune conditions. A lumbar puncture that drains CSF may also be used as part of treatment for some conditions, including idiopathic intracranial hypertension and normal pressure hydrocephalus.\nLumbar puncture can also be performed to measure the intracranial pressure, which might be increased in certain types of hydrocephalus. However, a lumbar puncture should never be performed if increased intracranial pressure is suspected due to certain situations such as a tumour, because it can lead to fatal brain herniation.\nAnesthesia and chemotherapy.\nSome anesthetics and chemotherapy drugs are injected intrathecally into the subarachnoid space, where they spread around CSF, meaning substances that cannot cross the blood\u2013brain barrier can still be active throughout the central nervous system. Baricity refers to the density of a substance compared to the density of human cerebrospinal fluid and is used in regional anesthesia to determine the manner in which a particular drug will spread in the intrathecal space.\nLiquorpheresis.\nLiquorpheresis is the process of filtering the CSF in order to clear it from endogen or exogen pathogens. It can be achieved by means of fully implantable or extracorporeal devices, though the technique remains experimental today.\nCSF drug delivery.\nCSF drug delivery refers to a number of methods designed to administer therapeutic agents directly into the CSF, bypassing the BBB to achieve higher drug concentrations in the CNS. This technique is particularly beneficial for treating neurological disorders such as brain tumors, infections, and neurodegenerative diseases. Intrathecal injection, where drugs are injected directly into the CSF via the lumbar region, and intracerebroventricular injection, targeting the brain's ventricles, are common approaches. These methods ensure that drugs can reach the CNS more effectively than systemic administration, potentially improving therapeutic outcomes and reducing systemic side effects. Advances in this field are driven by ongoing research into novel delivery systems and drug formulations, enhancing the precision and efficacy of treatments.\nIntrathecal pseudodelivery refers to a particular drug delivery method where the therapeutic agent is introduced into a reservoir connected to the intrathecal space, rather than being released into the CSF and distributed throughout the CNS. In this approach, the drug interacts with its target within the reservoir, allowing for changing the composition of the CSF without systemic release. This method can be advantageous for maximizing efficacy and minimizing systemic side effects. \nHistory.\nVarious comments by ancient physicians have been read as referring to CSF. Hippocrates discussed \"water\" surrounding the brain when describing congenital hydrocephalus, and Galen referred to \"excremental liquid\" in the ventricles of the brain, which he believed was purged into the nose. But for some 16 intervening centuries of ongoing anatomical study, CSF remained unmentioned in the literature. This is perhaps because of the prevailing autopsy technique, which involved cutting off the head, thereby removing evidence of CSF before the brain was examined.\nThe modern rediscovery of CSF is credited to Emanuel Swedenborg. In a manuscript written between 1741 and 1744, unpublished in his lifetime, Swedenborg referred to CSF as \"spirituous lymph\" secreted from the roof of the fourth ventricle down to the medulla oblongata and spinal cord. This manuscript was eventually published in translation in 1887.\nAlbrecht von Haller, a Swiss physician and physiologist, made note in his 1747 book on physiology that the \"water\" in the brain was secreted into the ventricles and absorbed in the veins, and when secreted in excess, could lead to hydrocephalus. Fran\u00e7ois Magendie studied the properties of CSF by vivisection. He discovered the foramen Magendie, the opening in the roof of the fourth ventricle, but mistakenly believed that CSF was secreted by the pia mater.\nThomas Willis (noted as the discoverer of the circle of Willis) made note of the fact that the consistency of CSF is altered in meningitis. In 1869 Gustav Schwalbe proposed that CSF drainage could occur via lymphatic vessels.\nIn 1891, W. Essex Wynter began treating tubercular meningitis by removing CSF from the subarachnoid space, and Heinrich Quincke began to popularize lumbar puncture, which he advocated for both diagnostic and therapeutic purposes. In 1912, a neurologist William Mestrezat gave the first accurate description of the chemical composition of CSF. In 1914, Harvey W. Cushing published conclusive evidence that CSF is secreted by the choroid plexus.\nOther animals.\nDuring phylogenesis, CSF is present within the neuraxis before it circulates. The CSF of teleost fish, which do not have a subarachnoid space, is contained within the ventricles of their brains. In mammals, where a subarachnoid space is present, CSF is present in it. Absorption of CSF is seen in amniotes and more complex species, and as species become progressively more complex, the system of absorption becomes progressively more enhanced, and the role of spinal epidural veins in absorption plays a progressively smaller and smaller role.\nThe amount of cerebrospinal fluid varies by size and species. In humans and other mammals, cerebrospinal fluid turns over at a rate of 3\u20135 times a day. Problems with CSF circulation, leading to hydrocephalus, can occur in other animals as well as humans.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "7633", "revid": "252195", "url": "https://en.wikipedia.org/wiki?curid=7633", "title": "Cordial", "text": "Cordial may refer to:\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "7635", "revid": "28481209", "url": "https://en.wikipedia.org/wiki?curid=7635", "title": "Charles F. Hockett", "text": "American linguist (1916\u20132000)\nCharles Francis Hockett (January 17, 1916 \u2013 November 3, 2000) was an American linguist who developed many influential ideas in American structuralist linguistics. He represents the post-Bloomfieldian phase of structuralism often referred to as \"distributionalism\" or \"taxonomic structuralism\". His academic career spanned over half a century at Cornell and Rice universities. Hockett was also a firm believer of linguistics as a branch of anthropology, making contributions that were significant to the field of anthropology as well.\nProfessional and academic career.\nEducation.\nAt the age of 16, Hockett enrolled at Ohio State University in Columbus, Ohio where he received a Bachelor of Arts and Master of Arts in ancient history. While enrolled at Ohio State, Hockett became interested in the work of Leonard Bloomfield, a leading figure in the field of structural linguistics. Hockett continued his education at Yale University where he studied anthropology and linguistics and received his PhD in anthropology in 1939. While studying at Yale, Hockett studied with several other influential linguists such as Edward Sapir, George P. Murdock, and Benjamin Whorf. Hockett's dissertation was based on his fieldwork in Potawatomi; his paper on Potawatomi syntax was published in \"Language\" in 1939. In 1948 his dissertation was published as a series in the International Journal of American Linguistics. Following fieldwork in Kickapoo and Michoac\u00e1n, Mexico, Hockett did two years of postdoctoral study with Leonard Bloomfield in Chicago and Michigan.\nCareer.\nHockett began his teaching career in 1946 as an assistant professor of linguistics in the Division of Modern Languages at Cornell University where he was responsible for directing the Chinese language program. In 1957, Hockett became a member of Cornell's anthropology department and continued to teach anthropology and linguistics until he retired to emeritus status in 1982. In 1986, he took up an adjunct post at Rice University in Houston, Texas, where he remained active until his death in 2000.\nAchievements.\nCharles Hockett held membership among many academic institutions such as the National Academy of Sciences the American Academy of Arts and Sciences, and the Society of Fellows at Harvard University. He served as president of both the Linguistic Society of America and the Linguistic Association of Canada and the United States.\nIn addition to making many contributions to the field of structural linguistics, Hockett also considered such things as Whorfian Theory, jokes, the nature of writing systems, slips of the tongue, and animal communication and their relativeness to speech.\nOutside the realm of linguistics and anthropology, Hockett practiced musical performance and composition. Hockett composed a full-length opera called \"The Love of Do\u00f1a Rosita\" which was based on a play by Federico Garc\u00eda Lorca and premiered at Ithaca College by the Ithaca Opera.\nHockett and his wife Shirley were vital leaders in the development of the Cayuga Chamber Orchestra in Ithaca, New York. In appreciation of the Hocketts' hard work and dedication to the Ithaca community, Ithaca College established the Charles F. Hockett Music Scholarship, the Shirley and Chas Hockett Chamber Music Concert Series, and the Hockett Family Recital Hall.\nView on linguistics.\nIn his paper \"A Note on Structure\", he proposes that linguistics can be seen as \"a game and as a science.\" A linguist as a player in the game of languages has the freedom to experiment on all utterances of a language, but must ensure that \"all the utterances of the corpus must be taken into account.\" Late in his career, he was known for his stinging criticism of Chomskyan linguistics.\nKey contributions.\nCriticisms of Noam Chomsky and the Generative Programme.\nHockett was initially receptive to Generative grammar, hailing Chomsky's Syntactic Structures as \"one of only four major breakthroughs in the history of modern linguistics\" (1965). After carefully examining the generative school's proposed innovations in Linguistics, Hockett decided that this approach was of little value. His book \"The State of the Art\" outlined his criticisms of the generative approach. In his paraphrase a key principle of the Chomskyan paradigm is that there are an infinite number of grammatical sentences in any particular language. \nThe grammar of a language is a finite system that characterizes an infinite set of (well-formed) sentences. More specifically, the grammar of a language is a \"well-defined system\" by definition not more powerful than a universal Turing machine (and, in fact, surely a great deal weaker).\nThe crux of Hockett's rebuttal is that the set of grammatical sentences in a language is not infinite, but rather ill-defined. Hockett proposes that \"no physical system is well-defined\".\nLater in \"Where the tongue slips, there slip I\" he writes as follows. \nIt is currently fashionable to assume that, underlying the actual more or less bumbling speech behavior of any human being, there is a subtle and complicated but determinate linguistic \"competence\": a sentence-generating device whose design can only be roughly guessed at by any techniques so far available to us. This point of view makes linguistics very hard and very erudite, so that anyone who actually does discover facts about underlying \"competence\" is entitled to considerable kudos.\nWithin this popular frame of reference, a theory of \"performance\" -- of the \"generation of speech\" -- must take more or less the following form. If a sentence is to be uttered aloud, or even thought silently to oneself, it must first be built by the internal \"competence\" of the speaker, the functioning of which is by definition such that the sentence will be legal (\"grammatical\") in every respect. But that is not enough; the sentence as thus constructed must then be \"performed\", either overtly so that others may hear it, or covertly so that it is perceived only by the speaker himself. It is in this second step that blunders may appear. That which is generated by the speaker's internal \"competence\"is what the speaker \"intends to say,\" and is the only real concern of linguistics: blunders in actually performed speech are instructions from elsewhere. Just if there are no such intrusions is what is performed an instance of \"smooth speech\".\nI believe this view is unmitigated nonsense, unsupported by any empirical evidence of any sort. In its place, I propose the following.\n\"All\" speech, smooth as well as blunderful, can be and must be accounted for essentially in terms of the three mechanisms we have listed: analogy, blending, and editing. An individual's language, at a given moment, is a set of habits--that is, of analogies, where different analogies are in conflict, one may appear as a constraint on the working of another. Speech actualizes habits--and changes the habits as it does so. Speech reflects awareness of norms; but norms are themselves entirely a matter of analogy (that is, of habit), not some different kind of thing. \nDespite his criticisms, Hockett always expressed gratitude to the generative school for seeing real problems in the preexisting approaches.\nThere are many situations in which bracketing does not serve to disambiguate. As already noted, words that belong together cannot always be spoken together, and when they are not, bracketing is difficult or impossible. In the 1950s this drove some grammarians to drink and other to transformations, but both are only anodynes, not answers\nDesign features of language.\nOne of Hockett's most important contributions was his development of the design-feature approach to comparative linguistics. He attempted to distinguish the similarities and differences among animal communication systems and human language.\nHockett initially developed seven features, which were published in the 1959 paper \u201cAnimal \u2018Languages\u2019 and Human Language.\u201d However, after many revisions, he settled on 13 design-features in the \"Scientific American \" \"The Origin of Speech.\"\nHockett argued that while every communication system has some of the 13 design features, only human, spoken language has all 13 features. In turn, that differentiates human spoken language from animal communication and other human communication systems such as written language.\nHockett's 13 design features of language.\nWhile Hockett believed that all communication systems, animal and human alike, share many of these features, only human language contains all 13 design features. Additionally, traditional transmission, and duality of patterning are key to human language.\nDesign feature representation in other communication systems.\nForaging honey bees communicate with other members of their hive when they have discovered a relevant source of pollen, nectar, or water. In an effort to convey information about the location and the distance of such resources, honeybees participate in a particular figure-eight dance known as the waggle dance.\nIn Hockett's \"The Origin of Speech\", he determined that the honeybee communication system of the waggle dance holds the following design features:\nGibbons are small apes in the family Hylobatidae. While they share the same kingdom, phylum, class, and order of humans and are relatively close to man, Hockett distinguishes between the gibbon communication system and human language by noting that gibbons are devoid of the last four design features.\nGibbons possess the first nine design features, but do not possess the last four (displacement, productivity, traditional transmission, and duality of patterning).\nLater additions to the features.\nIn a report published in 1968 with anthropologist and scientist Stuart A. Altmann, Hockett derived three more Design Features, bringing the total to 16. These are the additional three:\nCognitive scientist and linguist at the University of Sussex Larry Trask offered an alternative term and definition for number 14, Prevarication:\n14. (a) Stimulus Freedom: One can choose to say anything nothing in any given situation\nRelationship between design features and animal communication.\nChomsky theorized that humans are unique in the animal world because of their ability to utilize Design Feature 5: Total Feedback, or recursive grammar. This includes being able to correct oneself and insert explanatory or even non sequitur statements into a sentence, without breaking stride, and keeping proper grammar throughout.\nWhile there have been studies attempting to disprove Chomsky, Marcus states that, \"An intriguing possibility is that the capacity to recognize recursion might be found only in species that can acquire new patterns of vocalization, for example, songbirds, humans and perhaps some cetaceans.\" This is in response to a https:// by psychologist Timothy Gentner of the University of California at San Diego. Gentner's study found that starling songbirds use recursive grammar to identify \u201codd\u201d statements within a given \u201csong.\u201d However, the study does not necessarily debunk Chomsky's observation because it has not yet been proven that songbirds have the semantic ability to generalize from patterns.\nhttp:// that symbolic thought is necessary for grammar-based speech, and thus Homo Erectus and all preceding \u201chumans\u201d would have been unable to comprehend modern speech. Rather, their utterances would have been halting and even quite confusing to us, \ntoday.\nThe http://: Phonetics Laboratory Faculty of Linguistics, Philology and Phonetics published the following chart, detailing how Hockett's (and Altmann's) Design Features fit into other forms of communication, in animals:\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "7638", "revid": "49566734", "url": "https://en.wikipedia.org/wiki?curid=7638", "title": "Consilience", "text": "Principle about evidence\nIn science and history, consilience (also convergence of evidence or concordance of evidence) is the principle that evidence from independent, unrelated sources can \"converge\" on strong conclusions. That is, when multiple sources of evidence are in agreement, the conclusion can be very strong even when none of the individual sources of evidence is significantly so on its own. Most established scientific knowledge is supported by a convergence of evidence: if not, the evidence is comparatively weak, and there will probably not be a strong scientific consensus.\nThe principle is based on unity of knowledge; measuring the same result by several different methods should lead to the same answer. For example, it should not matter whether one measures distances within the Giza pyramid complex by laser rangefinding, by satellite imaging, or with a metre-stick \u2013 in all three cases, the answer should be approximately the same. For the same reason, different dating methods in geochronology should concur, a result in chemistry should not contradict a result in geology, etc.\nThe word \"consilience\" was originally coined as the phrase \"consilience of inductions\" by William Whewell (\"consilience\" refers to a \"jumping together\" of knowledge). The word comes from Latin \"com-\" \"together\" and \"-siliens\" \"jumping\" (as in resilience).\nDescription.\nConsilience requires the use of independent methods of measurement, meaning that the methods have few shared characteristics. That is, the mechanism by which the measurement is made is different; each method is dependent on an unrelated natural phenomenon. For example, the accuracy of laser range-finding measurements is based on the scientific understanding of lasers, while satellite pictures and metre-sticks (or yardsticks) rely on different phenomena. Because the methods are independent, when one of several methods is in error, it is very unlikely to be in error in the \"same way\" as any of the other methods, and a difference between the measurements will be observed. If the scientific understanding of the properties of lasers was inaccurate, then the laser measurement would be inaccurate but the others would not.\nAs a result, when several different methods agree, this is strong evidence that \"none\" of the methods are in error and the conclusion is correct. This is because of a greatly reduced likelihood of errors: for a consensus estimate from multiple measurements to be wrong, the errors would have to be similar for all samples and all methods of measurement, which is extremely unlikely. Random errors will tend to cancel out as more measurements are made, due to regression to the mean; systematic errors will be detected by differences between the measurements and will also tend to cancel out since the direction of the error will still be random. This is how scientific theories reach high confidence\u2014over time, they build up a large degree of evidence which converges on the same conclusion.\nWhen results from different strong methods do appear to conflict, this is treated as a serious problem to be reconciled. For example, in the 19th century, the Sun appeared to be no more than 20 million years old, but the Earth appeared to be no less than 300\u00a0million years (resolved by the discovery of nuclear fusion and radioactivity, and the theory of quantum mechanics); or current attempts to resolve theoretical differences between quantum mechanics and general relativity.\nSignificance.\nBecause of consilience, the strength of evidence for any particular conclusion is related to how many independent methods are supporting the conclusion, as well as how different these methods are. Those techniques with the fewest (or no) shared characteristics provide the strongest consilience and result in the strongest conclusions. This also means that confidence is usually strongest when considering evidence from different fields because the techniques are usually very different.\nFor example, the theory of evolution is supported by a convergence of evidence from genetics, molecular biology, paleontology, geology, biogeography, comparative anatomy, comparative physiology, and many other fields. In fact, the evidence within each of these fields is itself a convergence providing evidence for the theory. As a result, to disprove evolution, most or all of these independent lines of evidence would have to be found to be in error. The strength of the evidence, considered together as a whole, results in the strong scientific consensus that the theory is correct. In a similar way, evidence about the history of the universe is drawn from astronomy, astrophysics, planetary geology, and physics.\nFinding similar conclusions from multiple independent methods is also evidence for the reliability of the methods themselves, because consilience eliminates the possibility of all potential errors that do not affect all the methods equally. This is also used for the validation of new techniques through comparison with the consilient ones. If only partial consilience is observed, this allows for the detection of errors in methodology; any weaknesses in one technique can be compensated for by the strengths of the others. Alternatively, if using more than one or two techniques for every experiment is infeasible, some of the benefits of consilience may still be obtained if it is well-established that these techniques usually give the same result.\nConsilience is important across all of science, including the social sciences, and is often used as an argument for scientific realism by philosophers of science. Each branch of science studies a subset of reality that depends on factors studied in other branches. Atomic physics underlies the workings of chemistry, which studies emergent properties that in turn are the basis of biology. Psychology is not separate from the study of properties emergent from the interaction of neurons and synapses. Sociology, economics, and anthropology are each, in turn, studies of properties emergent from the interaction of countless individual humans. The concept that all the different areas of research are studying one real, existing universe is an apparent explanation of why scientific knowledge determined in one field of inquiry has often helped in understanding other fields.\nDeviations.\nConsilience does not forbid deviations: in fact, since not all experiments are perfect, some deviations from established knowledge are expected. However, when the convergence is strong enough, then new evidence inconsistent with the previous conclusion is not usually enough to outweigh that convergence. Without an equally strong convergence on the new result, the weight of evidence will still favor the established result. This means that the new evidence is most likely to be wrong.\nScience denialism (for example, AIDS denialism) is often based on a misunderstanding of this property of consilience. A denier may promote small gaps not yet accounted for by the consilient evidence, or small amounts of evidence contradicting a conclusion without accounting for the pre-existing strength resulting from consilience. More generally, to insist that all evidence converge precisely with no deviations would be na\u00efve falsificationism, equivalent to considering a single contrary result to falsify a theory when another explanation, such as equipment malfunction or misinterpretation of results, is much more likely.\nIn history.\nHistorical evidence also converges in an analogous way. For example: if five ancient historians, none of whom knew each other, all claim that Julius Caesar seized power in Rome in 49 BCE, this is strong evidence in favor of that event occurring even if each individual historian is only partially reliable. By contrast, if the same historian had made the same claim five times in five different places (and no other types of evidence were available), the claim is much weaker because it originates from a single source. The evidence from the ancient historians could also converge with evidence from other fields, such as archaeology: for example, evidence that many senators fled Rome at the time, that the battles of Caesar's civil war occurred, and so forth.\nConsilience has also been discussed in reference to Holocaust denial. \n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\"We [have now discussed] eighteen proofs all converging on one conclusion...the deniers shift the burden of proof to historians by demanding that \"each\" piece of evidence, independently and without corroboration between them, prove the Holocaust. Yet no historian has ever claimed that one piece of evidence proves the Holocaust. We must examine the collective whole.\"\nThat is, individually the evidence may underdetermine the conclusion, but together they overdetermine it. A similar way to state this is that to ask for one \"particular\" piece of evidence in favor of a conclusion is a flawed question.\nOutside the sciences.\nIn addition to the sciences, consilience can be important to the arts, ethics and religion. Both artists and scientists have identified the importance of biology in the process of artistic innovation.\nHistory of the concept.\nConsilience has its roots in the ancient Greek concept of an intrinsic orderliness that governs our cosmos, inherently comprehensible by logical process, a vision at odds with mystical views in many cultures that surrounded the Hellenes. The rational view was recovered during the high Middle Ages, separated from theology during the Renaissance and found its apogee in the Age of Enlightenment.\nWhewell's definition was that:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The Consilience of Inductions takes place when an Induction, obtained from one class of facts, coincides with an Induction obtained from another different class. Thus Consilience is a test of the truth of the Theory in which it occurs.\nMore recent descriptions include:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\"Where there is a convergence of evidence, where the same explanation is implied, there is increased confidence in the explanation. Where there is divergence, then either the explanation is at fault or one or more of the sources of information is in error or requires reinterpretation.\"\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nEdward O. Wilson.\nAlthough the concept of consilience in Whewell's sense was widely discussed by philosophers of science, the term was unfamiliar to the broader public until the end of the 20th century, when it was revived in \"Consilience: The Unity of Knowledge,\" a 1998 book by the author and biologist E. O. Wilson, as an attempt to bridge the cultural gap between the sciences and the humanities that was the subject of C. P. Snow's \"The Two Cultures and the Scientific Revolution\" (1959). Wilson believed that \"the humanities, ranging from philosophy and history to moral reasoning, comparative religion, and interpretation of the arts, will draw closer to the sciences and partly fuse with them\" with the result that science and the scientific method, from within this fusion, would not only explain the physical phenomenon but also provide moral guidance and be the ultimate source of all truths.\nWilson held that with the rise of the modern sciences, the sense of unity gradually was lost in the increasing fragmentation and specialization of knowledge in the last two centuries. He asserted that the sciences, humanities, and arts have a common goal: to give a purpose to understand the details, to lend to all inquirers \"a conviction, far deeper than a mere working proposition, that the world is orderly and can be explained by a small number of natural laws.\" An important point made by Wilson is that hereditary human nature and evolution itself profoundly affect the evolution of culture, in essence, a sociobiological concept. Wilson's concept is a much broader notion of consilience than that of Whewell, who was merely pointing out that generalizations invented to account for one set of phenomena often account for others as well.\nA parallel view lies in the term universology, which literally means \"the science of the universe.\" Universology was first promoted for the study of the interconnecting principles and truths of all domains of knowledge by Stephen Pearl Andrews, a 19th-century utopian futurist and anarchist.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "7642", "revid": "7563377", "url": "https://en.wikipedia.org/wiki?curid=7642", "title": "Clarence Brown", "text": "American film director (1890\u20131987)\nClarence Leon Brown (May 10, 1890 \u2013 August 17, 1987) was an American film director.\nEarly life.\nBorn in Clinton, Massachusetts, to Larkin Harry Brown, a cotton manufacturer, and Katherine Ann Brown (n\u00e9e Gaw), Brown moved to Tennessee when he was 11 years old. He attended Knoxville High School and the University of Tennessee, both in Knoxville, Tennessee, graduating from the university at the age of 19 with two degrees in engineering. An early fascination in automobiles led Brown to a job with the Stevens-Duryea Company, then to his own Brown Motor Car Company in Alabama. He later abandoned the car dealership after developing an interest in motion pictures around 1913. He was hired by the Peerless Studio at Fort Lee, New Jersey, and became an assistant to the French-born director Maurice Tourneur.\nCareer.\nAfter serving as a fighter pilot and flight instructor in the United States Army Air Service during World War I, Brown was given his first co-directing credit (with Tourneur) for \"The Great Redeemer\" (1920). Later that year, he directed a major portion of \"The Last of the Mohicans\" after Tourneur was injured in a fall.\nBrown moved to Universal in 1924, and then to Metro-Goldwyn-Mayer, where he remained until the mid-1950s. At MGM he was one of the main directors of their major female stars; he directed Joan Crawford six times and Greta Garbo seven.\nBrown's films gained a total of 38 Academy Award nominations and earned nine Oscars. Though he never won a directing Oscar, Brown received five Academy Award nominations for six films, and in 1949, he won the British Academy Award for the film version of William Faulkner's \"Intruder in the Dust\". At the 1935 Venice International Film Festival, he won Best Foreign Film for \"Anna Karenina\", starring Garbo.\nIn 1957, Brown was awarded The George Eastman Award, given by George Eastman House for distinguished contribution to the art of film. Brown retired a wealthy man due to his real estate investments, but refused to watch new movies. He feared they might cause him to restart his career.\nThe Clarence Brown Theater, on the campus of the University of Tennessee, is named in his honor. He holds the record for most nominations for the Academy Award for Best Director without a win, with six.\nPersonal life.\nClarence Brown was married four times. His first marriage was to Paula Herndon Pratt in 1913, which lasted until their divorce in 1920. The couple produced a daughter, Adrienne Brown.\nHis second marriage was to Ona Wilson, which lasted from 1922 until their divorce in 1927.\nHe was engaged to Dorothy Sebastian and Mona Maris, although he did not marry either of them, with Maris later saying she ended their relationship because she had her \"own ideas of marriage then.\"\nHe married his third wife, Alice Joyce, in 1933 and they divorced in 1945.\nHis last marriage was to Marian Spies in 1946, which lasted until his death in 1987.\nDeath.\nBrown died at the Saint John's Health Center in Santa Monica, California from kidney failure on August 17, 1987, at the age of 97. He is interred at Forest Lawn Memorial Park in Glendale, California.\nOn February 8, 1960, Brown received a star on the Hollywood Walk of Fame at 1752 Vine Street, for his contributions to the motion pictures industry.\nSelected filmography.\nDirector.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "7643", "revid": "28481209", "url": "https://en.wikipedia.org/wiki?curid=7643", "title": "Conciliation", "text": "Alternative dispute resolution (ADR) process\nConciliation is an alternative dispute resolution process whereby the parties to a dispute rely on a neutral third-party known as the conciliator, to assist them in solving their dispute. The conciliator, who may meet with the parties both separately and together, does this by: lowering tensions, improving communication, interpreting issues, and assisting parties in finding a mutually acceptable outcome.\nUnlike litigation or arbitration, conciliation is a voluntary, confidential, and flexible method aimed at resolving conflicts without the need for formal legal proceedings. The conciliation process has no legal standing and the decision made by the conciliator is not binding. The conciliator usually has no authority to seek evidence or call witnesses, usually writes no decision, and makes no award.\nConciliation process.\nThe conciliation process begins when both parties agree to engage in it as a method of resolving a dispute. There are multiple uses for this form of alternative dispute resolution including transnational intellectual property, legislative assemblies, peace efforts, and other areas of community concern. This can be either part of an outline contract that was handled before the dispute arose or after a dispute arises. Conciliation is a preferred method of dispute resolution compared to litigation or binding arbitration.\nParties may select a conciliator by mutual consent, or through an appointing institution. The conciliator then gathers information to understand the concerns and objectives of each side. The conciliator helps the parties move toward a resolution. In issues of international law, this may include shuttle diplomacy. \nMost successful \"conciliators\" are usually highly skilled negotiators. Some conciliators operate under the auspices of any one of several non-governmental entities, or for governmental agencies such as the Federal Mediation and Conciliation Service in the United States, and the Advisory, Conciliation and Arbitration Service (Acas) in the United Kingdom. Acas' staff include a Chief Conciliator supported by a team of conciliators.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "7644", "revid": "212624", "url": "https://en.wikipedia.org/wiki?curid=7644", "title": "Colin Fulcher", "text": ""}
{"id": "7645", "revid": "1316548485", "url": "https://en.wikipedia.org/wiki?curid=7645", "title": "Cyclone (programming language)", "text": "Memory-safe dialect of the C programming language\nThe Cyclone programming language was intended to be a safe dialect of the C language. It avoids buffer overflows and other vulnerabilities that are possible in C programs by design, without losing the power and convenience of C as a tool for system programming. It is no longer supported by its original developers, with the reference tooling not supporting 64-bit platforms. The Rust language is mentioned by the original developers for having integrated many of the same ideas Cyclone had.\nCyclone development was started as a joint project of Trevor Jim from AT&amp;T Labs Research and Greg Morrisett's group at Cornell University in 2001. Version 1.0 was released on May 8, 2006.\nLanguage features.\nCyclone attempts to avoid some of the common pitfalls of C, while still maintaining its look and performance. To this end, Cyclone places the following limits on programs:\nTo maintain the tool set that C programmers are used to, Cyclone provides the following extensions:\nFor a better high-level introduction to Cyclone, the reasoning behind Cyclone and the source of these lists, see http://.\nCyclone looks, in general, much like C, but it should be viewed as a C-like language.\nPointer types.\nCyclone implements three kinds of pointer:\nThe purpose of introducing these new pointer types is to avoid common problems when using pointers. Take for instance a function, called codice_17 that takes a pointer to an int:\nint foo(int* p);\nAlthough the person who wrote the function codice_17 could have inserted codice_1 checks, let us assume that for performance reasons they did not. Calling codice_20 will result in undefined behavior (typically, although not necessarily, a codice_21 signal being sent to the application). To avoid such problems, Cyclone introduces the codice_14 pointer type, which can never be codice_1. Thus, the \"safe\" version of codice_17 would be:\nint foo(int@ p);\nThis tells the Cyclone compiler that the argument to codice_17 should never be codice_1, avoiding the aforementioned undefined behavior. The simple change of codice_13 to codice_14 saves the programmer from having to write codice_1 checks and the operating system from having to trap codice_1 pointer dereferences. This extra limit, however, can be a rather large stumbling block for most C programmers, who are used to being able to manipulate their pointers directly with arithmetic. Although this is desirable, it can lead to buffer overflows and other \"off-by-one\"-style mistakes. To avoid this, the codice_16 pointer type is delimited by a known bound, the size of the array. Although this adds overhead due to the extra information stored about the pointer, it improves safety and security. Take for instance a simple (and na\u00efve) codice_32 function, written in C:\nint strlen(const char* s) {\n int i = 0;\n if (!s) {\n return 0;\n while (s[i] != '\\0') {\n i++;\n return i;\nThis function assumes that the string being passed in is terminated by codice_33. However, what would happen if were passed to this string? This is perfectly legal in C, yet would cause codice_32 to iterate through memory not necessarily associated with the string codice_35. There are functions, such as codice_36 which can be used to avoid such problems, but these functions are not standard with every implementation of ANSI C. The Cyclone version of codice_32 is not so different from the C version:\nint strlen(const char? s) {\n int n = s.size;\n if (!s) {\n return 0;\n for (int i = 0; i &lt; n; i++, s++) {\n if (*s == '\\0') {\n return i;\n return n;\nHere, codice_32 bounds itself by the length of the array passed to it, thus not going over the actual length. Each of the kinds of pointer type can be safely cast to each of the others, and arrays and strings are automatically cast to codice_16 by the compiler. (Casting from codice_16 to codice_13 invokes a bounds check, and casting from codice_16 to codice_14 invokes both a codice_1 check and a bounds check. Casting from codice_13 to codice_16 results in no checks whatsoever; the resulting codice_16 pointer has a size of 1.)\nDangling pointers and region analysis.\nConsider the following code, in C:\nchar* itoa(int i) {\n char buf[20];\n sprintf(buf, \"%d\", i);\n return buf;\nThe function codice_48 allocates an array of chars codice_49 on the stack and returns a pointer to the start of codice_49. However, the memory used on the stack for codice_49 is deallocated when the function returns, so the returned value cannot be used safely outside of the function. While GNU Compiler Collection and other compilers will warn about such code, the following will typically compile without warnings:\nchar* itoa(int i) {\n char buf[20];\n sprintf(buf, \"%d\", i);\n char* z = buf;\n return z;\nGNU Compiler Collection can produce warnings for such code as a side-effect of option or , but there are no guarantees that all such errors will be detected.\nCyclone does regional analysis of each segment of code, preventing dangling pointers, such as the one returned from this version of codice_48. All of the local variables in a given scope are considered to be part of the same region, separate from the heap or any other local region. Thus, when analyzing codice_48, the Cyclone compiler would see that codice_54 is a pointer into the local stack, and would report an error.\nFat pointers.\nA fat pointer is used for allowing pointer arithmetic. Fat pointers must be declared with codice_55. For example, codice_56 is often declared as type codice_57 (a pointer to a pointer to a character), or alternatively thought of as codice_58 (pointer to an array of characters). In Cyclone, this is instead expressed as codice_59 (a fat pointer to a fat pointer to characters).\nCyclone instead allows codice_16 to represent codice_61. Thus, the two declarations are equivalent:\nint main(int argc, char?? argv);\n// equivalent to the more verbose declaration\nint main(int argc, char*@fat*@fat argv);\nParameterized types.\nSimilar to templates in C++, Cyclone has a form of generic programming.\ntypedef struct LinkedList&lt;`a&gt; {\n `a head;\n struct LinkedList&lt;`a&gt;* next;\n} LinkedList&lt;`a&gt;;\nLinkedList&lt;int&gt;* ll = new LinkedList{1, new LinkedList{2, null}};\nAn \"abstract\" type can be used, that encapsulates the implementation type but ensures the definition does not leak to the client.\nabstract struct Queue&lt;`a&gt; {\n LinkedList&lt;`a&gt; front;\n LinkedList&lt;`a&gt; rear;\nextern struct Queue&lt;`a&gt;;\nNamespaces.\nNamespaces exist in Cyclone, similar to C++. Namespaces are used to avoid name clashes in code, and follow the codice_62 notation as in C++. Namespaces can be nested.\nnamespace foo {\n int x;\n int f() {\n return x;\nnamespace bar {\n using foo {\n int g() {\n return f();\n int h() {\n return foo::f();\nPattern matching.\nPattern-matching can be accomplished in Cyclone like so:\nint g(int a, int b) {\n switch ($(a, b - 1)) {\n case $(0, y) &amp;&amp; y &gt; 1:\n return 1;\n case $(3, y) &amp;&amp; f(x + y) == 7:\n return 2;\n case $(4, 72):\n return 3;\n default:\n return 4;\nA codice_63 declaration is used to match a pattern and expression.\ntypedef struct Pair {\n int x;\n int y;\n} Pair;\nvoid f(Pair p) {\n let Pair(first, second) = p;\n // equivalent to:\n // int first = p.x;\n // int second = p.y;\nType inference.\nIn Cyclone, rather than using codice_64 like C and C++ or codice_65 in Java and C#, Cyclone instead uses codice_66 (an underscore) to denote a type-inferred variable.\n_ x = (SomeType*)malloc(sizeof(SomeType));\n// instead of:\nSomeType x = (SomeType*)malloc(sizeof(SomeType));\n_ myNumber = 100; // inferred to int\nExceptions.\nCyclone features exceptions. An uncaught exception will halt the program. Like Java, Cyclone features a null pointer exception, called codice_67.\ntypedef FILE File;\nFile* f = fopen(\"/etc/passwd\", \"r\");\ntry {\n int code = getc((File* @notnull)f);\n} catch {\n case &amp;Null_Exception:\n printf(\"Error: can't open /etc/passwd\\n\");\n return 1;\n case &amp;Invalid_argument(s):\n printf(\"Error: invalid argument: %s\\n\", s);\n return 1;\nOne can also manually throw exceptions:\nthrow new Null_Exception(\"This is a null exception\");\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nExternal links.\nPresentations:"}
{"id": "7646", "revid": "842922", "url": "https://en.wikipedia.org/wiki?curid=7646", "title": "Cognitivism", "text": "Cognitivism may refer to:\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "7647", "revid": "6010417", "url": "https://en.wikipedia.org/wiki?curid=7647", "title": "Counter (digital)", "text": "Device storing number of times an event or process occurred\nIn digital electronics, a counter is a sequential logic circuit that counts and stores the number of positive or negative transitions of a clock signal. A counter typically consists of flip-flops, which store a value representing the current count, and in many cases, additional logic to effect particular counting sequences, qualify clocks and perform other functions. Each relevant clock transition causes the value stored in the counter to increment or decrement (increase or decrease by one).\nA digital counter is a finite state machine, with a \"clock\" input signal and multiple output signals that collectively represent the state. The state indicates the current count, encoded directly as a binary or binary-coded decimal (BCD) number or using encodings such as one-hot or Gray code. Most counters have a \"reset\" input which is used to initialize the count. Depending on the design, a counter may have additional inputs to control functions such as count enabling and parallel data loading.\nDigital counters are categorized in various ways, including by attributes such as modulus and output encoding, and by supplemental capabilities such as data preloading and bidirectional (up and down) counting. Every counter is classified as either synchronous or asynchronous. Some counters, specifically ring counters and Johnson counters, are categorized according to their unique architectures.\nCounters are the most commonly used sequential circuits and are widely used in computers, measurement and control, device interfaces, and other applications. They are implemented as stand-alone integrated circuits and as components of larger integrated circuits such as microcontrollers and FPGAs.\nCharacteristics.\nAn electronic counter is a sequential logic circuit that has a clock input signal and a group of output signals that represent an integer \"count\" value. Upon each qualified clock edge, the circuit will increment (or decrement, depending on circuit design) the stored count. When the count reaches the end of the counting sequence (maximum count when incrementing; zero count when decrementing), the next clock will cause the count to overflow or underflow and the counting sequence will start over.\nSignals.\nEvery counter has a fundamental group of signals common to state machines:\nIn addition to Clock and Reset, many counters provide other input signals such as:\nCounter inputs are in many cases synchronous, meaning that they only affect counter operation upon active clock edges. For any particular counter, each synchronous input signal must satisfy the setup and hold times required for proper operation (i.e., it must be stable before and after every active clock edge for specified minimum times).\nSome counters provide a Terminal Count output which indicates that the next clock will cause overflow or underflow. This is used in various ways, including:\nOutput encoding.\nAs it counts, every counter produces a sequence of output codes (bit patterns) on its Count outputs. Many of these code sequences, either by design or due to the nature of the counter, conform to widely used encoding systems. Several types of output encoding are commonly used in counters, including binary, BCD, Gray code, and one-hot.\nModulus.\nThe \"modulus\" of a counter is the number of states in its count sequence. A counter that has modulus value \"m\" is commonly referred to as a \"modulo-m\" or \"MOD-m\" counter. For example, a decade counter is a digital counter which has ten states, and therefore is a MOD-10 counter.\nThe maximum possible modulus of a counter is determined by the number of flip-flops. More specifically, a counter with \"n\" flip-flops has a maximum possible modulus of 2\"n\". For example, a four-bit counter can have a modulus of up to 16 (24).\nSome counters (e.g., binary counters) include all possible states in their count sequences. Other counters omit one or more possible states from their counting sequences. For example, a MOD-10 (decade) counter with four flip-flops only uses ten of 16 possible states.\nClocking method.\nCounters are broadly categorized as either synchronous or asynchronous depending on whether their flip-flops are clocked simultaneously or at different times.\nSynchronous.\nA synchronous counter is a digital counter in which all flip-flops share a common clock and change states at the same time.\nAsynchronous (ripple).\nIn an asynchronous counter, also known as a ripple counter, each flip-flop has a unique clock. The flip-flops are arranged in a \"chain\", with the counter's input clock connected to the first flip-flop and the output of each flip-flop clocking the next flip-flop in the chain. The natural counting sequence of such circuits is binary, and consequently most asynchronous counters are binary, with each flip-flop storing one bit of the binary count value.\nSince every flip-flop introduces a delay from active clock edge to output toggle, the counter bits change state at different times, producing a ripple effect that causes the count to be unstable while the input clock propagates through the flip-flops. During this instablility, the count will briefly transition through one or more invalid values. The duration of this instability (the settling time) depends on several factors, including the clock-to-output delay for each flip-flop and, for any particular count transition, the number of bits that change state. The maximum settling time occurs when all the counter bits change state (i.e., when the counter overflows or underflows) and thus is proportional to the number of flip-flops.\nThis makes ripple counters unsuitable for use in synchronous circuits that require the counter to have a fast output settling time. Also, it is often impractical to use ripple counter output bits as clocks for external circuits because the ripple effect causes timing skew between the bits. Ripple counters are commonly used as general-purpose counters and clock frequency dividers in applications where instantaneous count and timing skew are unimportant. Asynchronous counters are typically not used in VLSI ICs due to the difficulties of simulating and testing them and because they require much greater design effort to ensure reliable operation.\nCount direction.\nMany counters are designed to count in only one direction, meaning that they will either count up or down, but not both. A counter that only counts up is typically referred to as an \"up-counter\", and one that only counts down as a \"down-counter\".\nA bidirectional counter or up/down counter is a digital counter which counts up or down as directed by a direction control input signal. In synchronous up/down counters, the control signal is a single digital input whose state indicates count direction (e.g., '1' = count up; '0' = count down). In asynchronous up/down counters the direction control may alternatively consist of separate \"up\" and \"down\" clock inputs.\nCommon types.\nBinary counter.\nA binary counter is a digital counter that directly represents the count as a binary number. A binary counter is a MOD-2\"n\" counter, where \"n\" is the number of flip-flops used to store the count. For example, the illustrations below show the behavior of a 5-bit binary counter, which has 32 (25) states and is therefore a MOD-32 counter:\nAsynchronous binary counter.\nAn asynchronous binary counter, or binary ripple counter, is a \"chain\" of toggle (T) flip-flops (or equivalent) in which the least-significant flip-flop (bit 0) is clocked by the counter input clock, and all other flip-flops are clocked by the output of the nearest, less significant flip-flop (e.g., bit 0 clocks bit 1 flip-flop, bit 1 clocks bit 2, etc.). When implemented with JK or D flip-flops, each flip-flop is configured to toggle when clocked (i.e., J and K connected to logic high; D connected to Q).\nEach flip-flop is effectively a one-bit counter which increments its count (by toggling its output) once per clock cycle. It counts from zero to one and then, when the next clock arrives, it will overflow and start its count sequence over again at zero. Each output state persists for a full input clock cycle, and consequently the frequency of each flip-flop's output signal is exactly half that of its input clock. Additional flip-flops may be added to the chain to form a counter of any arbitrary word size (number of bits), with the output frequency of each bit equal to exactly half the frequency of its nearest, less significant bit.\nSynchronous binary counter.\nThe circuit shown below is a synchronous, up-counting four-bit binary counter implemented with JK flip-flops. Upon clock rising edge, bit 0 will always toggle, whereas other bits will toggle only when all less-significant bits are at a logic high state (i.e., Q1 toggles if Q0 is logic high; Q2 toggles if Q0 and Q1 are both high; and Q3 toggles if Q0, Q1, and Q2 are all high).\nAs in asynchronous counters, each flip-flop introduces a delay from input clock edge to output toggle, but in this case all flip-flops change state concurrently, and consequently the counter output will settle after only one flip-flop delay regardless of the number of bits.\nBCD decade counter.\nA binary-coded decimal (BCD) decade counter is a MOD-10 counter that directly represents the count as a binary number in the range 0 to 9. Typically a BCD decade counter will count up from 0 to 9 and then overflow. Because their output value range is identical to that of a decimal digit, BCD decade counters are commonly used to represent decimal digits.\nAsynchronous BCD decade counter.\nThe circuit shown below is an asynchronous BCD decade counter. It is effectively a 4-bit binary ripple counter that uses an AND gate to reset the count to zero (by resetting all flip-flops) when the binary count increments to decimal 10 (binary 1010), thus resulting in 10 output states. As in all asynchronous counters, the stored count is unstable while the external clock propagates through the flip-flop chain (including the reset upon reaching count 10).\nSynchronous BCD decade counter.\nThe circuit shown below is a synchronous BCD decade counter. Five logic gates are used to implement the next-state logic, thus facilitating faster operation than an asynchronous counter at the expense of additional circuitry.\nRing counter.\nA ring counter is a circular shift register which is initialized (via its reset input signal) such that one flip-flop (typically bit 0) stores a \u20181\u2019 and all other flip-flops store a \u20180\u2019. Each clock pulse causes the \u20181\u2019 to shift to the next flip-flop. When the \u20181\u2019 reaches the last flip-flop in the shift register, the next clock causes it to shift into the first flip-flop, thus restarting the counting sequence and effecting a counter overflow. At any particular time only one counter output bit is logic \u20181\u2019, and consequently a ring counter is effectively a one-hot state machine.\nA ring counter is MOD-n, where n is the number of flip-flops. For example, the ring counter shown below has four flip-flops and therefore is a MOD-4 counter. In this counter, bit 0 is initially set and all other bits are cleared.\nJohnson counter.\nA Johnson counter is a circular shift register in which the output of the last stage is inverted and connected to the data input of the first stage, and all bits are initialized to zero, thus producing a Gray code output sequence. It can be clocked at relatively high frequencies because there are no intermediate logic gates, and consequently the worst-case propagation delay is from clock to flip-flop output. A Johnson counter is MOD-2n, where n is the number of flip-flops. For example, the Johnson counter shown below has four flip-flops and therefore is a MOD-8 counter.\nJohnson counters are commonly used in state machines and in specialized applications such as analog waveform generation (e.g., Davies sinusoidal generator).\nState machine attributes.\nState register.\nA digital counter is a finite state machine in which the counter's flip-flops serve as the state register. The value stored in the state register is a bit vector comprising the counter's current state.\nState sequencing.\nWhen not otherwise influenced by its input signals, a counter will cyclically step through a fixed sequence of states. Consequently, the state diagram for a counter has the appearance of a loop. For example, a MOD-8 counter will repeatedly loop through eight states:\nIllegal states.\nA counter having formula_1 flip-flops and modulus formula_2 uses only a fraction of its possible states. The unused states are typically referred to as \"illegal states\", as they are forbidden during normal operation. In general, a MOD-formula_3 counter with formula_1 flip-flops has formula_5 illegal states. For example, a MOD-10 BCD decade counter with four flip-flops has six (formula_6) illegal states. A Johnson counter has formula_7, and a ring counter has formula_8 illegal states.\nDuring normal operation, a counter will never enter an illegal state. However, in some cases it is possible for a glitch (e.g., due to power supply noise, radiation exposure) to cause a counter to erroneously enter an illegal state. To allow for this possibility, counters are often designed to automatically recover from illegal states by transitioning to a valid state upon next active clock edge.\nGeneral model.\nDigital counters are typically implemented as Moore machines because their outputs are determined solely by the current state. This makes counters a natural fit for Moore machines, which in turn simplifies the design and promotes reliable operation.\nMore specifically, counters are most commonly implemented as Medvedev state machines, a subclass of Moore machines which directly output the current state, with each state naturally encoding a specific count value. Since the state register of such machines is directly connected to the counter outputs, encoding logic is not needed and output delays are minimized.\nSome counters employ combinational logic between state register and counter outputs to transform the state to a particular output encoding, and thus are classified as full Moore machines. For example, the CMOS 4017 integrated circuit encodes the output of a Johnson decade counter into one-hot format, taking advantage of the Johnson counter's inherent Gray code output to avoid glitches on the one-hot outputs.\nImplementation.\nCounters are implemented in a variety of ways, including as dedicated MSI and LSI integrated circuits, as embedded counters within ASICs, as general-purpose counter and timer peripherals in microcontrollers, and as IP blocks in FPGAs. In the latter case, a counter is typically instantiated by synthesizing it from a description written in VHDL, Verilog or some other hardware description language. For example, the following VHDL code describes a 32-bit binary up/down counter with count enable and preload capability:\nentity bidirectional_counter is\nport ( -- counter input/output signals:\n CLK : in std_logic; -- clock\n RESET : in std_logic; -- asynchronous reset\n ENABLE : in std_logic; -- count enable\n LOAD_ENABLE : in std_logic; -- load enable\n COUNT_UP : in std_logic; -- '1' for up, '0' for down counting\n DATA_IN : in unsigned(31 downto 0); -- value to load into counter\n DATA_OUT : out unsigned(31 downto 0) -- current counter value\nend bidirectional_counter;\narchitecture behavioral of bidirectional_counter is\n signal counter : unsigned(31 downto 0) := (others =&gt; '0'); -- counter register\nbegin\n process(CLK, RESET)\n begin\n if RESET = '1' then -- if counter reset is requested\n counter &lt;= (others =&gt; '0'); -- reset the counter\n elsif rising_edge(CLK) then -- else upon rising clock edge\n if LOAD_ENABLE = '1' then -- if load is requested\n counter &lt;= DATA_IN; -- jam new value into counter \n elsif ENABLE = '0' then -- else if counting is disabled\n null; -- do nothing\n elsif COUNT_UP = '1' then -- else if up-counting\n counter &lt;= counter + 1; -- increment counter\n else -- else down-counting, so\n counter &lt;= counter - 1; -- decrement counter\n end if;\n end if;\n end process;\n DATA_OUT &lt;= counter; -- output current counter value\nend behavioral;\nIn MSI and LSI integrated circuits, a counter is implemented as a semiconductor die which is bonded and encapsulated in a semiconductor package.\nCascading.\nSome counters are \"cascadable\", meaning that multiple instances of such counters can be connected together to form a larger, extended counter with a greater modulus. To facilitate cascading, a cascadable counter typically has an enable input that enables counting, and an output that propagates overflows or underflows to the enable input of the next counter in the cascade.\nThe first (least-significant) counter in a cascade may be permanently enabled by connecting its enable input to a fixed logic level, or its enable input may be dynamically driven. In either case, the enable input of the first counter serves as a count enable for the entire extended counter.\nCascadable binary counters typically output a ripple-carry signal to notify the next counter in the cascade of an impending overflow or underflow. For example, in the four-bit cascadable up-counter shown below, an AND gate asserts the ripple-carry output (RCO) when the next clock is expected to cause an overflow (I.e., when the count is binary 1111 and counting is enabled):\nApplications.\nBinary counters are widely used as timers and event counters.\nIn a digital timer, the counter is clocked by a periodic digital signal which serves as a time reference and causes the count to change at a constant rate. The clock signal is typically sourced by a stable frequency source such as a crystal oscillator, either directly or via a clock divider. Depending on the application, a timer may output a signal that indicates timing status, or it may output the current count, or both. In the latter case, the count typically indicates either the elapsed or remaining time.\nEvent counters are typically used to count asynchronous events that may or may not occur at variable frequencies. At any particular time, the current count indicates the number of events that have occurred since event counting began.\nMemory addressing.\nBinary counters are used extensively in computers to generate memory addresses. In such applications, the counter output is typically connected to an address bus and used to sequentially select contiguous memory locations as the count increments or decrements. Widespread examples of this include program counters, direct memory access (DMA) controllers, and FIFO buffers. When used to hold data addresses during data transfer operations, a counter is commonly referred to as a \"memory address register\" (MAR).\nProgram counter.\nThe program counter (PC) in a central processing unit typically consists of a binary counter as shown in the following example:\nIn the above PC, the current count is the memory address of the next instruction to be executed. Upon processor reset, the count is zeroed so that execution will begin at address zero. When an instruction is fetched from memory, CE (count enable) is asserted to allow the counter to increment the count and thus advance to the next sequential instruction address. If it becomes necessary to switch execution to a different instruction sequence (e.g., due to executing a branch instruction, subroutine call, interrupt, or return from subroutine or interrupt), the address of the first instruction in the new sequence is applied to the Data inputs and Load is asserted; this overrides CE (if asserted) and copies Data to Count.\nFIFO.\nElectronic FIFO (First-In, First-Out) buffers are commonly used to interface data producing devices to data consumers that operate in different clock domains or which, over finite intervals, cannot consume data fast enough to avoid data loss.\nThe FIFO shown below employs two binary counters as memory address registers (MARs) for a dual-port RAM. Upon FIFO write, data word WDATA is written to RAM address WADDR and the Write MAR is incremented to prepare for the next write. Upon FIFO read, RDATA receives the data word stored at RAM address RADDR and the Read MAR is incremented. Except for the special case when the FIFO is full, the FIFO level (number of unread words in the FIFO) is equal to WADDR-RADDR.\nThis FIFO may be asynchronous or synchronous, meaning that read and write operations may take place in different clock domains or in a single, common clock domain, respectively. In the latter case, RCLK and WCLK are connected together.\nDMA controller.\nBinary counters are used in various ways in direct memory access (DMA) controllers. For example, counters similar to those shown below are utilized when copying a memory buffer via DMA. Two counters are employed as memory address registers (MARs) to generate source and destination addresses for the data to be copied. The MARs are typically bidirectional to allow data transfers to begin at the base or end address of a buffer. A third counter keeps track of the number of remaining words to be transferred.\nTo prepare for the DMA operation, the initial addresses are loaded into the MARs, the buffer size is loaded into the data transfer counter, and the count direction (typically stored in a flip-flop) is programmed for each MAR.\nWhen each word transfer completes, CE (count enable) is asserted on all counters, thus causing the MARs to advance to their next address and the remaining word count to decrement. When the remaining count reaches zero, the logic NOR of its bits switches high, thus signaling that the DMA operation has completed.\nTimers.\nOne-shot timer.\nIn digital electronics, a one-shot timer (or simply \"one-shot\") is a circuit that produces a single, precisely timed output pulse in response to an input trigger. The digital design allows for easy adjustment of pulse duration and provides high accuracy and repeatability compared to analog counterparts, making digital one-shots preferable for applications where timing accuracy is critical.\nThe one-shot timer shown below uses a binary down-counter to generate an output pulse of precisely controlled duration. The timer output is the logical OR of all bits in the current count, and consequently the output pulse is active while the timer is running (I.e., when the count is not zero). When the count reaches zero, the output pulse is terminated and counting is halted.\nTo start the timer running, a value representing the desired pulse width is applied to the counter's Data inputs and Load is asserted to trigger pulse generation. The pulse width is specified in terms of clock cycles. For example, in the case of a 1 MHz clock, a 100 microsecond output pulse has a duration of 100 clock cycles, as shown below:\nThe one-shot shown above is \"retriggerable\", meaning that it can be restarted by a subsequent trigger while running and thus stretch (extend the duration of) the output pulse. Conversely, the one-shot shown below is \"non-retriggerable\", meaning that it will ignore incoming triggers while the output pulse is active.\nPeriodic interval timer.\nBinary counters are commonly used as periodic interval timers (PITs), which output periodic pulses at an integer fraction of the clock frequency. PITs are used to generate system clock interrupts in computers, as clock dividers in phase lock loops and frequency synthesizers, and in many other applications.\nIn the circuit below, a binary down-counter is used to implement a PIT. The interval between output pulses, measured in clock cycles, is stored in the Interval register, resulting in output frequency formula_9. When the count reaches zero, the NOR gate issues a pulse on the timer output. The output pulse is also used internally to reload the interval into the counter, thus restarting the timer. Each output pulse has a duration of one clock cycle.\nFor example, to obtain a 1 MHz output frequency from a 6 MHz clock, the interval would be set to 5 as shown in the following timing diagram:\nPulse width modulator.\nBinary counters are an essential building block in digital pulse width modulators, which are commonly used to control motor speed, temperature, LED brightness, and other physical processes. These can be implemented in various ways. For example, the pulse width modulator shown below uses a single binary up-counter with synchronous reset to control both the width and frequency of output pulses:\nThe value stored in the PWM period register (formula_10) determines the output frequency. formula_11 increments at clock frequency formula_12 until it matches formula_10, which causes the identity comparator to strobe EndCycle, thus resetting the counter and starting the next output cycle. Consequently, the counter modulus is formula_14 and the output pulse frequency formula_15.\nformula_16 specifies the output pulse width in clock periods. The magnitude comparator asserts formula_17 while Count is less than formula_16, thus producing a pulse that starts at the beginning of the output cycle and ends when the count reaches formula_16. A flip-flop buffers formula_17 to prevent glitches from appearing on the PWM output due to static hazards.\nThe duty cycle is the percentage of PWM cycle time in which the pulse is active: formula_21. For example, the following diagram shows signal timing for formula_22 and formula_23, resulting in a 25 percent duty cycle at formula_24 Hertz.\nPulse width measurement.\nPulse width measurement is a common counter application that is used in a wide variety of equipment, including radar and sonar, industrial automation, and medical imaging systems. A typical circuit is shown below, which uses a binary up-counter to measure the widths of asynchronous (with respect to the counter clock) positive pulses.\nThe measured signal is first synchronized to the counter's clock domain, thus producing the synchronized input signal \"Clock gate\". This is done to prevent measurement errors due to metastability or violations of minimum setup or hold times in the counter and edge detector flip-flops.\nWhen a \"Clock gate\" pulse begins, the rising edge detector strobes \"Start\" to zero the count, and the counter then proceeds to count clock pulses while \"Clock gate\" remains active. When the pulse ends, the counter stops counting and the accumulated count indicates the measured pulse width in units of clock periods. The pulse width is formula_25 seconds, where formula_12 is the clock frequency in Hertz.\nA falling edge detector strobes \"End\" to indicate end of measurement, which can be used to signal external circuitry or transfer the count to external storage, or both, before the next measurement begins.\nFrequency counter.\nSome counter applications utilize multiple counters. An example of this is the frequency counter shown below, which uses two counters to measure the frequency of a digital signal. One counter, configured as a one-shot, produces a pulse of precisely controlled width known as the \"time gate\". The time gate is used to enable the clocking of an event counter, which is clocked by the signal whose frequency is to be measured.\nWhen a measurement begins (by asserting \"Start\"), the event counter is zeroed and then proceeds to count rising edges of the unknown frequency signal while the time gate remains active. When the time gate ends, edge counting stops and the accumulated count indicates the measured frequency. The count directly indicates the measured frequency in Hz when the gate time is one second; for other gate times, the count must be scaled to obtain Hz.\nAnalog-to-digital conversion.\nCounters are employed in various ways in analog-to-digital converter (ADC) circuits. For example, in a tracking ADC, a bidirectional binary counter is used to control the output voltage (formula_27) of a digital-to-analog converter. formula_27 is proportional to the count and thus increases or decreases, respectively, when the count is incremented or decremented.\nA voltage comparator outputs a bit indicating whether formula_27 is greater than ADC input voltage formula_30. This bit controls the count direction such that the count \u2014 and DAC voltage \u2014 will increase or decrease, respectively, when the formula_27 is less than or greater than formula_30, thus causing formula_27 to track formula_30. Since the count tracks formula_30 in near real time, it is directly used as ADC output data.\nPosition tracking.\nBidirectional binary counters are commonly used to track the physical position of moving objects that are monitored by incremental encoders, as shown in the example circuit below. A position change is indicated by a rising or falling edge on the encoder's A or B output signal. Each position change is associated with a well-defined distance formula_36, with the phase difference between A and B indicating the direction of travel (e.g., \"forward\" or \"reverse\"). The count is incremented or decremented when the object moves in the forward or reverse direction, respectively.\nTo begin tracking, the monitored object is located at a reference position (formula_37) and the count is zeroed. From that point on, the count indicates the current position in terms of displacement from the reference position, measured in formula_36 distance units: formula_39. The count is effectively a signed integer in cases where the object can move to either side of the reference position.\nStepped sinusoidal waveform generator.\nA sinusoidal voltage waveform can be approximated by cycling through the output states of a Johnson counter and summing the output voltages through a network of resistors which are weighted to map each counter state to a point in the cosine function:\nThe resulting sinusoidal waveform has frequency formula_40 for formula_1 flip-flops and a clock frequency of formula_42. Consequently, the sine wave frequency can be changed simply by changing the clock frequency.\nHarmonic distortion is reduced by increasing formula_1, which gives more steps and smaller step sizes in the sine wave; by increasing resistance accuracy; and by adding a capacitor or active filter to low-pass filter the edges of voltage steps.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "7648", "revid": "8066546", "url": "https://en.wikipedia.org/wiki?curid=7648", "title": "Calendar method", "text": ""}
{"id": "7649", "revid": "11840768", "url": "https://en.wikipedia.org/wiki?curid=7649", "title": "Cervical mucus method", "text": "Cervical mucus method may refer to a specific method of fertility awareness or natural family planning:\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "7651", "revid": "11009441", "url": "https://en.wikipedia.org/wiki?curid=7651", "title": "Coleridge (disambiguation)", "text": "Samuel Taylor Coleridge (1772\u20131834) was an English poet, literary critic, philosopher and theologian.\nColeridge may also refer to:\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "7652", "revid": "212624", "url": "https://en.wikipedia.org/wiki?curid=7652", "title": "Columbium", "text": ""}
{"id": "7653", "revid": "6212487", "url": "https://en.wikipedia.org/wiki?curid=7653", "title": "Civil rights history", "text": ""}
{"id": "7655", "revid": "51038920", "url": "https://en.wikipedia.org/wiki?curid=7655", "title": "Clay Mathematics Institute", "text": "American foundation\nThe Clay Mathematics Institute (CMI) is a private, non-profit foundation dedicated to increasing and disseminating mathematical knowledge. Formerly based in Peterborough, New Hampshire, the corporate address is now in Denver, Colorado. CMI's scientific activities are managed from the President's office in Oxford, United Kingdom. It gives out various awards and sponsorships to promising mathematicians. The institute was founded in 1998 through the sponsorship of Boston businessman Landon T. Clay. Harvard mathematician Arthur Jaffe was the first president of CMI.\nWhile the institute is best known for its Millennium Prize Problems, it carries out a wide range of activities, including conferences, workshops, summer schools, and a postdoctoral program supporting Clay Research Fellows.\nGovernance.\nThe institute is run according to a standard structure comprising a scientific advisory committee that decides on grant-awarding and research proposals, and a board of directors that oversees and approves the committee's decisions. As of September 2024[ [update]], the board is made up of members of the Clay family, whereas the scientific advisory committee is composed of Simon Donaldson, Michael Hopkins, Andrei Okounkov, Gigliola Staffilani, Andrew Wiles, and Martin R. Bridson. Bridson is the current president of CMI.\n2024 updates.\n2024 Clay Research Fellows.\nThe Clay Mathematics Institute has announced that Ishan Levy and Mehtaab Sawhney have been awarded the 2024 Clay Research Fellowships. Both are completing their PhDs at the Massachusetts Institute of Technology and started their five-year fellowships on July 1, 2024.\n2024 Clay Research Conference and Workshops.\nThe 2024 Clay Research Conference was held on October 2, 2024, at the Mathematical Institute, University of Oxford. The conference was accompanied by workshops from September 30 to October 4, 2024. Notable workshops include:\nAwards and recognitions.\nDaniel Graham from the University of Surrey won the Gold Medal for Mathematical Sciences at the 2024 STEM for Britain competition for his work on quantum authentication methods.\nMillennium Prize Problems.\nThe institute is best known for establishing the Millennium Prize Problems on May 24, 2000. These seven problems are considered by CMI to be \"important classic questions that have resisted solution over the years.\" For each problem, the first person to solve it will be awarded US$1,000,000 by the CMI. In announcing the prize, CMI drew a parallel to Hilbert's problems, which were proposed in 1900, and had a substantial impact on 20th century mathematics. Of the initial 23 Hilbert problems, most of which have been solved, only the Riemann hypothesis (formulated in 1859) is included in the seven Millennium Prize Problems.\nFor each problem, the Institute had a professional mathematician write up an official statement of the problem, which will be the main standard against which a given solution will be measured. The seven problems are:\nSome of the mathematicians who were involved in the selection and presentation of the seven problems were Michael Atiyah, Enrico Bombieri, Alain Connes, Pierre Deligne, Charles Fefferman, John Milnor, David Mumford, Andrew Wiles, and Edward Witten.\nOther awards.\nThe Clay Research Award.\nIn recognition of major breakthroughs in mathematical research, the institute has an annual prize \u2013 the Clay Research Award. Its recipients to date are Ian Agol, Manindra Agrawal, Yves Benoist, Manjul Bhargava, Tristan Buckmaster, Danny Calegari, Alain Connes, Nils Dencker, Alex Eskin, David Gabai, Ben Green, Mark Gross, Larry Guth, Christopher Hacon, Richard S. Hamilton, Michael Harris, Philip Isett, Jeremy Kahn, Nets Katz, Laurent Lafforgue, G\u00e9rard Laumon, Aleksandr Logunov, Eugenia Malinnikova, Vladimir Markovic, James McKernan, Jason Miller, Maryam Mirzakhani, Ng\u00f4 B\u1ea3o Ch\u00e2u, Rahul Pandharipande, Jonathan Pila, Jean-Fran\u00e7ois Quint, Peter Scholze, Oded Schramm, Scott Sheffield, Bernd Siebert, Stanislav Smirnov, Terence Tao, Clifford Taubes, Richard Taylor, Maryna Viazovska, Vlad Vicol, Claire Voisin, Jean-Loup Waldspurger, Andrew Wiles, Geordie Williamson, Edward Witten and Wei Zhang.\nOther activities.\nBesides the Millennium Prize Problems, the Clay Mathematics Institute supports mathematics via the awarding of research fellowships (which range from two to five years and are aimed at younger mathematicians), as well as shorter-term scholarships for programs, individual research, and book writing. The institute also has a yearly Clay Research Award, recognizing major breakthroughs in mathematical research. Finally, the institute organizes a number of summer schools, conferences, workshops, public lectures, and outreach activities aimed primarily at junior mathematicians (from the high school to the postdoctoral level). CMI publications are available in PDF form at most six months after they appear in print.\nExternal links.\n\"This article incorporates material from Millennium Problems on PlanetMath, which is licensed under the .\""}
{"id": "7658", "revid": "35107032", "url": "https://en.wikipedia.org/wiki?curid=7658", "title": "Centum", "text": ""}
{"id": "7659", "revid": "20483999", "url": "https://en.wikipedia.org/wiki?curid=7659", "title": "Cerebral arteriovenous malformation", "text": "Abnormal connection between the arteries and veins in the brain\nMedical condition&lt;templatestyles src=\"Template:Infobox/styles-images.css\" /&gt;\nA cerebral arteriovenous malformation (cerebral AVM, CAVM, cAVM, brain AVM, or BAVM) is an abnormal connection between the arteries and veins in the brain\u2014specifically, an arteriovenous malformation in the cerebrum.\nSigns and symptoms.\nThe most frequently observed problems related to a cerebral arteriovenous malformation (AVM) are headaches and seizures, cranial nerve afflictions including pinched nerve and palsy, backaches, neckaches, and nausea from coagulated blood that has made its way down to be dissolved in the cerebrospinal fluid. Perhaps 15% of the population at detection are asymptomatic. Other common symptoms are a pulsing noise in the head, progressive weakness, numbness and vision changes as well as debilitating, excruciating pain.\nIn serious cases, blood vessels rupture and cause bleeding within the brain (intracranial hemorrhage). In more than half of patients with AVM, this is the first symptom. Symptoms due to bleeding include loss of consciousness, sudden and severe headache, nausea, vomiting, incontinence, and blurred vision, amongst others. Impairments caused by local brain-tissue damage on the bleed site are also possible, including seizure, one-sided weakness (hemiparesis), a loss of touch sensation on one side of the body and deficits in language processing (aphasia). Ruptured AVMs are responsible for considerable mortality and morbidity.\nAVMs in certain critical locations may stop the circulation of the cerebrospinal fluid, causing it to accumulate within the skull and giving rise to a clinical condition called hydrocephalus. A stiff neck can occur as the result of increased pressure within the skull and irritation of the meninges.\nPathophysiology.\nA cerebral AVM is an abnormal anastomosis (connection) between the arteries and veins in the brain due to the lack of a capillary bed, and is most commonly of prenatal origin.\nIn normal cerebral circulation, oxygen-enriched blood from the heart travels in sequence through smaller blood vessels going from arteries, to arterioles and then capillaries. Oxygen is removed in the capillaries to be used by the brain. After the oxygen is removed, blood reaches venules and later veins which will take it back to the heart and lungs. A cerebral AVM causes blood to be shunted directly from arteries to veins because the capillary bed is lacking, causing a disrupted circulation.\nThe overall annual incidence of haemorrhage from a ruptured AVM is 2-4%. Smaller AVMs have a greater propensity for haemorrhaging, whereas larger AVMs tend to more often cause seizures instead.\nDiagnosis.\nA cerebral AVM diagnosis is established by neuroimaging studies after a complete neurological and physical examination. Three main techniques are used to visualize the brain and search for an AVM: computed tomography (CT), magnetic resonance imaging (MRI), and cerebral angiography. A CT scan of the head is usually performed first when the subject is symptomatic. It can suggest the approximate site of the bleed. MRI is more sensitive than CT in the diagnosis, and provides better information about the exact location of the malformation. More detailed pictures of the tangle of blood vessels that compose an AVM can be obtained by using radioactive agents injected into the blood stream. If a CT is used in conjunction with an angiogram, this is called a computerized tomography angiogram; while, if MRI is used it is called magnetic resonance angiogram. The best images of a cerebral AVM are obtained through cerebral angiography. This procedure involves using a catheter, threaded through an artery up to the head, to deliver a contrast agent into the AVM. As the contrast agent flows through the AVM structure, a sequence of X-ray images are obtained.\nGrading.\nSpetzler-Martin (SM) Grade.\nA common method of grading cerebral AVMs is the Spetzler-Martin (SM) grade. This system was designed to assess the patient's risk of neurological deficit after open surgical resection (surgical morbidity), based on characteristics of the AVM itself. Based on this system, AVMs may be classified as grades 1\u20135. This system was not intended to characterize risk of hemorrhage.\n\"Eloquent\" is defined as areas within the brain that, if removed will result in loss of sensory processing or linguistic ability, minor paralysis, or paralysis. These include the basal ganglia, language cortices, sensorimotor regions, and white matter tracts. Importantly, eloquent areas are often defined differently across studies where deep cerebellar nuclei, cerebral peduncles, thalamus, hypothalamus, internal capsule, brainstem, and the visual cortex could be included.\nThe risk of post-surgical neurological deficit (difficulty with language, motor weakness, vision loss) increases with increasing Spetzler-Martin grade.\nSupplemented Spetzler-Martin (SM-supp, Lawton-Young) Grade.\nA limitation of the Spetzler-Martin Grading system is that it does not include the following factors: Patient age, hemorrhage, diffuseness of nidus, and arterial supply. In 2010 a new supplemented Spetzler-Martin system (SM-supp, Lawton-Young) was devised adding these variables to the SM system. Under this new system AVMs are classified from grades 1\u201310. It has since been determined to have greater predictive accuracy than SM grades alone.\nTreatment.\nTreatment depends on the location and size of the AVM and whether there is bleeding or not.\nThe treatment in the case of sudden bleeding is focused on restoration of vital function.\nMedical.\nAnticonvulsant medications such as phenytoin are often used to control seizure; medications or procedures may be employed to relieve intracranial pressure. Eventually, curative treatment may be required to prevent recurrent hemorrhage. However, any type of intervention may also carry a risk of creating a neurological deficit.\nSurgical.\nSurgical elimination of the blood vessels involved is the preferred curative treatment for many types of AVM. Surgery is performed by a neurosurgeon who temporarily removes part of the skull (craniotomy), separates the AVM from surrounding brain tissue, and resects the abnormal vessels. While surgery can result in an immediate, complete removal of the AVM, risks exist depending on the size and the location of the malformation. The AVM must be resected en bloc, for partial resection will likely cause severe hemorrhage. The preferred treatment of Spetzler-Martin grade 1 and 2 AVMs in young, healthy patients is surgical resection due to the relatively small risk of neurological damage compared to the high lifetime risk of hemorrhage. Grade 3 AVMs may or may not be amenable to surgery. Grade 4 and 5 AVMs are not usually surgically treated.\nRadiosurgical.\nRadiosurgery has been widely used on small AVMs with considerable success. The Gamma Knife is an apparatus used to precisely apply a controlled radiation dosage to the volume of the brain occupied by the AVM. While this treatment does not require an incision and craniotomy (with their own inherent risks), three or more years may pass before the complete effects are known, during which time patients are at risk of bleeding. Complete obliteration of the AVM may or may not occur after several years, and repeat treatment may be needed. Radiosurgery is itself not without risk. In one large study, nine percent of patients had transient neurological symptoms, including headache, after radiosurgery for AVM. However, most symptoms resolved, and the long-term rate of neurological symptoms was 3.8%.\nNeuroendovascular therapy.\nEmbolization is performed by interventional neuroradiologists and the occlusion of blood vessels most commonly is obtained with ethylene vinyl alcohol copolymer (Onyx) or n-butyl cyanoacrylate. These substances are introduced by a radiographically guided catheter, and block vessels responsible for blood flow into the AVM. Embolization is frequently used as an adjunct to either surgery or radiation treatment. Embolization reduces the size of the AVM and during surgery it reduces the risk of bleeding. However, embolization alone may completely obliterate some AVMs. In high flow intranidal fistulas balloons can also be used to reduce the flow so that embolization can be done safely.\nRisks.\nA first-of-its-kind controlled clinical trial by the National Institutes of Health and National Institute of Neurological Disorders and Stroke focuses on the risk of stroke or death in patients with an AVM who either did or did not undergo interventional eradication. Early results suggest that the invasive treatment of unruptured AVMs tends to yield worse results than the therapeutic (medical) management of symptoms. Because of the higher-than-expected experimental event rate (e.g. stroke or death), patient enrollment was halted by May 2013, while the study intended to follow participants (over a planned 5 to 10 years) to determine which approach seems to produce better long-term results.\nPrognosis.\nThe main risk is intracranial hemorrhage. This risk is difficult to quantify since many patients with asymptomatic AVMs will never come to medical attention. Small AVMs tend to bleed more often than do larger ones, the opposite of cerebral aneurysms. If a rupture or bleeding incident occurs, the blood may penetrate either into the brain tissue (cerebral hemorrhage) or into the subarachnoid space, which is located between the sheaths (meninges) surrounding the brain (subarachnoid hemorrhage). Bleeding may also extend into the ventricular system (intraventricular hemorrhage). Cerebral hemorrhage appears to be most common.\nOne long-term study (mean follow up greater than 20 years) of over 150 symptomatic AVMs (either presenting with bleeding or seizures) found the risk of cerebral hemorrhage to be approximately 4% per year, slightly higher than the 2\u20134% seen in other studies. The earlier an AVM appears, the more likely it is to cause hemorrhage over one's lifetime; e.g. (assuming a 3% annual risk), an AVM appearing at 25 years of age indicates a 79% lifetime chance of hemorrhage, while one appearing at age 85 indicates only a 17% chance. Ruptured AVMs are a significant source of morbidity and mortality; following a rupture, as many as 29% of patients will die, with only 55% able to live independently.\nEpidemiology.\nThe annual new detection rate incidence of AVMs is approximately 1 per 100,000 a year. The point prevalence in adults is approximately 18 per 100,000. AVMs are more common in males than females, although in females pregnancy may start or worsen symptoms due to the increase in blood flow and volume it usually brings. There is a significant preponderance (15\u201320%) of AVM in patients with hereditary hemorrhagic telangiectasia (Osler\u2013Weber\u2013Rendu syndrome).\nReferences.\nFootnotes\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nCitations\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "7660", "revid": "1326640", "url": "https://en.wikipedia.org/wiki?curid=7660", "title": "Comparative method", "text": "Technique for studying the historical development of languages, based on language comparison\nIn linguistics, the comparative method is a technique for studying the development of languages by performing a feature-by-feature comparison of two or more languages with common descent from a shared ancestor and then extrapolating backwards to infer the properties of that ancestor. The comparative method may be contrasted with the method of internal reconstruction in which the internal development of a single language is inferred by the analysis of features within that language. Ordinarily, both methods are used together to reconstruct prehistoric phases of languages; to fill in gaps in the historical record of a language; to discover the development of phonological, morphological and other linguistic systems and to confirm or to refute hypothesised relationships between languages.\nThe comparative method emerged in the early 19th century with the birth of Indo-European studies, then took a definite scientific approach with the works of the Neogrammarians in the late 19th\u2013early 20th century. Key contributions were made by the Danish scholars Rasmus Rask (1787\u20131832) and Karl Verner (1846\u20131896), and the German scholar Jacob Grimm (1785\u20131863). The first linguist to offer reconstructed forms from a proto-language was August Schleicher (1821\u20131868) in his \"Compendium der vergleichenden Grammatik der indogermanischen Sprachen\", originally published in 1861. Here is Schleicher's explanation of why he offered reconstructed forms:\nIn the present work an attempt is made to set forth the inferred Indo-European original language side by side with its really existent derived languages. Besides the advantages offered by such a plan, in setting immediately before the eyes of the student the final results of the investigation in a more concrete form, and thereby rendering easier his insight into the nature of particular Indo-European languages, there is, I think, another of no less importance gained by it, namely that it shows the baselessness of the assumption that the non-Indian Indo-European languages were derived from Old-Indian (Sanskrit).\nDefinition.\nPrinciples.\nThe aim of the comparative method is to highlight and interpret systematic phonological and semantic correspondences between two or more attested languages. If those correspondences cannot be rationally explained as the result of linguistic universals or language contact (borrowings, areal influence, etc.), and if they are sufficiently numerous, regular, and systematic that they cannot be dismissed as chance similarities, then it must be assumed that they descend from a single parent language called the 'proto-language'.\nA sequence of regular sound changes (along with their underlying sound laws) can then be postulated to explain the correspondences between the attested forms, which eventually allows for the reconstruction of a proto-language by the methodical comparison of \"linguistic facts\" within a generalized system of correspondences.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Every linguistic fact is part of a whole in which everything is connected to everything else. One detail must not be linked to another detail, but one linguistic system to another.\u2014\u200a\nRelation is considered to be \"established beyond a reasonable doubt\" if a reconstruction of the common ancestor is feasible.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The ultimate proof of genetic relationship, and to many linguists' minds the only real proof, lies in a successful reconstruction of the ancestral forms from which the semantically corresponding cognates can be derived.\u2014\u200aIn some cases, this reconstruction can only be partial, generally because the compared languages are too scarcely attested, the temporal distance between them and their proto-language is too deep, or their internal evolution render many of the sound laws obscure to researchers. In such case, a relation is considered plausible, but uncertain.\nTerminology.\n\"Descent\" is defined as transmission across the generations: children learn a language from the parents' generation and, after being influenced by their peers, transmit it to the next generation, and so on. For example, a continuous chain of speakers across the centuries links Vulgar Latin to all of its modern descendants.\nTwo languages are \"genetically related\" if they descended from the same ancestor language. For example, Italian and French both come from Latin and therefore belong to the same family, the Romance languages. Having a large component of vocabulary from a certain origin is not sufficient to establish relatedness; for example, heavy borrowing from Arabic into Persian has caused more of the vocabulary of Modern Persian to be from Arabic than from the direct ancestor of Persian, Proto-Indo-Iranian, but Persian remains a member of the Indo-Iranian family and is not considered \"related\" to Arabic.\nHowever, it is possible for languages to have different degrees of relatedness. English, for example, is related to both German and Russian but is more closely related to the former than to the latter. Although all three languages share a common ancestor, Proto-Indo-European, English and German also share a more recent common ancestor, Proto-Germanic, but Russian does not. Therefore, English and German are considered to belong to a subgroup of Indo-European that Russian does not belong to, the Germanic languages.\nThe division of related languages into subgroups is accomplished by finding \"shared linguistic innovations\" that differentiate them from the parent language. For instance, English and German both exhibit the effects of a collection of sound changes known as Grimm's Law, which Russian was not affected by. The fact that English and German share this innovation is seen as evidence of English and German's more recent common ancestor\u2014since the innovation actually took place within that common ancestor, before English and German diverged into separate languages. On the other hand, \"shared retentions\" from the parent language are not sufficient evidence of a sub-group. For example, German and Russian both retain from Proto-Indo-European a contrast between the dative case and the accusative case, which English has lost. However, that similarity between German and Russian is not evidence that German is more closely related to Russian than to English but means only that the \"innovation\" in question, the loss of the accusative/dative distinction, happened more recently in English than the divergence of English from German.\nOrigin and development.\nIn classical antiquity, Romans were aware of the similarities between Greek and Latin, but did not study them systematically. They sometimes explained them mythologically, as the result of Rome being a Greek colony speaking a debased dialect.\nEven though grammarians of Antiquity had access to other languages around them (Oscan, Umbrian, Etruscan, Gaulish, Egyptian, Parthian...), they showed little interest in comparing, studying, or just documenting them. Comparison between languages really began after classical antiquity.\nEarly works.\nIn the 9th or 10th century AD, Yehuda Ibn Quraysh compared the phonology and morphology of Hebrew, Aramaic and Arabic but attributed the resemblance to the Biblical story of Babel, with Abraham, Isaac and Joseph retaining Adam's language, with other languages at various removes becoming more altered from the original Hebrew.\nIn publications of 1647 and 1654, Marcus Zuerius van Boxhorn first described a rigorous methodology for historical linguistic comparisons and proposed the existence of an Indo-European proto-language, which he called \"Scythian\", unrelated to Hebrew but ancestral to Germanic, Greek, Romance, Persian, Sanskrit, Slavic, Celtic and Baltic languages. The Scythian theory was further developed by Andreas J\u00e4ger (1686) and William Wotton (1713), who made early forays to reconstruct the primitive common language. In 1710 and 1723, Lambert ten Kate first formulated the regularity of sound laws, introducing among others the term root vowel.\nAnother early systematic attempt to prove the relationship between two languages on the basis of similarity of grammar and lexicon was made by the Hungarian J\u00e1nos Sajnovics in 1770, when he attempted to demonstrate the relationship between Sami and Hungarian. That work was later extended to all Finno-Ugric languages in 1799 by his countryman Samuel Gyarmathi. However, the origin of modern historical linguistics is often traced back to Sir William Jones, an English philologist living in India, who in 1786 made his famous observation:The Sanscrit language, whatever be its antiquity, is of a wonderful structure; more perfect than the Greek, more copious than the Latin, and more exquisitely refined than either, yet bearing to both of them a stronger affinity, both in the roots of verbs and the forms of grammar, than could possibly have been produced by accident; so strong indeed, that no philologer could examine them all three, without believing them to have sprung from some common source, which, perhaps, no longer exists. There is a similar reason, though not quite so forcible, for supposing that both the Gothick and the Celtick, though blended with a very different idiom, had the same origin with the Sanscrit; and the old Persian might be added to the same family.\nComparative linguistics.\nThe comparative method developed out of attempts to reconstruct the proto-language mentioned by Jones, which he did not name but subsequent linguists have labelled Proto-Indo-European (PIE). The first professional comparison between the Indo-European languages that were then known was made by the German linguist Franz Bopp in 1816. He did not attempt a reconstruction but demonstrated that Greek, Latin and Sanskrit shared a common structure and a common lexicon. In 1808, Friedrich Schlegel first stated the importance of using the eldest possible form of a language when trying to prove its relationships; in 1818, Rasmus Christian Rask developed the principle of regular sound-changes to explain his observations of similarities between individual words in the Germanic languages and their cognates in Greek and Latin. Jacob Grimm, better known for his \"Fairy Tales\", used the comparative method in \"Deutsche Grammatik\" (published 1819\u20131837 in four volumes), which attempted to show the development of the Germanic languages from a common origin, which was the first systematic study of diachronic language change.\nBoth Rask and Grimm were unable to explain apparent exceptions to the sound laws that they had discovered. Although Hermann Grassmann explained one of the anomalies with the publication of Grassmann's law in 1862, Karl Verner made a methodological breakthrough in 1875, when he identified a pattern now known as Verner's law, the first sound-law based on comparative evidence showing that a phonological change in one phoneme could depend on other factors within the same word (such as neighbouring phonemes and the position of the accent), which are now called \"conditioning environments\".\nNeo-grammarian approach.\nSimilar discoveries made by the \"Junggrammatiker\" (usually translated as \"Neogrammarians\") at the University of Leipzig in the late 19th century led them to conclude that all sound changes were ultimately regular, resulting in the famous statement by Karl Brugmann and Hermann Osthoff in 1878 that \"sound laws have no exceptions\". That idea is fundamental to the modern comparative method since it necessarily assumes regular correspondences between sounds in related languages and thus regular sound changes from the proto-language. The \"Neogrammarian hypothesis\" led to the application of the comparative method to reconstruct Proto-Indo-European since Indo-European was then by far the most well-studied language family. Linguists working with other families soon followed suit, and the comparative method quickly became the established method for uncovering linguistic relationships.\nApplication.\nThere is no fixed set of steps to be followed in the application of the comparative method, but some steps are suggested by Lyle Campbell and Terry Crowley, who are both authors of introductory texts in historical linguistics. This abbreviated summary is based on their concepts of how to proceed.\nStep 1, assemble potential cognate lists.\nThis step involves making lists of words that are likely cognates among the languages being compared. If there is a regularly-recurring match between the phonetic structure of basic words with similar meanings, a genetic kinship can probably then be established. For example, linguists looking at the Polynesian family might come up with a list similar to the following (their actual list would be much longer):\nBorrowings or false cognates can skew or obscure the correct data. For example, English \"taboo\" () is like the six Polynesian forms because of borrowing from Tongan into English, not because of a genetic similarity. That problem can usually be overcome by using basic vocabulary, such as kinship terms, numbers, body parts and pronouns. Nonetheless, even basic vocabulary can be sometimes borrowed. Finnish, for example, borrowed the word for \"mother\", , from Proto-Germanic *ai\u00fe\u012f\u0304 (compare to Gothic ). English borrowed the pronouns \"they\", \"them\", and \"their(s)\" from Norse. Thai and various other East Asian languages borrowed their numbers from Chinese. An extreme case is represented by Pirah\u00e3, a Muran language of South America, which has been controversially claimed to have borrowed all of its pronouns from Nheengatu.\nStep 2, establish correspondence sets.\nThe next step involves determining the regular sound-correspondences exhibited by the lists of potential cognates. For example, in the Polynesian data above, it is apparent that words that contain \"t\" in most of the languages listed have cognates in Hawaiian with \"k\" in the same position. That is visible in multiple cognate sets: the words glossed as 'one', 'three', 'man' and 'taboo' all show the relationship. The situation is called a \"regular correspondence\" between \"k\" in Hawaiian and \"t\" in the other Polynesian languages. Similarly, a regular correspondence can be seen between Hawaiian and Rapanui \"h\", Tongan and Samoan \"f\", Maori \"\u0278\", and Rarotongan \"\u0294\".\nMere phonetic similarity, as between English \"day\" and Latin (both with the same meaning), has no probative value. English initial \"d-\" does not \"regularly\" match Latin \"d-\" since a large set of English and Latin non-borrowed cognates cannot be assembled such that English \"d\" repeatedly and consistently corresponds to Latin \"d\" at the beginning of a word, and whatever sporadic matches can be observed are due either to chance (as in the above example) or to borrowing (for example, Latin and English \"devil\", both ultimately of Greek origin). However, English and Latin exhibit a regular correspondence of \"t-\" : \"d-\" (in which \"A : B\" means \"A corresponds to B\"), as in the following examples:\nIf there are many regular correspondence sets of this kind (the more, the better), a common origin becomes a virtual certainty, particularly if some of the correspondences are non-trivial or unusual.\nStep 3, discover which sets are in complementary distribution.\nDuring the late 18th to late 19th century, two major developments improved the method's effectiveness.\nFirst, it was found that many sound changes are conditioned by a specific \"context\". For example, in both Greek and Sanskrit, an aspirated stop evolved into an unaspirated one, but only if a second aspirate occurred later in the same word; this is Grassmann's law, first described for Sanskrit by Sanskrit grammarian P\u0101\u1e47ini and promulgated by Hermann Grassmann in 1863.\nSecond, it was found that sometimes sound changes occurred in contexts that were later lost. For instance, in Sanskrit velars (\"k\"-like sounds) were replaced by palatals (\"ch\"-like sounds) whenever the following vowel was \"*i\" or \"*e\". Subsequent to this change, all instances of \"*e\" were replaced by \"a\". The situation could be reconstructed only because the original distribution of \"e\" and \"a\" could be recovered from the evidence of other Indo-European languages. For instance, the Latin suffix , \"and\", preserves the original \"*e\" vowel that caused the consonant shift in Sanskrit:\nVerner's Law, discovered by Karl Verner c. 1875, provides a similar case: the voicing of consonants in Germanic languages underwent a change that was determined by the position of the old Indo-European accent. Following the change, the accent shifted to initial position. Verner solved the puzzle by comparing the Germanic voicing pattern with Greek and Sanskrit accent patterns.\nThis stage of the comparative method, therefore, involves examining the correspondence sets discovered in step 2 and seeing which of them apply only in certain contexts. If two (or more) sets apply in complementary distribution, they can be assumed to reflect a single original phoneme: \"some sound changes, particularly conditioned sound changes, can result in a proto-sound being associated with more than one correspondence set\".\nFor example, the following potential cognate list can be established for Romance languages, which descend from Latin:\nThey evidence two correspondence sets, \"k : k\" and \"k : \":\nSince French \"\" occurs only before \"a\" where the other languages also have \"a\", and French \"k\" occurs elsewhere, the difference is caused by different environments (being before \"a\" conditions the change), and the sets are complementary. They can, therefore, be assumed to reflect a single proto-phoneme (in this case \"*k\", spelled \u27e8c\u27e9 in Latin). The original Latin words are , , and , all with an initial \"k\". If more evidence along those lines were given, one might conclude that an alteration of the original \"k\" took place because of a different environment.\nA more complex case involves consonant clusters in Proto-Algonquian. The Algonquianist Leonard Bloomfield used the reflexes of the clusters in four of the daughter languages to reconstruct the following correspondence sets:\nAlthough all five correspondence sets overlap with one another in various places, they are not in complementary distribution and so Bloomfield recognised that a different cluster must be reconstructed for each set. His reconstructions were, respectively, \"*hk\", \"*xk\", \"*\u010dk\" (=), \"*\u0161k\" (=), and \"\u00e7k\" (in which '\"x\"' and '\"\u00e7\"' are arbitrary symbols, rather than attempts to guess the phonetic value of the proto-phonemes).\nStep 4, reconstruct proto-phonemes.\nTypology assists in deciding what reconstruction best fits the data. For example, the voicing of voiceless stops between vowels is common, but the devoicing of voiced stops in that environment is rare. If a correspondence \"-t-\" : \"-d-\" between vowels is found in two languages, the proto-phoneme is more likely to be \"*-t-\", with a development to the voiced form in the second language. The opposite reconstruction would represent a rare type.\nHowever, unusual sound changes occur. The Proto-Indo-European word for \"two\", for example, is reconstructed as \"*dw\u014d\", which is reflected in Classical Armenian as \"erku\". Several other cognates demonstrate a regular change \"*dw-\" \u2192 \"erk-\" in Armenian. Similarly, in Bearlake, a dialect of the Athabaskan language of Slavey, there has been a sound change of Proto-Athabaskan \"*ts\" \u2192 Bearlake '. It is very unlikely that \"*dw-\" changed directly into \"erk-\" and \"*ts\" into ', but they probably instead went through several intermediate steps before they arrived at the later forms. It is not phonetic similarity that matters for the comparative method but rather regular sound correspondences.\nBy the principle of economy, the reconstruction of a proto-phoneme should require as few sound changes as possible to arrive at the modern reflexes in the daughter languages. For example, Algonquian languages exhibit the following correspondence set:\nThe simplest reconstruction for this set would be either \"*m\" or \"*b\". Both \"*m\" \u2192 \"b\" and \"*b\" \u2192 \"m\" are likely. Because \"m\" occurs in five of the languages and \"b\" in only one of them, if \"*b\" is reconstructed, it is necessary to assume five separate changes of \"*b\" \u2192 \"m\", but if \"*m\" is reconstructed, it is necessary to assume only one change of \"*m\" \u2192 \"b\" and so \"*m\" would be most economical.\nThat argument assumes the languages other than Arapaho to be at least partly independent of one another. If they all formed a common subgroup, the development \"*b\" \u2192 \"m\" would have to be assumed to have occurred only once.\nStep 5, examine the reconstructed system typologically.\nIn the final step, the linguist checks to see how the proto-phonemes fit the known typological constraints. For example, a hypothetical system,\nhas only one voiced stop, \"*b\", and although it has an alveolar and a velar nasal, \"*n\" and \"*\u014b\", there is no corresponding labial nasal. However, languages generally maintain symmetry in their phonemic inventories. In this case, a linguist might attempt to investigate the possibilities that either what was earlier reconstructed as \"*b\" is in fact \"*m\" or that the \"*n\" and \"*\u014b\" are in fact \"*d\" and \"*g\".\nEven a symmetrical system can be typologically suspicious. For example, here is the traditional Proto-Indo-European stop inventory:\nAn earlier voiceless aspirated row was removed on grounds of insufficient evidence. Since the mid-20th century, a number of linguists have argued that this phonology is implausible and that it is extremely unlikely for a language to have a voiced aspirated (breathy voice) series without a corresponding voiceless aspirated series.\nThomas Gamkrelidze and Vyacheslav Ivanov provided a potential solution and argued that the series that are traditionally reconstructed as plain voiced should be reconstructed as glottalized: either implosive or ejective . The plain voiceless and voiced aspirated series would thus be replaced by just voiceless and voiced, with aspiration being a non-distinctive quality of both. That example of the application of linguistic typology to linguistic reconstruction has become known as the glottalic theory. It has a large number of proponents but is not generally accepted.\nThe reconstruction of proto-sounds logically precedes the reconstruction of grammatical morphemes (word-forming affixes and inflectional endings), patterns of declension and conjugation and so on. The full reconstruction of an unrecorded protolanguage is an open-ended task.\nComplications.\nThe history of historical linguistics.\nThe limitations of the comparative method were recognized by the very linguists who developed it, but it is still seen as a valuable tool. In the case of Indo-European, the method seemed at least a partial validation of the centuries-old search for an Ursprache, the original language. The others were presumed to be ordered in a family tree, which was the tree model of the neogrammarians.\nThe archaeologists followed suit and attempted to find archaeological evidence of a culture or cultures that could be presumed to have spoken a proto-language, such as Vere Gordon Childe's \"The Aryans: a study of Indo-European origins\", 1926. Childe was a philologist turned archaeologist. Those views culminated in the \"Siedlungsarchaologie\", or \"settlement-archaeology\", of Gustaf Kossinna, becoming known as \"Kossinna's Law\". Kossinna asserted that cultures represent ethnic groups, including their languages, but his law was rejected after World War II. The fall of Kossinna's Law removed the temporal and spatial framework previously applied to many proto-languages. Fox concludes:\nThe Comparative Method \"as such\" is not, in fact, historical; it provides evidence of linguistic relationships to which we may give a historical interpretation... [Our increased knowledge about the historical processes involved] has probably made historical linguists less prone to equate the idealizations required by the method with historical reality... Provided we keep [the interpretation of the results and the method itself] apart, the Comparative Method can continue to be used in the reconstruction of earlier stages of languages.\nProto-languages can be verified in many historical instances, such as Latin. Although no longer a law, settlement-archaeology is known to be essentially valid for some cultures that straddle history and prehistory, such as the Celtic Iron Age (mainly Celtic) and Mycenaean civilization (mainly Greek). None of those models can be or have been completely rejected, but none is sufficient alone.\nThe Neogrammarian principle.\nThe foundation of the comparative method, and of comparative linguistics in general, is the Neogrammarians' fundamental assumption that \"sound laws have no exceptions\". When it was initially proposed, critics of the Neogrammarians proposed an alternate position that summarised by the maxim \"each word has its own history\". Several types of change actually alter words in irregular ways. Unless identified, they may hide or distort laws and cause false perceptions of relationship.\nBorrowing.\nAll languages borrow words from other languages in various contexts. Loanwords imitate the form of the donor language, as in Finnic \"kuningas\", from Proto-Germanic *\"kuningaz\" ('king'), with possible adaptations to the local phonology, as in Japanese \"sakk\u0101\", from English \"soccer\". At first sight, borrowed words may mislead the investigator into seeing a genetic relationship, although they can more easily be identified with information on the historical stages of both the donor and receiver languages. Inherently, words that were borrowed from a common source (such as English \"coffee\" and Basque \"kafe\", ultimately from Arabic \"qahwah\") do share a genetic relationship, although limited to the history of this word.\nAreal diffusion.\nBorrowing on a larger scale occurs in areal diffusion, when features are adopted by contiguous languages over a geographical area. The borrowing may be phonological, morphological or lexical. A false proto-language over the area may be reconstructed for them or may be taken to be a third language serving as a source of diffused features.\nSeveral areal features and other influences may converge to form a Sprachbund, a wider region sharing features that appear to be related but are diffusional. For instance, the Mainland Southeast Asia linguistic area, before it was recognised, suggested several false classifications of such languages as Chinese, Thai and Vietnamese.\nRandom mutations.\nSporadic changes, such as irregular inflections, compounding and abbreviation, do not follow any laws. For example, the Spanish words \"palabra\" ('word'), \"peligro\" ('danger') and \"milagro\" ('miracle') would have been \"parabla\", \"periglo\", \"miraglo\" by regular sound changes from the Latin \"parab\u014fla\", \"per\u012bc\u016dlum\" and \"m\u012br\u0101c\u016dlum\", but the \"r\" and \"l\" changed places by sporadic metathesis.\nAnalogy.\nAnalogy is the sporadic change of a feature to be like another feature in the same or a different language. It may affect a single word or be generalized to an entire class of features, such as a verb paradigm. An example is the Russian word for \"nine\". The word, by regular sound changes from Proto-Slavic, should have been , but it is in fact . It is believed that the initial ' changed to ' under influence of the word for \"ten\" in Russian, .\nGradual application.\nThose who study contemporary language changes, such as William Labov, acknowledge that even a systematic sound change is applied at first inconsistently, with the percentage of its occurrence in a person's speech dependent on various social factors. The sound change seems to gradually spread in a process known as lexical diffusion. While it does not invalidate the Neogrammarians' axiom that \"sound laws have no exceptions\", the gradual application of the very sound laws shows that they do not always apply to all lexical items at the same time. Hock notes, \"While it probably is true in the long run every word has its own history, it is not justified to conclude as some linguists have, that therefore the Neogrammarian position on the nature of linguistic change is falsified\".\nNon-inherited features.\nThe comparative method cannot recover aspects of a language that were not inherited in its daughter idioms. For instance, the Latin declension pattern was lost in Romance languages, resulting in an impossibility to fully reconstruct such a feature via systematic comparison.\nThe tree model.\nThe comparative method is used to construct a tree model (German \"Stammbaum\") of language evolution, in which daughter languages are seen as branching from the proto-language, gradually growing more distant from it through accumulated phonological, morpho-syntactic, and lexical changes.\nThe presumption of a well-defined node.\nThe tree model features nodes that are presumed to be distinct proto-languages existing independently in distinct regions during distinct historical times. The reconstruction of unattested proto-languages lends itself to that illusion since they cannot be verified, and the linguist is free to select whatever definite times and places seems best. Right from the outset of Indo-European studies, however, Thomas Young said:It is not, however, very easy to say what the definition should be that should constitute a separate language, but it seems most natural to call those languages distinct, of which the one cannot be understood by common persons in the habit of speaking the other... Still, however, it may remain doubtfull whether the Danes and the Swedes could not, in general, understand each other tolerably well... nor is it possible to say if the twenty ways of pronouncing the sounds, belonging to the Chinese characters, ought or ought not to be considered as so many languages or dialects... But... the languages so nearly allied must stand next to each other in a systematic order\u2026\nThe assumption of uniformity in a proto-language, implicit in the comparative method, is problematic. Even small language communities always have differences in dialect, whether they are based on area, gender, class or other factors. The Pirah\u00e3 language of Brazil is spoken by only several hundred people but has at least two different dialects, one spoken by men and one by women. Campbell points out:\nIt is not so much that the comparative method 'assumes' no variation; rather, it is just that there is nothing built into the comparative method which would allow it to address variation directly... This assumption of uniformity is a reasonable idealization; it does no more damage to the understanding of the language than, say, modern reference grammars do which concentrate on a language's general structure, typically leaving out consideration of regional or social variation.\nDifferent dialects, as they evolve into separate languages, remain in contact with and influence one another. Even after they are considered distinct, languages near one another continue to influence one another and often share grammatical, phonological, and lexical innovations. A change in one language of a family may spread to neighboring languages, and multiple waves of change are communicated like waves across language and dialect boundaries, each with its own randomly delimited range. If a language is divided into an inventory of features, each with its own time and range (isoglosses), they do not all coincide. History and prehistory may not offer a time and place for a distinct coincidence, as may be the case for Proto-Italic, for which the proto-language is only a concept. However, Hock observes:\nThe discovery in the late nineteenth century that isoglosses can cut across well-established linguistic boundaries at first created considerable attention and controversy. And it became fashionable to oppose a wave theory to a tree theory... Today, however, it is quite evident that the phenomena referred to by these two terms are complementary aspects of linguistic change...\nSubjectivity of the reconstruction.\nThe reconstruction of unknown proto-languages is inherently subjective. In the Proto-Algonquian example above, the choice of \"*m\" as the parent phoneme is only \"likely\", not \"certain\". It is conceivable that a Proto-Algonquian language with \"*b\" in those positions split into two branches, one that preserved \"*b\" and one that changed it to \"*m\" instead, and while the first branch developed only into Arapaho, the second spread out more widely and developed into all the other Algonquian tribes. It is also possible that the nearest common ancestor of the Algonquian languages used some other sound instead, such as \"*p\", which eventually mutated to \"*b\" in one branch and to \"*m\" in the other.\nExamples of strikingly complicated and even circular developments are indeed known to have occurred (such as Proto-Indo-European \"*t\" &gt; Pre-Proto-Germanic \"*\u00fe\" &gt; Proto-Germanic \"*\u00f0\" &gt; Proto-West-Germanic \"*d\" &gt; Old High German in &gt; Modern German ), but in the absence of any evidence or other reason to postulate a more complicated development, the preference of a simpler explanation is justified by the principle of parsimony, also known as Occam's razor. Since reconstruction involves many such choices, some linguists prefer to view the reconstructed features as abstract representations of sound correspondences, rather than as objects with a historical time and place.\nThe existence of proto-languages and the validity of the comparative method is verifiable if the reconstruction can be matched to a known language, which may be known only as a shadow in the loanwords of another language. For example, Finnic languages such as Finnish have borrowed many words from an early stage of Germanic, and the shape of the loans matches the forms that have been reconstructed for Proto-Germanic. Finnish 'king' and 'beautiful' match the Germanic reconstructions *\"kuningaz\" and *\"skauniz\" (&gt; German 'king', 'beautiful').\nAdditional models.\nThe wave model was developed in the 1870s as an alternative to the tree model to represent the historical patterns of language diversification. Both the tree-based and the wave-based representations are compatible with the comparative method.\nBy contrast, some approaches are incompatible with the comparative method, including contentious glottochronology and even more controversial mass lexical comparison considered by most historical linguists to be flawed and unreliable.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "7661", "revid": "48736052", "url": "https://en.wikipedia.org/wiki?curid=7661", "title": "Council of Constance", "text": "1414\u20131418 ecumenical council that settled the Western Schism\nThe Council of Constance (; ) was an ecumenical council of the Catholic Church that was held from 1414 to 1418 in the Bishopric of Constance (Konstanz) in present-day Germany. This was the first ecumenical council convened in the Holy Roman Empire. The council ended the Western Schism by deposing or accepting the resignation of the remaining papal claimants and by electing Pope Martin V. It was the last papal election to take place outside of Italy.\nThe council also condemned Jan Hus as a heretic and facilitated his execution; and it ruled on issues of national sovereignty and the rights of pagans and just war in response to a conflict between the Grand Duchy of Lithuania, the Kingdom of Poland and the Order of the Teutonic Knights.\nThe council is also important for its role in the debates over ecclesial conciliarism and papal supremacy. Constance issued two particularly significant decrees regarding the constitution of the Catholic Church: \"Haec sancta\" (1415), which asserted the superiority of ecumenical councils over popes in at least certain situations, and \"Frequens\" (1417), which provided for councils to be held automatically every ten years. The status of these decrees proved controversial in the centuries after the council, and \"Frequens\" was never put into practice. Though \"Haec sancta\", at least, continued to be accepted as binding by much of the church up to the 19th century, present-day Catholic theologians generally regard these decrees as either invalid or as practical responses to a particular situation without wider implications.\nOrigin and background.\nThe council's main purpose was to end the Papal schism that had resulted from the confusion following the Avignon Papacy. Pope Gregory XI's return to Rome in 1377, followed by his death (in 1378) and the controversial election of his successor, Pope Urban VI, resulted in the defection of a number of cardinals and the election of a rival pope based at Avignon in 1378. After thirty years of schism, the rival courts convened the Council of Pisa, seeking to resolve the situation by deposing the two claimant popes and electing a new one. The council claimed that, in such a situation, a council of bishops had greater authority than just one bishop, even if he were the bishop of Rome. Though the elected Antipope Alexander V and his successor, Antipope John XXIII (not to be confused with the 20th-century Pope John XXIII), gained widespread support, especially at the cost of the Avignon antipope, the schism remained, now involving not two but three claimants: Gregory XII at Rome, Benedict XIII at Avignon, and John XXIII.\nTherefore, many voices, including Sigismund, King of the Romans and of Hungary (and later Holy Roman Emperor), pressed for another council to resolve the issue. That council was called by John XXIII and was held from 16 November 1414 to 22 April 1418 in Constance, Germany. The council was attended by roughly 29 cardinals, 100 \"learned doctors of law and divinity\", 134 abbots, and 183 bishops and archbishops.\nParticipants.\nSigismund arrived on Christmas Eve 1414 and exercised a profound and continuous influence on the course of the council in his capacity of imperial protector of the church. An innovation at the council was that instead of voting as individuals, the bishops voted in national blocs. The vote by nations was in great measure the initiative of the English, German, and French members. The legality of this measure, in imitation of the \"nations\" of the universities, was more than questionable, but during February 1415 it carried and thenceforth was accepted in practice, though never authorized by any formal decree of the council. The four \"nations\" consisted of England, France, Italy, and Germany, with Poles, Hungarians, Danes, and Scandinavians counted with the Germans. While the Italian representatives made up half of those in attendance, they were equal in influence to the English, who sent twenty deputies and three bishops. The Spanish deputies (from Portugal, Castile, Navarre and Aragon), initially absent, joined the council at the twenty-first session, constituting upon arrival the fifth nation.\nDecrees and doctrinal status.\nMany members of the new assembly (comparatively few bishops, but many doctors of theology and of canon and civil law, procurators of bishops, deputies of universities, cathedral chapters, provosts, etc., agents and representatives of princes, etc.) strongly favored the voluntary abdication of all three popes, as did King Sigismund.\nAlthough the Italian bishops who had accompanied John XXIII in large numbers supported his legitimacy, he grew increasingly more suspicious of the council. Partly in response to a fierce anonymous attack on his character from an Italian source, on 2 March 1415 he promised to resign. However, on 20 March he secretly fled the city and took refuge at Schaffhausen in territory of his friend Frederick, Duke of Austria-Tyrol.\nThe famous decree \"Haec sancta synodus\", which gave primacy to the authority of the council and thus became a source for ecclesial conciliarism, was promulgated in the fifth session, 6 April 1415:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Legitimately assembled in the holy Spirit, constituting a general council and representing the Catholic church militant, it has power immediately from Christ; and everyone of whatever state or dignity, even papal, is bound to obey it in those matters which pertain to the faith, the eradication of the said schism, and the general reform of the said church of God in head and members.\n\"Haec sancta synodus\" marks the high-water mark of the Conciliar movement of reform. \nThe acts of the council were not made public until 1442, at the behest of the Council of Basel; they were printed in 1500. The creation of a book on how to die was ordered by the council, and thus written in 1415 under the title \"Ars moriendi\".\n\"Haec sancta\" is today generally considered invalid by the Catholic Church, on the basis that Gregory XII was the legitimate pope at the time and the decree was passed by the council in a session before his confirmation. On this reading, the first sessions of the Council of Constance represented an invalid and illicit assembly of bishops, gathered under the authority of an antipope. This historiography is of much later provenance than the council itself, however: the Pisan line represented by John XXIII had been considered legitimate not just by most of the Latin church at the time of the council, but also subsequently by Pope Martin V, who referred to John as \"our predecessor\" in contrast to the other two claimants, who were merely \"popes so-called in their obediences\". The specific argument distinguishing two parts in the council was seemingly first made by the 17th-century Sorbonne theologian Andr\u00e9 Duval, and remained a fringe view for some time before its vindication within the Catholic Church under the influence of 19th-century ultramontanism.\nEnding the Western Schism.\nWith the support of King Sigismund, enthroned before the high altar of the cathedral of Constance, the Council of Constance recommended that all three papal claimants abdicate, and that another be chosen. In part because of the constant presence of the King, other rulers demanded that they have a say in who would be pope.\nGregory XII then sent representatives to Constance, whom he granted full powers to summon, open, and preside over an Ecumenical Council; he also empowered them to present his resignation of the papacy. This would pave the way for the end of the Western Schism.\nThe legates were received by King Sigismund and by the assembled Bishops, and the King yielded the presidency of the proceedings to the papal legates, Cardinal Giovanni Dominici of Ragusa and Prince Carlo Malatesta. On 4 July 1415 the Bull of Gregory XII which appointed Dominici and Malatesta as his proxies at the council was formally read before the assembled Bishops. The cardinal then read a decree of Gregory XII which convoked the council and authorized its succeeding acts. Thereupon, the Bishops voted to accept the summons. Prince Malatesta immediately informed the council that he was empowered by a commission from Pope Gregory XII to resign the Papal Throne on the Pontiff's behalf. He asked the council whether they would prefer to receive the abdication at that point or at a later date. The Bishops voted to receive the Papal abdication immediately. Thereupon the commission by Gregory XII authorizing his proxy to resign the Papacy on his behalf was read and Malatesta, acting in the name of Gregory XII, pronounced the resignation of the papacy by Gregory XII and handed a written copy of the resignation to the assembly.\nFormer Pope Gregory XII was then created titular Cardinal Bishop of Porto and Santa Ruffina by the council, with rank immediately below the Pope (which made him the highest-ranking person in the church, since, due to his abdication, the See of Peter in Rome was vacant). Gregory XII's cardinals were accepted as true cardinals by the council, but the members of the council delayed electing a new pope for fear that a new pope would restrict further discussion of pressing issues in the church.\nBy the time the anti-popes were all deposed and the new Pope, Martin V, was elected, two years had passed since Gregory XII's abdication, and Gregory was already dead. The council took great care to protect the legitimacy of the succession, ratified all his acts, and a new pontiff was chosen. The new pope, Martin V, elected November 1417, soon asserted the absolute authority of the papal office.\nCondemnation of Jan Hus.\nA second goal of the council was to continue the reforms begun at the Council of Pisa (1409). The reforms were largely directed against John Wycliffe, mentioned in the opening session and condemned in the eighth on 4 May 1415, and Jan Hus, along with their followers. Hus, summoned to Constance under a letter of safe conduct, was found guilty of heresy by the council and turned over to the secular court. \"This holy synod of Constance, seeing that God's church has nothing more that it can do, relinquishes Jan Hus to the judgment of the secular authority and decrees that he is to be relinquished to the secular court.\" (Council of Constance Session 15 \u2013 6 July 1415). The secular court sentenced him to be burned to death at the stake.\nJerome of Prague, a supporter of Hus, came to Constance to offer assistance but was similarly arrested, judged, found guilty of heresy and turned over to the same secular court, with the same outcome as Hus. Poggio Bracciolini attended the council and related the unfairness of the process against Jerome.\nPawe\u0142 W\u0142odkowic and the other Polish representatives to the Council of Constance publicly defended Hus.\nPolish\u2013Lithuanian\u2013Teutonic conflict.\nIn 1411, the First Peace of Thorn ended the Polish\u2013Lithuanian\u2013Teutonic War, in which the Teutonic Knights fought the Kingdom of Poland and Grand Duchy of Lithuania. However, the peace was not stable and further conflicts arose regarding demarcation of the Samogitian borders. The tensions erupted into the brief Hunger War in summer 1414. It was concluded that the disputes would be mediated by the Council of Constance.\nThe Polish-Lithuanian position was defended by Paulus Vladimiri, rector of the Jagiellonian University, who challenged legality of the Teutonic crusade against Lithuania. He argued that a forced conversion was incompatible with free will, which was an essential component of a genuine conversion. Therefore, the Knights could only wage a defensive war if pagans violated natural rights of the Christians. Vladimiri further stipulated that infidels had rights which had to be respected, and neither the Pope nor the Holy Roman Emperor had the authority to violate them. Lithuanians also brought a group of Samogitian representatives to testify to atrocities committed by the Knights.\nThe Dominican theologian John of Falkenberg proved to be the fiercest opponent of the Poles. In his \"Liber de doctrina\", Falkenberg argued thatthe Emperor has the right to slay even peaceful infidels simply because they are pagans.\u00a0... The Poles deserve death for defending infidels, and should be exterminated even more than the infidels; they should be deprived of their sovereignty and reduced to slavery. In \"Satira\", he attacked Polish-Lithuanian King Jogaila, calling him a \"mad dog\" unworthy to be king. Falkenberg was condemned and imprisoned for such libel. Other opponents included Grand Master's proctor Peter Wormditt, Dominic of San Gimignano, John Urbach, Ardecino de Porta of Novara, and Bishop of Ciudad Rodrigo Andrew Escobar. They argued that the Knights were perfectly justified in their crusade as it was a sacred duty of Christians to spread the true faith. Cardinal Pierre d'Ailly published an independent opinion that attempted to somewhat balance both Polish and Teutonic positions.\nThe council established the Diocese of Samogitia, with its seat in Medininkai and subordinated to Lithuanian dioceses, and appointed Matthias of Trakai as the first bishop. Pope Martin V appointed the Lithuanians Jogaila and Vytautas, who were respectively King of Poland and Grand Duke of Lithuania, as vicars general in Pskov and Veliky Novgorod in recognition of their Catholicism. After another round of futile negotiations, the Gollub War broke out in 1422. It ended with the Treaty of Melno. Polish-Lithuanian-Teutonic wars continued for another hundred years.\nLater status.\nAlthough Pope Martin V did not directly challenge the decrees of the council, his successor Eugene IV repudiated an attempt by a faction at the Council of Basel to declare the provisions of \"Haec sancta\" and \"Frequens\" a matter of faith. His 1439 bull on the matter, \"Moyses vir Dei\", was underwritten by the Council of Florence. In convening the Fifth Lateran Council (1512\u201317), Pope Julius II further pronounced that \"Frequens\" had lost its force; Lateran V is sometimes seen as having itself abrogated \"Haec sancta\", though the reading is controversial. Either way, while Rome itself came to reject the provisions made by the council, significant parts of the Church, notably in France, continued to uphold the validity of its decisions long after the event: \"Haec sancta\" was reaffirmed in the Gallican Articles of 1682, and even during the First Vatican Council of 1869\u201370 the French-American bishop of St. Augustine, Florida, Augustin V\u00e9rot, attempted to read \"Haec sancta\" into the record of deliberations.\nDespite the apparently definitive rejection of conciliarism at the First Vatican Council, the debate over the status of Constance was renewed in the 20th century. In the 1960s, in the context of the Second Vatican Council, the reformist Catholic theologian Hans K\u00fcng and the historian Paul de Vooght argued in defense of the dogmatic character of \"Haec sancta\", suggesting that its terms could be reconciled with the definition of papal supremacy at Vatican I. K\u00fcng's argument received support from prelates such as Cardinal Franz K\u00f6nig. Other Catholic historians adopted different views: Hubert Jedin considered \"Haec sancta\" to be an emergency measure with no binding validity beyond its immediate context, while Joseph Gill rejected the validity of the session that passed the decree altogether. The debate over \"Haec sancta\" subsided in the 1970s, however, without resolution.\nReferences.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nSources.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "7662", "revid": "11362347", "url": "https://en.wikipedia.org/wiki?curid=7662", "title": "Churches Uniting in Christ", "text": "US ecumenical organization (founded 2002)\nChurches Uniting in Christ (CUIC) is an ecumenical organization that brings together mainline American denominations (including both predominantly white and predominantly black churches), and was inaugurated on January 20, 2002, in Memphis, Tennessee on the balcony of the Lorraine Motel. It is the successor organization to the Consultation on Church Union.\nHistory.\nOrigins.\nCUIC is the successor organization to the Consultation on Church Union (COCU), which had been founded in 1962. The original task of COCU was to negotiate a consensus between its nine (originally four) member communions (it also included three \"advisory participant\" churches). However, it never succeeded in this goal, despite making progress on several ecumenical fronts. At COCU's 18th plenary meeting in St. Louis, Missouri (January 1999), CUIC was proposed as a new relationship among the nine member communions. Each member communion voted to join CUIC over the next few years.\nInauguration.\nHeads of communion from each member of COCU (as well as the ELCA, a partner in mission and dialogue) inaugurated the group on the day before Martin Luther King Jr. Day in 2002 at the motel where he was killed. This particular location highlighted the group's focus on racism as a major dividing factor between and among churches.\nTask forces.\nThe Coordinating Council of CUIC created several task forces: Racial and Social Justice, Ministry, Young Adult and Local and Regional Ecumenism. Each task force represented an important part of early CUIC work. Local ecumenical liturgies were encouraged, and excitement initially built around \"pilot programs\" in Denver, Los Angeles, and Memphis. The Racial and Social Justice task force created gatherings and discussions on racial justice. The Ministry task force received much of the attention from church structures, however. The group had been given a mandate to complete work on reconciliation by 2007, and in 2003 began working on a document entitled \"Mutual Recognition and Mutual Reconciliation of Ministries.\"\nMutual Recognition and Mutual Reconciliation of Ministries (MRMRM).\nOne of the most difficult issues concerning recognition and reconciliation of ministries was that of the historic episcopate. This was one of the issues that defeated proposals for union by COCU as well. The group approached this problem through dialogue, soliciting information from each member communion on the particularities of their theology and ecclesiology in order to come to a mutually acceptable conclusion.\nCUIC released the seventh and final draft of the MRMRM document in June 2005. Much work was done in 2006 on this document, which focused on \"Episkope,\" the oversight of ministry. The work culminated in a consultation on episkope in St. Louis in October 2006 involving the heads of communion of the members of CUIC. At this consultation, the MRMRM document was met with resistance, and concern was raised in particular that CUIC was focusing too narrowly on reconciliation of ministries and \"not taking seriously our commitment to working on those issues of systemic racism that remain at the heart of our continuing and separated life as churches here in the United States.\"\nMoravian Church (Northern Province).\nThe nine churches which inaugurated CUIC in 2002 were joined by the Moravian Church, Northern Province. The Moravians had been partners in mission and dialogue since 2002, but joined as a member communion after the October 2006 consultation on episcope.\nSuspension of activities.\nIn 2007, the African Methodist Episcopal Zion Church and the African Methodist Episcopal Church withdrew from CUIC. Neither body sent representatives to the CUIC plenary on January 11\u201314, 2008, though the AME Council of Bishops never voted to suspend membership officially. They felt the other churches were not doing enough to counter the history of racial injustice between black and white churches. In response to this, the remaining churches in CUIC decided in 2008 to suspend their work while they seek reconciliation with these churches. This work began with a group of representatives who revisited the 1999 document \"Call to Christian Commitment and Action to Combat Racism,\" which is available on the current CUIC website. This also meant eliminating the position of Director as well as the suspension of the work of the CUIC task forces. As of 2012, CUIC no longer has physical offices, opting instead for a virtual office and storing the archives of both CUIC and COCU at Princeton Seminary's Henry Luce III Library.\nReconciliation efforts.\nThe African Methodist Episcopal Church resumed its participation by the February 2010 plenary meeting, where CUIC moved to refocus on its eight marks of commitment and a shared concern for racial justice as a major dividing factor facing ecumenism. Although the African Methodist Episcopal Zion Church has not rejoined the group, efforts have continued to bring this communion back into membership. The Rev. Staccato Powell, an AMEZ pastor, preached at the 2011 CUIC plenary in Ft. Lauderdale, Florida as a part of these reconciliation efforts. Combating racism has again become a priority of CUIC. Concerns over the historic episcopate have been sidelined since 2008, though they may re-emerge. The group's focus on mutual reconciliation of ministries has been revisited in the light of racism and the impact that racism may have on exchanging ministers between denominations. Therefore, the coordinating council of CUIC created a consultation on race and ministry while also choosing to partner with the Samuel Dewitt Proctor Conference, a social justice organization involved in African American faith communities.\nPurpose.\nThe purpose of CUIC has always been unity (as reflected in their current slogan, \"reconciling the baptized, seeking unity with justice\"). This reflects one of the core scripture passages in the ecumenical movement, Jesus' prayer in John 17:21, \"That they all may be one\". CUIC has approached this goal of unity in various ways throughout its history.\nRacism.\nRacism has been a primary focus of CUIC since 2002 (and, indeed, a primary focus of COCU alongside other forms of exclusion and prejudice, such as sexism and ableism). According to Dan Krutz, former president of CUIC, \"Overcoming racism has been a focal point of CUIC since its beginning... Racism may be the biggest sin that divides churches.\" Even before the absence of the AME and AMEZ churches at the January 2011 plenary, some in CUIC had noticed the lack of commitment to racial reconciliation. Since 2008, however, racism has become an even more pressing concern. This has led CUIC to address issues of racism in the public sphere, including the killing of Trayvon Martin and the recovery from the 2010 Haiti earthquake.\nMarks of Commitment.\nAccording to their website, one of the reasons for transitioning from COCU to CUIC is so that member churches \"stop 'consulting' and start living their unity in Christ more fully.\" This means that each member communion in CUIC agrees to abide by the eight Marks of Commitment, which are summarized as follows:\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "7663", "revid": "27015025", "url": "https://en.wikipedia.org/wiki?curid=7663", "title": "Canadian Unitarian Council", "text": "Canadian religious organization\nThe Canadian Unitarian Council () (CUC) is a liberal religious association of Unitarian, Universalist, and Unitarian Universalist congregations in Canada. It was formed on May 14, 1961, initially to be the national organization for Canadians belonging to the Unitarian Universalist Association (UUA) which formed a day later on May 15, 1961. Between 1961 and 2002, almost all member congregations of the CUC were also members of the UUA and most services to congregations in Canada were provided by the UUA. However, in 2002, the CUC formally became a separate entity from the UUA, although the UUA continues to provide ministerial settlement services and remains the primary source for education and theological resources. Some Canadian congregations have continued to be members of both the CUC and the UUA, while most congregations are only members of the CUC.\nThe Canadian Unitarian Council is the only national body for Unitarian, Universalist, and Unitarian Universalist congregations in Canada and was one of the seventeen members of the now defunct International Council of Unitarians and Universalists (1995\u20132021).\nOrganization.\nThe CUC is made up of 43 member congregations and emerging groups, who are the legal owners of the organization, and who are, for governance and service delivery, divided into four regions: \"BC\" (British Columbia), \"Western\" (Alberta to Thunder Bay), \"Central\" (between Thunder Bay and Kingston), and \"Eastern\" (Kingston, Ottawa and everything east of that). However, for youth ministry, the \"Central\" and \"Eastern\" regions are combined to form a youth region known as \"QuOM\" (Quebec, Ontario and the Maritimes), giving the youth only three regions for their activities. The organization as a whole is governed by the CUC Board of Trustees (Board), whose mandate it is to govern in the best interests of the CUC's owners. The Board is made up of eight members who are elected by congregational delegates at the CUC's Annual General Meeting. This consists of two Trustees from each region, who are eligible to serve a maximum of two three-year terms. Board meetings also include Official Observers to the Board, who participate without a vote and represent UU Youth and Ministers.\nService delivery.\nAs members of the CUC, congregations and emerging groups are served by volunteer Service Consultants, Congregational Networks, and a series of other committees. There are two directors of regional services, one for the Western two regions, and one for the Eastern two regions. Youth and young adults are served by a Youth and Young Adult Ministry Development staff of two.\nAnnual conference and meeting.\nPolicies and business of the CUC are determined at the Annual Conference and Meeting (ACM), consisting of the Bi-Annual Conference, in which workshops are held, and the Annual General Meeting, in which business matters and plenary meetings are performed. The ACM features two addresses, a Keynote and a Confluence Lecture. The Confluence Lecture is comparable to the UUA's Ware Lecture in prestige. In early days this event simply consisted of the Annual General Meeting component as the Annual Conference component was not added to much later. And starting in 2017 the conference portion will only take place every second year. Past ACMs have been held in the following locations:\nPrinciples and sources.\nThe CUC does not have a central creed in which members are required to believe, but they have found it useful to articulate their common values in what has become known as \"The Principles and Sources of our Religious Faith\", which are currently based on the UUA's former Principles and Sources with the addition of an 8th principle adopted by CUC members at a special meeting on November 27, 2021. The CUC had a task force whose mandate was to consider revising them.\nThe principles and sources as published in church literature and on the CUC website:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\n\"The Principles and Sources of our Religious Faith\"\n\"Principles\"\nWe, the member congregations of the Canadian Unitarian Council, covenant to affirm and promote:\n*The inherent worth and dignity of every person;\n*Justice, equity, and compassion in human relations;\n*Acceptance of one another and encouragement to spiritual growth in our congregations;\n*A free and responsible search for truth and meaning;\n*The right of conscience and the use of the democratic process within our congregations and in society at large;\n*The goal of world community with peace, liberty, and justice for all;\n*Respect for the interdependent web of all existence of which we are a part;\n*Individual and communal action that accountably dismantles racism and systemic barriers to full inclusion in ourselves and our institutions.\n\"Sources\"\nThe living tradition which we share draws from many sources:\n* Direct experience of that transcending mystery and wonder, affirmed in all cultures, which moves us to a renewal of the spirit and an openness to the forces which create and uphold life;\n* Words and deeds of prophetic women and men which challenge us to confront powers and structures of evil with justice, compassion, and the transforming power of love;\n* Wisdom from the world's religions which inspires us in our ethical and spiritual life;\n* Jewish and Christian teachings which call us to respond to God's love by loving our neighbours as ourselves;\n* Humanist teachings which counsel us to heed the guidance of reason and the results of science, and warn us against idolatries of the mind and spirit;\n* Spiritual teachings of Earth-centred traditions which celebrate the sacred circle of life and instruct us to live in harmony with the rhythms of nature.\nGrateful for the religious pluralism which enriches and ennobles our faith, we are inspired to deepen our understanding and expand our vision. As free congregations we enter into this covenant, promising to one another our mutual trust and support.\nFormation and relationship to the Unitarian Universalist Association.\nThe CUC formed on May 14, 1961, to be the national organization for Canadians within the about-to-form UUA (it formed a day later on May 15, 1961). And until 2002, almost all member congregations of the CUC were also members of the UUA and most services to CUC member congregations were provided by the UUA. However, after an agreement between the UUA and the CUC, since 2002 most services have been provided by the CUC to its own member congregations, with the UUA continuing to provide ministerial settlement services. And also since 2002, some Canadian congregations have continued to be members of both the UUA and CUC while others are members of only the CUC.\nThe Canadian Unitarian Universalist youth of the day disapproved of the 2002 change in relationship between the CUC and UUA. It is quite evident in the words of this statement, which was adopted by the attendees of the 2001 youth conference held at the Unitarian Church of Montreal:\nWe the youth of Canada are deeply concerned about the direction the CUC seems to be taking. As stewards of our faith, adults have a responsibility to take into consideration the concerns of youth. We are opposed to making this massive jump in our evolutionary progress.\nCanadian Unitarian Universalist Women's Association.\nThe Canadian Unitarian Universalist Women's Association (CUUWA), established in May 2011, is a women's rights organization associated with the CUC. The CUUWA gained initial support from Prairie Women's Gathering and the Vancouver Island Women's retreat, and has since become a nationally recognized organization.\nMission.\nOriginally called the Canadian Unitarian Universalist Women's Federation, the organization aims to raise awareness for women's education, rights, and equality of income. The association also aims to change societal attitudes about women and inform society of the issues women have faced locally and internationally. As a part of their mission, the CUUWA circulates educational materials that highlight women's contributions to society. The organization hosts an annual general meeting during the Canadian Unitarian Council Annual Conference.\nName of CUC and playful abbreviation of Unitarian Universalist.\nWhile the name of the organization is the Canadian Unitarian Council, the CUC includes congregations with Unitarian, Universalist, Unitarian Universalist, and Universalist Unitarian in their names. Changing the name of the CUC has occasionally been debated, but there have been no successful motions. To recognize this diversity, some members of the CUC abbreviate Unitarian Universalist as U*U (and playfully read it as \"You star, you\"). Note, not all CUC members like this playful reading and so when these people write the abbreviation they leave out the star (*), just writing UU instead.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "7666", "revid": "212624", "url": "https://en.wikipedia.org/wiki?curid=7666", "title": "Clay math prize", "text": ""}
{"id": "7668", "revid": "35791198", "url": "https://en.wikipedia.org/wiki?curid=7668", "title": "Charles Mingus", "text": "American jazz musician (1922\u20131979)\nCharles Mingus Jr. (April 22, 1922 \u2013 January 5, 1979) was an American jazz upright bassist, composer, bandleader, pianist, and author. A major proponent of collective improvisation, he is considered one of the greatest jazz musicians and composers in history, with a career spanning three decades and collaborations with other jazz greats such as Duke Ellington, Charlie Parker, Max Roach, and Eric Dolphy. Mingus's work ranged from advanced bebop and avant-garde jazz with small and midsize ensembles to pioneering the post-bop style on seminal recordings like \"Pithecanthropus Erectus\" (1956) and \"Mingus Ah Um\" (1959) and progressive big band experiments such as \"The Black Saint and the Sinner Lady\" (1963).\nMingus's compositions continue to be played by contemporary musicians ranging from the repertory bands Mingus Big Band, Mingus Dynasty, and Mingus Orchestra to high school students who play the charts and compete in the Charles Mingus High School Competition. In 1993, the Library of Congress acquired Mingus's collected papers\u2014including scores, sound recordings, correspondence and photos\u2014in what it called \"the most important acquisition of a manuscript collection relating to jazz in the Library's history\".\nBiography.\nEarly life and career.\nCharles Mingus was born in Nogales, Arizona. His father, Charles Mingus Sr., was a sergeant in the U.S. Army. Mingus Jr. was largely raised in the Watts area of Los Angeles.\nMingus's ethnic background was complex. His ancestry included German American, African American, and Native American heritage. His maternal grandfather was a Chinese British subject from Hong Kong, and his maternal grandmother was an African American from the southern United States. Mingus was the great-great-great-grandson of his family's founding patriarch who, by most accounts, was a German immigrant. In Mingus's autobiography \"Beneath the Underdog\", his mother was described as \"the daughter of an English/Chinese man and a South-American woman\", and his father was the son \"of a black farm worker and a Swedish woman\". Charles Mingus Sr. claims to have been raised by his mother and her husband as a white person until he was fourteen, when his mother revealed to her family that the child's true father was a black slave, after which he had to run away from his family and live on his own. The autobiography does not confirm whether Charles Mingus Sr. or Mingus himself believed this story was true, or whether it was merely an embellished version of the Mingus family's lineage. According to new information used to educate visitors to Mingus Mill in the Great Smoky Mountains National Park, included in signs unveiled May 23, 2023, the father of Mingus Sr. was former slave Daniel Mingus, owned by the family of his mother Clarinda Mingus, a white woman. When Clarinda married a white man, Mingus Sr. was left with his white grandfather and great-grandparents. His father, who later changed his name to West, apparently did not have a relationship with Mingus Sr.\nHis mother allowed only church-related music in their home, but Mingus developed an early love for other music, especially that of Duke Ellington. He studied trombone, and later cello, although he was unable to follow the cello professionally because, at the time, it was nearly impossible for a black musician to make a career of classical music, and the cello was not accepted as a jazz instrument. Despite this, Mingus was still attached to the cello; as he studied bass with Red Callender in the late 1930s, Callender even commented that the cello was still Mingus's main instrument. In \"Beneath the Underdog\", Mingus states that he did not actually start learning bass until Buddy Collette accepted him into his swing band under the stipulation that he be the band's bass player.\nDue to a poor education, the young Mingus could not read musical notation quickly enough to join the local youth orchestra. This had a serious impact on his early musical experiences, leaving him feeling ostracized from the classical music world. These early experiences, in addition to his lifelong confrontations with racism, were reflected in his music, which often focused on themes of racism, discrimination and (in)justice.\nMuch of the cello technique Mingus learned was applicable to double bass when he took up the instrument in high school. He studied for five years with Herman Reinshagen, principal bassist of the New York Philharmonic, and compositional techniques with Lloyd Reese. Throughout much of his career, he played a bass made in 1927 by the German maker Ernst Heinrich Roth.\nMingus was already writing relatively advanced musical pieces in his teenage years; many are similar to Third Stream in that they incorporate elements of classical music. A number of pieces were recorded in 1960 with conductor Gunther Schuller, and released as \"Pre-Bird\", referring to Charlie \"Bird\" Parker; Mingus was one of many musicians whose perspectives on music were altered by Parker into \"pre- and post-Bird\" eras.\nMingus gained a reputation as a bass prodigy. His first major professional job was playing with former Ellington clarinetist Barney Bigard. He toured with Louis Armstrong in 1943, and by early 1945 was recording in Los Angeles in a band led by Russell Jacquet, which also included Teddy Edwards, Maurice James Simon, Wild Bill Davis, and Chico Hamilton, and in May that year, in Hollywood, again with Edwards, in a band led by Howard McGhee.\nHe then played with Lionel Hampton's band in the late 1940s; Hampton performed and recorded several Mingus pieces. A popular trio of Mingus, Red Norvo, and Tal Farlow in 1950 and 1951 received considerable acclaim, but Mingus's race caused problems with some club owners and he left the group. Mingus was briefly a member of Ellington's band in 1953, as a substitute for bassist Wendell Marshall; however, Mingus's notorious temper led to his being one of the few musicians personally fired by Ellington (Bubber Miley and drummer Bobby Durham are among the others) after a backstage fight between Mingus and Juan Tizol.\nAlso in the early 1950s, before attaining commercial recognition as a bandleader, Mingus played gigs with Charlie Parker, whose compositions and improvisations greatly inspired and influenced him. Mingus considered Parker the greatest genius and innovator in jazz history, but he had a love-hate relationship with Parker's legacy. Mingus blamed the Parker mythology for a derivative crop of pretenders to Parker's throne. He was also conflicted and sometimes disgusted by Parker's self-destructive habits and the romanticized lure of drug addiction they offered to other jazz musicians. In response to the many sax players who imitated Parker, Mingus titled a song \"If Charlie Parker Were a Gunslinger, There'd Be a Whole Lot of Dead Copycats\" (released on \"Mingus Dynasty\" as \"Gunslinging Bird\").\nMingus married four times. His wives were Jeanne Gross, Lucille (Celia) Germanis, Judy Starkey, and Susan Graham Ungaro.\nBased in New York.\nIn 1952, Mingus co-founded Debut Records with Max Roach so he could conduct his recording career as he saw fit. The name originated from his desire to document unrecorded young musicians. Despite this, the best-known recording the company issued was of the most prominent figures in bebop. On May 15, 1953, Mingus joined Dizzy Gillespie, Parker, Bud Powell, and Roach for a concert at Massey Hall in Toronto, which is the last recorded documentation of Gillespie and Parker playing together. After the event, Mingus chose to overdub his barely audible bass part back in New York; the original version was issued later. The two 10\" albums of the Massey Hall concert (one featured the trio of Powell, Mingus and Roach) were among Debut Records' earliest releases. Mingus may have objected to the way the major record companies treated musicians, but Gillespie once commented that he did not receive any royalties \"for years and years\" for his Massey Hall appearance. The records, however, are often regarded as among the finest live jazz recordings.\nOne story has it that Mingus was involved in a notorious incident while playing a 1955 club date billed as a \"reunion\" with Parker, Powell, and Roach. Powell, who suffered from alcoholism and mental illness (possibly exacerbated by a severe police beating and electroshock treatments), had to be helped from the stage, unable to play or speak coherently. As Powell's incapacitation became apparent, Parker stood in one spot at a microphone, chanting \"Bud Powell\u00a0... Bud Powell\u00a0...\" as if beseeching Powell's return. Allegedly, Parker continued this incantation for several minutes after Powell's departure, to his own amusement and Mingus's exasperation. Mingus took another microphone and announced to the crowd, \"Ladies and Gentlemen, please don't associate me with any of this. This is not jazz. These are sick people.\" This was Parker's last public performance; about a week later he died after years of substance abuse.\nMingus often worked with a mid-sized ensemble (around 8\u201310 members) of rotating musicians known as the Jazz Workshop. Mingus broke new ground, constantly demanding that his musicians be able to explore and develop their perceptions on the spot. Those who joined the Workshop (or Sweatshops as they were colorfully dubbed by the musicians) included Pepper Adams, Jaki Byard, Booker Ervin, John Handy, Jimmy Knepper, Charles McPherson, and Horace Parlan. Mingus shaped these musicians into a cohesive improvisational machine that in many ways anticipated free jazz. Some musicians dubbed the workshop a \"university\" for jazz.\n\"Pithecanthropus Erectus\" and other recordings.\nThe 1950s are generally regarded as Mingus's most productive and fertile period. Over a ten-year period, he made 30 records for a number of labels (Atlantic, Candid, Columbia, Impulse and others). Mingus had already recorded around ten albums as a bandleader, but 1956 was a breakthrough year for him, with the release of \"Pithecanthropus Erectus\", arguably his first major work as both a bandleader and composer. Like Ellington, Mingus wrote songs with specific musicians in mind, and his band for \"Erectus\" included adventurous musicians: piano player Mal Waldron, alto saxophonist Jackie McLean and the Sonny Rollins-influenced tenor of J. R. Monterose. The title song is a ten-minute tone poem, depicting the rise of man from his hominid roots (\"Pithecanthropus erectus\") to an eventual downfall. A section of the piece was free improvisation, free of structure or theme.\nAnother album from this period, \"The Clown\" (1957, also on Atlantic Records), the title track of which features narration by humorist Jean Shepherd, was the first to feature drummer Dannie Richmond, who remained his preferred drummer until Mingus's death in 1979. The two men formed one of the most impressive and versatile rhythm sections in jazz. Both were accomplished performers seeking to stretch the boundaries of their music while staying true to its roots. When joined by pianist Jaki Byard, they were dubbed \"The Almighty Three\".\n\"Mingus Ah Um\" and other works.\nIn 1959, Mingus and his jazz workshop musicians recorded one of his best-known albums, \"Mingus Ah Um\". Even in a year of standout masterpieces, including Dave Brubeck's \"Time Out\", Miles Davis's \"Kind of Blue\", John Coltrane's \"Giant Steps\", and Ornette Coleman's \"The Shape of Jazz to Come\", this was a major achievement, featuring such classic Mingus compositions as \"Goodbye Pork Pie Hat\" (an elegy to Lester Young) and the vocal-less version of \"Fables of Faubus\" (a protest against segregationist Arkansas governor Orval Faubus that features double-time sections). In 2003 the album's legacy was cemented when it was inducted into the National Recording Registry. Also during 1959, Mingus recorded the album \"Blues &amp; Roots\", which was released the following year. Mingus said in his liner notes: \"I was born swinging and clapped my hands in church as a little boy, but I've grown up and I like to do things other than just swing. But blues can do more than just swing.\"\nMingus witnessed Ornette Coleman's legendary\u2014and controversial\u20141960 appearances at New York City's Five Spot jazz club. He initially expressed rather mixed feelings for Coleman's innovative music: \"... if the free-form guys could play the same tune twice, then I would say they were playing something ... Most of the time they use their fingers on the saxophone and they don't even know what's going to come out. They're experimenting.\" That same year, however, Mingus formed a quartet with Richmond, trumpeter Ted Curson and multi-instrumentalist Eric Dolphy. This ensemble featured the same instruments as Coleman's quartet, and is often regarded as Mingus rising to the challenging new standard established by Coleman. The quartet recorded on both \"Charles Mingus Presents Charles Mingus\" and \"Mingus\". The former also features the version of \"Fables of Faubus\" with lyrics, aptly titled \"Original Faubus Fables\".\nIn 1961, Mingus spent time staying at the house of his mother's sister (Louise) and her husband, Fess Williams, a clarinetist and saxophonist, in Jamaica, Queens. Subsequently, Mingus invited Williams to play at the 1962 Town Hall Concert.\nOnly one misstep occurred in this era: \"The Town Hall Concert\" in October 1962, a \"live workshop\"/recording session. With an ambitious program, the event was plagued with troubles from its inception. Mingus's vision, now known as \"Epitaph\", was finally realized by conductor Gunther Schuller in a concert in 1989, a decade after Mingus died.\nOutside of music, Mingus published a mail-order how-to guide in 1954 called \"The Charles Mingus CAT-alog for Toilet Training Your Cat\". The guide explained in detail how to get a cat to use a human toilet. Sixty years later, in 2014, the late American character actor Reg E. Cathey performed a voice recording of the complete guide for \"Studio 360\".\n\"The Black Saint and the Sinner Lady\" and other Impulse! albums.\nIn 1963, Mingus released \"The Black Saint and the Sinner Lady\", described as \"one of the greatest achievements in orchestration by any composer in jazz history.\" The album was also unique in that Mingus asked his psychotherapist, Dr. Edmund Pollock, to provide notes for the record.\nMingus also released \"Mingus Plays Piano\", an unaccompanied album featuring some fully improvised pieces, in 1963.\nIn addition, 1963 saw the release of \"Mingus Mingus Mingus Mingus Mingus\", an album praised by critic Nat Hentoff.\nIn 1964, Mingus put together one of his best-known groups, a sextet including Dannie Richmond, Jaki Byard, Eric Dolphy, trumpeter Johnny Coles, and tenor saxophonist Clifford Jordan. The group was recorded frequently during its short existence. Mosaic Records has released a 7-CD set, \"Charles Mingus \u2013 The Jazz Workshop Concerts 1964\u201365\", featuring concerts from Town Hall, Amsterdam, Monterey \u201964, Monterey \u201965, &amp; Minneapolis). Coles fell ill and left during a European tour. Dolphy stayed in Europe after the tour ended, and died suddenly in Berlin on June 28, 1964. 1964 was also the year that Mingus met his future wife, Sue Graham Ungaro. The couple were married in 1966 by Allen Ginsberg. Facing financial hardship, Mingus was evicted from his New York home in 1966.\n\"Changes\".\nMingus's pace slowed somewhat in the late 1960s and early 1970s. In 1974, after his 1970 sextet with Charles McPherson, Eddie Preston and Bobby Jones disbanded, he formed a quintet with Richmond, pianist Don Pullen, trumpeter Jack Walrath and saxophonist George Adams. They recorded two well-received albums, \"Changes One\" and \"Changes Two\". Mingus also played with Charles McPherson in many of his groups during this time. \"Cumbia and Jazz Fusion\" in 1976 sought to blend Colombian music (the \"Cumbia\" of the title) with more traditional jazz forms. In 1971, Mingus taught for a semester at the University at Buffalo, The State University of New York as the Slee Professor of Music.\nLater career and death.\nBy the mid-1970s, Mingus was feeling the effects of motor neuron disease. His once formidable bass technique declined until he could no longer play the instrument. He continued composing, however, and supervised a number of recordings before his death. At the time of his death, he was working with Joni Mitchell on an album eventually titled \"Mingus\", which included lyrics added by Mitchell to his compositions, including \"Goodbye Pork Pie Hat\". The album featured Wayne Shorter, Herbie Hancock, and bassist and composer, Jaco Pastorius.\nMingus died on January 5, 1979, aged 56, in Cuernavaca, Mexico, where he had traveled for treatment and convalescence. His ashes were scattered in the Ganges River.\nMusical style.\nHis compositions retained the hot and soulful feel of hard bop, drawing heavily from black gospel music and blues, while sometimes containing elements of third stream, free jazz, and classical music. He once cited Duke Ellington and church as his main influences.\nMingus espoused collective improvisation, similar to the old New Orleans jazz parades, paying particular attention to how each band member interacted with the group as a whole. In creating his bands, he looked not only at the skills of the available musicians, but also their personalities. Many musicians passed through his bands and later went on to impressive careers. He recruited talented and sometimes little-known artists, whom he utilized to assemble unconventional instrumental configurations. As a performer, Mingus was a pioneer in double bass technique, widely recognized as one of the instrument's most proficient players.\nBecause of his brilliant writing for midsize ensembles, and his catering to and emphasizing the strengths of the musicians in his groups, Mingus is often considered the heir of Duke Ellington, for whom he expressed great admiration and with whom he collaborated on the record \"Money Jungle\". Dizzy Gillespie had once said Mingus reminded him \"of a young Duke\", citing their shared \"organizational genius\".\nPersonality.\nMingus had a notoriously fiery temperament, which earned him the nickname \"the Angry Man of Jazz\". His refusal to compromise his musical integrity led to many onstage outbursts, which were directed at members of his band and the audience alike; in 1965, midway through a performance, he ordered half his band backstage to practice. Noisy audiences were subject to expressions of ire. Mingus chastised one such with \"Isaac Stern doesn't have to put up with this shit\", and on another occasion ordered his band to read books instead of playing. Also in the 1960s, playing a gig at the Five Spot Caf\u00e9 in New York City, Mingus reportedly destroyed a $20,000 bass in response to hecklers in the audience.\nGuitarist and singer Jackie Paris was a witness to Mingus's irascibility. Paris recalls his time in the Jazz Workshop: \"He chased everybody off the stand except [drummer] Paul Motian and me... The three of us just wailed on the blues for about an hour and a half before he called the other cats back.\"\nOn October 12, 1962, Mingus punched Jimmy Knepper in the mouth while the two men were working together at Mingus's apartment on a score for his upcoming concert at the Town Hall in New York, and Knepper refused to take on more work. Mingus's blow broke off a crowned tooth and its underlying stub. According to Knepper, this ruined his embouchure and resulted in the permanent loss of the top octave of his range on the trombone \u2013 a significant handicap for any professional trombonist. This attack temporarily ended their working relationship, and Knepper was unable to perform at the concert. Charged with assault, Mingus appeared in court in January 1963 and was given a suspended sentence. Knepper did again work with Mingus in 1977 and played extensively with the Mingus Dynasty, formed after Mingus's death in 1979.\nIn addition to bouts of ill temper, Mingus was prone to clinical depression and tended to have brief periods of extreme creative activity intermixed with fairly long stretches of greatly decreased output, such as the five-year period following the death of Eric Dolphy.\nIn 1966, Mingus was evicted from his apartment at 5 Great Jones Street in New York City for nonpayment of rent, captured in the 1968 documentary film \"\", directed by Thomas Reichman. The film also features Mingus performing in clubs and in the apartment, firing a .410 bore shotgun indoors, composing at the piano, playing with and taking care of his young daughter Carolyn, and discussing love, art, politics, and the music school he had hoped to create.\nLegacy.\nThe Mingus Big Band.\nCharles Mingus's music is currently being performed and reinterpreted by the Mingus Big Band, which in October 2008 began playing every Monday at Jazz Standard in New York City, and often tours the rest of the U.S. and Europe. The Mingus Big Band, the Mingus Orchestra, and the Mingus Dynasty band are managed by Jazz Workshop, Inc. and run by Mingus's widow, Sue Graham Mingus.\nElvis Costello has written lyrics for a few Mingus pieces. He had once sung lyrics for one piece, \"Invisible Lady\", backed by the Mingus Big Band on the album, \"Tonight at Noon: Three of Four Shades of Love\".\n\"Epitaph\".\n\"Epitaph\" is considered one of Charles Mingus's masterpieces. The composition is 4,235 measures long, requires two hours to perform, and is one of the longest jazz pieces ever written. \"Epitaph\" was only completely discovered by musicologist Andrew Homzy during the cataloging process after Mingus's death. With the help of a grant from the Ford Foundation, the score and instrumental parts were copied, and the piece itself was premiered by a 30-piece orchestra, conducted by Gunther Schuller. This concert was produced by Mingus's widow, Sue Graham Mingus, at Alice Tully Hall on 3 June 1989, 10 years after Mingus's death. It was performed again at several concerts in 2007. The performance at Walt Disney Concert Hall is available on NPR. Hal Leonard published the complete score in 2008.\nAutobiography.\nMingus wrote the sprawling, exaggerated, quasi-autobiography, \"Beneath the Underdog: His World as Composed by Mingus\", throughout the 1960s, and it was published in 1971. Its \"stream of consciousness\" style covered several aspects of his life that had previously been off-record. In addition to his musical and intellectual proliferation, Mingus goes into great detail about his perhaps overstated sexual exploits. He claims to have had more than 31 affairs in the course of his life (including 26 prostitutes in one sitting). This does not include any of his five wives (he claims to have been married to two of them simultaneously). In addition, he asserts that he held a brief career as a pimp. This has never been confirmed.\nMingus's autobiography also serves as an insight into his psyche, as well as his attitudes about race and society. It includes accounts of abuse at the hands of his father from an early age, being bullied as a child, his removal from a white musician's union, and grappling with disapproval while married to white women and other examples of hardship and prejudice.\nScholarly influence.\nThe work of Charles Mingus has also received attention in academia. The American scholar of religion and multidisciplinary artist Ashon Crawley writes in his book \"Blackpentecostal Breath: The Aesthetics of Possibility\" that Mingus's musicianship is an example of the power of music to blur the boundaries between the sacred and the profane. Discussing the song \"Wednesday Night Prayer Meeting\", which Mingus was inspired to write by attending a Holiness Pentecostal church in Los Angeles, Crawley suggests that Mingus found the gatherings to be an \"ongoing, deep, intense mode of study, a kind of study wherein the aesthetic forms created could not be severed from the intellectual practice because they were one and also, but not, the same\", and sought to express this through his compositions. \nGunther Schuller has suggested that Mingus should be ranked among the most important American composers, jazz or otherwise. In 1988, a grant from the National Endowment for the Arts made possible the cataloging of Mingus compositions, which were then donated to the Music Division of the New York Public Library for public use. In 1993, The Library of Congress acquired Mingus's collected papers\u2014including scores, sound recordings, correspondence and photos\u2014in what they described as \"the most important acquisition of a manuscript collection relating to jazz in the Library's history\". \nCover versions.\nConsidering the number of compositions that Charles Mingus wrote, his works have not been recorded as often as comparable jazz composers. The only Mingus tribute albums recorded during his lifetime were baritone saxophonist Pepper Adams's album, \"Pepper Adams Plays the Compositions of Charlie Mingus\", in 1963, and Joni Mitchell's album \"Mingus\", in 1979. Of all his works, his elegy for Lester Young, \"Goodbye Pork Pie Hat\" (from \"Mingus Ah Um\") has probably had the most recordings. The song has been covered by both jazz and non-jazz artists, such as Jeff Beck, Andy Summers, Eugene Chadbourne, and Bert Jansch and John Renbourn with and without Pentangle. Joni Mitchell sang a version with lyrics that she wrote for it.\nElvis Costello has recorded \"Hora Decubitus\" (from \"Mingus Mingus Mingus Mingus Mingus\") on \"My Flame Burns Blue\" (2006). \"Better Git It in Your Soul\" was covered by Davey Graham on his album \"Folk, Blues, and Beyond\". Trumpeter Ron Miles performs a version of \"Pithecanthropus Erectus\" on his CD \"Witness\". New York Ska Jazz Ensemble has done a cover of Mingus's \"Haitian Fight Song\", as have the British folk rock group Pentangle and others. Hal Willner's 1992 tribute album \"Weird Nightmare: Meditations on Mingus\" (Columbia Records) contains idiosyncratic renditions of Mingus's works involving numerous popular musicians including Chuck D, Keith Richards, Henry Rollins and Dr. John. The Italian band Quintorigo recorded an entire album devoted to Mingus's music, titled \"Play Mingus\".\nGunther Schuller's edition of Mingus's \"Epitaph\", which premiered at Lincoln Center in 1989, was subsequently released on Columbia/Sony Records.\nOne of the most elaborate tributes to Mingus came on September 29, 1969, at a festival honoring him. Duke Ellington performed \"The Clown\", with Ellington reading Jean Shepherd's narration. It was long believed that no recording of this performance existed; however, one was discovered and premiered on July 11, 2013, by Dry River Jazz host http:// for NPR member station KRWG-FM with re-airings on July 13, 2013, and July 26, 2014. Mingus's elegy for Duke, \"Duke Ellington's Sound Of Love\", was recorded by Kevin Mahogany on \"Double Rainbow\" (1993) and Anita Wardell on \"Why Do You Cry?\" (1995).\nDiscography.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "7669", "revid": "45179772", "url": "https://en.wikipedia.org/wiki?curid=7669", "title": "Centimetre", "text": "Unit of length\n&lt;templatestyles src=\"Template:Infobox/styles-images.css\" /&gt;\nA centimetre (International spelling) or centimeter (American English), with SI symbol cm, is a unit of length in the International System of Units (SI) equal to one hundredth of a metre, \"centi-\" being the SI prefix for a factor of . Equivalently, there are 100 centimetres in 1 metre. The centimetre was the base unit of length in the now deprecated centimetre\u2013gram\u2013second (CGS) system of units.\nThough for many physical quantities, SI prefixes for factors of 103\u2014like \"milli-\" and \"kilo-\"\u2014are often preferred by technicians, the centimetre remains a practical unit of length for many everyday measurements; for instance, human height is commonly measured in centimetres. A centimetre is approximately the width of the fingernail of an average adult person.\nEquivalence to other units of length.\nOne millilitre is defined as one cubic centimetre, under the SI system of units.\nOther uses.\nIn addition to its use in the measurement of length, the centimetre is used:\nUnicode symbols.\nFor the purposes of compatibility with Chinese, Japanese and Korean (CJK) characters, Unicode has symbols for:\nThese characters are each equal in size to one Chinese character and are typically used only with East Asian, fixed-width CJK fonts.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "7670", "revid": "37922243", "url": "https://en.wikipedia.org/wiki?curid=7670", "title": "Central Coast", "text": "Central Coast may refer to:\nUnited States.\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n Topics referred to by the same termThis page lists articles about distinct geographical locations with the same name. "}
{"id": "7671", "revid": "50365198", "url": "https://en.wikipedia.org/wiki?curid=7671", "title": "Committee on Data of the International Science Council", "text": "Internal open science organization\nThe Committee on Data of the International Science Council (CODATA) was established in 1966 as the Committee on Data for Science and Technology, originally part of the International Council of Scientific Unions, now part of the International Science Council (ISC). Since November 2023 its president is the Catalan researcher Merc\u00e8 Crosas.\nCODATA exists to promote global collaboration to advance open science and to improve the availability and usability of data for all areas of research. CODATA supports the principle that data produced by research and susceptible to being used for research should be as open as possible and as closed as necessary. CODATA works also to advance the interoperability and the usability of such data; research data should be FAIR (findable, accessible, interoperable and reusable). By promoting the policy, technological, and cultural changes that are essential to promote open science, CODATA helps advance ISC's vision and mission of advancing science as a global public good.\nThe CODATA Strategic Plan 2015 and Prospectus of Strategy and Achievement 2016 identify three priority areas:\nCODATA achieves these objectives through a number of standing committees and strategic executive led initiatives, and through its task groups and working groups. CODATA also works closely with member unions and associations of ISC to promote the efforts on open data and open science.\nPublications and conferences.\nCODATA supports the \"Data Science Journal\" and collaborates on major data conferences like SciDataCon and International Data Week.\nIn October 2020 CODATA is co-organising an International FAIR Symposium together with the GO FAIR initiative to provide a forum for advancing international and cross-domain convergence around FAIR. The event will bring together a global data community with an interest in combining data across domains for a host of research issues \u2013 including major global challenges, such as those relating to the Sustainable Development Goals. Outcomes will directly link to the CODATA Decadal Programme Data for the Planet: making data work for cross-domain grand challenges and to the developments of GO FAIR community towards the Internet of FAIR data and services.\nTask Group on Fundamental Physical Constants.\nOne of the CODATA strategic Initiatives and Task Groups concentrates on Fundamental Physical Constants. Established in 1969, its purpose is to periodically provide the international scientific and technological communities with an internationally accepted set of values of the fundamental physical constants and closely related conversion factors for use worldwide.\nThe first such CODATA set was published in 1973. Later versions are named based on the year of the data incorporated; the 1986 CODATA (published April 1987) used data up to 1 January 1986. All subsequent releases use data up to the \"end\" of the stated year, and are necessarily published a year or two later, with an additional gap between the values themselves and the paper explaining how they were arrived at: 1998 (April 2000), 2002 (January 2005), 2006 (June 2008), 2010 (November 2012), 2014 (June 2015), 2018 (May 2019), and 2022 (May/August 2024).\nThe CODATA recommended values of fundamental physical constants are published at the National Institute of Standards and Technology Reference on Constants, Units, and Uncertainty.\nSchedule.\nSince 1998, the task group has produced a new version every four years, incorporating results published up to the end of the specified year.\nIn order to support the 2019 revision of the SI, adopted at the 26th General Conference on Weights and Measures on 16 November 2018, CODATA made a special release that was published in October 2017.\nIt incorporates all data up to 1 July 2017, and determines the final numerical values of \"h\", \"e\", \"k\", and \"N\"A that are used for the new SI definitions.\nThe regular version with a closing date of 31 December 2018 was used to produce the new 2018 CODATA values that were made available by the time the revised SI came into force on 20 May 2019. This was necessary because the redefinitions have a significant (mostly beneficial) effect on the uncertainties and correlation coefficients reported by CODATA.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "7672", "revid": "50551861", "url": "https://en.wikipedia.org/wiki?curid=7672", "title": "Chuck Jones", "text": "American animator and filmmaker (1912\u20132002)\nCharles Martin Jones (September 21, 1912 \u2013 February 22, 2002) was an American animator, painter, and voice actor, best known for his work with Warner Bros. Cartoons on the \"Looney Tunes\" and \"Merrie Melodies\" series of shorts. He wrote, produced, and/or directed many classic animated cartoon shorts starring Bugs Bunny, Daffy Duck, Wile E. Coyote and the Road Runner, Pep\u00e9 Le Pew, Marvin the Martian, and Porky Pig, among others.\nJones started his career in 1933 alongside Tex Avery, Friz Freleng, Bob Clampett, and Robert McKimson at the Leon Schlesinger Production's Termite Terrace studio, the studio that made Warner Brothers cartoons, where they created and developed the Looney Tunes characters. During the Second World War, Jones directed many of the \"Private Snafu\" (1943\u20131946) shorts which were shown to members of the United States military. After his career at Warner Bros. ended in 1962, Jones started Sib Tower 12 Productions and began producing cartoons for Metro-Goldwyn-Mayer, including a new series of (1963\u20131967) as well as the television adaptations of Dr. Seuss's \"How the Grinch Stole Christmas!\" (1966) and \"Horton Hears a Who!\" (1970). He later started his own studio, Chuck Jones Enterprises, where he directed and produced the film adaptation of Norton Juster's \"The Phantom Tollbooth\" (1970).\nJones's work along with the other animators was showcased in the documentary ' (1975). Jones directed the first feature-length animated \"Looney Tunes\" compilation film, \"The Bugs Bunny/Road Runner Movie\" (1979). In 1990 he wrote his memoir, \"Chuck Amuck: The Life and Times of an Animated Cartoonist\", which was made into a documentary film, ' (1991). He was also profiled in the American Masters documentary \"\" (2000) which aired on PBS.\nTwo Warner Brothers cartoons that Jones directed, \"For Scent-imental Reasons\" and \"So Much for So Little\", won Academy Awards for Best Animated Short Film, though at this time it was customary for the statuette to be given to a cartoon's producer, not the director. Jones did not receive a Best Animated Short Film Oscar of his own until winning for \"The Dot and the Line\" in 1966. Robin Williams later presented Jones with an Honorary Academy Award in 1996 for his work in the animation industry. Film historian Leonard Maltin has praised Jones's work at Warner Bros., MGM and Chuck Jones Enterprises. In Jerry Beck's 1994 book \"The 50 Greatest Cartoons\", a group of animation professionals ranked \"What's Opera, Doc?\" (1957) as the greatest cartoon of all time, with ten of the entries being directed by Jones including \"Duck Amuck\" (1953), \"Duck Dodgers in the 24\u00bdth Century\" (1953), \"One Froggy Evening\" (1955), \"Rabbit of Seville\" (1950), and \"Rabbit Seasoning\" (1952).\nEarly life.\nCharles Martin Jones was born on September 21, 1912, in Spokane, Washington, to Mabel McQuiddy (n\u00e9e Martin) and Charles Adams Jones. When he was six months old, he moved with his parents and three siblings to Los Angeles, California.\nIn his autobiography, \"Chuck Amuck\", Jones credits his artistic bent to circumstances surrounding his father, who was an unsuccessful businessman in California in the 1920s. He recounted that his father would start every new business venture by purchasing new stationery and new pencils with the company name on them. When the business failed, his father would quietly turn the huge stacks of useless stationery and pencils over to his children, requiring them to use up all the material as fast as possible. The children drew frequently, owing to the abundance of high-quality paper and pencils. Later, in one art school class, the professor gravely informed the students that they each had 100,000 bad drawings in them that they must first get past before they could possibly draw anything worthwhile. Jones recounted years later that this pronouncement came as a great relief to him, as he was well past the 200,000 mark, having used up all that stationery. Jones and several of his siblings went on to artistic careers.\nDuring his artistic education, he worked part-time as a janitor. After graduating from Chouinard Art Institute, Jones got a phone call from a friend named Fred Kopietz, who had been hired by the Ub Iwerks studio and offered him a job. He worked his way up in the animation industry, starting as a cel washer; \"then I moved up to become a painter in black and white, some color. Then I went on to take animator's drawings and traced them onto the celluloid. Then I became what they call an in-betweener, which is the guy that does the drawing between the drawings the animator makes\". While at Iwerks, he met a cel painter named Dorothy Webster, who later became his first wife.\nInfluences.\nWhen he was a kid, Jones loved to read any fiction and non fiction authors such as Charles Dickens, Rudyard Kipling and his favorite was Mark Twain. He also liked cinema mainly admiring the works of Laurel &amp; Hardy, Charlie Chaplin, Buster Keaton and The Marx Brothers. His main graphic influences was Winsor McCay, and later cited Walt Disney and Tex Avery, as well as comic artist Ronald Searle.\nCareer.\nWarner Bros. Cartoons.\nJones joined Leon Schlesinger Productions, the independent studio that produced \"Looney Tunes\" and \"Merrie Melodies\" for Warner Bros., in 1933 as an assistant animator. In 1935 he was promoted to animator and assigned to work with a new Schlesinger director, Tex Avery. There was no room for the new Avery unit in Schlesinger's small studio, so Avery, Jones, and fellow animators Bob Clampett, Virgil Ross, and Sid Sutherland were moved into a small adjacent building they dubbed \"Termite Terrace\". In 1937, Jones' old boss Ub Iwerks was subcontracted to produce several \"Looney Tunes\" shorts for Schlesinger, with Clampett and Jones brought in to assist him. Iwerks completed only two shorts before he left, with Clampett taking his position soon after. Jones worked alongside Clampett as an animator and an uncredited co-director (or \"supervisor\", the original title for an animation director in the studio) before becoming a main director himself in 1938 when Frank Tashlin left the studio, a position that was initially offered to animator Robert McKimson. The following year, Jones created his first major character, Sniffles, a cute Disney-style mouse, who went on to star in twelve Warner Bros. cartoons.\nJones initially struggled in with his directorial style in his formative years. Unlike the other directors in the studio, Jones wanted to make cartoons that would rival the quality and tone to that of ones made by Walt Disney Productions. However, his cartoons suffered from sluggish pacing and confusing gags, with Jones himself later describing his early conception of timing and dialog to have been \"formed by watching the action in the La Brea Tar Pits\". Schlesinger and the studio heads were unsatisfied with his Disney-esque style and demanded him make cartoons that were more funny. Jones began to change of directorial style starting with the 1942 short \"The Draft Horse\", but the cartoon that was generally considered his true turning point was \"The Dover Boys\" later that year. The short became highly-regarded in recent years for its quick-timed gags and extensive use of limited animation. Despite this, Schlesinger and the studios heads were still dissatisfied and begun the process to fire him, but they were unable to find a replacement due to a labor shortage stemming from World War II, so Jones kept his position.\nHe was actively involved in efforts to unionize the staff of Leon Schlesinger Studios. He was responsible for recruiting animators, layout men, and background people. Almost all animators joined, in reaction to salary cuts imposed by Leon Schlesinger. The Metro-Goldwyn-Mayer cartoon studio had already signed a union contract, encouraging their counterparts under Schlesinger. In a meeting with his staff, Schlesinger talked for a few minutes, then turned over the meeting to his attorney. His insulting manner had a unifying effect on the staff. Jones gave a pep talk at the union headquarters. As negotiations broke down, the staff decided to go on strike. Schlesinger locked them out of the studio for a few days, before agreeing to sign the contract. A Labor-Management Committee was formed and Jones served as a moderator. Because of his role as a supervisor in the studio, he could not himself join the union.\nDuring World War II, Jones worked closely with Theodor Geisel, better known as Dr. Seuss, to create the \"Private Snafu\" series of Army educational cartoons (the character was created by director Frank Capra). Jones later collaborated with Seuss on animated adaptations of Seuss' books, including \"How the Grinch Stole Christmas!\" in 1966. Jones directed such shorts as \"The Weakly Reporter\", a 1944 short that related to shortages and rationing on the home front. During the same year, he directed UPA's second short subject \"Hell-Bent for Election\", a propaganda campaign film for Franklin D. Roosevelt.\nJones created characters through the late 1930s, late 1940s, and the 1950s, which include his collaborative help in co-developing Bugs Bunny and also included creating Claude Cat, Marc Antony and Pussyfoot, Charlie Dog, Michigan J. Frog, Gossamer, and his four most popular creations, Marvin the Martian, Pep\u00e9 Le Pew, Wile E. Coyote and the Road Runner. Jones and writer Michael Maltese collaborated on the Road Runner cartoons, \"Duck Amuck\", \"One Froggy Evening\", and \"What's Opera, Doc?\". Other staff at Unit A with whom Jones collaborated include layout artist, background designer, and co-director Maurice Noble; animator and co-director Abe Levitow; and animators Ken Harris and Ben Washam.\nJones remained at Warner Bros. throughout the 1950s, except for a brief period in 1953 when Warner closed the animation studio. During this interim, Jones found employment at Walt Disney Productions, where he teamed with Ward Kimball for four months. According to Kimball, Jones expected to work at Disney at a higher salary then at Warner Bros., but was instead employed at the same salary despite numerous negotiations with Walt Disney. Furthermore, Jones was not given directorial assignments but was instead assigned to assist Kimball on \"Sleeping Beauty\" (1959), which at the time was enduring production delays. Upon Warner Bros. Cartoons reopening, Jones was rehired and reunited with most of his unit. Despite the unsatisfying tenure, Jones still held the Disney studio in high regard, but later joked that the only job worth having at Disney belonged to Walt.\nIn the early 1960s, Jones and his wife Dorothy wrote the screenplay for the animated feature \"Gay Purr-ee\". The finished film included the voices of Judy Garland, Robert Goulet, and Red Buttons as cats in Paris. The feature was produced by UPA and directed by Jones' former Warner Bros. collaborator, Abe Levitow. Jones was moonlighting to work on the film as he had an exclusive contract with Warner Bros. UPA completed the film and made it available for distribution in 1962, whereupon it was picked up by Warner Bros. When Warner Bros. discovered that Jones had violated his exclusive contract with them, they terminated him. Jones's former animation unit was laid off after completing the final cartoon in their pipeline, \"The Iceman Ducketh\", and the rest of the Warner Bros. Cartoons studio was closed in 1963.\nMGM Animation/Visual Arts.\nWith business partner Les Goldman, Jones started an independent animation studio, Tower 12, Inc. (later Sib Tower 12 Productions after Walter Bien's SIB Productions took over), and brought on most of his unit from Warner Bros., including Maurice Noble and Michael Maltese. In 1963, Metro-Goldwyn-Mayer contracted with Sib Tower 12 to have Jones and his staff produce new \"Tom and Jerry\" cartoons as well as a television adaptation of all \"Tom and Jerry\" theatricals produced to that date. This included major editing, including writing out the African-American maid, Mammy Two-Shoes, and replacing her with one of Irish descent voiced by June Foray. In 1964, Sib Tower 12 was absorbed by MGM and was renamed MGM Animation/Visual Arts. His animated short film, \"The Dot and the Line: A Romance in Lower Mathematics\", won the 1965 Academy Award for Best Animated Short Film. Jones directed the classic animated short \"The Bear That Wasn't\".\nIn 1966, he produced and directed the TV special \"How the Grinch Stole Christmas!\", featuring narration by Boris Karloff.\nJones continued to work on other TV specials such as \"Horton Hears a Who!\" (1970), but his main focus during this time was producing the feature film \"The Phantom Tollbooth\", which did lukewarm business when MGM released it in 1970. Jones co-directed 1969's \"The Pogo Special Birthday Special\", based on the Walt Kelly comic strip, and voiced the characters of Porky Pine and Bun Rab. It was at this point that he decided to start ST Incorporated.\nChuck Jones Enterprises.\nMGM closed the animation division in 1970, and Jones once again started his own studio, Chuck Jones Enterprises. He produced a Saturday morning children's TV series for the American Broadcasting Company called \"The Curiosity Shop\" in 1971. In 1973, he produced an animated version of the George Selden book \"The Cricket in Times Square\" and subsequently produced two sequels.\nThree of his works during this period were animated TV adaptations of short stories from Rudyard Kipling's \"The Jungle Book\": \"Mowgli's Brothers\", \"The White Seal\" and \"Rikki-Tikki-Tavi\". During this period, Jones began to experiment with more realistically designed characters, most of which had larger eyes, leaner bodies, and altered proportions, such as those of the \"Looney Tunes\" characters.\nReturn to Warner Bros..\nJones resumed working with Warner Bros. in 1976 with the animated TV adaptation of \"The Carnival of the Animals\" with Bugs Bunny and Daffy Duck. Jones also produced \"The Bugs Bunny/Road Runner Movie\" (1979), which was a compilation of Jones's best theatrical shorts, new Road Runner shorts for \"The Electric Company\" series and \"Bugs Bunny's Looney Christmas Tales\" (1979). New shorts were made for \"Bugs Bunny's Bustin' Out All Over\" (1980).\nFrom 1977 to 1978, Jones wrote and drew the newspaper comic strip \"Crawford\" (also known as \"Crawford &amp; Morgan\") for the Chicago Tribune-NY News Syndicate. In 2011 IDW Publishing collected Jones's strip as part of their Library of American Comic Strips.\nIn 1978, Jones's wife Dorothy died. He married Marian Dern, the writer of the comic strip \"Rick O'Shay\" in 1981.\nControversy.\nJones\u2013Avery letter.\nOn December 11, 1975, shortly after the release of \"\", which prominently featured Bob Clampett, Jones wrote a letter to Tex Avery, accusing Clampett of taking credit for ideas that were not his, and for characters created by other directors (notably Jones's Sniffles and Friz Freleng's Yosemite Sam). Their correspondence was never published in the media. It was forwarded to Michael Barrier, who had conducted the interview with Clampett, and over the years Jones distributed it to multiple people concerned with animation.\nLater years.\nThrough the 1980s and 1990s, Jones was painting cartoon and parody art, sold through animation galleries by his daughter's company, Linda Jones Enterprises. Jones was the creative consultant and character designer for two Raggedy Ann animated specials and the first \"Alvin and the Chipmunks\" Christmas special \"A Chipmunk Christmas\". He made a cameo appearance in the film \"Gremlins\" (1984) and he wrote and directed the Bugs Bunny/Daffy Duck animated sequences that bookend its sequel \"\" (1990). Jones directed animated sequences for various features such as a lengthy sequence in the film \"Stay Tuned\" (1992) and a shorter one seen at the start of the Robin Williams vehicle \"Mrs. Doubtfire\" (1993). Also during the 1980s and 1990s, Jones served on the advisory board of the National Student Film Institute. In 1993, he started Chuck Jones Film Productions with a contract at Warner Bros. to produce new animated \"Looney Tunes\" shorts for theatrical release. The venture was later dissolved in 1996.\nJones's final Looney Tunes cartoon was \"From Hare to Eternity\" (1997), which starred Bugs Bunny and Yosemite Sam, with Greg Burson voicing Bugs. The cartoon was dedicated to Friz Freleng, who had died in 1995. Jones's final animation project was a series of 13 shorts starring a timber wolf character he had designed in the 1960s named Thomas Timber Wolf. The series was released online by Warner Bros. in 2000. From 2001 until 2004, Cartoon Network aired \"The Chuck Jones Show\" which features shorts directed by him. The show won the Annie Award for Outstanding Achievement in an Animated Special Project.\nIn 1997, Jones was awarded the Edward MacDowell Medal.\nIn 1999, he founded the non-profit Chuck Jones Center for Creativity, in Costa Mesa, California, an art education \"gymnasium for the brain\" dedicated to teaching creative skills, primarily to children and seniors, which is still in operation.\nIn his later years, he recovered from skin cancer and received hip and ankle replacements.\nDeath.\nJones died of congestive heart failure on February 22, 2002, at his home in Corona del Mar, Newport Beach at the age of 89. He was cremated and his ashes were scattered at sea. After his death, Cartoon Network aired a 20-second segment tracing Jones's portrait with the words \"We'll miss you\". Also, the Looney Tunes cartoon \"Daffy Duck for President\", based on the book that Jones had written and using Jones's style for the characters, originally scheduled to be released in 2000, was released in 2004 as part of disc three of the \"\" DVD set.\nLegacy.\nAcademy Awards.\nJones received an Honorary Academy Award in 1996 by the board of governors of the Academy of Motion Picture Arts and Sciences, for \"the creation of classic cartoons and cartoon characters whose animated lives have brought joy to our real ones for more than half a century.\" At that year's awards show, Robin Williams, a self-confessed \"Jones-aholic\", presented the honorary award to Jones, calling him \"The Orson Welles of cartoons\", and the audience gave Jones a standing ovation as he walked onto the stage. For himself, a flattered Jones wryly remarked in his acceptance speech, \"Well, what can I say in the face of such humiliating evidence? I stand guilty before the world of directing over three hundred cartoons in the last fifty or sixty years. Hopefully, this means you've forgiven me.\" He received the Lifetime Achievement Award at the World Festival of Animated Film \u2013 Animafest Zagreb in 1988.\nHonors.\nJones was a historical authority as well as a major contributor to the development of animation throughout the 20th century. In 1990, Jones received the Golden Plate Award of the American Academy of Achievement. He received an honorary degree from Oglethorpe University in 1993. For his contribution to the motion picture industry, Jones has a star on the Hollywood Walk of Fame at 7011 Hollywood Blvd. He was awarded the Inkpot Award in 1974. In 1996, Jones received an Honorary Oscar at the 68th Academy Awards.\nThree short films directed by Jones have been inducted into the National Film Registry by the United States Film Preservation Board: \"What's Opera, Doc?\", inducted in 1992; \"Duck Amuck,\" inducted in 1999; and \"One Froggy Evening,\" inducted in 2003.\nArt exhibit.\nJones's life and legacy were celebrated on January 12, 2012, with the official grand opening of \"The Chuck Jones Experience\" at Circus Circus Las Vegas.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "7673", "revid": "49214", "url": "https://en.wikipedia.org/wiki?curid=7673", "title": "Costume", "text": "Wardrobe and dress in general\nCostume is the distinctive style of dress and/or makeup of an individual or group that reflects class, gender, occupation, ethnicity, nationality, activity or epoch\u2014in short, culture.\nThe term also was traditionally used to describe typical appropriate clothing for certain activities, such as riding costume, swimming costume, dance costume, and evening costume. Appropriate and acceptable costume is subject to changes in fashion and local cultural norms.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\"But sable is worn more in carriages, lined with real lace over ivory satin, and worn over some smart costume suitable for an afternoon reception.\" \"A Woman's Letter from London\" (23 November 1899).\nThis general usage has gradually been replaced by the terms \"dress\", \"attire\", \"robes\" or \"wear\" and usage of \"costume\" has become more limited to unusual or out-of-date clothing and to attire intended to evoke a change in identity, such as theatrical, Halloween, and mascot costumes.\nBefore the advent of ready-to-wear apparel, clothing was made by hand. When made for commercial sale it was made, as late as the beginning of the 20th century, by \"costumiers\", often women who ran businesses that met the demand for complicated or intimate female costume, including millinery and corsetry.\nEtymology.\nDerived from the Italian language and passed down through French, the term \"costume\" shares its origins with the word signifying fashion or custom. Variedly, the term \"costume,\" indicating clothing exclusively from the eighteenth century onward, can be traced back to the Latin consuetudo, meaning \"custom\" or \"usage.\"\nNational costume.\nNational costume or regional costume expresses local (or exiled) identity and emphasizes a culture's unique attributes. They are often a source of national pride. Examples include the Scottish kilt, Turkish Zeybek, or Japanese kimono.\nIn Bhutan there is a traditional national dress prescribed for men and women, including the monarchy. These have been in vogue for thousands of years and have developed into a distinctive dress style. The dress worn by men is known as Gho which is a robe worn up to knee-length and is fastened at the waist by a band called the Kera. The front part of the dress which is formed like a pouch, in olden days was used to hold baskets of food and short dagger, but now it is used to keep cell phone, purse and the betel nut called \"Doma\". The dress worn by women consist of three pieces known as Kira, Tego and Wonju. The long dress which extends up to the ankle is Kira. The jacket worn above this is Tego which is provided with Wonju, the inner jacket. However, while visiting the Dzong or monastery a long scarf or stoll, called Kabney is worn by men across the shoulder, in colours appropriate to their ranks. Women also wear scarfs or stolls called Rachus, made of raw silk with embroidery, over their shoulder but not indicative of their rank.\nTheatrical costume.\n\"Costume\" often refers to a particular style of clothing worn to portray the wearer as a character or type of character at a social event in a theatrical performance on the stage or in film or television. In combination with other aspects of stagecraft, theatrical costumes can help actors portray characters' and their contexts as well as communicate information about the historical period/era, geographic location and time of day, season or weather of the theatrical performance. Some stylized theatrical costumes, such as Harlequin and Pantaloon in the Commedia dell'arte, exaggerate an aspect of a character.\nIn the tourism industry, some tour guides may wear historical costumes in heritage sites or neighbourhoods, in order to enhance the quality of their tour. Such costumes range from those worn solo or by a group of guides.\nCostume construction.\nA costume technician is a term used for a person that constructs and/or alters the costumes. The costume technician is responsible for taking the two dimensional sketch and translating it to create a garment that resembles the designer's rendering. It is important for a technician to keep the ideas of the designer in mind when building the garment.\nDraping and cutting.\nDraping is the art of manipulating fabric directly on a dress form or body form as the first step to create a pattern. A body form can be padded to a person's specific measurements. Flat drafting is the art of drawing patterns onto paper based on measurements to create a pattern. \nCutting is the act of tracing a pattern onto fabric and cutting out the pieces. These pieces are put together to create a final costume. In costuming, the person who creates a pattern is called a cutter/draper, and in fashion this person is more commonly called a pattern drafter, though both techniques may be used in both fields. Draping is especially useful with stretchy fabrics or bias cut garments as the maker can see how it will be effected by body curves and the pull of gravity.\nReligious festivals.\nWearing costumes is an important part of holidays developed from religious festivals such as Mardi Gras (in the lead up to Easter), and Halloween (related to All Hallow's Eve). Mardi Gras costumes usually take the form of jesters and other fantasy characters; Halloween costumes traditionally take the form of supernatural creatures such as ghosts, vampires, pop-culture icons and angels. Halloween costumes developed from pre-Christian religious traditions: to avoid being terrorized by evil spirits walking the Earth during the harvest festival Samhain, the Celts donned disguises. In the eighth century, Pope Gregory VIII designated November 1 as All Saints Day, and the preceding days as All Hallows Eve; Samhain's costuming tradition was incorporated into these Christian holidays. Given the Catholic and pagan roots of the holiday, it has been repudiated by some Protestants. However, in the modern era, Halloween \"is widely celebrated in almost every corner of American life,\" and the wearing of costumes forms part of a secular tradition. In 2022, United States households spent an average of $100 preparing for Halloween, with $34 going to costume-related spending.\nChristmas costumes typically portray characters such as Santa Claus (developed from Saint Nicholas). In Australia, the United Kingdom and the United States the American version of a Santa suit and beard is popular; in the Netherlands, the costume of Zwarte Piet is customary. Easter costumes are associated with the Easter Bunny or other animal costumes.\nIn Judaism, a common practice is to dress up on Purim. During this holiday, Jews celebrate the change of their destiny. They were delivered from being the victims of an evil decree against them and were instead allowed by the King to destroy their enemies. A quote from the Book of Esther, which says: \"On the contrary\" () is the reason that wearing a costume has become customary for this holiday.\nBuddhist religious festivals in Tibet, Bhutan, Mongolia and Lhasa and Sikkim in India perform the Cham dance, which is a popular dance form utilising masks and costumes.\nParades and processions.\nParades and processions provide opportunities for people to dress up in historical or imaginative costumes. For example, in 1879 the artist Hans Makart designed costumes and scenery to celebrate the wedding anniversary of the Austro-Hungarian Emperor and Empress and led the people of Vienna in a costume parade that became a regular event until the mid-twentieth century. Uncle Sam costumes are worn on Independence Day in the United States. The Lion Dance, which is part of Chinese New Year celebrations, is performed in costume. Some costumes, such as the ones used in the Dragon Dance, need teams of people to create the required effect.\nSporting events and parties.\nPublic sporting events such as fun runs also provide opportunities for wearing costumes, as do private masquerade balls and fancy dress parties.\nMascots.\nCostumes are popularly employed at sporting events, during which fans dress as their team's representative mascot to show their support. Businesses use mascot costumes to bring in people to their business either by placing their mascot in the street by their business or sending their mascot out to sporting events, festivals, national celebrations, fairs, and parades. Mascots appear at organizations wanting to raise awareness of their work. Children's Book authors create mascots from the main character to present at their book signings. Animal costumes that are visually very similar to mascot costumes are also popular among the members of the furry fandom, where the costumes are referred to as fursuits and match one's animal persona, or \"fursona\".\nChildren.\nCostumes also serve as an avenue for children to explore and role-play. For example, children may dress up as characters from history or fiction, such as pirates, princesses, cowboys, or superheroes. They may also dress in uniforms used in common jobs, such as nurses, police officers, or firefighters, or as zoo or farm animals. Young boys tend to prefer costumes that reinforce stereotypical ideas of being male, and young girls tend to prefer costumes that reinforce stereotypical ideas of being female.\nCosplay.\nCosplay, a word of Japanese origin that in English is short for \"costume display\" or \"costume play\", is a performance art in which participants wear costumes and accessories to represent a specific character or idea that is usually always identified with a unique name (as opposed to a generic word). These costume wearers often interact to create a subculture centered on role play, so they can be seen most often in play groups, or at a gathering or convention. A significant number of these costumes are homemade and unique, and depend on the character, idea, or object the costume wearer is attempting to imitate or represent. The costumes themselves are often artistically judged to how well they represent the subject or object that the costume wearer is attempting to contrive.\nDesign.\nCostume design is the envisioning of clothing and the overall appearance of a character or performer. Costume may refer to the style of dress particular to a nation, a class, or a period. In many cases, it may contribute to the fullness of the artistic, visual world that is unique to a particular theatrical or cinematic production. The most basic designs are produced to denote status, provide protection or modesty, or provide visual interest to a character. Costumes may be for, but not limited to, theater, cinema, or musical performances. Costume design should not be confused with costume coordination, which merely involves altering existing clothing, although both processes are used to create stage clothes.\nOrganizations.\nThe Costume Designers Guild's international membership includes motion picture, television, and commercial costume designers, assistant costume designers and costume illustrators, and totals over 750 members.\nThe National Costumers Association is an 80 year old association of professional costumers and costume shops.\nPublications.\n\"The Costume Designer\" is a quarterly magazine devoted to the costume design industry.\nNotable designers and awards.\nNotable costume designers include recipients of the Academy Award for Best Costume Design, Tony Award for Best Costume Design, and Drama Desk Award for Outstanding Costume Design. Edith Head and Orry-Kelly, both of whom were born late in 1897, were two of Hollywood's most notable costume designers.\nIndustry.\nProfessional-grade costumes are typically designed and produced by costume companies who can design and create unique costumes. These companies have often been in business for over 100 years, and continue to work with individual clients to create professional quality costumes.\nProfessional costume houses rent and sell costumes for the trade. This includes companies that create mascots, costumes for film, TV costumes and theatrical costumes.\nLarger costume companies have warehouses full of costumes for rental to customers.\nThere is an industry where costumers work with clients and design costumes from scratch. They then will create original costumes specifically to the clients specifications.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "7674", "revid": "1398", "url": "https://en.wikipedia.org/wiki?curid=7674", "title": "Cable car (railway)", "text": "Cable-hauled mass transit system\nA cable car (usually known as a cable tram outside North America) is a type of cable railway used for mass transit in which rail cars are hauled by a continuously moving cable running at a constant speed. Individual cars stop and start by releasing and gripping this cable as required. Cable cars are distinct from funiculars, where the cars are permanently attached to the cable.\nHistory.\nThe first cable-operated railway to use a moving rope that could be picked up or released by a grip on the cars was the Fawdon Wagonway, a colliery railway line that opened in 1826. \nAnother began operation in 1840: the London and Blackwall Railway, which hauled passengers in east London, England. The rope available at the time proved too susceptible to wear and the system was abandoned in favour of steam locomotives after eight years. \nIn America, the first cable car installation in operation probably was the West Side and Yonkers Patent Railway, New York City's first-ever elevated railway, which ran from 1 July 1868 to 1870. The collar-equipped cables and claw-equipped cars proving cumbersome, and the line was closed and rebuilt to operate with steam locomotives.\nIn 1869, P. G. T. Beauregard demonstrated a cable car at New Orleans and was issued https://.\nIn 1873, the Clay Street Hill Railroad, which later became part of the San Francisco cable car system, was first tested. Promoted by Andrew Smith Hallidie with design work by William Eppelsheimer, the line's grips became the model for other cable car transit systems, whose cars were often known as the \"Hallidie Cable Car\".\nIn 1881, the first such system opened outside San Francisco: the Dunedin cable tramway system in Dunedin, New Zealand. For Dunedin, George Smith Duncan further developed the Hallidie model, introducing the pull curve and the slot brake; the former was a way to pull cars through a curve, since Dunedin's curves were too sharp to allow coasting, while the latter forced a wedge down into the cable slot to stop the car. Both of these innovations were generally adopted by other cities, including San Francisco.\nIn Australia: the Melbourne cable tramway system operated from 1885 to 1940 and was one of the most extensive in the world with 1200 trams and trailers operating over 15 routes with 103\u00a0km (64 miles) of track; while Sydney had two cable tram routes - Milsons Point to North Sydney (1886-1905) and King Street Wharf to Edgecliff (1894-1905).\nCable cars rapidly spread to other cities, although the major attraction for most was the ability to displace horsecar (or mule-drawn) systems rather than the ability to climb hills. Many people at the time viewed horse-drawn transit as unnecessarily cruel, and the fact that a typical horse could work only four or five hours per day necessitated the maintenance of large stables of draft animals that had to be fed, housed, groomed, medicated and rested. Thus, for a period, economics worked in favour of cable cars even in relatively flat cities.\nFor example, the Chicago City Railway, also designed by Eppelsheimer, opened in Chicago in 1882 and went on to become the largest and most profitable cable car system. As with many cities, the problem in flat Chicago was not one of incline, but of transportation capacity. This caused a different approach to the combination of grip car and trailer. Rather than using a grip car and single trailer, as many cities did, or combining the grip and trailer into a single car, like San Francisco's \"California Cars\", Chicago used grip cars to pull trains of up to three trailers.\nIn 1883 the New York and Brooklyn Bridge Railway was opened, which had a most curious feature: though it was a cable car system, it used steam locomotives to get the cars into and out of the terminals. After 1896 the system was changed to one on which a motor car was added to each train to maneuver at the terminals, while en route, the trains were still propelled by the cable.\nOn 25 September 1883, a test of a cable car system was held by Liverpool Tramways Company in Kirkdale, Liverpool. This would have been the first cable car system in Europe, but the company decided against implementing it. Instead, the distinction went to the 1884 Highgate Hill Cable Tramway, a route from Archway to Highgate, north London, which used a continuous cable and grip system on the 1 in 11 (9%) climb of Highgate Hill. The installation was not reliable and was replaced by electric traction in 1909. Other cable car systems were implemented in Europe, though, among which was the Glasgow District Subway, the first underground cable car system, in 1896. (London, England's first deep-level tube railway, the City &amp; South London Railway, had earlier also been built for cable haulage but had been converted to electric traction before opening in 1890.) A few more cable car systems were built in the United Kingdom, Portugal, and France. European cities, having many more curves in their streets, were ultimately less suitable for cable cars than American cities.\nThough some new cable car systems were still being built, by 1890 the cheaper to construct and simpler to operate electrically-powered trolley or tram started to become the norm, and eventually started to replace existing cable car systems. For a while hybrid cable/electric systems operated, for example in Chicago where electric cars had to be pulled by grip cars through the loop area, due to the lack of trolley wires there. Eventually, San Francisco became the only street-running manually operated system to survive\u00a0\u2013 Dunedin, the second city with such cars, was also the second-last city to operate them, closing down in 1957.\nRecent revival.\nIn the last decades of the 20th century and the early 21st century, cable traction in general has seen a limited revival as automatic people movers, used in resort areas, airports (for example, Terminal Link at Toronto Pearson International Airport opening in 2006 and Oakland Airport Connector at Oakland International Airport, San Francisco), huge hospital centers and some urban settings. While many of these systems involve cars permanently attached to the cable, the Minimetro system from Poma/Leitner Group and the Cable Liner system from DCC Doppelmayr Cable Car both have variants that allow the cars to be automatically decoupled from the cable under computer control, and can thus be considered a modern interpretation of the cable car.\nOperation.\nThe cable is itself powered by a stationary engine or motor situated in a cable house or power house. The speed at which it moves is relatively constant depending on the number of units gripping the cable at any given time.\nThe cable car begins moving when a clamping device attached to the car, called a \"grip\", applies pressure to (\"grip\") the moving cable. Conversely, the car is stopped by releasing pressure on the cable (with or without completely detaching) and applying the brakes. This gripping and releasing action may be manual, as was the case in all early cable car systems, or automatic, as is the case in some recent cable operated people mover type systems. Gripping must be applied evenly and gradually in order to avoid bringing the car to cable speed too quickly and unacceptably jarring passengers.\nThe grip of manual systems resembles a large pair of pliers, and considerable strength and skill are required to operate the car. As many early cable car operators discovered, an improperly applied grip can damage the cable. A grip can also become entangled in the cable; when this happens, the cable car may not be able to stop and can wreak havoc along its route until the cable house realizes the mishap and halts the cable.\nOne apparent advantage of the cable car is its relative energy efficiency. This is due to the economy of centrally located power stations, and the ability of descending cars to transfer energy to ascending cars. However, this advantage is totally negated by the relatively large energy consumption required to simply move the cable over and under the numerous guide rollers and around the many sheaves. Approximately 95% of the tractive effort in the San Francisco system is expended in simply moving the four cables at . Electric cars with regenerative braking do offer the advantages, without the problem of moving a cable. In the case of steep grades, however, cable traction has the major advantage of not depending on adhesion between wheels and rails. There is also the advantage that keeping the car gripped to the cable will also limit the downhill speed of the car to that of the cable and provide counterbalance to uphill cars.\nBecause of the constant and relatively low speed, a cable car's potential to cause harm in an accident can be underestimated. Even with a cable car traveling at only , the mass of the cable car and the combined strength and speed of the cable can cause extensive damage in a collision.\nRelation to funiculars.\nA cable car is superficially similar to a funicular, but differs from such a system in that its cars are not permanently attached to the cable and can stop independently, whereas a funicular has cars that are permanently attached to the propulsion cable, which is itself stopped and started. A cable car cannot climb as steep a grade as a funicular, but many more cars can be operated with a single cable, making it more flexible, and allowing a higher capacity. During the rush hour on San Francisco's Market Street Railway in 1883, a car would leave the terminal every 15 seconds.\nA few funicular railways operate in street traffic, and because of this operation are often incorrectly described as cable cars. Examples of such operation, and the consequent confusion, are:\nEven more confusingly, a hybrid cable car/funicular line once existed in the form of the original Wellington Cable Car, in the New Zealand city of Wellington. This line had both a continuous loop haulage cable that the cars gripped using a cable car gripper, and a balance cable permanently attached to both cars over an undriven pulley at the top of the line. The descending car gripped the haulage cable and was pulled downhill, in turn pulling the ascending car (which remained ungripped) uphill by the balance cable. This line was rebuilt in 1979 and is now a standard funicular, although it retains its old cable car name.\nList of cable car systems.\nCities currently operating cable cars.\nTraditional cable car systems.\nThe only known existing traditional cable car system is the San Francisco cable car system in the city of San Francisco, California. San Francisco's cable cars constitute the oldest and largest such system in permanent operation, and it is one of the few still functioning in the traditional manner, with manually operated cars running in street traffic. Other examples of cable powered street running systems can be found on the Great Orme in North Wales, and in Lisbon in Portugal. Both of these, however, are funiculars.\nModern cable car systems.\nSeveral cities operate a modern version of the cable car system. These systems are fully automated and run on their own reserved right of way. They are commonly referred to as people movers, although that term is also applied to systems with other forms of propulsion, including funicular style cable propulsion.\nThese cities include:\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nExternal links.\nInformation\nPatents"}
{"id": "7676", "revid": "39029752", "url": "https://en.wikipedia.org/wiki?curid=7676", "title": "Creaky voice", "text": "Type of phonation\nIn linguistics, creaky voice (sometimes called laryngealisation, pulse phonation, vocal fry, or glottal fry) refers to a low, scratchy sound that occupies the vocal range below the common vocal register. It is a special kind of phonation in which the arytenoid cartilages in the larynx are drawn together; as a result, the vocal folds are compressed rather tightly, becoming relatively slack and compact. They normally vibrate irregularly at 20\u201350 pulses per second, about two octaves below the frequency of modal voicing, and the airflow through the glottis is very slow. Although creaky voice may occur with very low pitch, as at the end of a long intonation unit, it can also occur with a higher pitch. All contribute to make a speaker's voice sound creaky or raspy. \nIn phonology.\nIn the Received Pronunciation of English, creaky voice has been described as a possible realisation of glottal reinforcement. For example, an alternative phonetic transcription of \"attempt\" could be .\nIn some languages, such as Jalapa Mazatec, creaky voice has a phonemic status; that is, the presence or absence of creaky voice can change the meaning of a word. In the International Phonetic Alphabet, creaky voice of a phone is represented by a diacritical tilde , for example . The Danish prosodic feature \"st\u00f8d\" is an example of a form of laryngealisation that has a phonemic function. A slight degree of laryngealisation, occurring in some Korean language consonants for example, is called \"stiff voice\".\nSocial aspects.\nUse of creaky voice across general speech and in singing is termed \"vocal fry\".\nSome evidence exists of vocal fry becoming more common in the speech of young female speakers of American English in the early 21st century, with researcher Ikuko Patricia Yuasa finding that college-age Americans perceived female creaky voice as \"hesitant, nonaggressive, and informal but also educated, urban-oriented, and upwardly mobile.\" Yuasa further theorizes that because California is at the center of much of the entertainment industry, young Americans may unconsciously be using creaky voice more because of the media they consume.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "7677", "revid": "910180", "url": "https://en.wikipedia.org/wiki?curid=7677", "title": "Computer monitor", "text": "Computer output device\nA computer monitor is an output device that displays information in pictorial or textual form. A discrete monitor comprises a visual display, support electronics, power supply, housing, electrical connectors, and external user controls.\nThe display in modern monitors is typically an LCD with LED backlight, having by the 2010s replaced CCFL backlit LCDs. Before the mid-2000s, most monitors used a cathode-ray tube (CRT) as the image output technology. A monitor is typically connected to its host computer via DisplayPort, HDMI, USB-C, DVI, or VGA. Monitors sometimes use other proprietary connectors and signals to connect to a computer, which is less common.\nOriginally computer monitors were used for data processing while television sets were used for video. From the 1980s onward, computers (and their monitors) have been used for both data processing and video, while televisions have implemented some computer functionality. Since 2010, the typical display aspect ratio of both televisions and computer monitors changed from 4:3 to 16:9\nModern computer monitors are often functionally interchangeable with television sets and vice versa. As most computer monitors do not include integrated speakers, TV tuners, or remote controls, external components such as a DTA box may be needed to use a computer monitor as a TV set.\nHistory.\nEarly electronic computer front panels were fitted with an array of light bulbs where the state of each particular bulb would indicate the on/off state of a particular register bit inside the computer. This allowed the engineers operating the computer to monitor the internal state of the machine, so this panel of lights came to be known as the 'monitor'. As early monitors were only capable of displaying a very limited amount of information and were very transient, they were rarely considered for program output. Instead, a line printer was the primary output device, while the monitor was limited to keeping track of the program's operation.\nComputer monitors were formerly known as visual display units (VDU), particularly in British English. This term mostly fell out of use by the 1990s.\nTechnologies.\nMultiple technologies have been used for computer monitors. Until the 21st century most used cathode-ray tubes but they have largely been superseded by LCD monitors.\nCathode-ray tube.\nThe first computer monitors used cathode-ray tubes (CRTs). Prior to the advent of home computers in the late 1970s, it was common for a video display terminal (VDT) using a CRT to be physically integrated with a keyboard and other components of the workstation in a single large chassis, typically limiting them to emulation of a paper teletypewriter, thus the early epithet of 'glass TTY'. The display was monochromatic and far less sharp and detailed than on a modern monitor, necessitating the use of relatively large text and severely limiting the amount of information that could be displayed at one time. High-resolution CRT displays were developed for specialized military, industrial and scientific applications but they were far too costly for general use; wider commercial use became possible after the release of a slow, but affordable Tektronix 4010 terminal in 1972.\nSome of the earliest home \ncomputers (such as the TRS-80 and Commodore PET) were limited to monochrome CRT displays, but color display capability was already a possible feature for a few MOS 6500 series-based machines (such as introduced in 1977 Apple II computer or Atari 2600 console), and the color output was a specialty of the more graphically sophisticated Atari 8-bit computers, introduced in 1979. Either computer could be connected to the antenna terminals of an ordinary color TV set or used with a purpose-made CRT color monitor for optimum resolution and color quality. Lagging several years behind, in 1981 IBM introduced the Color Graphics Adapter, which could display four colors with a resolution of pixels, or it could produce pixels with two colors. In 1984 IBM introduced the Enhanced Graphics Adapter which was capable of producing 16 colors and had a resolution of .\nBy the end of the 1980s color progressive scan CRT monitors were widely available and increasingly affordable, while the sharpest prosumer monitors could clearly display high-definition video, against the backdrop of efforts at HDTV standardization from the 1970s to the 1980s failing continuously, leaving consumer SDTVs to stagnate increasingly far behind the capabilities of computer CRT monitors well into the 2000s. During the following decade, maximum display resolutions gradually increased and prices continued to fall as CRT technology remained dominant in the PC monitor market into the new millennium, partly because it remained cheaper to produce. CRTs still offer color, grayscale, motion, and latency advantages over today's LCDs, but improvements to the latter have made them much less obvious. The dynamic range of early LCD panels was very poor, and although text and other motionless graphics were sharper than on a CRT, an LCD characteristic known as pixel lag caused moving graphics to appear noticeably smeared and blurry.\nLiquid-crystal display.\nThere are multiple technologies that have been used to implement liquid-crystal displays (LCD). Throughout the 1990s, the primary use of LCD technology as computer monitors was in laptops where the lower power consumption, lighter weight, and smaller physical size of LCDs justified the higher price versus a CRT. Commonly, the same laptop would be offered with an assortment of display options at increasing price points: (active or passive) monochrome, passive color, or active matrix color (TFT). As volume and manufacturing capability have improved, the monochrome and passive color technologies were dropped from most product lines.\nTFT-LCD is a variant of LCD which is now the dominant technology used for computer monitors.\nThe first standalone LCDs appeared in the mid-1990s selling for high prices. As prices declined they became more popular, and by 1997 were competing with CRT monitors. Among the first desktop LCD computer monitors were the Eizo FlexScan L66 in the mid-1990s, the SGI 1600SW, Apple Studio Display and the ViewSonic VP140 in 1998. In 2003, LCDs outsold CRTs for the first time, becoming the primary technology used for computer monitors. The physical advantages of LCD over CRT monitors are that LCDs are lighter, smaller, and consume less power. In terms of performance, LCDs produce less or no flicker, reducing eyestrain, sharper image at native resolution, and better checkerboard contrast. On the other hand, CRT monitors have superior blacks, viewing angles, and response time, can use arbitrary lower resolutions without aliasing, and flicker can be reduced with higher refresh rates, though this flicker can also be used to reduce motion blur compared to less flickery displays such as most LCDs. Many specialized fields such as vision science remain dependent on CRTs, the best LCD monitors having achieved moderate temporal accuracy, and so can be used only if their poor spatial accuracy is unimportant.\nHigh dynamic range (HDR) has been implemented into high-end LCD monitors to improve grayscale accuracy. Since around the late 2000s, widescreen LCD monitors have become popular, in part due to television series, motion pictures and video games transitioning to widescreen, which makes squarer monitors unsuited to display them correctly.\nOrganic light-emitting diode.\nOrganic light-emitting diode (OLED) monitors provide most of the benefits of both LCD and CRT monitors with few of their drawbacks, though much like plasma panels or very early CRTs they suffer from burn-in, and remain very expensive.\nMeasurements of performance.\nThe performance of a monitor is measured by the following parameters:\nSize.\nOn two-dimensional display devices such as computer monitors the display size or viewable image size is the actual amount of screen space that is available to display a picture, video or working space, without obstruction from the bezel or other aspects of the unit's design. The main measurements for display devices are width, height, total area and the diagonal.\nThe size of a display is usually given by manufacturers diagonally, i.e. as the distance between two opposite screen corners. This method of measurement is inherited from the method used for the first generation of CRT television when picture tubes with circular faces were in common use. Being circular, it was the external diameter of the glass envelope that described their size. Since these circular tubes were used to display rectangular images, the diagonal measurement of the rectangular image was smaller than the diameter of the tube's face (due to the thickness of the glass). This method continued even when cathode-ray tubes were manufactured as rounded rectangles; it had the advantage of being a single number specifying the size and was not confusing when the aspect ratio was universally 4:3.\nWith the introduction of flat-panel technology, the diagonal measurement became the actual diagonal of the visible display. This meant that an eighteen-inch LCD had a larger viewable area than an eighteen-inch cathode-ray tube.\nEstimation of monitor size by the distance between opposite corners does not take into account the display aspect ratio, so that for example a 16:9 widescreen display has less area, than a 4:3 screen. The 4:3 screen has dimensions of and an area , while the widescreen is , .\nAspect ratio.\nUntil about 2001, most computer monitors had a aspect ratio and some had or . Between 2001 and 2006, monitors with and mostly (8:5) aspect ratios became commonly available, first in laptops and later also in standalone monitors. Reasons for this transition included productive uses (i.e. field of view in video games and movie viewing) such as the word processor display of two standard letter pages side by side, as well as CAD displays of large-size drawings and application menus at the same time. In 2008 16:10 became the most common sold aspect ratio for LCD monitors and the same year 16:10 was the mainstream standard for laptops and notebook computers.\nIn 2010, the computer industry started to move over from to because 16:9 was chosen to be the standard high-definition television display size, and because they were cheaper to manufacture.\nIn 2011, non-widescreen displays with 4:3 aspect ratios were only being manufactured in small quantities. According to Samsung, this was because the \"Demand for the old 'Square monitors' has decreased rapidly over the last couple of years,\" and \"I predict that by the end of 2011, production on all 4:3 or similar panels will be halted due to a lack of demand.\"\nResolution.\nThe resolution for computer monitors has increased over time. From during the late 1970s, to during the late 1990s. Since 2009, the most commonly sold resolution for computer monitors is , shared with the 1080p of HDTV. Before 2013 mass market LCD monitors were limited to at , excluding niche professional monitors. By 2015 most major display manufacturers had released (4K UHD) displays, and the first (8K) monitors had begun shipping.\nGamut.\nEvery RGB monitor has its own color gamut, bounded in chromaticity by a color triangle. Some of these triangles are smaller than the sRGB triangle, some are larger. Colors are typically encoded by 8 bits per primary color. The RGB value [255, 0, 0] represents red, but slightly different colors in different color spaces such as Adobe RGB and sRGB. Displaying sRGB-encoded data on wide-gamut devices can give an unrealistic result. The gamut is a property of the monitor; the image color space can be forwarded as Exif metadata in the picture. As long as the monitor gamut is wider than the color space gamut, correct display is possible, if the monitor is calibrated. A picture that uses colors that are outside the sRGB color space will display on an sRGB color space monitor with limitations. Still today, many monitors that can display the sRGB color space are not factory nor user-calibrated to display it correctly. Color management is needed both in electronic publishing (via the Internet for display in browsers) and in desktop publishing targeted to print.\nPower saving\nAdditional features.\nUniversal features.\nMost modern monitors will switch to a power-saving mode if no video-input signal is received. This allows modern operating systems to turn off a monitor after a specified period of inactivity. This also extends the monitor's service life. Some monitors will also switch themselves off after a time period on standby.\nMost modern laptops provide a method of screen dimming after periods of inactivity or when the battery is in use. This extends battery life and reduces wear.\nIndicator light\nMost modern monitors have two different indicator light colors wherein if video-input signal was detected, the indicator light is green and when the monitor is in power-saving mode, the screen is black and the indicator light is orange. Some monitors have different indicator light colors and some monitors have a blinking indicator light when in power-saving mode.\nIntegrated accessories\nMany monitors have other accessories (or connections for them) integrated. This places standard ports within easy reach and eliminates the need for another separate hub, camera, microphone, or set of speakers. These monitors have advanced microprocessors which contain codec information, Windows interface drivers and other small software which help in proper functioning of these functions.\nUltrawide screens\nMonitors that feature an aspect ratio greater than 2:1 (for instance, 21:9 or 32:9, as opposed to the more common 16:9, which resolves to 1.77:1).Monitors with an aspect ratio greater than 3:1 are marketed as super ultrawide monitors. These are typically massive curved screens intended to replace a multi-monitor deployment.\nTouch screen\nThese monitors use touching of the screen as an input method. Items can be selected or moved with a finger, and finger gestures may be used to convey commands. The screen will need frequent cleaning due to image degradation from fingerprints.\nSensors\nGlossy screen\nConsumer features.\nSome displays, especially newer flat-panel monitors, replace the traditional anti-glare matte finish with a glossy one. This increases color saturation and sharpness but reflections from lights and windows are more visible. Anti-reflective coatings are sometimes applied to help reduce reflections, although this only partly mitigates the problem.\nCurved designs\nMost often using nominally flat-panel display technology such as LCD or OLED, a concave rather than convex curve is imparted, reducing geometric distortion, especially in extremely large and wide seamless desktop monitors intended for close viewing range.\n3D\nNewer monitors are able to display a different image for each eye, often with the help of special glasses and polarizers, giving the perception of depth. An autostereoscopic screen can generate 3D images without headgear.\nAnti-glare and anti-reflection screens\nProfessional features.\nFeatures for medical using or for outdoor placement.\nDirectional screen\nNarrow viewing angle screens are used in some security-conscious applications.\nIntegrated professional accessories\nIntegrated screen calibration tools, screen hoods, signal transmitters; Protective screens.\nTablet screens\nA combination of a monitor with a graphics tablet. Such devices are typically unresponsive to touch without the use of one or more special tools' pressure. Newer models however are now able to detect touch from any pressure and often have the ability to detect tool tilt and rotation as well.\nTouch and tablet sensors are often used on sample and hold displays such as LCDs to substitute for the light pen, which can only work on CRTs.\nIntegrated display LUT and 3D LUT tables\nThe option for using the display as a reference monitor; these calibration features can give an advanced color management control for take a near-perfect image.\nLocal dimming backlight\nOption for professional LCD monitors, inherent to OLED &amp; CRT; professional feature with mainstream tendency.\nBacklight brightness/color uniformity compensation\nNear to mainstream professional feature; advanced hardware driver for backlit modules with local zones of uniformity correction.\nMounting.\nComputer monitors are provided with a variety of methods for mounting them depending on the application and environment.\nDesktop.\nA desktop monitor is typically provided with a stand from the manufacturer which lifts the monitor up to a more ergonomic viewing height. The stand may be attached to the monitor using a proprietary method or may use, or be adaptable to, a VESA mount. A VESA standard mount allows the monitor to be used with more after-market stands if the original stand is removed. Stands may be fixed or offer a variety of features such as height adjustment, horizontal swivel, and landscape or portrait screen orientation.\nVESA mount.\nThe Flat Display Mounting Interface (FDMI), also known as VESA Mounting Interface Standard (MIS) or colloquially as a VESA mount, is a family of standards defined by the Video Electronics Standards Association for mounting flat-panel displays to stands or wall mounts. It is implemented on most modern flat-panel monitors and TVs.\nFor computer monitors, the VESA Mount typically consists of four threaded holes on the rear of the display that will mate with an adapter bracket.\nRack mount.\nRack mount computer monitors are available in two styles and are intended to be mounted into a 19-inch rack:\nA fixed rack mount monitor is mounted directly to the rack with the flat-panel or CRT visible at all times. The height of the unit is measured in rack units (RU) and 8U or 9U are most common to fit 17-inch or 19-inch screens. The front sides of the unit are provided with flanges to mount to the rack, providing appropriately spaced holes or slots for the rack mounting screws. A 19-inch diagonal screen is the largest size that will fit within the rails of a 19-inch rack. Larger flat-panels may be accommodated but are 'mount-on-rack' and extend forward of the rack. There are smaller display units, typically used in broadcast environments, which fit multiple smaller screens side by side into one rack mount.\nA stowable rack mount monitor is 1U, 2U or 3U high and is mounted on rack slides allowing the display to be folded down and the unit slid into the rack for storage as a drawer. The flat display is visible only when pulled out of the rack and deployed. These units may include only a display or may be equipped with a keyboard creating a KVM (Keyboard Video Monitor). Most common are systems with a single LCD but there are systems providing two or three displays in a single rack mount system.\nPanel mount.\nA panel mount computer monitor is intended for mounting into a flat surface with the front of the display unit protruding just slightly. They may also be mounted to the rear of the panel. A flange is provided around the screen, sides, top and bottom, to allow mounting. This contrasts with a rack mount display where the flanges are only on the sides. The flanges will be provided with holes for thru-bolts or may have studs welded to the rear surface to secure the unit in the hole in the panel. Often a gasket is provided to provide a water-tight seal to the panel and the front of the screen will be sealed to the back of the front panel to prevent water and dirt contamination.\nOpen frame.\nAn open frame monitor provides the display and enough supporting structure to hold associated electronics and to minimally support the display. Provision will be made for attaching the unit to some external structure for support and protection. Open frame monitors are intended to be built into some other piece of equipment providing its own case. An arcade video game would be a good example with the display mounted inside the cabinet. There is usually an open frame display inside all end-use displays with the end-use display simply providing an attractive protective enclosure. Some rack mount monitor manufacturers will purchase desktop displays, take them apart, and discard the outer plastic parts, keeping the inner open-frame display for inclusion into their product.\nSecurity vulnerabilities.\nAccording to an NSA document leaked to , the NSA sometimes swaps the monitor cables on targeted computers with a bugged monitor cable to allow the NSA to remotely see what is being displayed on the targeted computer monitor.\nVan Eck phreaking is the process of remotely displaying the contents of a CRT or LCD by detecting its electromagnetic emissions. It is named after Dutch computer researcher Wim van Eck, who in 1985 published the first paper on it, including proof of concept. While most effective on older CRT monitors due to their strong electromagnetic emissions, it can potentially apply to LCDs as well, although modern shielding techniques significantly mitigate the risk. Phreaking more generally is the process of exploiting telephone networks.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "7678", "revid": "36767729", "url": "https://en.wikipedia.org/wiki?curid=7678", "title": "Computer display/LCD", "text": ""}
{"id": "7679", "revid": "11292982", "url": "https://en.wikipedia.org/wiki?curid=7679", "title": "Computer display/CRT", "text": ""}
{"id": "7681", "revid": "28481209", "url": "https://en.wikipedia.org/wiki?curid=7681", "title": "ClearType", "text": "Font-rendering technology by Microsoft\nClearType is Microsoft's implementation of subpixel rendering technology in rendering text in a font system. ClearType attempts to improve the appearance of text on certain types of computer display screens by sacrificing color fidelity for additional intensity variation. This trade-off is asserted to work well on LCD flat panel monitors.\nClearType was first announced at the November 1998 COMDEX exhibition. The technology was first introduced in software in January 2000 as an always-on feature of Microsoft Reader, which was released to the public in August 2000.\nClearType was significantly changed with the introduction of DirectWrite in Windows 7.\nWith the increasing availability of HiDPI displays after 2012, subpixel rendering has become less necessary.\nBackground.\nComputer displays where the positions of individual pixels are permanently fixed\u00a0\u2013 such as most modern flat panel displays\u00a0\u2013 can show saw-tooth edges when displaying small, high-contrast graphic elements, such as text. ClearType uses spatial anti-aliasing at the subpixel level to reduce visible artifacts on such displays when text is rendered, making the text appear \"smoother\" and less jagged. ClearType also uses font hinting to force the font to fit into the pixel grid. This increases edge contrast and readability of small fonts at the expense of font rendering fidelity and has been criticized by graphic designers for making different fonts look similar.\nLike most other types of subpixel rendering, ClearType involves a compromise, sacrificing one aspect of image quality (color or \"chrominance\" detail) for another (light and dark or \"luminance\" detail). The compromise can improve text appearance when luminance detail is more important than chrominance.\nOnly user and system applications render ClearType. ClearType does not alter other graphic display elements, including text already in bitmaps. For example, ClearType enhancement renders text on the screen in Microsoft Word, but not in images within programs such as Adobe Photoshop. In theory, the method (called \"RGB Decimation\" internally) can enhance the anti-aliasing of any digital image.\nClearType was invented in the Microsoft e-Books team by Bert Keely and Greg Hitchcock. It was then analyzed by researchers in the company, and signal processing expert John Platt designed an improved version of the algorithm. Dick Brass, a vice president at Microsoft from 1997 to 2004, complained that the company was slow in moving ClearType to market in the portable computing field.\nHuman vision and cognition.\nClearType and similar technologies work on the theory that variations in intensity are more noticeable than variations in color.\nExpert opinion.\nIn a MSDN article, Microsoft acknowledges that \"[te]xt that is rendered with ClearType can also appear significantly different when viewed by individuals with varying levels of color sensitivity. Some individuals can detect slight differences in color better than others.\" This opinion is shared by font designer Thomas Phinney (former CEO of FontLab, also formerly with Adobe Systems): \"There is also considerable variation between individuals in their sensitivity to color fringing. Some people just notice it and are bothered by it a lot more than others.\" Software developer Melissa Elliott has written about finding ClearType rendering uncomfortable to read, saying that \"instead of seeing black text, I see blue text, and rendered over it but offset by a pixel or two, I see orange text, and someone reached into a bag of purple pixel glitter and just tossed it on...I\u2019m not the only person in the world with this problem, and yet, every time it comes up, people are quick to assure me it works for them as if that\u2019s supposed to make me feel better.\"\nHinting expert Beat Stamm, who worked on ClearType at Microsoft, agrees that ClearType may look blurry at 96 dpi, which was a typical resolution for LCDs in 2008, but adds that higher resolution displays improve on this aspect: \"WPF [Windows Presentation Foundation] uses method C [ClearType with fractional pixel positioning], but few display devices have a sufficiently high resolution to make the potential blur a moot point for everybody.\u00a0.\u00a0.\u00a0. Some people are ok with the blur in Method C, some aren\u2019t. Anecdotal evidence suggests that some people are fine with Method C when reading continuous text at 96 dpi (e.g. Times Reader, etc.) but not in UI scenarios. Many people are fine with the colors of ClearType, even at 96 dpi, but a few aren\u2019t\u2026 To my eyes and at 96 dpi, Method C doesn\u2019t read as well as Method A. It reads \u201cblurrily\u201d to me. Conversely, at 144 dpi, I don't see a problem with Method C. It looks and reads just fine to me.\" One illustration of the potential problem is the following image:\nIn the above block of text, the same portion of text is shown in the upper half without and in the lower half with ClearType rendering (as opposed to Standard and ClearType in the previous image). This demonstrates the blurring introduced.\nEmpirical studies.\nA 2001 study, conducted by researchers from Clemson University and The University of Pennsylvania on \"18 users who spent 60 minutes reading fiction from each of three different displays\" found that \"When reading from an LCD display, users preferred text rendered with ClearType. ClearType also yielded higher readability judgments and lower ratings of mental fatigue.\" A 2002 study on 24 users conducted by the same researchers from Clemson University also found that \"Participants were significantly more accurate at identifying words with ClearType than without ClearType.\"\nAccording to a 2006 study, at the University of Texas at Austin by Dillon et al., ClearType \"may not be universally beneficial\". The study notes that maximum benefit may be seen when the information worker is spending large proportions of their time reading text (which is not necessarily the case for the majority of computer users today). Additionally, over one third of the study participants experienced some disadvantage when using ClearType. Whether ClearType, or other rendering, should be used is very subjective and it must be the choice of the individual, with the report recommending \"to allow users to disable [ClearType] if they find it produces effects other than improved performance\".\nAnother 2007 empirical study, found that \"while ClearType rendering does not improve text legibility, reading speed or comfort compared to perceptually-tuned grayscale rendering, subjects prefer text with moderate ClearType rendering to text with grayscale or higher-level ClearType contrast.\"\nA 2007 survey, of the literature by Microsoft researcher Kevin Larson presented a different picture: \"Peer-reviewed studies have consistently found that using ClearType boosts reading performance compared with other text-rendering systems. In a 2004 study, for instance, Lee Gugerty, a psychology professor at Clemson University, in South Carolina, measured a 17 percent improvement in word recognition accuracy with ClearType. Gugerty\u2019s group also showed, in a sentence comprehension study, that ClearType boosted reading speed by 5 percent and comprehension by 2 percent. Similarly, in a study published in 2007, psychologist Andrew Dillon at the University of Texas at Austin found that when subjects were asked to scan a spreadsheet and pick out certain information, they did those tasks 7 percent faster with ClearType.\"\nDisplay requirements.\nClearType and allied technologies require display hardware with fixed pixels and subpixels. More precisely, the positions of the pixels and subpixels on the screen must be exactly known to the computer to which it is connected. This is the case for flat-panel displays, on which the positions of the pixels are permanently fixed by the design of the screen itself. Almost all flat panels have a perfectly rectangular array of square pixels, each of which contains three rectangular subpixels in the three primary colors, with the normal ordering being red, green, and blue, arranged in vertical bands. ClearType assumes this arrangement of pixels when rendering text.\nClearType does not work properly with flat-panel displays that are operated at resolutions other than their \u201cnative\u201d resolutions, since only the native resolution corresponds exactly to the actual positions of pixels on the screen of the display.\nIf a display does not have the type of fixed pixels that ClearType expects, text rendered with ClearType enabled actually looks worse than type rendered without it. Some flat panels have unusual pixel arrangements, with the colors in a different order, or with the subpixels positioned differently (in three horizontal bands, or in other ways). ClearType needs to be manually tuned for use with such displays (see below).\nClearType will not work as intended on displays that have no fixed pixel positions, such as CRT displays (which were still prevalent at the time of the release of Windows XP, which is why ClearType is disabled by default), however it will still have some antialiasing effect and may be preferable to some users as compared to non-anti-aliased type.\nSensitivity to display orientation.\nBecause ClearType utilizes the physical layout of the red, green and blue pigments of the LCD screen, it is sensitive to the orientation of the display.\nClearType in Windows XP supports the RGB and BGR sub pixel structures; rotated displays, in which the subpixels are stacked vertically rather than arranged horizontally, are \"not\" supported. Using ClearType on these display configurations will actually reduce the display quality. The best option for users of Windows XP having rotated LCD displays (Tablet PCs or swivel-stand LCD displays) is using regular anti-aliasing, or switching off font-smoothing altogether.\nThe software developer documentation for Windows CE states that ClearType for rotated screens is supported on that platform.\nImplementations.\nClearType is also an integrated component of the Windows Presentation Foundation text-rendering engine.\nClearType Font Collection.\nAs part of the Vista release, Microsoft released a set of fonts, known as the \"ClearType Font Collection\", thought to work well with the ClearType system:\nFonts included by some, but not always part of the set:\nClearType in GDI.\nClearType can be globally enabled or disabled for GDI applications. A control panel applet is available to let the users tune the GDI ClearType settings. The GDI implementation of ClearType does not support sub-pixel positioning.\nClearType tuning.\nWindows XP, as supplied, allow ClearType to be turned on or off, with no adjustment; Windows 7 and later allow tuning of the ClearType parameters in Control Panel. A Microsoft ClearType tuner utility is available for free download for Windows versions lacking this facility. If ClearType is disabled in the operating system, applications with their own ClearType controls can still support it. Microsoft Reader (for e-books) has its own ClearType tuner.\nClearType in WPF.\nAll text in Windows Presentation Foundation is anti-aliased and rendered using ClearType. There are separate ClearType registry settings for GDI and WPF applications, but by default the WPF entries are absent, and the GDI values are used in their absence. WPF registry entries can be tuned using the instructions from the MSDN WPF Text Blog.\nClearType in WPF supports sub-pixel positioning, natural advance widths, Y-direction anti-aliasing and hardware acceleration. WPF supports aggressive caching of pre-rendered ClearType text in video memory. The extent to which this is supported is dependent on the video card. DirectX 10 cards will be able to cache the font glyphs in video memory, then perform the composition (assembling of character glyphs in the correct order, with the correct spacing), alpha blending (application of anti-aliasing), and RGB blending (ClearType's sub-pixel color calculations), entirely in hardware. This means that only the original glyphs need to be stored in video memory once per font (Microsoft estimates that this would require 2\u00a0MB of video memory per font), and other operations such as the display of anti-aliased text on top of other graphics\u00a0\u2013 including video\u00a0\u2013 can also be done with no computation effort on the part of the CPU. DirectX 9 cards will only be able to cache the alpha-blended glyphs in memory, thus requiring the CPU to handle glyph composition and alpha-blending before passing this to the video card. Caching these partially rendered glyphs requires significantly more memory (Microsoft estimates 5\u00a0MB per process). Cards that don't support DirectX 9 have no hardware-accelerated text rendering capabilities.\nClearType in DirectWrite.\nAs pixel densities of displays improved and more high DPI screens became available, colored subpixel rendering became less of a necessity according to Microsoft. Also Windows tablet user interfaces evolved to support vertical screen orientations where the LCD color stripes would run horizontally. The original colored ClearType subpixel rendering was tuned to work optimally with horizontal orientation LCD displays where RGB or BGR stripes run vertically. For these reasons, DirectWrite which is the next-generation text rendering API from Microsoft moved away from color-aware ClearType. The font rendering engine in DirectWrite supports a different version of ClearType with only greyscale anti-aliasing, not color subpixel rendering, as demonstrated at PDC 2008. This version is sometimes called \"Natural ClearType\" but is often referred to simply as DirectWrite rendering (with the term \"ClearType\" being designated to only the RGB/BGR color subpixel rendering version). The improvements have been confirmed by independent sources, such as Firefox developers; they were particularly noticeable for OpenType fonts in Compact Font Format (CFF).\nMany Office 2013 apps including Word 2013, Excel 2013, parts of Outlook 2013 stopped using ClearType and switched to this DirectWrite greyscale antialiasing. The reasons invoked are, in the words of Murray Sargent: \"There is a problem with ClearType: it depends critically on the color of the background pixels. This isn\u2019t a problem if you know a priori that those pixels are white, which is usually the case for text. But the general case involves calculating what the colors should be for an arbitrary background and that takes time. Meanwhile, Word 2013 enjoys cool animations and smooth zooming. Nothing jumps any more. Even the caret (the blinking vertical line at the text insertion point) glides from one position to the next as you type. Jerking movement just isn\u2019t considered cool any more. Well animations and zooms have to be faster than human response times in order to appear smooth. And that rules out ClearType in animated scenarios at least with present generation hardware. And in future scenarios, screens will have sufficiently high resolution that gray-scale anti-aliasing should suffice.\"\nFor the same reasons related to animation performance and vertical screen orientations where the colored RGB/BGR ClearType antialiasing would be a problem, the color-aware version of ClearType was abandoned in Metro-style apps platform of Windows 8 (and Universal Windows Platform of Windows 10)., including the Start menu and everything not using classic Win32 APIs (GDI/GDI+).\nPatents.\nClearType is a registered trademark and Microsoft claims protection under the following U.S. patents, all expired:\nOther uses of the ClearType brand.\nThe ClearType name was also used to refer to the screens of Microsoft Surface tablets. ClearType HD Display indicates a 1366\u00d7768 screen, while ClearType Full HD Display indicates a 1920\u00d71080 screen.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "7682", "revid": "49679309", "url": "https://en.wikipedia.org/wiki?curid=7682", "title": "Centriole", "text": "Organelle in eukaryotic cells\nIn cell biology a centriole is a cylindrical organelle composed mainly of a protein called tubulin. Centrioles are found in most eukaryotic cells, but are not present in conifers (Pinophyta), flowering plants (angiosperms) and most fungi, and are only present in the male gametes of charophytes, bryophytes, seedless vascular plants, cycads, and \"Ginkgo\". A bound pair of centrioles, surrounded by a highly ordered mass of dense material, called the pericentriolar material (PCM), makes up a structure called a centrosome.\nCentrioles are typically made up of nine sets of short microtubule triplets, arranged in a cylinder. Deviations from this structure include crabs and \"Drosophila melanogaster\" embryos, with nine doublets, and \"Caenorhabditis elegans\" sperm cells and early embryos, with nine singlets. Additional proteins include centrin, cenexin and tektin.\nThe main function of centrioles is to produce cilia during interphase and the aster and the spindle during cell division.\nHistory.\nThe centrosome was discovered jointly by Walther Flemming in 1875 and Edouard Van Beneden in 1876. Edouard Van Beneden made the first observation of centrosomes as composed of two orthogonal centrioles in 1883. Theodor Boveri introduced the term \"centrosome\" in 1888 and the term \"centriole\" in 1895. The basal body was named by Theodor Wilhelm Engelmann in 1880. The pattern of centriole duplication was first worked out independently by \u00c9tienne de Harven and Joseph G. Gall c. 1950.\nRole in cell division.\nCentrioles are involved in the organization of the mitotic spindle and in the completion of cytokinesis. Centrioles were previously thought to be required for the formation of a mitotic spindle in animal cells. However, more recent experiments have demonstrated that cells whose centrioles have been removed via laser ablation can still progress through the G1 stage of interphase before centrioles can be synthesized later in a de novo fashion. Additionally, mutant flies lacking centrioles develop normally, although the adult flies' cells lack flagella and cilia and as a result, they die shortly after birth.\nThe centrioles can self replicate during cell division.\nCellular organization.\nCentrioles are a very important part of centrosomes, which are involved in organizing microtubules in the cytoplasm. The position of the centriole determines the position of the nucleus and plays a crucial role in the spatial arrangement of the cell.\nFertility.\nSperm centrioles are important for 2 functions: (1) to form the sperm flagellum and sperm movement and (2) for the development of the embryo after fertilization. The sperm supplies the centriole that creates the centrosome and microtubule system of the zygote.\nCiliogenesis.\nIn flagellates and ciliates, the position of the flagellum or cilium is determined by the mother centriole, which becomes the basal body. An inability of cells to use centrioles to make functional flagella and cilia has been linked to a number of genetic and developmental diseases. In particular, the inability of centrioles to properly migrate prior to ciliary assembly has recently been linked to Meckel\u2013Gruber syndrome.\nAnimal development.\nProper orientation of cilia via centriole positioning toward the posterior of embryonic node cells is critical for establishing left-right asymmetry, during mammalian development.\nCentriole duplication.\nBefore DNA replication, cells contain two centrioles, an older mother centriole, and a younger daughter centriole. During cell division, a new centriole grows at the proximal end of both mother and daughter centrioles. After duplication, the two centriole pairs (the freshly assembled centriole is now a daughter centriole in each pair) will remain attached to each other orthogonally until mitosis. At that point the mother and daughter centrioles separate dependently on an enzyme called separase.\nThe two centrioles in the centrosome are tied to one another. The mother centriole has radiating appendages at the distal end of its long axis and is attached to its daughter at the proximal end. Each daughter cell formed after cell division will inherit one of these pairs. Centrioles start duplicating when DNA replicates.\nOrigin.\nLECA, the last common ancestor of all eukaryotes was a ciliated cell with centrioles. Some lineages of eukaryotes, such as land plants, do not have centrioles except in their motile male gametes. Centrioles are completely absent from all cells of conifers and flowering plants, which do not have ciliate or flagellate gametes.\nIt is unclear if the last common ancestor had one or two cilia. Important genes such as those coding for centrins, required for centriole growth, are only found in eukaryotes, and not in bacteria or archaea.\nEtymology and pronunciation.\nThe word \"centriole\" () uses combining forms of \"centri-\" and \"-ole\", yielding \"little central part\", which describes a centriole's typical location near the center of the cell.\nAtypical centrioles.\nTypical centrioles are made of 9 triplets of microtubules organized with radial symmetry. Centrioles can vary the number of microtubules and can be made of 9 doublets of microtubules (as in \"Drosophila melanogaster\") or 9 singlets of microtubules as in \"C. elegans\". Atypical centrioles are centrioles that do not have microtubules, such as the Proximal Centriole-Like found in \"D. melanogaster\" sperm, or that have microtubules with no radial symmetry, such as in the distal centriole of human spermatozoon. Atypical centrioles may have evolved at least eight times independently during vertebrate evolution and may evolve in the sperm after internal fertilization evolves.\nIt wasn't clear why the centriole became atypical until recently. The atypical distal centriole forms a dynamic basal complex (DBC) that, together with other structures in the sperm neck, facilitates a cascade of internal sliding that couples tail beating with head kinking. The atypical distal centriole's properties suggest that it evolved into a transmission system that couples the sperm tail motors to the whole sperm, thereby enhancing sperm function.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "7683", "revid": "27015025", "url": "https://en.wikipedia.org/wiki?curid=7683", "title": "Creation science", "text": "Pseudoscientific form of Young Earth creationism\nCreation science or scientific creationism is a pseudoscientific form of Young Earth creationism which claims to offer scientific arguments for certain literalist and inerrantist interpretations of the Bible. It is often presented without overt faith-based language, but instead relies on reinterpreting scientific results to argue that various myths in the Book of Genesis and other select biblical passages are scientifically valid. The most commonly advanced ideas of creation science include special creation based on the Genesis creation narrative and flood geology based on the Genesis flood narrative. Creationists also claim they can disprove or reexplain a variety of scientific facts, theories and paradigms of geology, cosmology, biological evolution, archaeology, history, and linguistics using creation science. Creation science was foundational to intelligent design.\nThe overwhelming consensus of the scientific community is that creation science fails to qualify as scientific because it lacks empirical support, supplies no testable hypotheses, and resolves to describe natural history in terms of scientifically untestable supernatural causes. Courts, most often in the United States where the question has been asked in the context of teaching the subject in public schools, have consistently ruled since the 1980s that creation science is a religious view rather than a scientific one. Historians, philosophers of science and skeptics have described creation science as a pseudoscientific attempt to map the Bible into scientific facts. Professional biologists have criticized creation science for being unscholarly, and even as a dishonest and misguided sham, with extremely harmful educational consequences.\nBeliefs and activities.\nReligious basis.\nCreation science is based largely upon chapters 1\u201311 of the Book of Genesis. These describe how God calls the world into existence through the power of speech (\"And God said, Let there be light,\" etc.) in six days, calls all the animals and plants into existence, and molds the first man from clay and the first woman from a rib taken from the man's side; a worldwide flood destroys all life except for Noah and his family and representatives of the animals, and Noah becomes the ancestor of the 70 \"nations\" of the world; the nations live together until the incident of the Tower of Babel, when God disperses them and gives them their different languages. Creation science attempts to explain history and science within the span of Biblical chronology, which places the initial act of creation some six thousand years ago.\nModern religious affiliations.\nMost creation science proponents hold fundamentalist or Evangelical Christian beliefs in Biblical literalism or Biblical inerrancy, as opposed to the higher criticism supported by liberal Christianity in the Fundamentalist\u2013Modernist Controversy. However, there are also examples of Islamic and Jewish scientific creationism that conform to the accounts of creation as recorded in their religious doctrines.\nThe Seventh-day Adventist Church has a history of support for creation science. This dates back to George McCready Price, an active Seventh-day Adventist who developed views of flood geology, which formed the basis of creation science. This work was continued by the Geoscience Research Institute, an official institute of the Seventh-day Adventist Church, located on its Loma Linda University campus in California.\nCreation science is generally rejected by the Church of England as well as the Roman Catholic Church. The Pontifical Gregorian University has officially discussed intelligent design as a \"cultural phenomenon\" without scientific elements. The Church of England's official website cites Charles Darwin's local work assisting people in his religious parish.\nViews on science.\nCreation science rejects evolution and the common descent of all living things on Earth. Instead, it asserts that the field of evolutionary biology is itself pseudoscientific or even a religion. Creationists argue instead for a system called baraminology, which considers the living world to be descended from uniquely created kinds or \"baramins.\"\nCreation science incorporates the concept of catastrophism to reconcile current landforms and fossil distributions with Biblical interpretations, proposing the remains resulted from successive cataclysmic events, such as a worldwide flood and subsequent ice age. It rejects one of the fundamental principles of modern geology (and of modern science generally), uniformitarianism, which applies the same physical and geological laws observed on the Earth today to interpret the Earth's geological history.\nSometimes creationists attack other scientific concepts, like the Big Bang cosmological model or methods of scientific dating based upon radioactive decay. Young Earth creationists also reject current estimates of the age of the universe and the age of the Earth, arguing for creationist cosmologies with timescales much shorter than those determined by modern physical cosmology and geological science, typically less than 10,000 years.\nThe scientific community has overwhelmingly rejected the ideas put forth in creation science as lying outside the boundaries of a legitimate science. The foundational premises underlying scientific creationism disqualify it as a science because the answers to all inquiry therein are preordained to conform to Bible doctrine, and because that inquiry is constructed upon theories which are not empirically testable in nature.\nScientists also deem creation science's attacks against biological evolution to be without scientific merit. The views of the scientific community were accepted in two significant court decisions in the 1980s, which found the field of creation science to be a religious mode of inquiry, not a scientific one.\nHistory.\nCreation science began in the 1960s, as a fundamentalist Christian effort in the United States to prove Biblical inerrancy and nullify the scientific evidence for evolution. It has since developed a sizable religious following in the United States, with creation science ministries branching worldwide. The main ideas in creation science are: the belief in creation \"ex nihilo\" (Latin: out of nothing); the conviction that the Earth was created within the last 6,000\u201310,000 years; the belief that humans and other life on Earth were created as distinct fixed \"baraminological\" \"kinds\"; and \"flood geology\" or the idea that fossils found in geological strata were deposited during a cataclysmic flood which completely covered the entire Earth. As a result, creationists also challenge the geologic and astrophysical measurements of the age of the Earth and the universe along with their origins, which creationists believe are irreconcilable with the account in the Book of Genesis. Creation science proponents often refer to the theory of evolution as \"Darwinism\" or as \"Darwinian evolution.\"\nThe creation science texts and curricula that first emerged in the 1960s focused upon concepts derived from a literal interpretation of the Bible and were overtly religious in nature, most notably proposing Noah's flood in the Biblical Genesis account as an explanation for the geological and fossil record. These works attracted little notice beyond the schools and congregations of conservative fundamental and Evangelical Christians until the 1970s, when its followers challenged the teaching of evolution in the public schools and other venues in the United States, bringing it to the attention of the public-at-large and the scientific community. Many school boards and lawmakers were persuaded to include the teaching of creation science alongside evolution in the science curriculum. Creation science texts and curricula used in churches and Christian schools were revised to eliminate their Biblical and theological references, and less explicitly sectarian versions of creation science education were introduced in public schools in Louisiana, Arkansas, and other regions in the United States.\nThe 1982 ruling in \"McLean v. Arkansas\" found that creation science fails to meet the essential characteristics of science and that its chief intent is to advance a particular religious view. The teaching of creation science in public schools in the United States effectively ended in 1987 following the United States Supreme Court decision in \"Edwards v. Aguillard\". The court affirmed that a statute requiring the teaching of creation science alongside evolution when evolution is taught in Louisiana public schools was unconstitutional because its sole true purpose was to advance a particular religious belief.\nIn response to this ruling, drafts of the creation science school textbook \"Of Pandas and People\" were edited to change references of creation to intelligent design before its publication in 1989. The intelligent design movement promoted this version. Requiring intelligent design to be taught in public school science classes was found to be unconstitutional in the 2005 \"Kitzmiller v. Dover Area School District\" federal court case.\nBefore 1960s.\nThe teaching of evolution was gradually introduced into more and more public high school textbooks in the United States after 1900, but in the aftermath of the First World War the growth of fundamentalist Christianity gave rise to a creationist opposition to such teaching. Legislation prohibiting the teaching of evolution was passed in certain regions, most notably Tennessee's Butler Act of 1925.\nThe Soviet Union's successful launch of \"Sputnik 1\" in 1957 sparked national concern that the science education in public schools was outdated. In 1958, the United States passed National Defense Education Act which introduced new education guidelines for science instruction. With federal grant funding, the Biological Sciences Curriculum Study (BSCS) drafted new standards for the public schools' science textbooks which included the teaching of evolution. Almost half the nation's high schools were using textbooks based on the guidelines of the BSCS soon after they were published in 1963.\nThe Tennessee legislature did not repeal the Butler Act until 1967.\nCreation science (dubbed \"scientific creationism\" at the time) emerged as an organized movement during the 1960s. It was strongly influenced by the earlier work of armchair geologist George McCready Price who wrote works such as \"Illogical Geology: The Weakest Point in the Evolution Theory\" (1906) and \"The New Geology\" (1923) to advance what he termed \"new catastrophism\" and dispute the current geological time frames and explanations of geologic history. Price was cited at the Scopes Trial of 1925, but his writings had no credence among geologists and other scientists. Price's \"new catastrophism\" was also disputed by most other creationists until its revival with the 1961 publication of \"\" by John C. Whitcomb and Henry M. Morris, a work which quickly became an important text on the issue to fundamentalist Christians and expanded the field of creation science beyond critiques of geology into biology and cosmology as well. Soon after its publication, a movement was underway to have the subject taught in United States' public schools.\nCourt determinations.\nThe various state laws prohibiting teaching of evolution were overturned in 1968 when the United States Supreme Court ruled in \"Epperson v. Arkansas\" such laws violated the Establishment Clause of the First Amendment to the United States Constitution. This ruling inspired a new creationist movement to promote laws requiring that schools give balanced treatment to creation science when evolution is taught. The 1981 Arkansas Act 590 was one such law that carefully detailed the principles of creation science that were to receive equal time in public schools alongside evolutionary principles. The act defined creation science as follows:\n\"'Creation-science' means the scientific evidences for creation and inferences from those evidences. Creation-science includes the scientific evidences and related inferences that indicate:\n#Sudden creation of the universe, and, in particular, life, from nothing;\n#The insufficiency of mutation and natural selection in bringing about development of all living kinds from a single organism;\n#Changes only with fixed limits of originally created kinds of plants and animals;\n#Separate ancestry for man and apes;\n#Explanation of the earth's geology by catastrophism, including the occurrence of worldwide flood; and\n#A relatively recent inception of the earth and living kinds.\"\nThis legislation was examined in \"McLean v. Arkansas\", and the ruling handed down on January 5, 1982, concluded that creation-science as defined in the act \"is simply not science\". The judgement defined the following as essential characteristics of science:\n#It is guided by natural law;\n#It has to be explanatory by reference to nature law;\n#It is testable against the empirical world;\n#Its conclusions are tentative, i.e., are not necessarily the final word; and\n#It is falsifiable.\nThe court ruled that creation science failed to meet these essential characteristics and identified specific reasons. After examining the key concepts from creation science, the court found:\n#Sudden creation \"from nothing\" calls upon a supernatural intervention, not natural law, and is neither testable nor falsifiable\n#Objections in creation science that mutation and natural selection are insufficient to explain common origins was an incomplete negative generalization\n#'Kinds' are not scientific classifications, and creation science's claims of an outer limit to the evolutionary change possible of species are not explained scientifically or by natural law\n#The separate ancestry of man and apes is an assertion rather than a scientific explanation, and did not derive from any scientific fact or theory\n#Catastrophism, including its identification of the worldwide flood, failed as a science\n#\"Relatively recent inception\" was the product of religious readings and had no scientific meaning, and was neither the product of, nor explainable by, natural law; nor is it tentative\nThe court further noted that no recognized scientific journal had published any article espousing the creation science theory as described in the Arkansas law, and stated that the testimony presented by defense attributing the absence to censorship was not credible.\nIn its ruling, the court wrote that for any theory to qualify as scientific, the theory must be tentative, and open to revision or abandonment as new facts come to light. It wrote that any methodology which begins with an immutable conclusion that cannot be revised or rejected, regardless of the evidence, is not a scientific theory. The court found that creation science does not culminate in conclusions formed from scientific inquiry, but instead begins with the conclusion, one taken from a literal wording of the Book of Genesis, and seeks only scientific evidence to support it.\nThe law in Arkansas adopted the same two-model approach as that put forward by the Institute for Creation Research, one allowing only two possible explanations for the origins of life and existence of man, plants and animals: it was either the work of a creator or it was not. Scientific evidence that failed to support the theory of evolution was posed as necessarily scientific evidence in support of creationism, but in its judgment the court ruled this approach to be no more than a \"contrived dualism which has not scientific factual basis or legitimate educational purpose.\"\nThe judge concluded that \"Act 590 is a religious crusade, coupled with a desire to conceal this fact,\" and that it violated the First Amendment's Establishment Clause. The decision was not appealed to a higher court, but had a powerful influence on subsequent rulings. Louisiana's 1982 Balanced Treatment for Creation-Science and Evolution-Science Act, authored by State Senator Bill P. Keith, judged in the 1987 United States Supreme Court case \"Edwards v. Aguillard\", and was handed a similar ruling. It found the law to require the balanced teaching of creation science with evolution had a particular religious purpose and was therefore unconstitutional.\nIntelligent design splits off.\nIn 1984, \"The Mystery of Life's Origin\" was first published. It was co-authored by chemist and creationist Charles B. Thaxton with Walter L. Bradley and Roger L. Olsen, the foreword written by Dean H. Kenyon, and sponsored by the Christian-based Foundation for Thought and Ethics (FTE). The work presented scientific arguments against current theories of abiogenesis and offered a hypothesis of special creation instead. While the focus of creation science had until that time centered primarily on the criticism of the fossil evidence for evolution and validation of the creation myth of the Bible, this new work posed the question whether science reveals that even the simplest living systems were far too complex to have developed by natural, unguided processes.\nKenyon later co-wrote with creationist Percival Davis a book intended as a \"scientific brief for creationism\" to use as a supplement to public high school biology textbooks. Thaxton was enlisted as the book's editor, and the book received publishing support from the FTE. Prior to its release, the 1987 Supreme Court ruling in \"Edwards v. Aguillard\" barred the teaching of creation science and creationism in public school classrooms. The book, originally titled \"Biology and Creation\" but renamed \"Of Pandas and People\", was released in 1989 and became the first published work to promote the anti-evolutionist design argument under the name intelligent design. The contents of the book later became a focus of evidence in the federal court case, \"Kitzmiller v. Dover Area School District\", when a group of parents filed suit to halt the teaching of intelligent design in Dover, Pennsylvania, public schools. School board officials there had attempted to include \"Of Pandas and People\" in their biology classrooms and testimony given during the trial revealed the book was originally written as a creationist text but following the adverse decision in the Supreme Court it underwent simple cosmetic editing to remove the explicit allusions to \"creation\" or \"creator,\" and replace them instead with references to \"design\" or \"designer.\"\nBy the mid-1990s, intelligent design had become a separate movement. The creation science movement is distinguished from the intelligent design movement, or neo-creationism, because most advocates of creation science accept scripture as a literal and inerrant historical account, and their primary goal is to corroborate the scriptural account through the use of science. In contrast, as a matter of principle, neo-creationism eschews references to scripture altogether in its polemics and stated goals (see Wedge strategy). By so doing, intelligent design proponents have attempted to succeed where creation science has failed in securing a place in public school science curricula. Carefully avoiding any reference to the identity of the intelligent designer as God in their public arguments, intelligent design proponents sought to reintroduce the creationist ideas into science classrooms while sidestepping the First Amendment's prohibition against religious infringement. However, the intelligent design curriculum was struck down as a violation of the Establishment Clause in \"Kitzmiller v. Dover Area School District\", the judge in the case ruled \"that ID is nothing less than the progeny of creationism.\"\nToday, creation science as an organized movement is primarily centered within the United States. Creation science organizations are also known in other countries, most notably Creation Ministries International which was founded (under the name Creation Science Foundation) in Australia. Proponents are usually aligned with a Christian denomination, primarily with those characterized as evangelical, conservative, or fundamentalist. While creationist movements also exist in Islam and Judaism, these movements do not use the phrase \"creation science\" to describe their beliefs.\nIssues.\nCreation science has its roots in the work of young Earth creationist George McCready Price disputing modern science's account of natural history, focusing particularly on geology and its concept of uniformitarianism, and his efforts instead to furnish an alternative empirical explanation of observable phenomena which was compatible with strict Biblical literalism. Price's work was later discovered by civil engineer Henry M. Morris, who is now considered to be the father of creation science. Morris and later creationists expanded the scope with attacks against the broad spectrum scientific findings that point to the antiquity of the Universe and common ancestry among species, including growing body of evidence from the fossil record, absolute dating techniques, and cosmogony.\nThe proponents of creation science often say that they are concerned with religious and moral questions as well as natural observations and predictive hypotheses. Many state that their opposition to scientific evolution is primarily based on religion.\nThe overwhelming majority of scientists are in agreement that the claims of science are necessarily limited to those that develop from natural observations and experiments which can be replicated and substantiated by other scientists, and that claims made by creation science do not meet those criteria. Duane Gish, a prominent creation science proponent, has similarly claimed, \"We do not know how the creator created, what processes He used, \"for He used processes which are not now operating anywhere in the natural universe.\" This is why we refer to creation as special creation. We cannot discover by scientific investigation anything about the creative processes used by the Creator.\" But he also makes the same claim against science's evolutionary theory, maintaining that on the subject of origins, scientific evolution is a religious theory which cannot be validated by science.\nMetaphysical assumptions.\nCreation science makes the \"a priori\" metaphysical assumption that there exists a creator of the life whose origin is being examined. Christian creation science holds that the description of creation is given in the Bible, that the Bible is inerrant in this description (and elsewhere), and therefore empirical scientific evidence must correspond with that description. Creationists also view the preclusion of all supernatural explanations within the sciences as a doctrinaire commitment to exclude the supreme being and miracles. They claim this to be the motivating factor in science's acceptance of Darwinism, a term used in creation science to refer to evolutionary biology which is also often used as a disparagement. Critics argue that creation science is religious rather than scientific because it stems from faith in a religious text rather than by the application of the scientific method. The United States National Academy of Sciences (NAS) has stated unequivocally, \"Evolution pervades all biological phenomena. To ignore that it occurred or to classify it as a form of dogma is to deprive the student of the most fundamental organizational concept in the biological sciences. No other biological concept has been more extensively tested and more thoroughly corroborated than the evolutionary history of organisms.\" Anthropologist Eugenie Scott has noted further, \"Religious opposition to evolution propels antievolutionism. Although antievolutionists pay lip service to supposed scientific problems with evolution, what motivates them to battle its teaching is apprehension over the implications of evolution for religion.\"\nCreation science advocates argue that scientific theories of the origins of the Universe, Earth, and life are rooted in \"a priori\" presumptions of methodological naturalism and uniformitarianism, each of which they reject. In some areas of science such as chemistry, meteorology or medicine, creation science proponents do not necessarily challenge the application of naturalistic or uniformitarian assumptions, but instead single out those scientific theories they judge to be in conflict with their religious beliefs, and it is against those theories that they concentrate their efforts.\nReligious criticism.\nMany mainstream Christian churches criticize creation science on theological grounds, asserting either that religious faith alone should be a sufficient basis for belief in the truth of creation, or that efforts to prove the Genesis account of creation on scientific grounds are inherently futile because reason is subordinate to faith and cannot thus be used to prove it.\nMany Christian theologies, including Liberal Christianity, consider the Genesis creation narrative to be a poetic and allegorical work rather than a literal history, and many Christian churches\u2014including the Eastern Orthodox Church, the Roman Catholic, Anglican and the more liberal denominations of the Lutheran, Methodist, Congregationalist and Presbyterian faiths\u2014have either rejected creation science outright or are ambivalent to it. Belief in non-literal interpretations of Genesis is often cited as going back to Saint Augustine.\nTheistic evolution and evolutionary creationism are theologies that reconcile belief in a creator with biological evolution. Each holds the view that there is a creator but that this creator has employed the natural force of evolution to unfold a divine plan. Religious representatives from faiths compatible with theistic evolution and evolutionary creationism have challenged the growing perception that belief in a creator is inconsistent with the acceptance of evolutionary theory. Spokespersons from the Catholic Church have specifically criticized biblical creationism for relying upon literal interpretations of biblical scripture as the basis for determining scientific fact.\nScientific criticism.\nThe National Academy of Sciences states that \"the claims of creation science lack empirical support and cannot be meaningfully tested\" and that \"creation science is in fact not science and should not be presented as such in science classes.\" According to Joyce Arthur writing for \"Skeptic\" magazine, the \"creation 'science' movement gains much of its strength through the use of distortion and scientifically unethical tactics\" and \"seriously misrepresents the theory of evolution.\"\nScientists have considered the hypotheses proposed by creation science and have rejected them because of a lack of evidence. Furthermore, the claims of creation science do not refer to natural causes and cannot be subject to meaningful tests, so they do not qualify as scientific hypotheses. In 1987, the United States Supreme Court ruled that creationism is religion, not science, and cannot be advocated in public school classrooms. Most mainline Christian denominations have concluded that the concept of evolution is not at odds with their descriptions of creation and human origins.\nA summary of the objections to creation science by scientists follows:\nBy invoking claims of \"abrupt appearance\" of species as a miraculous act, creation science is unsuited for the tools and methods demanded by science, and it cannot be considered scientific in the way that the term \"science\" is currently defined. Scientists and science writers commonly characterize creation science as a pseudoscience.\nHistorical, philosophical, and sociological criticism.\nHistorically, the debate of whether creationism is compatible with science can be traced back to 1874, the year science historian John William Draper published his \"History of the Conflict between Religion and Science\". In it Draper portrayed the entire history of scientific development as a war against religion. This presentation of history was propagated further by followers such as Andrew Dickson White in his two-volume \"A History of the Warfare of Science with Theology in Christendom\" (1896). Their conclusions have been disputed.\nIn the United States, the principal focus of creation science advocates is on the government-supported public school systems, which are prohibited by the Establishment Clause from promoting specific religions. Historical communities have argued that Biblical translations contain many translation errors and errata, and therefore that the use of biblical literalism in creation science is self-contradictory.\nKinds of creation science.\nBiology.\nCreationist arguments in relation to biology center on an idea derived from Genesis that states that life was created by God, in a finite number of \"created kinds,\" rather than through biological evolution from a common ancestor. Creationists contend that any observable speciation descends from these distinctly created kinds through inbreeding, deleterious mutations and other genetic mechanisms. Whereas evolutionary biologists and creationists share similar views of microevolution, creationists reject the fact that the process of macroevolution can explain common ancestry among organisms far beyond the level of common species. Creationists contend that there is no empirical evidence for new plant or animal species, and deny fossil evidence has ever been found documenting the process.\nPopular arguments against evolution have changed since the publishing of Henry M. Morris' first book on the subject, \"Scientific Creationism\" (1974), but some consistent themes remain: that missing links or gaps in the fossil record are proof against evolution; that the increased complexity of organisms over time through evolution is not possible due to the law of increasing entropy; that it is impossible that the mechanism of natural selection could account for common ancestry; and that evolutionary theory is untestable. The origin of the human species is particularly hotly contested; the fossil remains of hominid ancestors are not considered by advocates of creation biology to be evidence for a speciation event involving \"Homo sapiens\". Creationists also assert that early hominids, are either apes, or humans.\nRichard Dawkins has explained evolution as \"a theory of gradual, incremental change over millions of years, which starts with something very simple and works up along slow, gradual gradients to greater complexity,\" and described the existing fossil record as entirely consistent with that process. Biologists emphasize that transitional gaps between recovered fossils are to be expected, that the existence of any such gaps cannot be invoked to disprove evolution, and that instead the fossil evidence that could be used to disprove the theory would be those fossils which are found and which are entirely inconsistent with what can be predicted or anticipated by the evolutionary model. One example given by Dawkins was, \"If there were a single hippo or rabbit in the Precambrian, that would completely blow evolution out of the water. None have ever been found.\"\nGeology.\nFlood geology.\nFlood geology is a concept based on the belief that most of Earth's geological record was formed by the Great Flood described in the story of Noah's Ark. Fossils and fossil fuels are believed to have formed from animal and plant matter which was buried rapidly during this flood, while submarine canyons are explained as having formed during a rapid runoff from the continents at the end of the flood. Sedimentary strata are also claimed to have been predominantly laid down during or after Noah's flood and orogeny. Flood geology is a variant of catastrophism and is contrasted with geological science in that it rejects standard geological principles such as uniformitarianism and radiometric dating. For example, the Creation Research Society argues that \"uniformitarianism is wishful thinking.\"\nGeologists conclude that no evidence for such a flood is observed in the preserved rock layers and moreover that such a flood is physically impossible, given the current layout of land masses. For instance, since Mount Everest currently is approximately 8.8 kilometres in elevation and the Earth's surface area is 510,065,600\u00a0km2, the volume of water required to cover Mount Everest to a depth of 15 cubits (6.8 m), as indicated by Genesis 7:20, would be 4.6 billion cubic kilometres. Measurements of the amount of precipitable water vapor in the atmosphere have yielded results indicating that condensing all water vapor in a column of atmosphere would produce liquid water with a depth ranging between zero and approximately 70mm, depending on the date and the location of the column. Nevertheless, there continue to be adherents to the belief in flood geology, and in recent years new creationist models have been introduced such as catastrophic plate tectonics and catastrophic orogeny.\nRadiometric dating.\nCreationists point to flawed experiments they have performed, which they claim demonstrate that 1.5 billion years of nuclear decay took place over a short period of time, from which they infer that \"billion-fold speed-ups of nuclear decay\" have occurred, a massive violation of the principle that radioisotope decay rates are constant, a core principle underlying nuclear physics generally, and radiometric dating in particular.\nThe scientific community points to numerous flaws in the creationists' experiments, to the fact that their results have not been accepted for publication by any peer-reviewed scientific journal, and to the fact that the creationist scientists conducting them were untrained in experimental geochronology. They have also been criticised for widely publicising the results of their research as successful despite their own admission of insurmountable problems with their hypothesis.\nThe constancy of the decay rates of isotopes is well supported in science. Evidence for this constancy includes the correspondences of date estimates taken from different radioactive isotopes as well as correspondences with non-radiometric dating techniques such as dendrochronology, ice core dating, and historical records. Although scientists have noted slight increases in the decay rate for isotopes subject to extreme pressures, those differences were too small to significantly impact date estimates. The constancy of the decay rates is also governed by first principles in quantum mechanics, wherein any deviation in the rate would require a change in the fundamental constants. According to these principles, a change in the fundamental constants could not influence different elements uniformly, and a comparison between each of the elements' resulting unique chronological timescales would then give inconsistent time estimates.\nIn refutation of young Earth claims of inconstant decay rates affecting the reliability of radiometric dating, Roger C. Wiens, a physicist specializing in isotope dating states:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nRadiohaloes.\nIn the 1970s, young Earth creationist Robert V. Gentry proposed that radiohaloes in certain granites represented evidence for the Earth being created instantaneously rather than gradually. This idea has been criticized by physicists and geologists on many grounds including that the rocks Gentry studied were not primordial and that the radionuclides in question need not have been in the rocks initially.\nThomas A. Baillieul, a geologist and retired senior environmental scientist with the United States Department of Energy, disputed Gentry's claims in an article entitled, \"'Polonium Haloes' Refuted: A Review of 'Radioactive Halos in a Radio-Chronological and Cosmological Perspective' by Robert V. Gentry.\" Baillieul noted that Gentry was a physicist with no background in geology and given the absence of this background, Gentry had misrepresented the geological context from which the specimens were collected. Additionally, he noted that Gentry relied on research from the beginning of the 20th century, long before radioisotopes were thoroughly understood; that his assumption that a polonium isotope caused the rings was speculative; and that Gentry falsely argued that the half-life of radioactive elements varies with time. Gentry claimed that Baillieul could not publish his criticisms in a reputable scientific journal, although some of Baillieul's criticisms rested on work previously published in reputable scientific journals.\nAstronomy and cosmology.\nCreationist cosmologies.\nSeveral attempts have been made by creationists to construct a cosmology consistent with a young Universe rather than the standard cosmological age of the universe, based on the belief that Genesis describes the creation of the Universe as well as the Earth. The primary challenge for young-universe cosmologies is that the accepted distances in the Universe require millions or billions of years for light to travel to Earth (the \"starlight problem\"). An older creationist idea, proposed by creationist astronomer Barry Setterfield, is that the speed of light has decayed in the history of the Universe. More recently, creationist physicist Russell Humphreys has proposed a hypothesis called \"white hole cosmology\", asserting that the Universe expanded out of a white hole less than 10,000 years ago; claiming that the age of the universe is illusory and results from relativistic effects. Humphreys' cosmology is advocated by creationist organisations such as Answers in Genesis; however because its predictions conflict with current observations, it is not accepted by the scientific community.\nPlanetology.\nVarious claims are made by creationists concerning alleged evidence that the age of the Solar System is of the order of thousands of years, in contrast to the scientifically accepted age of 4.6 billion years. It is commonly argued that the number of comets in the Solar System is much higher than would be expected given its supposed age. Young Earth Creationists reject the existence of the Kuiper belt and Oort cloud. They also argue that the recession of the Moon from the Earth is incompatible with either the Moon or the Earth being billions of years old. These claims have been refuted by planetologists.\nIn response to increasing evidence suggesting that Mars once possessed a wetter climate, some creationists have proposed that the global flood affected not only the Earth but also Mars and other planets. People who support this claim include creationist astronomer Wayne Spencer and Russell Humphreys.\nAn ongoing problem for creationists is the presence of impact craters on nearly all Solar System objects, which is consistent with scientific explanations of solar system origins but creates insuperable problems for young Earth claims. Creationists Harold Slusher and Richard Mandock, along with Glenn Morton (who later repudiated this claim) asserted that impact craters on the Moon are subject to rock flow, and so cannot be more than a few thousand years old. While some creationist astronomers assert that different phases of meteoritic bombardment of the Solar System occurred during \"creation week\" and during the subsequent Great Flood, others regard this as unsupported by the evidence and call for further research.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nBibliography.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nFurther reading.\nProponents.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nExternal links.\nNotable creationist museums in the United States:"}
{"id": "7684", "revid": "8066546", "url": "https://en.wikipedia.org/wiki?curid=7684", "title": "Boeing C-135", "text": ""}
{"id": "7685", "revid": "40727880", "url": "https://en.wikipedia.org/wiki?curid=7685", "title": "List of cartographers", "text": "Cartography is the study of map making and cartographers are map makers."}
{"id": "7688", "revid": "11292982", "url": "https://en.wikipedia.org/wiki?curid=7688", "title": "Christian antisemitism", "text": ""}
{"id": "7689", "revid": "49843479", "url": "https://en.wikipedia.org/wiki?curid=7689", "title": "Cirth", "text": "Artificial script in Tolkien's writings\nThe Cirth (, meaning \"runes\"; sg. certh )\u00a0is a semi\u2011artificial script, based on real\u2011life runic alphabets, one of several scripts invented by J. R. R. Tolkien for the constructed languages he devised and used in his works. \"Cirth\" is written with a capital letter when referring to the writing system; the letters themselves can be called \"cirth\".\nIn the fictional history of Middle-earth, the original \"Certhas\" was created by the Sindar (or Grey Elves) for their language, Sindarin. Its extension and elaboration was known as the \"Angerthas Daeron\", as it was attributed to the Sinda Daeron, despite the fact that it was most probably arranged by the Noldor in order to represent the sounds of other languages like Quenya and Telerin.\nAlthough it was later largely replaced by the Tengwar, the Cirth was nonetheless adopted by the Dwarves to write down both their Khuzdul language (\"Angerthas Moria\") and the languages of Men (\"Angerthas Erebor\"). The Cirth was also adapted, in its oldest and simplest form, by various races including Men and even Orcs.\nExternal history.\nConcept and creation.\nMany letters have shapes also found in the historical runic alphabets, but their sound values are only similar in a few of the vowels. Rather, the system of assignment of sound values is much more systematic in the Cirth than in the historical runes (e.g., voiced variants of a voiceless sound are expressed by an additional stroke).\nThe division between the older Cirth of Daeron and their adaptation by Dwarves and Men has been interpreted as a parallel drawn by Tolkien to the development of the Futhorc to the Younger Futhark. The original Elvish Cirth \"as supposed products of a superior culture\" are focused on logical arrangement and a close connection between form and value whereas the adaptations by mortal races introduced irregularities. Similar to the Germanic tribes who had no written literature and used only simple runes before their conversion to Christianity, the Sindarin Elves of Beleriand with their Cirth were introduced to the more elaborate Tengwar of F\u00ebanor when the Noldorin Elves returned to Middle-earth from the lands of the divine Valar.\nInternal history and description.\n\"Certhas\".\nIn the Appendix E to \"The Return of the King\", Tolkien writes that the Sindar of Beleriand first developed an alphabet for their language some time between the invention of the Tengwar by F\u00ebanor (YT 1250) and the introduction thereof to Middle-earth by the Exiled Noldor towards the end of the First Age.\nThis alphabet was devised to represent only the sounds of their Sindarin language and its letters were mostly used for inscribing names or brief memorials on wood, stone or metal, hence their angular shapes and straight lines. In Sindarin these letters were named \"cirth\" (sing. \"certh\"), from the Elvish root \"*kir-\" meaning \"to cleave, to cut\". An abecedarium of \"cirth\", consisting of the runes listed in due order, was commonly known as Certhas (, meaning \"rune-rows\" in Sindarin and loosely translated as \"runic alphabet\").\nThe oldest \"cirth\" were the following:\nThe form of these letters was somewhat unsystematic, unlike later rearrangements and extensions that made them more featural. The \"cirth\" and were used for \u27e8h\u27e9 and \u27e8s\u27e9, but varied as to which was which. Many of the runes consisted of a single vertical line (or \"stem\") with an appendage (or \"branch\") attached to one or both sides. If the attachment was made on one side only, it was usually to the right, but \"the reverse was not infrequent\" and did not change the value of the letter. (For example, the variants or specifically mentioned for \"h\" or \"s\", also or for \"t\", etc.).\n\"Angerthas Daeron\".\nIn Beleriand, before the end of the First Age, the \"Certhas\" was rearranged and further developed, partly under the influence of the Tengwar introduced by the Noldor. This reorganisation of the Cirth was commonly attributed to the Elf Daeron, minstrel and loremaster of King Thingol of Doriath. Thus, the new system became known as the Angerthas Daeron (where \"angerthas\" is from Sindarin \"an(d)\" + \"certhas\" , meaning \"long rune-rows\").\nIn this arrangement, the assignment of values to each \"certh\" is systematic. The runes consisting of a stem and a branch attached to the right are used for voiceless stops, while other sounds are allocated according to the following principles:\nThe \"cirth\" constructed in this way can therefore be arranged into series, each corresponding to a place of articulation:\nOther letters introduced in this system include: and for \u27e8a\u27e9 and \u27e8w\u27e9, respectively; runes for long vowels, evidently originated by doubling and binding the \"certh\" of the corresponding short vowel (e.g., \u2192 two front vowels, probably stemming from ligatures of the corresponding back vowel with the \u27e8i\u27e9-\"certh\" (i.e., \u2192 , and \u2192 some homorganic nasal + stop clusters (e.g., \nBack to the fictional history, since the new and encompass sounds which do not occur in Sindarin but are present in Quenya, they were most probably introduced by the Exiled Noldor who spoke Quenya as a language of knowledge.\nBy loan-translation, the Cirth became known in Quenya as \"Certar\" , while a single \"certh\" was called \"certa\" .\nAfter the Tengwar became the sole script used for writing, the \"Angerthas Daeron\" was essentially relegated to carved inscriptions. The Elves of the West, for the most part, abandoned the Cirth altogether, with the exception of the Noldor dwelling in the country of Eregion, who maintained it in use and made it known as Angerthas Eregion.\nNote: In this article, the runes of the \"Angerthas\" come with the same peculiar transliteration used by Tolkien in the Appendix E, which differs from the (Latin) spelling of both Quenya and Sindarin. The IPA transcription that follows is applicable to both languages, except where indicated otherwise.\nNotes:\n\"Angerthas Moria\".\nAccording to Tolkien's legendarium, the Dwarves first came to know the runes of the Noldor at the beginning of the Second Age. The Dwarves \"introduced a number of unsystematic changes in value, as well as certain new cirth\". They modified the previous system to suit the specific needs of their language, Khuzdul. The Dwarves spread their revised alphabet to Moria, where it came to be known as \"Angerthas Moria\", and developed both carved and pen-written forms of these runes.\nMany cirth here represent sounds not occurring in Khuzdul (at least in published words of Khuzdul: of course, our corpus is very limited to judge the necessity or not, of these sounds). Here they are marked with a black star (\u2605).\nNotes:\nIn \"Angerthas Moria\" the cirth and were dropped. Thus and were adopted for and , although they were used for and in Elvish languages. Subsequently, this script used the certh for , which had the sound in the Elvish systems. Therefore, the certh (which was previously used for the sound , useless in Khuzdul) was adopted for the sound . A totally new introduction was the certh , used as an alternative, simplified and, maybe, weaker form of . Because of the visual relation of these two cirth, the certh was given the sound to relate better with that, in this script, had the sound .\n\"Angerthas Erebor\".\nAt the beginning of the Third Age the Dwarves were driven out of Moria, and some migrated to Erebor. As the Dwarves of Erebor would trade with the Men of the nearby towns of Dale and Lake-town, they needed a script to write in Westron (the \"lingua franca\" of Middle-earth, usually rendered in English by Tolkien in his works). The \"Angerthas Moria\" was adapted accordingly: some new cirth were added, while some were restored to their Elvish usage, thus creating the \"Angerthas Erebor\".\nWhile the \"Angerthas Moria\" was still used to write down Khuzdul, this new script was primarily used for Mannish languages. It is also the script used in the first and third page of the Book of Mazarbul.\nAngerthas Erebor also features combining diacritics:\nThe \"Angerthas Erebor\" is used twice in \"The Lord of the Rings\" to write in English:\nThe Book of Mazarbul shows some additional cirth used in \"Angerthas Erebor\": one for a double \u27e8l\u27e9 ligature, one for the definite article, and six for the representation of the same number of English diphthongs:\nNotes:\nOther runic scripts by Tolkien.\nThe Cirth is not the only runic writing system used by Tolkien in his \"legendarium\". In fact, he devised a great number of runic alphabets, of which only a few others have been published. Some of these are included in the \"Appendix on Runes\" of \"The Treason of Isengard\" (\"The History of Middle-earth\", vol. VII), edited by Christopher Tolkien.\nRunes from \"The Hobbit\".\nAccording to Tolkien himself, those found in \"The Hobbit\" are a form of \"English runes\" used in lieu of the Dwarvish runes proper. They can be interpreted as an attempt made by Tolkien to adapt the Fu\u00feorc (i.e., the Old English runic alphabet) to the Modern English language.\nThese runes are basically the same found in Fu\u00feorc, but their sound may change according to their position, just like the letters of the Latin script: the writing mode used by Tolkien is, in this case, mainly orthographic. This means that the system has one rune for each Latin letter, regardless of pronunciation. For example, the rune \u27e8c\u27e9 can sound in \u27e8cover\u27e9, in \u27e8sincere\u27e9, in \u27e8special\u27e9, and even in the digraph \u27e8ch\u27e9.\nA few sounds are instead written with the same rune, without considering the English spelling. For example, the sound is always written with the rune whether in English it is spelt \u27e8o\u27e9 as in \u27e8north\u27e9, \u27e8a\u27e9 as in \u27e8fall\u27e9, or \u27e8oo\u27e9 as in \u27e8door\u27e9. The only two letters that are subject to this phonemic spelling are \u27e8a\u27e9 and \u27e8o\u27e9.\nFinally, some runes stand for particular English digraphs and diphthongs.\nHere the runes used in \"The Hobbit\" are displayed along with their Fu\u00feorc counterpart and corresponding English grapheme:\nNotes:\nGondolinic runes.\nNot all the runes mentioned in \"The Hobbit\" are Dwarf-runes. The swords found in the Trolls' cave bore runes that Gandalf could not read. In fact, the swords Glamdring and Orcrist (which were forged in the ancient kingdom of Gondolin) bore a type of letters known as Gondolinic runes. They seem to have become obsolete and been forgotten by the Third Age, and this is supported by the fact that only Elrond could still read the inscriptions on the swords.\nTolkien devised this runic alphabet in a very early stage of his shaping of Middle-earth. Nevertheless, they are known to us from a slip of paper that Tolkien wrote; his son Christopher sent a photocopy of it to Paul Nolan Hyde in February 1992. Hyde published it, with an extensive analysis, in the 1992 Summer issue of \"Mythlore\", no. 69. The system was reanalyzed by Carl F. Hostetter, who corrected the reading of the \u03c7\u0311 rune to an \"ich-laut\" (voiceless palatal fricative)\".\" Later, in Parma Eldalamberon 15, the original manuscript including a script variety of Gondolinic, the first cursive form of any of Tolkien's runic scripts, was presented.\nThe system provides sounds not found in any of the known Elvish languages of the First Age, but perhaps it was designed for a variety of languages. However, the consonants seem to be, more or less, the same found in Welsh phonology, a theory supported by the fact that Tolkien was heavily influenced by Welsh when creating Elvish languages.\nEncoding schemes.\nUnicode.\nEquivalents for some (but not all) cirth can be found in the Runic block of Unicode.\nTolkien's mode of writing Modern English in Anglo-Saxon runes received explicit recognition with the introduction of his three additional runes to the Runic block with the release of Unicode 7.0, in June 2014. The three characters represent the English \u27e8k\u27e9, \u27e8oo\u27e9 and \u27e8sh\u27e9 graphemes, as follows:\nA formal Unicode proposal to encode Cirth as a separate script was made in September 1997 by Michael Everson.\nNo action was taken by the Unicode Technical Committee (UTC) but Cirth appears in the Roadmap to the SMP.\nConScript Unicode Registry.\nUnicode character block\nUnicode Private Use Area layouts for Cirth are defined at the ConScript Unicode Registry (CSUR) and the Under-ConScript Unicode Registry (UCSUR).\nTwo different layouts are defined by the CSUR/UCSUR:\nWithout proper rendering support, you may see question marks, boxes, or other symbols below instead of Cirth.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "7694", "revid": "40192293", "url": "https://en.wikipedia.org/wiki?curid=7694", "title": "Chinese food", "text": ""}
{"id": "7695", "revid": "274180", "url": "https://en.wikipedia.org/wiki?curid=7695", "title": "Chiliasm", "text": ""}
{"id": "7696", "revid": "13304210", "url": "https://en.wikipedia.org/wiki?curid=7696", "title": "Theosophy (Boehmian)", "text": ""}
{"id": "7697", "revid": "47906728", "url": "https://en.wikipedia.org/wiki?curid=7697", "title": "Lockheed C-130 Hercules", "text": "American military transport aircraft\nThe Lockheed C-130 Hercules is an American four-engine turboprop military transport aircraft designed and built by Lockheed (now Lockheed Martin). Capable of using unprepared runways for takeoffs and landings, the C-130 was originally designed as a troop, medevac, and cargo transport aircraft. The versatile airframe has found uses in other roles, including as a gunship (AC-130), for airborne assault, search and rescue, scientific research support, weather reconnaissance, aerial refueling, maritime patrol, and aerial firefighting. It is now the main tactical airlifter for many military forces worldwide. More than 40 variants of the Hercules, including civilian versions marketed as the Lockheed L-100, operate in more than 60 nations.\nThe C-130 entered service with the U.S. in 1956, followed by Australia and many other nations. During its years of service, the Hercules has participated in numerous military, civilian and humanitarian aid operations. In 2007, the transport became the fifth aircraft to mark 50 years of continuous service with its original primary customer, which for the C-130 is the United States Air Force (USAF). The C-130 is the longest continuously produced military aircraft, having achieved 70 years of production in 2024.\nDesign and development.\nBackground and requirements.\nThe Korean War showed that World War II-era piston-engine transports\u2014Fairchild C-119 Flying Boxcars, Douglas C-47 Skytrains and Curtiss C-46 Commandos\u2014were no longer adequate. On 2 February 1951, the United States Air Force issued a General Operating Requirement (GOR) for a new transport to Boeing, Douglas, Fairchild, Lockheed, Martin, Chase Aircraft, North American, Northrop, and Airlifts Inc.\nThe new transport would have a capacity of 92 passengers, 72 combat troops or 64 paratroopers in a cargo compartment that was approximately long, high, and wide. Unlike transports derived from passenger airliners, it was to be designed specifically as a combat transport with loading from a hinged loading ramp at the rear of the fuselage. A notable advance for large aircraft was the introduction of a turboprop powerplant, the Allison T56 which was developed for the C-130. It gave the aircraft greater range than a turbojet engine as it used less fuel. Turboprop engines also produced much more power for their weight than piston engines. However, the turboprop configuration chosen for the T56, with the propeller connected to the compressor, had the potential to cause structural failure of the aircraft if an engine failed. Safety devices had to be incorporated to reduce the excessive drag from a windmilling propeller.\nDesign phase.\nThe Hercules resembles a larger, four-engine version of the Fairchild C-123 Provider with a similar wing and cargo ramp layout. The C-123 had evolved from the Chase XCG-20 Avitruc first flown in 1950. The Boeing C-97 Stratofreighter had rear ramps, which made it possible to drive vehicles onto the airplane (also possible with the forward ramp on a C-124). The ramp on the Hercules was also used to airdrop cargo, which included a low-altitude parachute-extraction system for Sheridan tanks and even dropping large improvised \"daisy cutter\" bombs. The new Lockheed cargo plane had a range of and it could operate from short and unprepared strips.\nFairchild, North American, Martin, and Northrop declined to participate. The remaining five companies tendered a total of ten designs: Lockheed two, Boeing one, Chase three, Douglas three, and Airlifts Inc. one. The contest was a close affair between the lighter of the two Lockheed (preliminary project designation L-206) proposals and a four-turboprop Douglas design.\nThe Lockheed design team was led by Willis Hawkins, starting with a 130-page proposal for the \"Lockheed L-206\". Hall Hibbard, Lockheed vice president and chief engineer, saw the proposal and directed it to Kelly Johnson, who did not care for the low-speed, unarmed aircraft, and remarked, \"If you sign that letter, you will destroy the Lockheed Company.\" Both Hibbard and Johnson signed the proposal and the company won the contract for the now-designated Model 82 on 2 July 1951.\nThe first flight of the \"YC-130\" prototype was made on 23 August 1954 from the Lockheed plant in Burbank, California. The aircraft, serial number \"53-3397\", was the second prototype, but the first of the two to fly. The YC-130 was piloted by Stanley Beltz and Roy Wimmer on its 61-minute flight to Edwards Air Force Base; Jack Real and Dick Stanton served as flight engineers. Kelly Johnson flew chase in a Lockheed P2V Neptune.\nAfter the two prototypes were completed, production began in Marietta, Georgia, where over 2,300 C-130s have been built through 2009.\nThe initial production model, the \"C-130A\", was powered by Allison T56-A-9 turboprops with three-blade propellers and originally equipped with the blunt nose of the prototypes. Deliveries began in December 1956, continuing until the introduction of the \"C-130B\" model in 1959. Some A-models were equipped with skis and re-designated \"C-130D\". As the C-130A became operational with Tactical Air Command (TAC), the C-130's lack of range became apparent and additional fuel capacity was added with wing pylon-mounted tanks outboard of the engines; this added of fuel capacity for a total capacity of .\nImproved versions.\nThe C-130B model was developed to complement the A-models that had previously been delivered, and incorporated new features, particularly increased fuel capacity in the form of auxiliary tanks built into the center wing section and an AC electrical system. Four-bladed Hamilton Standard propellers replaced the Aero Products' three-blade propellers that distinguished the earlier A-models. The C-130B had ailerons operated by hydraulic pressure that was increased from , as well as uprated engines and four-blade propellers that were standard until the J-model.\nThe B model was originally intended to have \"blown controls\", a system that blows high-pressure air over the control surfaces to improve their effectiveness during slow flight. It was tested on an NC-130B prototype aircraft with a pair of T-56 turbines providing high-pressure air through a duct system to the control surfaces and flaps during landing. This greatly reduced landing speed to just 63 knots and cut landing distance in half. The system never entered service because it did not improve takeoff performance by the same margin, making the landing performance pointless if the aircraft could not also take off from where it had landed.\nAn electronic reconnaissance variant of the C-130B was designated C-130B-II. A total of 13 aircraft were converted. The C-130B-II was distinguished by its false external wing fuel tanks, which were disguised signals intelligence (SIGINT) receiver antennas. These pods were slightly larger than the standard wing tanks found on other C-130Bs. Most aircraft featured a swept blade antenna on the upper fuselage, as well as extra wire antennas between the vertical fin and upper fuselage not found on other C-130s. Radio call numbers on the tail of these aircraft were regularly changed to confuse observers and disguise their true mission.\nThe extended-range \"C-130E\" model entered service in 1962 after it was developed as an interim long-range transport for the Military Air Transport Service. Essentially a B-model, the new designation was the result of the installation of \"Sargent Fletcher\" external fuel tanks under each wing's midsection and more powerful Allison T56-A-7A turboprops. The hydraulic boost pressure to the ailerons was reduced back to as a consequence of the external tanks' weight in the middle of the wingspan. The E model also featured structural improvements, avionics upgrades, and a higher gross weight. Australia took delivery of 12 C130E Hercules during 1966\u201367 to supplement the 12 C-130A models already in service with the RAAF. Sweden and Spain fly the TP-84T version of the C-130E fitted for aerial refueling capability.\nThe \"KC-130\" tankers, originally \"C-130F\" procured for the US Marine Corps (USMC) in 1958 (under the designation \"GV-1\") are equipped with a removable stainless steel fuel tank carried inside the cargo compartment. The two wing-mounted hose and drogue aerial refueling pods each transfer up to to two aircraft simultaneously, allowing for rapid cycle times of multiple-receiver aircraft formations, (a typical tanker formation of four aircraft in less than 30 minutes). The US Navy's \"C-130G\" has increased structural strength allowing higher gross weight operation.\nFurther developments.\nThe \"C-130H\" model has updated Allison T56-A-15 turboprops, a redesigned outer wing, updated avionics, and other minor improvements. Later \"H\" models had a new, fatigue-life-improved, center wing that was retrofitted to many earlier H-models. For structural reasons, some models are required to land with reduced amounts of fuel when carrying heavy cargo, reducing usable range.\nThe H model remains in widespread use with the United States Air Force (USAF) and many foreign air forces. Initial deliveries began in 1964 (to the RNZAF), remaining in production until 1996. An improved C-130H was introduced in 1974, with Australia purchasing 12 of the type in 1978 to replace the original 12 C-130A models, which had first entered Royal Australian Air Force (RAAF) service in 1958. The U.S. Coast Guard employs the HC-130H for long-range search and rescue, drug interdiction, illegal migrant patrols, homeland security, and logistics.\nC-130H models produced from 1992 to 1996 were designated as C-130H3 by the USAF, with the \"3\" denoting the third variation in design for the H series. Improvements included ring laser gyros for the INUs, GPS receivers, a partial glass cockpit (ADI and HSI instruments), a more capable APN-241 color radar, night vision device compatible instrument lighting, and an integrated radar and missile warning system. The electrical system upgrade included Generator Control Units (GCU) and Bus Switching units (BSU) to provide stable power to the more sensitive upgraded components.\nThe equivalent model for export to the UK is the \"C-130K\", known by the Royal Air Force (RAF) as the \"Hercules C.1\". The \"C-130H-30\" (\"Hercules C.3\" in RAF service) is a stretched version of the original Hercules, achieved by inserting a plug aft of the cockpit and an plug at the rear of the fuselage. A single C-130K was purchased by the Met Office for use by its Meteorological Research Flight, where it was classified as the \"Hercules W.2\". This aircraft was heavily modified, with its most prominent feature being the long red and white striped atmospheric probe on the nose and the move of the weather radar into a pod above the forward fuselage. This aircraft, named \"Snoopy\", was withdrawn in 2001 and was then modified by Marshall of Cambridge Aerospace as a flight testbed for the A400M turbine engine, the TP400. The C-130K is used by the RAF Falcons for parachute drops. Three C-130Ks (Hercules C Mk.1P) were upgraded and sold to the Austrian Air Force in 2002.\nEnhanced models.\nThe \"MC-130E Combat Talon\" was developed for the USAF during the Vietnam War to support special operations missions in Southeast Asia, and led to both the \"MC-130H Combat Talon II\" as well as a family of other special missions aircraft. 37 of the earliest models currently operating with the Air Force Special Operations Command (AFSOC) are scheduled to be replaced by new-production MC-130J versions. The EC-130 Commando Solo is another special missions variant within AFSOC, albeit operated solely by an AFSOC-gained wing in the Pennsylvania Air National Guard, and is a psychological operations/information operations (PSYOP/IO) platform equipped as an aerial radio station and television stations able to transmit messaging over commercial frequencies. Other versions of the EC-130, most notably the EC-130H Compass Call, are also special variants, but are assigned to the Air Combat Command (ACC). The AC-130 gunship was first developed during the Vietnam War to provide close air support and other ground-attack duties.\nThe \"HC-130\" is a family of long-range search and rescue variants used by the USAF and the U.S. Coast Guard. Equipped for the deep deployment of Pararescuemen (PJs), survival equipment, and (in the case of USAF versions) aerial refueling of combat rescue helicopters, HC-130s are usually the on-scene command aircraft for combat SAR missions (USAF only) and non-combat SAR (USAF and USCG). Early USAF versions were also equipped with the Fulton surface-to-air recovery system, designed to pull a person off the ground using a wire strung from a helium balloon. The John Wayne movie \"The Green Berets\" features its use. The Fulton system was later removed when aerial refueling of helicopters proved safer and more versatile. The movie \"The Perfect Storm\" depicts a real-life SAR mission involving aerial refueling of a New York Air National Guard HH-60G by a New York Air National Guard HC-130P.\nThe \"C-130R\" and \"C-130T\" are U.S. Navy and USMC models, both equipped with underwing external fuel tanks. The USN C-130T is similar but has additional avionics improvements. In both models, aircraft are equipped with Allison T56-A-16 engines. The USMC versions are designated \"KC-130R\" or \"KC-130T\" when equipped with underwing refueling pods and pylons and are fully night vision system compatible.\nThe RC-130 is a reconnaissance version developed during the Cold War. Sometimes called \"ferret\" aircraft, these planes were initially retrofitted standard C-130s.\nThe \"Lockheed L-100 (L-382)\" is a civilian variant, equivalent to a C-130E model without military equipment. The L-100 also has two stretched versions.\nNext generation.\nIn the 1970s, Lockheed proposed a C-130 variant with turbofan engines rather than turboprops, but the U.S. Air Force preferred the takeoff performance of the existing aircraft. In the 1980s, the C-130 was intended to be replaced by the Advanced Medium STOL Transport project. The project was canceled and the C-130 has remained in production.\nBuilding on lessons learned, Lockheed Martin modified a commercial variant of the C-130 into a High Technology Test Bed (HTTB). This test aircraft set numerous short takeoff and landing performance records and significantly expanded the database for future derivatives of the C-130. Modifications made to the HTTB included extended chord ailerons, a long chord rudder, fast-acting double-slotted trailing edge flaps, a high-camber wing leading edge extension, a larger dorsal fin and dorsal fins, the addition of three spoiler panels to each wing upper surface, a long-stroke main and nose landing gear system, and changes to the flight controls and a change from direct mechanical linkages assisted by hydraulic boost, to fully powered controls, in which the mechanical linkages from the flight station controls operated only the hydraulic control valves of the appropriate boost unit.\nThe HTTB first flew on 19 June 1984, with civil registration of N130X. After demonstrating many new technologies, some of which were applied to the C-130J, the HTTB was lost in a fatal accident on 3 February 1993, at Dobbins Air Reserve Base, in Marietta, Georgia. The crash was attributed to disengagement of the rudder fly-by-wire flight control system, resulting in a total loss of rudder control capability while conducting ground minimum control speed tests (Vmcg). The disengagement was a result of the inadequate design of the rudder's integrated actuator package by its manufacturer; the operator's insufficient system safety review failed to consider the consequences of the inadequate design to all operating regimes. A factor that contributed to the accident was the flight crew's lack of engineering flight test training.\nIn the 1990s, the improved C-130J Super Hercules was developed by Lockheed (later Lockheed Martin). This model is the newest version and the only model in production. Externally similar to the classic Hercules in general appearance, the J model has new turboprop engines, six-bladed propellers, digital avionics, and other new systems.\nUpgrades and changes.\nIn 2000, Boeing was awarded a US$ contract to develop an Avionics Modernization Program kit for the C-130. The program was beset with delays and cost overruns until project restructuring in 2007. In September 2009, it was reported that the planned Avionics Modernization Program (AMP) upgrade to the older C-130s would be dropped to provide more funds for the F-35, CV-22 and airborne tanker replacement programs. However, in June 2010, Department of Defense approved funding for the initial production of the AMP upgrade kits. Under the terms of this agreement, the USAF has cleared Boeing to begin low-rate initial production (LRIP) for the C-130 AMP. A total of 198 aircraft are expected to feature the AMP upgrade. The current cost per aircraft is US$, although Boeing expects that this price will drop to US$7\u00a0million for the 69th aircraft.\nIn the 2000s, Lockheed Martin and the U.S. Air Force began outfitting and retrofitting C-130s with the eight-blade UTC Aerospace Systems NP2000 propellers. An engine enhancement program saving fuel and providing lower temperatures in the T56 engine has been approved, and the US Air Force expects to save $2\u00a0billion (~$ in 2024) and extend the fleet life.\nIn 2021, the Air Force Research Laboratory demonstrated the Rapid Dragon system which transforms the C-130 into a lethal strike platform capable of launching 12 JASSM-ER with 500\u00a0kg warheads from a standoff distance of . Future anticipated improvements support includes support for JDAM-ER, mine laying, drone dispersal as well as improved standoff range when JASSM-XR become available in 2024.\nReplacement.\nIn October 2010, the U.S. Air Force released a capability request for information (CRFI) for the development of a new airlifter to replace the C-130. The new aircraft was to carry a 190% greater payload and assume the mission of mounted vertical maneuver (MVM). The greater payload and mission would enable it to carry medium-weight armored vehicles and unload them at locations without long runways. Various options were under consideration, including new or upgraded fixed-wing designs, rotorcraft, tiltrotors, or even an airship. The C-130 fleet of around 450 planes would be replaced by only 250 aircraft. The Air Force had attempted to replace the C-130 in the 1970s through the Advanced Medium STOL Transport project, which resulted in the C-17 Globemaster III that instead replaced the C-141 Starlifter.\nThe Air Force Research Laboratory funded Lockheed Martin and Boeing demonstrators for the \"Speed Agile\" concept, which had the goal of making a STOL aircraft that could take off and land at speeds as low as on airfields less than long and cruise at Mach 0.8-plus. Boeing's design used upper-surface blowing from embedded engines on the inboard wing and blown flaps for circulation control on the outboard wing. Lockheed's design also used blown flaps outboard, but inboard used patented reversing ejector nozzles.\nBoeing's design completed over 2,000 hours of wind tunnel tests in late 2009. It was a 5 percent-scale model of a narrow body design with a payload. When the AFRL increased the payload requirement to , they tested a 5 percent-scale model of a widebody design with a take-off gross weight and an \"A400M-size\" wide cargo box. It would be powered by four IAE V2533 turbofans.\nIn August 2011, the AFRL released pictures of the Lockheed Speed Agile concept demonstrator. A 23% scale model went through wind tunnel tests to demonstrate its hybrid powered lift, which combined a low drag airframe with simple mechanical assembly to reduce weight and improve aerodynamics. The model had four engines, including two Williams FJ44 turbofans. On 26 March 2013, Boeing was granted a patent for its swept-wing powered lift aircraft.\nIn January 2014, Air Mobility Command, Air Force Materiel Command and the Air Force Research Lab were in the early stages of defining requirements for the C-X next generation airlifter program to replace both the C-130 and C-17. The aircraft would be produced from the early 2030s to the 2040s.\nOperational history.\nMilitary.\nThe first production batch of C-130A aircraft were delivered beginning in 1956 to the 463d Troop Carrier Wing at Ardmore AFB, Oklahoma, and the 314th Troop Carrier Wing at Sewart AFB, Tennessee. Six additional squadrons were assigned to the 322d Air Division in Europe and the 315th Air Division in the Far East. Additional aircraft were modified for electronics intelligence work and assigned to Rhein-Main Air Base, Germany while modified RC-130As were assigned to the Military Air Transport Service (MATS) photo-mapping division. The C-130A entered service with the U.S. Air Force in December 1956.\nIn 1958, a U.S. reconnaissance C-130A-II of the 7406th Support Squadron was shot down over Armenia by four Soviet MiG-17s along the Turkish-Armenian border during a routine mission.\nAustralia became the first non-American operator of the Hercules with 12 examples being delivered from late 1958. The Royal Canadian Air Force became another early user with the delivery of four B-models (Canadian designation CC-130 Mk I) in October / November 1960.\nIn 1963, a Hercules achieved and still holds the record for the largest and heaviest aircraft to land on an aircraft carrier. During October and November that year, a USMC KC-130F (BuNo \"149798\"), loaned to the U.S. Naval Air Test Center, made 29 touch-and-go landings, 21 unarrested full-stop landings and 21 unassisted take-offs on at a number of different weights. The pilot, Lieutenant (later Rear Admiral) James H. Flatley III, USN, was awarded the Distinguished Flying Cross for his role in this test series. The tests were highly successful, but the aircraft was not deployed this way. Flatley denied that C-130 was tested for carrier onboard delivery (COD) operations, or for delivering nuclear weapons. He said that the intention was to support the Lockheed U-2, also being tested on carriers. The Hercules used in the test, most recently in service with Marine Aerial Refueler Squadron 352 (VMGR-352) until 2005, is now part of the collection of the National Museum of Naval Aviation at NAS Pensacola, Florida.\nIn 1964, C-130 crews from the 6315th Operations Group at Naha Air Base, Okinawa commenced forward air control (FAC; \"Flare\") missions over the Ho Chi Minh Trail in Laos supporting USAF strike aircraft. In April 1965 the mission was expanded to North Vietnam where C-130 crews led formations of Martin B-57 Canberra bombers on night reconnaissance/strike missions against communist supply routes leading to South Vietnam. In early 1966 Project Blind Bat/Lamplighter was established at Ubon Royal Thai Air Force Base, Thailand. After the move to Ubon, the mission became a four-engine FAC mission with the C-130 crew searching for targets and then calling in strike aircraft. Another little-known C-130 mission flown by Naha-based crews was Operation Commando Scarf (or Operation Commando Lava), which involved the delivery of chemicals onto sections of the Ho Chi Minh Trail in Laos that were designed to produce mud and landslides in hopes of making the truck routes impassable.\nIn November 1964, on the other side of the globe, C-130Es from the 464th Troop Carrier Wing but loaned to 322d Air Division in France, took part in Operation Dragon Rouge, one of the most dramatic missions in history in the former Belgian Congo. After communist Simba rebels took white residents of the city of Stanleyville hostage, the U.S. and Belgium developed a joint rescue mission that used the C-130s to drop, air-land, and air-lift a force of Belgian paratroopers to rescue the hostages. Two missions were flown, one over Stanleyville and another over Paulis during Thanksgiving week. The headline-making mission resulted in the first award of the prestigious MacKay Trophy to C-130 crews.\nIn the Indo-Pakistani War of 1965, the No. 6 Transport Squadron of the Pakistan Air Force modified its C-130Bs for use as bombers to carry up to of bombs on pallets. These improvised bombers were used to hit Indian targets such as bridges, heavy artillery positions, tank formations, and troop concentrations, though they were largely unsuccessful.\nIn October 1968, a C-130Bs from the 463rd Tactical Airlift Wing dropped a pair of M-121 bombs that had been developed for the massive Convair B-36 Peacemaker bomber but had never been used. The U.S. Army and U.S. Air Force resurrected the huge weapons as a means of clearing landing zones for helicopters and in early 1969 the 463rd commenced Commando Vault missions. Although the stated purpose of Commando Vault was to clear LZs, they were also used on enemy base camps and other targets.\nDuring the late 1960s, the U.S. was eager to get information on Chinese nuclear capabilities. After the failure of the Black Cat Squadron to plant operating sensor pods near the Lop Nur Nuclear Weapons Test Base using a U-2, the CIA developed a plan, named \"Heavy Tea\", to deploy two battery-powered sensor pallets near the base. To deploy the pallets, a Black Bat Squadron crew was trained in the U.S. to fly the C-130 Hercules. The crew of 12, led by Col Sun Pei Zhen, took off from Takhli Royal Thai Air Force Base in an unmarked U.S. Air Force C-130E on 17 May 1969. Flying for six and a half hours at low altitude in the dark, they arrived over the target and the sensor pallets were dropped by parachute near Anxi in Gansu province. After another six and a half hours of low-altitude flight, they arrived back at Takhli. The sensors worked and uploaded data to a U.S. intelligence satellite for six months before their batteries failed. The Chinese conducted two nuclear tests, on 22 September 1969 and 29 September 1969, during the operating life of the sensor pallets. Another mission to the area was planned as Operation Golden Whip, but it was called off in 1970. It is most likely that the aircraft used on this mission was either C-130E serial number 64-0506 or 64-0507 (cn 382-3990 and 382\u20133991). These two aircraft were delivered to Air America in 1964. After being returned to the U.S. Air Force sometime between 1966 and 1970, they were assigned the serial numbers of C-130s that had been destroyed in accidents. 64-0506 is now flying as 62\u20131843, a C-130E that crashed in Vietnam on 20 December 1965, and 64-0507 is now flying as 63\u20137785, a C-130E that had crashed in Vietnam on 17 June 1966.\nThe A-model continued in service through the Vietnam War, where the aircraft assigned to the four squadrons at Naha AB, Okinawa, and one at Tachikawa Air Base, Japan performed yeoman's service, including operating highly classified special operations missions such as the BLIND BAT FAC/Flare mission and Fact Sheet leaflet mission over Laos and North Vietnam. The A-model was also provided to the Republic of Vietnam Air Force as part of the Vietnamization program at the end of the war, and equipped three squadrons based at Tan Son Nhut Air Base. The last operator in the world is the Honduran Air Force, which is still flying one of five A model Hercules (FAH \"558\", c/n 3042) as of October 2009. As the Vietnam War wound down, the 463rd Troop Carrier/Tactical Airlift Wing B-models and A-models of the 374th Tactical Airlift Wing were transferred back to the United States where most were assigned to Air Force Reserve and Air National Guard units.\nAnother prominent role for the B model was with the United States Marine Corps, where Hercules initially designated as GV-1s replaced C-119s. After Air Force C-130Ds proved the type's usefulness in Antarctica, the U.S. Navy purchased several B-models equipped with skis that were designated as LC-130s. C-130B-II electronic reconnaissance aircraft were operated under the SUN VALLEY program name primarily from Yokota Air Base, Japan. All reverted to standard C-130B cargo aircraft after their replacement in the reconnaissance role by other aircraft.\nThe C-130 was also used in the 1976 Entebbe raid in which Israeli commando forces performed a surprise operation to rescue 103 passengers of an airliner hijacked by Palestinian and German terrorists at Entebbe Airport, Uganda. The rescue force\u2014200 soldiers, jeeps, and a black Mercedes-Benz (intended to resemble Ugandan Dictator Idi Amin's vehicle of state)\u2014was flown over almost entirely at an altitude of less than from Israel to Entebbe by four Israeli Air Force (IAF) Hercules aircraft without mid-air refueling (on the way back, the aircraft refueled in Nairobi, Kenya).\nDuring the Falklands War () of 1982, Argentine Air Force C-130s undertook dangerous re-supply night flights as blockade runners to the Argentine garrison on the Falkland Islands. They also performed daylight maritime survey flights. One was shot down by a Royal Navy Sea Harrier using AIM-9 Sidewinders and cannon. The crew of seven were killed. Argentina also operated two KC-130 tankers during the war, and these refueled both the Douglas A-4 Skyhawks and Navy Dassault-Breguet Super \u00c9tendards; some C-130s were modified to operate as bombers with bomb-racks under their wings. The British also used RAF C-130s to support their logistical operations.\nDuring the Gulf War of 1991 (Operation Desert Storm), the C-130 Hercules was used operationally by the U.S. Air Force, U.S. Navy, and U.S. Marine Corps, along with the air forces of Australia, New Zealand, Saudi Arabia, South Korea, and the UK. The MC-130 Combat Talon variant also made the first attacks using the largest conventional bombs in the world, the BLU-82 \"Daisy Cutter\" and GBU-43/B \"Massive Ordnance Air Blast\" (MOAB) bomb. Daisy Cutters were used to primarily clear landing zones and to eliminate mine fields. The weight and size of the weapons make it impossible or impractical to load them on conventional bombers. The GBU-43/B MOAB is a successor to the BLU-82 and can perform the same function, as well as perform strike functions against hardened targets in a low air threat environment.\nSince 1992, two successive C-130 aircraft named \"Fat Albert\" have served as the support aircraft for the U.S. Navy Blue Angels flight demonstration team. \"Fat Albert I\" was a TC-130G (\"151891\") a former U.S. Navy TACAMO aircraft serving with Fleet Air Reconnaissance Squadron Three (VQ-3) before being transferred to the BLUES, while \"Fat Albert II\" is a C-130T (\"164763\"). Although \"Fat Albert\" supports a Navy squadron, it is operated by the U.S. Marine Corps (USMC) and its crew consists solely of USMC personnel. At some air shows featuring the team, \"Fat Albert\" takes part, performing flyovers. Until 2009, it also demonstrated its rocket-assisted takeoff (RATO) capabilities; these ended due to dwindling supplies of rockets.\nThe AC-130 also holds the record for the longest sustained flight by a C-130. From 22 to 24 October 1997, two AC-130U gunships flew 36 hours nonstop from Hurlburt Field, Florida to Daegu International Airport, South Korea, being refueled seven times by KC-135 tanker aircraft. This record flight beat the previous record longest flight by over 10 hours and the two gunships took on of fuel. The gunship has been used in every major U.S. combat operation since Vietnam, except for Operation El Dorado Canyon, the 1986 attack on Libya.\nDuring the invasion of Afghanistan in 2001 and the ongoing support of the International Security Assistance Force (Operation Enduring Freedom), the C-130 Hercules has been used operationally by Australia, Belgium, Canada, Denmark, France, Italy, the Netherlands, New Zealand, Norway, Portugal, Romania, South Korea, Spain, the UK, and the United States.\nDuring the 2003 invasion of Iraq (Operation Iraqi Freedom), the C-130 Hercules was used operationally by Australia, the UK, and the United States. After the initial invasion, C-130 operators as part of the Multinational force in Iraq used their C-130s to support their forces in Iraq.\nSince 2004, the Pakistan Air Force has employed C-130s in the War in North-West Pakistan. Some variants had forward looking infrared (FLIR Systems Star Safire III EO/IR) sensor balls, to enable close tracking of militants.\nIn 2017, France and Germany announced that they will build up a joint air transport squadron at Evreux Air Base, France, comprising ten C-130J aircraft. Six of these will be operated by Germany. Initial operational capability is expected for 2021 while full operational capability is scheduled for 2024.\nThe Argentine Air Force has five C-130H aircraft that are part of a US-funded security assistance donation. The US has been leasing the aircraft to the Argentine Air Force through the Georgia Air National Guard since June 2023.\nDeepwater Horizon Oil Spill.\nFor almost two decades, the USAF 910th Airlift Wing's 757th Airlift Squadron and the U.S. Coast Guard have participated in oil spill cleanup exercises to ensure the U.S. military has a capable response in the event of a national emergency. The 757th Airlift Squadron operates the DOD's only fixed-wing Aerial Spray System which was certified by the EPA to disperse pesticides on DOD property to spread oil dispersants onto the \"Deepwater Horizon\" oil spill in the Gulf Coast in 2010.\nDuring the 5-week mission, the aircrews flew 92 sorties and sprayed approximately 30,000 acres with nearly 149,000 gallons of oil dispersant to break up the oil. The Deepwater Horizon mission was the first time the US used the oil dispersing capability of the 910th Airlift Wing\u2014its only large area, fixed-wing aerial spray program\u2014in an actual spill of national significance. The Air Force Reserve Command announced the 910th Airlift Wing has been selected as a recipient of the Air Force Outstanding Unit Award for its outstanding achievement from 28 April 2010 through 4 June 2010.\nHurricane Harvey (2017).\nC-130s temporarily based at Kelly Field conducted mosquito control aerial spray applications over areas of eastern Texas devastated by Hurricane Harvey. This special mission treated more than 2.3\u00a0million acres at the direction of Federal Emergency Management Agency (FEMA) and the Texas Department of State Health Services (DSHS) to assist in recovery efforts by helping contain the significant increase in pest insects caused by large amounts of standing, stagnant water. The 910th Airlift Wing operates the Department of Defense's only aerial spray capability to control pest insect populations, eliminate undesired and invasive vegetation, and disperse oil spills in large bodies of water.\nThe aerial spray flight also is now able to operate during the night with NVGs, which increases the flight's best case spray capacity from approximately 60 thousand acres per day to approximately 190 thousand acres per day. Spray missions are normally conducted at dusk and nighttime hours when pest insects are most active, the U.S. Air Force Reserve reports.\nAerial firefighting.\nIn the early 1970s, Congress authorized the Modular Airborne Firefighting System (MAFFS), a joint operation between the U.S. Forest Service and the Department of Defense. MAFFS is roll-on/roll-off device that allows C-130s to be temporarily converted into a 3,000-gallon airtanker for fighting wildfires when demand exceeds the supply of privately contracted and publicly available airtankers.\nIn the late 1980s, 22 retired USAF C-130As were removed from storage and transferred to the U.S. Forest Service, which then transferred them to six private companies to be converted into airtankers. One of these C-130s crashed in June 2002 while operating near Walker, California. The crash was attributed to wing separation caused by fatigue stress cracking and contributed to the grounding of the entire large aircraft fleet. After an extensive review, US Forest Service and the Bureau of Land Management declined to renew the leases on nine C-130A over concerns about the age of the aircraft, which had been in service since the 1950s, and their ability to handle the forces generated by aerial firefighting.\nMore recently, an updated Retardant Aerial Delivery System known as RADS XL was developed by Coulson Aviation USA. That system consists of a C-130H/Q retrofitted with an in-floor discharge system, combined with a removable 3,500- or 4,000-gallon water tank. The combined system is FAA certified. On 23 January 2020, Coulson's Tanker 134, an EC-130Q registered N134CG, crashed during aerial firefighting operations in New South Wales, Australia, killing all three crew members. The aircraft had taken off out of RAAF Base Richmond and was supporting firefighting operations during Australia's 2019\u201320 fire season.\nVariants.\nSignificant military variants of the C-130 include:\n Initial production model with four Allison T56-A-11/9 turboprop engines. 219 were ordered and deliveries to the USAF began in December 1956.\n Variant with four Allison T56-A-7 engines. 134 were ordered and entered USAF service in May 1959.\n Same engines as the C-130B but with two external fuel tanks, and an increased maximum takeoff weight capability. Introduced in August 1962 with 389 were ordered.\n Variants procured by the U.S. Navy for Marine Corps refueling missions, and other support/transport operations.\n Identical to the C-130E but with more powerful Allison T56-A-15 turboprop engines. Introduced in June 1964 with 308 ordered.\n Designation for RAF Hercules C1/W2/C3 aircraft (C-130Js in RAF service are the Hercules C.4 and Hercules C.5)\n Improved variants procured by the U.S. Navy for Marine Corps for refueling and other support/transport operations.\n Early version Electronic Intelligence/Signals Intelligence (ELINT/SIGINT) aircraft\n Tactical airlifter, with new engines, avionics, and updated systems\n Gunship variants\n Ski-equipped version for snow and ice operations United States Air Force / Air National Guard\n Designation for Canadian Armed Forces / Royal Canadian Air Force Hercules aircraft. U.S. Air Force used the CC-130J designation to differentiate the standard C-130J variant from the \"stretched\" C-130J (company designation C-130J-30). CC-130H(T) is the Canadian tanker variant of the KC-130H.\n USAF and USN Drone control\n Future USN TACAMO aircraft\nEC-130E/J Commando Solo\u00a0\u2013 USAF / Air National Guard psychological operations version\nEC-130E Airborne Battlefield Command and Control Center (ABCCC)\u00a0\u2013 USAF procedural air-to-ground attack control, also provided NRT threat updates\nEC-130E Rivet Rider\u00a0\u2013 Airborne psychological warfare aircraft\nEC-130H Compass Call\u00a0\u2013 Electronic warfare and electronic attack.\nEC-130Q\u00a0\u2013 USN TACAMO aircraft\nEC-130V\u00a0\u2013 Airborne early warning and control (AEW&amp;C) variant used by USCG for counter-narcotics missions\n Permanently grounded instructional airframes\nHC-130B/E/H\u00a0\u2013 Early model combat search and rescue\nHC-130P/N Combat King\u00a0\u2013 USAF aerial refueling tanker and combat search and rescue\nHC-130J Combat King II\u00a0\u2013 Next generation combat search and rescue tanker\nHC-130H/J\u00a0\u2013 USCG long-range surveillance and search and rescue, https://\n Temporary conversion for flight test operations; used to recover drones and spy satellite film capsules.\n United States Marine Corps aerial refueling tanker and tactical airlifter\n USAF / Air National Guard\u00a0\u2013 Ski-equipped version for Arctic and Antarctic support operations; LC-130F and R previously operated by USN\nMC-130E/H Combat Talon I/II\u00a0\u2013 Special operations infiltration/extraction variant\nMC-130W Combat Spear/Dragon Spear\u00a0\u2013 Special operations tanker/gunship\nMC-130P Combat Shadow\u00a0\u2013 Special operations tanker \u2013 all operational aircraft converted to HC-130P standard\nMC-130J Commando II (formerly Combat Shadow II)\u00a0\u2013 Special operations tanker Air Force Special Operations Command\nYMC-130H\u00a0\u2013 Modified aircraft under Operation Credible Sport for second Iran hostage crisis rescue attempt\n Permanent conversion for flight test operations\n Maritime patrol\n Surveillance aircraft for reconnaissance\n Proposed maritime patrol version of the C-130J, designed for coastal surveillance and anti-submarine warfare.\n Aircrew training\n VIP transport\n Weather reconnaissance (\"Hurricane Hunter\") version for USAF / Air Force Reserve Command's 53d Weather Reconnaissance Squadron in support of the National Weather Service's National Hurricane Center\nElectronic warfare version of C-130H for Republic of China Air Force.\nTurkey's Erciyes modernization program covers modernization of the avionics of C-130B/E variants of the aircraft. In scope of modernization the aircraft is equipped with Digital Cockpit (four-color Multifunctional Display with moving map capability-MFD), two Central Display Units (CDU) and two multifunction Central Control Computers compatible with international navigational requirements, as well as with a multifunction Mission Computer with high operational capability, Flight Management System (FMS), Link-16, Ground Mission Planning Unit compatible with the Air Force Information System, and display and lighting systems compatible with Night Vision Goggles. Other components such as GPS, indicator, anti-collision system, air radar, advanced military and civilian navigation systems, night-time invisible lighting for military missions, black box voice recorder, communication systems, advanced automated flight systems (military and civilian), systems enabling operation in the military network, digital moving map and ground mission planning systems are also included.\n() Royal Thai Armed Forces designation for the C-130H.\n() Royal Thai Armed Forces designation for the C-130H-30.\nSwedish Air Force designation for the C-130H\nOperators.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nFormer operators\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nAccidents.\nThe C-130 Hercules has had a low accident rate in general. The Royal Air Force recorded an accident rate of about one aircraft loss per 250,000 flying hours over the last 40 years, placing it behind Vickers VC10s and Lockheed TriStars with no flying losses. USAF C-130A/B/E-models had an overall attrition rate of 5% as of 1989 as compared to 1\u20132% for commercial airliners in the U.S., according to the NTSB, 10% for B-52 bombers, and 20% for fighters (F-4, F-111), trainers (T-37, T-38), and helicopters (H-3).\nSpecifications (C-130H).\n\"Data from\" USAF C-130 Hercules fact sheet, \"International Directory of Military Aircraft\", \"Complete Encyclopedia of World Aircraft\", and \"Encyclopedia of Modern Military Aircraft\".General characteristics* Crew: 5 (2 pilots, CSO/navigator, flight engineer and loadmaster)* Capacity: payload\nPerformance* Maximum speed: Mach * Endurance: * g limits: * Roll rate: * Maximum glide ratio: *Takeoff distance: at max gross weight;\n at gross weight\nAvionics\nSee also.\nRelated development\nAircraft of comparable role, configuration, and era\nRelated lists\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "7699", "revid": "12136076", "url": "https://en.wikipedia.org/wiki?curid=7699", "title": "Commodore 1570", "text": "The Commodore 1570 is a 5\u00bc\" floppy disk drive for the Commodore 128 home/personal computer. It is a single-sided, 170 kB version of the Commodore 1571, released as a stopgap measure when Commodore International was unable to provide sufficient quantities of 1571s due to a shortage of double-sided drive mechanisms (which were supplied by an outside manufacturer). Like the 1571, it can read and write both GCR and MFM disk formats.\nThe 1570 utilizes a 1571 logic board in a cream-colored original-1541-like case with a drive mechanism similar to the 1541's except that it was equipped with track-zero detection. Like the 1571, its built-in DOS provides a data burst mode for transferring data to the C128 computer at a faster speed than a 1541 can. Its ROM also contains some DOS bug fixes that didn't appear in the 1571 until much later. The 1570 can read and write all single-sided CP/M-format disks that the 1571 can access.\nAlthough the 1570 is compatible with the Commodore 64, the C64 isn't capable of taking advantage of the drive's higher-speed operation, and when used with the C64 it is little more than a pricier 1541. Also, many early buyers of the C128 chose to temporarily make do with a 1541 drive, perhaps owned as part of a previous C64 setup, until the 1571 became more widely available.\nThe drive uses the CPU MOS 6502, floppy controller WD1770 or WD1772, I/O controllers 2x MOS Technology 6522 and 1x MOS Technology 6526.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "7700", "revid": "47197650", "url": "https://en.wikipedia.org/wiki?curid=7700", "title": "Commodore 1571", "text": "Floppy disk drive\nThe Commodore 1571 is Commodore's high-end 5\u00bc\" floppy disk drive, announced in the summer of 1985. With its double-sided drive mechanism, it has the ability to use double-sided, double-density (DS/DD) floppy disks, storing a total of 360\u00a0kB per floppy. It also implemented a \"burst mode\" that improved transfer speeds, helping address the very slow performance of previous Commodore drives.\nEarlier Commodore drives used a custom group coded recording format that stored 170\u00a0kB per side of a disk. This made it fairly competitive in terms of storage, but limited it to only reading and writing disks from other Commodore machines. The 1571 was designed to partner with the new Commodore 128 (C128), which introduced support for CP/M. Adding double-density MFM encoding allowed the drive to read and write contemporary CP/M disks (and many others).\nIn contrast to its single-sided predecessors, the 1541 and the briefly-available 1570, the 1571 can use both sides of the disk at the same time. Previously, users could only use the second side by manually flipping them over. Because flipping the disk also reverses the direction of rotation, the two methods are not interchangeable; disks which had their back side created in a 1541 by flipping them over would have to be flipped in the 1571 too, and the back side of disks written in a 1571 using the native support for two-sided operation could not be read in a 1541.\nRelease and features.\nThe 1571 was released to match the Commodore 128, both design-wise and feature-wise. It was announced in the summer of 1985, at the same time as the C128, and became available in quantity later that year. The later C128D had a 1571 drive built into the system unit. A double-sided disk on the 1571 would have a capacity of 340 kB (70 tracks, 1,360 disk blocks of 256 bytes each); as 8 kB are reserved for system use (directory and block availability information) and, under CBM DOS, 2 bytes of each block serve as pointers to the next logical block, 254 x 1,328 = 337,312 B or about 329.4 kB were available for user data. (However, with a program organizing disk storage on its own, all space could be used, e.g. for data disks.)\nThe 1571 was designed to accommodate the C128's \"burst\" mode for faster disk access, however the drive cannot use it if connected to older Commodore machines. This mode replaced the slow bit-banging serial routines of the 1541 with a true serial shift register implemented in hardware, thus dramatically increasing the drive speed. Although this originally had been planned when Commodore first switched from the parallel IEEE-488 interface to the CBM-488 custom serial interface, hardware bugs in the VIC-20's 6522 VIA shift register prevented it from working properly.\nWhen connected to a C128, the 1571 would default to double-sided mode, which allowed the drive to read its own 340k disks as well as single-sided 170 kB 1541 disks. If the C128 was switched into C64 mode by typing GO 64 from BASIC, the 1571 will stay in double-sided mode. If C64 mode was activated by holding down the C= key on power-up, the drive would automatically switch to single-sided mode, in which case it is unable to read 340 kB disks (also the default if a 1571 is used with a C64, Plus/4, VIC-20, or PET). A manual command can also be issued from BASIC to switch the 1571 between single and double sided mode. There is also an undocumented command which allows the user to independently control either of the read/write heads of the 1571, making it possible to format both sides of a diskette separate from each other, however the resultant disk cannot be read in a 1541 as it would be spinning in reverse direction when flipped upside down. In the same vein, \"flippy\" disks created with a 1541 cannot be read on a 1571 with this feature; they must be inserted upside down.\nThe 1571 is not 100% low-level compatible with the 1541; however, this isn't a problem except in some software that uses advanced copy protections such as the RapidLok system found on MicroProse and Accolade games.\nThe 1571 was noticeably quieter than its predecessor and tended to run cooler as well, even though, like the 1541, it had an internal power supply (later Commodore drives, like the 1541-II and the 3\u00bd\" 1581, came with external power supplies). The 1541-II/1581 power supply makes mention of a 1571-II, hinting that Commodore may have intended to release a version of the 1571 with an external power supply. However, no 1571-IIs are known to exist. The embedded OS in the 1571 was CBM DOS V3.0 1571, an improvement over the 1541's V2.6.\nEarly 1571s had a bug in the ROM-based disk operating system that caused relative files to corrupt if they occupied both sides of the disk. A version 2 ROM was released, but though it cured the initial bug, it introduced some minor quirks of its own \u2013 particularly with the 1541 emulation. Curiously, it was also identified as V3.0.\nAs with the 1541, Commodore initially could not meet demand for the 1571, and that lack of availability and the drive's relatively high price (about US$300) presented an opportunity for cloners. Two 1571 clones appeared, one from Oceanic and one from Blue Chip, but legal action from Commodore quickly drove them from the market.\nCommodore announced at the 1985 Consumer Electronics Show a dual-drive version of the 1571, to be called the Commodore 1572, but quickly canceled it, reportedly due to technical difficulties with the 1572 DOS. It would have had four times as much RAM as the 1571 (8 kB), and twice as much ROM (64 kB). The 1572 would have allowed for fast disk backups of non-copy-protected media, much like the old 4040, 8050, and 8250 dual drives.\nThe 1571 built into the European plastic-case C128\"D\" computer is electronically identical to the stand-alone version, but 1571 version integrated into the later metal-case C128D (often called C128 DCR, for D Cost-Reduced) differs a lot from the stand-alone 1571. It includes a newer DOS, version 3.1, replaces the MOS Technology CIA interface chip, of which only a few features were used by the 1571 DOS, with a very much simplified chip called 5710, and has some compatibility issues with the stand-alone drive. Because this internal 1571 does not have an unused 8-bit input/output port on any chip, unlike most other Commodore drives, it is not possible to install a parallel cable in this drive, such as that used by SpeedDOS, DolphinDOS and some other fast third-party Commodore DOS replacements.\nTechnical design.\nThe drive detects the motor speed and generates an internal data sampling clock signal that matches with the motor speed.\nThe 1571 uses a saddle canceler when reading the data stream. A correction signal is generated when the raw data pattern on the disk consists of two consecutive zeros. With the GCR recording format a problem occurs in the read signal waveform. The worst case pattern 1001 may cause a saddle condition where a false data bit may occur. The original 1541 drives uses a one-shot to correct the condition. The 1571 uses a gate array to correct this digitally.\nThe drive uses the MOS 6502 CPU, WD1770 or WD1772 floppy controller, 2x MOS Technology 6522 I/O controllers and 1x MOS Technology 6526.\nDisk format.\nUnlike the 1541, which was limited to GCR formatting, the 1571 could read both GCR and MFM disk formats. The version of CP/M included with the C128 supported the following formats:\nThe 1571 can read any of the many CP/M &lt;templatestyles src=\"Fraction/styles.css\" /&gt;5+1\u20444-disk formats. If the CP/M BIOS is modified, it is possible to read any soft sector 40-track MFM format. Single density (FM) formats are not supported because the density selector pin on the MFM controller chip in the drive is disabled (wired to ground).\nA 1571 cannot boot from MFM disks; the user must boot CP/M from a GCR disk and then switch to MFM disks.\nWith additional software, it was possible to read and write to MS-DOS-formatted floppies as well. Numerous commercial and public-domain programs for this purpose became available, the best-known being SOGWAP's \"Big Blue Reader\". Although the C128 could not run any MS-DOS-based software, this capability allowed data files to be exchanged with PC users. Reading Atari 8-bit 130 kB or 180 kB disks was possible as well with special software, but the standard Atari 8-bit 90 kB format, which used FM rather than MFM encoding, could not be handled by the 1571 hardware without modifying the drive circuitry as the control line that determines if FM or MFM encoding is used by the disc controller chip was permanently wired to ground (MFM mode) rather than being under software control.\nIn the 1541 format, while 40 tracks are possible for a 5.25\" DD drive like the 154x/157x, only 35 tracks are used. Commodore chose not to use the upper five tracks by default (or at least to use more than 35) due to the bad quality of some of the drive mechanisms, which did not always work reliably on those tracks.\nFor compatibility and ease of implementation, the 1571's double-sided format of one logical disk side with 70 tracks was created by putting together the lower 35 physical tracks on each of the physical sides of the disk rather than using two times 40 tracks, even though there were no more quality problems with the mechanisms of the 1571 drives.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
