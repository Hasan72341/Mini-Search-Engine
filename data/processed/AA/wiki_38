{"id": "4473", "revid": "13821153", "url": "https://en.wikipedia.org/wiki?curid=4473", "title": "BIOS", "text": "Firmware for hardware initialization and OS runtime services\nIn computing, BIOS (, ; Basic Input/Output System, also known as the System BIOS, ROM BIOS, BIOS ROM or PC BIOS) is a type of firmware used to provide runtime services for operating systems and programs and to perform hardware initialization during the booting process (power-on startup). On a computer using BIOS firmware, the firmware comes pre-installed on the computer's motherboard.\nThe name originates from the Basic Input/Output System used in the CP/M operating system in 1975. The BIOS firmware was originally proprietary to the IBM PC; it was reverse engineered by some companies, such as Compaq, Phoenix Technologies, AMI and others, looking to create compatible systems. The interface of that original system serves as a \"de facto\" standard.\nThe BIOS in older PCs initializes and tests the system hardware components (power-on self-test or POST for short), and loads a boot loader from a mass storage device which then initializes a kernel. In the era of DOS, the BIOS provided BIOS interrupt calls for the keyboard, display, storage, and other input/output (I/O) devices that standardized an interface to application programs and the operating system. More recent operating systems do not use the BIOS interrupt calls after startup.\nMost BIOS implementations are specifically designed to work with a particular computer or motherboard model, by interfacing with various devices especially system chipset. Originally, BIOS firmware was stored in a ROM chip on the PC motherboard. In later computer systems, the BIOS contents are stored on flash memory so it can be rewritten without removing the chip from the motherboard. This allows easy, end-user updates to the BIOS firmware so new features can be added or bugs can be fixed, but it also creates a possibility for the computer to become infected with BIOS rootkits. Furthermore, a BIOS upgrade that fails could brick the motherboard.\nUnified Extensible Firmware Interface (UEFI) is a successor to the PC BIOS, aiming to address its technical limitations. UEFI firmware may include legacy BIOS compatibility to maintain compatibility with operating systems and option cards that do not support UEFI native operation. Since 2020, all PCs for Intel platforms no longer support legacy BIOS. The last version of Microsoft Windows to officially support running on PCs which use legacy BIOS firmware is Windows 10 as Windows 11 requires a UEFI-compliant system (except for IoT Enterprise editions of Windows 11 since version 24H2).\nHistory.\n&lt;templatestyles src=\"Rquote/styles.css\"/&gt;{ class=\"rquote pullquote floatright\" role=\"presentation\" style=\"display:table; border-collapse:collapse; border-style:none; float:right; margin:0.5em 0.75em; width:33%; \"\nThe term BIOS (Basic Input/Output System) was created by Gary Kildall and first appeared in the CP/M operating system in 1975, describing the machine-specific part of CP/M loaded during boot time that interfaces directly with the hardware. (A CP/M machine usually has only a simple boot loader in its ROM.)\nVersions of MS-DOS, PC DOS or DR-DOS contain a file called variously \"IO.SYS\", \"IBMBIO.COM\", \"IBMBIO.SYS\", or \"DRBIOS.SYS\"; this file is known as the \"DOS BIOS\" (also known as the \"DOS I/O System\") and contains the lower-level hardware-specific part of the operating system. Together with the underlying hardware-specific but operating system-independent \"System BIOS\", which resides in ROM, it represents the analogue to the \"CP/M BIOS\".\nThe BIOS originally proprietary to the IBM PC has been reverse engineered by some companies, such as Compaq, Phoenix Technologies, AMI and others, looking to create compatible systems.\nWith the introduction of PS/2 machines, IBM divided the System BIOS into real- and protected-mode portions. The real-mode portion was meant to provide backward compatibility with existing operating systems such as DOS, and therefore was named \"CBIOS\" (for \"Compatibility BIOS\"), whereas the \"ABIOS\" (for \"Advanced BIOS\") provided new interfaces specifically suited for multitasking operating systems such as OS/2.\nUser interface.\nThe BIOS of the original IBM PC and XT had no interactive user interface. Error codes or messages were displayed on the screen, or coded series of sounds were generated to signal errors when the power-on self-test (POST) had not proceeded to the point of successfully initializing a video display adapter. Options on the IBM PC and XT were set by switches and jumpers on the main board and on expansion cards. Starting around the mid-1990s, it became typical for the BIOS ROM to include a \"BIOS configuration utility\" (BCU) or \"BIOS setup utility\", accessed at system power-up by a particular key sequence. This program allowed the user to set system configuration options, of the type formerly set using DIP switches, through an interactive menu system controlled through the keyboard. In the interim period, IBM-compatible PCs\u200d\u2014\u200cincluding the IBM AT\u200d\u2014\u200cheld configuration settings in battery-backed RAM and used a bootable configuration program on floppy disk, not in the ROM, to set the configuration options contained in this memory. The floppy disk was supplied with the computer, and if it was lost the system settings could not be changed. The same applied in general to computers with an EISA bus, for which the configuration program was called an EISA Configuration Utility (ECU).\nA modern Wintel-compatible computer provides a setup routine essentially unchanged in nature from the ROM-resident BIOS setup utilities of the late 1990s; the user can configure hardware options using the keyboard and video display. The modern Wintel machine may store the BIOS configuration settings in flash ROM, perhaps the same flash ROM that holds the BIOS itself.\nExtensions (option ROMs).\nPeripheral cards such as hard disk drive host bus adapters and video cards have their own firmware, and BIOS extension option ROM code may be a part of the expansion card firmware; that code provides additional capabilities in the BIOS. Code in option ROMs runs before the BIOS boots the operating system from mass storage. These ROMs typically test and initialize hardware, add new BIOS services, or replace existing BIOS services with their own services. For example, a SCSI controller usually has a BIOS extension ROM that adds support for hard drives connected through that controller. An extension ROM could in principle contain operating system, or it could implement an entirely different boot process such as network booting. Operation of an IBM-compatible computer system can be completely changed by removing or inserting an adapter card (or a ROM chip) that contains a BIOS extension ROM.\nThe motherboard BIOS typically contains code for initializing and bootstrapping integrated display and integrated storage. The initialization process can involve the execution of code related to the device being initialized, for locating the device, verifying the type of device, then establishing base registers, setting pointers, establishing interrupt vector tables, selecting paging modes which are ways for organizing available registers in devices, setting default values for accessing software routines related to interrupts, and setting the device's configuration using default values. In addition, plug-in adapter cards such as SCSI, RAID, network interface cards, and video cards often include their own BIOS (e.g. Video BIOS), complementing or replacing the system BIOS code for the given component. Even devices built into the motherboard can behave in this way; their option ROMs can be a part of the motherboard BIOS.\nAn add-in card requires an option ROM if the card is not supported by the motherboard BIOS and the card needs to be initialized or made accessible through BIOS services before the operating system can be loaded (usually this means it is required in the boot process). An additional advantage of ROM on some early PC systems (notably including the IBM PCjr) was that ROM was faster than main system RAM. (On modern systems, the case is very much the reverse of this, and BIOS ROM code is usually copied (\"shadowed\") into RAM so it will run faster.)\nPhysical placement.\nOption ROMs normally reside on adapter cards. However, the original PC, and perhaps also the PC XT, have a spare ROM socket on the motherboard (the \"system board\" in IBM's terms) into which an option ROM can be inserted, and the four ROMs that contain the BASIC interpreter can also be removed and replaced with custom ROMs which can be option ROMs. The IBM PCjr is unique among PCs in having two ROM cartridge slots on the front. Cartridges in these slots map into the same region of the upper memory area used for option ROMs, and the cartridges can contain option ROM modules that the BIOS would recognize. The cartridges can also contain other types of ROM modules, such as BASIC programs, that are handled differently. One PCjr cartridge can contain several ROM modules of different types, possibly stored together in one ROM chip.\nOperation.\nSystem startup.\nThe 8086 and 8088 start at physical address FFFF0h. The 80286 starts at physical address FFFFF0h. The 80386 and later x86 processors start at physical address FFFFFFF0h. When the system is initialized, the first instruction of the BIOS appears at that address.\nIf the system has just been powered up or the reset button was pressed (\"cold boot\"), the full power-on self-test (POST) is run. If Ctrl+Alt+Delete was pressed (\"warm boot\"), a special flag value stored in nonvolatile BIOS memory (\"CMOS\") tested by the BIOS allows bypass of the lengthy POST and memory detection.\nThe POST identifies, tests and initializes system devices such as the CPU, chipset, RAM, motherboard, video card, keyboard, mouse, hard disk drive, optical disc drive and other hardware, including integrated peripherals.\nEarly IBM PCs had a routine in the POST that would download a program into RAM through the keyboard port and run it. This feature was intended for factory test or diagnostic purposes.\nAfter the motherboard BIOS completes its POST, most BIOS versions search for option ROM modules, also called BIOS extension ROMs, and execute them. The motherboard BIOS scans for extension ROMs in a portion of the \"upper memory area\" (the part of the x86 real-mode address space at and above address 0xA0000) and runs each ROM found, in order. To discover memory-mapped option ROMs, a BIOS implementation scans the real-mode address space from codice_1 to codice_2 on 2\u00a0KB (2,048 bytes) boundaries, looking for a two-byte ROM \"signature\": 0x55 followed by 0xAA. In a valid expansion ROM, this signature is followed by a single byte indicating the number of 512-byte blocks the expansion ROM occupies in real memory, and the next byte is the option ROM's entry point (also known as its \"entry offset\"). If the ROM has a valid checksum, the BIOS transfers control to the entry address, which in a normal BIOS extension ROM should be the beginning of the extension's initialization routine.\nAt this point, the extension ROM code takes over, typically testing and initializing the hardware it controls and registering interrupt vectors for use by post-boot applications. It may use BIOS services (including those provided by previously initialized option ROMs) to provide a user configuration interface, to display diagnostic information, or to do anything else that it requires.\nAn option ROM should normally return to the BIOS after completing its initialization process. Once (and if) an option ROM returns, the BIOS continues searching for more option ROMs, calling each as it is found, until the entire option ROM area in the memory space has been scanned. It is possible that an option ROM will not return to BIOS, pre-empting the BIOS's boot sequence altogether.\nBoot process.\nAfter the POST completes and, in a BIOS that supports option ROMs, after the option ROM scan is completed and all detected ROM modules with valid checksums have been called, the BIOS calls interrupt 19h to start boot processing. Post-boot, programs loaded can also call interrupt 19h to reboot the system, but they must be careful to disable interrupts and other asynchronous hardware processes that may interfere with the BIOS rebooting process, or else the system may hang or crash while it is rebooting.\nWhen interrupt 19h is called, the BIOS attempts to locate boot loader software on a \"boot device\", such as a hard disk, a floppy disk, CD, or DVD. It loads and executes the first boot software it finds, giving it control of the PC.\nThe BIOS uses the boot devices set in Nonvolatile BIOS memory (CMOS), or, in the earliest PCs, DIP switches. The BIOS checks each device in order to see if it is bootable by attempting to load the first sector (boot sector). If the sector cannot be read, the BIOS proceeds to the next device. If the sector is read successfully, some BIOSes will also check for the boot sector signature 0x55 0xAA in the last two bytes of the sector (which is 512 bytes long), before accepting a boot sector and considering the device bootable.\nWhen a bootable device is found, the BIOS transfers control to the loaded sector. The BIOS does not interpret the contents of the boot sector other than to possibly check for the boot sector signature in the last two bytes. Interpretation of data structures like partition tables and BIOS Parameter Blocks is done by the boot program in the boot sector itself or by other programs loaded through the boot process.\nA non-disk device such as a network adapter attempts booting by a procedure that is defined by its option ROM or the equivalent integrated into the motherboard BIOS ROM. As such, option ROMs may also influence or supplant the boot process defined by the motherboard BIOS ROM.\nWith the El Torito optical media boot standard, the optical drive actually emulates a 3.5\" high-density floppy disk to the BIOS for boot purposes. Reading the \"first sector\" of a CD-ROM or DVD-ROM is not a simply defined operation like it is on a floppy disk or a hard disk. Furthermore, the complexity of the medium makes it difficult to write a useful boot program in one sector. The bootable virtual floppy disk can contain software that provides access to the optical medium in its native format.\nIf an expansion ROM wishes to change the way the system boots (such as from a network device or a SCSI adapter) in a cooperative way, it can use the \"BIOS Boot Specification\" (BBS) API to register its ability to do so. Once the expansion ROMs have registered using the BBS APIs, the user can select among the available boot options from within the BIOS's user interface. This is why most BBS compliant PC BIOS implementations will not allow the user to enter the BIOS's user interface until the expansion ROMs have finished executing and registering themselves with the BBS API.\nAlso, if an expansion ROM wishes to change the way the system boots unilaterally, it can simply hook interrupt 19h or other interrupts normally called from interrupt 19h, such as interrupt 13h, the BIOS disk service, to intercept the BIOS boot process. Then it can replace the BIOS boot process with one of its own, or it can merely modify the boot sequence by inserting its own boot actions into it, by preventing the BIOS from detecting certain devices as bootable, or both. Before the BIOS Boot Specification was promulgated, this was the only way for expansion ROMs to implement boot capability for devices not supported for booting by the native BIOS of the motherboard.\nBoot priority.\nThe user can select the boot priority implemented by the BIOS. For example, most computers have a hard disk that is bootable, but sometimes there is a removable-media drive that has higher boot priority, so the user can cause a removable disk to be booted.\nIn most modern BIOSes, the boot priority order can be configured by the user. In older BIOSes, limited boot priority options are selectable; in the earliest BIOSes, a fixed priority scheme was implemented, with floppy disk drives first, fixed disks (i.e., hard disks) second, and typically no other boot devices supported, subject to modification of these rules by installed option ROMs. The BIOS in an early PC also usually would only boot from the first floppy disk drive or the first hard disk drive, even if there were two drives installed.\nBoot failure.\nOn the original IBM PC and XT, if no bootable disk was found, the BIOS would try to start ROM BASIC with the interrupt call to . Since few programs used BASIC in ROM, clone PC makers left it out; then a computer that failed to boot from a disk would display \"No ROM BASIC\" and halt (in response to interrupt 18h).\nLater computers would display a message like \"No bootable disk found\"; some would prompt for a disk to be inserted and a key to be pressed to retry the boot process. A modern BIOS may display nothing or may automatically enter the BIOS configuration utility when the boot process fails.\nBoot environment.\nThe environment for the boot program is very simple: the CPU is in real mode and the general-purpose and segment registers are undefined, except SS, SP, CS, and DL. CS:IP always points to physical address codice_3. What values CS and IP actually have is not well defined. Some BIOSes use a CS:IP of codice_4 while others may use codice_5. Because boot programs are always loaded at this fixed address, there is no need for a boot program to be relocatable. DL may contain the drive number, as used with interrupt 13h, of the boot device. SS:SP points to a valid stack that is presumably large enough to support hardware interrupts, but otherwise SS and SP are undefined. (A stack must be already set up in order for interrupts to be serviced, and interrupts must be enabled in order for the system timer-tick interrupt, which BIOS always uses at least to maintain the time-of-day count and which it initializes during POST, to be active and for the keyboard to work. The keyboard works even if the BIOS keyboard service is not called; keystrokes are received and placed in the 15-character type-ahead buffer maintained by BIOS.) The boot program must set up its own stack, because the size of the stack set up by BIOS is unknown and its location is likewise variable; although the boot program can investigate the default stack by examining SS:SP, it is easier and shorter to just unconditionally set up a new stack.\nAt boot time, all BIOS services are available, and the memory below address codice_6 contains the interrupt vector table. BIOS POST has initialized the system timers, interrupt controller(s), DMA controller(s), and other motherboard/chipset hardware as necessary to bring all BIOS services to ready status. DRAM refresh for all system DRAM in conventional memory and extended memory, but not necessarily expanded memory, has been set up and is running. The interrupt vectors corresponding to the BIOS interrupts have been set to point at the appropriate entry points in the BIOS, hardware interrupt vectors for devices initialized by the BIOS have been set to point to the BIOS-provided ISRs, and some other interrupts, including ones that BIOS generates for programs to hook, have been set to a default dummy ISR that immediately returns. The BIOS maintains a reserved block of system RAM at addresses codice_7 with various parameters initialized during the POST. All memory at and above address codice_8 can be used by the boot program; it may even overwrite itself.\nOperating system services.\nThe BIOS ROM is customized to the particular manufacturer's hardware, allowing low-level services (such as reading a keystroke or writing a sector of data to diskette) to be provided in a standardized way to programs, including operating systems. For example, an IBM PC might have either a monochrome or a color display adapter (using different display memory addresses and hardware), but a single, standard, BIOS system call may be invoked to display a character at a specified position on the screen in text mode or graphics mode.\nThe BIOS provides a small library of basic input/output functions to operate peripherals (such as the keyboard, rudimentary text and graphics display functions and so forth). When using MS-DOS, BIOS services could be accessed by an application program (or by MS-DOS) by executing an interrupt 13h interrupt instruction to access disk functions, or by executing one of a number of other documented BIOS interrupt calls to access video display, keyboard, cassette, and other device functions.\nOperating systems and executive software that are designed to supersede this basic firmware functionality provide replacement software interfaces to application software. Applications can also provide these services to themselves. This began even in the 1980s under MS-DOS, when programmers observed that using the BIOS video services for graphics display were very slow. To increase the speed of screen output, many programs bypassed the BIOS and programmed the video display hardware directly. Other graphics programmers, particularly but not exclusively in the demoscene, observed that there were technical capabilities of the PC display adapters that were not supported by the IBM BIOS and could not be taken advantage of without circumventing it. Since the AT-compatible BIOS ran in Intel real mode, operating systems that ran in protected mode on 286 and later processors required hardware device drivers compatible with protected mode operation to replace BIOS services.\nModern operating systems, such as Windows and Linux, use the BIOS interrupt calls only during the booting process. Before the operating system's first graphical screen is displayed, input and output are typically handled through BIOS. A boot menu such as the textual menu of Windows, which allows users to choose an operating system to boot, to boot into the safe mode, or to use the last known good configuration, is displayed through BIOS and receives keyboard input through BIOS.\nMany modern PCs can still boot and run legacy operating systems such as MS-DOS or DR-DOS that rely heavily on BIOS for their console and disk I/O, providing that the system has a BIOS, or a CSM-capable UEFI firmware.\nProcessor microcode updates.\nIntel processors have reprogrammable microcode since the P6 microarchitecture. AMD processors have reprogrammable microcode since the K7 microarchitecture. The BIOS contains patches to the processor microcode that fix errors in the initial processor microcode; microcode is loaded into processor's SRAM so reprogramming is not persistent, thus loading of microcode updates is performed each time the system is powered up. Without reprogrammable microcode, an expensive processor swap would be required; for example, the Pentium FDIV bug became an expensive fiasco for Intel as it required a product recall because the original Pentium processor's defective microcode could not be reprogrammed. Operating systems can also update the microcode.\nIdentification.\nSome BIOSes contain a software licensing description table (SLIC), a digital signature placed inside the BIOS by the original equipment manufacturer (OEM), for example Dell. The SLIC is inserted into the ACPI data table and contains no active code.\nComputer manufacturers that distribute OEM versions of Microsoft Windows and Microsoft application software can use the SLIC to authenticate licensing to the OEM Windows Installation disk and system recovery disc containing Windows software. Systems with a SLIC can be preactivated with an OEM product key, and they verify an XML formatted OEM certificate against the SLIC in the BIOS as a means of self-activating (see System Locked Preinstallation, SLP). If a user performs a fresh install of Windows, they will need to have possession of both the OEM key (either SLP or COA) and the digital certificate for their SLIC in order to bypass activation. This can be achieved if the user performs a restore using a pre-customised image provided by the OEM. Power users can copy the necessary certificate files from the OEM image, decode the SLP product key, then perform SLP activation manually.\nOverclocking.\nSome BIOS implementations allow overclocking, an action in which the CPU is adjusted to a higher clock rate than its manufacturer rating for guaranteed capability. Overclocking may, however, seriously compromise system reliability in insufficiently cooled computers and generally shorten component lifespan. Overclocking, when incorrectly performed, may also cause components to overheat so quickly that they mechanically destroy themselves.\nModern use.\nSome older operating systems, for example MS-DOS, rely on the BIOS to carry out most input/output tasks within the PC.\nCalling real mode BIOS services directly is inefficient for protected mode (and long mode) operating systems. BIOS interrupt calls are not used by modern multitasking operating systems after they initially load.\nIn the 1990s, BIOS provided some protected mode interfaces for Microsoft Windows and Unix-like operating systems, such as Advanced Power Management (APM), Plug and Play BIOS, Desktop Management Interface (DMI), VESA BIOS Extensions (VBE), e820 and MultiProcessor Specification (MPS). Starting from the year 2000, most BIOSes provide ACPI, SMBIOS, VBE and e820 interfaces for modern operating systems.\nAfter operating systems load, the System Management Mode code is still running in SMRAM. Since 2010, BIOS technology is in a transitional process toward UEFI.\nConfiguration.\nSetup utility.\nHistorically, the BIOS in the IBM PC and XT had no built-in user interface. The BIOS versions in earlier PCs (XT-class) were not software configurable; instead, users set the options via DIP switches on the motherboard. Later computers, including most IBM-compatibles with 80286 CPUs, had a battery-backed nonvolatile BIOS memory (CMOS RAM chip) that held BIOS settings. These settings, such as video-adapter type, memory size, and hard-disk parameters, could only be configured by running a configuration program from a disk, not built into the ROM. A special \"reference diskette\" was inserted in an IBM AT to configure settings such as memory size.\nEarly BIOS versions did not have passwords or boot-device selection options. The BIOS was hard-coded to boot from the first floppy drive, or, if that failed, the first hard disk. Access control in early AT-class machines was by a physical keylock switch (which was not hard to defeat if the computer case could be opened). Anyone who could switch on the computer could boot it.\nLater, 386-class computers started integrating the BIOS setup utility in the ROM itself, alongside the BIOS code; these computers usually boot into the BIOS setup utility if a certain key or key combination is pressed, otherwise the BIOS POST and boot process are executed.\nA modern BIOS setup utility has a text user interface (TUI) or graphical user interface (GUI) accessed by pressing a certain key on the keyboard when the PC starts. Usually, the key is advertised for short time during the early startup, for example \"Press DEL to enter Setup\". \nThe actual key depends on specific hardware. The settings key is most often Delete (Acer, ASRock, Asus PC, ECS, Gigabyte, MSI, Zotac) and F2 (Asus\u00a0motherboard, Dell, Lenovo laptop, Origin PC, Samsung, Toshiba), but it can also be F1 (Lenovo\u00a0desktop) and F10 (HP).\nFeatures present in the BIOS setup utility typically include:\nHardware monitoring.\nA modern BIOS setup screen often features a PC Health Status or a Hardware Monitoring tab, which directly interfaces with a Hardware Monitor chip of the mainboard. This makes it possible to monitor CPU and chassis temperature, the voltage provided by the power supply unit, as well as monitor and control the speed of the fans connected to the motherboard.\nOnce the system is booted, hardware monitoring and computer fan control is normally done directly by the Hardware Monitor chip itself, which can be a separate chip, interfaced through I\u00b2C or SMBus, or come as a part of a Super I/O solution, interfaced through Industry Standard Architecture (ISA) or Low Pin Count (LPC). Some operating systems, like NetBSD with envsys and OpenBSD with sysctl hw.sensors, feature integrated interfacing with hardware monitors.\nHowever, in some circumstances, the BIOS also provides the underlying information about hardware monitoring through ACPI, in which case, the operating system may be using ACPI to perform hardware monitoring.\nReprogramming.\nIn modern PCs the BIOS is stored in rewritable EEPROM or NOR flash memory, allowing the contents to be replaced and modified. This rewriting of the contents is sometimes termed \"flashing.\" It can be done by a special program, usually provided by the system's manufacturer, or at POST, with a BIOS image in a hard drive or USB flash drive. A file containing such contents is sometimes termed \"a BIOS image\". A BIOS might be reflashed in order to upgrade to a newer version to fix bugs or provide improved performance or to support newer hardware. Some computers also support updating the BIOS via an update floppy disk or a special partition on the hard drive.\nHardware.\nThe original IBM PC BIOS (and cassette BASIC) was stored on mask-programmed read-only memory (ROM) chips in sockets on the motherboard. ROMs could be replaced, but not altered, by users. To allow for updates, many compatible computers used re-programmable BIOS memory devices such as EPROM, EEPROM and later flash memory (usually NOR flash) devices. According to Robert Braver, the president of the BIOS manufacturer Micro Firmware, Flash BIOS chips became common around 1995 because the electrically erasable PROM (EEPROM) chips are cheaper and easier to program than standard ultraviolet erasable PROM (EPROM) chips. Flash chips are programmed (and re-programmed) in-circuit, while EPROM chips need to be removed from the motherboard for re-programming. BIOS versions are upgraded to take advantage of newer versions of hardware and to correct bugs in previous revisions of BIOSes.\nBeginning with the IBM AT, PCs supported a hardware clock settable through BIOS. It had a century bit which allowed for manually changing the century when the year 2000 happened. Most BIOS revisions created in 1995 and nearly all BIOS revisions in 1997 supported the year 2000 by setting the century bit automatically when the clock rolled past midnight, 31 December 1999.\nThe first flash chips were attached to the ISA bus. Starting in 1998, the BIOS flash moved to the LPC bus, following a new standard implementation known as \"firmware hub\" (FWH). In 2005, the BIOS flash memory moved to the SPI bus.\nThe size of the BIOS, and the capacity of the ROM, EEPROM, or other media it may be stored on, has increased over time as new features have been added to the code; BIOS versions now exist with sizes up to 32 megabytes. For contrast, the original IBM PC BIOS was contained in an 8\u00a0KB mask ROM. Some modern motherboards are including even bigger NAND flash memory ICs on board which are capable of storing whole compact operating systems, such as some Linux distributions. For example, some ASUS notebooks included Splashtop OS embedded into their NAND flash memory ICs. However, the idea of including an operating system along with BIOS in the ROM of a PC is not new; in the 1980s, Microsoft offered a ROM option for MS-DOS, and it was included in the ROMs of some PC clones such as the Tandy 1000 HX.\nAnother type of firmware chip was found on the IBM PC AT and early compatibles. In the AT, the keyboard interface was controlled by a microcontroller with its own programmable memory. On the IBM AT, that was a 40-pin socketed device, while some manufacturers used an EPROM version of this chip which resembled an EPROM. This controller was also assigned the A20 gate function to manage memory above the one-megabyte range; occasionally an upgrade of this \"keyboard BIOS\" was necessary to take advantage of software that could use upper memory. \nThe BIOS may contain components such as the Memory Reference Code (MRC), which is responsible for the memory initialization (e.g. SPD and memory timings initialization).\nModern BIOS includes\nIntel Management Engine or AMD Platform Security Processor firmware.\nVendors and products.\nIBM published the listings of the BIOS for its original PC, PC XT, PC AT, and other contemporary PC models, in an appendix of the \"IBM PC Technical Reference Manual\" for each machine type. However, BIOS of an IBM PC is still proprietary to IBM.\nIn March 1983, Compaq released its Compaq Portable, which included a clean-room engineered BIOS. This makes Compaq became the first company that cloned IBM PC successfully. However, Compaq did not offer BIOS to other computer manufacturers.\nIn May 1984, Phoenix Software Associates released its first ROM-BIOS. This BIOS enabled OEMs to build essentially fully compatible clones without having to reverse-engineer the IBM PC BIOS themselves, as Compaq had done for the Portable; it also helped fuel the growth in the PC-compatibles industry and sales of non-IBM versions of DOS. The first American Megatrends (AMI) BIOS was released in 1986.\nNew standards grafted onto the BIOS are usually without complete public documentation or any BIOS listings. As a result, it is not as easy to learn the intimate details about the many non-IBM additions to BIOS as about the core BIOS services.\nMany PC motherboard suppliers licensed the BIOS \"core\" and toolkit from a commercial third party, known as an \"independent BIOS vendor\" or IBV. The motherboard manufacturer then customized this BIOS to suit its own hardware. For this reason, updated BIOSes are normally obtained directly from the motherboard manufacturer. Major IBVs included American Megatrends (AMI), Insyde Software, Phoenix Technologies, and Byosoft. Microid Research and Award Software were acquired by Phoenix Technologies in 1998; Phoenix later phased out the Award brand name (although Award Software is still credited in newer AwardBIOS versions and in UEFI firmwares). General Software, which was also acquired by Phoenix in 2007, sold BIOS for embedded systems based on Intel processors.\nSeaBIOS is an open-source BIOS implementation.\nOpen-source BIOS replacements.\nThe open-source community increased their effort to develop a replacement for proprietary BIOSes and their future incarnations with open-sourced counterparts. Open Firmware was an early attempt to make an open specification for boot firmware. It was initially endorsed by IEEE in its \"IEEE 1275-1994\" standard but was withdrawn in 2005. Later examples include the OpenBIOS, coreboot and libreboot projects. AMD provided product specifications for some chipsets using coreboot, and Google is sponsoring the project. Motherboard manufacturer Tyan offers coreboot next to the standard BIOS with their Opteron line of motherboards.\nSecurity.\nEEPROM and flash memory chips are advantageous because they can be easily updated by the user; it is customary for hardware manufacturers to issue BIOS updates to upgrade their products, improve compatibility and remove bugs. However, this advantage had the risk that an improperly executed or aborted BIOS update could render the computer or device unusable. To avoid these situations, more recent BIOSes use a \"boot block\"; a portion of the BIOS which runs first and must be updated separately. This code verifies if the rest of the BIOS is intact (using hash checksums or other methods) before transferring control to it. If the boot block detects any corruption in the main BIOS, it will typically warn the user that a recovery process must be initiated by booting from removable media (floppy, CD or USB flash drive) so the user can try flashing the BIOS again. Some motherboards have a \"backup\" BIOS (sometimes referred as DualBIOS) to recover from BIOS corruptions, and they use a special PLC to do BIOS recovery from BIOS corruptions.\nThere are at least five known viruses that attack the BIOS, two of which were for demonstration purposes. The first one found in the wild was \"Mebromi\", targeting Chinese users.\nThe first BIOS virus was BIOS Meningitis, which instead of erasing BIOS chips it infected them. BIOS Meningitis was relatively harmless, compared to a virus like CIH.\nThe second BIOS virus was CIH, also known as the \"Chernobyl Virus\", which was able to erase flash ROM BIOS content on compatible chipsets. CIH appeared in mid-1998 and became active in April 1999. Often, infected computers could no longer boot, and people had to remove the flash ROM IC from the motherboard and reprogram it. CIH targeted the then-widespread Intel i430TX motherboard chipset and took advantage of the fact that the Windows 9x operating systems, also widespread at the time, allowed direct hardware access to all programs.\nModern systems are not vulnerable to CIH because of a variety of chipsets being used which are incompatible with the Intel i430TX chipset, and also other flash ROM IC types. There is also extra protection from accidental BIOS rewrites in the form of boot blocks which are protected from accidental overwrite or dual BIOS equipped systems which may, in the event of a crash, use a backup BIOS. Also, all modern operating systems such as FreeBSD, Linux, macOS, Windows NT-based Windows OS like Windows 2000, Windows XP and newer, do not allow user-mode programs to have direct hardware access using a hardware abstraction layer.\nAs a result, as of 2008, CIH has become essentially harmless, at worst causing annoyance by infecting executable files and triggering antivirus software. Other BIOS viruses remain possible, however; since most Windows home users without Windows Vista/7's UAC run all applications with administrative privileges, a modern CIH-like virus could in principle still gain access to hardware without first using an exploit. The operating system OpenBSD prevents all users from having this access and the grsecurity patch for the Linux kernel also prevents this direct hardware access by default, the difference being an attacker requiring a much more difficult kernel level exploit or reboot of the machine.\nThe third BIOS virus was a technique presented by John Heasman, principal security consultant for UK-based Next-Generation Security Software. In 2006, at the Black Hat Security Conference, he showed how to elevate privileges and read physical memory, using malicious procedures that replaced normal ACPI functions stored in flash memory.\nThe fourth BIOS virus was a technique called \"Persistent BIOS infection.\" It appeared in 2009 at the CanSecWest Security Conference in Vancouver, and at the SyScan Security Conference in Singapore. Researchers Anibal Sacco and Alfredo Ortega, from Core Security Technologies, demonstrated how to insert malicious code into the decompression routines in the BIOS, allowing for nearly full control of the PC at start-up, even before the operating system is booted. The proof-of-concept does not exploit a flaw in the BIOS implementation, but only involves the normal BIOS flashing procedures. Thus, it requires physical access to the machine, or for the user to be root. Despite these requirements, Ortega underlined the profound implications of his and Sacco's discovery: \"We can patch a driver to drop a fully working rootkit. We even have a little code that can remove or disable antivirus.\"\nMebromi is a trojan which targets computers with AwardBIOS, Microsoft Windows, and antivirus software from two Chinese companies: Rising Antivirus and Jiangmin KV Antivirus. Mebromi installs a rootkit which infects the Master boot record.\nIn a December 2013 interview with \"60 Minutes\", Deborah Plunkett, Information Assurance Director for the US National Security Agency claimed the NSA had uncovered and thwarted a possible BIOS attack by a foreign nation state, targeting the US financial system. The program cited anonymous sources alleging it was a Chinese plot. However follow-up articles in \"The Guardian,\" \"The Atlantic,\" \"Wired\" and \"The Register\" refuted the NSA's claims.\nNewer Intel platforms have Intel Boot Guard (IBG) technology enabled, this technology will check the BIOS digital signature at startup, and the IBG public key is fused into the PCH. End users can't disable this function.\nAlternatives and successors.\nUnified Extensible Firmware Interface (UEFI) supplements the BIOS in many new machines. Initially written for the Intel Itanium architecture, UEFI is now available for x86 and Arm platforms; the specification development is driven by the Unified EFI Forum, an industry special interest group. EFI booting has been supported in only Microsoft Windows versions supporting GPT, the Linux kernel 2.6.1 and later, and macOS on Intel-based Macs. As of 2014[ [update]], new PC hardware predominantly ships with UEFI firmware. The architecture of the rootkit safeguard can also prevent the system from running the user's own software changes, which makes UEFI controversial as a legacy BIOS replacement in the open hardware community. Also, Windows 11 requires UEFI to boot, with the exception of IoT Enterprise editions of Windows 11. UEFI is required for devices shipping with Windows 8 and above.\nAfter the popularity of UEFI in 2010s, the older BIOS that supported BIOS interrupt calls was renamed to \"legacy BIOS\".\nOther alternatives to the functionality of the \"Legacy BIOS\" in the x86 world include coreboot and libreboot.\nSome servers and workstations use a platform-independent Open Firmware (IEEE-1275) based on the Forth programming language; it is included with Sun's SPARC computers, IBM's RS/6000 line, and other PowerPC systems such as the CHRP motherboards, along with the x86-based OLPC XO-1.\nAs of at least 2015, Apple has removed legacy BIOS support from the UEFI monitor in Intel-based Macs. As such, the BIOS utility no longer supports the legacy option, and prints \"Legacy mode not supported on this system\".\nIn 2017, Intel announced that it would remove legacy BIOS support by 2020. Since 2019, new Intel platform OEM PCs no longer support the legacy option.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "4474", "revid": "31861199", "url": "https://en.wikipedia.org/wiki?curid=4474", "title": "Bose\u2013Einstein condensate", "text": "State of matter\nIn condensed matter physics, a Bose\u2013Einstein condensate (BEC) is a state of matter that is typically formed when a gas of bosons at very low densities is cooled to temperatures very close to absolute zero, i.e. . Under such conditions, a large fraction of bosons occupy the lowest quantum state, at which microscopic quantum-mechanical phenomena, particularly wavefunction interference, become apparent macroscopically.\nMore generally, \"condensation\" refers to the appearance of macroscopic occupation of one or several states: for example, in BCS theory, a superconductor is a condensate of Cooper pairs. As such, condensation can be associated with phase transition, and the macroscopic occupation of the state is the order parameter.\nBose\u2013Einstein condensates were first predicted, generally, in 1924\u20131925 by Albert Einstein, crediting a pioneering paper by Satyendra Nath Bose on the new field now known as quantum statistics. In 1995, the Bose\u2013Einstein condensate was created by Eric Cornell and Carl Wieman of the University of Colorado Boulder using rubidium atoms. Later that year, Wolfgang Ketterle of MIT produced a BEC using sodium atoms. In 2001 Cornell, Wieman, and Ketterle shared the Nobel Prize in Physics \"for the achievement of Bose\u2013Einstein condensation in dilute gases of alkali atoms, and for early fundamental studies of the properties of the condensates\".\nHistory.\nBose first sent a paper to Einstein on the quantum statistics of light quanta (now called photons), in which he derived Planck's quantum radiation law without any reference to classical physics. Einstein was impressed, translated the paper himself from English to German and submitted it for Bose to the \"Zeitschrift f\u00fcr Physik\", which published it in 1924. Einstein's manuscript, once believed to be lost, was found in a library at Leiden University in 2005. Einstein then extended Bose's ideas to matter in two other papers. The result of their efforts is the concept of a Bose gas, governed by Bose\u2013Einstein statistics, which describes the statistical distribution of identical particles with integer spin, now called bosons. Bosons are allowed to share a quantum state. Einstein proposed that cooling bosonic atoms to a very low temperature would cause them to fall (or \"condense\") into the lowest accessible quantum state, resulting in a new form of matter. Bosons include the photon, polaritons, magnons, some atoms and molecules (depending on the number of nucleons, see #Isotopes) such as atomic hydrogen, helium-4, lithium-7, rubidium-87 or strontium-84.\nIn 1938, Fritz London proposed the BEC as a mechanism for superfluidity in helium-4 and superconductivity.\nThe quest to produce a Bose\u2013Einstein condensate in the laboratory was stimulated by a paper published in 1976 by two program directors at the National Science Foundation (William Stwalley and Lewis Nosanow), proposing to use spin-polarized atomic hydrogen to produce a gaseous BEC. This led to the immediate pursuit of the idea by four independent research groups; these were led by Isaac Silvera (University of Amsterdam), Walter Hardy (University of British Columbia), Thomas Greytak (Massachusetts Institute of Technology) and David Lee (Cornell University). However, cooling atomic hydrogen turned out to be technically difficult, and Bose-Einstein condensation of atomic hydrogen was only realized in 1998.\nOn 5 June 1995, the first gaseous condensate was produced by Eric Cornell and Carl Wieman at the University of Colorado at Boulder NIST\u2013JILA lab, in a gas of rubidium atoms cooled to 170\u00a0nanokelvins (nK). Shortly thereafter, Wolfgang Ketterle at MIT produced a Bose\u2013Einstein Condensate in a gas of sodium atoms. For their achievements Cornell, Wieman, and Ketterle received the 2001 Nobel Prize in Physics. Bose-Einstein condensation of alkali gases is easier because they can be pre-cooled with laser cooling techniques, unlike atomic hydrogen at the time, which give a significant head start when performing the final forced evaporative cooling to cross the condensation threshold. These early studies founded the field of ultracold atoms, and hundreds of research groups around the world now routinely produce BECs of dilute atomic vapors in their labs.\nSince 1995, many other atomic species have been condensed (see #Isotopes), and BECs have also been realized using molecules, polaritons, and other quasi-particles. BECs of photons can be made, for example, in dye microcavites with wavelength-scale mirror separation, forming a two-dimensional harmonically confined photon gas with tunable chemical potential. BEC of plasmonic quasiparticles (plasmon-exciton polaritons) has been realized in periodic arrays of metal nanoparticles overlaid with dye molecules, exhibiting ultrafast sub-picosecond dynamics and long-range correlations.\nCritical temperature.\nThis transition to BEC occurs below a critical temperature, which for a uniform three-dimensional gas consisting of non-interacting particles with no apparent internal degrees of freedom is given by\n formula_1\nwhere:\n formula_2 is the critical temperature,\n formula_3 is the particle density,\n formula_4 is the mass per boson,\n formula_5 is the reduced Planck constant,\n formula_6 is the Boltzmann constant,\n formula_7 is the Riemann zeta function (formula_8).\nInteractions shift the value, and the corrections can be calculated by mean-field theory.\nThis formula is derived from finding the gas degeneracy in the Bose gas using Bose\u2013Einstein statistics.\nThe critical temperature depends on the density. A more concise and experimentally relevant condition involves the phase-space density formula_9, where\n formula_10\nis the thermal de Broglie wavelength. It is a dimensionless quantity. The transition to BEC occurs when the phase-space density is greater than critical value:\n formula_11\nin 3D uniform space. This is equivalent to the above condition on the temperature. In a 3D harmonic potential, the critical value is instead\n formula_12\nwhere formula_3 has to be understood as the peak density.\nDerivation.\nIdeal Bose gas.\nFor an ideal Bose gas we have the equation of state\n formula_14\nwhere formula_15 is the per-particle volume, formula_16 is the thermal wavelength, formula_17 is the fugacity, and\n formula_18\nIt is noticeable that formula_19 is a monotonically growing function of formula_17 in formula_21, which are the only values for which the series converge.\nRecognizing that the second term on the right-hand side contains the expression for the average occupation number of the fundamental state formula_22, the equation of state can be rewritten as\n formula_23\nBecause the left term on the second equation must always be positive, formula_24, and because formula_25, a stronger condition is\n formula_26\nwhich defines a transition between a gas phase and a condensed phase. On the critical region it is possible to define a critical temperature and thermal wavelength:\n formula_27\n formula_28\nrecovering the value indicated on the previous section. The critical values are such that if formula_29 or formula_30, we are in the presence of a Bose\u2013Einstein condensate.\nUnderstanding what happens with the fraction of particles on the fundamental level is crucial. As so, write the equation of state for formula_31, obtaining\n formula_32 and equivalently formula_33\nSo, if formula_34, the fraction formula_35, and if formula_36, the fraction formula_37. At temperatures near to absolute 0, particles tend to condense in the fundamental state, which is the state with momentum formula_38.\nExperimental observation.\nSuperfluid helium-4.\nIn 1938, Pyotr Kapitsa, John Allen and Don Misener discovered that helium-4 became a new kind of fluid, now known as a superfluid, at temperatures less than 2.17\u00a0K (the lambda point). Superfluid helium has many unusual properties, including zero viscosity (the ability to flow without dissipating energy) and the existence of quantized vortices. It was quickly believed that the superfluidity was due to partial Bose\u2013Einstein condensation of the liquid. In fact, many properties of superfluid helium also appear in gaseous condensates created by Cornell, Wieman and Ketterle (see below). Superfluid helium-4 is a liquid rather than a gas, which means that the interactions between the atoms are relatively strong; the original theory of Bose\u2013Einstein condensation must be heavily modified in order to describe it. Bose\u2013Einstein condensation remains, however, fundamental to the superfluid properties of helium-4. Note that helium-3, a fermion, also enters a superfluid phase (at a much lower temperature) which can be explained by the formation of bosonic Cooper pairs of two atoms (see also fermionic condensate).\nDilute atomic gases.\nThe first \"pure\" Bose\u2013Einstein condensate was created by Eric Cornell, Carl Wieman, and co-workers at JILA on 5 June 1995. They cooled a dilute vapor of approximately two thousand rubidium-87 atoms to below 170\u00a0nK using a combination of laser cooling (a technique that won its inventors Steven Chu, Claude Cohen-Tannoudji, and William D. Phillips the 1997 Nobel Prize in Physics) and magnetic evaporative cooling. About four months later, an independent effort led by Wolfgang Ketterle at MIT condensed sodium-23. Ketterle's condensate had a hundred times more atoms, allowing important results such as the observation of quantum mechanical interference between two different condensates. Cornell, Wieman and Ketterle won the 2001 Nobel Prize in Physics for their achievements.\nA group led by Randall Hulet at Rice University announced a condensate of lithium atoms only one month following the JILA work. Lithium has attractive interactions, causing the condensate to be unstable and collapse for all but a few atoms. Hulet's team subsequently showed the condensate could be stabilized by confinement quantum pressure for up to about 1000 atoms. Various isotopes have since been condensed.\nVelocity-distribution data graph.\nIn the image accompanying this article, the velocity-distribution data indicates the formation of a Bose\u2013Einstein condensate out of a gas of rubidium atoms. The false colors indicate the number of atoms at each velocity, with red being the fewest and white being the most. The areas appearing white and light blue are at the lowest velocities. The peak is not infinitely narrow because of the Heisenberg uncertainty principle: spatially confined atoms have a minimum width velocity distribution. This width is given by the curvature of the magnetic potential in the given direction. More tightly confined directions have bigger widths in the ballistic velocity distribution. This anisotropy of the peak on the right is a purely quantum-mechanical effect and does not exist in the thermal distribution on the left.\nQuasiparticles.\nBose\u2013Einstein condensation also applies to quasiparticles in solids. Magnons, excitons, and polaritons have integer spin which means they are bosons that can form condensates.\nMagnons, electron spin waves, can be controlled by a magnetic field. Densities from the limit of a dilute gas to a strongly interacting Bose liquid are possible. Magnetic ordering is the analog of superfluidity. In 1999 condensation was demonstrated in antiferromagnetic TlCuCl3, at temperatures as great as 14\u00a0K. The high transition temperature (relative to atomic gases) is due to the magnons' small mass (near that of an electron) and greater achievable density. In 2006, condensation in a ferromagnetic yttrium-iron-garnet thin film was seen even at room temperature, with optical pumping.\nExcitons, electron\u2013hole pairs, were predicted to condense at low temperature and high density by Boer et al., in 1961. Bilayer system experiments first demonstrated condensation in 2003, by Hall voltage disappearance. Fast optical exciton creation was used to form condensates in sub-kelvin Cu2O in 2005 on.\nPolariton condensation was first detected for exciton-polaritons in a quantum well microcavity kept at 5\u00a0K. Quasiparticle BECs have been achieved at room-temperature, for example, in microcavity-coupled organic semiconductors and plasmon-exciton polaritons in periodic arrays of metal nanoparticles coupled to dye molecules.\nIn zero gravity.\nIn June 2020, the Cold Atom Laboratory experiment on board the International Space Station successfully created a BEC of rubidium atoms and observed them for over a second in free-fall. Although initially just a proof of function, early results showed that, in the microgravity environment of the ISS, about half of the atoms formed into a magnetically insensitive halo-like cloud around the main body of the BEC.\nModels.\nBose Einstein's non-interacting gas.\nConsider a collection of \"N\" non-interacting particles, which can each be in one of two quantum states, formula_39 and formula_40. If the two states are equal in energy, each different configuration is equally likely.\nIf we can tell which particle is which, there are formula_41 different configurations, since each particle can be in formula_39 or formula_40 independently. In almost all of the configurations, about half the particles are in formula_39 and the other half in formula_40. The balance is a statistical effect: the number of configurations is largest when the particles are divided equally.\nIf the particles are indistinguishable, however, there are only formula_46 different configurations. If there are formula_47 particles in state formula_40, there are formula_49 particles in state formula_39. Whether any particular particle is in state formula_39 or in state formula_40 cannot be determined, so each value of formula_47 determines a unique quantum state for the whole system.\nSuppose now that the energy of state formula_40 is slightly greater than the energy of state formula_39 by an amount formula_56. At temperature formula_57, a particle will have a lesser probability to be in state formula_40 by formula_59. In the distinguishable case, the particle distribution will be biased slightly towards state formula_39. But in the indistinguishable case, since there is no statistical pressure toward equal numbers, the most-likely outcome is that most of the particles will collapse into state formula_39.\nIn the distinguishable case, for large \"N\", the fraction in state formula_39 can be computed. It is the same as flipping a coin with probability proportional to formula_63 to land tails.\nIn the indistinguishable case, each value of formula_47 is a single state, which has its own separate Boltzmann probability. So the probability distribution is exponential:\nformula_65\nFor large formula_66, the normalization constant formula_67 is formula_68. The expected total number of particles not in the lowest energy state, in the limit that formula_69, is equal to\n formula_70\nIt does not grow when \"N\" is large; it just approaches a constant. This will be a negligible fraction of the total number of particles. So a collection of enough Bose particles in thermal equilibrium will mostly be in the ground state, with only a few in any excited state, no matter how small the energy difference.\nConsider now a gas of particles, which can be in different momentum states labeled formula_71. If the number of particles is less than the number of thermally accessible states, for high temperatures and low densities, the particles will all be in different states. In this limit, the gas is classical. As the density increases or the temperature decreases, the number of accessible states per particle becomes smaller, and at some point, more particles will be forced into a single state than the maximum allowed for that state by statistical weighting. From this point on, any extra particle added will go into the ground state.\nTo calculate the transition temperature at any density, integrate, over all momentum states, the expression for maximum number of excited particles, formula_72:\nformula_73\nformula_74\nWhen the integral (also known as Bose\u2013Einstein integral) is evaluated with factors of formula_75 and formula_5 restored by dimensional analysis, it gives the critical temperature formula of the preceding section. Therefore, this integral defines the critical temperature and particle number corresponding to the conditions of negligible chemical potential formula_77. In Bose\u2013Einstein statistics distribution, formula_77 is actually still nonzero for BECs; however, formula_77 is less than the ground state energy. Except when specifically talking about the ground state, formula_77 can be approximated for most energy or momentum states as\u00a0formula_81.\nBogoliubov theory for weakly interacting gas.\nNikolay Bogolyubov considered perturbations on the limit of dilute gas, finding a finite pressure at zero temperature and positive chemical potential. This leads to corrections for the ground state. The Bogoliubov state has pressure formula_82: formula_83.\nThe weakly interacting Bose gas can be converted to a system of non-interacting particles with a dispersion law.\nGross\u2013Pitaevskii equation.\nIn some simplest cases, the state of condensed particles can be described with a nonlinear Schr\u00f6dinger equation, also known as Gross\u2013Pitaevskii or Ginzburg\u2013Landau equation. The validity of this approach is actually limited to the case of ultracold temperatures, which fits well for the most alkali atoms experiments.\nThis approach originates from the assumption that the state of the BEC can be described by the unique wavefunction of the condensate formula_84. For a system of this nature, formula_85 is interpreted as the particle density, so the total number of atoms is formula_86\nProvided essentially all atoms are in the condensate (that is, have condensed to the ground state), and treating the bosons using mean-field theory, the energy (E) associated with the state formula_84 is:\nformula_88\nMinimizing this energy with respect to infinitesimal variations in formula_84, and holding the number of atoms constant, yields the Gross\u2013Pitaevski equation (GPE) (also a non-linear Schr\u00f6dinger equation):\nformula_90\nwhere:\nIn the case of zero external potential, the dispersion law of interacting Bose\u2013Einstein-condensed particles is given by so-called Bogoliubov spectrum (for formula_91):\nformula_92\nThe Gross-Pitaevskii equation (GPE) provides a relatively good description of the behavior of atomic BEC's. However, GPE does not take into account the temperature dependence of dynamical variables, and is therefore valid only for formula_91.\nIt is not applicable, for example, for the condensates of excitons, magnons and photons, where the critical temperature is comparable to room temperature.\nNumerical solution.\nThe Gross-Pitaevskii equation is a partial differential equation in space and time variables. Usually it does not have analytic solution and\ndifferent numerical methods, such as split-step\nCrank\u2013Nicolson\nand Fourier spectral methods, are used for its solution. There are different Fortran and C programs for its solution for contact interaction\nand long-range dipolar interaction which can be freely used.\nWeaknesses of Gross\u2013Pitaevskii model.\nThe Gross\u2013Pitaevskii model of BEC is a physical approximation valid for certain classes of BECs. By construction, the GPE uses the following simplifications: it assumes that interactions between condensate particles are of the contact two-body type and also neglects anomalous contributions to self-energy. These assumptions are suitable mostly for the dilute three-dimensional condensates. If one relaxes any of these assumptions, the equation for the condensate wavefunction acquires the terms containing higher-order powers of the wavefunction. Moreover, for some physical systems the amount of such terms turns out to be infinite, therefore, the equation becomes essentially non-polynomial. The examples where this could happen are the Bose\u2013Fermi composite condensates, effectively lower-dimensional condensates, and dense condensates and superfluid clusters and droplets. It is found that one has to go beyond the Gross-Pitaevskii equation. For example, the logarithmic term formula_94 found in the Logarithmic Schr\u00f6dinger equation must be added to the Gross-Pitaevskii equation along with a Ginzburg\u2013Sobyanin contribution to correctly determine that the speed of sound scales as the cubic root of pressure for Helium-4 at very low temperatures in close agreement with experiment.\nOther.\nHowever, it is clear that in a general case the behaviour of Bose\u2013Einstein condensate can be described by coupled evolution equations for condensate density, superfluid velocity and distribution function of elementary excitations. This problem was solved in 1977 by Peletminskii et al. in microscopical approach. The Peletminskii equations are valid for any finite temperatures below the critical point. Years after, in 1985, Kirkpatrick and Dorfman obtained similar equations using another microscopical approach. The Peletminskii equations also reproduce Khalatnikov hydrodynamical equations for superfluid as a limiting case.\nSuperfluidity of BEC and Landau criterion.\nThe phenomena of superfluidity of a Bose gas and superconductivity of a strongly-correlated Fermi gas (a gas of Cooper pairs) are tightly connected to Bose\u2013Einstein condensation. Under corresponding conditions, below the temperature of phase transition, these phenomena were observed in helium-4 and different classes of superconductors. In this sense, the superconductivity is often called the superfluidity of Fermi gas. In the simplest form, the origin of superfluidity can be seen from the weakly interacting bosons model.\nPeculiar properties.\nQuantized vortices.\nAs in many other systems, vortices can exist in BECs.\nVortices can be created, for example, by \"stirring\" the condensate with lasers,\nrotating the confining trap,\nor by rapid cooling across the phase transition.\nThe vortex created will be a quantum vortex with core shape determined by the interactions. Fluid circulation around any point is quantized due to the single-valued nature of the order BEC order parameter or wavefunction, that can be written in the form formula_95 where formula_96 and formula_97 are as in the cylindrical coordinate system, and formula_98 is the angular quantum number (a.k.a. the \"charge\" of the vortex). Since the energy of a vortex is proportional to the square of its angular momentum, in trivial topology only formula_99 vortices can exist in the steady state; Higher-charge vortices will have a tendency to split into formula_99 vortices, if allowed by the topology of the geometry.\nAn axially symmetric (for instance, harmonic) confining potential is commonly used for the study of vortices in BEC. To determine formula_101, the energy of formula_84 must be minimized, according to the constraint formula_95. This is usually done computationally, however, in a uniform medium, the following analytic form demonstrates the correct behavior, and is a good approximation:\nformula_104\nHere, formula_3 is the density far from the vortex and formula_106, where formula_107 is the healing length of the condensate.\nA singly charged vortex (formula_99) is in the ground state, with its energy formula_109 given by\nformula_110\nwhere formula_111\u00a0is\u00a0the farthest distance from the vortices considered.(To obtain an energy which is well defined it is necessary to include this boundary formula_112.)\nFor multiply charged vortices (formula_113) the energy is approximated by\nformula_114\nwhich is greater than that of formula_98 singly charged vortices, indicating that these multiply charged vortices are unstable to decay. Research has, however, indicated they are metastable states, so may have relatively long lifetimes.\nClosely related to the creation of vortices in BECs is the generation of so-called dark solitons in one-dimensional BECs. These topological objects feature a phase gradient across their nodal plane, which stabilizes their shape even in propagation and interaction. Although solitons carry no charge and are thus prone to decay, relatively long-lived dark solitons have been produced and studied extensively.\nAttractive interactions.\nExperiments led by Randall Hulet at Rice University from 1995 through 2000 showed that lithium condensates with attractive interactions could stably exist up to a critical atom number. Quench cooling the gas, they observed the condensate to grow, then subsequently collapse as the attraction overwhelmed the zero-point energy of the confining potential, in a burst reminiscent of a supernova, with an explosion preceded by an implosion.\nFurther work on attractive condensates was performed in 2000 by the JILA team, of Cornell, Wieman and coworkers. Their instrumentation now had better control so they used naturally \"attracting\" atoms of rubidium-85 (having negative atom\u2013atom scattering length). Through Feshbach resonance involving a sweep of the magnetic field causing spin flip collisions, they lowered the characteristic, discrete energies at which rubidium bonds, making their Rb-85 atoms repulsive and creating a stable condensate. The reversible flip from attraction to repulsion stems from quantum interference among wave-like condensate atoms.\nWhen the JILA team raised the magnetic field strength further, the condensate suddenly reverted to attraction, imploded and shrank beyond detection, then exploded, expelling about two-thirds of its 10,000 atoms. About half of the atoms in the condensate seemed to have disappeared from the experiment altogether, not seen in the cold remnant or expanding gas cloud. Carl Wieman explained that under current atomic theory this characteristic of Bose\u2013Einstein condensate could not be explained because the energy state of an atom near absolute zero should not be enough to cause an implosion; however, subsequent mean-field theories have been proposed to explain it. Most likely they formed molecules of two rubidium atoms; energy gained by this bond imparts velocity sufficient to leave the trap without being detected.\nThe process of creation of molecular Bose condensate during the sweep of the magnetic field throughout the Feshbach resonance, as well as the reverse process, are described by the exactly solvable model that can explain many experimental observations.\nCurrent research.\n&lt;templatestyles src=\"Unsolved/styles.css\" /&gt;\nUnsolved problem in physics\nHow do we rigorously prove the existence of Bose\u2013Einstein condensates for generally interacting systems?\nMore unsolved problems in physics\nCompared to more commonly encountered states of matter, Bose\u2013Einstein condensates are extremely fragile. The slightest interaction with the external environment can be enough to warm them past the condensation threshold, eliminating their interesting properties and forming a normal gas.\nNevertheless, they have proven useful in exploring a wide range of questions in fundamental physics, and the years since the initial discoveries by the JILA and MIT groups have seen an increase in experimental and theoretical activity.\nBose\u2013Einstein condensates composed of a wide range of isotopes have been produced; see below.\nFundamental research.\nExamples include experiments that have demonstrated interference between condensates due to wave\u2013particle duality, the study of superfluidity and quantized vortices, the creation of bright matter wave solitons from Bose condensates confined to one dimension, and the slowing of light pulses to very low speeds using electromagnetically induced transparency. Vortices in Bose\u2013Einstein condensates are also currently the subject of analogue gravity research, studying the possibility of modeling black holes and their related phenomena in such environments in the laboratory.\nExperimenters have also realized \"optical lattices\", where the interference pattern from overlapping lasers provides a periodic potential. These are used to explore the transition between a superfluid and a Mott insulator.\nThey are also useful in studying Bose\u2013Einstein condensation in fewer than three dimensions, for example the Lieb\u2013Liniger model (an the limit of strong interactions, the Tonks\u2013Girardeau gas) in 1D and the Berezinskii\u2013Kosterlitz\u2013Thouless transition in 2D. Indeed, a deep optical lattice allows the experimentalist to freeze the motion of the particles along one or two directions, effectively eliminating one or two dimensions from the system.\nFurther, the sensitivity of the pinning transition of strongly interacting bosons confined in a shallow one-dimensional optical lattice originally observed by Haller has been explored via a tweaking of the primary optical lattice by a secondary weaker one. Thus for a resulting weak bichromatic optical lattice, it has been found that the pinning transition is robust against the\nintroduction of the weaker secondary optical lattice.\nStudies of vortices in nonuniform Bose\u2013Einstein condensates as well as excitations of these systems by the application of moving repulsive or attractive obstacles, have also been undertaken. Within this context, the conditions for order and chaos in the dynamics of a trapped Bose\u2013Einstein condensate have been explored by the application of moving blue and red-detuned laser beams (hitting frequencies slightly above and below the resonance frequency, respectively) via the time-dependent Gross-Pitaevskii equation.\nApplications.\nIn 1999, Danish physicist Lene Hau led a team from Harvard University which slowed a beam of light to about 17 meters per second using a superfluid. Hau and her associates have since made a group of condensate atoms recoil from a light pulse such that they recorded the light's phase and amplitude, recovered by a second nearby condensate, in what they term \"slow-light-mediated atomic matter-wave amplification\" using Bose\u2013Einstein condensates.\nAnother current research interest is the creation of Bose\u2013Einstein condensates in microgravity in order to use its properties for high precision atom interferometry. The first demonstration of a BEC in weightlessness was achieved in 2008 at a drop tower in Bremen, Germany by a consortium of researchers led by Ernst M. Rasel from Leibniz University Hannover. The same team demonstrated in 2017 the first creation of a Bose\u2013Einstein condensate in space and it is also the subject of two upcoming experiments on the International Space Station.\nResearchers in the new field of atomtronics use the properties of Bose\u2013Einstein condensates in the emerging quantum technology of matter-wave circuits.\nIn 1970, BECs were proposed by Emmanuel David Tannenbaum for anti-stealth technology.\nIsotopes.\nBose-Einstein condensation has mainly been observed on alkaline atoms, some of which have collisional properties particularly suitable for evaporative cooling in traps, and which were the first to be laser-cooled. As of 2021, using ultra-low temperatures of or below, Bose\u2013Einstein condensates had been obtained for a multitude of isotopes with more or less ease, mainly of alkali metal, alkaline earth metal, and lanthanide atoms ([&lt;noinclude /&gt;[lithium-7|Li]&lt;noinclude /&gt;], [&lt;noinclude /&gt;[sodium-23|Na]&lt;noinclude /&gt;], [&lt;noinclude /&gt;[potassium-39|K]&lt;noinclude /&gt;], [&lt;noinclude /&gt;[potassium-41|K]&lt;noinclude /&gt;], [&lt;noinclude /&gt;[rubidium-85|Rb]&lt;noinclude /&gt;], [&lt;noinclude /&gt;[rubidium-87|Rb]&lt;noinclude /&gt;], [&lt;noinclude /&gt;[caesium-133|Cs]&lt;noinclude /&gt;], [&lt;noinclude /&gt;[chromium-52|Cr]&lt;noinclude /&gt;], [&lt;noinclude /&gt;[calcium-40|Ca]&lt;noinclude /&gt;], [&lt;noinclude /&gt;[strontium-84|Sr]&lt;noinclude /&gt;], [&lt;noinclude /&gt;[strontium-86|Sr]&lt;noinclude /&gt;], [&lt;noinclude /&gt;[strontium-88|Sr]&lt;noinclude /&gt;], [&lt;noinclude /&gt;[ytterbium-170|Yb]&lt;noinclude /&gt;], [&lt;noinclude /&gt;[ytterbium-174|Yb]&lt;noinclude /&gt;], [&lt;noinclude /&gt;[ytterbium-176|Yb]&lt;noinclude /&gt;], [&lt;noinclude /&gt;[dysprosium-164|Dy]&lt;noinclude /&gt;], [&lt;noinclude /&gt;[erbium-168|Er]&lt;noinclude /&gt;], [&lt;noinclude /&gt;[thulium-169|Tm]&lt;noinclude /&gt;], and metastable [&lt;noinclude /&gt;[helium-4|He]&lt;noinclude /&gt;] (orthohelium)). Research was finally successful in atomic hydrogen with the aid of the newly developed method of 'evaporative cooling'.\nIn contrast, the superfluid state of [&lt;noinclude /&gt;[helium-4|He]&lt;noinclude /&gt;] below is differs significantly from dilute degenerate atomic gases because the interaction between the atoms is strong. Only 8% of atoms are in the condensed fraction near absolute zero, rather than near 100% of a weakly interacting BEC.\nThe bosonic behavior of some of these alkaline gases appears odd at first sight, because their nuclei have half-integer total spin. It arises from the interplay of electronic and nuclear spins: at ultra-low temperatures and corresponding excitation energies, the half-integer total spin of the electronic shell (one outer electron) and half-integer total spin of the nucleus are coupled by a very weak hyperfine interaction. The total spin of the atom, arising from this coupling, is an integer value. Conversely, alkali isotopes which have an integer nuclear spin (such as [&lt;noinclude /&gt;[lithium-6|Li]&lt;noinclude /&gt;] and [&lt;noinclude /&gt;[potassium-40|K]&lt;noinclude /&gt;]) are fermions and can form degenerate Fermi gases, also called \"Fermi condensates\".\nCooling fermions to extremely low temperatures has created degenerate gases, subject to the Pauli exclusion principle. To exhibit Bose\u2013Einstein condensation, the fermions must \"pair up\" to form bosonic compound particles (e.g. molecules or Cooper pairs). The first molecular condensates were created in November 2003 by the groups of Rudolf Grimm at the University of Innsbruck, Deborah S. Jin at the University of Colorado at Boulder and Wolfgang Ketterle at MIT. Jin quickly went on to create the first fermionic condensate, working with the same system but outside the molecular regime.\nContinuous Bose\u2013Einstein condensation.\nLimitations of evaporative cooling have restricted atomic BECs to \"pulsed\" operation, involving a highly inefficient duty cycle that discards more than 99% of atoms to reach BEC. Achieving continuous BEC has been a major open problem of experimental BEC research, driven by the same motivations as continuous optical laser development: high flux, high coherence matter waves produced continuously would enable new sensing applications.\nContinuous BEC was achieved for the first time in 2022 with [&lt;noinclude /&gt;[strontium-84|Sr]&lt;noinclude /&gt;].\nIn solid state physics.\nIn 2020, researchers reported the development of superconducting BEC and that there appears to be a \"smooth transition between\" BEC and Bardeen\u2013Cooper\u2013Shrieffer regimes.\nDark matter.\nP. Sikivie and Q. Yang showed that cold dark matter axions would form a Bose\u2013Einstein condensate by thermalisation because of gravitational self-interactions. Axions have not yet been confirmed to exist. However the important search for them has been greatly enhanced with the completion of upgrades to the Axion Dark Matter Experiment (ADMX) at the University of Washington in early 2018.\nIn 2014, a potential dibaryon was detected at the J\u00fclich Research Center at about 2380 MeV. The center claimed that the measurements confirm results from 2011, via a more replicable method. The particle existed for 10\u221223 seconds and was named d*(2380). This particle is hypothesized to consist of three up quarks and three down quarks. It is theorized that groups of d* (d-stars) could form Bose\u2013Einstein condensates due to prevailing low temperatures in the early universe, and that BECs made of such hexaquarks with trapped electrons could behave like dark matter.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "4475", "revid": "7611264", "url": "https://en.wikipedia.org/wiki?curid=4475", "title": "B (programming language)", "text": "Procedural programming language\nB is a programming language developed at Bell Labs circa 1969 by Ken Thompson and Dennis Ritchie.\nThough often mythologized that B derived from BCPL, Thompson created B from a stripped down Fortran source. Thompson began with the letter Z and after each revision, he decremented the name, one letter toward A. When finished, he landed on B. After Ritchie ported B to another machine, Ritchie called it new B, a tongue-in-cheek reference to newbie. That porting let Ritchie add types and structs. Doing that necessitated a bump up revision of the name to C.. Later, when writing about C, Ritchie stated one could think of it like a BCPL and from that is the source of all origins confusion.\nB was designed for recursive, non-numeric, machine-independent applications, such as system and language software. It was a typeless language, with the only data type being the underlying machine's natural memory word format, whatever that might be. Depending on the context, the word was treated either as an integer or a memory address.\nAs machines with ASCII processing became common, notably the DEC PDP-11 that arrived at Bell Labs, support for character data stuffed in memory words became important. The typeless nature of the language was seen as a disadvantage, which led Thompson and Ritchie to develop an expanded version of the language supporting new internal and user-defined types, which became the ubiquitous C programming language.\nHistory.\n&lt;templatestyles src=\"Rquote/styles.css\"/&gt;{ class=\"rquote pullquote float\" role=\"presentation\" style=\"display:table; border-collapse:collapse; border-style:none; float:; margin:0.5em 0.75em; width:33%; \"\nCirca 1969, Ken Thompson and later Dennis Ritchie developed B basing it mainly on the BCPL language Thompson used in the Multics project. B was essentially the BCPL system stripped of any component Thompson felt he could do without in order to make it fit within the memory capacity of the minicomputers of the time. The BCPL to B transition also included changes made to suit Thompson's preferences (mostly along the lines of reducing the number of non-whitespace characters in a typical program). Much of the typical ALGOL-like syntax of BCPL was rather heavily changed in this process. The assignment operator codice_1 reverted to the codice_2 of Rutishauser's Superplan, and the equality operator codice_2 was replaced by codice_4.\nThompson added \"two-address assignment operators\" using codice_5 syntax to add y to x (in C the operator is written codice_6). This syntax came from Douglas McIlroy's implementation of TMG, in which B's compiler was first implemented (and it came to TMG from ALGOL 68's codice_7 syntax). Thompson went further by inventing the increment and decrement operators (codice_8 and codice_9). Their prefix or postfix position determines whether the value is taken before or after alteration of the operand. This innovation was not in the earliest versions of B. According to Dennis Ritchie, people often assumed that they were created for the auto-increment and auto-decrement address modes of the DEC PDP-11, but this is historically impossible as the machine didn't exist when B was first developed.\nThe semicolon version of the for loop was borrowed by Ken Thompson from the work of Stephen Johnson.\nB is typeless, or more precisely has one data type: the computer word. Most operators (e.g. codice_10, codice_11, codice_12, codice_13) treated this as an integer, but others treated it as a memory address to be dereferenced. In many other ways it looked a lot like an early version of C. There are a few library functions, including some that vaguely resemble functions from the standard I/O library in C. \nIn Thompson's words: \"B and the old old C were very very similar languages except for all the types [in C]\".\nEarly implementations were for the DEC PDP-7 and PDP-11 minicomputers using early Unix, and Honeywell GE 645 36-bit mainframes running the operating system GCOS. The earliest PDP-7 implementations compiled to threaded code, and Ritchie wrote a compiler using TMG which produced machine code. In 1970 a PDP-11 was acquired and threaded code was used for the port; an assembler, &lt;samp style=\"padding-left:0.4em; padding-right:0.4em; color:var( --color-subtle, #666666); \" &gt;dc&lt;/samp&gt;, and the B language itself were written in B to bootstrap the computer. An early version of yacc was produced with this PDP-11 configuration. Ritchie took over maintenance during this period.\nThe typeless nature of B made sense on the Honeywell, PDP-7 and many older computers, but was a problem on the PDP-11 because it was difficult to elegantly access the character data type that the PDP-11 and most modern computers fully support. Starting in 1971 Ritchie made changes to the language while converting its compiler to produce machine code, most notably adding data typing for variables. During 1971 and 1972 B evolved into \"New B\" (NB) and then C.\nB is almost extinct, having been superseded by the C language. However, it continues to see use on GCOS mainframes (as of 2014[ [update]]) \nand on certain embedded systems (as of 2000[ [update]]) for a variety of reasons: limited hardware in small systems, extensive libraries, tooling, licensing cost issues, and simply being good enough for the job. The highly influential AberMUD was originally written in B.\nExamples.\nThe following examples are from the \"Users' Reference to B\" by Ken Thompson:\n/* The following function will print a non-negative number, n, to\n the base b, where 2&lt;=b&lt;=10. This routine uses the fact that\n in the ASCII character set, the digits 0 to 9 have sequential\n code values. */\nprintn(n,b) {\n extrn putchar;\n auto a;\n /* Wikipedia note: the auto keyword declares a variable with\n automatic storage (lifetime is function scope), not\n \"automatic typing\" as in C++11. */\n if(a=n/b) /* assignment, not test for equality */\n printn(a, b); /* recursive */\n putchar(n%b + '0');\n/* The following program will calculate the constant e-2 to about\n 4000 decimal digits, and print it 50 characters to the line in\n groups of 5 characters. The method is simple output conver-\n sion of the expansion\n 1/2! + 1/3! + ... = .111...\n where the bases of the digits are 2, 3, 4, ... */\nmain() {\n extrn putchar, n, v;\n auto i, c, col, a;\n i = col = 0;\n while(i&lt;n)\n v[i++] = 1;\n while(col&lt;2*n) {\n a = n+1;\n c = i = 0;\n while(i&lt;n) {\n c =+ v[i]*10;\n v[i++] = c%a;\n c =/ a--;\n putchar(c+'0');\n if(!(++col%5))\n putchar(col%50?' ':'*n');\n putchar('*n*n');\nv[2000];\nn 2000;\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "4476", "revid": "35936988", "url": "https://en.wikipedia.org/wiki?curid=4476", "title": "Beer\u2013Lambert law", "text": "Scientific law describing absorption of light\nThe Beer\u2013Bouguer\u2013Lambert (BBL) extinction law is an empirical relationship describing the attenuation in intensity of a radiation beam passing through a macroscopically homogenous medium with which it interacts. Formally, it states that the intensity of radiation decays exponentially in the absorbance of the medium, and that said absorbance is proportional to the length of beam passing through the medium, the concentration of interacting matter along that path, and a constant representing said matter's propensity to interact.\nThe extinction law's primary application is in chemical analysis, where it underlies the Beer\u2013Lambert law, commonly called Beer's law. Beer's law states that a beam of visible light passing through a chemical solution of fixed geometry experiences absorption proportional to the solute concentration. Other applications appear in physical optics, where it quantifies astronomical extinction and the absorption of photons, neutrons, or rarefied gases.\nForms of the BBL law date back to the mid-eighteenth century, but it only took its modern form during the early twentieth.\nHistory.\nThe first work towards the BBL law began with astronomical observations Pierre Bouguer performed in the early eighteenth century and published in 1729. Bouguer needed to compensate for the refraction of light by the earth's atmosphere, and found it necessary to measure the local height of the atmosphere. The latter, he sought to obtain through variations in the observed intensity of known stars. When calibrating this effect, Bouguer discovered that light intensity had an exponential dependence on length traveled through the atmosphere (in Bouguer's terms, a geometric progression).\nBouguer's work was then popularized in Johann Heinrich Lambert's \"Photometria\" in 1760. Lambert expressed the law, which states that the loss of light intensity when it propagates in a medium is directly proportional to intensity and path length, in a mathematical form quite similar to that used in modern physics. Lambert began by assuming that the intensity I of light traveling into an absorbing body would be given by the differential equation formula_1 which is compatible with Bouguer's observations. The constant of proportionality \u03bc was often termed the \"optical density\" of the body. As long as \u03bc is constant along a distance d, the exponential attenuation law, formula_2 follows from integration.\nIn 1852, August Beer noticed that colored solutions also appeared to exhibit a similar attenuation relation. In his analysis, Beer does not discuss Bouguer and Lambert's prior work, writing in his introduction that \"Concerning the absolute magnitude of the absorption that a particular ray of light suffers during its propagation through an absorbing medium, there is no information available.\" Beer may have omitted reference to Bouguer's work because there is a subtle physical difference between color absorption in solutions and astronomical contexts. Solutions are homogeneous and do not scatter light at common analytical wavelengths (ultraviolet, visible, or infrared), except at entry and exit. Thus light within a solution is reasonably approximated as due to absorption alone. In Bouguer's context, atmospheric dust or other inhomogeneities could also scatter light away from the detector. Modern texts combine the two laws because scattering and absorption have the same effect. Thus a scattering coefficient \u03bcs and an absorption coefficient \u03bca can be combined into a total extinction coefficient \u03bc \n \u03bcs + \u03bca.\nImportantly, Beer also seems to have conceptualized his result in terms of a given thickness' opacity, writing \"If \u03bb is the coefficient (fraction) of diminution, then this coefficient (fraction) will have the value \u03bb2 for double this thickness.\" Although this geometric progression is mathematically equivalent to the modern law, modern treatments instead emphasize the logarithm of \u03bb, which clarifies that concentration and path length have equivalent effects on the absorption. An early, possibly the first, modern formulation was given by Robert Luther and Andreas Nikolopulos in 1913.\nMathematical formulations.\nThere are several equivalent formulations of the BBL law, depending on the precise choice of measured quantities. All of them state that, provided that the physical state is held constant, the extinction process is linear in the intensity of radiation and amount of radiatively-active matter, a fact sometimes called the fundamental law of extinction. Many of them then connect the quantity of radiatively-active matter to a length traveled \u2113 and a concentration c or number density n. For concentrations expressed as moles per volume, the latter two are related by Avogadro's number: \"n\" \n \"N\"A\"c\".\nA collimated beam (directed radiation) with cross-sectional area S will encounter \"S\u2113n\" particles (on average) during its travel. However, not all of these particles interact with the beam. Propensity to interact is a material-dependent property, typically summarized in absorptivity &amp;varepsilon; or scattering cross-section \u03c3. These almost exhibit another Avogadro-type relationship: ln(10)\u03b5 \n \"N\"A\u03c3. The factor of ln(10) appears because physicists tend to use natural logarithms and chemists decadal logarithms.\nBeam intensity can also be described in terms of multiple variables: the intensity I or radiant flux \u03a6. In the case of a collimated beam, these are related by \u03a6 \n \"IS\", but \u03a6 is often used in non-collimated contexts. The ratio of intensity (or flux) in to out is sometimes summarized as a transmittance coefficient \"T\" \n &lt;templatestyles src=\"Fraction/styles.css\" /&gt;\"I\"\u2044\"I\"0.\nWhen considering an extinction law, dimensional analysis can verify the consistency of the variables, as logarithms (being nonlinear) must always be dimensionless.\nFormulation.\nThe simplest formulation of Beer's relates the optical attenuation of a physical material containing a single attenuating species of uniform concentration to the optical path length through the sample and absorptivity of the species. This expression is:formula_3The quantities so equated are defined to be the absorbance A, which depends on the logarithm base. The Naperian absorbance \u03c4 is then given by \u03c4 \n ln(10)\"A\" and satisfies formula_4\nIf multiple species in the material interact with the radiation, then their absorbances add. Thus a slightly more general formulation is that formula_5where the sum is over all possible radiation-interacting (\"translucent\") species, and i indexes those species.\nIn situations where length may vary significantly, absorbance is sometimes summarized in terms of an attenuation coefficient formula_6\nIn atmospheric science and radiation shielding applications, the attenuation coefficient may vary significantly through an inhomogenous material. In those situations, the most general form of the Beer\u2013Lambert law states that the total attenuation can be obtained by integrating the attenuation coefficient over small slices \"dz\" of the beamline: formula_7These formulations then reduce to the simpler versions when there is only one active species and the attenuation coefficients are constant.\nDerivation.\nThere are two factors that determine the degree to which a medium containing particles will attenuate a light beam: the number of particles encountered by the light beam, and the degree to which each particle extinguishes the light.\nAssume that a beam of light enters a material sample. Define z as an axis parallel to the direction of the beam. Divide the material sample into thin slices, perpendicular to the beam of light, with thickness d\"z\" sufficiently small that one particle in a slice cannot obscure another particle in the same slice when viewed along the z direction. The radiant flux of the light that emerges from a slice is reduced, compared to that of the light that entered, by formula_8 where \u03bc is the (Napierian) attenuation coefficient, which yields the following first-order linear, ordinary differential equation:formula_9\nThe attenuation is caused by the photons that did not make it to the other side of the slice because of scattering or absorption. The solution to this differential equation is obtained by multiplying the integrating factorformula_10throughout to obtainformula_11which simplifies due to the product rule (applied backwards) toformula_12\nIntegrating both sides and solving for \u03a6e for a material of real thickness \u2113, with the incident radiant flux upon the slice formula_13 and the transmitted radiant flux formula_14 givesformula_15and finallyformula_16\nSince the decadic attenuation coefficient \"\u03bc\"10 is related to the (Napierian) attenuation coefficient by formula_17 we also haveformula_18\nTo describe the attenuation coefficient in a way independent of the number densities ni of the N attenuating species of the material sample, one introduces the attenuation cross section formula_19 \u03c3i has the dimension of an area; it expresses the likelihood of interaction between the particles of the beam and the particles of the species i in the material sample:formula_20\nOne can also use the molar attenuation coefficients formula_21 where NA is the Avogadro constant, to describe the attenuation coefficient in a way independent of the amount concentrations formula_22 of the attenuating species of the material sample:formula_23\nValidity.\nUnder certain conditions the Beer\u2013Lambert law fails to maintain a linear relationship between attenuation and concentration of analyte. These deviations are classified into three categories:\nThere are at least six conditions that need to be fulfilled in order for the Beer\u2013Lambert law to be valid. These are:\nIf any of these conditions are not fulfilled, there will be deviations from the Beer\u2013Lambert law.\nThe law tends to break down at very high concentrations, especially if the material is highly scattering. Absorbance within range of 0.2 to 0.5 is ideal to maintain linearity in the Beer\u2013Lambert law. If the radiation is especially intense, nonlinear optical processes can also cause variances. The main reason, however, is that the concentration dependence is in general non-linear and Beer's law is valid only under certain conditions as shown by derivation below. For strong oscillators and at high concentrations the deviations are stronger. If the molecules are closer to each other interactions can set in. These interactions can be roughly divided into physical and chemical interactions. Physical interaction do not alter the polarizability of the molecules as long as the interaction is not so strong that light and molecular quantum state intermix (strong coupling), but cause the attenuation cross sections to be non-additive via electromagnetic coupling. Chemical interactions in contrast change the polarizability and thus absorption.\nIn solids, attenuation is usually an addition of absorption coefficient formula_24 (creation of electron-hole pairs) or scattering (for example Rayleigh scattering if the scattering centers are much smaller than the incident wavelength). Also note that for some systems we can put formula_25 (1 over inelastic mean free path) in place of formula_26.\nApplications.\nIn plasma physics.\nThe BBL extinction law also arises as a solution to the BGK equation.\nChemical analysis by spectrophotometry.\nThe Beer\u2013Lambert law can be applied to the analysis of a mixture by spectrophotometry, without the need for extensive pre-processing of the sample. An example is the determination of bilirubin in blood plasma samples. The spectrum of pure bilirubin is known, so the molar attenuation coefficient \u03b5 is known. Measurements of decadic attenuation coefficient \"\u03bc\"10 are made at one wavelength \u03bb that is nearly unique for bilirubin and at a second wavelength in order to correct for possible interferences. The amount concentration c is then given by\nformula_27\nFor a more complicated example, consider a mixture in solution containing two species at amount concentrations \"c\"1 and \"c\"2. The decadic attenuation coefficient at any wavelength \u03bb is, given by\nformula_28\nTherefore, measurements at two wavelengths yields two equations in two unknowns and will suffice to determine the amount concentrations \"c\"1 and \"c\"2 as long as the molar attenuation coefficients of the two components, \"\u03b5\"1 and \"\u03b5\"2 are known at both wavelengths. This two system equation can be solved using Cramer's rule. In practice it is better to use linear least squares to determine the two amount concentrations from measurements made at more than two wavelengths. \nMixtures containing more than two components can be analyzed in the same way, using a minimum of m wavelengths for a mixture containing n components. So, in general: \nformula_29\nwhere formula_30is the absorbance at wavelength formula_31, formula_32 is the molar absorptivity of component formula_33 at formula_31, formula_35 is the concentration of component formula_33, and formula_37 is the path length.\nThe law is used widely in infra-red spectroscopy and near-infrared spectroscopy for analysis of polymer degradation and oxidation (also in biological tissue) as well as to measure the concentration of various compounds in different food samples. The carbonyl group attenuation at about 6 micrometres can be detected quite easily, and degree of oxidation of the polymer calculated.\nIn-atmosphere astronomy.\nThe Bouguer\u2013Lambert law may be applied to describe the attenuation of solar or stellar radiation as it travels through the atmosphere. In this case, there is scattering of radiation as well as absorption. The optical depth for a slant path is \"\u03c4\u2032\" = \"m\u03c4\", where \u03c4 refers to a vertical path, m is called the relative airmass, and for a plane-parallel atmosphere it is determined as \"m\" = sec \"\u03b8\" where \u03b8 is the zenith angle corresponding to the given path. The Bouguer-Lambert law for the atmosphere is usually written\nformula_38\nwhere each \u03c4x is the optical depth whose subscript identifies the source of the absorption or scattering it describes:\nm is the \"optical mass\" or \"airmass factor\", a term approximately equal (for small and moderate values of \u03b8) to &amp;NoBreak;&amp;NoBreak; where \u03b8 is the observed object's zenith angle (the angle measured from the direction perpendicular to the Earth's surface at the observation site). This equation can be used to retrieve \"\u03c4\"a, the aerosol optical thickness, which is necessary for the correction of satellite images and also important in accounting for the role of aerosols in climate.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "4477", "revid": "50719333", "url": "https://en.wikipedia.org/wiki?curid=4477", "title": "The Beach Boys", "text": "American rock band\nThe Beach Boys are an American rock band formed in Hawthorne, California, in 1961. The group's original lineup consisted of brothers Brian, Dennis, and Carl Wilson, their cousin Mike Love, and their friend Al Jardine. Distinguished by their vocal harmonies, adolescent-oriented lyrics, and musical ingenuity, they are one of the most influential acts of the rock era. The group drew on the music of older pop vocal groups, 1950s rock and roll, and black R&amp;B to create their unique sound. Under Brian's direction, they often incorporated classical or jazz elements and unconventional recording techniques in innovative ways.\nThey formed as a garage band centered on Brian's songwriting and managed by the Wilsons' father, Murry. Jardine was briefly replaced by David Marks during 1962\u20131963. In 1962, they enjoyed their first national hit with \"Surfin' Safari\", beginning a string of hit singles that reflected a southern California youth culture of surfing, cars, and romance, dubbed the \"California sound\". They were one of the few American rock bands to sustain their commercial standing during the British Invasion. 1965 saw the addition of Bruce Johnston to the band, as well as Brian's move away from beach-going themes for more introspective lyrics and ambitious studio productions. In 1966, the \"Pet Sounds\" album and \"Good Vibrations\" single raised the group's prestige as rock innovators; both are now widely considered to be among the greatest and most influential works in popular music history.\nAfter shelving the \"Smile\" album in 1967, Brian gradually ceded control of the group to his bandmates. In the late 1960s, the group's commercial momentum faltered in the U.S., and they were frequently dismissed by the early rock music press. Rebranding themselves in the early 1970s, Blondie Chaplin and Ricky Fataar of the Flames briefly joined their lineup while Johnston left the band before rejoining in the late 1970s. Carl took over as \"de facto\" leader until the mid-1970s, when the band responded to the growing success of their live shows and greatest hits compilations by becoming an oldies touring act. Brian would return as producer for \"15 Big Ones\" (1976) and \"The Beach Boys Love You\" (1977) after which his contributions again became sporadic. Dennis drowned in 1983, and Brian became estranged from the group in the late 1990s. Following Carl's death from lung cancer in 1998, Jardine left the band while Love was granted legal rights to tour under the group's name and continued performing with Johnston and, occasionally, Marks. In the early 2010s, the surviving original members, alongside Marks and Johnston, briefly reunited for the album \"That's Why God Made the Radio\" (2012) and a 50th anniversary tour. Brian died in 2025 of respiratory arrest.\nThe Beach Boys are one of the most critically acclaimed and commercially successful bands of all time, selling over 100 million records worldwide. They helped legitimize popular music as a recognized art form, and influenced the development of music genres and movements such as psychedelia, power pop, progressive rock, punk, alternative, and lo-fi. Between the 1960s and 2020s, the group had 37 songs reach the U.S. Top 40 of the \"Billboard\" Hot 100 (the most by an American band), with four topping the chart. In 2004, the group was ranked number 12 on \"Rolling Stone\"'s list of the greatest artists of all time, the highest ranking of any American band. Many critics' polls have ranked \"The Beach Boys Today!\" (1965), \"Pet Sounds\", \"Smiley Smile\", \"Wild Honey\" (both 1967), \"Sunflower\" (1970), \"Surf's Up\" (1971), and the archival compilation box set \"The Smile Sessions\" (2011) among the finest albums in history. The founding members were inducted into the Rock and Roll Hall of Fame in 1988.\nHistory.\n1958\u20131961: Formation.\nAt the time of his 16th birthday on June 20, 1958, Brian Wilson shared a bedroom with his brothers, Dennis and Carl\u2014aged 13 and 11, respectively\u2014in their family home in Hawthorne. He had watched his father Murry Wilson play piano, and had listened intently to the harmonies of vocal groups such as the Four Freshmen. After dissecting songs such as \"Ivory Tower\" and \"Good News\", Brian would teach family members how to sing the background harmonies. For his birthday that year, Brian received a reel-to-reel tape recorder. He learned how to overdub, using his vocals and those of Carl and their mother. Brian played piano, while Carl and David Marks, an eleven-year-old longtime neighbor, played guitars that each had received as Christmas presents.\nSoon Brian and Carl were avidly listening to Johnny Otis' KFOX radio show. Inspired by the simple structure and vocals of the rhythm and blues songs he heard, Brian changed his piano-playing style and started writing songs. Family gatherings brought the Wilsons in contact with cousin Mike Love. Brian taught Love's sister Maureen and a friend harmonies. Later, Brian, Carl, Love and two friends performed at Hawthorne High School under the name \"Carl and The Passions\". Brian also knew Al Jardine, a high school classmate. Brian suggested to Jardine that they team up with his cousin and brother Carl. Soon after Dennis also joined the band on demand of the Wilson's mother Audree. Love gave the fledgling band its name: \"The Pendletones\", a pun on \"Pendleton\", a brand of woolen shirt popular among local surfers at the time. Dennis was the only avid surfer in the group, and he suggested that the group write songs that celebrated the sport and the lifestyle that it had inspired in Southern California. Brian finished the song, titled \"Surfin'\", and with Mike Love, wrote \"Surfin' Safari\".\nMurry Wilson, who was an occasional songwriter, arranged for the Pendletones to meet his publisher Hite Morgan. He said: \"Finally, [Hite] agreed to hear it, and Mrs. Morgan said 'Drop everything, we're going to record your song. I think it's good.' And she's the one responsible.\" On September 15, 1961, the band recorded a demo of \"Surfin'\" with the Morgans. A more professional recording was made on October 3, at World Pacific Studio in Hollywood. David Marks was not present at the session as he was in school that day. Murry brought the demos to Herb Newman, owner of Candix Records and Era Records, and he signed the group on December 8. When the single was released a few weeks later, the band found that they had been renamed \"the Beach Boys\". Candix wanted to name the group the Surfers until Russ Regan, a young promoter with Era Records, noted that there already existed a group by that name. He suggested calling them the Beach Boys. \"Surfin'\" was a regional success for the West Coast, and reached number 75 on the national \"Billboard\" Hot 100 chart.\n1962\u20131967: Peak years.\nSigning to Capitol Records.\nBy this time the de facto manager of the Beach Boys, Murry landed the group's first paying gig (for which they earned $300) on New Year's Eve, 1961, at the Ritchie Valens Memorial Dance in Long Beach. In their early public appearances, the band wore the heavy Pendleton woolen jacket-like shirts that local surfers favored before switching to their trademark striped shirts and white pants (a look that was taken directly from the Kingston Trio). All five members sang, with Brian playing bass, Dennis playing drums, Carl playing lead guitar, and Al Jardine playing rhythm guitar, while Mike Love was the main singer and occasionally played saxophone. In early 1962, Morgan requested that some of the members add vocals to a couple of instrumental tracks that he had recorded with other musicians. This led to the creation of the short-lived group Kenny &amp; the Cadets, which Brian led under the pseudonym \"Kenny\". The other members were Carl, Jardine, and the Wilsons' mother Audree. In February, Jardine left the Beach Boys and was replaced by David Marks on rhythm guitar. A common misconception is that Jardine left to focus on dental school. In reality, Jardine did not even apply to dental school until 1964, and the reason he left in February 1962 was due to creative differences and his belief that the newly-formed group would not be a commercial success.\nAfter being turned down by Dot and Liberty, the Beach Boys signed a seven-year contract with Capitol Records. This was at the urging of Capitol executive and staff producer Nick Venet who signed the group, seeing them as the \"teenage gold\" he had been scouting for. On June 4, 1962, the Beach Boys debuted on Capitol with their second single, \"Surfin' Safari\" backed with \"409\". The release prompted national coverage in the June 9 issue of \"Billboard\", which praised Love's lead vocal and said the song had potential. \"Surfin' Safari\" rose to number 14 and found airplay in New York and Phoenix, a surprise for the label.\nFirst studio albums.\nThe Beach Boys' debut album, \"Surfin' Safari\", was released in October 1962. It was different from other rock albums of the time in that it consisted almost entirely of original songs, primarily written by Brian with Mike Love and friend Gary Usher. Another unusual feature of the Beach Boys was that, although they were marketed as \"surf music\", their repertoire bore little resemblance to the music of other surf bands, which was mainly instrumental and incorporated heavy use of spring reverb. For this reason, some of the Beach Boys' early local performances had young audience members throwing vegetables at the band, believing that the group were poseurs.\nIn January 1963, the Beach Boys recorded their first top-ten single, \"Surfin' U.S.A.\", which began their long run of highly successful recording efforts. It was during the sessions for this single that Brian made the production decision from that point on to use double tracking on the group's vocals, resulting in a deeper and more resonant sound. The album of the same name followed in March and reached number 2 on the \"Billboard\" charts. Its success propelled the group into a nationwide spotlight, and was vital to launching surf music as a national craze, albeit the Beach Boys' vocal approach to the genre, not the original instrumental style pioneered by Dick Dale. Biographer Luis Sanchez highlights the \"Surfin' U.S.A.\" single as a turning point for the band, \"creat[ing] a direct passage to California life for a wide teenage audience\u00a0... [and] a distinct Southern California sensibility that exceeded its conception as such to advance right to the front of American consciousness\". Jardine returned in spring 1963 so Brian could make fewer touring appearances. Issues between Marks, his parents, and manager/the Wilsons' father Murry led Marks to quit in October 1963.\n\"Surfer Girl\" marked the first time the group used outside musicians on a substantial portion of an LP. Many of them were the musicians Spector used for his Wall of Sound productions. Only a month after \"Surfer Girl\"'s release the group's fourth album \"Little Deuce Coupe\" was issued. To close 1963, the band released a standalone Christmas-themed single \"Little Saint Nick\", backed with an a cappella rendition of the scriptural song \"The Lord's Prayer\". The A-side peaked at number 3 on the US \"Billboard\" Christmas chart.\nReaction to British Invasion.\nThe surf music craze, along with the careers of nearly all surf acts, was slowly replaced by the British Invasion. Following a successful Australasian tour in January and February 1964, the Beach Boys returned home to face their new competition, the Beatles. Both groups shared the same record label in the US, and Capitol's support for the Beach Boys immediately began waning. Although it generated a top-five single in \"Fun Fun Fun\", the group's fifth album, \"Shut Down Volume 2\", became their first since \"Surfin' Safari\" not to reach the US top-ten. This caused Murry to fight for the band at the label more than before, often visiting their offices without warning to \"twist executive arms\". Carl said that Phil Spector \"was Brian's favorite kind of rock; he liked [him] better than the early Beatles stuff. He loved the Beatles' later music when they evolved and started making intelligent, masterful music, but before that Phil was it.\" According to Mike Love, Carl followed the Beatles more closely than anyone else in the band, while Brian was the most \"rattled\" by the Beatles and felt tremendous pressure to \"keep pace\" with them. For Brian, the Beatles ultimately \"eclipsed a lot [of what] we'd worked for\u00a0... [they] eclipsed the whole music world\".\nBrian wrote his last surf song for nearly four years, \"Don't Back Down\", in April 1964. That month, during recording of the single \"I Get Around\", the band dismissed Murry as their manager. He remained in close contact with the group, offering unsolicited advice on their business decisions. When \"I Get Around\" was released in May, it would climb to number 1 in the US and Canada, their first single to do so (also reaching the top-ten in Sweden and the UK), proving that the Beach Boys could compete with contemporary British pop groups. \"I Get Around\" and \"Don't Back Down\" both appeared on the band's sixth album \"All Summer Long\", released in July 1964 and reaching number 4 in the US. \"All Summer Long\" introduced exotic textures to the Beach Boys' sound exemplified by the piccolos and xylophones of its title track. The album was a swan-song to the surf and car music the Beach Boys built their commercial standing upon. Later albums took a different stylistic and lyrical path. Before this, a live album, \"Beach Boys Concert\", was released in October to a four-week chart stay at number 1, containing a set list of previously recorded songs and covers that they had not yet recorded.\nIn June 1964, Brian recorded the bulk of \"The Beach Boys' Christmas Album\" with a forty-one-piece studio orchestra in collaboration with Four Freshmen arranger Dick Reynolds. The album was a response to Phil Spector's \"A Christmas Gift for You\" (1963). Released in December, the Beach Boys' album was divided between five new, original Christmas-themed songs, and seven reinterpretations of traditional Christmas songs. It would be regarded as one of the finest holiday albums of the rock era. One single from the album, \"The Man with All the Toys\", was released, peaking at number 6 on the US \"Billboard\" Christmas chart. On October 29, the Beach Boys performed for \"The T.A.M.I. Show\", a concert film intended to bring together a wide range of musicians for a one-off performance. The result was released to movie theaters one month later.\nArtistic growth in 1965.\nBy the end of 1964, the stress of road travel, writing, and producing became too much for Brian. On December 23, while on a flight from Los Angeles to Houston, he suffered a panic attack. In January 1965, he announced his withdrawal from touring to concentrate entirely on songwriting and record production. For the last few days of 1964 and into early 1965, session musician and up-and-coming solo artist Glen Campbell agreed to temporarily serve as Brian's replacement in concert. Carl took over as the band's musical director onstage. Now a full-time studio artist, Brian wanted to move the Beach Boys beyond their surf aesthetic, believing that their image was antiquated and distracting the public from his talents as a producer and songwriter. Musically, he said he began to \"take the things I learned from Phil Spector and use more instruments whenever I could. I doubled up on basses and tripled up on keyboards, which made everything sound bigger and deeper.\"\nReleased in March 1965, \"The Beach Boys Today!\" marked the first time the group experimented with the \"album-as-art\" form. Music writer Scott Schinder referenced its \"suite-like structure\" as an early example of the rock album format being used to make a cohesive artistic statement. Brian also established his new lyrical approach toward the autobiographical; journalist Nick Kent wrote that the subjects of Brian's songs \"were suddenly no longer simple happy souls harmonizing their sun-kissed innocence and dying devotion to each other over a honey-coated backdrop of surf and sand\". In the book \"Yeah Yeah Yeah: The Story of Modern Pop\", Bob Stanley remarked that \"Brian was aiming for Johnny Mercer but coming up proto-indie.\" In 2012, the album was voted 271 on \"Rolling Stone\" magazine's list of the 500 Greatest Albums of All Time.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\nWe needed to grow. Up to this point we had milked every idea dry [and did] every possible angle about surfing and [cars]. But we needed to grow\nartistically.\n\u2014 Brian Wilson\nIn April 1965, Campbell's own career success pulled him from touring with the group. Columbia Records staff producer Bruce Johnston was asked to locate a replacement for Campbell; having failed to find one, Johnston himself became a full-time member of the band on May 19, 1965. With Johnston's arrival, Brian now had a sixth voice he could work with in the band's vocal arrangements, with the June 4 vocal sessions for \"California Girls\" being Johnston's first recording session with the Beach Boys. \"California Girls\" was included on the band's next album \"Summer Days (And Summer Nights!!)\". The first single from \"Summer Days\" had been a reworked arrangement of \"Help Me, Rhonda\", which became the band's second number 1 US single in the spring of 1965. To appease Capitol's demands for a Beach Boys LP for the 1965 Christmas season, Brian conceived \"Beach Boys' Party!\", a live-in-the-studio album consisting mostly of acoustic covers of 1950s rock and R&amp;B songs, in addition to covers of three Beatles songs, Bob Dylan's \"The Times They Are a-Changin'\", and idiosyncratic rerecordings of the group's earlier songs. The album was an early precursor of the \"unplugged\" trend. It also included a cover of the Regents' song \"Barbara Ann\", which unexpectedly reached number 2 when released as a single several weeks later. In November, the group released another top-twenty single, \"The Little Girl I Once Knew\". It was considered the band's most experimental statement thus far.\n\"Pet Sounds\".\nWilson collaborated with jingle writer Tony Asher for several of the songs on the album \"Pet Sounds\", a refinement of the themes and ideas that were introduced in \"Today!\". In some ways, the music was a jarring departure from their earlier style. Jardine explained that \"it took us quite a while to adjust to [the new material] because it wasn't music you could necessarily dance to\u2014it was more like music you could make love to\". In \"The Journal on the Art of Record Production\", Marshall Heiser writes that \"Pet Sounds\" \"diverges from previous Beach Boys' efforts in several ways: its sound field has a greater sense of depth and 'warmth;' the songs employ even more inventive use of harmony and chord voicings; the prominent use of percussion is a key feature (as opposed to driving drum backbeats); whilst the orchestrations, at times, echo the quirkiness of 'exotica' bandleader Les Baxter, or the 'cool' of Burt Bacharach, more so than Spector's teen fanfares\".\nFor \"Pet Sounds\", Brian desired to make \"a complete statement\", similar to what he believed the Beatles had done with their newest album \"Rubber Soul\", released in December 1965. Brian was immediately enamored with the album, given the impression that it had no filler tracks, a feature that was mostly unheard of at a time when 45\u00a0rpm singles were considered more noteworthy than full-length LPs. He later said: \"It didn't make me want to copy them but to be as good as them. I didn't want to do the same kind of music, but on the same level.\" Thanks to mutual connections, Brian was introduced to the Beatles' former press officer Derek Taylor, who was subsequently employed as the Beach Boys' publicist. Responding to Brian's request to reinvent the band's image, Taylor devised a promotion campaign with the tagline \"Brian Wilson is a genius\", a belief Taylor sincerely held. Taylor's prestige was crucial in offering a credible perspective to those on the outside, and his efforts are widely recognized as instrumental in the album's success in Britain.\nReleased on May 16, 1966, \"Pet Sounds\" was widely influential and raised the band's prestige as an innovative rock group. Early reviews for the album in the US ranged from negative to tentatively positive, and its sales numbered approximately 500,000 units, a drop-off from the run of albums that immediately preceded it. It was assumed that Capitol considered \"Pet Sounds\" a risk, appealing more to an older demographic than the younger, female audience upon which the Beach Boys had built their commercial standing. Within two months, the label capitulated by releasing the group's first greatest hits compilation album, \"Best of the Beach Boys\", which was quickly certified gold by the RIAA. By contrast, \"Pet Sounds\" met a highly favorable critical response in Britain, where it reached number 2 and remained among the top-ten positions for six months. Responding to the hype, \"Melody Maker\" ran a feature in which many pop musicians were asked whether they believed that the album was truly revolutionary and progressive, or \"as sickly as peanut butter\". The author concluded that \"the record's impact on artists and the men behind the artists has been considerable\".\n\"Good Vibrations\" and \"Smile\".\nThroughout the summer of 1966, Brian concentrated on finishing the group's next single, \"Good Vibrations\". Instead of working on whole songs with clear large-scale syntactical structures, he recorded short interchangeable fragments. Through tape splicing, each fragment could be assembled into a linear sequence, allowing larger structures and divergent moods to be produced later. Pop singles were usually recorded in under two hours at that time, so it was one of the most complex pop productions ever undertaken, with sessions for the song stretching over months in four major Hollywood studios. It was the most expensive single then ever recorded, with production costs estimated to be tens of thousands.\nIn the midst of \"Good Vibrations\" sessions, Wilson invited session musician and songwriter Van Dyke Parks to collaborate as lyricist for the Beach Boys' next album project, soon titled \"Smile\". Wilson and Parks intended \"Smile\" to be a continuous suite of songs linked thematically and musically, with the main songs linked together by small vocal pieces and instrumental segments that elaborated on the major songs' musical themes. It was explicitly American in style and subject, a conscious reaction to the overwhelming British dominance of popular music . Some of the music incorporated chanting, cowboy songs, explorations in Indian and Hawaiian music, jazz, classical tone poems, cartoon sound effects, \"musique concr\u00e8te\", and yodeling. \"Saturday Evening Post\" writer Jules Siegel recalled that, on one October evening, Brian announced to his wife and friends that he was \"writing a teenage symphony to God\".\nRecording for \"Smile\" lasted from mid-1966 to mid-1967, and followed the same modular production approach as \"Good Vibrations\". Concurrently, Wilson planned different multimedia side projects, such as a sound effects collage, a comedy album, and a \"health food\" album. Capitol did not support all these, which led to the Beach Boys' desire to form their own label, Brother Records. Wilson employed his newfound \"best friend\" David Anderle as head of the label. Released on October 10, 1966, \"Good Vibrations\" was the Beach Boys' third US number 1 single, reaching the top of the \"Billboard\" Hot 100 in December, and became their first number 1 in Britain. The record was their first single certified gold by the RIAA. It came to be widely acclaimed as one of the greatest masterpieces of rock music. In December, the Beach Boys were voted the top band in the world in the \"NME\"'s annual readers' poll, ahead of the Beatles, the Walker Brothers, the Rolling Stones, and the Four Tops.\nThroughout the first half of 1967, the release date for \"Smile\" was repeatedly postponed as Brian tinkered with the recordings, experimenting with different takes and mixes, and appeared unwilling to supply finished versions of songs. Meanwhile, he began to suffer from delusions and paranoia, believing on one occasion that the would-be album track \"\" caused a building to burn down. On January 3, 1967, Carl Wilson refused to be drafted for military service, leading to indictment and criminal prosecution, which he challenged as a conscientious objector. The FBI arrested him in April, and it took years for courts to resolve the matter.\nAfter months of recording and media hype, \"Smile\" was shelved for personal, technical, and legal reasons. A February 1967 lawsuit seeking $255,000 (equivalent to $ in 2024) was launched against Capitol Records over neglected royalty payments. Within the lawsuit was an attempt to terminate the band's contract with Capitol before its November 1969 expiry. Many of Wilson's associates, including Parks and Anderle, disassociated themselves from the group by April 1967. Brian later said: \"Time can be spent in the studio to the point where you get so next to it, you don't know where you are with it\u2014you decide to just chuck it for a while.\" In the decades following \"Smile\"'s non-release, it became the subject of intense speculation and mystique and the most legendary unreleased album in pop music history. Many of the album's advocates believe that had it been released, it would have altered the group's direction and cemented them at the vanguard of rock innovators. In 2011, \"Uncut\" magazine staff voted \"Smile\" the \"greatest bootleg recording of all time\".\nBritish prominence.\nThroughout 1966, EMI flooded the UK market with Beach Boys albums not yet released there, including \"Beach Boys' Party!\", \"The Beach Boys Today!\" and \"Summer Days (and Summer Nights!!)\", while \"Best of the Beach Boys\" was number 2 there for several weeks at the end of the year.&lt;ref name=\"Mawer/OCC\"&gt;&lt;/ref&gt; Over the final quarter of 1966, the Beach Boys were the highest-selling album act in the UK, where for the first time in three years American artists broke the chart dominance of British acts. In 1971, \"Cue\" magazine wrote that, from mid-1966 to late-1967, the Beach Boys \"were among the vanguard in practically every aspect of the counter culture\".\n1967\u20131969: Faltering popularity and Brian's reduced involvement.\n\"Smiley Smile\".\nFrom 1965 to 1967, the Beach Boys had developed a musical and lyrical sophistication that contrasted their work from before and after. This divide was further solidified by the difference in sound between their albums and their stage performances. This resulted in a split fanbase corresponding to two distinct musical markets. One group enjoys the band's early work as a wholesome representation of American popular culture from before the political and social movements brought on in the mid-1960s. The other group also appreciates the early songs for their energy and complexity, but not as much as the band's ambitious work that was created during the formative psychedelic era. At the time, rock music journalists typically valued the Beach Boys' early records over their experimental work.\nAlthough \"Smile\" had been cancelled, the Beach Boys were still under pressure and a contractual obligation to record and present an album to Capitol. Carl remembered: \"Brian just said, 'I can't do this. We're going to make a homespun version of [\"Smile\"] instead. We're just going to take it easy. I'll get in the pool and sing. Or let's go in the gym and do our parts.' That was \"Smiley Smile\".\" Sessions for the new album lasted from June to July 1967 at Brian's new makeshift home studio. Most of the album featured the Beach Boys playing their own instruments, rather than the session musicians employed in much of their previous work. It was the first album for which production was credited to the entire group instead of Brian alone.\nIn July 1967, lead single \"Heroes and Villains\" was issued, arriving after months of public anticipation, and reached number 12 in US. By then, the group's lawsuit with Capitol was resolved, and it was agreed that \"Smile\" would not be the band's next album. In August, the group embarked on a two-date tour of Hawaii. The shows saw Brian make a brief return to live performance, as Bruce Johnston chose to take a temporary break from the band during the summer of 1967, feeling that the atmosphere within the band \"had all got too weird\". \"Smiley Smile\" was released on September 18, 1967, and peaked at number 41 in the US, making it their worst-selling album to that date. Critics and fans were generally underwhelmed by the album. According to Scott Schinder, the album was released to \"general incomprehension. While \"Smile\" may have divided the Beach Boys' fans had it been released, \"Smiley Smile\" merely baffled them.\" The group was virtually blacklisted by the music press, to the extent that reviews of the group's records were either withheld from publication or published long after the release dates. When released in the UK in November, it performed better, reaching number 9. Over the years, the album gathered a reputation as one of the best \"chill-out\" albums to listen to during an LSD comedown. In 1974, \"NME\" voted it the 64th-greatest album of all time.\n\"Wild Honey\".\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\nWhen we did \"Wild Honey\", Brian asked me to get more involved in the recording end. He wanted a break [because he] had been doing it all too long.\n\u2014Carl Wilson\nThe Beach Boys immediately recorded a new album, \"Wild Honey\", an excursion into soul music, and a self-conscious attempt to \"regroup\" themselves as a rock band in opposition to their more orchestral affairs of the past. Its music differs in many ways from previous Beach Boys records: it contains very little group singing compared to previous albums, and mainly features Brian singing at his piano. Again, the Beach Boys recorded mostly at his home studio. Love reflected that \"Wild Honey\" was \"completely out of the mainstream for what was going on at that time\u00a0... and that was the idea\".\n\"Wild Honey\" was released on December 18, 1967, in competition with the Beatles' \"Magical Mystery Tour\" and the Rolling Stones' \"Their Satanic Majesties Request\". It had a higher chart placing than \"Smiley Smile\", but still failed to make the top-twenty and remained on the charts for only 15 weeks. As with \"Smiley Smile\", contemporary critics viewed it as inconsequential, and it alienated fans whose expectations had been raised by \"Smile\". That month, Mike Love told a British journalist: \"Brian has been rethinking our recording program and in any case we all have a much greater say nowadays in what we turn out in the studio.\"\n\"Friends\", \"20/20\", and Manson affair.\nThe Beach Boys were at their lowest popularity in the late 1960s, and their cultural standing was especially worsened by their public image, which remained incongruous with their peers' \"heavier\" music. At the end of 1967, \"Rolling Stone\" co-founder and editor Jann Wenner printed an influential article that denounced the Beach Boys as \"just one prominent example of a group that has gotten hung up on trying to catch The Beatles. It's a pointless pursuit.\" The article had the effect of excluding the group among serious rock fans and such controversy followed them into the next year. Capitol continued to bill them as \"America's Top Surfin' Group!\" and expected Brian to write more beachgoing songs for the yearly summer markets. From 1968 onward, his songwriting output declined substantially, but the public narrative of \"Brian as leader\" continued. The group also stopped wearing their longtime striped-shirt stage uniforms in favor of matching white, polyester suits that resembled a Las Vegas show band's.\nAfter meeting Maharishi Mahesh Yogi at a UNICEF Variety Gala in Paris, Love and other high-profile celebrities such as the Beatles and Donovan traveled to Rishikesh, India, in February\u2013March 1968. The following Beach Boys album, \"Friends\", had songs influenced by the Transcendental Meditation the Maharishi taught. In support of \"Friends\", Love arranged for the Beach Boys to tour with the Maharishi in the US. Starting on May 3, 1968, the tour lasted five shows and was canceled when the Maharishi withdrew to fulfill film contracts. Because of disappointing audience numbers and the Maharishi's withdrawal, 24 tour dates were canceled at a cost estimated at $250,000. \"Friends\", released on June 24, peaked at number 126 in the US. In August, Capitol issued an album of Beach Boys backing tracks, \"Stack-o-Tracks\". It was the first Beach Boys LP that failed to chart in the US and UK.\nIn June 1968, Dennis befriended Charles Manson, an aspiring singer-songwriter, and their relationship lasted for several months. Dennis bought him time at Brian's home studio, where recording sessions were attempted while Brian stayed in his room. Dennis then proposed that Manson be signed to Brother Records. Brian reportedly disliked Manson, and a deal was never made. In July 1968, the group released the single \"Do It Again\", which lyrically harkened back to their earlier surf songs. Around this time, Brian admitted himself to a psychiatric hospital; his bandmates wrote and produced material in his absence. Released in January 1969, the album \"20/20\" mixed new material with outtakes and leftovers from recent albums; Brian produced virtually none of the newer recordings.\nThe Beach Boys recorded one song by Manson without his involvement: \"Cease to Exist\", rewritten as \"Never Learn Not to Love\", which was included on \"20/20\". As his cult of followers took over Dennis's home, Dennis gradually distanced himself from Manson. According to author David Leaf, \"The entire Wilson family reportedly feared for their lives.\"\nIn August, the Manson Family committed the Tate\u2013LaBianca murders. According to Jon Parks, the band's tour manager, it was widely suspected in the Hollywood community that Manson was responsible for the murders, and it had been known that Manson had been involved with the Beach Boys, causing the band to be viewed as pariahs for a time. In November, police apprehended Manson, and his connection with the Beach Boys received media attention. He was later convicted for several counts of murder and conspiracy to murder.\nSelling of the band's publishing.\nIn April 1969, the band revisited its 1967 lawsuit against Capitol after it alleged an audit revealed the band was owed over $2 million for unpaid royalties and production duties. In May, Brian told the music press that the group's funds were depleted to the point that it was considering filing for bankruptcy at the end of the year, which \"Disc &amp; Music Echo\" called \"stunning news\" and a \"tremendous shock on the American pop scene\". Brian hoped that the success of a forthcoming single, \"Break Away\", would mend the financial issues. The song, written and produced by Brian and Murry, reached number 63 in the US and number 6 in the UK, and Brian's remarks to the press ultimately thwarted long-simmering contract negotiations with Deutsche Grammophon. The group's Capitol contract expired two weeks later with one more album still due. \"Live in London\", a live album recorded in December 1968, was released in the UK and a few other countries in 1970 to fulfil the contract, although it would not see US release until 1976, under the erroneous re-title \"Beach Boys '69\". After the contract was completed Capitol deleted the Beach Boys' catalog from print, effectively cutting off their royalty flow. The lawsuit was later settled in their favor and they acquired the rights to their post-1965 catalog.\nIn August, Sea of Tunes, the Beach Boys' catalog, was sold to Irving Almo Music for $700,000 (equivalent to $ in 2024). According to his wife, Marilyn Wilson, Brian was devastated by the sale. Over the years, the catalog generated more than $100 million in publishing royalties, none of which Murry or the band members ever received. That same month, Carl, Dennis, Love, and Jardine sought a permanent replacement for Johnston, with Johnston unaware of this search. They approached Carl's brother-in-law Billy Hinsche, who declined the offer to focus on his college studies.\n1970\u20131978: Reprise era.\n\"Sunflower\", \"Surf's Up\", \"Carl and the Passions\", and \"Holland\".\nThe group was signed to Reprise Records in 1970. Scott Schinder described the label as \"probably the hippest and most artist-friendly major label of the time\". The deal was brokered by Van Dyke Parks, who was then employed as a multimedia executive at Warner Music Group. Reprise's contract stipulated Brian's proactive involvement with the band in all albums. By the time the Beach Boys' tenure ended with Capitol in 1969, they had sold 65 million records worldwide, closing the decade as the most commercially successful American group in popular music. After recording over 30 different songs and going through several album titles, their first LP for Reprise, \"Sunflower\", was released on August 31, 1970. \"Sunflower\" featured a strong group presence with significant writing contributions from all six band members. Brian was active during this period, writing or co-writing seven of \"Sunflower\"'s 12 songs and performing at half of the band's domestic concerts in 1970. The album received critical acclaim in both the US and the UK.\nIn early-1970, the Beach Boys hired radio presenter Jack Rieley as their manager. One of his initiatives was to encourage the band to record songs featuring more socially conscious lyrics. He also requested the completion of \"Smile\" track \"Surf's Up\" and arranged a guest appearance at a Grateful Dead concert at Bill Graham's Fillmore East in April 1971 to foreground the Beach Boys' transition into the counterculture. During this time, the group ceased wearing matching uniforms on stage, while Dennis took time to star alongside James Taylor, Laurie Bird, and Warren Oates in the cult film \"Two-Lane Blacktop\", released in 1971. In early 1971, David Marks reunited onstage in Boston with the Beach Boys, after which he received an offer from Mike Love to rejoin, which he declined. In July, the American music press rated the Beach Boys \"the hottest grossing act\" in the country, alongside Grand Funk Railroad. The band filmed a concert for ABC-TV in Central Park, which aired as \"Good Vibrations from Central Park\" on August 19.\nOn August 30, the band released \"Surf's Up\", which was moderately successful, reaching the US top-thirty, a marked improvement over their recent releases. While the record charted, the Beach Boys added to their renewed fame by performing a near-sellout set at Carnegie Hall; their live shows during this era included reworked arrangements of many of their previous songs, with their set lists culling from \"Pet Sounds\" and \"Smile\". On October 28, the Beach Boys were the featured cover story on that date's issue of \"Rolling Stone\". It included the first part of a lengthy two-part interview, titled \"The Beach Boys: A California Saga\", conducted by Tom Nolan and David Felton.\nEarly 1972 saw Bruce Johnston leave the band, and the recruitment of two former members of South African band the Flames, guitarist/singer Blondie Chaplin and drummer/singer Ricky Fataar. The new line-up released \"Carl and the Passions \u2013 \"So Tough\"\" in May 1972. The original US release was a double album, the second disc being a reissue of \"Pet Sounds\". After the upswing of \"Surf's Up\", \"Carl and the Passions\" was relatively unsuccessful in the US, charting at number 50. It was more successful in the UK, where it was issued as a single album without \"Pet Sounds\", peaking at number 25. The next album, \"Holland\", was released in January 1973. Reprise initially rejected the album, feeling it lacked a strong single. Following the intervention of Van Dyke Parks, this resulted in the inclusion of \"Sail On, Sailor\". Reprise approved, and the resulting album peaked at number 37. Brian's musical children's story, \"Mount Vernon and Fairway\", was included with the album as a bonus EP.\nGreatest hits LPs, touring resurgence, and Caribou sessions.\nAfter \"Holland\", the group maintained a touring regimen, captured on the double live album \"The Beach Boys in Concert\" released in November 1973, but recorded very little in the studio through 1975. Several months earlier, they had announced that they would complete \"Smile\", but this never came to fruition, and plans for its release were once again abandoned. Following Murry's death in June 1973, Brian retreated into his bedroom and withdrew further into drug abuse, alcoholism, chain smoking, and overeating. In October, the band dismissed Rieley as manager and appointed Mike Love's brother, Stephen, and Chicago manager James William Guercio. Chaplin and Fataar left the band in December 1973 and November 1974, respectively, reducing the band back to the original five members.\nThe Beach Boys' greatest hits compilation album \"Endless Summer\" was released in June 1974 to unexpected success, becoming the band's second number 1 US album in October. The LP had a 155-week chart run, selling over 3 million copies. A second volume of greatest hits, \"Spirit of America\", followed in April 1975, reaching US number 8, being certified Gold, and having a 43-week chart run. The Beach Boys became the number-one act in the US, propelling themselves from opening for Crosby, Stills, Nash and Young in the summer of 1974 to headliners selling out basketball arenas in a matter of weeks. Guercio prevailed upon the group to swap out newer songs with older material in their concert setlists, partly to accommodate their growing audience and the demand for their early hits. Later in the year, members of the band appeared as guests on Chicago's hit \"Wishing You Were Here\". At the end of 1974, \"Rolling Stone\" proclaimed the Beach Boys \"Band of the Year\" based on the strength of their live performances.\nTo capitalize on their sudden resurgence in popularity, the Beach Boys accepted Guercio's invitation to record their next Reprise album at his Caribou Ranch studio, located around the mountains of Nederland, Colorado. These October 1974 sessions marked the group's return to the studio after a 21-month period of virtual inactivity, but the proceedings were cut short after Brian had insisted on returning to his home in Los Angeles. With the project put on hold, the Beach Boys spent most of the next year on the road playing college football stadiums and basketball arenas. The only Beach Boys recording of 1974 to see release at the time was the Christmas single \"Child of Winter\", recorded upon the group's return to Los Angeles in November and released the following month.\nOver the summer of 1975, the touring group played a co-headlining series of concert dates with Chicago, a pairing that was nicknamed \"Beachago\". The tour was massively successful and restored the Beach Boys' profitability to what it had been in the mid-1960s. Although another joint tour with Chicago had been planned for the summer of 1976, the Beach Boys' association with Guercio and his Caribou Management company ended in early 1976. Stephen Love subsequently took over as the band's \"de facto\" business manager.\n\"15 Big Ones\", \"Love You\", and \"Adult/Child\".\nEarly in 1975, Brian signed a production deal with California Music, a Los Angeles collective that included Bruce Johnston and Gary Usher, but was drawn away by the Beach Boys' pressing demands for a new album. In October, Marilyn persuaded Brian to admit himself to the care of psychologist Eugene Landy, who kept him from indulging in substance abuse with constant supervision. Brian was kept in the program until December 1976.\nAt the end of January 1976, the Beach Boys returned to the studio with Brian producing once again. Brian decided the band should do an album of rock and roll and doo wop standards. Carl and Dennis disagreed, feeling that an album of originals was far more ideal, while Love and Jardine wanted the album out as quickly as possible. To highlight Brian's recovery and his return to writing and producing, Stephen launched a media campaign and paid the Rogers &amp; Cowan publicity agency $3,500 per month to implement it. The band also commissioned an NBC-TV special, later known as \"\", that was produced by \"NBC's Saturday Night\" creator Lorne Michaels.\nReleased on July 5, 1976, \"15 Big Ones\" was generally disliked by fans and critics, as well as Carl and Dennis, who disparaged the album to the press. The album peaked at number 8 in the US, becoming their first top-ten album of new material since \"Pet Sounds\", and their highest-charting studio album since \"Summer Days (And Summer Nights!!)\". Lead single \"Rock and Roll Music\" peaked at number 5 \u2013 their highest chart ranking since \"Good Vibrations\".\nFrom late-1976 to early-1977, Brian made sporadic public appearances and produced the band's next album, \"The Beach Boys Love You\". He regarded it as a spiritual successor to \"Pet Sounds\", namely because of the autobiographical lyrics. Released on April 11, 1977, \"Love You\" peaked at number 53 in the US and number 28 in the UK. Critically, it was widely praised, though it initially met with polarized reactions from the public. Numerous esteemed critics penned favorable reviews, but casual listeners generally found the album's idiosyncratic sound to be a detriment.\n\"Adult/Child\", the intended follow-up to \"Love You\", was completed, but the release was vetoed by Love and Jardine. According to Stan Love, when his brother Mike heard the album, Mike turned to Brian and asked: \"What the fuck are you doing?\" Some of the unreleased songs on \"Adult/Child\" later saw individual release on subsequent Beach Boys albums and compilations. Following this period, his concert appearances with the band gradually diminished and their performances were occasionally erratic.\nCBS signing and \"M.I.U. Album\".\nAt the beginning of 1977, the Beach Boys had enjoyed their most lucrative concert tours ever, with the band playing in packed stadiums and earning up to $150,000 per show. Concurrently, the band was the subject of a record company bidding war, as their contract with Warner Bros. had been set to expire soon. Stephen Love arranged for the Beach Boys to sign an $8 million deal with CBS Records on March 1. Numerous stipulations were given in the CBS contract, including that Brian was required to write at least four songs per album, co-write at least 70% of all the tracks, and produce or co-produce alongside his brothers. Another part of the deal required the group to play thirty concerts a year in the U.S., in addition to one tour in Australia and Japan, and two tours in Europe. The first Beach Boys-related release on CBS was Dennis' solo album \"Pacific Ocean Blue\", which would be issued in August 1977.\nWithin weeks of the CBS contract, the band dismissed Stephen, with one of the alleged reasons being that Mike had not permitted Stephen to sign on his behalf while at a TM retreat in Switzerland. For Stephen's replacement, the group hired Carl's friend Henry Lazarus, an entertainment business owner that had no prior experience in the music industry. Lazarus arranged a major European tour for the Beach Boys, starting in late July, with stops in Germany, Switzerland, and France. Due to poor planning, the tour was cancelled shortly before it began. The band dismissed Lazarus and were sued by many of the concert promoters, with losses of $200,000 in preliminary expenses and $550,000 in potential revenue.\nIn July, the Beach Boys played a concert at Wembley Stadium before Mike attacked Brian with a piano bench onstage in front of over 15,000 attendees. In August, Mike and Jardine persuaded Stephen to return as the group's manager, a decision that Carl and Dennis had strongly opposed. By this point, the band had effectively split into two camps; Dennis and Carl on one side, and Mike and Jardine on the other, with Brian remaining neutral. The internal wrangling came to a head in September, with Dennis declaring to a \"Rolling Stone\" journalist that he had left the band. The group was broken up until a meeting at Brian's house on September 17. In light of the lucrative CBS contract, the parties negotiated a settlement resulting in Love gaining control of Brian's vote in the group, allowing Love and Jardine to outvote Carl and Dennis on any matter.\nThe group had still owed one more album for Reprise. Released in September 1978, \"M.I.U. Album\" was recorded at Maharishi International University in Iowa at the suggestion of Love. The band originally attempted to record a Christmas album, to be titled \"Merry Christmas from the Beach Boys\", but this idea was rejected by Reprise. These Christmas recordings would eventually be released in 1998 as part of the archival album \"Ultimate Christmas\". Dennis and Carl made limited contributions to \"M.I.U. Album\"; the album was produced by Jardine and Ron Altbach, with Brian credited as \"executive producer\". Dennis started to withdraw from the group to focus on his second solo album, \"Bambu\", which was shelved just as alcoholism and marital problems overcame all three Wilson brothers.\n1978\u20131998: Continued recording and Brian's estrangement.\n\"L.A. (Light Album)\" and \"Keepin' the Summer Alive\".\nThe group's first two albums for CBS, 1979's \"L.A. (Light Album)\" and 1980's \"Keepin' the Summer Alive\", struggled in the US, charting at 100 and 75 respectively, though the band did manage a top-forty single from \"L.A. (Light Album)\" with \"Good Timin'\". The recording of these albums saw Bruce Johnston return to the band, initially solely as a producer and eventually as a full-time band member. In-between the two albums, the group contributed the song \"It's a Beautiful Day\" to the soundtrack of the film \"Americathon\".\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\nI think a lot of critics punish the band for not going beyond \"Good Vibrations\"\u00a0... they love the band so much that they get crazy because we don't top ourselves.\u00a0... [but] growth in this business is tough.\n\u2014 Bruce Johnston, 1982\nOn June 21, 1980, the Beach Boys performed a concert at Knebworth, England, which featured a slightly intoxicated Dennis. The concert would later be released as a live album titled \"\" in 2002. In 1981, the band scored a surprise US top-twenty hit when their cover of the Del-Vikings' \"Come Go with Me\", from the three year old \"M.I.U. Album\", was released as a single from \"Ten Years of Harmony\", a double compilation album focusing on the Reprise and CBS years.\nIn an April 1980 interview, Carl reflected that \"the last two years have been the most important and difficult time of our career. We were at the ultimate crossroads. We had to decide whether what we had been involved in since we were teenagers had lost its meaning. We asked ourselves and each other the difficult questions we'd often avoided in the past.\" In 1981, he temporarily left the touring group because of unhappiness with the band's nostalgia format and lackluster live performances, taking the time to record and release his first solo album \"Carl Wilson\". He stated: \"I haven't quit the Beach Boys but I do not plan on touring with them until they decide that 1981 means as much to them as 1961.\" He returned in May 1982, after approximately 14 months of being away, on the condition that the group reconsider their rehearsal and touring policies and refrain from \"Las Vegas-type\" engagements.\nDuring Carl's absence, Jeffrey Foskett, who previously performed in Love's Endless Summer Beach Band, was recruited to the touring band to sing Carl's parts. On Carl's return, Foskett remained in the band to perform falsetto vocals and guitar until 1990, and would return for the 2012 reunion tour and album, and the touring band of 2014-2019. Though never named as an official member of the Beach Boys, he would later be identified by members as the band's only \"vice principal\".\nIn late 1982, Eugene Landy was hired once more as Brian's therapist. On November 5, Carl, Love and Jardine falsely informed Brian that he was destitute and no longer a Beach Boy, insisting he reenlist Landy as his caretaker to continue receiving his touring income, in addition to putting him on a strict diet and health regimen. Coupled with counseling sessions that retaught him basic social etiquette, this therapy restored Brian's physical health, slimming down from to and Brian returned to the group.\nDeath of Dennis, \"The Beach Boys\", and \"Still Cruisin\"'.\nBy the late 1970s and early 1980s, Dennis had been embroiled in successive failed romantic relationships, including a tense and short-lived relationship with Fleetwood Mac's Christine McVie, and found himself in severe economic trouble resulting in the sale of Brother Studios, established by the Wilson brothers in 1974 and where \"Pacific Ocean Blue\" was produced, and the forfeiture of his beloved yacht. To cope with the combination of devastating losses, Dennis heavily abused alcohol, cocaine, and heroin and was, by 1983, homeless and lived a nomadic lifestyle. He was often seen spending much of his time wandering the Los Angeles coast and often missed Beach Boys performances. By this point, he had lost his voice and much of his ability to play drums.\nThat year, tensions between Dennis and Love escalated to the point that each filed a restraining order against the other. Following Brian's readmission for Landy's treatment, Dennis was given an ultimatum after his last performance in November to check into rehab for his alcohol problems or be banned from performing live with the band again. Dennis checked into rehab for his chance to get sober, but on December 28, he drowned at the age of 39 in Marina del Rey while diving from a friend's boat trying to recover items that he had previously thrown overboard in a fit of rage.\nThe Beach Boys spent the next several years touring, often playing in front of large audiences, and recording songs for film soundtracks and various artists compilations. One new studio album, the self-titled \"The Beach Boys\", appeared in 1985 and proved a modest success, becoming their highest-charting album in the US since \"15 Big Ones\". It was the band's last album for CBS, as they returned to Capitol in 1986 with a 25th anniversary greatest hits album, \"Made in U.S.A\", which went double platinum. In 1988, the Beach Boys unexpectedly claimed their first US number 1 single in 22 years with \"Kokomo\", which topped the chart for one week. The track was included on the band's next studio album, 1989's \"Still Cruisin\"', which went platinum in the US. During that period, Brian was largely absent during the recording sessions and tour dates due the recording of his debut solo album \"Brian Wilson\" and conflicts between the band and Landy.\nLawsuits, \"Summer in Paradise\", and \"Stars and Stripes, Vol. 1\".\nBiographer Peter Ames Carlin summarized: \"Once surfin' pin-ups, they remade themselves as avant-garde pop artists, then psychedelic oracles. After that they were down-home hippies, then retro-hip icons. Eventually they devolved into none of the above: a kind of perpetual-motion nostalgia machine.\" Music journalist Erik Davis wrote in 1990: \"the Beach Boys are either dead, deranged, or dinosaurs; their records are Eurocentric, square, unsampled; they've made too much money to merit hip revisionism\". In 1992, critic Jim Miller wrote: \"They have become a figment of their own past, prisoners of their unflagging popularity\u2014incongruous emblems of a sunny myth of eternal youth belied by much of their own best music.\u00a0... The group is still largely identified with its hits from the early Sixties.\"\nLove filed a defamation lawsuit against Brian due to how he was presented in Brian's 1992 memoir \"\". Its publisher HarperCollins settled the suit for $1.5 million. He said that the suit allowed his lawyer \"to gain access to the transcripts of Brian's interviews with his [book] collaborator, Todd Gold. Those interviews affirmed\u2014according to Brian\u2014that I had been the inspiration of the group and that I had written many of the songs that [would soon be] in dispute.\" Other defamation lawsuits were filed by Carl, Brother Records, and the Wilsons' mother Audree. With Love and Brian unable to determine exactly what Love was properly owed in royalties and songwriting credits, Love sued Brian in 1992, awarding him $5\u202fmillion and a share of future royalties from Wilson. Thirty-five of the group's songs were then amended to credit Love. He later called it \"almost certainly the largest case of fraud in music history\".\nAfter dissolving his relationship with Landy, Brian phoned Sire Records staff producer Andy Paley to collaborate on new material tentatively for the Beach Boys. After losing the songwriting credits lawsuit with Love, Brian told \"MOJO\" in February 1995: \"Mike and I are just cool. There's a lot of shit Andy and I got written for him. I just had to get through that goddamn trial!\" In April, it was unclear whether the project would turn into a Wilson solo album, a Beach Boys album, or a combination of the two. The project ultimately disintegrated. Instead, Brian and his bandmates recorded \"Stars and Stripes Vol. 1\", an album of country music stars covering Beach Boys songs, with co-production helmed by River North Records owner Joe Thomas. After the release of \"Stars and Stripes Vol. 1\", Brian became completely estranged from the band and did not perform or collaborate with his bandmates until 2012, focussing on his solo career instead. The group would also discuss about finishing the album \"Smile\", but Carl rejected the idea, fearing that it would cause Brian another nervous breakdown. The Grammy-nominated \"The Pet Sounds Sessions\" box set was released in 1997.\n1998\u2013present: Love-led tours and brief reunion.\nCarl's death, name litigation, and \"The Smile Sessions\".\nIn 1997, Carl was diagnosed with lung and brain cancer after years of heavy smoking. Despite his terminal condition, Carl performed with the band on its summer tour (a double-bill with Chicago) while undergoing chemo. During performances, he sat on a stool and needed oxygen after each song. When Carl became too unwell to perform in late 1997, David Marks returned as lead guitarist. Carl died on February 6, 1998, aged 51, two months after the death of the Wilsons' mother, Audree.\nAfter Carl's death, Jardine quit the band. His final appearance with the band for more than a decade occurred on May 9, 1998, which was the final official Beach Boys show performed before the license dispute. During the dispute, Love, Johnston and Marks toured as \"The California Beach Band\". After Love secured a license from BRI, he, Johnston and Marks continued touring as the Beach Boys from July 4, 1998. At the time, Brian was also offered the license, but declined. Jardine began to perform regularly with his band \"Beach Boys: Family &amp; Friends\" until he ran into legal issues for using the name without license. Jardine sued Love, claiming he had been excluded from their concerts. Brother Records, Inc. (BRI), through its attorney, Ed McPherson, sued Jardine. Jardine counter-claimed against BRI for wrongful termination. Courts ruled in Love's favor, denying Jardine use of the Beach Boys name. Jardine appealed, and sought $4 million in damages. The California Court of Appeal ruled that \"Love acted wrongfully in freezing Jardine out of touring under the Beach Boys name\", allowing Jardine to continue with his lawsuit. The case was settled outside of court with the terms undisclosed. Marks quit the band again in 1999, due to a diagnosis of hepatitis C and Love and Johnston continued touring without him.\nIn 2000, ABC-TV premiered a miniseries, \", that dramatized the Beach Boys' story. It was criticized by numerous parties, including Wilson, for inaccuracies.\n\", a greatest hits compilation, was released in 2003, going multi-platinum. In 2004, Wilson recorded and released his solo album \"Brian Wilson Presents Smile\", a reinterpretation of the unfinished \"Smile\" project. That September, Wilson issued a free CD through the \"Mail On Sunday\" that included Beach Boys songs he had rerecorded, five of which he co-authored with Love. The 10-track compilation had 2.6 million copies distributed and prompted Love to file a lawsuit in 2005; he claimed the promotion hurt sales of the original recordings and his image was used for the CD. Wilson's wife Melinda alleged that, during the deposition, Love turned to Wilson and remarked: \"you better start writing a real big hit because you're going to have to write me a real big check\". Love's suit was dismissed in 2007 when a judge determined there were no triable issues and the case was without merit.\nIn 2006, Brian Wilson, Love, Jardine, Marks, and Johnston participated in a non-performing reunion atop the Capitol Records Building to celebrate that \"Sounds of Summer\" had been certified double-platinum. Later that year, Jardine joined Wilson and his band for a tour celebrating the 40th anniversary of \"Pet Sounds\". In 2008, Marks briefly reunited with Love and Johnston's touring band for a tour of Europe.\nIn 2010, Jardine released \"A Postcard from California\", his solo debut. The album features contributions from Brian, Johnston, Marks, and Love, as well as a posthumous feature from Carl and features of several other artist. Also in 2010, Brian and Jardine sang on \"We Are the World 25 for Haiti\", a new recording of \"We Are the World\", to benefit the population of Haiti.\nJardine made his first appearance with the Beach Boys touring band in more than 10 years in 2011 at a tribute concert for Ronald Reagan's 100th birthday. He made other appearances with Love and Johnston's touring band in preparation for a reunion.\nOn October 31, 2011, \"The Smile Sessions\" compilation album and box set was released, featuring comprehensive session highlights and outtakes from the original 1966-1967 \"Smile\" recordings, with the first 19 tracks comprising a hypothetical version of the completed \"Smile\" album. \"The Smile Sessions\" received virtually unanimous critical acclaim upon release. It was ranked number 381 in \"Rolling Stone\"'s 2012 list of the greatest albums of all time and won the Grammy Award for Best Historical Album at the 2013 Grammy Awards.\n\"That's Why God Made the Radio\" and reunion tour.\nOn December 16, 2011, it was announced that Wilson, Love, Jardine, Johnston, and David Marks would reunite for a new album and 50th anniversary tour. On February 12, 2012, the Beach Boys performed at the 2012 Grammy Awards. It marked the group's first live performance to include Wilson since 1996, Jardine since 1998, and Marks since 1999. A new studio album, \"That's Why God Made the Radio\", was released on July 5; it debuted at number 3 on the \"Billboard\" 200, expanding the group's span of top-ten albums there across 49 years and one week, passing the Beatles with 47 years of top-ten albums. Critics generally regarded the album as an \"uneven\" collection, with most of the praise centered on its closing musical suite.\nDuring the tour, when asked about the future held for the band and its reunion after the scheduled end of the tour in September, Love stated that \"We're looking at our present and future. I think we're going to be doing this again with Brian for a long time.\" Wilson said that he had begun planning for another Beach Boys album for the band to record after the tour. On June 1, 2012, Love received an e-mail stating \"no more shows for Wilson\". Love then began accepting invitations for when the reunion was over. Johnston told reporter Mark Dillon in mid-June that the current tour was \"a one-time event. You're not going to see this next year. I'm busy next year doing my thing with Mike.\" On June 25, Wilson's team sent another e-mail asking Love to disregard the previous message, but by then, Love claimed that \"it was too late. We had booked other concerts, and promoters had begun selling tickets.\"\nDespite this, in July, Love stated: \"There's talk of us going and doing a return to the Grammys next year, and there's talk about doing another album together. There's nothing in stone, but there's a lot of ideas being floated around\". Ultimately, the reunion tour ended in September 2012 as planned, after a final show on September 28, but amid rumors that Love had dismissed Wilson from the Beach Boys. Love and Johnston announced that the Beach Boys would revert to the pre-reunion lineup, without Brian, Jardine or Marks, all of whom expressed surprise. Although such dates were noted in a late June issue of \"Rolling Stone\", it was widely reported that the three had been \"fired\". On October 5, Love responded in a self-written press release to the \"Los Angeles Times\" stating he \"did not fire Brian Wilson from the Beach Boys. I cannot fire Brian Wilson from the Beach Boys\u00a0... I do not have such authority. And even if I did, I would never fire Brian Wilson from the Beach Boys.\" He claimed that nobody in the band \"wanted to do a 50th anniversary tour that lasted 10 years\" and that its limited run \"was long agreed upon\". Love and Johnston continue to perform under the Beach Boys name, while Wilson, Jardine, and Marks toured as a trio in 2013, and a subsequent tour with guitarist Jeff Beck also included Blondie Chaplin at select dates. Wilson and Jardine continued to tour together in 2014 and following years, often joined by Chaplin; Marks declined to join them after 2013.\nOccasional partial reunions.\nIn June 2013, Wilson's website announced that he was recording and self-producing new material featuring Jardine, Marks, and Chaplin, among others. \"No Pier Pressure\", Brian's solo album for April 2015, marked another collaboration between him and Joe Thomas, featuring guest appearances from Jardine, Marks and Chaplin.\nIn February 2014, Love, Jardine, Marks and Johnston appeared together at the 2014 Ella Awards Ceremony, where Love was honored for his work as a singer. In April, when asked if he was interested in making music with Love again, Wilson said he wasn't, adding in July that he \"doesn't talk to the Beach Boys [or] Mike Love\". In December, \"Soundstage\" aired an episode featuring Wilson performing with Jardine, Chaplin and Ricky Fataar at The Venetian in Las Vegas.\nIn 2016, Wilson and Jardine embarked on the Pet Sounds 50th Anniversary World Tour, promoted as Wilson's final performances of the album, with Chaplin appearing as a special guest at all dates on select songs. That same year, Love and Wilson each published memoirs, \"\" and \"I Am Brian Wilson\", respectively. Asked about negative comments that Wilson made about him in the book, Love challenged the legitimacy of statements attributed to Wilson in the book and in the press. In an interview with \"Rolling Stone\" conducted in June 2016, Wilson said he would like to try to repair his relationship with Love and collaborate with him again. In January 2017, Love said: \"If it were possible to make it just Brian and I, and have it under control and done better than what happened in 2012, then yeah, I'd be open to something.\"\nIn July 2018, Wilson, Jardine, Love, Johnston, and Marks reunited for a one-off Q&amp;A session moderated by director Rob Reiner at the Capitol Records Building in Los Angeles. It was the first time the band had appeared together in public since their 2012 tour. That December, Love described his new holiday album, \"Reason for the Season\", as a \"message to Brian\" and said that he \"would love nothing more than to get together with Brian and do some music\". In 2019, Wilson and Jardine (with Chaplin) embarked on a co-headlining tour with the Zombies, performing selections from \"Friends\" and \"Surf's Up\".\nIn February 2020, Wilson and Jardine's official social media pages encouraged fans to boycott the band's music after it was announced that Love's Beach Boys would perform at the Safari Club International Convention in Reno, Nevada on animal rights grounds. The concert proceeded despite online protests, as Love issued a statement that said his group has always supported \"freedom of thought and expression as a fundamental tenet of our rights as Americans\". In October, Love and Johnston's Beach Boys performed at a fundraiser for Donald Trump's 2020 presidential campaign; Wilson and Jardine again issued a statement that they had not been informed about this performance and did not support it.\nIntellectual property sale and Brian's death.\nIn February 2021, it was announced that Brian Wilson, Love, Jardine, and the estate of Carl Wilson had sold a majority stake in the band's intellectual property to Irving Azoff and his new company Iconic Artists Group. In April, Omnivore Recordings released the album \"California Music Presents Add Some Music\", featuring Love, Jardine, Marks, Johnston, and several of their children. That August, Capitol released the \"Feel Flows\" box set, comprising sessions from \"Sunflower and Surf's Up\". Capitol succeeded this in December 2022 with the \"Sail On Sailor \u2013 1972\" box set, this time focusing on \"Carl and the Passions\" and \"Holland\".\nIn March 2024, the band announced a self-titled documentary directed by Frank Marshall and Thom Zimny, which would be released by streaming service Disney+, which includes new and archived interviews from various members of the band and their inner circle. The documentary included some footage from a private reunion of Wilson, Love, Jardine, Marks, and Johnston at Paradise Cove, where the \"Surfin' Safari\" album cover photo was taken in 1962. They and Chaplin also participated in a non-performing reunion at the documentary's premiere on May 24, 2024.\nIn August 2024, Jardine revealed that, with Wilson's permission for the use of his band and name, he was planning a tour with many of the musicians from the Brian Wilson Band, minus Wilson himself as he had retired touring in 2022. In May 2025, during an interview with \"Variety\" that month, while promoting his tour with the newly-formed Pet Sounds Band, Jardine announced the upcoming release of a box set, called \"Brother Records 1454\", and due for release in early 2026, which will release the album \"Adult/Child\" alongside reissues of \"15 Big Ones\", \"The Beach Boys Love You\", and \"M.I.U. Album\".\nBrian Wilson died in his sleep in his Beverly Hills home on June 11, 2025, at the age of 82. His primary cause of death was declared as respiratory arrest amid sepsis, cystitis, and other associated factors. Wilson had also been battling dementia. Wilson's death left Love and Jardine as the two remaining original members. Shortly after Wilson's death, Love, Jardine, and Chaplin paid tribute to Wilson on social media. Jardine's tour with the Pet Sounds Band started in July, and was dedicated to Brian's memory. Love and Johnston would also pay tribute to Brian by playing a slideshow during their shows.\nMusical style and development.\nIn \"Understanding Rock: Essays in Musical Analysis\", musicologist Daniel Harrison writes:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Even from their inception, the Beach Boys were an experimental group. They combined, as Jim Miller has put it, \"the instrumental sleekness of the Ventures, the lyric sophistication of Chuck Berry, and the vocal expertise of some weird cross between the Lettermen and Frankie Lymon and the Teenagers\" with lyrics whose images, idioms, and concerns were drawn from the rarefied world of the middle-class white male southern California teenager.\u00a0... [But] it was the profound vocal virtuosity of the group, coupled with the obsessional drive and compositional ambitions of their leader, Brian Wilson, that promised their survival after the eventual breaking of fad fever.\u00a0... Comparison to other vocally oriented rock groups, such as the Association, shows the Beach Boys' technique to be far superior, almost embarrassingly so. They were so confident of their ability, and of Brian's skill as a producer to enhance it, that they were unafraid of doing sophisticated, a cappella glee-club arrangements containing multiple suspensions, passing formations, complex chords, and both chromatic and enharmonic modulations.\nThe Beach Boys began as a garage band playing 1950s style rock and roll, reassembling styles of music such as surf to include vocal jazz harmony, which created their unique sound. In addition, they introduced their signature approach to common genres such as the pop ballad by applying harmonic or formal twists. Among the distinct elements of the Beach Boys' style were the nasal quality of their singing voices, their use of a falsetto harmony over a driving, locomotive-like melody, and the sudden chiming in of the whole group on a key line. Brian Wilson handled most stages of the group's recording process from the beginning, even though he was not properly credited on earlier recordings.\nEarly on, Mike Love sang lead vocals in the rock-oriented songs, while Carl contributed guitar lines on the group's ballads. Jim Miller commented: \"On straight rockers they sang tight harmonies behind Love's lead\u00a0... on ballads, Brian played his falsetto off against lush, jazz-tinged voicings, often using (for rock) unorthodox harmonic structures.\" Harrison adds that \"even the least distinguished of the Beach Boys' early uptempo rock 'n' roll songs show traces of structural complexity at some level; Brian was simply too curious and experimental to leave convention alone\". Although Brian was often dubbed a perfectionist, he was an inexperienced musician, and his understanding of music was mostly self-taught. At the lyric stage, he usually worked with Love, whose assertive persona provided youthful swagger that contrasted Brian's explorations in romanticism and sensitivity. Luis Sanchez noted a pattern where Brian would spare surfing imagery when working with collaborators outside of his band's circle, in the examples \"Lonely Sea\" and \"In My Room\".\nBrian's bandmates resented the notion that he was the sole creative force in the group. In a 1966 article that asked if \"the Beach Boys rely too much on sound genius Brian\", Carl said that although Brian was the most responsible for their music, every member of the group contributed ideas. Mike Love wrote: \"As far as I was concerned, Brian \"was\" a genius, deserving of that recognition. But the rest of us were seen as nameless components in Brian's music machine\u00a0... It didn't feel to us as if we were just riding on Brian's coattails.\" Conversely, Dennis defended Brian's stature in the band, stating: \"Brian Wilson \"is\" the Beach Boys. He is the band. We're his fucking messengers. He is all of it. Period. We're nothing. He's everything.\"\nInfluences.\nThe band's earliest influences came primarily from the work of Chuck Berry and the Four Freshmen. Performed by the Four Freshmen, \"Their Hearts Were Full of Spring\" (1961) was a particular favorite of the group. By analyzing their arrangements of pop standards, Brian educated himself on jazz harmony. Philip Lambert noted: \"If Bob Flanigan helped teach Brian how to sing, then Gershwin, Kern, Porter, and the other members of this pantheon helped him learn how to craft a song.\" Other general influences on the group included the Hi-Lo's, the Penguins, the Robins, Bill Haley &amp; His Comets, Otis Williams, the Cadets, the Everly Brothers, the Shirelles, the Regents, and the Crystals.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\n Though the Beach Boys are often caricatured as the ultimate white, suburban act, black R&amp;B was crucial to their sound.\n \u2014 Geoffrey Himes\nThe eclectic mix of white and black vocal group influences \u2013 ranging from the rock and roll of Berry, the jazz harmonies of the Four Freshmen, the pop of the Four Preps, the folk of the Kingston Trio, the R&amp;B of groups like the Coasters and the Five Satins, and the doo wop of Dion and the Belmonts \u2013 helped contribute to the Beach Boys' uniqueness in American popular music. Carl remembered that Love was \"really immersed in doo-wop\" and likely \"influenced Brian to listen to it\", adding that the \"black artists were so much better in terms of rock records in those days that the white records almost sounded like put-ons\".\nAnother significant influence on Brian's work was Burt Bacharach. He said in the 1960s: \"Burt Bacharach and Hal David are more like me. They're also the best pop team \u2013 per se \u2013 today. As a producer, Bacharach has a very fresh, new approach.\" Regarding surf rock pioneer Dick Dale, Brian said that his influence on the group was limited to Carl and his style of guitar playing. Carl credited Chuck Berry, the Ventures, and John Walker with shaping his guitar style, and that the Beach Boys had learned to play all of the Ventures' songs by ear early in their career.\nIn 1967, Lou Reed wrote in \"Aspen\" that the Beach Boys created a \"hybrid sound\" out of rock and roll and the Four Freshmen, explaining that such songs as \"Let Him Run Wild\", \"Don't Worry Baby\", \"I Get Around\", and \"Fun, Fun, Fun\" were not unlike \"Peppermint Stick\" by the Elchords. Similarly, John Sebastian of the Lovin' Spoonful noted: \"Brian had control of this vocal palette of which we had no idea. We had never paid attention to the Four Freshmen or doo-wop combos like the Crew Cuts. Look what gold he mined out of that.\"\nVocals.\nBrian identified each member individually for their vocal range, once detailing the ranges for Carl, Dennis, Jardine (\"[they] progress upwards through G, A, and B\"), Love (\"can go from bass to the E above middle C\"), and himself (\"I can take the second D in the treble clef\"). He declared in 1966 that his greatest interest was to expand modern vocal harmony, owing to his fascination with a voice to the Four Freshmen, which he considered a \"groovy sectional sound\". He added: \"The harmonies that we are able to produce give us a uniqueness which is really the only important thing you can put into records \u2013 some quality that no one else has got.\" For a period, Brian avoided singing falsetto for the group, saying: \"I thought people thought I was a fairy\u00a0... the band told me, 'If that's the way you sing, don't worry about it.'\"\nIn the group's early recordings, from lowest intervals to highest, the group's vocal harmony stack usually began with Love or Dennis, followed by Jardine or Carl, and finally Brian on top, according to Jardine, while Carl said that the blend was Love on bottom, Carl above, followed by Dennis or Jardine, and then Brian on top. Jardine explains: We always sang the same vocal intervals.\u00a0... As soon as we heard the chords on the piano we'd figure it out pretty easily. If there was a vocal move [Brian] envisioned, he'd show that particular singer that move. We had somewhat photographic memory as far as the vocal parts were concerned so that [was] never a problem for us. Striving for perfection, Brian ensured that his intricate vocal arrangements exercised the group's calculated blend of intonation, attack, phrasing, and expression. Sometimes, he would sing each vocal harmony part alone through multi-track tape.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\n[Love] had a hand in a lot of the arrangements. He would bring out the funkier approaches, whether to go \"shoo-boo-bop\" or \"bom-bom-did-di-did-did\". It makes a big difference, because it can change the whole rhythm, the whole color and tone of it.\n\u2014 Carl Wilson\nOn the group's blend, Carl said: \"[Love] has a beautifully rich, very full-sounding bass voice. Yet his lead singing is real nasal, real punk. [Jardine]'s voice has a bright timbre to it; it really cuts. My voice has a kind of calm sound. We're big oooh-ers; we love to oooh. It's a big, full sound, that's very pleasing to us; it opens up the heart.\" Rock critic Erik Davis wrote: \"The 'purity' of tone and genetic proximity that smoothed their voices was almost creepy, pseudo-castrato, [and] a 'barbershop' sound.\" Jimmy Webb said: \"They used very little vibrato and sing in very straight tones. The voices all lie down beside each other very easily \u2013 there's no bumping between them because the pitch is very precise.\" Writer Richard Goldstein reported that, according to a fellow journalist who asked Brian about the black roots of his music, Brian's response was: \"We're white and we sing white.\" Goldstein added that when he asked where his approach to vocal harmonies had derived from, Wilson answered: 'Barbershop'.\"\nUse of studio musicians.\nBiographer James Murphy said: \"By most contemporary accounts, they were not a very good live band when they started.\u00a0... The Beach Boys learned to play as a band in front of live audiences\", eventually to become \"one of the best and enduring live bands\". With only a few exceptions, the Beach Boys played every instrument heard on their first four albums and first five singles. Music critic Richie Unterberger believed that \"Before session musicians took over most of the parts, the Beach Boys could play respectably gutsy surf rock as a self-contained unit.\"\nAs Wilson's arrangements increased in complexity, he began employing a group of professional studio musicians, later known as \"the Wrecking Crew\", to assist with recording the instrumentation on select tracks. According to some reports, these musicians then completely replaced the Beach Boys on the backing tracks to their records. Much of the relevant documentation, while accounting for the attendance of unionized session players, had failed to record the presence of the Beach Boys themselves. These documents, along with the full unedited studio session tapes, were not available for public scrutiny until the 1990s.\nWilson started occasionally employing members of the Wrecking Crew for certain Beach Boys tracks during the 1963 \"Surfer Girl\" sessions \u2013 specifically, on two songs, \"Hawaii\" and \"Our Car Club\". The 1964 albums \"Shut Down Volume 2\" and \"All Summer Long\" featured the Beach Boys themselves playing the vast majority of the instruments while occasionally being augmented by outside musicians. It is commonly misreported that Dennis in particular was replaced by Hal Blaine on drums. Dennis's drumming is documented on a number of the group's singles, including 1964's \"I Get Around\", \"Fun, Fun, Fun\", and \"Don't Worry Baby\". Starting with the 1965 albums \"Today!\" and \"Summer Days\", Brian used the Wrecking Crew with greater frequency, \"but still\", Stebbins writes, \"the Beach Boys continued to play the instruments on many of the key tracks and single releases\".\nOverall, the Beach Boys played the instruments on the majority of their recordings from the decade, with 1966 and 1967 being the only years when Wilson used the Wrecking Crew almost exclusively. \"Pet Sounds\" and \"Smile\" are their only albums in which the backing tracks were largely played by studio musicians. After 1967, the band's use of studio musicians was considerably reduced. Wrecking Crew biographer Kent Hartman supported in : \"Though [Brian Wilson] had for several months brought in various session players on a sporadic, potluck basis to supplement things, the other Beach Boys generally played on the earliest songs, too.\"\nThe source of the longstanding controversy regarding the Beach Boys' use of studio musicians largely derives from a misinterpreted statement in Leaf's 1978 biography \"The Beach Boys and the California Myth\", later bolstered by erroneous recollections from participants of the recording sessions. Starting in the 1990s, unedited studio session tapes, along with American Federation of Musicians (AFM) sheets and tape logs, were leaked. Music historian Craig Slowinski, who contributes musician credits to the liner notes of the band's reissues and compilations, wrote in 2006: \"[O]nce the vaults were opened up and the tapes were studied, the true situation became clear: the Boys themselves played \"most\" of the instruments on their records until the \"Beach Boys Today!\" album in early 1965.\" Slowinski goes on to note: \"when painting a picture of a Beach Boys recording session, it's important to examine \"both\" the AFM contracts and the session tapes, either of which may be incomplete on their own\".\nDuring the period when Brian relied heavily on studio musicians, Carl was an exception among the Beach Boys in that he played alongside the studio musicians whenever he was available to attend sessions. In Slowinski's view, \"One should not sell short Carl's own contributions; the youngest Wilson had developed as a musician sufficiently to play alongside the horde of high-dollar session pros that big brother was now bringing into the studio. Carl's guitar playing [was] a key ingredient.\"\nSpirituality.\nThe band members often reflected on the spiritual nature of their music (and music in general), particularly for the recording of \"Pet Sounds\" and \"Smile\". Even though the Wilsons did not grow up in a particularly religious household, Carl was described as \"the most truly religious person I know\" by Brian, and Carl was forthcoming about the group's spiritual beliefs stating: \"We believe in God as a kind of universal consciousness. God is love. God is you. God is me. God is everything right here in this room. It's a spiritual concept which inspires a great deal of our music.\" Carl told \"Rave\" magazine in 1967 that the group's influences are of a \"religious nature\", but not any religion in specific, only \"an idea based upon that of Universal Consciousness.\u00a0... The spiritual concept of happiness and doing good to others is extremely important to the lyric of our songs, and the religious element of some of the better church music is also contained within some of our new work.\"\nDuring the recording of \"Pet Sounds\", Brian held prayer meetings, later reflecting that \"God was with us the whole time we were doing this record\u00a0... I could feel that feeling in my brain.\" In 1966, he explained that he wanted to move into a white spiritual sound, and predicted that the rest of the music industry would follow suit. In 2011, Brian maintained the spirituality was important to his music, and that he did not follow any particular religion.\nCarl said that \"Smile\" was chosen as an album title because of its connection to the group's spiritual beliefs. Brian referred to \"Smile\" as his \"teenage symphony to God\", composing a hymn, \"Our Prayer\", as the album's opening spiritual invocation. Experimentation with psychotropic substances also proved pivotal to the group's development as artists. He spoke of his LSD trips as a \"religious experience\", and during a session for \"Our Prayer\", Brian can be heard asking the other Beach Boys: \"Do you guys feel any acid yet?\". In 1968, the group's interest in transcendental meditation led them to record the original song, \"Transcendental Meditation\".\nLegacy.\nAchievements.\nThe Beach Boys are one of the most critically acclaimed, commercially successful, and influential bands of all time. They have sold over 100 million records worldwide. The group's early songs made them major pop stars in the US, the UK, Australia and other countries, having seven top 10 singles between April 1963 and November 1964. They were one of the first American groups to exhibit the definitive traits of a self-contained rock band, playing their own instruments and writing their own songs, and they were one of the few American bands formed prior to the 1964 British Invasion to continue their success. Among artists of the 1960s, they are one of the central figures in the histories of rock. Between the 1960s and 2020s, they had 37 songs reach the US Top 40 (the most by an American group) with four topping the \"Billboard\" Hot 100; they also hold Nielsen SoundScan's record as the top-selling American band for albums and singles.\nBrian Wilson's artistic control over the Beach Boys' records was unprecedented for the time. Carl Wilson elaborated: \"Record companies were used to having absolute control over their artists. It was especially nervy, because Brian was a 21-year-old kid with just two albums. It was unheard of. But what could they say? Brian made good records.\" This made the Beach Boys one of the first rock groups to exert studio control. Music producers after the mid-1960s would draw on Brian's influence, setting a precedent that allowed bands and artists to enter a recording studio and act as producers, either autonomously, or in conjunction with other like minds.\nIn 1988, the original five members (the Wilson brothers, Love, and Jardine) were inducted into the Rock and Roll Hall of Fame. Ten years later, they were selected for the Vocal Group Hall of Fame. In 2004, \"Pet Sounds\" was preserved in the National Recording Registry by the Library of Congress for being \"culturally, historically, or aesthetically significant\". Their recordings of \"In My Room\", \"Good Vibrations\", \"California Girls\" and the entire \"Pet Sounds\" album have been inducted into the Grammy Hall of Fame.\nThe Beach Boys are one of the most influential acts of the rock era. In 2017, a study of AllMusic's catalog indicated the Beach Boys as the sixth most frequently cited artist influence in its database. In 2021, the staff of \"Ultimate Classic Rock\" ranked the Beach Boys as the top American band of all time; the publication's editor wrote in the group's entry that \"few bands\u00a0... have had a greater impact on popular music\".\nCalifornia sound.\nProfessor of cultural studies James M. Curtis wrote in 1987: We can say that the Beach Boys represent the outlook and values of white Protestant Anglo-Saxon teenagers in the early sixties. Having said that, we immediately realize that they must mean much more than this. Their stability, their staying power, and their ability to attract new fans prove as much. Historian Kevin Starr explains that the group first connected with young Americans specifically for their lyrical interpretation of a mythologized landscape: \"Cars and the beach, surfing, the California Girl, all this fused in the alembic of youth: Here was a way of life, an iconography, already half-released into the chords and multiple tracks of a new sound.\" In critic Robert Christgau's opinion, \"the Beach Boys were a touchstone for real rock and rollers, all of whom understood that the music had its most essential roots in an innocently hedonistic materialism\".\nThe group's \"California sound\" grew to prominence through the success of their 1963 album \"Surfin' U.S.A.\", which helped turn the surfing subculture into a mainstream youth-targeted advertising image exploited by the film, television, and food industry. The group's surf music was not entirely their invention, being preceded by artists such as Dick Dale. However, previous surf musicians did not project a world view as the Beach Boys did. The band's earlier surf music helped raise the profile of California, creating its first major regional style with national significance, and establishing a musical identity for Southern California, as opposed to Hollywood. California supplanted New York as the center of popular music thanks to the success of Brian's productions.\nA 1966 article discussing trends in rock music writes that the Beach Boys popularized a type of drum beat heard in Jan and Dean's \"Surf City\", which sounds like \"a locomotive getting up speed\", in addition to the method of \"suddenly stopping in between the chorus and verse\". Pete Townshend of the Who coined the term \"power pop\", which he defined as \"what we play\u2014what the Small Faces used to play, and the kind of pop the Beach Boys played in the days of 'Fun, Fun, Fun' which I preferred\".\nThe California sound evolved to reflect a more musically ambitious and mature worldview, becoming less to do with surfing and cars and more about social consciousness and political awareness. Throughout the 1960s, it fueled innovation and transition, inspiring artists to tackle largely unmentioned themes such as sexual freedom, black pride, drugs, oppositional politics, other countercultural motifs, and war. Soft pop, later known as \"sunshine pop\", derived in part from this movement. Sunshine pop producers imitated the orchestral style of \"Pet Sounds\"; however, the Beach Boys were rarely representative of the genre, which was rooted in easy listening and advertising jingles.\nBy the end of the 1960s, the California sound declined due to a combination of the West Coast's cultural shifts, Wilson's psychological downturn, and the Manson murders, with David Howard calling it the \"sunset of the original California Sunshine Sound\u00a0... [the] sweetness advocated by the California Myth had led to chilling darkness and unsightly rot\". Drawing from the Beach Boys' associations with Manson and former California governor Ronald Reagan, Erik Davis remarked: \"The Beach Boys may be the only bridge between those deranged poles. There is a wider range of political and aesthetic sentiments in their records than in any other band in those heady times\u2014like the state [of California], they expand and bloat and contradict themselves.\"\nDuring the 1970s, advertising jingles and imagery were predominately based on the Beach Boys' early music and image. The group inspired the development of the West Coast style later dubbed \"yacht rock\". According to \"Jacobin\"'s Dan O'Sullivan, the band's aesthetic was the first to be \"scavenged\" by yacht rock acts like Rupert Holmes. O'Sullivan cites the Beach Boys' recording of \"Sloop John B\" as the origin of yacht rock's preoccupation with the \"sailors and beachgoers\" aesthetic that was \"lifted by everyone, from Christopher Cross to Eric Carmen, from 'Buffalo Springfield' folksters like Jim Messina to 'Philly Sound' rockers like Hall &amp; Oates\".\nInnovations.\n\"Pet Sounds\" informed the development of pop, rock, jazz, electronic, experimental, punk, and hip-hop. Similar to subsequent experimental rock LPs by Frank Zappa, the Beatles, and the Who, \"Pet Sounds\" featured countertextural aspects that called attention to the very recordedness of the album. Professor John Robert Greene stated that the album broke new ground and took rock music away from its casual lyrics and melodic structures into then uncharted territory. He called it one factor which spawned the majority of trends in post-1965 rock music, the only others being \"Rubber Soul\", the Beatles' \"Revolver\", and the contemporary folk movement. The album was the first in popular music to incorporate the Electro-Theremin, an easier-to-play version of the theremin, as well as the first in rock music to feature a theremin-like instrument. With \"Pet Sounds\", they were the first group to make an entire album that departed from the usual small-ensemble electric rock band format.\nAccording to David Leaf in 1978, \"Pet Sounds\" and \"Good Vibrations\" \"established the group as the leaders of a new type of pop music, Art Rock\". Academic Bill Martin states that the band opened a path in rock music \"that went from \"Sgt. Pepper's\" to \"Close to the Edge\" and beyond\". He argues that the advancing technology of multitrack recording and mixing boards were more influential to experimental rock than electronic instruments such as the synthesizer, allowing the Beatles and Beach Boys to become the first crop of non-classically trained musicians to create extended and complex compositions. In \"Strange Sounds: Offbeat Instruments and Sonic Experiments in Pop\", Mark Brend writes:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Other artists and producers, notably the Beatles and Phil Spector, had used varied instrumentation and multi-tracking to create complex studio productions before. And others, like Roy Orbison, had written complicated pop songs before. But \"Good Vibrations\" eclipsed all that came before it, in both its complexity as a production and the liberties it took with conventional notions of how to structure a pop song. \nThe production of \"Good Vibrations\" was unprecedented in any prior genre or recording; Carlin wrote that it \"sounded like nothing that had ever been played on the radio before\". It contained previously untried mixes of instruments, and was the first successful pop song to have cellos in a juddering rhythm. Charlie Gillett called it \"one of the first records to flaunt studio production as a quality in its own right, rather than as a means of presenting a performance\". Brian used Electro-Theremin for the track. Upon release, the single prompted an unexpected revival in theremins while increasing awareness of analog synthesizers, leading Moog Music to produce their own brand of ribbon-controlled instruments. In a 1968 editorial for \"Jazz &amp; Pop\", Gene Sculatti predicted that the song \"may yet prove to be the most significantly revolutionary piece of the current rock renaissance\u00a0... In no minor way, 'Good Vibrations' is a primary influential piece for all producing rock artists; everyone has felt its import to some degree\".\nDiscussing \"Smiley Smile\", Daniel Harrison argues that the album could \"almost\" be considered art music in the Western classical tradition, and that the group's innovations in the language of rock can be compared to those that introduced atonal and other nontraditional techniques into that classical tradition. However, such notions were not widely acknowledged by rock audiences nor by the classically-minded at the time. Harrison concludes: \"What influences could these innovations then have? The short answer is, not much. \"Smiley Smile\", \"Wild Honey\", \"Friends\", and \"20/20\" sound like few other rock albums; they are \"sui generis\".\u00a0... It must be remembered that the commercial failure of the Beach Boys' experiments was hardly motivation for imitation.\" Musicologist David Toop placed the Beach Boys' innovations alongside Les Baxter, Aphex Twin, Herbie Hancock, King Tubby, and My Bloody Valentine.\n\"Sunflower\" marked an end to the experimental songwriting and production phase initiated by \"Smiley Smile\". After \"Surf's Up\", Harrison wrote, their albums \"contain a mixture of middle-of-the-road music entirely consonant with pop style during the early 1970s with a few oddities that proved that the desire to push beyond conventional boundaries was not dead\", until 1974, \"the year in which the Beach Boys ceased to be a rock 'n' roll act and became an oldies act\".\nPunk, alternative, and indie.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\n For the artier branches of post-punk, Wilson's pained vulnerability, his uses of offbeat instruments and his intricate harmonies, not to mention the \"Smile\" saga itself, became a touchstone, from Pere Ubu and XTC to REM [\"sic\"] and the Pixies to U2 and My Bloody Valentine.\n \u2014 Music critic Carl Wilson (no relation to Beach Boys member Carl Wilson)\nIn the 1970s, the Beach Boys served a \"totemic influence\" on punk rock that later gave way to indie rock. Brad Shoup of Stereogum surmised that, thanks to the Ramones' praise for the group, many punk, pop punk, or \"punk-adjacent\" artists showed influence from the Beach Boys, noting cover versions of the band's songs recorded by Slickee Boys, Agent Orange, Bad Religion, Shonen Knife, the Queers, Hi-Standard, the Descendents, the Donnas, M.O.D., and the Vandals. \"The Beach Boys Love You\" is sometimes considered the group's \"punk album\", and \"Pet Sounds\" is sometimes advanced as the first emo album.\nIn the 1990s, the Beach Boys experienced a resurgence of popularity with the alternative rock generation. According to Sean O'Hagan, leader of the High Llamas and former member of Stereolab, a younger generation of record-buyers \"stopped listening to indie records\" in favor of the Beach Boys. Bands who advocated for the Beach Boys included founding members of the Elephant 6 Collective (Neutral Milk Hotel, the Olivia Tremor Control, the Apples in Stereo, and of Montreal). United by a shared love of the group's music, they named Pet Sounds Studio in honor of the band. \"Rolling Stone\" writer Barry Walters wrote in 2000 that albums such as \"Surf's Up\" and \"Love You\" \"are becoming sonic blueprints, akin to what early Velvet Underground LPs meant to the previous indie peer group\". The High Llamas, Eric Matthews and Saint Etienne are among the \"alt heroes\" who contributed cover versions of \"unreleased, overlooked or underappreciated Wilson/Beach Boys obscurities\" on the tribute album \"Caroline Now!\" (2000).\nThe Beach Boys remained among the most significant influences on indie rock into the late 2000s. \"Smile\" became a touchstone for many bands who were labelled \"chamber pop\", a term used for artists influenced by the lush orchestrations of Brian Wilson, Lee Hazlewood, and Burt Bacharach. \"Pitchfork\" writer Mark Richardson cited \"Smiley Smile\" as the origin point of \"the kind of lo-fi bedroom pop that would later propel Sebadoh, Animal Collective, and other characters\". The \"Sunflower\" track \"All I Wanna Do\" is also cited as one of the earliest precursors to chillwave, a microgenre that emerged in 2009.\nDiscography.\nStudio albums.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nPrint sources.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nFurther reading.\nArticles\nBooks\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "4479", "revid": "44062", "url": "https://en.wikipedia.org/wiki?curid=4479", "title": "BCE (disambiguation)", "text": "BCE is an abbreviation meaning Before Common Era, an alternative to the use of BC.\nBCE, B.C.E. or bce may also refer to:\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "4480", "revid": "50564054", "url": "https://en.wikipedia.org/wiki?curid=4480", "title": "BC", "text": "BC most often refers to:\nBC may also refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "4481", "revid": "38455", "url": "https://en.wikipedia.org/wiki?curid=4481", "title": "Beatrix Potter", "text": "English writer and illustrator (1866\u20131943)\nHelen Beatrix Heelis (n\u00e9e\u00a0Potter; 28 July 1866\u00a0\u2013 22 December 1943), usually known as Beatrix Potter ( ), was an English writer, illustrator, natural scientist, and conservationist. She is best known for her children's books featuring animals, such as \"The Tale of Peter Rabbit\", which was her first commercially published work in 1902. Her books, including \"The Tale of Jemima Puddle Duck\" and \"The Tale of Tom Kitten\", have sold more than 250 million copies. An entrepreneur, Potter was a pioneer of character merchandising. In 1903, Peter Rabbit was the first fictional character to be made into a patented stuffed toy, making him the oldest licensed character.\nBorn into an upper-middle-class household, Potter was educated by governesses and grew up isolated from other children. She had numerous pets and spent holidays in Scotland and the Lake District, developing a love of landscape, flora and fauna, all of which she closely observed and painted. Potter's study and watercolours of fungi led to her being widely respected in the field of mycology. In her thirties, Potter self-published the highly successful children's book \"The Tale of Peter Rabbit\". Following this, Potter began writing and illustrating children's books full-time.\nPotter wrote over sixty books, with the best known being her twenty-three children's tales. In 1905, using the proceeds from her books and a legacy from an aunt, Potter bought Hill Top Farm in Near Sawrey, a village in the Lake District. Over the following decades, she purchased additional farms to preserve the unique hill country landscape. In 1913, at the age of 47, she married William Heelis (1871\u20131945), a respected local solicitor with an office in Hawkshead. Potter was also a prize-winning breeder of Herdwick sheep and a prosperous farmer keenly interested in land preservation. She continued to write, illustrate, and design merchandise based on her children's books for British publisher Warne until the duties of land management and her diminishing eyesight made it difficult to continue.\nPotter died of pneumonia and heart disease on 22 December 1943 at her home in Near Sawrey at the age of 77, leaving almost all her property to the National Trust. She is credited with preserving much of the land that now constitutes the Lake District National Park. Potter's books continue to sell throughout the world in many languages with her stories being retold in songs, films, ballet, and animations, and her life is depicted in two films \u2013 \"The Tales of Beatrix Potter\" (1983) and \"Miss Potter\" (2006).\nBiography.\nEarly life.\nPotter's family on both sides were from the Manchester area. They were English Unitarians, associated with dissenting Protestant congregations, influential in 19th-century Britain, that affirmed the oneness of God and that rejected the doctrine of the Trinity. Potter's paternal grandfather, Edmund Potter, from Glossop in Derbyshire, owned what was then the largest calico printing works in England, and later served as a Member of Parliament.\nPotter's father, Rupert William Potter (1832\u20131914), was educated at Manchester College by the Unitarian philosopher James Martineau. He then trained as a barrister in London. Rupert practiced law, specialising in equity law and conveyancing. He married Helen Leech (1839\u20131932) on 8 August 1863 at Hyde Unitarian Chapel, Gee Cross. Helen was the daughter of Jane Ashton (1806\u20131884) and John Leech, a wealthy cotton merchant and shipbuilder from Stalybridge. Helen's first cousins were siblings Harriet Lupton (\"n\u00e9e\" Ashton) and Thomas Ashton, 1st Baron Ashton of Hyde. It was reported in July 2014 that Potter had personally given a number of her own original hand-painted illustrations to the two daughters of Arthur and Harriet Lupton, who were cousins to both Beatrix Potter and Catherine, Princess of Wales.\nPotter's parents lived comfortably at 2 Bolton Gardens, West Brompton, London, where Helen Beatrix was born on 28 July 1866 and her brother Walter Bertram on 14 March 1872. The house was destroyed in the Blitz. Bousfield Primary School now stands where the house once was. A blue plaque on the school building testifies to the former site of the Potter home. Both parents were artistically talented, and Rupert was an adept amateur photographer. Rupert had invested in the stock market, and by the early 1890s, he was extremely wealthy.\nBeatrix Potter was educated by three governesses, the last of whom was Annie Moore (\"n\u00e9e\" Carter), just three years older than Potter, who tutored Potter in German as well as acting as lady's companion. She and Potter remained friends throughout their lives, and Annie's eight children were the recipients of many of Potter's picture letters. It was Annie who later suggested that these letters might make good children's books.\nShe and her younger brother Walter Bertram (1872\u20131918) grew up with few friends outside their large extended family. Her parents were artistic, interested in nature, and enjoyed the countryside. As children, Potter and Bertram had numerous small animals as pets which they observed closely and drew endlessly. In their schoolroom, Potter and Bertram kept a variety of small pets\u2014mice, rabbits, a hedgehog and some bats, along with collections of butterflies and other insects\u2014which they drew and studied. Potter was devoted to the care of her small animals, often taking them with her on long holidays. In most of the first fifteen years of her life, Potter spent summer holidays at Dalguise, an estate on the River Tay in Perthshire, Scotland. There she sketched and explored an area that nourished her imagination and her observation. Her first sketchbook from those holidays, kept at age 8 and dated 1875, is held at and has been digitised by the Victoria &amp; Albert Museum, London. Potter and her brother were allowed great freedom in the country, and both children became adept students of natural history. In 1882, when Dalguise was no longer available, the Potters took their first summer holiday in the Lake District, at Wray Castle near Lake Windermere. Here Potter met Hardwicke Rawnsley, vicar of Wray and later the founding secretary of the National Trust, whose interest in the countryside and country life inspired the same in Potter and who was to have a lasting impact on her life.\nAt about the age of 14, Potter began to keep a diary, written in a simple substitution cipher of her own devising. Her \"Journal\" was important to the development of her creativity, serving as both sketchbook and literary experiment. In tiny handwriting, she reported on society, recorded her impressions of art and artists, recounted stories and observed life around her. The \"Journal\", deciphered and transcribed by Leslie Linder in 1958, does not provide an intimate record of her personal life, but it is an invaluable source for understanding a vibrant part of British society in the late 19th century. It describes Potter's maturing artistic and intellectual interests, her often amusing insights into the places she visited, and her unusual ability to observe nature and to describe it. Started in 1881, her journal ends in 1897 when her artistic and intellectual energies were absorbed in scientific study and in efforts to publish her drawings. Precocious but reserved and often bored, she was searching for more independent activities and wished to earn some money of her own while dutifully taking care of her parents, dealing with her especially demanding mother, and managing their various households.\nScientific illustrations and work in mycology.\nIn the Victorian era, women of her class were privately educated and rarely went to university. Potter's parents encouraged her higher education, but the social norms of the time limited her academic career within Britain's institutions.\nBeatrix Potter was interested in every branch of natural science except astronomy. Botany was a passion for most Victorians, and nature study was a popular enthusiasm. She collected fossils, studied archaeological artefacts from London excavations, and was interested in entomology. In all these areas, she drew and painted her specimens with increasing skill. By the 1890s, her scientific interests centred on mycology. First drawn to fungi because of their colours and evanescence in nature and her delight in painting them, her interest deepened after meeting Charles McIntosh, a revered naturalist and amateur mycologist, during a summer holiday in Dunkeld in Perthshire in 1892. He helped improve the accuracy of her illustrations, taught her taxonomy, and supplied her with live specimens to paint during the winter. &lt;onlyinclude&gt;&lt;/onlyinclude&gt;\nRebuffed by William Thiselton-Dyer, the Director at Kew, because of her sex and amateur status, Potter wrote up her conclusions and submitted a paper, \"On the Germination of the Spores of the Agaricineae\", to the Linnean Society in 1897. It was introduced by Massee because, as a woman, Potter could not attend proceedings nor read her paper. She subsequently withdrew it, realising that some of her samples were contaminated, but continued her microscopic studies for several more years. Her work is only now being properly evaluated. Potter later gave her other mycological and scientific drawings to the Armitt Museum and Library in Ambleside, where mycologists still refer to them to identify fungi. There is also a collection of her fungus paintings at the Perth Museum and Art Gallery in Perth, Scotland, donated by Charles McIntosh. In 1967, the mycologist W. P. K. Findlay included many of Potter's beautifully accurate fungus drawings in his \"Wayside &amp; Woodland Fungi\", thereby fulfilling her desire to one day have her fungus drawings published in a book. In 1997, the Linnean Society issued a posthumous apology to Potter for the sexism displayed in its handling of her research.\nArtistic and literary career.\nPotter's artistic and literary interests were deeply influenced by fairy tales and fantasy. She was a student of the classic fairy tales of Western Europe as well as stories from the Old Testament, John Bunyan's \"The Pilgrim's Progress\" and Harriet Beecher Stowe's \"Uncle Tom's Cabin\". She grew up with \"Aesop's Fables\", the fairy tales of the Brothers Grimm and Hans Christian Andersen, Charles Kingsley's \"The Water Babies\", the folk tales and mythology of Scotland, the German Romantics, Shakespeare, and the romances of Sir Walter Scott. As a young child, before the age of eight, Edward Lear's \"\", including the much-loved \"The Owl and the Pussycat\", and Lewis Carroll's \"Alice in Wonderland\" had made their impression, although she later said of \"Alice\" that she was more interested in Tenniel's illustrations than what they were about.\nThe \"Brer Rabbit\" stories of Joel Chandler Harris had been family favourites, and she later studied his \"Uncle Remus\" stories and illustrated them. She studied book illustration from a young age and developed her own tastes, but the work of the picture book triumvirate Walter Crane, Kate Greenaway and Randolph Caldecott, the last an illustrator whose work was later collected by her father, was a great influence. Her earliest illustrations focused on traditional rhymes and stories like \"Cinderella\", \"Sleeping Beauty\", \"Ali Baba and the Forty Thieves\", \"Puss in Boots\", and \"Little Red Riding Hood\". However, most often her illustrations were fantasies featuring her own pets: mice, rabbits, kittens, and guinea pigs.\nIn her teenage years, Potter was a regular visitor to the art galleries of London, particularly enjoying the summer and winter exhibitions at the Royal Academy in London. Her \"Journal\" reveals her growing sophistication as a critic as well as the influence of her father's friend, the artist Sir John Everett Millais, who recognised Potter's talent of observation. Although Potter was aware of art and artistic trends, her drawing and her prose style were uniquely her own.\nAs a way to earn money in the 1890s, Potter printed Christmas cards of her own design, as well as cards for special occasions. These were her first commercially successful works as an illustrator. Mice and rabbits were the most frequent subject of her fantasy paintings. In 1890, the firm of Hildesheimer and Faulkner bought several of the drawings of her rabbit Benjamin Bunny to illustrate verses by Frederic Weatherly titled \"A Happy Pair\". In 1893, the same printer bought several more drawings for Weatherly's \"Our Dear Relations\", another book of rhymes, and the following year Potter sold a series of frog illustrations and verses for \"Changing Pictures\", a popular annual offered by the art publisher Ernest Nister. Potter was pleased by this success and determined to publish her own illustrated stories.\nWhenever Potter went on holiday to the Lake District or Scotland, she sent letters to young friends, illustrating them with quick sketches. Many of these letters were written to the children of her former governess Annie Carter Moore, particularly to Moore's eldest son Noel, who was often ill. In September 1893, Potter was on holiday at Eastwood in Dunkeld, Perthshire. She had run out of things to say to Noel, and so she told him a story about \"four little rabbits whose names were Flopsy, Mopsy, Cottontail, and Peter\". It became one of the most famous children's letters ever written and the basis of Potter's future career as a writer-artist-storyteller.\nIn 1900, Potter revised her tale about the four little rabbits, and fashioned a dummy book of it \u2013 it has been suggested, in imitation of Helen Bannerman's 1899 bestseller \"The Story of Little Black Sambo\". Unable to find a buyer for the work, she published it for family and friends at her own expense in December 1901. It was drawn in black and white with a coloured frontispiece. Rawnsley had great faith in Potter's tale, recast it in didactic verse, and made the rounds of the London publishing houses. Frederick Warne &amp; Co had previously rejected the tale but, eager to compete in the booming small format children's book market, reconsidered and accepted the \"bunny book\" (as the firm called it) following the recommendation of their prominent children's book artist L. Leslie Brooke. The firm declined Rawnsley's verse in favour of Potter's original prose, and Potter agreed to colour her pen and ink illustrations, choosing the new Hentschel three-colour process to reproduce her watercolours.\nOn 2 October 1902, \"The Tale of Peter Rabbit\" was published and became an immediate success. It was followed the next year by \"The Tale of Squirrel Nutkin\" and \"The Tailor of Gloucester\", which had also first been written as picture letters to the Moore children. Working with Norman Warne as her editor, Potter published two or three little books each year: 23 books in all. The last book in this format was \"Cecily Parsley's Nursery Rhymes\" in 1922, a collection of favourite rhymes. Although \"The Tale of Little Pig Robinson\" was not published until 1930, it had been written much earlier. Potter continued creating her little books until after the First World War when her energies were increasingly directed toward her farming, sheep-breeding, and land conservation.\nThe immense popularity of Potter's books was based on the lively quality of her illustrations, the non-didactic nature of her stories, the depiction of the rural countryside, and the imaginative qualities she lent to her animal characters.\nPotter was also a canny businesswoman. As early as 1903, she made and patented a Peter Rabbit doll. It was followed by other merchandise over the years, including painting books, board games, wall-paper, figurines, baby blankets and china tea-sets. All were licensed by Frederick Warne &amp; Co and earned Potter an independent income, as well as immense profits for her publisher.\nIn 1905, Potter and Norman Warne became unofficially engaged. Potter's parents objected to the match because Warne was \"in trade\" and thus not socially suitable. The engagement lasted only one month\u2014Warne died of pernicious anaemia at age 37. That same year, Potter used some of her income and a small inheritance from an aunt to buy Hill Top Farm in Near Sawrey, located west of Lake Windermere in the English Lake District. Potter and Warne may have hoped that Hill Top Farm would be their holiday home, but after Warne's death, Potter went ahead with its purchase as she had always wanted to own that farm and live in \"that charming village\".\nCountry life and marriage.\nThe tenant farmer John Cannon and his family agreed to stay on to manage the farm for her while she made physical improvements and learned the techniques of fell farming and of raising livestock, including pigs, cows and chickens; the following year she added sheep. Realising she needed to protect her boundaries, she sought advice from W.H. Heelis &amp; Son, a local firm of solicitors with offices in nearby Hawkshead. With William Heelis acting for her, she bought contiguous pasture, and in 1909 the Castle Farm across the road from Hill Top Farm. She visited Hill Top at every opportunity, and her books written during this period (such as \"The Tale of Ginger and Pickles\", about the local shop in Near Sawrey and \"The Tale of Mrs. Tittlemouse\", a wood mouse) reflect her increasing participation in village life and her delight in country living.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\n\"Hill Top is to be presented to my visitors as if I had just gone out and they had just missed me.\"\n\u2014Statement by Potter in her will to the National Trust.\nOwning and managing these working farms required routine collaboration with the widely respected William Heelis. By the summer of 1912, Heelis had proposed marriage and Potter had accepted; although she did not immediately tell her parents, who once again disapproved because Heelis was only a country solicitor. Potter and Heelis were married on 15 October 1913 in London at St Mary Abbots in Kensington. The couple moved immediately to Near Sawrey, residing at Castle Cottage, the renovated farmhouse on Castle Farm, which was large. Hill Top remained a working farm but was now remodelled to allow for the tenant family and Potter's private studio and workshop. At last her own woman, Potter settled into the partnerships that shaped the rest of her life: her country solicitor husband and his large family, her farms, the Sawrey community and the predictable rounds of country life. \"The Tale of Jemima Puddle-Duck\" and \"The Tale of Tom Kitten\" are representative of Hill Top Farm and her farming life and reflect her happiness with her country life.\nHer father, Rupert Potter, died in 1914, and with the outbreak of World War I, Potter persuaded her mother to move to the Lake District, renting her a property in Sawrey. Finding life in Sawrey dull, Helen Potter soon moved to Lindeth Howe (now a 34-bedroomed hotel), a large house the Potters had previously rented for the summer in Bowness, on the other side of Lake Windermere. Potter continued to write stories for Frederick Warne &amp; Co and fully participated in country life. She established a nursing trust for local villages and served on various committees and councils responsible for footpaths and other rural issues.\nSheep farming.\nSoon after acquiring Hill Top Farm, Potter became keenly interested in the breeding and raising of Herdwick sheep, the indigenous fell sheep. In 1923 she bought a large sheep farm in the Troutbeck Valley called Troutbeck Park Farm, formerly a deer park, restoring its land with thousands of Herdwick sheep. This established her as one of the major Herdwick sheep farmers in the county. She was admired by her shepherds and farm managers for her willingness to experiment with the latest biological remedies for the common diseases of sheep, and for her employment of the best shepherds, sheep breeders, and farm managers.\nBy the late 1920s, Potter and her Hill Top farm manager Tom Storey had made a name for their prize-winning Herdwick flock, which took many prizes at the local agricultural shows, where Potter was often asked to serve as a judge. In 1942 she became President-elect of the Herdwick Sheepbreeders' Association, the first time a woman had been elected, but died before taking office.\nWelsh language.\nIn one of her diary entries whilst travelling through Wales, Potter complained about the Welsh language. She wrote \"Machynlleth, wretched town, hardly a person could speak English\", continuing \"Welsh seem a pleasant intelligent race, but I should think awkward to live with... the language is past description.\"\nLake District conservation.\nPotter had been a disciple of the land conservation and preservation ideals of her long-time friend and mentor, Canon Hardwicke Rawnsley, the first secretary and founding member of the National Trust. According to the National Trust, \"she supported the efforts of the National Trust to preserve not just the places of extraordinary beauty but also those heads of valleys and low grazing lands that would be irreparably ruined by development.\" Potter was also an authority on the traditional Lakeland crafts and period furniture, as well as local stonework. She restored and preserved the farms that she bought or managed, making sure that each farm house had in it a piece of antique Lakeland furniture. Potter was interested in preserving not only the Herdwick sheep but also the way of life of fell farming. In 1930 the Heelises became partners with the National Trust in buying and managing the fell farms included in the large Monk Coniston Estate.\nThe estate was composed of many farms spread over a wide area of north-western Lancashire, including the Tarn Hows. Potter was the \"de facto\" estate manager for the Trust for seven years until the National Trust could afford to repurchase most of the property from her. Potter's stewardship of these farms earned her full regard, but she was not without her critics, not the least of which were her contemporaries who felt she used her wealth and the position of her husband to acquire properties in advance of their being made public. She was notable in observing the problems of afforestation, preserving the intact grazing lands, and husbanding the quarries and timber on these farms. All her farms were stocked with Herdwick sheep and frequently with Galloway cattle.\nLater life.\nPotter continued to write stories and to draw, although mostly for her own pleasure. In 1922, \"Cecily Parsley's Nursery Rhymes\", a collection of traditional English nursery rhymes, was published. Her books in the late 1920s included the semi-autobiographical \"The Fairy Caravan\", a fanciful tale set in her beloved Troutbeck fells. It was published only in the US during Potter's lifetime, and not until 1952 in the UK. \"Sister Anne\", Potter's version of the story of Bluebeard, was written for her American readers, but illustrated by Katharine Sturges. A final folktale, \"Wag by Wall\", was published posthumously by \"The Horn Book Magazine\" in 1944. Potter was a generous patron of the Girl Guides, whose troops she allowed to make their summer encampments on her land, and whose company she enjoyed as an older woman.\nPotter and William Heelis enjoyed a happy marriage of thirty years, continuing their farming and preservation efforts throughout the hard days of World War II. Although they were childless, Potter played an important role in William's large family, particularly enjoying her relationship with several nieces whom she helped educate, and giving comfort and aid to her husband's brothers and sisters.\nPotter died of complications from pneumonia and heart disease on 22 December 1943 at Castle Cottage, and her remains were cremated at Carleton Crematorium, Blackpool. She left nearly all her property to the National Trust, including over of land, sixteen farms, cottages and herds of cattle and Herdwick sheep. Hers was the largest gift at that time to the National Trust, and it enabled the preservation of the land now included in the Lake District National Park and the continuation of fell farming. The central office of the National Trust in Swindon was named \"Heelis\" in 2005 in her memory. William Heelis continued his stewardship of their properties and of her literary and artistic work for the twenty months he survived her. When he died in August 1945, he left the remainder to the National Trust.\nLegacy.\nPotter left almost all the original illustrations for her books to the National Trust. The copyright to her stories and merchandise was then given to her publisher Frederick Warne &amp; Co, now a division of the Penguin Group. On 1 January 2014, the copyright expired in the UK and other countries with a 70-years-after-death limit. Hill Top Farm was opened to the public by the National Trust in 1946; her artwork was displayed there until 1985 when it was moved to William Heelis's former law offices in Hawkshead, also owned by the National Trust as the Beatrix Potter Gallery.\nPotter gave her folios of mycological drawings to the Armitt Library and Museum in Ambleside before her death. \"The Tale of Peter Rabbit\" is owned by Warne, \"The Tailor of Gloucester\" by the Tate Gallery, and \"The Tale of the Flopsy Bunnies\" by the British Museum.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Beatrix Potter was the first to recognise that content\u2014as we now call the stuff that makes up a book or a film\u2014was only the beginning. In 1903, Peter hopped outside his pages to become a patented soft toy, which gave him the distinction of being not only Mr. McGregor\u2018s mortal enemy, but also becoming the first licensed character.\u2014\u200a\nIn 1903, Potter created the first Peter Rabbit soft toy and registered him at the Patent Office in London, making Peter the oldest licensed fictional character. Merchandise of Peter and other Potter characters have been sold at Harrods department store in London since at least 1910 when the range first appeared in their catalogues. Along with her writing Potter would continue to oversee merchandising and licensing opportunities for her characters. On her legacy, Nicholas Tucker in \"The Guardian\" writes, \"she was the first author to license fictional characters to a range of toys and household objects still on sale today\". In an article by the \"Smithsonian\" magazine titled, \"How Beatrix Potter Invented Character Merchandising\", Joy Lanzendorfer writes, \"Potter was also an entrepreneur and a pioneer in licensing and merchandising literary characters. Potter built a retail empire out of her \u201cbunny book\u201d that is worth $500 million today. In the process, she created a system that continues to benefit all licensed characters, from Mickey Mouse to Harry Potter.\"\nThe largest public collection of her letters and drawings is the Leslie Linder Bequest and Leslie Linder Collection at the Victoria and Albert Museum in London. (Linder was the collector who\u2014after five years of work\u2014finally transcribed Potter's early journal, originally written in code.) In the United States, the largest public collections are those in the Rare Book Department of the Free Library of Philadelphia, and the Cotsen Children's Library at Princeton University.\nIn 2015, a manuscript for an unpublished book was discovered by Jo Hanks, a publisher at Penguin Random House Children's Books, in the Victoria and Albert Museum archive. The book \"The Tale of Kitty-in-Boots\", with illustrations by Quentin Blake, was published 1 September 2016, to mark the 150th anniversary of Potter's birth. Also in 2016, Peter Rabbit was depicted on the reverse of a British fifty pence coin, and Peter along with other Potter characters featured on a series of UK postage stamps issued by the Royal Mail.\nIn 2017, \"The Art of Beatrix Potter: Sketches, Paintings, and Illustrations\" by Emily Zach was published after San Francisco publisher Chronicle Books decided to mark the 150th anniversary of Beatrix Potter's birth by showing that she was \"far more than a 19th-century weekend painter. She was an artist of astonishing range.\"\nIn December 2017, the asteroid 13975 Beatrixpotter, discovered by Belgian astronomer Eric Elst in 1992, was renamed in her memory. In 2022, an exhibition, \"Beatrix Potter: Drawn to Nature\", was held at the Victoria and Albert Museum. Research for the exhibition identified the man's court waistcoat c. 1780s, which inspired Potter's sketch in \"The Tailor of Gloucester\". In 2024, the exhibition traveled to the Morgan Library &amp; Museum.\nAnalysis.\nThere are many interpretations of Potter's literary work, the sources of her art, and her life and times. These include critical evaluations of her corpus of children's literature and Modernist interpretations of Humphrey Carpenter and Katherine Chandler. Judy Taylor, \"That Naughty Rabbit: Beatrix Potter and Peter Rabbit\" (rev. 2002) tells the story of the first publication and many editions.\nPotter's country life, her farming and role as a landscape preservationist are discussed in the work of Matthew Kelly, \"The Women Who Saved the English Countryside\" (2022). See also Susan Denyer and authors in the publications of The National Trust, such as \"Beatrix Potter at Home in the Lake District\" (2004).\nPotter's work as a scientific illustrator and her work in mycology are discussed in Linda Lear's books \"Beatrix Potter: A Life in Nature\" (2006) and \"Beatrix Potter: The Extraordinary Life of a Victorian Genius\" (2008).\nAdaptations.\nIn 1971, a ballet film was released, \"The Tales of Beatrix Potter\", directed by Reginald Mills, set to music by John Lanchbery with choreography by Frederick Ashton, and performed in character costume by members of the Royal Ballet and the Royal Opera House orchestra. The ballet of the same name has been performed by other dance companies around the world.\nIn 1992, Potter's children's book \"The Tale of Benjamin Bunny\" was featured in the film \"Lorenzo's Oil\".\nPotter is also featured in Susan Wittig Albert's series of light mysteries called \"The Cottage Tales of Beatrix Potter\". The first of the eight-book series is \"Tale of Hill Top Farm\" (2004), which deals with Potter's life in the Lake District and the village of Near Sawrey between 1905 and 1913.\nIn film.\nIn 1982, the BBC produced \"The Tale of Beatrix Potter\". This dramatization of her life was written by John Hawkesworth, directed by Bill Hayes, and starred Holly Aird and Penelope Wilton as the young and adult Potter, respectively. \"The World of Peter Rabbit and Friends\", a TV series based on fourteen of her twenty-four stories, starred actress Niamh Cusack as Beatrix Potter.\nIn 1993, Weston Woods Studios made an almost hour non-story film called \"Beatrix Potter: Artist, Storyteller, and Countrywoman\" with narration by Lynn Redgrave. In 2006, Chris Noonan directed \"Miss Potter\", a biographical film of Potter's life focusing on her early career and romance with her editor Norman Warne. The film stars Ren\u00e9e Zellweger as Beatrix Potter, Ewan McGregor as Norman Warne, and Emily Watson as Warne's sister.\nOn 9 February 2018, Columbia Pictures released \"Peter Rabbit\", directed by Will Gluck, based on the work by Potter. The character Bea, played by Rose Byrne, is a re-imagined version of Potter. A sequel to the film titled \" was released in 2021.\nOn 24 December 2020, Sky One premiered \", a made-for-television drama film inspired by the true story of a six-year-old Roald Dahl meeting his idol Potter. Set in 1922, the movie was written by Abigail Wilson, directed by David Kerr and starred Dawn French as Beatrix Potter, Rob Brydon as William Heelis and Jessica Hynes as Sofie Dahl. Filming took place in Wales, the birthland of Dahl, French and Brydon. This production incorporates live action, stop motion, and puppetry. The DVD was released on 26 April 2021.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "4482", "revid": "5957417", "url": "https://en.wikipedia.org/wiki?curid=4482", "title": "Liberal Party (UK)", "text": "Political party in the United Kingdom from 1859 to 1988\nThe Liberal Party was one of the two major political parties in the United Kingdom, along with the Conservative Party, in the 19th and early 20th centuries. Beginning as an alliance of Whigs, free trade\u2013supporting Peelites, and reformist Radicals in the 1850s, by the end of the 19th century, it had formed four governments under William Ewart Gladstone. Despite being divided over the issue of Irish Home Rule, the party returned to government in 1905 and won a landslide victory in the 1906 general election. Under prime ministers Henry Campbell-Bannerman (1905\u20131908) and H. H. Asquith (1908\u20131916), the Liberal Party passed reforms that created a basic welfare state. Although Asquith was the party leader, its dominant figure was David Lloyd George. \nAsquith was overwhelmed by his wartime role as prime minister and Lloyd George led a coalition that replaced him in late 1916. However, Asquith remained as Liberal Party leader. The split between Lloyd George's breakaway faction and Asquith's official Liberal faction badly weakened the party. The coalition government of Lloyd George was increasingly dominated by the Conservative Party, which finally ousted him as prime minister in 1922. The subsequent Liberal collapse was quick and catastrophic. With 400 MPs elected in the 1906 election; they had only 40 in 1924. Their share of the popular vote plunged from 49% to 18%. The Labour Party absorbed most of the ex-Liberal voters and then became the Conservatives' main rival. \nBy the 1950s, the party had won as few as six seats at general elections. Apart from a few notable by-election victories, its fortunes did not improve significantly until it formed the SDP\u2013Liberal Alliance with the newly formed Social Democratic Party (SDP) in 1981. At the 1983 general election, the Alliance won over a quarter of the vote, but won only 23 of the 633 seats it contested. At the 1987 general election, its share of the vote fell below 23%. Further, the Liberals and the SDP merged in 1988 to form the Social and Liberal Democrats (SLD), who the following year were renamed the Liberal Democrats. A splinter group reconstituted the Liberal Party in 1989.\nThe Liberals were a coalition with diverse positions on major issues and no unified national policy. This made them repeatedly liable to deep splits, such as that of the Liberal Unionists in 1886 (they eventually joined the Conservative Party); the faction of labour union members that joined the new Labour Party; the split between factions led by Asquith and that led by Lloyd George in 1918\u20131922; and a three-way split in 1931. Many prominent intellectuals were active in the party, including philosopher John Stuart Mill, economist John Maynard Keynes, and social planner William Beveridge. Winston Churchill during his years as a Liberal (1904\u20131924) authored \"Liberalism and the Social Problem\" (1909).\nHistory.\nOrigins.\nThe Liberal Party grew out of the Whigs, who had their origins in an aristocratic faction in the reign of Charles II and the early 19th century Radicals. The Whigs were in favour of reducing the power of the Crown and increasing the power of Parliament. Although their motives in this were originally to gain more power for themselves, the more idealistic Whigs gradually came to support an expansion of democracy for its own sake. The great figures of reformist Whiggery were Charles James Fox (died 1806) and his disciple and successor Earl Grey. After decades in opposition, the Whigs returned to power under Grey in 1830 and carried the First Reform Act in 1832.\nThe Reform Act was the climax of Whiggism, but it also brought about the Whigs' demise. The admission of the middle classes to the franchise and to the House of Commons led eventually to the development of a systematic middle-class liberalism and the end of Whiggery, although for many years reforming aristocrats held senior positions in the party. In the years after Grey's retirement, the party was led first by Lord Melbourne, a fairly traditional Whig, and then by Lord John Russell, the son of a Duke but a crusading radical, and by Lord Palmerston, a renegade Irish Tory and essentially a conservative, although capable of radical gestures.\nAs early as 1839, Russell had adopted the name of \"Liberals\"; in reality, his party was a loose coalition of Whigs in the House of Lords and Radicals in the Commons. The leading Radicals were John Bright and Richard Cobden, who represented the manufacturing towns which had gained representation under the Reform Act. They favoured social reform, personal liberty, reducing the powers of the Crown and the Church of England (many Liberals were Nonconformists), avoidance of war and foreign alliances (which were bad for business) and above all free trade. For a century, free trade remained the one cause which could unite all Liberals.\nIn 1841, the Liberals lost office to the Conservatives under Sir Robert Peel. However, their period in opposition was short because the Conservatives split over the repeal of the Corn Laws, a free trade issue; and a faction known as the Peelites (but not Peel himself, who died soon after) aligned to the Liberal side on the issue of free trade. This allowed ministries led by Russell, Palmerston and the Peelite Lord Aberdeen to hold office for most of the 1850s and 1860s. A leading Peelite was William Gladstone, who was a reforming Chancellor of the Exchequer in most of these governments. The formal foundation of the Liberal Party is traditionally traced to 1859 when the remaining Peelites, Radicals and Whigs agreed to vote down the incumbent Conservative government. This meeting was held at the Willis' rooms in London on 6 June 1859. This led to Palmerston's second government.\nHowever, the Whig-Radical amalgam could not become a true modern political party while it was dominated by aristocrats and it was not until the departure of the \"Two Terrible Old Men\", Russell and Palmerston, that Gladstone could become the first leader of the modern Liberal Party. This was brought about by Palmerston's death in 1865 and Russell's retirement in 1868. After a brief Conservative government (during which the Second Reform Act was passed by agreement between the parties), Gladstone won a huge victory at the 1868 election and formed the first Liberal government. The establishment of the party as a national membership organisation came with the foundation of the National Liberal Federation in 1877. The philosopher John Stuart Mill was also a Liberal MP from 1865 to 1868.\nGladstone era.\nFor the next 30 years, Gladstone and Liberalism were synonymous. William Gladstone served as prime minister four times (1868\u201374, 1880\u201385, 1886, and 1892\u201394). His financial policies, based on the notion of balanced budgets, low taxes and \"laissez-faire\", were suited to a developing capitalist society, but they could not respond effectively as economic and social conditions changed. Called the \"Grand Old Man\" later in life, Gladstone was always a dynamic popular orator who appealed strongly to the working class and to the lower middle class. Deeply religious, Gladstone brought a new moral tone to politics, with his evangelical sensibility and his opposition to aristocracy. His moralism often angered his upper-class opponents (including Queen Victoria), and his heavy-handed control split the Liberal Party.\nIn foreign policy, Gladstone was in general against foreign entanglements, but he did not resist the realities of imperialism. For example, he ordered the occupation of Egypt by British forces in the 1882 Anglo-Egyptian War. His goal was to create a European order based on co-operation rather than conflict and on mutual trust instead of rivalry and suspicion; the rule of law was to supplant the reign of force and self-interest. This Gladstonian concept of a harmonious Concert of Europe was opposed to and ultimately defeated by a Bismarckian system of manipulated alliances and antagonisms.\nAs prime minister from 1868 to 1874, Gladstone headed a Liberal Party which was a coalition of Peelites like himself, Whigs and Radicals. He was now a spokesman for \"peace, economy and reform\". One major achievement was the Elementary Education Act 1870 (33 &amp; 34 Vict. c. 75), which provided England with an adequate system of elementary schools for the first time. He also secured the abolition of the purchase of commissions in the British Army and of religious tests for admission to Oxford and Cambridge; the introduction of the secret ballot in elections; the legalization of trade unions; and the reorganization of the judiciary in the Judicature Act.\nRegarding Ireland, the major Liberal achievements were land reform, where he ended centuries of landlord oppression, and the disestablishment of the (Anglican) Church of Ireland through the Irish Church Act 1869.\nIn the 1874 general election, Gladstone was defeated by the Conservatives under Benjamin Disraeli during a sharp economic recession. He formally resigned as Liberal leader and was succeeded by the Marquess of Hartington, but he soon changed his mind and returned to active politics. He strongly disagreed with Disraeli's pro-Ottoman foreign policy and in 1880 he conducted the first outdoor mass-election campaign in Britain, known as the Midlothian campaign. The Liberals won a large majority in the 1880 election. Hartington ceded his place and Gladstone resumed office.\nIreland and Home Rule.\nAmong the consequences of the Third Reform Act (1884) was the giving of the vote to many Irish Catholics. In the 1885 general election the Irish Parliamentary Party held the balance of power in the House of Commons and demanded Irish Home Rule as the price of support for a continued Gladstone ministry. Gladstone personally supported Home Rule, but a strong Liberal Unionist faction led by Joseph Chamberlain, along with the last of the Whigs, Hartington, opposed it. The Irish Home Rule bill proposed to offer all owners of Irish land a chance to sell to the state at a price equal to 20 years' purchase of the rents and allowing tenants to purchase the land. Irish nationalist reaction was mixed, Unionist opinion was hostile, and the election addresses during the 1886 election revealed English radicals to be against the bill also. Among the Liberal rank and file, several Gladstonian candidates disowned the bill, reflecting fears at the constituency level that the interests of the working people were being sacrificed to finance a costly rescue operation for the landed \u00e9lite. Further, Home Rule had not been promised in the Liberals' election manifesto, and so the impression was given that Gladstone was buying Irish support in a rather desperate manner to hold on to power.\nThe result was a catastrophic split in the Liberal Party, and heavy defeat in the 1886 election at the hands of Lord Salisbury, who was supported by the breakaway Liberal Unionist Party. There was a final weak Gladstone ministry in 1892, but it also was dependent on Irish support and failed to get Irish Home Rule through the House of Lords.\nNewcastle Programme.\nHistorically, the aristocracy was divided between Conservatives and Liberals. However, when Gladstone committed to home rule for Ireland, Britain's upper classes largely abandoned the Liberal party, giving the Conservatives a large permanent majority in the House of Lords. Following the Queen, High Society in London largely ostracized home rulers and Liberal clubs were badly split. Joseph Chamberlain took a major element of upper-class supporters out of the Party and into a third party called Liberal Unionism on the Irish issue. It collaborated with and eventually merged into the Conservative party. The Gladstonian liberals in 1891 adopted The Newcastle Programme that included home rule for Ireland, disestablishment of the Church of England in Wales, tighter controls on the sale of liquor, major extension of factory regulation and various democratic political reforms. The Programme had a strong appeal to the nonconformist middle-class Liberal element, which felt liberated by the departure of the aristocracy.\nRelations with trade unions.\nA major long-term consequence of the Third Reform Act was the rise of Lib-Lab candidates. The Act split all county constituencies (which were represented by multiple MPs) into single-member constituencies, roughly corresponding to population patterns. With the foundation of the Labour Party not to come till 1906, many trade unions allied themselves with the Liberals. In areas with working class majorities, in particular coal-mining areas, Lib-Lab candidates were popular, and they received sponsorship and endorsement from trade unions. In the first election after the Act was passed (1885), thirteen were elected, up from two in 1874. The Third Reform Act also facilitated the demise of the Whig old guard; in two-member constituencies, it was common to pair a Whig and a radical under the Liberal banner. After the Third Reform Act, fewer former Whigs were selected as candidates.\nReform policies.\nA broad range of interventionist reforms were introduced by the 1892\u20131895 Liberal government. Amongst other measures, standards of accommodation and of teaching in schools were improved, factory inspection was made more stringent, and ministers used their powers to increase the wages and reduce the working hours of large numbers of male workers employed by the state.\nHistorian Walter L. Arnstein concludes:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Notable as the Gladstonian reforms had been, they had almost all remained within the nineteenth-century Liberal tradition of gradually removing the religious, economic, and political barriers that prevented men of varied creeds and classes from exercising their individual talents in order to improve themselves and their society. As the third quarter of the century drew to a close, the essential bastions of Victorianism still held firm: respectability; a government of aristocrats and gentlemen now influenced not only by middle-class merchants and manufacturers but also by industrious working people; a prosperity that seemed to rest largely on the tenets of laissez-faire economics; and a Britannia that ruled the waves and many a dominion beyond.\nAfter Gladstone.\nGladstone finally retired in 1894. Gladstone's support for Home Rule deeply divided the party, and it lost its upper and upper-middle-class base, while keeping support among Protestant nonconformists and the Celtic fringe. Historian R. C. K. Ensor reports that after 1886, the main Liberal Party was deserted by practically the entire whig peerage and the great majority of the upper-class and upper-middle-class members. High prestige London clubs that had a Liberal base were deeply split. Ensor notes that, \"London society, following the known views of the Queen, practically ostracized home rulers.\"\nThe new Liberal leader was the ineffectual Lord Rosebery. He led the party to a heavy defeat in the 1895 general election.\nLiberal factions.\nThe Liberal Party lacked a unified ideological base in 1906. It contained numerous contradictory and hostile factions, such as imperialists and supporters of the Boers; near-socialists and laissez-faire classical liberals; suffragettes and opponents of women's suffrage; antiwar elements and supporters of the military alliance with France. Nonconformists \u2013 Protestants outside the Anglican fold \u2013 were a powerful element, dedicated to opposing the established church in terms of education and taxation. However, the non-conformists were losing support amid society at large and played a lesser role in party affairs after 1900. The party, furthermore, also included Irish Catholics, and secularists from the labour movement. Many Conservatives (including Winston Churchill) had recently protested against high tariff moves by the Conservatives by switching to the anti-tariff Liberal camp, but it was unclear how many old Conservative traits they brought along, especially on military and naval issues.\nThe middle-class business, professional and intellectual communities were generally strongholds, although some old aristocratic families played important roles as well. The working-class element was moving rapidly toward the newly emerging Labour Party. One uniting element was widespread agreement on the use of politics and Parliament as a device to upgrade and improve society and to reform politics. All Liberals were outraged when Conservatives used their majority in the House of Lords to block reform legislation. In the House of Lords, the Liberals had lost most of their members, who in the 1890s \"became Conservative in all but name.\" The government could force the unwilling king to create new Liberal peers, and that threat did prove decisive in the battle for dominance of Commons over Lords in 1911.\nRise of New Liberalism.\nThe late nineteenth century saw the emergence of New Liberalism within the Liberal Party, which advocated state intervention as a means of guaranteeing freedom and removing obstacles to it such as poverty and unemployment. The policies of the New Liberalism are now known as social liberalism.\nThe New Liberals included intellectuals like L. T. Hobhouse, and John A. Hobson. They saw individual liberty as something achievable only under favourable social and economic circumstances. In their view, the poverty, squalor, and ignorance in which many people lived made it impossible for freedom and individuality to flourish. New Liberals believed that these conditions could be ameliorated only through collective action coordinated by a strong, welfare-oriented, and interventionist state.\nAfter the historic 1906 victory, the Liberal Party introduced multiple reforms on a range of issues, including health insurance, unemployment insurance, and pensions for elderly workers, thereby laying the groundwork for the future British welfare state. Some proposals failed, such as licensing fewer pubs, or rolling back Conservative educational policies. The People's Budget of 1909, championed by David Lloyd George and fellow Liberal Winston Churchill, introduced unprecedented taxes on the wealthy in Britain and radical social welfare programmes to the country's policies. In the Liberal camp, as noted by one study, \"the Budget was on the whole enthusiastically received.\" It was the first budget with the expressed intent of redistributing wealth among the public. It imposed increased taxes on luxuries, liquor, tobacco, high incomes, and land \u2013 taxation that fell heavily on the rich. The new money was to be made available for new welfare programmes as well as new battleships. In 1911 Lloyd George succeeded in putting through Parliament his National Insurance Act, making provision for sickness and invalidism, and this was followed by his Unemployment Insurance Act.\nHistorian Peter Weiler argues:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Although still partially informed by older Liberal concerns for character, self-reliance, and the capitalist market, this legislation nevertheless, marked a significant shift in Liberal approaches to the state and social reform, approaches that later governments would slowly expand and that would grow into the welfare state after the Second World War. What was new in these reforms was the underlying assumption that the state could be a positive force, that the measure of individual freedom... was not how much the state left people alone, but whether it gave them the capacity to fill themselves as individuals.\nContrasting Old Liberalism with New Liberalism, David Lloyd George noted in a 1908 speech the following:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;[Old Liberals] used the natural discontent of the people with the poverty and precariousness of the means of subsistence as a motive power to win for them a better, more influential, and more honourable status in the citizenship of their native land. The new Liberalism, while pursuing this great political ideal with unflinching energy, devotes a part of its endeavour also to the removing of the immediate causes of discontent. It is true that man cannot live by bread alone. It is equally true that a man cannot live without bread.\nLiberal zenith.\nThe Liberals languished in opposition for a decade while the coalition of Salisbury and Chamberlain held power. The 1890s were marred by infighting between the three principal successors to Gladstone, party leader William Harcourt, former prime minister Lord Rosebery, and Gladstone's personal secretary, John Morley. This intrigue finally led Harcourt and Morley to resign their positions in 1898 as they continued to be at loggerheads with Rosebery over Irish home rule and issues relating to imperialism. Replacing Harcourt as party leader was Sir Henry Campbell-Bannerman. Harcourt's resignation briefly muted the turmoil in the party, but the beginning of the Second Boer War soon nearly broke the party apart, with Rosebery and a circle of supporters including important future Liberal figures H. H. Asquith, Edward Grey and Richard Burdon Haldane forming a clique dubbed the Liberal Imperialists that supported the government in the prosecution of the war. On the other side, more radical members of the party formed a Pro-Boer faction that denounced the conflict and called for an immediate end to hostilities. Quickly rising to prominence among the Pro-Boers was David Lloyd George, a relatively new MP and a master of rhetoric, who took advantage of having a national stage to speak out on a controversial issue to make his name in the party. Harcourt and Morley also sided with this group, though with slightly different aims. Campbell-Bannerman tried to keep these forces together at the head of a moderate Liberal rump, but in 1901 he delivered a speech on the government's \"methods of barbarism\" in South Africa that pulled him further to the left and nearly tore the party in two. The party was saved after Salisbury's retirement in 1902 when his successor, Arthur Balfour, pushed a series of unpopular initiatives such as the Education Act 1902 and Joseph Chamberlain called for a new system of protectionist tariffs.\nCampbell-Bannerman was able to rally the party around the traditional liberal platform of free trade and land reform and led them to the greatest election victory in their history. This would prove the last time the Liberals won a majority in their own right. Although he presided over a large majority, Sir Henry Campbell-Bannerman was overshadowed by his ministers, most notably H. H. Asquith at the Exchequer, Edward Grey at the Foreign Office, Richard Burdon Haldane at the War Office and David Lloyd George at the Board of Trade. Campbell-Bannerman retired in 1908 and died soon after. He was succeeded by Asquith, who stepped up the government's radicalism. Lloyd George succeeded Asquith at the Exchequer and was in turn succeeded at the Board of Trade by Winston Churchill, a recent defector from the Conservatives.\nThe 1906 general election also represented a shift to the left by the Liberal Party. According to Rosemary Rees, almost half of the Liberal MPs elected in 1906 were supportive of the 'New Liberalism' (which advocated government action to improve people's lives),) while claims were made that \"five-sixths of the Liberal party are left wing.\" Other historians, however, have questioned the extent to which the Liberal Party experienced a leftward shift; according to Robert C. Self however, only between 50 and 60 Liberal MPs out of the 400 in the parliamentary party after 1906 were Social Radicals, with a core of 20 to 30. Nevertheless, important junior offices were held in the cabinet by what Duncan Tanner has termed \"genuine New Liberals, Centrist reformers, and Fabian collectivists,\" and much legislation was pushed through by the Liberals in government. This included the regulation of working hours, National Insurance and welfare.\nA political battle erupted over the People's Budget, which was rejected by the House of Lords and for which the government obtained an electoral mandate at the January 1910 election. The election resulted in a hung parliament, with the government left dependent on the Irish Nationalists. Although the Lords now passed the budget, the government wished to curtail their power to block legislation. Asquith was required by King George V to fight a second general election in December 1910 (whose result was little changed from that in January) before he agreed, if necessary, to create hundreds of Liberals peers. Faced with that threat, the Lords voted to give up their veto power and allowed the passage of the Parliament Act 1911.\nAs the price of Irish support, Asquith was now forced to introduce a third Home Rule bill in 1912. Since the House of Lords no longer had the power to block the bill, but only to delay it for two years, it was due to become law in 1914. The Unionist Ulster Volunteers, led by Sir Edward Carson, launched a campaign of opposition that included the threat of a provisional government and armed resistance in Ulster. The Ulster Protestants had the full support of the Conservatives, whose leader, Bonar Law, was of Ulster-Scots descent. Government plans to deploy troops into Ulster had to be cancelled after the threat of mass resignation of their commissions by army officers in March 1914 (\"see Curragh Incident\"). Ireland seemed to be on the brink of civil war when the First World War broke out in August 1914. Asquith had offered the Six Counties (later to become Northern Ireland) an opt out from Home Rule for six years (i.e., until after two more general elections were likely to have taken place) but the Nationalists refused to agree to permanent Partition of Ireland. Historian George Dangerfield has argued that the multiplicity of crises in 1910 to 1914, political and industrial, so weakened the Liberal coalition before the war broke out that it marked the \"Strange Death of Liberal England\". Political scientist Harold Webb Jr. also concludes that the combination of overambitious reforms, internal divisions and external political pressures set the stage for the Party's post-World War I fragmentation and decline. However, most historians date the collapse to the crisis of the First World War.\nDecline.\nThe Liberal Party might have survived a short war, but the totality of the Great War called for measures that the Party had long rejected. The result was the permanent destruction of the ability of the Liberal Party to lead a government. Historian Robert Blake explains the dilemma:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nBlake further notes that it was the Liberals, not the Conservatives who needed the moral outrage of Belgium to justify going to war, while the Conservatives called for intervention from the start of the crisis on the grounds of \"realpolitik\" and the balance of power. However, Lloyd George and Churchill were zealous supporters of the war, and gradually forced the old peace-orientated Liberals out.\nAsquith was blamed for the poor British performance in the first year. Since the Liberals ran the war without consulting the Conservatives, there were heavy partisan attacks. However, even Liberal commentators were dismayed by the lack of energy at the top. At the time, public opinion was intensely hostile, both in the media and in the street, against any young man in civilian garb and labeled as a slacker. The leading Liberal newspaper, the \"Manchester Guardian\" complained:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The fact that the Government has not dared to challenge the nation to rise above itself, is one among many signs. [...] The war is, in fact, not being taken seriously. [...] How can any slacker be blamed when the Government itself is slack.\nAsquith's Liberal government was brought down in May 1915, due in particular to a crisis in inadequate artillery shell production and the protest resignation of Admiral Fisher over the disastrous Gallipoli Campaign against Turkey. Reluctant to face doom in an election, Asquith formed a new coalition government on 25 May, with the majority of the new cabinet coming from his own Liberal party and the Unionist (Conservative) party, along with a token Labour representation. The new government lasted a year and a half and was the last time Liberals controlled the government. The analysis of historian A. J. P. Taylor is that the British people were so deeply divided over numerous issues, but on all sides, there was growing distrust of the Asquith government. There was no agreement whatsoever on wartime issues. The leaders of the two parties realized that embittered debates in Parliament would further undermine popular morale and so the House of Commons did not once discuss the war before May 1915. Taylor argues:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The Unionists, by and large, regarded Germany as a dangerous rival, and rejoiced at the chance to destroy her. They meant to fight a hard-headed war by ruthless methods; they condemned Liberal 'softness' before the war and now. The Liberals insisted on remaining high-minded. Many of them had come to support the war only when the Germans invaded Belgium. [...] Entering the war for idealistic motives, the Liberals wished to fight it by noble means and found it harder to abandon their principles than to endure defeat in the field.\nThe 1915 coalition fell apart at the end of 1916, when the Conservatives withdrew their support from Asquith and gave it instead to Lloyd George, who became prime minister at the head of a new coalition largely made up of Conservatives. Asquith and his followers moved to the opposition benches in Parliament and the Liberal Party was deeply split once again.\nLloyd George as a Liberal heading a Conservative coalition.\nLloyd George remained a Liberal all his life, but he abandoned many standard Liberal principles in his crusade to win the war at all costs. He insisted on strong government controls over business as opposed to the \"laissez-faire\" attitudes of traditional Liberals. in 1915\u201316 he had insisted on conscription of young men into the Army, a position that deeply troubled his old colleagues. That brought him and a few like-minded Liberals into the new coalition on the ground long occupied by Conservatives. There was no more planning for world peace or liberal treatment of Germany, nor discomfit with aggressive and authoritarian measures of state power. More deadly to the future of the party, says historian Trevor Wilson, was its repudiation by ideological Liberals, who decided sadly that it no longer represented their principles. Finally, the presence of the vigorous new Labour Party on the left gave a new home to voters disenchanted with the Liberal performance.\nThe last majority Liberal Government in Britain was elected in 1906. The years preceding the First World War were marked by worker strikes and civil unrest and saw many violent confrontations between civilians and the police and armed forces. Other issues of the period included women's suffrage and the Irish Home Rule movement. After the carnage of 1914\u20131918, the democratic reforms of the Representation of the People Act 1918 instantly tripled the number of people entitled to vote in Britain from seven to twenty-one million. The Labour Party benefited most from this huge change in the electorate, forming its first minority government in 1924.\nIn the 1918 general election, Lloyd George, hailed as \"the Man Who Won the War\", led his coalition into a khaki election. Lloyd George and the Conservative leader Bonar Law wrote a joint letter of support to candidates to indicate they were considered the official Coalition candidates\u2014this \"coupon\", as it became known, was issued against many sitting Liberal MPs, often to devastating effect, though not against Asquith himself. The coalition won a massive victory: Labour increased their position slightly, but the Asquithian Liberals were decimated. Those remaining Liberal MPs who were opposed to the Coalition Government went into opposition under the parliamentary leadership of Sir Donald MacLean who also became Leader of the Opposition. Asquith, who had appointed MacLean, remained as overall Leader of the Liberal Party even though he lost his seat in 1918. Asquith returned to Parliament in 1920 and resumed leadership. Between 1919 and 1923, the anti-Lloyd George Liberals were called Asquithian Liberals, Wee Free Liberals or Independent Liberals.\nLloyd George was increasingly under the influence of the rejuvenated Conservative party who numerically dominated the coalition. In 1922, the Conservative backbenchers rebelled against the continuation of the coalition, citing, in particular, Lloyd George's plan for war with Turkey in the Chanak Crisis, and his corrupt sale of honours. He resigned as prime minister and was succeeded by Bonar Law.\nAt the 1922 and 1923 elections, the Liberals won barely a third of the vote and only a quarter of the seats in the House of Commons as many radical voters abandoned the divided Liberals and went over to Labour. In 1922, Labour became the official opposition. A reunion of the two warring factions took place in 1923 when the new Conservative prime minister Stanley Baldwin committed his party to protective tariffs, causing the Liberals to reunite in support of free trade. The party gained ground in the 1923 general election but made most of its gains from Conservatives whilst losing ground to Labour\u2014a sign of the party's direction for many years to come. The party remained the third largest in the House of Commons, but the Conservatives had lost their majority. There was much speculation and fear \"[by whom?]\" about the prospect of a Labour government and comparatively little about a Liberal government, even though it could have plausibly presented an experienced team of ministers compared to Labour's almost complete lack of experience as well as offering a middle ground that could obtain support from both Conservatives and Labour in crucial Commons divisions. However, instead of trying to force the opportunity to form a Liberal government, Asquith decided instead to allow Labour the chance of office in the belief that they would prove incompetent, and this would set the stage for a revival of Liberal fortunes at Labour's expense, but it was a fatal error.\nLabour was determined to destroy the Liberals and become the sole party of the left. Ramsay MacDonald was forced into a snap election in 1924 and although his government was defeated, he achieved his objective of virtually wiping the Liberals out as many more radical voters now moved to Labour whilst moderate middle-class Liberal voters concerned about socialism moved to the Conservatives. The Liberals were reduced to a mere forty seats in Parliament, only seven of which had been won against candidates from both parties and none of these formed a coherent area of Liberal survival. The party seemed finished, and during this period some Liberals, such as Churchill, went over to the Conservatives while others went over to Labour. Several Labour ministers of later generations, such as Michael Foot and Tony Benn, were the sons of Liberal MPs.\nAsquith finally resigned as Liberal leader in 1926 (he died in 1928). Lloyd George, now party leader, began a drive to produce coherent policies on many key issues of the day. In the 1929 general election, he made a final bid to return the Liberals to the political mainstream, with an ambitious programme of state stimulation of the economy called \"We Can Conquer Unemployment!\", largely written for him by the Liberal economist John Maynard Keynes. The Liberal Party stood in Northern Ireland for the first and only time in the 1929 general election, gaining 17% of the vote, but won no seats. Nationally the Liberals gained ground, but once again it was at the Conservatives' expense whilst also losing seats to Labour. Indeed, the urban areas of the country suffering heavily from unemployment, which might have been expected to respond the most to the radical economic policies of the Liberals, instead gave the party its worst results. By contrast, most of the party's seats were won either due to the absence of a candidate from one of the other parties or in rural areas on the Celtic fringe, where local evidence suggests that economic ideas were at best peripheral to the electorate's concerns. The Liberals now found themselves with 59 members, holding the balance of power in a Parliament where Labour was the largest party but lacked an overall majority. Lloyd George offered a degree of support to the Labour government in the hope of winning concessions, including a degree of electoral reform to introduce the alternative vote, but this support was to prove bitterly divisive as the Liberals increasingly divided between those seeking to gain what Liberal goals they could achieve, those who preferred a Conservative government to a Labour one and vice versa.\nSplits over the National Government.\nA group of Liberal MPs led by Sir John Simon opposed the Liberal Party's support for the minority Labour government. They preferred to reach an accommodation with the Conservatives. In 1931 MacDonald's Labour government fell apart in response to the Great Depression. Macdonald agreed to lead a National Government of all parties, which passed a budget to deal with the financial crisis. When few Labour MPs backed the National government, it became clear that the Conservatives had the clear majority of government supporters. They then forced MacDonald to call a general election. Lloyd George called for the party to leave the National Government but only a few MPs and candidates followed. The majority, led by Sir Herbert Samuel, decided to contest the elections as part of the government. The bulk of Liberal MPs supported the government, \u2013 the Liberal Nationals (officially the \"National Liberals\" after 1947) led by Simon, also known as \"Simonites\", and the \"Samuelites\" or \"official Liberals\", led by Samuel who remained as the official party. Both groups secured about 34 MPs but proceeded to diverge even further after the election, with the Liberal Nationals remaining supporters of the government throughout its life. There were to be a succession of discussions about them rejoining the Liberals, but these usually foundered on the issues of free trade and continued support for the National Government. The one significant reunification came in 1946 when the Liberal and Liberal National party organisations in London merged. The National Liberals, as they were called by then, were gradually absorbed into the Conservative Party, finally merging in 1968.\nThe official Liberals found themselves a tiny minority within a government committed to protectionism. Slowly they found this issue to be one they could not support. In early 1932 it was agreed to suspend the principle of collective responsibility to allow the Liberals to oppose the introduction of tariffs. Later in 1932 the Liberals resigned their ministerial posts over the introduction of the Ottawa Agreement on Imperial Preference. However, they remained sitting on the government benches supporting it in Parliament, though in the country local Liberal activists bitterly opposed the government. Finally in late 1933 the Liberals crossed the floor of the House of Commons and went into complete opposition. By this point their number of MPs was severely depleted. In the 1935 general election, just 17 Liberal MPs were elected, along with Lloyd George and three followers as independent Liberals. Immediately after the election the two groups reunited, though Lloyd George declined to play much of a formal role in his old party. Over the next ten years there would be further defections as MPs deserted to either the Liberal Nationals or Labour. Yet there were a few recruits, such as Clement Davies, who had deserted to the National Liberals in 1931 but now returned to the party during World War II and who would lead it after the war.\nNear extinction.\nSamuel had lost his seat in the 1935 election and the leadership of the party fell to Sir Archibald Sinclair. With many traditional domestic Liberal policies now regarded as irrelevant, he focused the party on opposition to both the rise of Fascism in Europe and the appeasement foreign policy of the National Government, arguing that intervention was needed, in contrast to the Labour calls for pacifism. Despite the party's weaknesses, Sinclair gained a high profile as he sought to recall the Midlothian Campaign and once more revitalise the Liberals as the party of a strong foreign policy.\nIn 1940, they joined Churchill's wartime coalition government, with Sinclair serving as Secretary of State for Air, the last British Liberal to hold Cabinet rank office for seventy years. However, it was a sign of the party's lack of importance that they were not included in the War Cabinet; some leading party members founded Radical Action, a group which called for liberal candidates to break the war-time electoral pact. At the 1945 general election, Sinclair and many of his colleagues lost their seats to both Conservatives and Labour and the party returned just 12 MPs to Westminster, but this was just the beginning of the decline. In 1950, the general election saw the Liberals return just nine MPs. Another general election was called in 1951 and the Liberals were left with just six MPs and all but one of them were aided by the fact that the Conservatives refrained from fielding candidates in those constituencies.\nIn 1957, this total fell to five when one of the Liberal MPs died and the subsequent by-election was lost to the Labour Party, which selected the former Liberal Deputy Leader Megan Lloyd George as its own candidate. The Liberal Party seemed close to extinction. During this low period, it was often joked that Liberal MPs could hold meetings in the back of one taxi.\nLiberal revival.\nThrough the 1950s and into the 1960s, the Liberals survived only because a handful of constituencies in rural Scotland and Wales clung to their Liberal traditions, whilst in two English towns, Bolton and Huddersfield, local Liberals and Conservatives agreed to each contest only one of the town's two seats. Jo Grimond, for example, who became Leader of the Liberal Party in 1956, was MP for the remote Orkney and Shetland islands. Under his leadership a Liberal revival began, marked by the Orpington by-election of March 1962 which was won by Eric Lubbock. There, the Liberals won a seat in the London suburbs for the first time since 1935.\nThe Liberals became the first of the major British political parties to advocate British membership of the European Economic Community. Grimond also sought an intellectual revival of the party, seeking to position it as a non-socialist radical alternative to the Conservative government of the day. In particular he canvassed the support of the young post-war university students and recent graduates, appealing to younger voters in a way that many of his recent predecessors had not, and asserting a new strand of Liberalism for the post-war world.\nThe new middle-class suburban generation began to find the Liberals' policies attractive again. Under Grimond (who retired in 1967) and his successor, Jeremy Thorpe, the Liberals regained the status of a serious third force in British politics, polling up to 20% of the vote, but unable to break the duopoly of Labour and Conservative and win more than fourteen seats in the Commons. An additional problem was competition in the Liberal heartlands in Scotland and Wales from the Scottish National Party and Plaid Cymru who both grew as electoral forces from the 1960s onwards. Although Emlyn Hooson held on to the seat of Montgomeryshire, upon Clement Davies death in 1962, the party lost five Welsh seats between 1950 and 1966. In September 1966, the Welsh Liberal Party formed their own state party, moving the Liberal Party into a fully federal structure.\nIn local elections, Liverpool remained a Liberal stronghold, with the party taking the plurality of seats on the elections to the new Liverpool Metropolitan Borough Council in 1973. On 26 July 1973, the party won two by-elections on the same day, in the Isle of Ely (with Clement Freud), and Ripon (with David Austick). In the February 1974 general election, the Conservative government of Edward Heath won a plurality of votes cast, but the Labour Party gained a plurality of seats. The Conservatives were unable to form a government due to the Ulster Unionist MPs refusing to support the Conservatives following the Northern Ireland Sunningdale Agreement. The Liberals obtained 6.1 million votes, the most it would ever achieve, and now held the balance of power in the Commons. Conservatives offered Thorpe the Home Office if he would join a coalition government with Heath. Thorpe was personally in favour of it, but the party insisted it would only agree pending a clear government commitment to introducing proportional representation (PR) and a change of prime minister. The former was unacceptable to Heath's cabinet and the latter to Heath personally, so the talks collapsed. Instead, a minority Labour government was formed under Harold Wilson but with no formal support from Thorpe. In the October 1974 general election, the Liberals total vote slipped back slightly (and declined in each of the next three) and the Labour government won a wafer-thin majority.\nThorpe was subsequently forced to resign after allegations that he attempted to have his homosexual lover murdered by a hitman. The party's new leader, David Steel, negotiated the Lib\u2013Lab pact with Wilson's successor as prime minister, James Callaghan. According to this pact, the Liberals would support the government in crucial votes in exchange for some influence over policy. The agreement lasted from 1977 to 1978, but proved mostly fruitless, for two reasons: the Liberals' key demand of PR was rejected by most Labour MPs, whilst the contacts between Liberal spokespersons and Labour ministers often proved detrimental, such as between Treasury spokesperson John Pardoe and Chancellor of the Exchequer Denis Healey, who were mutually antagonistic.\nAlliance, Liberal Democrats and reconstituted Liberal Party.\nThe Conservative Party under the leadership of Margaret Thatcher won the 1979 general election, placing the Labour Party back in opposition, which served to push the Liberals back into the margins.\nIn 1981, defectors from a moderate faction of the Labour Party, led by former Cabinet ministers Roy Jenkins, David Owen and Shirley Williams, founded the Social Democratic Party (SDP). The new party and the Liberals quickly formed the SDP\u2013Liberal Alliance, which for a while polled as high as 50% in the opinion polls and appeared capable of winning the next general election. Indeed, Steel was so confident of an Alliance victory that he told the 1981 Liberal conference, \"Go back to your constituencies, and prepare for government!\".\nHowever, the Alliance was overtaken in the polls by the Tories in the aftermath of the Falkland Islands War and at the 1983 general election the Conservatives were re-elected by a landslide, with Labour once again forming the opposition. While the SDP\u2013Liberal Alliance came close to Labour in terms of votes (a share of more than 25%), it only had 23 MPs compared to Labour's 209. The Alliance's support was spread out across the country, and was not concentrated in enough areas to translate into seats.\nIn the 1987 general election, the Alliance's share of the votes fell slightly and it now had 22 MPs. In the election's aftermath Steel proposed a merger of the two parties. Most SDP members voted in favour of the merger, but SDP leader David Owen objected and continued to lead a \"rump\" SDP.\nIn March 1988, the Liberal Party and Social Democratic Party merged to create the Social and Liberal Democrats, renamed the Liberal Democrats in October 1989. Over two-thirds of Liberal members joined the merged party, along with all sitting MPs. Steel and SDP leader Robert Maclennan served briefly as interim leaders of the merged party.\nA group of Liberal opponents of the merger with the Social Democrats, including Michael Meadowcroft (the former Liberal MP for Leeds West) and Paul Wiggin (who served on Peterborough City Council as a Liberal), continued with a new party organisation under the name of the 'Liberal Party'. Meadowcroft joined the Liberal Democrats in 2007, but the Liberal Party as reconstituted in 1989 continues to hold council seats and field candidates in Westminster Parliamentary elections. Only one of the twelve Liberal candidates in 2024 achieved 5% or more of the votes, resulting in all bar that one losing their deposits.\nIdeology.\nDuring the 19th century, the Liberal Party was broadly in favour of what would today be called classical liberalism, supporting \"laissez-faire\" economic policies such as free trade and minimal government interference in the economy (this doctrine was usually termed Gladstonian liberalism after the Victorian era Liberal Prime Minister William Gladstone). The Liberal Party favoured social reform, personal liberty, reducing the powers of the Crown and the Church of England (many of them were nonconformists) and an extension of the electoral franchise. Sir William Harcourt, a prominent Liberal politician in the Victorian era, said this about liberalism in 1872: If there be any party which is more pledged than another to resist a policy of restrictive legislation, having for its object social coercion, that party is the Liberal party. (Cheers.) But liberty does not consist in making others do what you think right, (Hear, hear.) The difference between a free Government and a Government which is not free is principally this\u2014that a Government which is not free interferes with everything it can, and a free Government interferes with nothing except what it must. A despotic Government tries to make everybody do what it wishes; a Liberal Government tries, as far as the safety of society will permit, to allow everybody to do as he wishes. It has been the tradition of the Liberal party consistently to maintain the doctrine of individual liberty. It is because they have done so that England is the place where people can do more what they please than in any other country in the world. [...] It is this practice of allowing one set of people to dictate to another set of people what they shall do, what they shall think, what they shall drink, when they shall go to bed, what they shall buy, and where they shall buy it, what wages they shall get and how they shall spend them, against which the Liberal party have always protested.\nThe political terms of \"modern\", \"progressive\" or \"new\" Liberalism began to appear in the mid to late 1880s and became increasingly common to denote the tendency in the Liberal Party to favour an increased role for the state as more important than the classical liberal stress on self-help and freedom of choice.\nBy the early 20th century, the Liberals stance began to shift towards \"New Liberalism\", what would today be called social liberalism, namely a belief in personal liberty with a support for government intervention to provide social welfare. This shift was best exemplified by the Liberal government of H. H. Asquith and his Chancellor David Lloyd George, whose Liberal reforms in the early 1900s created a basic welfare state.\nDavid Lloyd George adopted a programme at the 1929 general election entitled \"We Can Conquer Unemployment!\", although by this stage the Liberals had declined to third-party status. The Liberals as expressed in the \"Liberal Yellow Book\" now regarded opposition to state intervention as being a characteristic of right-wing extremists.\nAfter nearly becoming extinct in the 1940s and the 1950s, the Liberal Party revived its fortunes somewhat under the leadership of Jo Grimond in the 1960s by positioning itself as a radical centrist, non-socialist alternative to the Conservative and Labour Party governments of the time.\nReligious alignment.\nSince 1660, nonconformist Protestants have played a major role in English politics. Relatively few MPs were Dissenters. However the Dissenters were a major voting bloc in many areas, such as the East Midlands. They were very well organised and highly motivated and largely won over the Whigs and Liberals to their cause. Down to the 1830s, Dissenters demanded removal of political and civil disabilities that applied to them (especially those in the Test and Corporation Acts). The Anglican establishment strongly resisted until 1828. Numerous reforms of voting rights, especially that of 1832, increased the political power of Dissenters. They demanded an end to compulsory church rates, in which local taxes went only to Anglican churches. They finally achieved the end of religious tests for university degrees in 1905. Gladstone brought the majority of Dissenters around to support for Home Rule for Ireland, putting the dissenting Protestants in league with the Irish Roman Catholics in an otherwise unlikely alliance. The Dissenters gave significant support to moralistic issues, such as temperance and sabbath enforcement. The nonconformist conscience, as it was called, was repeatedly called upon by Gladstone for support for his moralistic foreign policy. In election after election, Protestant ministers rallied their congregations to the Liberal ticket. In Scotland, the Presbyterians played a similar role to the Nonconformist Methodists, Baptists and other groups in England and Wales.\nBy the 1820s, the different Nonconformists, including Wesleyan Methodists, Baptists, Congregationalists and Unitarians, had formed the Committee of Dissenting Deputies and agitated for repeal of the highly restrictive Test and Corporation Acts. These Acts excluded Nonconformists from holding civil or military office or attending Oxford or Cambridge, compelling them to set up their own Dissenting Academies privately. The Tories tended to be in favour of these Acts and so the Nonconformist cause was linked closely to the Whigs, who advocated civil and religious liberty. After the Test and Corporation Acts were repealed in 1828, all the Nonconformists elected to Parliament were Liberals. Nonconformists were angered by the Education Act 1902, which integrated Church of England denominational schools into the state system and provided for their support from taxes. John Clifford formed the National Passive Resistance Committee and by 1906 over 170 Nonconformists had gone to prison for refusing to pay school taxes. They included 60 Primitive Methodists, 48 Baptists, 40 Congregationalists and 15 Wesleyan Methodists.\nThe political strength of Dissent faded sharply after 1920 with the secularisation of British society in the 20th century. The rise of the Labour Party reduced the Liberal Party strongholds into the nonconformist and remote \"Celtic Fringe\", where the party survived by an emphasis on localism and historic religious identity, thereby neutralising much of the class pressure on behalf of the Labour movement. Meanwhile, the Anglican Church was a bastion of strength for the Conservative Party. On the Irish issue, the Anglicans strongly supported unionism. Increasingly after 1850, the Roman Catholic element in England and Scotland was composed of recent emigrants from Ireland who largely voted for the Irish Parliamentary Party until its collapse in 1918.\nElection results.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "4484", "revid": "13452816", "url": "https://en.wikipedia.org/wiki?curid=4484", "title": "Bank of England", "text": "Central bank of the United Kingdom\n&lt;templatestyles src=\"Hlist/styles.css\" /&gt;\nThe Bank of England is the central bank of the United Kingdom and the model on which most modern central banks have been based. Established in 1694 to act as the English Government's banker and debt manager, and still one of the bankers for the government of the United Kingdom, it is the world's second oldest central bank.\nThe bank was privately owned by stockholders from its foundation in 1694 until it was nationalised in 1946 by the Attlee ministry. In 1998 it became an independent public organisation, wholly owned by the Treasury Solicitor on behalf of the government, with a mandate to support the economic policies of the government of the day, but independence in maintaining price stability. In the 21st century the bank took on increased responsibility for maintaining and monitoring financial stability in the UK, and it increasingly functions as a statutory regulator.\nThe bank's headquarters have been in London's main financial district, the City of London, since 1694, and on Threadneedle Street since 1734. It is sometimes known as \"The Old Lady of Threadneedle Street\", a name taken from a satirical cartoon by James Gillray in 1797. The road junction outside is known as Bank Junction.\nThe bank, among other things, is custodian to the official gold reserves of the United Kingdom (and those of around 30 other countries). As of \u00a02016[ [update]], the bank held around of gold, worth \u00a3141\u00a0billion. These estimates suggest that the vault could hold as much as 3% of the 171,300 tonnes of gold mined throughout human history.\nFunctions.\nAccording to its strapline, the bank's core purpose is 'promoting the good of the people of the United Kingdom by maintaining monetary and financial stability'. This is achieved in a variety of ways:\nMonetary stability.\nStable prices and secure forms of payment are the two main criteria for monetary stability.\nStable prices.\nStable prices are maintained by seeking to ensure that price increases meet the Government's inflation target. The bank aims to meet this target by adjusting the base interest rate (known as the bank rate), which is decided by the bank's Monetary Policy Committee (MPC). (The MPC has devolved responsibility for managing monetary policy; HM Treasury has reserve powers to give orders to the committee \"if they are required in the public interest and by extreme economic circumstances\", but Parliament must endorse such orders within 28 days.)\nAs of 2024 the inflation target is 2%; if this target is missed the Governor is required to write an open letter to the Chancellor of the Exchequer explaining the situation and proposing remedies. Other than setting the base interest rate, the main tool at the bank's disposal in this regard is quantitative easing.\nSecure forms of payment.\nThe bank has a monopoly on the issue of banknotes in England and Wales and regulates the issuance of banknotes by commercial banks in Scotland and Northern Ireland. (Scottish and Northern Irish banks retain the right to issue their own banknotes, but they must be backed one-for-one with deposits at the bank, excepting a few million pounds representing the value of notes they had in circulation in 1845.)\nIn addition the bank supervises other payment systems, acting as a settlement agent and operating Real-time gross settlement systems including CHAPS. In 2024 the bank was settling around \u00a3500 billion worth of payments between banks each day.\nFinancial stability.\nMaintaining financial stability involves protecting the UK's savers, investors and borrowers against threats to the financial system as a whole. Threats are detected by the bank's surveillance and market intelligence functions, and dealt with through financial and other operations (both at home and abroad). The majority of these safeguards were put in place in after the 2008 financial crisis:\nRegulation.\nIn 2011 the bank's Prudential Regulation Authority was established to regulate and supervise all major banks, building societies, credit unions, insurers and investment firms in the UK ('microprudential regulation'). The bank also has a statutory supervisory role in relation to financial market infrastructures.\nRisk management.\nAt the same time, the bank's Financial Policy Committee (FPC) was set up to identify and monitor risks in the financial system, and to take appropriate action where necessary ('macroprudential regulation'). The FPC publishes its findings (and actions taken) in a biannual Financial Stability Report.\nBanking services.\nThe bank provides wholesale banking services to the UK Government (and to over a hundred overseas central banks). It manages the UK's Exchange Equalisation Account on behalf of HM Treasury and it maintains the government's Consolidated Fund account. It also manages the country's foreign exchange reserves and is custodian of the UK's (and others') gold reserves.\nThe bank also offers 'liquidity support and other services to banks and other financial institutions'. Commercial banks customarily keep a sizeable proportion of their cash reserves on deposit at the Bank of England. These central bank reserves are used by the banks to settle payments with one another; (for this reason the Bank of England is sometimes called 'the bankers' bank'). In exceptional circumstances, the Bank may act as the lender of last resort by extending credit when no other institution will.\nAs a regulator and central bank, the Bank of England has not offered consumer banking services for many years, but it still does manage some public-facing services (such as exchanging superseded bank notes). Until 2017, Bank staff were entitled to open current accounts directly with the Bank of England and were given the unique sort code of 10-00-00.\nResolution.\nUnder the terms of the Banking Act 2009 the bank is the UK's Resolution Authority for any bank or building society judged 'too big to fail'; as such it is empowered to act in the event of a bank failure 'to protect the UK's vital financial services and financial stability'.\nHistoric services and responsibilities.\nBetween 1715 and 1998, the Bank of England managed Government Stocks (which formed the bulk of the national debt): the bank was responsible for issuing stocks to stockholders, paying dividends and maintaining a register of transfers; however in 1998, following the decision to grant the bank operational independence, responsibility for government debt management was transferred to a new Debt Management Office, which also took over Exchequer cash management and responsibility for issuing Treasury bills from the bank in 2000. Computershare took over as the registrar for UK Government bonds (gilt-edged securities or 'gilts') from the bank at the end of 2004. The bank, however, continues to act as settlement agent for the Debt Management Office and custodian of its securities.\nEver since its foundation in 1694, the bank had provided a retail banking service for the Government; however in 2008 it decided to withdraw from offering these services, which are now provided by a range of other financial institutions and managed by the Government Banking Service.\nUntil 2016, the bank provided personal banking services as a privilege for employees. Previously, the bank had maintained private and commercial accounts for all sorts of customers, including individuals, small businesses and public organisations; but a change of policy following the First World War saw the bank increasingly withdraw from this type of business to focus more clearly on its central banking role.\nHistory.\nFounding.\nDuring the Nine Years' War, the Royal Navy was defeated by the French Navy in the 1690 Battle of Beachy Head, causing consternation in the government of William III of England. The English government decided to rebuild the Royal Navy into a force that was capable of challenging the French on equal terms; however, their ability to do so was hampered both by a lack of available public funds and the government's low credit. This lack of credit made it impossible for the English government to borrow the \u00a31.5m that it wanted to use to expand the Royal Navy.\nConcept.\nIn 1691, William Paterson had proposed establishing a national bank as a means of bolstering public finances. As he later wrote in his pamphlet \"A Brief Account of the Intended Bank of England\" (1694): &lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\"...it was proposed some years ago that a publick transferrable Fund of Interest should be established by Parliament, and made convenient for the Receipts and Payments in and about the Cities of London and Westminster; and to constitute a Society of Money'd Men for the government thereof, who should be induced by their Interest to exchange for Money the Assignments upon the Fund, at every demand\". While his scheme was not immediately acted upon, it did provide the basis for the bank's first Charter and the legislation which made its establishment possible.\nTwo other key figures in the bank's creation were Charles Montagu, the Member of Parliament for Maldon, who played a crucial role in steering the proposals through Parliament (and was afterwards appointed Chancellor of the Exchequer); and Michael Godfrey, who helped persuade City financiers of its benefits (and was subsequently chosen to be the bank's first Deputy Governor).\nIt has also been claimed (by W. R. Scott, among others) that William Phips played a timely, if incidental, role: his successful expedition to retrieve booty from a sunken Spanish galleon (the \"Nuestra Se\u00f1ora de la Concepci\u00f3n\") helped create an ideal market for the bank's foundation: flooding the market with bullion and creating an enthusiasm for joint-stock ventures.\nLegislation.\nPaterson's proposal required the Government to set up a fund from which interest would be paid to the subscribers. It was decided that this would be provided for by income from tonnage, and certain other shipping duties routinely levied by HM Exchequer; therefore Parliament approved the bank's establishment by means of the Tonnage Act 1694 ('An Act for granting to theire Majesties severall Rates and Duties upon Tunnage of Shipps and Vessells and upon Beere Ale and other Liquors for secureing certaine Recompenses and Advantages in the said Act mentioned to such Persons as shall voluntarily advance the summe of Fifteen hundred thousand Pounds towards the carrying on the Warr against France').\nTo induce subscription to the loan, the subscribers were to be incorporated by the name of the Governor and Company of the Bank of England. Public finances were in such dire condition at the time that the terms of the loan (as laid down in the Act of Parliament) were that it was to be serviced at a rate of 8% per annum; there was also a service charge of \u00a34,000 per annum payable to the bank for the management of the loan.\nThe Act limited the subscribers' investment to a maximum of \u00a310,000 each in the first instance, and \u00a31,200,000 in total (it was envisaged that the Exchequer would raise the remaining \u00a3300,000 through other forms of borrowing).\nIncorporation.\nThe royal charter of the Bank of England was granted on 27 July 1694, three months after the passing of the Act.\nIn the end the \u00a31.2 million was raised in 12 days; 1,268 people subscribed. Their holdings were known as Bank Stock (Bank Stock continued to be held in private ownership until 1946 when the Bank of England was nationalised). The majority of the original subscribers were of 'the mercantile middle classes of London' (though tradesmen and artisans also subscribed). Most (more than two-thirds) contributed less than \u00a31,000. As a proportion of the total amount raised, 25% came from 'esquires', 21% from merchants and 15% from titled aristocrats. Twelve per cent of the original subscribers were women. King William and Queen Mary (jointly) invested \u00a310,000, the maximum permitted sum, as did a handful of others (including Sir John Houblon).\nInvestment in the navy duly took place. As a side effect, the huge industrial effort needed (including establishing ironworks to make more nails and advances in agriculture feeding the quadrupled strength of the navy) started to transform the economy. This helped the new Kingdom of Great Britain \u2013 England and Scotland were formally united in 1707 \u2013 to become powerful. The power of the Royal Navy made Britain the dominant world power in the late 18th and early 19th centuries.\nGovernance.\nThe first Governor of the bank was John Houblon, and the first Deputy Governor Michael Godfrey. (330 years later, in 1994, the bank would issue a \u00a350 note depicting Houblon to mark its tercentenary.)\nGovernance was vested in the Governor, his Deputy and a 'Court' of 24 Directors (most of whom were merchant bankers recruited from the City); the Directors were elected annually by a 'General Court' of all the Bank's registered stockholders (collectively known as 'the Proprietors'). The common seal of the Court of Directors, adopted on 30 July 1694, depicted 'Britannia sitting and looking on a Bank of mony'; Britannia has been the bank's emblem ever since.\nThe Court appointed three senior officers who, alongside the Governor and Deputy Governor, were responsible for its day-to-day running of the bank: the Secretary and Sollicitor, the First Accomptant and the First Cashier. (Their successors, the Secretary, Chief Accountant and Chief Cashier, continued to head up the main divisions of the bank's operations for the next 250 years: the Chief Cashier and the Chief Accountant had oversight of the 'cash side' and the 'stock side' of the bank, respectively, while the Secretary oversaw its internal administration.)\nBesides these officers, the bank in 1694 was staffed by seventeen clerks and two doorkeepers.\nPremises.\nThe bank initially did not have its own building, first opening on 1 August 1694 in Mercers' Hall on Cheapside. This however was found to be too small and from 31 December 1694 the bank operated from Grocers' Hall (located then on Poultry), where it would remain for almost 40 years. (Houblon had served as Master of the Grocers' Company in 1690\u20131691.)\nOperation.\nThe Act of Parliament prohibited the bank from trading in goods or merchandise of any kind, though it was allowed to deal in gold and silver bullion, and in bills of exchange. Before very long, the bank was maximising its profits by issuing banknotes, taking deposits and lending on mortgages.\nIn its early days the bank made significant losses, not least by accepting clipped coins in exchange for its banknotes. The establishment of a Land Bank (by John Asgill and Nicholas Barbon) in 1695, and a currency shortage occasioned by the Great Recoinage of 1696, both threatened the bank's position; but Parliament intervened, passing another Act that year, which authorised the bank to increase its capital to over \u00a32.2 million through the enlarging of its stock by new subscriptions.\n18th century.\nIn 1700, the Hollow Sword Blade Company was purchased by a group of businessmen who wished to establish a competing English bank (in an action that would today be considered a \"back door listing\"). The Bank of England's initial monopoly on English banking was due to expire in 1710. However, it was instead renewed, and the Sword Blade company failed to achieve its goal.\nThe idea and reality of the national debt came about at around this time, and this was also largely managed by the bank. Through the 1715 Ways and Means Act, Parliament authorised the bank to receive subscriptions for a government issue of 5% annuities, designed to raise \u00a3910,000; this marked the start of the bank's role in managing Government Stocks, which were a means for people to invest in government debt (previously Government borrowing had been administered directly by the Exchequer). The bank was obliged by the Act to pay half-yearly dividends and to keep a book record of all transfers (as it was already accustomed to do with regard to its own Bank Stock).\nThe bank did not have a monopoly on lending to the government, however: the South Sea Company had been established in 1711, and in 1720 it too became responsible for part of the UK's national debt, becoming a major competitor to the Bank of England. While the \"South Sea Bubble\" disaster soon ensued, the company continued managing part of the UK national debt until 1853. The East India Company too was a lender of choice for the government.\nIn 1734 there were ninety-six members of staff at the bank. The bank's charter was renewed in 1742, and again in 1764. By the 1742 Act the bank became the only joint-stock company allowed to issue bank notes in the metropolis.\nThreadneedle Street.\nThe Bank of England moved to its current location, on the site of Sir John Houblon's house and garden in Threadneedle Street (close by the church of St Christopher le Stocks), in 1734. (The estate had been purchased ten years earlier; Houblon had died in 1712, but his widow lived on in the house until her death in 1731, after which the house was demolished and work on the bank began.)\nThe newly built premises, designed by George Sampson, occupied a narrow plot (around wide) extending north from Threadneedle Street. The front building contained transfer offices on the first floor, beneath which was an entrance arch leading to a courtyard. Facing the entrance was the 'main building' of the bank: a large Hall () in which bank notes were issued and exchanged, and where deposits and withdrawals could be made. (Sampson's Great Hall, later known as the Pay Hall, remained \"in situ\" and in use until Herbert Baker's comprehensive rebuilding in the late 1920s.) Beyond the Hall was a quadrangle of buildings enclosing a 'spacious and commodious Court-yard' (later known as Bullion Court). On the south side of the quadrangle were the Court Room and Committee Room, on the north side was a large Accountants' Office; on either side were arcaded walkways, with rooms for the senior officers, while the upper floors contained offices and apartments. Beneath the quadrangle were the vaults ('that have very strong Walls and Iron Gates, for the Preservation of the Cash'); access to the courtyard was provided, by way of a passage leading to a 'grand Gateway' on Bartholomew Lane, for the coaches and waggons 'that come frequently loaded with Gold and Silver Bullion'. The pediment above the entrance to the main Hall was decorated with a carved \"alto relievo\" figure of Britannia (who had appeared on the common seal of the bank since 30 July 1694); the sculptor was Robert Taylor, who went on to be appointed Architect, in succession to Sampson, in 1764. Inside, the east end of the Hall was dominated by a large statue by John Cheere of King William III, lauded in an accompanying Latin inscription as the bank's founder (\"conditor\"); at the opposite end, a large Venetian window looked out on St Christopher's churchyard.\nExpansion.\nIn the second half of the 18th century the bank gradually acquired neighbouring plots of land to enable it to expand, and after 1765 new buildings began to be added by the bank's newly appointed architect Robert Taylor. North-west of the Pay Hall, overlooking St Christopher's churchyard to the south, Taylor built a suite of rooms for the Directors of the bank centred on a new (much larger) Court Room and Committee Room (When the bank was rebuilt in the 1920s-30s, these rooms were removed from their original ground-floor location and reconstructed on the first floor; they continue to be used for meetings of the bank's Court of Directors and Monetary Policy Committee respectively.). East of the Pay Hall, Taylor built a suite of halls and offices dedicated to the management of stocks and dividends, which more or less doubled the size of the bank's footprint (extending it as far as Bartholomew Lane). These rooms were centred on a large Rotunda, also known as the Brokers' Exchange, where dealing in Government Stock took place; around it were arranged four sizeable Transfer Offices, each corresponding with a different fund (as described in the 1820s: 'In each office under the several letters of the alphabet, are arranged the books on which the names of all persons having property in the funds are registered, as well as the particulars of their respective interests'). All these offices were top-lit, to avoid the need for windows in the external walls.\nIn 1782 the church of St Christopher le Stocks was demolished, allowing the bank to expand westwards along Threadneedle Street. The new west wing was completed to Taylor's design in 1786 (its frontage matching that of Taylor's earlier east wing): it housed the Reduced Annuities Office, the Cheque Office and the Dividend Warrant Office (among others). Immediately to the north lay the former churchyard of St Christopher le Stocks, which was preserved within the complex of buildings as a garden (known as the 'Garden Court'). North of Bullion Court, Taylor built a new four-storey Library, to house the bank's expanding collection of archives.\nThe Bank Picquet.\nThe church's demolition had been prompted by the 1780 Gordon Riots, during which rioters reportedly climbed on the church to throw projectiles at the buildings of the bank. During the riots, in June 1780, the Lord Mayor of London petitioned the Secretary of State to send a military guard to protect the bank and the Mansion House. Thenceforward a nightly guard (the 'Bank Picquet') was provided by soldiers of the Household Brigade (a practice which continued until 1973). To house the guard Taylor built a barracks (accessed from a separate entrance on Princes Street) in the north-west corner of the site.\nJohn Soane's rebuilding.\nSir Robert Taylor died in 1788 and in his place the bank appointed John Soane as Architect and Surveyor (he would remain in post until 1827). Under his direction, the bank was further expanded and partially rebuilt, bit by bit but to a cohesive plan. A survey of the buildings, undertaken at the start of his tenure, identified some problems, which were promptly remedied by Soane: for example in 1795 he rebuilt the Rotunda and two of the adjacent Transfer Offices (the Bank Stock Office and the Four Per Cent Office), replacing Taylor's timber roofs, which were leaking, with more durable stonework. At the same time Soane was tasked with purchasing properties to the north-east, with compulsory purchase powers granted by the &lt;templatestyles src=\"Template:Visible anchor/styles.css\" /&gt;Bank of England Site Act 1793 (33 Geo. 3. c. 15), so as to enable the bank to expand in that direction as far as Lothbury. Between 1794 and 1800 he designed a cohesive set of buildings within the new irregularly-shaped site: he reconfigured Bullion Court and provided a new entrance route for vehicles from the north, which was named Lothbury Court; to the west of this he built a new Chief Cashier's office, and rooms for the Secretary and Chief Accountant; to the east he constructed a new Library block and added a fifth Transfer Office (the Consols Transfer Office) to the north of the other four.\nThe Brokers' Exchange in the Bank.\nIn the late 18th and early 19th century, prior to the establishment of the London Stock Exchange, the Rotunda in the Bank of England was used as a trading floor 'where stock-brokers, stock-jobbers, and other persons, meet for the purpose of transacting business in public funds'. Branching off from the Rotunda were 'offices appropriated to the management of each particular stock' containing books listing every individual's registered interest in the fund. The use of the Rotunda for trading ceased in 1838, but it continued to be used for the cashing of fundholders' dividend warrants.\nConflicts and credit crises.\nThe credit crisis of 1772 has been described as the first modern banking crisis faced by the Bank of England. The whole City of London was in uproar when Alexander Fordyce was declared bankrupt. In August 1773, the Bank of England assisted the EIC with a loan. The strain upon the reserves of the Bank of England was not eased until towards the end of the year.\nDuring the American War of Independence, business for the bank was so good that George Washington remained a shareholder throughout the period.\nBy the bank's charter renewal in 1781, it was also the bankers' bank\u00a0\u2013 keeping enough gold to pay its notes on demand until 26 February 1797 when war had so diminished gold reserves that \u2013 following an invasion scare caused by the Battle of Fishguard days earlier \u2013 the government prohibited the bank from paying out in gold by the passing of the bank Restriction Act 1797. This prohibition lasted until 1821.\nIn 1798, during the French Revolutionary Wars, a Corps of bank Volunteers was formed (of between 450 and 500 men) to defend the bank in the event of an invasion. It was disbanded in 1802, but promptly re-formed the following year at the start of the Napoleonic Wars. Its soldiers were trained, in the event of an invasion, to remove the gold and silver from the vaults to a remote location, along with the banknote printing presses and certain important records. An armoury was provided on site at Threadneedle Street for their arms and accoutrements. The Corps was finally disbanded in 1814.\n19th century.\nAt the start of the 19th century a plan was enacted by John Soane for the further extension of the bank's premises, this time to the north-west (necessitating the rerouting of Princes Street, to form the new western boundary of the site). Much of the area of the new extension was taken up with steam-powered presses for the printing of banknotes (notes continued to be printed on site until the First World War, when the former St Luke's Hospital was acquired and converted into the bank's printing works). Soane continued in post until 1833; in the last years before his retirement he completed his rebuilding of Taylor's east wing and reconfigured Sampson and Taylor's street-facing fa\u00e7ades to make the entire perimeter of the complex a coherent whole.\nIn 1811, an 'ingeniously contrived clock' by Thwaites &amp; Co. was installed above the Pay Hall: as well as chiming the hours and quarters, it conveyed the time remotely (by means of brass rods extending a total of in length) to dials located in sixteen different offices around the site.\nThe 'panic of 1825' highlighted risks inherent in the bank's three-way split loyalties: to its stockholders, to the Government (and thereby to the public), and to its commercial banking customers. In 1825\u201326 the bank was able to avert a liquidity crisis when Nathan Mayer Rothschild succeeded in supplying it with gold; nevertheless, after the crisis, many country and provincial banks failed prompting numerous commercial bankruptcies. The passing of the Country Bankers Act 1826 allowed the bank to open provincial branches for the better distribution of its banknotes (at the time small country banks, some of which were significantly undercapitalised, issued their own notes); by the end of the following year eight Bank of England branches had been set up around the country.\nThe Bank Charter Act 1844 tied the issue of notes to the gold reserves and gave the Bank of England sole rights with regard to the issue of banknotes in England. Private banks that had previously had that right retained it, provided that their headquarters were outside London and that they deposited security against the notes that they issued; but they were offered inducements to relinquish this right. (The last private bank in England to issue its own notes was Thomas Fox's Fox, Fowler and Company bank in Wellington, which rapidly expanded until it merged with Lloyds Bank in 1927. They remained legal tender until 1964. (There are nine notes left in circulation; one is housed at Tone Dale House, Wellington.))\nThe bank acted as lender of last resort for the first time in the panic of 1866.\n20th century.\nUntil 1931 Britain was on the gold standard, meaning the value of sterling was fixed by the price of gold. That year, the Bank of England had to take Britain off the gold standard due to the effects of Great Depression spreading to Europe.\n1913 attempted bombing.\nA terrorist bombing was attempted outside the Bank of England building on 4\u00a0April 1913. A bomb was discovered smoking and ready to explode next to railings outside the building. The bomb had been planted as part of the suffragette bombing and arson campaign, in which the Women's Social and Political Union (WSPU) launched a series of politically motivated bombing and arson attacks nationwide as part of their campaign for women's suffrage. The bomb was defused before it could detonate, in what was then one of the busiest public streets in the capital, which likely prevented many civilian casualties. The bomb had been planted the day after WSPU leader Emmeline Pankhurst was sentenced to three years' imprisonment for carrying out a bombing on the home of politician David Lloyd George.\nThe remains of the bomb, which was built into a milk churn, are now on display at the City of London Police Museum.\nRestructuring and rebuilding.\nDuring the governorship of Montagu Norman, from 1920 to 1944, the bank made deliberate efforts to move away from commercial banking and become a central bank. A later Governor, Robin Leigh-Pemberton, described it as 'a time of rapid change, in which we began to move away from the clerical traditions of 200 years [...] and to accept specialisation, mechanisation and modern management disciplines'. Economists and statisticians began to be employed at the bank in increasing number. In 1931 the 'Peacock Committee', set up to advise on organisational improvements, published recommendations which included the appointment of paid executive Directors (alongside the traditional non-executive members of the Court). It also recommended reconfiguration of the bank's traditional departmental structures.\nThe work of the bank had significantly increased since the end of the First World War, and the decision was taken to expand. Between 1925 and 1939 the bank's headquarters on Threadneedle Street were comprehensively rebuilt by Herbert Baker. (This involved the demolition of most of Sir John Soane's buildings, an act described by architectural historian Nikolaus Pevsner as \"the greatest architectural crime, in the City of London, of the twentieth century\".) Initially the plan had been to retain Soane's banking halls behind the curtain wall, but this proved challenging so they were instead demolished and rebuilt in facsimile. The demolition and rebuilding took place in stages, with staff moving from one part of the building to another (or, in some cases, into temporary accommodation at Finsbury Circus). The bullion and securities remained on site throughout. During reconstruction human remains pertaining to the old churchyard of St Christopher le Stocks were exhumed and reburied at Nunhead Cemetery.\nBaker's steel-framed building stands seven storeys high, with a further three vault storeys extending below ground level. It is decorated with sculpture and bronze work by Charles Wheeler, plasterwork by Joseph Armitage and mosaics by Boris Anrep. The bank today is a Grade I listed building.\n1939 saw the introduction of Exchange Controls in the United Kingdom at the outbreak of the Second World War; these were administered by the bank. During WWII, over 10% of the face value of circulating Pound Sterling banknotes were forgeries produced by Germany.\nA number of the bank's operations and staff were relocated to Hampshire for the duration of the war, including the printing works (which moved to Overton), the Accountant's Department (which went to Hurstbourne Park) and various other offices. Those who remained at Threadneedle Street, including the Directors, moved their offices into the underground vaults.\nPost-war nationalisation.\nIn 1946, shortly after the end of Montagu Norman's tenure, the bank was nationalised by the Labour government. At the same time the number of Directors was reduced to sixteen (four of whom were full-time Executive Directors).\nThe bank pursued the multiple goals of Keynesian economics after 1945, especially \"easy money\" and low-interest rates to support aggregate demand. It tried to keep a fixed exchange rate and attempted to deal with inflation and sterling weakness by credit and exchange controls.\nAfter the war, the very large Accountant's Department (which managed the stock side of the bank) moved back to London from Hampshire. Its designated office-space at Threadneedle Street, however, had in the meantime been taken over by the Exchange Control office. The department was instead provided with temporary accommodation (once more in Finsbury Circus), pending construction of a new building, which would occupy a two-acre bombsite immediately to the east of St Paul's Cathedral. 'Bank of England New Change' was designed by Victor Heal and opened in 1957 (at the time it was London's biggest post-war rebuilding project); the new building contained several staff amenities alongside the office accommodation and, at street level, retail units were let to an assortment of businesses. The bank had the building on a 200-year lease; but with the advent of computerisation staff numbers were drastically reduced in the 1980s-90s; parts of the building were let to other firms (most notably the law firm Allen &amp; Overy). The bank sold the building in 2000 and in 2007 it was demolished; One New Change now stands on the site.\nThe bank's \"10 bob note\" was withdrawn from circulation in 1970 in preparation for Decimal Day in 1971.\nIn 1977 the bank set up a wholly owned subsidiary called Bank of England Nominees Limited (BOEN), a now-defunct private limited company, with two of its hundred \u00a31 shares issued. According to its memorandum of association, its objectives were: \"To act as Nominee or agent or attorney either solely or jointly with others, for any person or persons, partnership, company, corporation, government, state, organisation, sovereign, province, authority, or public body, or any group or association of them\". Bank of England Nominees Limited was granted an exemption by Edmund Dell, Secretary of State for Trade, from the disclosure requirements under Section 27(9) of the Companies Act 1976, because \"it was considered undesirable that the disclosure requirements should apply to certain categories of shareholders\". The Bank of England is also protected by its royal charter status and the Official Secrets Act. BOEN was a vehicle for governments and heads of state to invest in UK companies (subject to approval from the Secretary of State), providing they undertake \"not to influence the affairs of the company\". In its later years, BOEN was no longer exempt from company law disclosure requirements. Although a dormant company, dormancy does not preclude a company actively operating as a nominee shareholder. BOEN had two shareholders: the Bank of England, and the Secretary of the Bank of England.\nThe reserve requirement for banks to hold a minimum fixed proportion of their deposits as reserves at the Bank of England was abolished in 1981: see for more details. The contemporary transition from Keynesian economics to Chicago economics was analysed by Nicholas Kaldor in \"The Scourge of Monetarism\".\nThe handing over of monetary policy to the bank became a key plank of the Liberal Democrats' economic policy for the 1992 general election. Conservative MP Nicholas Budgen had also proposed this as a private member's bill in 1996, but the bill failed as it had the support of neither the government nor the opposition.\nThe UK government left the expensive-to-maintain European Exchange Rate Mechanism in September 1992, in an action that cost HM Treasury over \u00a33 billion. This led to closer communication between the government and the bank.\nIn 1993, the bank produced its first \"Inflation Report\" for the government, detailing inflationary trends and pressures. This annually produced report remains one of the bank's major publications. The success of inflation targeting in the United Kingdom has been attributed to the bank's focus on transparency. The Bank of England has been a leader in producing innovative ways of communicating information to the public, especially through its Inflation Report, which many other central banks have emulated.\nThe bank celebrated its three-hundredth birthday in 1994.\nIn 1996, the bank produced its first \"Financial Stability Review\". This annual publication became known as the \"Financial Stability Report\" in 2006. Also that year, the bank set up its real-time gross settlement (RTGS) system to improve risk-free settlement between UK banks.\nOn 6 May 1997, following the 1997 general election that brought a Labour government to power for the first time since 1979, it was announced by the Chancellor of the Exchequer, Gordon Brown, that the bank would be granted operational independence over monetary policy. Under the terms of the Bank of England Act 1998 (which came into force on 1 June 1998) the bank's Monetary Policy Committee (MPC) was given sole responsibility for setting interest rates to meet the Government's Retail Prices Index (RPI) inflation target of 2.5%. The target has changed to 2% since the Consumer Price Index (CPI) replaced the Retail Prices Index as the Treasury's inflation index. If inflation overshoots or undershoots the target by more than 1% the Governor has to write a letter to the Chancellor of the Exchequer explaining why, and how he will remedy the situation.\nIndependent central banks that adopt an inflation target are known as Friedmanite central banks. This change in Labour's politics was described by Skidelsky in \"The Return of the Master\" as a mistake and as an adoption of the rational expectations hypothesis as promulgated by Alan Walters. Inflation targets combined with central bank independence have been characterised as a \"starve the beast\" strategy creating a lack of money in the public sector.\nin June 1998 responsibility for the regulation and supervision of the banking and insurance industries was transferred from the bank to the Financial Services Authority. A memorandum of understanding described the terms under which the bank, the Treasury, and the FSA would work toward the common aim of increased financial stability. (Ten years later, however, after the 2008 financial crisis, new banking legislation transferred the responsibility for regulation and supervision of the banking and insurance industries back to the Bank of England).\n21st century.\nThe bank decided to sell its banknote-printing operations to De La Rue in December 2002, under the advice of Close Brothers Corporate Finance Ltd.\nMervyn King became the Governor of the Bank of England on 30\u00a0June 2003.\nIn 2009, a request made to HM Treasury under the Freedom of Information Act sought details about the 3% Bank of England stock owned by unnamed shareholders whose identity the bank is not at liberty to disclose. In a letter of reply dated 15\u00a0October 2009, HM Treasury explained that \"Some of the 3% Treasury stock which was used to compensate former owners of bank stock has not been redeemed. However, interest is paid out twice a year and it is not the case that this has been accumulating and compounding.\"\nIn 2010, the incoming Chancellor announced his intention to merge the Financial Services Authority back into the bank. In 2011 an interim Financial Policy Committee (FPC) was created (as a mirror committee to the Monetary Policy Committee) to spearhead the bank's new mandate on financial stability. The Financial Services Act 2012 gave the bank additional functions and bodies, including an independent FPC, the Prudential Regulation Authority (PRA), and more powers to supervise financial market infrastructure providers. It also created the independent Financial Conduct Authority. These bodies are responsible for macroprudential regulation of all UK banks and insurance companies.\nCanadian Mark Carney assumed the post of Governor of the Bank of England on 1\u00a0July 2013. He served an initial five-year term rather than the typical eight. He became the first Governor not to be a United Kingdom citizen but has since been granted citizenship. At Government request, his term was extended to 2019, then again to 2020. As of \u00a02014[ [update]], the bank also had four Deputy Governors.\nBOEN was dissolved, following liquidation, in July 2017.\nAndrew Bailey succeeded Carney as the Governor of the Bank of England on 16\u00a0March 2020.\nAsset purchase facility.\nThe bank has operated, since January 2009, an Asset Purchase Facility (APF) to buy \"high-quality assets financed by the issue of Treasury bills and the DMO's cash management operations\" and thereby improve liquidity in the credit markets. It has, since March 2009, also provided the mechanism by which the bank's policy of quantitative easing (QE) is achieved, under the auspices of the MPC. Along with managing the QE funds, which were \u00a3895 bn at peak, the APF continues to operate its corporate facilities. Both are undertaken by a subsidiary company of the Bank of England, the Bank of England Asset Purchase Facility Fund Limited (BEAPFF).\nQE was primarily designed as an instrument of monetary policy. The mechanism required the Bank of England to purchase government bonds on the secondary market, financed by creating new central bank money. This would have the effect of increasing the asset prices of the bonds purchased, thereby lowering yields and dampening longer-term interest rates. The policy's aim was initially to ease liquidity constraints in the sterling reserves system but evolved into a wider policy to provide economic stimulus.\nQE was enacted in six tranches between 2009 and 2020. At its peak in 2020, the portfolio totalled \u00a3895 billion, comprising \u00a3875 billion of UK government bonds and \u00a320 billion of high-grade commercial bonds.\nIn February 2022, the Bank of England announced its intention to commence winding down the QE portfolio. Initially this would be achieved by not replacing tranches of maturing bonds, and would later be accelerated through active bond sales.\nIn August 2022, the Bank of England reiterated its intention to accelerate the QE wind-down through active bond sales. This policy was affirmed in an exchange of letters between the Bank of England and the UK Chancellor of the Exchequer in September 2022. Between February 2022 and September 2022, a total of \u00a337.1bn of government bonds matured, reducing the outstanding stock from \u00a3875.0bn at the end of 2021 to \u00a3837.9bn. In addition, a total of \u00a31.1bn of corporate bonds matured, reducing the stock from \u00a320.0bn to \u00a318.9bn, with sales of the remaining stock planned to begin on 27 September.\nBanknote issues.\nThe bank has issued banknotes since 1694. Notes were originally hand-written; although they were partially printed from 1725 onwards, cashiers still had to sign each note and make them payable to someone. Notes were fully printed from 1855. Until 1928 all notes were \"White Notes\", printed in black and with a blank reverse. In the 18th and 19th centuries, White Notes were issued in \u00a31 and \u00a32 denominations. During the 20th century, White Notes were issued in denominations between \u00a35 and \u00a31000. Until the passing of the Gold Standard Act 1925 the bank was obliged to pay on demand the value of the note in gold coin to its bearer.\nIn 1724 the bank entered into a contract with Henry Portal of Whitchurch, Hampshire to provide high-quality paper for the printing of banknotes. The printing itself was undertaken by private printing firms; the copper plates were kept in the vault, and accompanied during their time at the printer by a bank clerk (who would record the number of copies made); once dry they would be delivered to the bank. The printing operation was brought within the bank's premises (albeit still under private contract) in 1791; in 1808 it was brought fully in-house.\nUntil the mid-19th century, commercial banks were allowed to issue their own banknotes, and notes issued by provincial banking companies were commonly in circulation. The Bank Charter Act 1844 began the process of restricting note issue to the bank; new banks were prohibited from issuing their own banknotes, and existing note-issuing banks were not permitted to expand their issue. As provincial banking companies merged to form larger banks, they lost their right to issue notes, and the English private banknote eventually disappeared, leaving the bank with a monopoly of note issues in England and Wales. The last private bank to issue its own banknotes in England and Wales was Fox, Fowler and Company in 1921. However, the limitations of the 1844 Act only affected banks in England and Wales, and today three commercial banks in Scotland and three in Northern Ireland continue to issue their own banknotes, regulated by the bank.\nAt the start of the First World War, the Currency and Bank Notes Act 1914 was passed, which granted temporary powers to HM Treasury for issuing banknotes to the values of \u00a31 and 10/- (ten shillings). Treasury notes had full legal tender status and were not convertible into gold through the bank; they replaced the gold coin in circulation to prevent a run on sterling and to enable raw material purchases for armament production. These notes featured an image of King George V (Bank of England notes did not begin to display an image of the monarch until 1960). The wording on each note was:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;UNITED KINGDOM OF GREAT BRITAIN AND IRELAND \u2013 Currency notes are Legal Tender for the payment of any amount \u2013 Issued by the Lords Commissioners of His Majesty's Treasury under the Authority of Act of Parliament (4 &amp; 5 Geo. V c.14).\nTreasury notes were issued until 1928 when the Currency and Bank Notes Act 1928 returned note-issuing powers to the banks. The Bank of England issued notes for ten shillings and one pound for the first time on 22 November 1928.\nDuring the Second World War, the German Operation Bernhard attempted to counterfeit denominations between \u00a35 and \u00a350, producing 500,000 notes each month in 1943. The original plan was to parachute the money into the UK in an attempt to destabilise the British economy, but it was found more useful to use the notes to pay German agents operating throughout Europe. Although most fell into Allied hands at the end of the war, forgeries frequently appeared for years afterward, which led banknote denominations above \u00a35 to be removed from circulation.\nIn 2006, over \u00a353\u00a0million in banknotes belonging to the bank was stolen from a depot in Tonbridge, Kent.\nIn 1917 the bank had moved its printing operation into St Luke's Printing Works, a former hospital; in 1958 it moved out to Debden. Modern banknotes are printed by contract with De La Rue Currency in Loughton, Essex.\nBranch offices.\nFor most of the nineteenth and twentieth centuries the bank had a number of branches in London and other English cities.\nThe first branches opened in 1826 (with impetus provided by the passing of the Country Bankers Act, which for the first time permitted the establishment of joint-stock banks outside London). The bank envisaged that the new network of branches would 'increase the circulation of Bank Notes, give the bank much more complete control over the whole paper circulation, and protect the bank against the competition of larger banking Companies'. Each branch was overseen by an Agent (a person of 'commercial knowledge, with local experience'). By 1829 there were eleven branches operating (ten in England and one in Wales). Some of the less profitable branches were relatively short-lived, but others continued operating into the 1990s.\nIn 1997 the five last remaining branches closed; the Agents, however, were retained, with a structure of Regional Agencies created (across the UK), some of which were based in former branch buildings.\nGovernance of the Bank of England.\nGovernors.\nFollowing is a list of the governors of the Bank of England since the beginning of the 20th century:\nCourt of Directors.\nThe Court of Directors is a unitary board that is responsible for setting the organisation's strategy and budget and making key decisions on resourcing and appointments. It consists of five executive members from the bank (the Governor and the four Deputy Governors, each of whom oversees a different area of the bank's work), plus up to 9 non-executive members, all of whom are appointed by the Crown. The Chancellor selects the Chairman of the Court from among the non-executive members. The Court is required to meet at least seven times a year.\nThe Governor serves for a period of eight years, the Deputy Governors for five years, and the non-executive members for up to four years.\nOther staff.\nThe Secretary of the Bank of England is today responsible for the banks governance and ethics: 'He is responsible for ensuring the organisation is well run and advises our Court of Directors [...] He is also our conflicts officer and supports the Government when it makes appointments to our policy committees and Court of Directors'.\nSince 2013, the bank has had a chief operating officer (COO) with the status and remuneration of a Deputy Governor. As of 2024[ [update]], the bank's COO is Ben Stimson; he is responsible for the day-to-day operations of the bank, including Human Resources, Property, IT and Security. In March 2025, the Bank of England appointed Sarah John as its new Chief Operating Officer. John previously served as the Bank's Chief Cashier.\nSome twenty executive directors work alongside the Governors, forming 'the wider executive management team'. Among their number are the bank's chief economist (Huw Pill since 2021), and chief cashier.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "4485", "revid": "27015025", "url": "https://en.wikipedia.org/wiki?curid=4485", "title": "Bakelite", "text": "First synthetic plastic\n&lt;templatestyles src=\"Chembox/styles.css\"/&gt;\nChemical compound\nBakelite ( ), formally , is a thermosetting phenol formaldehyde resin, formed from a condensation reaction of phenol with formaldehyde. The first plastic made from synthetic components, it was developed by Belgian chemist Leo Baekeland in Yonkers, New York, in 1907, and patented on December 7, 1909.\nBakelite was one of the first plastic-like materials to be introduced into the modern world and was popular because it could be molded and then hardened into any shape.\nBecause of its electrical nonconductivity and heat-resistant properties, it became a great commercial success. It was used in electrical insulators, radio and telephone casings, and such diverse products as kitchenware, jewelry, pipe stems, children's toys, and firearms.\nThe retro appeal of old Bakelite products has made them collectible.\nThe creation of a synthetic plastic was revolutionary for the chemical industry, which at the time made most of its income from cloth dyes and explosives. Bakelite's commercial success inspired the industry to develop other synthetic plastics. As the world's first commercial synthetic plastic, Bakelite was named a National Historic Chemical Landmark by the American Chemical Society.\nHistory.\nThe reaction between phenol and aldehyde was first reported in 1872 by Adolf von Baeyer, though its use as a commercial product was not considered at the time.\nLeo Baekeland was already wealthy due to his invention of Velox photographic paper when he began to investigate the reactions of phenol and formaldehyde in his home laboratory. Chemists had begun to recognize that many natural resins and fibers were polymers. Baekeland's initial intent was to find a replacement for shellac, a material in limited supply because it was made naturally from the secretion of lac insects (specifically \"Kerria lacca\"). He produced a soluble phenol-formaldehyde shellac called Novolak, but it was not a market success, even though it is still used to this day (e.g., as a photoresist).\nHe then began experimenting on strengthening wood by impregnating it with a synthetic resin rather than coating it. By controlling the pressure and temperature applied to phenol and formaldehyde, he produced a hard moldable material that he named Bakelite, after himself and the heat curing process it required. It was the first synthetic thermosetting plastic produced, and Baekeland speculated on \"the thousand and one\u00a0... articles\" it could be used to make. He considered the possibilities of using a wide variety of filling materials, including cotton, powdered bronze, and slate dust, but was most successful with wood and asbestos fibers, though asbestos was gradually abandoned by all manufacturers in the latter quarter of the 20th century due to stricter environmental laws.\nBaekeland filed a substantial number of related patents. Bakelite, his \"method of making insoluble products of phenol and formaldehyde\", was filed on July 13, 1907, and granted on December 7, 1909. He also filed for patent protection in other countries, including Belgium, Canada, Denmark, Hungary, Japan, Mexico, Russia, and Spain. He announced his invention at a meeting of the American Chemical Society on February 5, 1909.\nBaekeland started semi-commercial production of his new material in his home laboratory, marketing it as a material for electrical insulators. In the summer of 1909, he licensed the continental European rights to R\u00fctger AG. The subsidiary formed at that time, Bakelite AG, was the first to produce Bakelite on an industrial scale.\nBy 1910, Baekeland was producing enough material in the US to justify expansion. He formed the General Bakelite Company of Perth Amboy, New Jersey, as a U.S. company to manufacture and market his new industrial material, and made overseas connections to produce it in other countries.\nThe Bakelite Company produced \"transparent\" cast resin (which did not include filler) for a small market during the 1910s and 1920s. Blocks or rods of cast resin, also known as \"artificial amber\", were machined and carved to create items such as pipe stems, cigarette holders, and jewelry. However, the demand for molded plastics led the company to concentrate on molding rather than cast solid resins.\nThe Bakelite Corporation was formed in 1922 after patent litigation favorable to Baekeland, from a merger of three companies: Baekeland's General Bakelite Company; the Condensite Company, founded by J. W. Aylesworth; and the Redmanol Chemical Products Company, founded by Lawrence V. Redman. Under director of advertising and public relations Allan Brown, who came to Bakelite from Condensite, Bakelite was aggressively marketed as \"the material of a thousand uses\". A filing for a trademark featuring the letter B above the infinity symbol was made August 25, 1925, and claimed the mark was in use as of December 1, 1924. A wide variety of uses were listed in their trademark applications.\nThe first issue of \"Plastics\" magazine, October 1925, featured Bakelite on its cover and included the article \"Bakelite \u2013 What It Is\" by Allan Brown. The range of colors that were available included \"black, brown, red, yellow, green, gray, blue, and blends of two or more of these\". The article emphasized that Bakelite came in various forms.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Bakelite is manufactured in several forms to suit varying requirements. In all these forms the fundamental basis is the initial Bakelite resin. This variety includes clear material, for jewelry, smokers' articles, etc.; cement, for sealing electric light bulbs in metal bases; varnishes, for impregnating electric coils, etc.; lacquers, for protecting the surface of hardware; enamels, for giving resistive coating to industrial equipment; Laminated Bakelite, used for silent gears and insulation; and molding material, from which are formed innumerable articles of utility and beauty. The molding material is prepared ordinarily by the impregnation of cellulose substances with the initial \"uncured\" resin.\nIn a 1925 report, the United States Tariff Commission hailed the commercial manufacture of synthetic phenolic resin as \"distinctly an American achievement\", and noted that \"the publication of figures, however, would be a virtual disclosure of the production of an individual company\".\nIn the UK, Bakelite Limited, a merger of three British phenol formaldehyde resin suppliers (Damard Lacquer Company Limited of Birmingham, Mouldensite Limited of Darley Dale and Redmanol Chemical Products Company of London), was formed in 1926. A new Bakelite factory opened in Tyseley, Birmingham, around 1928. It was the \"heart of Bakelite production in the UK\" until it closed in 1987.\nA factory to produce phenolic resins and precursors opened in Bound Brook, New Jersey, in 1931.\nIn 1939, the companies were acquired by Union Carbide and Carbon Corporation.\nIn 2005, German Bakelite manufacturer Bakelite AG was acquired by Borden Chemical of Columbus, Ohio, now Hexion Inc.\nIn addition to the original Bakelite material, these companies eventually made a wide range of other products, many of which were marketed under the brand name \"Bakelite plastics\". These included other types of cast phenolic resins similar to Catalin, and urea-formaldehyde resins, which could be made in brighter colors than .\nOnce Baekeland's heat and pressure patents expired in 1927, Bakelite Corporation faced serious competition from other companies. Because molded Bakelite incorporated fillers to give it strength, it tended to be made in concealing dark colors. In 1927, beads, bangles, and earrings were produced by the Catalin company, through a different process which enabled them to introduce 15 new colors. Translucent jewelry, poker chips and other items made of phenolic resins were introduced in the 1930s or 1940s by the Catalin company under the Prystal name. The creation of marbled phenolic resins may also be attributable to the Catalin company.\nSynthesis.\nMaking Bakelite is a multi-stage process. It begins with the heating of phenol and formaldehyde in the presence of a catalyst such as hydrochloric acid, zinc chloride, or the base ammonia. This creates a liquid condensation product, referred to as \"Bakelite A\", which is soluble in alcohol, acetone, or additional phenol. Heated further, the product becomes partially soluble and can still be softened by heat. Sustained heating results in an \"insoluble hard gum\". However, the high temperatures required to create this tend to cause violent foaming of the mixture when done at standard atmospheric pressure, which results in the cooled material being porous and breakable. Baekeland's innovative step was to put his \"last condensation product\" into an egg-shaped \"Bakelizer\". By heating it under pressure, at about , Baekeland was able to suppress the foaming that would otherwise occur. The resulting substance is extremely hard and both infusible and insoluble.\nCompression molding.\nMolded Bakelite forms in a condensation reaction of phenol and formaldehyde, with wood flour or asbestos fiber as a filler, under high pressure and heat in a time frame of a few minutes of curing. The result is a hard plastic material. Asbestos was gradually abandoned as filler because many countries banned the production of asbestos.\nBakelite's molding process had a number of advantages. Bakelite resin could be provided either as powder or as preformed partially cured slugs, increasing the speed of the casting. Thermosetting resins such as Bakelite required heat and pressure during the molding cycle but could be removed from the molding process without being cooled, again making the molding process faster. Also, because of the smooth polished surface that resulted, Bakelite objects required less finishing. Millions of parts could be duplicated quickly and relatively cheaply.\nPhenolic sheet.\nAnother market for Bakelite resin was the creation of phenolic sheet materials. A phenolic sheet is a hard, dense material made by applying heat and pressure to layers of paper or glass cloth impregnated with synthetic resin. Paper, cotton fabrics, synthetic fabrics, glass fabrics, and unwoven fabrics are all possible materials used in lamination. When heat and pressure are applied, polymerization transforms the layers into thermosetting industrial laminated plastic.\nBakelite phenolic sheet is produced in many commercial grades and with various additives to meet diverse mechanical, electrical, and thermal requirements. Some common types include:\nProperties.\nBakelite has a number of important properties. It can be molded very quickly, decreasing production time. Moldings are smooth, retain their shape, and are resistant to heat, scratches, and destructive solvents. It is also resistant to electricity, and prized for its low conductivity. It is not flexible.\nPhenolic resin products may swell slightly under conditions of extreme humidity or perpetual dampness. When rubbed or burnt, Bakelite has a distinctive, acrid, sickly-sweet or fishy odor.\nApplications.\nThe characteristics of Bakelite made it particularly suitable as a molding compound, an adhesive or binding agent, a varnish, and a protective coating, as well as for the emerging electrical and automobile industries because of its extraordinarily high resistance to electricity, heat, and chemical action.\nThe earliest commercial use of Bakelite in the electrical industry was the molding of tiny insulating bushings, made in 1908 for the Weston Electrical Instrument Corporation by Richard W. Seabury of the Boonton Rubber Company. Bakelite was soon used for non-conducting parts of telephones, radios, and other electrical devices, including bases and sockets for light bulbs and electron tubes (vacuum tubes), supports for any type of electrical components, automobile distributor caps, and other insulators. By 1912, it was being used to make billiard balls, since its elasticity and the sound it made were similar to ivory.\nDuring World War I, Bakelite was used widely, particularly in electrical systems. Important projects included the Liberty airplane engine, the wireless telephone and radio phone, and the use of micarta-bakelite propellers in the NBS-1 bomber and the DH-4B aeroplane.\nBakelite's availability and ease and speed of molding helped to lower the costs and increase product availability so that telephones and radios became common household consumer goods. It was also very important to the developing automobile industry. It was soon found in myriad other consumer products ranging from pipe stems and buttons to saxophone mouthpieces, cameras, early machine guns, and appliance casings. Bakelite was also very commonly used in the pistol grip, hand guard, and buttstock of firearms. Also magazines for Kalashnikov rifles - though components of the AKM, and some early AK-74 rifles are frequently mistakenly identified as using Bakelite, but most were made with AG-4S. Other uses through the first half of the 20th century include knife handles and \"scales\".\nBeginning in the 1920s, it became a popular material for jewelry. Designer Coco Chanel included Bakelite bracelets in her costume jewelry collections. Designers such as Elsa Schiaparelli used it for jewelry and also for specially designed dress buttons. Later, Diana Vreeland, editor of \"Vogue\", was enthusiastic about Bakelite. Bakelite was also used to make presentation boxes for Breitling watches.\nBy 1930, designer Paul T. Frankl considered Bakelite a \"Materia Nova\", \"expressive of our own age\". By the 1930s, Bakelite was used for game pieces like chess pieces, poker chips, dominoes, and mahjong sets. Kitchenware made with Bakelite, including canisters and tableware, was promoted for its resistance to heat and to chipping. In the mid-1930s, Northland marketed a line of skis with a black \"Ebonite\" base, a coating of Bakelite. By 1935, it was used in solid-body electric guitars. Performers such as Jerry Byrd loved the tone of Bakelite guitars but found them difficult to keep in tune.\nCharles Plimpton patented BAYKO in 1933 and rushed out his first construction sets for Christmas 1934. He called the toy Bayko Light Constructional Sets, the words \"Bayko Light\" being a pun on the word \"Bakelite\".\nDuring World War II, Bakelite was used in a variety of wartime equipment including pilots' goggles and field telephones. It was also used for patriotic wartime jewelry. In 1943, the thermosetting phenolic resin was even considered for the manufacture of coins, due to a shortage of traditional material. Bakelite and other non-metal materials were tested for usage for the one cent coin in the US before the Mint settled on zinc-coated steel.\nDuring World War II, Bakelite buttons were part of British uniforms. These included brown buttons for the Army and black buttons for the RAF.\nIn 1947, Dutch art forger Han van Meegeren was convicted of forgery, after chemist and curator Paul B. Coremans proved that a purported Vermeer contained Bakelite, which van Meegeren had used as a paint hardener.\nBy the late 1940s, newer materials were superseding Bakelite in many areas. Phenolics are less frequently used in general consumer products today due to their cost and complexity of production, and brittle nature. They still appear in some applications where their specific properties are required, such as small precision-shaped components, molded disc brake cylinders, saucepan handles, electrical plugs, switches and parts for electrical irons, printed circuit boards, as well as in the area of inexpensive board and tabletop games produced in China, Hong Kong, and India. Items such as billiard balls, dominoes and pieces for board games such as chess, checkers, and backgammon are constructed of Bakelite for its look, durability, fine polish, weight, and sound. Common dice are sometimes made of Bakelite for weight and sound, but the majority are made of a thermoplastic polymer such as acrylonitrile butadiene styrene (ABS).\nBakelite continues to be used for wire insulation, brake pads and related automotive components, and industrial electrical-related applications. Bakelite stock is still manufactured and produced in sheet, rod, and tube form for industrial applications in the electronics, power generation, and aerospace industries, and under a variety of commercial brand names.\nPhenolic resins have high heat resistance and tend to smolder rather than burn or melt. For this reason Phenolics are used in welding and other high heat applications and have been commonly used in ablative heat shields. Soviet heatshields for ICBM warheads and spacecraft reentry consisted of asbestos textolite, impregnated with Bakelite. Bakelite is also used in the mounting of metal samples in metallography. \nCollectibles.\nBakelite items, particularly jewelry and radios, have become popular collectibles.\nThe term \"Bakelite\" is sometimes used in the resale market as a catch-all for various types of early plastics, including Catalin and Faturan, which may be brightly colored, as well as items made of true Bakelite material.\nDue to its aesthetics, a similar material \"fakelite\" (fake bakelite) exists made from modern safer materials which do not contain asbestos.\nPatents.\nThe United States Patent and Trademark Office granted Baekeland a patent for a \"Method of making insoluble products of phenol and formaldehyde\" on December 7, 1909. Producing hard, compact, insoluble, and infusible condensation products of phenols and formaldehyde marked the beginning of the modern plastics industry.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "4486", "revid": "22831189", "url": "https://en.wikipedia.org/wiki?curid=4486", "title": "Buckyball (molecule)", "text": ""}
{"id": "4487", "revid": "49291118", "url": "https://en.wikipedia.org/wiki?curid=4487", "title": "Bean", "text": "Seed of several plants in the legume family\nA bean is the seed of plants in many genera of the legume family (Fabaceae) used as a vegetable for human consumption or animal feed. The seeds are sold fresh or preserved through drying (a \"pulse\"). Beans have been cultivated since the seventh millennium BCE in Thailand, and since the second millennium BCE in Europe and in Peru. Most beans, with the exception of peas, are summer crops. As legumes, the plants fix nitrogen and form seeds with a high protein content. They are produced on a scale of millions of tons annually in many countries; India is the largest producer.\nDried beans are traditionally soaked and boiled, and used in traditional dishes throughout the world including salads, soups, and stews such as chili con carne. Some are processed into tofu; others are fermented to form tempeh. Guar beans are used for their gum. The unripe seedpods of some varieties are also eaten whole as green beans or \"edamame\" (immature soybean). Some types are sprouted to form beansprouts.\nMany fully ripened beans contain toxins like phytohaemagglutinin and require cooking to make them safe to eat. Many species contain indigestible oligosaccharides that produce flatulence. Beans have traditionally been seen as a food of the poor.\nEtymology and naming.\nThe word \"bean\" and its Germanic cognates (e.g. German \"Bohne\") have existed in common use in West Germanic languages since before the 12th century, referring to broad beans, chickpeas, and other pod-borne seeds. This was long before the New World genus \"Phaseolus\" was known in Europe. With the Columbian exchange of domestic plants between Europe and the Americas, use of the word was extended to pod-borne seeds of \"Phaseolus\", such as the common bean and the runner bean, and the related genus \"Vigna\". The term has long been applied generally to seeds of similar form, such as Old World soybeans and lupins, and to the fruits or seeds of unrelated plants such as coffee beans and vanilla beans. This article discusses only legumes.\nHistory.\nBeans in an early cultivated form were grown in Thailand from the early seventh millennium BCE, predating ceramics. Beans were deposited with the dead in ancient Egypt. Not until the second millennium BCE did cultivated, large-seeded broad beans appear in the Aegean region, Iberia, and transalpine Europe. In the \"Iliad\" (8th century BCE), there is a passing mention of beans and chickpeas cast on the threshing floor.\nThe oldest-known domesticated beans in the Americas were found in Guitarrero Cave, Peru, dated to around the second millennium BCE. Genetic analyses of the common bean \"Phaseolus\" show that it originated in Mesoamerica, and subsequently spread southward.\nMost of the kinds of beans commonly eaten today are part of the genus \"Phaseolus\", which originated in the Americas. The first European to encounter them was Christopher Columbus, while exploring what may have been the Bahamas, and saw them growing in fields. Five kinds of \"Phaseolus\" beans were domesticated by pre-Columbian peoples, selecting pods that did not open and scatter their seeds when ripe: common beans (\"P. vulgaris\") grown from Chile to the northern part of the United States; lima and sieva beans (\"P. lunatus\"); and the less widely distributed teparies (\"P. acutifolius\"), scarlet runner beans (\"P. coccineus\"), and polyanthus beans.\nPre-Columbian peoples as far north as the Atlantic seaboard grew beans in the \"Three Sisters\" method of companion planting. The beans were interplanted with maize and squash. Beans were cultivated across Chile in Pre-Hispanic times, likely as far south as the Chilo\u00e9 Archipelago.\nDiversity.\nTaxonomic range.\nBeans are legumes, but from many different genera, native to different regions. \nConservation of cultivars.\nThe biodiversity of bean cultivars is threatened by modern plant breeding, which selects a small number of the most productive varieties. Efforts are being made to conserve the germplasm of older varieties in different countries. As of 2023, the Norwegian Svalbard Global Seed Vault holds more than 40,000 accessions of \"Phaseolus\" bean species.\nCultivation.\nAgronomy.\nMany beans are summer crops that need warm temperatures to grow, with peas as an exception. Legumes are capable of nitrogen fixation and hence need less fertiliser than most plants. Maturity is typically 55\u201360 days from planting to harvest. As the pods mature, they turn yellow and dry up, and the beans inside change from green to their mature colour. Many beans are vines needing external support, such as \"bean cages\" or poles. Native Americans customarily grew them along with corn and squash, the tall stalks acting as support for the beans.\nMore recently, the commercial \"bush bean\" which does not require support and produces all its pods simultaneously has been developed.\nProduction.\nThe production data for legumes are published by FAO in three categories:\nThe following is a summary of FAO data.\nThe world leader in production of dry beans (\"Phaseolus\" spp), is India, followed by Myanmar (Burma) and Brazil. In Africa, the most important producer is Tanzania.\n\"Source: UN Food and Agriculture Organization (FAO)\"\nUses.\nCulinary.\nBeans can be cooked in a wide variety of casseroles, curries, salads, soups, and stews. They can be served whole or mashed alongside meat or toast, or included in an omelette or a flatbread wrap. Other options are to include them in a bake with a cheese sauce, a Mexican-style chili con carne, or to use them as a meat substitute in a burger or in falafels. The French cassoulet is a slow-cooked stew with haricot beans, sausage, pork, mutton, and preserved goose. Soybeans can be processed into bean curd (tofu) or fermented into a cake (tempeh); these can be eaten fried or roasted like meat, or included in stir-fries, curries, and soups. Most dry beans contain 21\u201325% protein by weight; dry soybeans are 36.5% protein by weight.\nOther.\nGuar beans are used for their gum, a galactomannan polysaccharide. It is used to thicken and stabilise foods and other products.\nHealth concerns.\nToxins.\nSome kinds of raw beans contain a harmful, flavourless toxin: the lectin phytohaemagglutinin, which must be destroyed by cooking. Red kidney beans are particularly toxic, but other types also pose risks of food poisoning. Even small quantities (4 or 5 raw beans) may cause severe stomachache, vomiting, and diarrhea. This risk does not apply to canned beans because they have already been cooked. A recommended method is to boil the beans for at least ten minutes; under-cooked beans may be more toxic than raw beans.\nBeans need to be cooked thoroughly to destroy toxins; slow cooking is unsafe as it makes the beans soft without necessarily destroying the toxins. A case of poisoning by butter beans used to make falafel was reported; the beans were used instead of traditional broad beans or chickpeas, soaked and ground without boiling, made into patties, and shallow fried.\nBean poisoning is not well known in the medical community, and many cases may be misdiagnosed or never reported; figures appear not to be available. In the case of the United Kingdom National Poisons Information Service, available only to health professionals, the dangers of beans other than red beans were not flagged as of 2008[ [update]].\nFermentation is used in some parts of Africa to make beans more digestible by removing toxins.\nOther hazards.\nIt is common to make beansprouts by letting some types of bean, often mung beans, germinate in moist and warm conditions; beansprouts may be used as ingredients in cooked dishes, or eaten raw or lightly cooked. There have been many outbreaks of disease from bacterial contamination, often by \"salmonella\", \"listeria\", and \"Escherichia coli\", of beansprouts not thoroughly cooked, some causing significant mortality.\nMany types of bean, such as kidney beans, contain significant amounts of antinutrients that inhibit some enzyme processes in the body. Phytic acid, present in beans, interferes with bone growth and interrupts vitamin D metabolism.\nMany beans, including broad beans, navy beans, kidney beans and soybeans, contain large sugar molecules, oligosaccharides (particularly raffinose and stachyose). A suitable oligosaccharide-cleaving enzyme is necessary to digest these. As the human digestive tract does not contain such enzymes, consumed oligosaccharides are digested by bacteria in the large intestine, producing gases such as methane, released as flatulence.\nIn human society.\nBeans have traditionally been considered a food of the poor, as farmers ate grains and vegetables, obtaining their protein from beans, whereas the wealthier classes could afford meat. European society has what Ken Albala calls \"a class-based antagonism\" to beans. \nDifferent cultures agree in disliking the flatulence that beans cause, and possess their own seasonings to attempt to remedy it: Mexico uses the herb epazote; India the aromatic resin asafoetida; Germany applies the herb savory; in the Middle East, cumin; and Japan the seaweed kombu. A substance for which there is evidence of effectiveness in reducing flatulence is the enzyme alpha-galactosidase; extracted from the mould fungus \"Aspergillus niger\", it breaks down glycolipids and glycoproteins. The reputation of beans for flatulence is the theme of a children's song \"Beans, Beans, the Musical Fruit\".\nThe Mexican jumping bean is a segment of a seed pod occupied by the larva of the moth \"Cydia saltitans\", and sold as a novelty. The pods start to jump when warmed in the palm of the hand. Scientists have suggested that the random walk that results may help the larva to find shade and so to survive on hot days.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "4489", "revid": "28481209", "url": "https://en.wikipedia.org/wiki?curid=4489", "title": "Breast", "text": "Part of the female primate torso that has mammary glands\nThe breasts are two prominences located on the upper ventral region of the torso among humans and other primates. Both sexes develop breasts from the same embryological tissues. The relative size and development of the breasts is a major secondary sex distinction between females and males. There is also considerable variation in size between individuals. Permanent breast growth during puberty is caused by estrogens in conjunction with the growth hormone. Female humans are the only mammals that permanently develop breasts at puberty; all other mammals develop their mammary tissue during the latter period of pregnancy. \nIn females, the breast serves as the mammary gland, which produces and secretes milk to feed infants. Subcutaneous fat covers and envelops a network of ducts that converge on the nipple, and these tissues give the breast its distinct size and globular shape. At the ends of the ducts are lobules, or clusters of alveoli, where milk is produced and stored in response to hormonal signals. During pregnancy, the breast responds to a complex interaction of hormones, including estrogens, progesterone, and prolactin, that mediate the completion of its development, namely lobuloalveolar maturation, in preparation of lactation and breastfeeding.\nAlong with their major function in providing nutrition for infants, breasts can figure prominently in the perception of a woman's body and sexual attractiveness. Breasts, especially the nipples, can be an erogenous zone, and part of sexual activity. Some cultures ascribe social and sexual characteristics to female breasts, and may regard bare breasts in public as immodest or indecent. Breasts can represent fertility, femininity, or abundance. Breasts have been featured in ancient and modern sculpture, art, and photography.\nEtymology and terminology.\nThe English word \"breast\" derives from the Old English word 'breast, bosom' from Proto-Germanic 'breast', from the Proto-Indo-European base 'to swell, to sprout'. The \"breast\" spelling conforms to the Scottish and North English dialectal pronunciations. The \"Merriam-Webster Dictionary\" states that \"Middle English , [comes] from Old English ; akin to Old High German ..., Old Irish [belly], [and] Russian \"; the first known usage of the term was before the 12th century.\n\"Breasts\" is often used to refer to female breasts in particular, though the stricter anatomical term refers to the same region on members of either sex. Male breasts are sometimes referred to in the singular to mean the collective upper chest area, whereas female breasts are referred to in the plural unless speaking of a specific left or right breast.\nA large number of colloquial terms for female breasts are used in English, ranging from fairly polite terms to vulgar or slang. Some vulgar slang expressions may be considered to be derogatory or sexist to women.\nEvolutionary development.\nHumans are the only mammals whose breasts become permanently enlarged after sexual maturity (known in humans as puberty). The reason for this evolutionary change is unknown. Several hypotheses have been put forward:\nA link has been proposed to processes for synthesizing the endogenous steroid hormone precursor dehydroepiandrosterone which takes place in fat rich regions of the body like the buttocks and breasts. These contributed to human brain development and played a part in increasing brain size. Breast enlargement may for this purpose have occurred as early as \"Homo ergaster\" (1.7\u20131.4 MYA). Other breast formation hypotheses may have then taken over as principal drivers.\nIt has been suggested by zoologists Avishag and Amotz Zahavi that the size of the human breasts can be explained by the handicap theory of sexual dimorphism. This would see the explanation for larger breasts as them being an honest display of the women's health and ability to grow and carry them in her life. Prospective mates can then evaluate the genes of a potential mate for their ability to sustain her health even with the additional energy demanding burden she is carrying.\nThe zoologist Desmond Morris describes a sociobiological approach in his science book \"The Naked Ape\". He suggests, by making comparisons with the other primates, that breasts evolved to replace swelling buttocks as a sex signal of ovulation. He notes how humans have, relatively speaking, large penises as well as large breasts. Furthermore, early humans adopted bipedalism and face-to-face coitus. He therefore suggested enlarged sexual signals helped maintain the bond between a mated male and female even though they performed different duties and therefore were separated for lengths of time.\nA 2001 study proposed that the rounded shape of a woman's breast evolved to prevent the sucking infant offspring from suffocating while feeding at the teat; that is, because of the human infant's small jaw, which did not project from the face to reach the nipple, they might block the nostrils against the mother's breast if it were of a flatter form (compare with the common chimpanzee). Theoretically, as the human jaw receded into the face, the woman's body compensated with round breasts.\nAshley Montagu (1965) proposed that breasts came about as an adaptation for infant feeding for a different reason, as early human ancestors adopted bipedalism and the loss of body hair. Human upright stance meant infants must be carried at the hip or shoulder instead of on the back as in the apes. This gives the infant less opportunity to find the nipple or the purchase to cling on to the mother's body hair. The mobility of the nipple on a large breast in most human females gives the infant more ability to find it, grasp it and feed.\nOther suggestions include simply that permanent breasts attracted mates, that \"pendulous\" breasts gave infants something to cling to, or that permanent breasts shared the function of a camel's hump, to store fat as an energy reserve.\nStructure.\nIn women, the breasts overlie the pectoralis major muscles and extend on average from the level of the second rib to the level of the sixth rib in the front of the rib cage; thus, the breasts cover much of the chest area and the chest walls. At the front of the chest, the breast tissue can extend from the clavicle (collarbone) to the middle of the sternum (breastbone). At the sides of the chest, the breast tissue can extend into the axilla (armpit), and can reach as far to the back as the latissimus dorsi muscle, extending from the lower back to the humerus bone (the bone of the upper arm). As a mammary gland, the breast is composed of differing layers of tissue, predominantly two types: adipose tissue; and glandular tissue, which affects the lactation functions of the breasts. The natural resonant frequency of the human breast is about 2 hertz.\nMorphologically, the breast is tear-shaped. The superficial tissue layer (superficial fascia) is separated from the skin by 0.5\u20132.5\u00a0cm of subcutaneous fat (adipose tissue). The suspensory Cooper's ligaments are fibrous-tissue prolongations that radiate from the superficial fascia to the skin envelope. The female adult breast contains 14\u201318 irregular lactiferous lobes that converge at the nipple. The 2.0\u20134.5\u00a0mm milk ducts are immediately surrounded with dense connective tissue that support the glands. Milk exits the breast through the nipple, which is surrounded by a pigmented area of skin called the areola. The size of the areola can vary widely among women. The areola contains modified sweat glands known as Montgomery's glands. These glands secrete oily fluid that lubricate and protect the nipple during breastfeeding. Volatile compounds in these secretions may also serve as an olfactory stimulus for the newborn's appetite.\nThe dimensions and weight of the breast vary widely among women. A small-to-medium-sized breast weighs 500\u00a0grams (1.1 pounds) or less, and a large breast can weigh approximately 750 to 1,000 grams (1.7 to 2.2 pounds) or more. In terms of composition, the breasts are about 80 to 90% stromal tissue (fat and connective tissue), while epithelial or glandular tissue only accounts for about 10 to 20% of the volume of the breasts. The tissue composition ratios of the breast also vary among women. Some women's breasts have a higher proportion of glandular tissue than of adipose or connective tissues. The fat-to-connective-tissue ratio determines the density or firmness of the breast. During a woman's life, her breasts change size, shape, and weight due to hormonal changes during puberty, the menstrual cycle, pregnancy, breastfeeding, and menopause.\nGlandular structure.\nThe breast is an apocrine gland that produces the milk used to feed an infant. The nipple of the breast is surrounded by the areola (nipple-areola complex). The areola has many sebaceous glands, and the skin color varies from pink to dark brown. The basic units of the breast are the terminal duct lobular units (TDLUs), which produce the fatty breast milk. They give the breast its offspring-feeding functions as a mammary gland. They are distributed throughout the body of the breast. Approximately two-thirds of the lactiferous tissue is within 30\u00a0mm of the base of the nipple. The terminal lactiferous ducts drain the milk from TDLUs into 4\u201318 lactiferous ducts, which drain to the nipple. The milk-glands-to-fat ratio is 2:1 in a lactating woman, and 1:1 in a non-lactating woman. In addition to the milk glands, the breast is also composed of connective tissues (collagen, elastin), white fat, and the suspensory Cooper's ligaments. Sensation in the breast is provided by the peripheral nervous system innervation by means of the front (anterior) and side (lateral) cutaneous branches of the fourth-, fifth-, and sixth intercostal nerves. The T-4 nerve (Thoracic spinal nerve 4), which innervates the dermatomic area, supplies sensation to the nipple-areola complex.\nLymphatic drainage.\nApproximately 75% of the lymph from the breast travels to the axillary lymph nodes on the same side of the body, while 25% of the lymph travels to the parasternal nodes (beside the sternum bone). A small amount of remaining lymph travels to the other breast and to the abdominal lymph nodes. The subareolar region has a lymphatic plexus known as the \"subareolar plexus of Sappey\". The axillary lymph nodes include the pectoral (chest), subscapular (under the scapula), and humeral (humerus-bone area) lymph-node groups, which drain to the central axillary lymph nodes and to the apical axillary lymph nodes. The lymphatic drainage of the breasts is especially relevant to oncology because breast cancer is common to the mammary gland, and cancer cells can metastasize (break away) from a tumor and be dispersed to other parts of the body by means of the lymphatic system.\nMorphology.\nThe morphologic variations in the size, shape, volume, tissue density, pectoral locale, and spacing of the breasts determine their natural shape, appearance, and position on a woman's chest. Breast size and other characteristics do not predict the fat-to-milk-gland ratio or the potential for the woman to nurse an infant. The size and the shape of the breasts are influenced by normal-life hormonal changes (thelarche, menstruation, pregnancy, menopause) and medical conditions (e.g. virginal breast hypertrophy). The shape of the breasts is naturally determined by the support of the suspensory Cooper's ligaments, the underlying muscle and bone structures of the chest, and by the skin envelope. The suspensory ligaments sustain the breast from the clavicle (collarbone) and the clavico-pectoral fascia (collarbone and chest) by traversing and encompassing the fat and milk-gland tissues. The breast is positioned, affixed to, and supported upon the chest wall, while its shape is established and maintained by the skin envelope. In most women, one breast is slightly larger than the other. More obvious and persistent asymmetry in breast size occurs in up to 25% of women.\nThe base of each breast is attached to the chest by the deep fascia over the pectoralis major muscles. The base of the breast is semi-circular, however the shape and position of the breast above the surface is variable. The space between the breast and the pectoralis major muscle, called retromammary space, gives mobility to the breast. The chest (thoracic cavity) progressively slopes outwards from the thoracic inlet (atop the breastbone) and above to the lowest ribs that support the breasts. The inframammary fold (IMF), where the lower portion of the breast meets the chest, is an anatomic feature created by the adherence of the breast skin and the underlying connective tissues of the chest; the IMF is the lower-most extent of the anatomic breast. Normal breast tissue has a texture that feels nodular or granular, with considerable variation from woman to woman.\nBreasts have been categorized into four general morphological groups: \"flat, spheric, protruded, and drooped\", or \"small/flat, large/inward, upward, and droopy\".\nSupport.\nWhile it is a common belief that breastfeeding causes breasts to sag, researchers have found that a woman's breasts sag due to four key factors: cigarette smoking, number of pregnancies, gravity, and weight loss or gain. Women sometimes wear bras because they mistakenly believe they prevent breasts from sagging as they get older. Physicians, lingerie retailers, teenagers, and adult women used to believe that bras were medically required to support breasts. In a 1952 article in \"Parents' Magazine\", Frank H. Crowell erroneously reported that it was important for teen girls to begin wearing bras early. According to Crowell, this would prevent sagging breasts, stretched blood vessels, and poor circulation later on. This belief was based on the false idea that breasts cannot anatomically support themselves.\nSports bras are sometimes used for cardiovascular exercise, sports bras are designed to secure the breasts closely to the body to prevent movement during high-motion activity such as running. Studies have indicated sports bras which are overly tight may restrict respiratory function.\nDevelopment.\nThe breasts are principally composed of adipose, glandular, and connective tissues. Because these tissues have hormone receptors, their sizes and volumes fluctuate according to the hormonal changes particular to thelarche (sprouting of breasts), menstruation (egg production), pregnancy (reproduction), lactation (feeding of offspring), and menopause (end of menstruation).\nPuberty.\nThe morphological structure of the human breast is identical in males and females until puberty. For pubescent girls in thelarche (the breast-development stage), the female sex hormones (principally estrogens) in conjunction with growth hormone promote the sprouting, growth, and development of the breasts. During this time, the mammary glands grow in size and volume and begin resting on the chest. These development stages of secondary sex characteristics (breasts, pubic hair, etc.) are illustrated in the five-stage Tanner scale.\nDuring thelarche, the developing breasts are sometimes of unequal size, and usually the left breast is slightly larger. This condition of asymmetry is transitory and statistically normal in female physical and sexual development. Medical conditions can cause overdevelopment (e.g., virginal breast hypertrophy, macromastia) or underdevelopment (e.g., tuberous breast deformity, micromastia) in girls and women.\nApproximately two years after the onset of puberty (a girl's first menstrual cycle), estrogen and growth hormone stimulate the development and growth of the glandular fat and suspensory tissues that compose the breast. This continues for approximately four years until the final shape of the breast (size, volume, density) is established at about the age of 21. Mammoplasia (breast enlargement) in girls begins at puberty, unlike all other primates, in which breasts enlarge only during lactation.\nHormone replacement therapy.\nHormone replacement therapy, including gender-affirming hormone therapy, stimulates the growth of glandular and adipose tissue through estrogen supplementation.\nIn menopausal women, HRT helps restore breast volume and skin elasticity diminished by declining estrogen levels, typically using oral or transdermal estradiol.\nIn gender-affirming hormone therapy, breast development is induced through feminizing HRT, often combining estrogen with anti-androgens to suppress testosterone. Maximum growth is usually achieved after 2\u20133 years.\nFactors such as age, genetics, and hormone dosage influence outcomes.\nChanges during the menstrual cycle.\nDuring the menstrual cycle, the breasts are enlarged by premenstrual water retention and temporary growth as influenced by changing hormone levels. \nPregnancy and breastfeeding.\nThe breasts reach full maturity only when a woman's first pregnancy occurs. Changes to the breasts are among the first signs of pregnancy. The breasts become larger, the nipple-areola complex becomes larger and darker, the Montgomery's glands enlarge, and veins sometimes become more visible. Breast tenderness during pregnancy is common, especially during the first trimester. By mid-pregnancy, the breast is physiologically capable of lactation and some women can express colostrum, a form of breast milk.\nPregnancy causes elevated levels of the hormone prolactin, which has a key role in the production of milk. However, milk production is blocked by the hormones progesterone and estrogen until after delivery, when progesterone and estrogen levels plummet.\nMenopause.\nAt menopause, breast atrophy occurs. The breasts can decrease in size when the levels of circulating estrogen decline. The adipose tissue and milk glands also begin to wither. The breasts can also become enlarged from adverse side effects of combined oral contraceptive pills. The size of the breasts can also increase and decrease in response to weight fluctuations. \nPhysical changes to the breasts are often recorded in the stretch marks of the skin envelope; they can serve as historical indicators of the increments and the decrements of the size and volume of a woman's breasts throughout the course of her life.\nBreast changes during menopause are sometimes treated with hormone replacement therapy.\nCancer.\nBreast cancer is a cancer that develops from breast tissue. Signs of breast cancer may include a lump in the breast, a change in breast shape, dimpling of the skin, milk rejection, fluid coming from the nipple, a newly inverted nipple, or a red or scaly patch of skin. In those with distant spread of the disease, there may be bone pain, swollen lymph nodes, shortness of breath, or yellow skin.\nRisk factors for developing breast cancer include obesity, a lack of physical exercise, alcohol consumption, hormone replacement therapy during menopause, ionizing radiation, an early age at first menstruation, having children late in life (or not at all), older age, having a prior history of breast cancer, and a family history of breast cancer. About five to ten percent of cases are the result of an inherited genetic predisposition, including \"BRCA\" mutations among others. Breast cancer most commonly develops in cells from the lining of milk ducts and the lobules that supply these ducts with milk. Cancers developing from the ducts are known as ductal carcinomas, while those developing from lobules are known as lobular carcinomas. There are more than 18 other sub-types of breast cancer. Some, such as ductal carcinoma in situ, develop from pre-invasive lesions. The diagnosis of breast cancer is confirmed by taking a biopsy of the concerning tissue. Once the diagnosis is made, further tests are carried out to determine if the cancer has spread beyond the breast and which treatments are most likely to be effective.\nBreastfeeding.\nThe primary function of the breasts, as mammary glands, is the nourishing of an infant with breast milk. Milk is produced in milk-secreting cells in the alveoli. When the breasts are stimulated by the suckling of her baby, the mother's brain secretes oxytocin. High levels of oxytocin trigger the contraction of muscle cells surrounding the alveoli, causing milk to flow along the ducts that connect the alveoli to the nipple.\nFull-term newborns have an instinct and a need to suck on a nipple, and breastfed babies nurse for both nutrition and for comfort. Breast milk provides all necessary nutrients for the first six months of life, and then remains an important source of nutrition, alongside solid foods, until at least one or two years of age.\nExercise.\nBiomechanical studies have demonstrated that, depending on the activity and the size of a woman's breast, when she walks or runs braless, her breasts may move up and down by or more, and also oscillate side to side. Researchers have also found that as women's breast size increased, they took part in less physical activity, especially vigorous exercise. Few very-large-breasted women jogged, for example. To avoid exercise-related discomfort and pain, medical experts suggest women wear a well-fitted sports bra during activity.\nClinical significance.\nThe breast is susceptible to numerous benign and malignant conditions. The most frequent benign conditions are puerperal mastitis, fibrocystic breast changes and mastalgia.\nLactation unrelated to pregnancy is known as galactorrhea. It can be caused by certain drugs (such as antipsychotic medications), extreme physical stress, or endocrine disorders. Lactation in newborns is caused by hormones from the mother that crossed into the baby's bloodstream during pregnancy.\nBreast cancer.\nBreast cancer is the most common cause of cancer death among women and it is one of the leading causes of death among women. Factors that appear to be implicated in decreasing the risk of breast cancer are regular breast examinations by health care professionals, regular mammograms, self-examination of breasts, healthy diet, exercise to decrease excess body fat, and breastfeeding.\nMale breasts.\nBoth females and males develop breasts from the same embryological tissues. Anatomically, male breasts do not normally contain lobules and acini that are present in females. In rare instances, it is possible for very few lobules to be present; this makes it possible for some men to develop lobular carcinoma of the breast. Normally, males produce lower levels of estrogens and higher levels of androgens, namely testosterone, which suppress the effects of estrogens in developing excessive breast tissue. In boys and men, abnormal breast development is manifested as gynecomastia, the consequence of a biochemical imbalance between the normal levels of estrogen and testosterone in the male body. Around 70% of boys temporarily develop breast tissue during adolescence. The condition usually resolves by itself within two years. When male lactation occurs, it is considered a symptom of a disorder of the pituitary gland.\nPlastic surgery.\nPlastic surgery can be performed to augment or reduce the size of breasts, or to reconstruct the breast in cases of deformative disease, such as breast cancer. Breast augmentation and breast lift (mastopexy) procedures are done only for cosmetic reasons, whereas breast reduction is sometimes medically indicated. In cases where a woman's breasts are severely asymmetrical, surgery can be performed to either enlarge the smaller breast, reduce the size of the larger breast, or both.\nBreast augmentation surgery generally does not interfere with future ability to breastfeed. Breast reduction surgery more frequently leads to decreased sensation in the nipple-areola complex, and to low milk supply in women who choose to breastfeed. Implants can interfere with mammography (breast x-ray images).\nSociety and culture.\nGeneral.\nIn Christian iconography, some works of art depict women with their breasts in their hands or on a platter, signifying that they died as a martyr by having their breasts severed; one example of this is Saint Agatha of Sicily.\nFemen is a feminist activist group which uses topless protests as part of their campaigns against sex tourism religious institutions, sexism, and homophobia. Femen activists have been regularly detained by police in response to their protests.\nThere is a long history of female breasts being used by comedians as a subject for comedy fodder (e.g., British comic Benny Hill's burlesque/slapstick routines).\nArt history.\nIn European pre-historic societies, sculptures of female figures with pronounced or highly exaggerated breasts were common. A typical example is the so-called Venus of Willendorf, one of many Paleolithic Venus figurines with ample hips and bosom. Artifacts such as bowls, rock carvings and sacred statues with breasts have been recorded from 15,000\u00a0BC up to late antiquity all across Europe, North Africa and the Middle East.\nMany female deities representing love and fertility were associated with breasts and breast milk. Figures of the Phoenician goddess Astarte were represented as pillars studded with breasts. Isis, an Egyptian goddess who represented, among many other things, ideal motherhood, was often portrayed as suckling pharaohs, thereby confirming their divine status as rulers. Even certain male deities representing regeneration and fertility were occasionally depicted with breast-like appendices, such as the river god Hapy who was considered to be responsible for the annual overflowing of the Nile.\nFemale breasts were also prominent in Minoan art in the form of the famous Snake Goddess statuettes, and a few other pieces, though most female breasts are covered. In Ancient Greece there were several cults worshipping the \"Kourotrophos\", the suckling mother, represented by goddesses such as Gaia, Hera and Artemis. The worship of deities symbolized by the female breast in Greece became less common during the first millennium. The popular adoration of female goddesses decreased significantly during the rise of the Greek city states, a legacy which was passed on to the later Roman Empire.\nDuring the middle of the first millennium BC, Greek culture experienced a gradual change in the perception of female breasts. Women in art were covered in clothing from the neck down, including female goddesses like Athena, the patron of Athens who represented heroic endeavor. There were exceptions: Aphrodite, the goddess of love, was more frequently portrayed fully nude, though in postures that were intended to portray shyness or modesty, a portrayal that has been compared to modern pin ups by historian Marilyn Yalom. Although nude men were depicted standing upright, most depictions of female nudity in Greek art occurred \"usually with drapery near at hand and with a forward-bending, self-protecting posture\". A popular legend at the time was of the Amazons, a tribe of fierce female warriors who socialized with men only for procreation and even removed one breast to become better warriors (the idea being that the right breast would interfere with the operation of a bow and arrow). The legend was a popular motif in art during Greek and Roman antiquity and served as an antithetical cautionary tale.\nBody image.\nMany women regard their breasts as important to their sexual attractiveness, as a sign of femininity that is important to their sense of self. A woman with smaller breasts may regard her breasts as less attractive.\nClothing.\nBecause breasts are mostly fatty tissue, their shape can\u2014within limits\u2014be molded by clothing, such as foundation garments. Bras are commonly worn by about 90% of Western women, and are often worn for support. The social norm in most Western cultures is to cover breasts in public, though the extent of coverage varies depending on the social context. Some religions ascribe a special status to the female breast, either in formal teachings or through symbolism. Islam forbids free women from exposing their breasts in public.\nMany cultures, including Western cultures in North America, associate breasts with sexuality and tend to regard bare breasts as immodest or indecent. In some cultures, like the Himba in northern Namibia, bare-breasted women are normal. In some African cultures, for example, the thigh is regarded as highly sexualized and never exposed in public, but breast exposure is not taboo. In a few Western countries and regions female toplessness at a beach is acceptable, although it may not be acceptable in the town center.\nSocial attitudes and laws regarding breastfeeding in public vary widely. In many countries, breastfeeding in public is common, legally protected, and generally not regarded as an issue. However, even though the practice may be legal or socially accepted, some mothers may nevertheless be reluctant to expose a breast in public to breastfeed due to actual or potential objections by other people, negative comments, or harassment. It is estimated that around 63% of mothers across the world have publicly breast-fed. Bare-breasted women are legal and culturally acceptable at public beaches in Australia and much of Europe. Filmmaker Lina Esco made a film entitled \"Free the Nipple\", which is about \"...laws against female toplessness or restrictions on images of female, but not male, nipples\", which Esco states is an example of sexism in society.\nBreast binding, also known as chest binding, is the flattening and hiding of breasts with constrictive materials such as cloth strips or purpose-built undergarments. Binders may also be used as alternatives to bras or for reasons of propriety. People who bind include women, trans men, non-binary people, and cisgender men with gynecomastia.\nSexual characteristic.\nIn some cultures, breasts play a role in human sexual activity. Breasts and especially the nipples are among the various human erogenous zones. They are sensitive to the touch as they have many nerve endings; and it is common to press or massage them with hands or orally before or during sexual activity. During sexual arousal, breast size increases, venous patterns across the breasts become more visible, and nipples harden. Compared to other primates, human breasts are proportionately large throughout adult females' lives. Some writers have suggested that they may have evolved as a visual signal of sexual maturity and fertility. In \"Patterns of Sexual Behavior\", a 1951 analysis of 191 traditional cultures, the researchers noted that stimulation of the female breast by a male sexual partner \"seemed absent in all subhuman forms, although it is common among the members of many different human societies.\"\nMany people regard bare female breasts to be aesthetically pleasing or erotic, and they can elicit heightened sexual desires in men in many cultures. In the ancient Indian work the \"Kama Sutra\", light scratching of the breasts with nails and biting with teeth are considered erotic. Some people show a sexual interest in female breasts distinct from that of the person, which may be regarded as a breast fetish. A number of Western fashions include clothing which accentuate the breasts, such as the use of push-up bras and decollete (plunging neckline) gowns and blouses which show cleavage. While U.S. culture prefers breasts that are youthful and upright, some cultures venerate women with drooping breasts, indicating mothering and the wisdom of experience.\nResearch conducted at the Victoria University of Wellington showed that breasts are often the first thing men look at, and for a longer time than other body parts. The writers of the study had initially speculated that the reason for this is due to endocrinology with larger breasts indicating higher levels of estrogen and a sign of greater fertility, but the researchers said that \"Men may be looking more often at the breasts because they are simply aesthetically pleasing, regardless of the size.\"\nSome women report achieving an orgasm from nipple stimulation, but this is rare. Research suggests that the orgasms are genital orgasms, and may also be directly linked to \"the genital area of the brain\". In these cases, it seems that sensation from the nipples travels to the same part of the brain as sensations from the vagina, clitoris and cervix. Nipple stimulation may trigger uterine contractions, which then produce a sensation in the genital area of the brain.\nAnthropomorphic geography.\nThere are many mountains named after the breast because they resemble it in appearance and so are objects of religious and ancestral veneration as a fertility symbol and of well-being. In Asia, there was \"Breast Mountain\", which had a cave where the Buddhist monk Bodhidharma (Da Mo) spent much time in meditation. Other such breast mountains are Mount Elgon on the Uganda\u2013Kenya border; and the Maiden Paps in Scotland; the ('Maiden's breast mountains') in Talim Island, Philippines, the twin hills known as the Paps of Anu ( or 'the breasts of Anu'), near Killarney in Ireland; the 2,086\u00a0m high or in the , Spain; in Thailand, in Puerto Rico; and the Breasts of Aphrodite in Mykonos, among many others. In the United States, the Teton Range is named after the French word for 'nipple'.\nMeasurement.\nThe maturation and size of the breasts can be measured by a variety of different methods. These include Tanner staging, bra cup size, breast volume, breast\u2013chest difference, the breast unit, breast hemicircumference, and breast circumference, among other measures.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "4492", "revid": "46538735", "url": "https://en.wikipedia.org/wiki?curid=4492", "title": "Baghdad", "text": "Capital and largest city of Iraq\nBaghdad is the capital and largest city in Iraq. It is located on the banks of the Tigris in central Iraq. The city has an estimated population of 8 million. It ranks among the most populous and largest cities in the Middle East and the Arab world and constitutes 22% of the country's population. Baghdad is a primary financial and commercial center in the region.\nFounded in 762 AD by Al-Mansur, Baghdad was the capital of the Abbasid Caliphate and became its most notable development project. The city evolved into an intellectual and cultural center. This, in addition to housing several key academic institutions, including the House of Wisdom, as well as a multi-ethnic and multi-religious environment, garnered it a worldwide reputation as the \"Center of Learning\". For much of the Abbasid era, during the Islamic Golden Age, Baghdad was one of the largest cities in the world and rivaled Chang'an, as the population peaked at more than one million. It was largely destroyed at the hands of the Mongol Empire in 1258, resulting in a decline that would linger through many centuries due to frequent plagues, shift in power and multiple successive empires. Later, Baghdad served as the administrative center of Ottoman Iraq, exercising authority over the provinces of Basra, Mosul, and Shahrizor.\nDuring the First World War, Baghdad was made the capital of Mandatory Iraq. With the recognition of Iraq as an independent monarchy in 1932, it gradually regained some of its former prominence as a significant center of Arab culture. During the Ba'ath Party rule, the city experienced a period of relative prosperity and growth. However, it faced severe infrastructural damage due to the Iraq War, which began with the invasion of Iraq in 2003, resulting in a substantial loss of cultural heritage and historical artifacts. During the insurgency and renewed war from 2013 to 2017, it had one of the highest rates of terrorist attacks in the world. However, these attacks have gradually declined since the territorial defeat of the Islamic State militant group in Iraq in 2017, and are now rare. Since the end of the war, numerous reconstruction projects have been underway to induce stability.\nIraq's largest city, Baghdad is the seat of government. It generates 40% of the economy of Iraq. A major center of Islamic history, Baghdad is home to numerous historic mosques, as well as churches, \"mandis\" and synagogues, highlighting the city's historical diversity. Religious sites such as Masjid al-Kadhimayn, Buratha Mosque, the Shrine of Abdul-Qadir Gilani and Abu Hanifa Mosque are visited by millions of people annually. It was once home to a large Jewish community and was regularly visited by Sikh pilgrims from India. Baghdad is a regional cultural hub. The city is well known for its coffeehouses.\nName.\nThe name Baghdad is pre-Islamic, and its origin is disputed. The site where the city of Baghdad developed has been populated for millennia. Archaeological evidence shows that the site of Baghdad was occupied by various peoples long before the Arab conquest of Mesopotamia in 637 CE, and several ancient empires had capitals located in the surrounding area.\nArab authors, realizing the pre-Islamic origins of Baghdad's name, generally looked for its roots in Middle Persian. They suggested various meanings, the most common of which was \"bestowed by God\". Modern scholars generally tend to favor this etymology, which views the word as a Persian compound of \"bagh\" () \"god\" and \"d\u0101d\" () \"given\". In Old Persian the first element can be traced to \"boghu\" and is related to Indo-Iranian \"bhag\" and Slavic \"bog\" \"god.\" A similar term in Middle Persian is the name \"Mithrad\u0101t\" (\"Mehrdad\" in New Persian), known in English by its borrowed Hellenistic form \"Mithridates\", meaning \"Given by Mithra\" (\"d\u0101t\" is the more archaic form of \"d\u0101d\", related to Sanskrit \"d\u0101t\", Latin \"dat\" and English \"donor\"), ultimately borrowed from Persian \"Mehrdad\". There are a number of other locations whose names are compounds of the Middle Persian word \"bagh\", including Baghlan and Bagram in Afghanistan, Baghshan in Iran itself, and Baghdati in Georgia, which likely share the same etymological Iranic origins.\nOther authors have suggested older origins for the name, in particular the name \"Bagdadu\" or \"Hudadu\" that existed in Old Babylonian (spelled with a sign that can represent both \"bag\" and \"hu\"), and the Jewish Babylonian Aramaic name of a place called \"Baghdatha\" (). Some scholars suggested Aramaic derivations.\nAnother highly recommended view is that Baghdad is a reference to Bagh and Dad as in Dadan, Dedan, and Dad as in Hadad, Adad. Another view suggested by Christophe Wall-Romana, is that name of \"Baghdad\" is derived from \"Akkad\", as the cuneiform logogram for Akkad () is pronounced \"\"a-ga-d\u00e8\"KI\" (\"Agade\") and its resemblance to \"Baghdad\" is compelling. It is argued that, throughout all the various spellings of the city's name, whether \"Baghdad\" [\u0628\u063a\u062f\u0627\u062f], \"Baghdadh\" [\u0628\u063a\u062f\u0627\u0630], \"Baghdan\" [\u0628\u063a\u062f\u0627\u0646], \"Maghdad\" [\u0645\u063a\u062f\u0627\u062f], \"Maghdadh\" [\u0645\u063a\u062f\u0627\u0630], or \"Maghdan\" [\u0645\u063a\u062f\u0627\u0646], the only phonetically definite segment of the name appears to be \"Aghda\" [\u0649\u064e\u063a\u0652\u062f\u064e\u0627], which could be equated with the pronunciation of the name Agade.\nWhen the Abbasid caliph al-Mansur founded a completely new city for his capital, he chose the name \"City of peace\" (), which now refers to the Round City of Baghdad proper. By the 11th century, \"Baghdad\" became almost the exclusive name for the world-renowned metropolis.\nChristophe Wall-Romana has suggested that al-Mansur's choice to found his \"new city\" at Baghdad because of its strategic location was the same criteria which influenced Sargon's choice to found the original city of Akkad in the exact same location.\nHistory.\nFoundation.\nAfter the fall of the Umayyads, the victorious Abbasids sought a new capital. On 30 July 762, the Caliph Al-Mansur commissioned Baghdad's construction, guided by the Iranian Barmakids. He believed Baghdad was ideal for ruling the Islamic Empire. Historian al-Tabari recorded a prophecy from Christian monks about a leader named Miklas building a great city in the area, and Al-Mansur, who was once called Miklas, saw this as a good omen. He expressed deep affection for the site, declaring it would be the home of his dynasty.\nThe two designers who were hired by Al-Mansur to plan the city's design were Naubakht, a Zoroastrian who also determined that the date of the foundation of the city would be astrologically auspicious, and Mashallah, a Jew from Khorasan, Iran. They determined the city's auspicious founding date under the sign of Leo the lion, symbolizing strength and expansion.\nBaghdad's strategic location along the Tigris and its abundant water supply contributed to its rapid growth. It was divided into three judicial districts: Round City (\"Madinat al-Mansur\"), al-Karkh (\"al-Sharqiyya\"), and Askar al-Mahdi. To prevent disturbances, Al-Mansur moved markets to al-Karkh. Over time, Baghdad became a hub for merchants and craftsmen. Officials called \"Muhtasib\" monitored trade to prevent fraud.\nBaghdad surpassed Ctesiphon, the former Sassanid capital, located 30\u00a0km southeast. The ruins of Ctesiphon remain in Salman Pak, where Salman the Persian is believed to be buried. Ctesiphon itself had replaced Seleucia, which had earlier succeeded Babylon. According to the traveler Ibn Battuta, Baghdad was one of the largest cities, not including the damage it has received. The residents are mostly Hanbalis. Most residents were Hanbali Muslims. The city housed Abu Hanifa's grave, marked by a mosque and cell. Its ruler, Abu Said Bahadur Khan, was a Tatar who had embraced Islam.\nBaghdad was designed to symbolize Paradise as described in the Qur'an. It took four years (764\u2013768) to build, with over 100,000 workers involved. Al-Mansur recruited engineers and artisans worldwide. Astrologers Naubakht Ahvazi and Mashallah advised starting construction under Leo, associated with fire, productivity, and expansion. Bricks for the city were 18 inches square, and Abu Hanifah supervised their production. A canal supplied water for drinking and construction. Marble was used extensively, including steps leading to the river.\nThe city's layout consisted of two large semicircles, with a 2\u00a0km-wide circular core known as the \"Round City.\" It had parks, gardens, villas, and promenades. Unlike European cities of the time, Baghdad had a sanitation system, fountains, and public baths, with thousands of \"hammams\" enhancing hygiene. The mosque and guard headquarters stood at the center, though some central space's function remains unknown. Baghdad's circular design reflected ancient Near Eastern urban planning, similar to the Sasanian city of Gur and older Mesopotamian cities like Mari. While Tell Chuera and Tell al-Rawda also provide examples of this type of urban planning existing in Bronze Age Syria. This style of urban planning contrasted with Ancient Greek and Roman urban planning, in which cities are designed as squares or rectangles with streets intersecting each other at right angles.\nBaghdad was lively, with attractions like cabarets, chess halls, live plays, concerts, and acrobatics. Storytelling flourished, with professional storytellers (\"al-Qaskhun\") captivating crowds, inspiring the tales of \"Arabian Nights\". The city had four walls named after major destinations\u2014Kufa, Basra, Khurasan, and Syria; their gates pointed in on these destinations. The gates were 2.4\u00a0km apart, with massive iron doors requiring several men to operate. The walls, up to 44 meters thick and 30 meters high, were reinforced with a second wall, towers, and a moat for added defense. On street corners, storytellers engaged crowds with tales such as those later told in Arabian Nights. The Golden Gate Palace, home of the caliph, stood at Baghdad's center with a grand 48-meter green dome. Only the caliph could approach its esplanade on horseback. Nearby were officer residences and a guardhouse. After Caliph Al-Amin's death in 813, the palace ceased to be the caliph's residence.\nCenter of learning (8th\u20139th centuries).\nWithin a generation of its founding, Baghdad became a hub of learning and commerce. The city flourished into an unrivaled intellectual center of science, medicine, philosophy, and education, especially with the Abbasid translation movement began under the second caliph Al-Mansur and thrived under the seventh caliph Al-Ma'mun. \"Baytul-Hikmah\" or the \"House of Wisdom\" was among the most well known academies, and had the largest selection of books in the world by the middle of the 9th century. Notable scholars based in Baghdad during this time include translator Hunayn ibn Ishaq, mathematician al-Khwarizmi, and philosopher Al-Kindi.\nAlthough Arabic was used as the language of science, the scholarship involved not only Arabs, but also Persians, Syriacs, Nestorians, Jews, Arab Christians, and people from other ethnic and religious groups native to the region. These are considered among the fundamental elements that contributed to the flourishing of scholarship in the Medieval Islamic world. Baghdad was also a significant center of Islamic religious learning, with Al-Jahiz contributing to the formation of Mu'tazili theology, as well as Al-Tabari culminating in the scholarship on the Quranic exegesis. Baghdad is likely to have been the largest city in the world from shortly after its foundation until the 930s, when it tied with C\u00f3rdoba. Several estimates suggest that the city contained over a million inhabitants at its peak. Many of the \"One Thousand and One Nights\" tales, widely known as the \"Arabian Nights\", are set in Baghdad during this period. It would surpass even Constantinople in prosperity and size.\nAmong the notable features of Baghdad during this period were its exceptional libraries. Many of the Abbasid caliphs were patrons of learning and enjoyed collecting both ancient and contemporary literature. Although some of the princes of the previous Umayyad dynasty had begun to gather and translate Greek scientific literature, the Abbasids were the first to foster Greek learning on a large scale. Many of these libraries were private collections intended only for the use of the owners and their immediate friends, but the libraries of the caliphs and other officials soon took on a public or a semi-public character.\nFour great libraries were established in Baghdad during this period. The earliest was that of the famous Al-Ma'mun, who was caliph from 813 to 833. Another was established by Sabur ibn Ardashir in 991 or 993 for the literary men and scholars who frequented his academy. This second library was plundered and burned by the Seljuks only seventy years after it was established. This was a good example of the sort of library built up out of the needs and interests of a literary society. The last two were examples of \"madrasa\" or theological college libraries. The Nezamiyeh was founded by the Persian Nizam al-Mulk, who was vizier of two early Seljuk sultans. It continued to operate even after the coming of the Mongols in 1258. The Mustansiriyya Madrasa, which owned an exceedingly rich library, was founded by Al-Mustansir, the second last Abbasid caliph, who died in 1242. This would prove to be the last great library built by the caliphs of Baghdad.\nStagnation and invasions (10th\u201316th centuries).\nBy the 10th century, the city's population was between 1.2\u00a0million and 2\u00a0million. Baghdad's early meteoric growth eventually slowed due to troubles within the Caliphate, including relocations of the capital to Samarra (during 808\u2013819 and 836\u2013892), the loss of the western and easternmost provinces, and periods of political domination by the Iranian Buwayhids (945\u20131055) and Seljuk Turks (1055\u20131135). The Seljuks were a clan of the Oghuz Turks from Central Asia that converted to the Sunni branch of Islam. In 1040, they destroyed the Ghaznavids, taking over their land and in 1055, Tughril Beg, the leader of the Seljuks, took over Baghdad. The Seljuks expelled the Buyid dynasty of Shiites that had ruled for some time and took over power and control of Baghdad. They ruled as Sultans in the name of the Abbasid caliphs (they saw themselves as being part of the Abbasid regime). Tughril Beg saw himself as the protector of the Abbasid Caliphs.\nBaghdad was captured in 1394, 1534, 1623 and 1638. The city has been sieged in 812, 865, 946, 1157, 1258 and in 1393 and 1401, by Tamerlane. In 1058, Baghdad was captured by the Fatimids under the Turkish general Abu'l-\u1e24\u0101rith Arsl\u0101n al-Basasiri, an adherent of the Ismailis along with the 'Uqaylid Quraysh. Not long before the arrival of the Saljuqs in Baghdad, al-Basasiri petitioned to the Fatimid Imam-Caliph al-Mustansir to support him in conquering Baghdad on the Ismaili Imam's behalf. It has recently come to light that the famed Fatimid \"da'i\", al-Mu'ayyad al-Shirazi, had a direct role in supporting al-Basasiri and helped the general to succeed in taking Maw\u1e63il, W\u0101sit and Kufa. Soon after, by December 1058, a Shi'i \"adh\u0101n\" (call to prayer) was implemented in Baghdad and a \"khutbah\" (sermon) was delivered in the name of the Fatimid Imam-Caliph. Despite his Shi'i inclinations, Al-Basasiri received support from Sunnis and Shi'is alike, for whom opposition to the Saljuq power was a common factor.\nOn 10 February 1258, Baghdad was captured by the Mongols led by Hulegu, a grandson of Genghis Khan (\"Chingiz Khan\"), during the siege of Baghdad. Many quarters were ruined by fire, siege, or looting. The Mongols massacred most of the city's inhabitants, including the caliph Al-Musta'sim, and destroyed large sections of the city. The canals and dykes forming the city's irrigation system were also destroyed. During this time, in Baghdad, Christians and Shia were tolerated, while Sunnis were treated as enemies. The sack of Baghdad put an end to the Abbasid Caliphate. It has been argued that this marked an end to the Islamic Golden Age and served a blow from which Islamic civilization never fully recovered.\nAt this point, Baghdad was ruled by the Ilkhanate, a breakaway state of the Mongol Empire, ruling from Iran. In August 1393, Baghdad was occupied by the Central Asian Turkic conqueror Timur (\"Tamerlane\"), by marching there in only eight days from Shiraz. Sultan Ahmad Jalayir fled to Syria, where the Mamluk Sultan Barquq protected him and killed Timur's envoys. Timur left the Sarbadar prince Khwaja Mas'ud to govern Baghdad, but he was driven out when Ahmad Jalayir returned.\nIn 1401, Baghdad was again sacked, by Timur, a Central Asian Turko-Mongol figure. When his forces took Baghdad, he spared almost no one, and ordered that each of his soldiers bring back two severed human heads. Baghdad became a provincial capital controlled by the Mongol Jalayirid (1400\u20131411), Turkic Kara Koyunlu (1411\u20131469), Turkic Ak Koyunlu (1469\u20131508), and the Iranian Safavid (1508\u20131534) dynasties.\nOttoman and Mamluks (16th\u201319th centuries).\nThe Safavids took control of the city in 1509 under the leadership of Shah Ismail I. It remained under Safavid rule until the Ottomans seized it in 1535, but the Safavids regained control in 1624. A massacre occurred when the Shah's army entered the city. It remained under Safavid rule until 1639 when Sultan Murad IV recaptured it in 1638.\nIn 1534, Baghdad was captured by the Ottoman Empire, becoming the administrative capital of Ottoman Iraq. Under the Ottomans, Baghdad continued into a period of decline, partially as a result of the enmity between its rulers and Iranian Safavids, which did not accept the Sunni control of the city. Between 1623 and 1638, it returned to Iranian rule before falling back into Ottoman hands. Baghdad has suffered severely from visitations of the plague and cholera, and sometimes two-thirds of its population has been wiped out. The city became part of an eyalet and then a vilayet.\nFor a time, Baghdad had been the largest city in the Middle East. The city saw relative revival in the latter part of the 18th century, under Mamluk government. Direct Ottoman rule was reimposed by Ali R\u0131za Pasha in 1831. From 1851 to 1852 and from 1861 to 1867, Baghdad was governed, under the Ottoman Empire by Mehmed Nam\u0131k Pasha. The Nuttall Encyclopedia reports the 1907 population of Baghdad as 185,000.\nThe city's municipality was established in 1868, and Ibrahim al-Daftari was appointed its first mayor. The year 1869 is of great importance in the history of Baghdad in the Ottoman era, as it was the beginning of what can be considered a distinct era of the Ottoman eras, the foundations of which were laid by Governor Midhat Pasha, who implemented a number of reform systems and laws that the state legislated during the era of reforms and reconstruction, which was called the Tanzimat era. The overall importance of Baghdad to the Ottomans was that they made the headquarters of the Sixth Corps of the Ottoman Army in the city.\nBy the 19th century, Baghdad emerged as a leading center for Jewish learning. The city had Jewish population of over 6,000 and had numerous yeshivas. The Jewish population has grown so rapidly that by 1884, there were 30,000 Jews in Baghdad and by 1900, around 50,000, comprising over a quarter of the city's total population. Large-scale Jewish immigration from Kurdistan to Baghdad continued throughout this period. By the mid-19th century, the religious infrastructure of Baghdad grew to include a large yeshiva which trained up to sixty rabbis at time. Religious scholarship flourished in Baghdad, which produced great rabbis, such as Joseph Hayyim ben Eliahu Mazal-Tov, known as the Ben Ish Chai (1834\u20131909) or Rabbi Abdallah Somekh (1813\u20131889). During this time, Baghdadi Jews established a successful trade diaspora in China, India and Singapore.\nModern era.\nBaghdad and southern Iraq remained under Ottoman rule until 1918, when they were captured by the British during World War I. In 1920, a revolt erupted in Baghdad against new British policies. It began in summer with mass demonstrations by Iraqis, including protests by embittered officers from the old Ottoman Army. The revolt gained momentum and spread to the middle and lower Euphrates. The British authorities retaliated by air bombing across Baghdad, which killed thousands of residents. In 1921, under the Mandate of Mesopotamia, Baghdad became the capital of the British-protected monarchy. Baghdad was made capital of the independent kingdom of Iraq in 1932.\nSeveral architectural and planning projects were commissioned to reinforce this administration. During this period, the substantial Jewish community (probably exceeding 100,000 people) comprised between a quarter and a third of the city's population. The National Museum of Iraq and the University of Baghdad were built by King Faisal, who laid foundation for the modern Iraqi state. The city's population grew from an estimated 145,000 in 1900 to 580,000 in 1950. A development plan came in 1957, visioned by Frank Lloyd Wright. The plan proposed to build a cultural hub on an island on the river, with an opera house, museums, a university, shopping malls, and a 300-foot statue of the fifth Abbasid caliph Harun al-Rashid.\nOn 1 April 1941, members of the \"Golden Square\" led by former minister Rashid Ali al-Gaylani staged a coup in Baghdad and installed a pro-German and pro-Italian government to replace the pro-British government of Regent Abd al-Ilah. The British forces intervened in the resulting Anglo-Iraqi War. Fearing the advancement, Gaylani and his government had fled, and the mayor of Baghdad surrendered to the British and Commonwealth forces. On 1\u20132 June, during the ensuing power vacuum, Jewish residents were attacked following rumors they had aided the British. In what became known as the \"Farhud\", over 180 Jews were killed and 1,000 injured, 900 Jewish homes were destroyed, and hundreds of Jewish properties were ransacked. Many Jewish girls were raped and children maimed in front of their families. Between 300 and 400 non-Jewish rioters were killed in the attempt to quell the violence. Between 1950 and 1951, Jews were targeted in series of bombings. According to Avi Shlaim, Israel was behind bombings.\nOn 14 July 1958, a significant portion of the Iraqi Army under Abdul-Karim Qasim, staged a coup to topple the Kingdom of Iraq. The army seized control over Baghdad and stormed the radio station and the Al-Rehab Palace. Many people were brutally killed during the coup, including King Faisal II, former Regent Abd al-Ilah and former Prime Minister Nuri al-Said and members of the royal family. Many of the royal figures' bodies were dragged through the streets and mutilated. Mob violence emerged and several foreign nationals staying at the Baghdad Hotel, including Americans and Jordanians were killed. New principles were adopted for the city's development. New Baghdad and Sadr City were developed during the reign of Qasim. In 1960, Baghdad hosted an international conference with dignitaries from Iran, Venezuela and Saudi Arabia, that founded Organization of Petroleum Exporting Countries (OPEC).During the 1970s, Baghdad experienced a period of prosperity and growth because of a sharp increase in the price of petroleum, Iraq's main export. New infrastructure including oil pipelines, modern sewerage, and highways were built. Master plans of the city (1967 and 1973) were delivered by the Polish planning office Miastoprojekt-Krak\u00f3w, mediated by Polservice. Saddam Hussein sponsored architectural and artwork events, that attracted world's popular architects. The city had a vibrant lifestyle. Baghdad was called as \"Nuremberg of 1930s\" and \"Las Vegas of the 1980s\".\nHowever, the Iran\u2013Iraq War of the 1980s was a difficult time for the city, as money was diverted to the military and thousands of residents endured devastations. Iran launched a number of missiles and rockets on Baghdad, some of them hitting dangerously close to Al-Rashid Street and the Jewish Quarter. Power plants and oil refineries were damaged. A nuclear reactor near Baghdad was destroyed in an airstrike by Israel. Despite the war, preparations were underway for Baghdad to host a Non-Alignment Movement summit. Conference centers and hotels such as Palestine Hotel, Al-Mansour Hotel and Ishtar Hotel were built. However, the summit was later shifted to New Delhi, due to deteriorating security.\nDuring the Gulf War, Baghdad was the most heavily defended area of Iraq. Initially, U.S. airstrikes on Baghdad failed and resulted a tactical victory for the Iraqi Air Force. Later, the Coalition forces proceeded with aerial bombings. Air defense, communication systems, bridges, chemical weapon facilities, and artilleries were damaged. Oil refineries and airport were targeted. On 13 February 1991, an aerial bombing attack in Amiriya killed at least 408 civilians. Shortly after the end of the war, ethnic Kurds and Shi'a Muslims led uprisings against the government. Clashes took place Shi'a rebels and the Republican Guard led by Qusay Hussein. Sadr City was besieged until the order restored. Another uprising occurred in 1999, after Ayatollah Muhammad Sadiq al-Sadr was assassinated in Najaf. Unrest began as large scale protests took place in Shia neighborhoods of Baghdad, specially Saddam City. The Republican Guard deployed in the district suppressed the demonstration, leaving between 27 and 100 dead.\nBaghdad was targeted in frequent U.S. airstrikes. On 26 June 1993, cruise missiles were launched into downtown Baghdad, targeting the intelligence headquarters in the Mansour district. The attack killed nine civilians nearby, including actress and painter Layla Al-Attar. During the 1998 bombing of Iraq, missiles struck multiple locations across Baghdad, including presidential palaces, several Republican Guard barrakcs, and offices of the Ministry of Defense and the Military industry. On February 16, 2001, the U.S. launched air strikes on five military targets at Taji.\n21st century (2001\u2013present).\nThe city was economically drained, as a result of the Gulf War and the subsequent embargo against Iraq. By the end of the 1990s, the government made improvements and began rebuilding Baghdad. Government offices, presidential palaces, bridges and roads damaged in the war and follow-up U.S. attacks were restored. The city's airport was reopened, with flights from Lebanon, Syria and Jordan. Numerous mosques were built as a part of the Faith Campaign. In 2001, a broad initiative came to restore Baghdad's cultural heritage. Older mosques, churches, \"mandis\" and synagogues were restored and other historical structures were rebuilt. Under Saddam's architectural vision, a large number of palaces were built around the city. However, these efforts were interrupted by the war which began in 2003.\nIn 2003, the United States-led coalition invaded Iraq. Coalition forces launched massive aerial assaults. The resistance of the Iraqi Army of the city's airport delayed coalition's entry into Baghdad. Following the fall of Baghdad on 9 April 2003, the government lost its power. A statue of Saddam was toppled in Firdous Square, symbolizing the end of his rule. Many of the former government officials were either killed or captured, while others managed to escape and flee. After the overthrow the government, the Coalition Provisional Authority (CPA) was formed. CPA's decisions caused a power vacuum. Also two minor riots took place in 2003, on 21 July and 2 October, causing some disturbance in the population. Shortly after the invasion and the fall of the regime, an insurgancy began against the U.S-led rule of Iraq, consisting of former government officers and Islamist groups.\nBombings took place at Jordanian Embassy and Canal Hotel. Religious and ethnic minorities,\u2014 Christians, Mandaeans, and Jews, began leaving the city out of fear of being targeted in attacks, as they were subjected to kidnappings, death threats, and violence. The Iraqi Film Archives site was bombed, priceless collection of artifacts in the National Museum was looted, and thousands of ancient manuscripts in the National Library were destroyed. The Haifa Street helicopter incident on 12 September was controversial. On the eve of Ashura on 2 March 2004, one of the deadliest bombing took place in Baghdad, that killed at least 80\u2013100 and injured 200 Shi'a Muslims. In 2005, over 965 people were killed in Al-Aimmah Bridge near Al-Kadhimiya Mosque. Attempts were made to rescue people, specially from the Sunni district of Adhamiyah, which is today seen as a symbol of unity.\nCoinciding the execution of Saddam Hussein in 2006, violence increased during the civil war between Shi'ite militias and Sunni insurgents. Shi'ite militias were Muqtada as-Sadr's Jaysh al-Mahdi (JAM) and the Iranian-backed Special Groups and among Sunni insurgents, the largest was Al-Qaeda in Iraq (AQI). Sunni insurgents established their bases Mansour, Adhamiyah and Doura. Mansour district borders the Shi'ite populated Kadhimiyah and East Rasheed. Before 2003, it was home to wealthy Sunnis and Ba'athist officials. Hence, when the regime fell, it quickly became a stronghold for the Sunni insurgency. While Shia militias were based in Sadr City, Kadhimiyah, and West Rasheed, with Bab Al-Sharqi becoming stronghold for the Mahdi Army. Later, they also expanded into the surrounding districts of eastern Baghdad. 9 Nissan, Karadah, and Rusafa were dominated by Shias.\nUnder Operation Imposing Law (\"Operation Fardh al-Qanoon\"), the coalition forces and post-2003 Iraqi Army successfully defeated Al-Qaeda and targeted Shia militias. By 2009, the level of violence decreased. However, violence continued. The period surrounding Provincial Elections was remarkably peaceful. But Baghdad witnessed an uptick in attacks in early April 2009, when a series of suicide bomb and vehicle-borne improvised explosive device attacks were perpetrated across the capital.\u00a0 The war and subsequent occupation ended in 2011, that caused huge damage to Baghdad's transportation, power, and sanitary infrastructure. It resulted in massive civilian casualties, whose number is disputed.\nThough the war ended, but an Islamist insurgency lasted until 2013. Baghdad experienced anti-government protests by Sunnis during the Arab Spring. It was followed by another war from 2013 to 2017 and a low-level insurgency from 2017, which included suicide bombings in January 2018 and January 2021. It has been site of clashes between the citizens and the government. The city attracted global media attention on 3 January 2020, when Iranian general Qasem Soleimani was assassinated in a U.S. drone strike near Baghdad Airport. In December 2015, Baghdad was selected by UNESCO as the first Arab city of the center of literary creativity.\nGeography.\nThe city is located on a vast plain bisected by the Tigris river. The Tigris splits Baghdad in half, with the eastern half being called \"Risafa\" and the Western half known as \"Karkh\". The land on which the city is built is almost entirely flat and low-lying, being of quaternary alluvial origin due to periodic large flooding of the Tigris river. The Diyala river is a tributary of the Tigris, flowing southeast of the city and bordering its eastern suburbs.\nBaghdad is northwest of Basra, south of Mosul, south of Erbil and northeast of Karbala. Located to the south is Mahmoudiyah, which serves as the gateway to Baghdad.\nClimate.\nBaghdad has a hot desert climate (K\u00f6ppen \"BWh\"), featuring extremely hot, prolonged, dry summers and mild to cool, slightly wet, short winters. In the summer, from June through August, the average maximum temperature is as high as and accompanied by sunshine. Rainfall has been recorded on fewer than half a dozen occasions at this time of year and has never exceeded . Even at night, temperatures in summer are seldom below . Baghdad's record highest temperature of was reached on 28 July 2020. Humidity is under 50% in summer, due to Baghdad's distance from both the marshes in southern Iraq and the coasts of the Persian Gulf. Dust storms from the deserts to the west are a normal occurrence during the summer.\nIts winter temperatures are those of a hot desert climate. From December through February, Baghdad has maximum temperatures averaging , with highs possible above . Lows below freezing occur statistically a couple of times per year.\nAnnual rainfall, almost entirely confined to the period from November through March, averages approximately , but has been as high as and as low as . On 11 January 2008, light snow fell across Baghdad for the first time in 100 years. Snowfall was again reported on 11 February 2020, with accumulations across the city.\nGovernance.\nAdministratively, Baghdad Governorate is divided into districts which are further divided into sub-districts. Municipally, the governorate is divided into 9 municipalities, which have responsibility for local issues. Regional services, however, are coordinated and carried out by a mayor who oversees the municipalities. The governorate council is responsible for the governorate-wide policy. These official subdivisions of the city served as administrative centers for the delivery of municipal services but until 2003 had no political function. Beginning in April 2003, the U.S\u2014controlled Coalition Provisional Authority (CPA) began the process of creating new functions for these. The process initially focused on the election of neighborhood councils in official neighborhoods, elected by neighborhood caucuses. The CPA convened a series of meetings in each neighborhood to explain local government, to describe the caucus election process and to encourage participants to spread the word and bring friends, relatives and neighbors to subsequent meetings.\nEach neighborhood process ultimately ended with a final meeting where candidates for the new neighborhood councils identified themselves and asked their neighbors to vote for them. Once all 88 neighborhood councils were in place, each neighborhood council elected representatives from among their members to serve on one of the city's nine district councils. The number of neighborhood representatives on a district council is based upon the neighborhood's population. The next step was to have each of the nine district councils elect representatives from their membership to serve on the 37 member Baghdad City Council. Later, the number of official neighborhoods were increased to 89. This three tier system of local government connected the people of Baghdad to the central government through their representatives from the neighborhood, through the district, and up to the city council. The same process was used to provide representative councils for the other communities in Baghdad Province outside of the city itself. There, local councils were elected from 20 neighborhoods (\"Nahia\") and these councils elected representatives from their members to serve on six district councils (\"Qada\").\nAs within the city, the district councils then elected representatives from among their members to serve on the 35 member Baghdad Regional Council. The first step in the establishment of the system of local government for Baghdad Province was the election of the Baghdad Provincial Council. As before, the representatives to the Provincial Council were elected by their peers from the lower councils in numbers proportional to the population of the districts they represent. The 41 member Provincial Council took office in February 2004 and served until national elections held in January 2005, when a new Provincial Council was elected. This system of 127 separate councils may seem overly cumbersome; however, Baghdad Province is home to approximately seven million people. At the lowest level, the neighborhood councils, each council represents an average of 75,000 people. The nine District Advisory Councils (DAC) are as follows:\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;*Adhamiyah\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nDemographics.\nBaghdad's population was estimated at 7.22\u00a0million in 2015. The surrounding metropolitan region's population is estimated to be 10,500,000. It is second largest city in the Arab world after Cairo and fourth largest metropolitan area in the Middle East after Tehran. At the beginning of the 21st century, some 1.5\u00a0million people migrated to Baghdad. The 2013\u20132017 civil war following the Islamic State's invasion in 2014 caused hundreds of thousands of Iraqi internally displaced people to flee to the city.\nEthnicity.\nThe vast majority of Baghdad's ethnic population are Iraqi Arabs, while minority groups include Kurds, Feyli, Kurdish, Turkmen, Assyrians, Kawliya, Circassians, Mandaeans, and Armenians. Post-2003 have left an impact of Baghdad's ethnic composition. In 2003, approximately 500,000 Kurds lived in Baghdad. As of 2016, around 300,000 remained in Baghdad. Among them, about 150,000 are Shi'a mostly of Luri origin. The main Kurdish neighborhood is situated in central Baghdad, known as the Quarter of Kurds (\"Akd al\u2013Akrad\"). It is itself home to more than 200 Kurdish families that have lived for generations.\nChristians in Baghdad are predominantly ethnic Assyrians and Armenians. Assyrians began moving to Baghdad by the mid 20th century from northern Iraq and Iran. The historic \"Assyrian Quarter\" of the city \u2013 Dora, which boasted a population of 150,000 Assyrians in 2003, made up over 3% of the capital's Assyrian population then. The community has been subject to kidnappings, death threats, vandalism, and house burnings by al-Qaeda and other insurgent groups. As of the end of 2014, only 1,500 Assyrians remained in Dora and others in Karrada district. Before the war, 25,000 Armenians lived in Iraq, with majority them concentrated in Baghdad. Although the Armenian population has reduced, Baghdad is still home to the largest community of Armenians in Iraq, primarily concentrated in the Armenian quarter of Bab al-Sharqi area.\nAn estimated 60,000 Iraqi Turkmen live in Baghdad, with significant population in the neighborhoods of Adhamiyah and Ragheba Khatun. There is a Circassian neighborhood in the city, which is home to the largest Circassian community of Iraq. The metropolitan area and the adjoining governorate is also home to Kawliya, African Iraqis, Chechens and other groups.\nReligion.\nThe majority of the citizens are Muslims with minorities of Christians, Yezidis, Jews and Mandeans also present. There are many religious centers distributed around the city including mosques, churches, synagogues and Mashkhannas cultic huts. The city historically has a predominantly Sunni population, but by the early 21st century around 52% of the city's population were Shi'ites. Sunni Muslims make up 29\u201334% of Iraq's population and they are still a majority in west and north Iraq. As early as 2003, about 20% of the population of the city was the result of mixed marriages between Shi'ites and Sunnis. Following the civil war between Sunni and Shia militia groups during the occupation of Iraq, the population of Sunnis significantly decreased as they were pushed out of many neighborhoods. Today majority of the neighborhoods are either entirely Sunni or Shi'ite. While few localities are mixed, such as Yarmouk.\nThe Christian community in Baghdad is divided among various denominations, mainly the Chaldean Catholic Church and the Syriac Catholic Church. There is also a significant presence of followers of the Assyrian Church of the East and the Syriac Orthodox Church, along with the largest Armenian Apostolic and Protestant communities in Iraq, which is also located in Baghdad. The city serves as the headquarters of the Chaldean Catholic Church, with its see located in the Cathedral of Our Lady of Sorrows, while the Ancient Church of the East has its see in the Cathedral of the Virgin. Before the Iraq War in 2003, Baghdad was home to 300,000\u2013800,000 Christians, primarily concentrated in several neighborhoods with a Christian majority or significant minority, the most notable being Karrada and al\u2013Dora, which had around 150,000 Christians. After 2003, a large number of Christians were displaced in wars and many of them fled to Baghdad after ISIS's takeover of Mosul. Today about 100,000 Christians remained in Baghdad, primarily in Karrada and Mansour district.\nBaghdad was once home to one of the world's most significant Jewish communities. In 1948, Jews numbered approximately 150,000, constituting 33% of the city's population. Persecution forced most Jews to flee Iraq. Even after 1948, up to 100,000 Jews remained, which decreased. Majority of 15,000 Iraqi Jews lived in Baghdad during Saddam Hussein's rule and their population dwindled, not due to persecution but because of lifted travel restrictions that allowed many to emigrate. By 2003, Iraq still had a Jewish community of about 1,500 people, majority of whom resided in Baghdad. But the population decreased sharply after the war. Today, an estimated 160 Jews live in Baghdad out of spotlight, primarily in the old Jewish quarters of Bataween and Shorja, which was once home to vibrant Jewish community. The city was historically home to over 60 synagogues, cemeteries, and shrines, many of which were preserved before 2003. However, their condition deteriorated after the war, and only a few sites, such as the Meir Taweig Synagogue and Al-Habibiyah Jewish Cemetery, remain today.\nBeyond their traditional homelands, around Amarah and Basra, Mandaeans are also found in Baghdad. By the late 20th century, Mandaeans began settling in Baghdad for better opportunities. Most of them live primarily around al-Qadisiyah and Dora, which is location to their place of worship and cultural centers. However, persecution of Mandaeans have been greatly decreased since 2003. There is also a small of community of Baha'is and Sikhs, who live in Baghdad. The Sikhs are mostly Indians. Before 2003, Baghdad was regularly visited by Sikh pilgrims from India.\nEconomy.\nBaghdad serves as the commercial and financial hub, home to 22% of the population, and generating 40% of the Iraq's GDP. It connects trade routes between Turkey, Syria, India, and Southeast Asia. As the capital, it hosts government institutions and state enterprises, key sources of employment. The public education system follows Ba'athist socialist ideologies, for employment in the public sector. Since 2003, the public sector has struggled to provide jobs, and the private sector hasn't grown sufficiently, leading companies to hire mainly foreigners. To address this, NGOs are establishing incubation centers in the city.\nBaghdad serves as headquarters for important companies of Iraq, such as Iraq National Oil Company, State Organization for Marketing of Oil and Iraqi Airways. Baghdad is home to large insurance companies and banks \u2014 Central Bank of Iraq, Rafidain Bank, and Rashid Bank and regional headquarters for First Abu Dhabi Bank, Fransabank and Saudi National Bank. Multinational companies such as Honeywell, Shell, General Electric, SalamAir and Robert Bosch GmbH have established their regional base. Baghdad is also home to Iraq Stock Exchange, that was established in 1992. Most of these establishments are located in Al-Rasheed Street, Karrada and Mansour district.\nIt was once one of the main destinations in the region with a wealth of cultural attractions. Tourism has diminished due to wars, but in recent years the city has a revival in tourism although still facing challenges. There are numerous historic, scientific and artistic museums in Baghdad. Religious tourism in Baghdad has grown since 2003, with sites like Al-Kadhimiya Mosque, Abu Hanifa Mosque, Mausoleum of Abdul-Qadir Gilani, and Buratha Mosque attracting visitors from Iran, Pakistan, and India, while non-religious tourists mainly come from Turkey, France, and the United States. Around 1 million people visit the city annually for religious purposes. The pilgrims are both Shia and Sunni Muslims.\nThe city contains the factories of carpets, leather and textiles, workshops, cement and tobacco factories. Industrial areas extend from the city center to outside and suburbs in the metropolitan area, such as Taji and northern Baghdad. Subsequently, it has produced a wide variety of consumer and industrial goods, including processed foods and beverages, clothes, footwear, wood products, furniture, paper and printed material, bricks, chemicals, plastics, electrical equipment, and metal and nonmetallic products. Bismayah, southeast of Baghdad, is home to world's largest precast factory. In agricultural aspect, palm groves are spread in the city, and many of its people depends on the cultivation of many yields.\nBaghdad, like other provinces such as Babylon, Karbala and Qadissiya, contains metals such as aluminum, ceramics, nickel, manganese and chromium, whose size is not yet known, being recently discovered by local Iraqi cadres lacking experience and mechanisms to determine the size of these explorations. An oilfield is located in eastern Baghdad. It was believed that the quantities of oil is modest, but the drilling disclosed that its size exceeds the initial estimates, and has northern extensions in the province of Salah al-Din, and southern province of Wasit. The city is also home to Dora Refinery, a large oil refinery in Dora, which is the 3rd largest in Iraq in terms of production. The production of it exceeds per day, while its total production estimated if it was developed up to per day.\nMost reconstruction efforts have been devoted to the restoration and repair of badly damaged urban infrastructure. Some of the private projects includes Baghdad Renaissance Plan, Sindbad Hotel Complex and Conference Center, and Central Bank of Iraq Tower. Other project proposed includes Romantic Island and Baghdad Gate.&lt;ref name=\"MSNBC/id/264259112\"&gt;&lt;/ref&gt; Numerous projects have been also impacted due to corruption. According to a report published by CNBC, there are around 150 entertainment projects planned for the city. Many of them were delayed due to government policies. Also Baghdad has witnessed the opening of dozens of tourist complexes annually with areas reaching in addition to some major tourism projects with areas exceeding with the aim of investment combining trade and tourism as a distinctive economic model. In recent years, Baghdad has also adopted modern economic trends like, establishment of startup hubs, office space and incubation center, as well as development of shopping malls such Baghdad Mall and Dijlah Village.\nTransportation.\nBaghdad lacks substantial public transportation, and taxis are the primary means of transportation in the city. Roads in Baghdad have been known to be especially congested since at least 2003. According to MP Jassim Al-Bukhati in 2021, \"Baghdad's roads are designed to accommodate 700,000 cars, while now there are between 2.5 and 3 million cars on them\". This is because, since 2003, car imports have increased. Since then, river-based water transport has become a popular mode of transport. Use of boats crossing across the river saves time for travelers escaping congestion. Private organizations are working to improve the transport system.\nAmong the major bridges connecting Karkh and Rusafa are 14th of July Bridge, Al-Aimmah Bridge and Al-Sarafiya Bridge. In 2023, the authorities announced plans to build 19 bridges in Baghdad. This is a part of its post-war reconstruction efforts, as many bridges were damaged during the war. Streets, avenues and alleys form an important part of the transport network. Al-Sa'doun Street stretches from Liberation Square to Masbah. Abu Nuwas Street runs along the Tigris from the Jumhouriya Bridge to 14 July Suspended Bridge. Damascus Street goes from Damascus Square to the Baghdad Airport Road. Hilla Road runs from the north into Baghdad via Yarmouk. Mutanabbi Street is a street with numerous bookshops, named after the 10th century Iraqi poet Al-Mutanabbi. Caliphs Street is the site of historical mosques and churches.\nAir transport.\nIraqi Airways, the national airline of Iraq, operates out of Baghdad International Airport in Baghdad. The airport was opened by Saddam Hussein in 1982 as Saddam International Airport. It was closed as result of the Gulf War and subsequent embargo. The airport was reopened in August 2000. The airport adopted its current name after the 2003 invasion of Iraq.\nPlanned Baghdad Metro.\nThe Baghdad Metro project was first proposed during the 1970s but did not come to fruition due to wars and sanctions. After the Iraq war, Iraqi authorities intended to revive the project, but it was again delayed due to domestic instability. In 2019, it was reported that Korean Hyundai and French Alstom would be building the metro. However, the planned construction did not happen.\nAs of February 2024, the current plan consisted of fully electric and automated (\"driverless\") trains running on an extensive railway network including an underground railway portion as well as an elevated railway. The proposed Baghdad Metro system includes seven main lines with a total length of more than 148 kilometres, 64 metro stations, four workshops and depots for trains, several operations control centers (OCC) and seven main power stations (MPS) with a capacity of 250 mega-watts, and several Global System for Mobile Communication (GSM) towers. The metro will be equipped with CCTV and internet as well as USB ports for charging. Special compartments will be allocated for women and children as well as seats for people with special needs, pregnant women, and the elderly. The metro stations will be connected to other public transport networks such as buses and taxis, and 10 parking spaces will be available for commuters. The planned operating speed will be 80\u2013140\u00a0km/hour with an estimated 3.25 million riders per day.\nIn July 2024, it was announced that an international consortium of German French, Spanish, and Turkish companies was awarded $17.5 billion contract to construct Baghdad's metro. The consortium includes Alstom, Systra, SNCF, Talgo, Deutsche Bank and SENER. The consortium was then to negotiate the technical, financial and operational details of the project which is now estimated to be completed in May 2029.\nCityscape.\nThe Round City was the core of the city, during the establishment of Baghdad. It ceased to exist, as a result of the Mongolian siege. Urban features such as streets, avenues, alleyways and squares clusters a large number of landmarks, which itself creates an identity of cultural or intellectual hubs and define the beauty of Baghdad.\nAl-Rasheed Street is one of the most significant landmarks in Baghdad. Located in al-Rusafa area, the street was an artistic, intellectual and cultural center for many Baghdadis. It also included many prominent theaters and nightclubs such as the Crescent Theatre where Egyptian Singer Umm Kulthum sang during her visit in 1932 as well as the Chakmakji Company that recorded the music of various Arab singers. The street also contains famous and well-known landmarks including the ancient Haydar-Khana Mosque as well as numerous well-known caf\u00e9s such as al-Zahawi Caf\u00e9 and the Brazilian Caf\u00e9.\nMutanabbi Street is located near the old quarter of Baghdad; at Al-Rasheed Street. It is the historic center of Baghdadi book-selling, a street filled with bookstores and outdoor book stalls. It was named after the 10th-century classical Iraqi poet Al-Mutanabbi. This street is well established for bookselling and has often been referred to as the heart and soul of the Baghdad literacy and intellectual community. Firdos Square is a public open space in Baghdad and the location of two of the best-known hotels, the Palestine Hotel and the Sheraton Ishtar, which are both also the tallest buildings in Baghdad. The square was the site of the statue of Saddam Hussein that was pulled down by the coalition forces in a widely televised event during the 2003 invasion of Iraq.\nQushla or Qishla is a public square and the historical complex located in al-Rusafa neighborhood at the riverbank of Tigris. The place and its surroundings is where the historical features and cultural capitals of Baghdad are concentrated, from the Mutanabbi Street, Abbasid-era palace and bridges, Ottoman-era mosques to the Mustansariyah Madrasa. The square developed during the Ottoman era as a military barracks. Today, it is a place where the citizens of Baghdad find leisure such as reading poetry in gazebos. It is characterized by the iconic clock tower which was donated by George V. The entire area is submitted to the UNESCO World Heritage Site Tentative list.\nArchitecture.\nDuring the 1970s and 1980s, Saddam Hussein's government spent a lot of money on new monuments, mosques, palaces and hotels. The Street is also notable for its architecture and aesthetic which was inspired by Renaissance architecture and also includes the famous Iraqi shanasheel.\nModern Landmarks.\nThe National Museum of Iraq whose collection of artifacts was looted during the invasion, and the iconic Hands of Victory arches. Multiple political parties are in discussions as to whether the arches should remain as historical monuments or be dismantled. Thousands of ancient manuscripts in the National Library were destroyed under Saddam's command.\nGrand Festivities Square is the main square where public celebrations are held and is also the home to three important monuments commemorating Iraqi's fallen soldiers and victories in war; namely Al-Shaheed Monument, the Victory Arch and the Unknown Soldier's Monument. Al-Shaheed Monument, also known as the Martyr's Memorial, is a monument dedicated to the Iraqi soldiers who died in the Iran\u2013Iraq War. However, now it is generally considered by Iraqis to be for all of the martyrs of Iraq, especially those allied with Iran and Syria fighting ISIS, not just of the Iran\u2013Iraq War. The monument was opened in 1983, and was designed by the Iraqi architect Saman Kamal and the Iraqi sculptor and artist Ismail Fatah Al Turk. Though these works symbolize the ruling entity. Neverthelsess, they have remained part of architectural legacy, which beautified Baghdad.\nMasjid Al-Kadhimain is a shrine that is located in the K\u0101dhimayn suburb of Baghdad. It contains the tombs of the seventh and ninth Twelver Shi'ite Imams, Musa al-Kadhim and Muhammad at-Taqi respectively, upon whom the title of \"K\u0101dhimayn\" (\"Two who swallow their anger\") was bestowed. Many Shi'ites travel to the mosque from far away places to commemorate those imams. A'dhamiyyah is a predominantly Sunni area with a Mosque that is associated with the Sunni Imam Abu Hanifa. The name of \"Al-A\u02bf\u1e93amiyyah\" is derived from Abu Hanifa's title, \"al-Im\u0101m al-A\u02bf\u1e93am\" (the Great Imam).\nThe historic Jewish quarters of Bataween and Shorja is home to numerous sites that are associated with Jews. These sites were preserved during the Ba'athist regime. However, after 2003, many of them are in poor conditions. Meir Taweig Synagogue is the only active synagogue of Iraq, which have a large compound, that consist of community center, Jewish school and library. Daniel Market (\"Souq Danial\"), which was named after Menahem Saleh Daniel, still bears the same name. It is popular for fabrics and shoes. The Great Synagogue of Baghdad, the oldest synagogue of Iraq, is now restored as a museum. Al-Habibiyah Cemetery is the largest Jewish cemetery in Baghdad, home to around 1,000 graves. The Tomb of Joshua, now a Muslim shrine, is believed to be the burial site of Joshua. Shaykh Yitzhak Tomb and Synagogue was preserved until 2003. Today it is neglected. Other sites includes House of Sassoon Eskell and library of Mir Basri.\nThe Sabian\u2013Mandaean Mandi of Baghdad is a Mandaen temple in al-Qadisiyyah. It is the main community center for Mandaeans in Iraq. Plans are underway to demolish and build a larger one to accommodate more worshippers. A cultural institute for Mandeans is also in Baghdad. The city is home to Baba Nanak Shrine, a sacred site in Sikhism. It was destroyed during the Iraq War in 2003. In the Kadhimiya district of Baghdad, was the house of Bah\u00e1\u02bcu'll\u00e1h, (Prophet Founder of the Baha'i Faith) also known as the \"Most Great House\" (Bayt-i-A\u02bbzam) and the \"House of God\", where Bah\u00e1\u02bcu'll\u00e1h mostly resided from 1853 to 1863. It is considered a holy place and a place of pilgrimage by Baha'is according to their \"Most Holy Book\". On 23 June 2013, the house was destroyed under unclear circumstances.\nBaghdad Zoo used to be the largest zoological park in the Middle East. Within eight days following the 2003 invasion, however, only 35 of the 650 animals in the facility survived. This was a result of theft of some animals for human food, and starvation of caged animals that had no food. Conservationist Lawrence Anthony and some of the zoo keepers cared for the animals and fed the carnivores with donkeys they had bought locally. Eventually Paul Bremer, Director of the Coalition Provisional Authority in Iraq after the invasion, ordered protection for the zoo and enlisted U.S. engineers to help reopen the facility. Al-Zawraa Park is also part of the zoo, which is main urban park of the city.\nEducation.\nThe House of Wisdom was a major academy and public center in Baghdad. The Mustansiriya Madrasa was established in 1227 by the Abbasid Caliph al-Mustansir. The name was changed to al-Mustansiriya University in 1963. The University of Baghdad is the largest university in Iraq and the second largest in the Arab world. Prior to the Gulf War, multiple international schools operated in Baghdad, including:\nCulture.\nBaghdad has always played a significant role in the broader Arab cultural sphere, contributing several significant writers, musicians and visual artists. Historically, the city had a vibrant modern culture and lifestyle. Famous Arab poets and singers such as Nizar Qabbani, Umm Kulthum, Fairuz, Salah Al-Hamdani, Ilham al-Madfai and others have performed for the city. The dialect of Arabic spoken in Baghdad today differs from that of other large urban centers in Iraq, having features more characteristic of nomadic Arabic dialects (Versteegh, \"The Arabic Language\"). It is possible that this was caused by the repopulating of the city with rural residents after the multiple sackings of the late Middle Ages. For poetry written about Baghdad, see Reuven Snir (ed.), \"Baghdad: The City in Verse\" (Harvard, 2013). Baghdad joined the UNESCO Creative Cities Network as a City of Literature in December 2015.\nSome of the important cultural institutions in the city include the National Theater, which was looted during the 2003 invasion of Iraq, but efforts are underway to restore the theater. The live theater industry received a boost during the 1990s, when UN sanctions limited the import of foreign films. As many as 30 movie theaters were reported to have been converted to live stages, producing a wide range of comedies and dramatic productions. Institutions offering cultural education in Baghdad include The Music and Ballet School of Baghdad and the Institute of Fine Arts Baghdad. The Iraqi National Symphony Orchestra is a government funded symphony orchestra in Baghdad. The INSO plays primarily classical European music, as well as original compositions based on Iraqi and Arab instruments and music. Mandaeans had cultural club in Al-Zawraa, where poetry evenings and cultural seminars were held, attended by poets, writers, artists, officials, and dignitaries of the communities. There is also a social cultural center of Mandaeans at al-Qadisiyyah. Baghdad Jewish Community Center is located in Al-Rashid Street.\nBaghdad is also home to a number of museums which housed artifacts and relics of ancient civilization; many of these were stolen, and the museums looted, during the widespread chaos immediately after United States forces entered the city.\nDuring occupation of Iraq, AFN Iraq (\"Freedom Radio\") broadcast news and entertainment within Baghdad, among other locations. There is also a private radio station called \"Dijlah\" (named after the Arabic word for the Tigris River) that was created in 2004 as Iraq's first independent talk radio station. Radio Dijlah offices, in the Jamia neighborhood of Baghdad, have been attacked on several occasions.\nSport.\nBaghdad is home to some of the most successful football (soccer) teams in Iraq, the biggest being Al-Shorta (Police), Al-Quwa Al-Jawiya (Air Force), Al-Zawraa, and Al-Talaba (Students). The largest stadium in Baghdad is Al-Shaab Stadium, which was opened in 1966. In recent years, the capital has seen the building of several football stadiums which are meant be opened in near future. The city has also had a strong tradition of horse racing ever since World War I, known to Baghdadis simply as 'Races'. There are reports of pressures by the Islamists to stop this tradition due to the associated gambling.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "4493", "revid": "1754504", "url": "https://en.wikipedia.org/wiki?curid=4493", "title": "Outline of biology", "text": " \nBiology \u2013 The natural science that studies life. Areas of focus include structure, function, growth, origin, evolution, distribution, and taxonomy.\n&lt;templatestyles src=\"Template:TOC limit/styles.css\" /&gt;\nChemical basis.\nOutline of biochemistry\nCells.\nOutline of cell biology\nGenetics.\nOutline of Genetics\nEvolution.\nOutline of evolution (see also evolutionary biology) \nEcology.\nOutline of ecology\nSee also.\nRelated outlines\nJournals\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "4495", "revid": "20612", "url": "https://en.wikipedia.org/wiki?curid=4495", "title": "British thermal unit", "text": "Unit of energy\n&lt;templatestyles src=\"Template:Infobox/styles-images.css\" /&gt;\nThe British thermal unit (Btu) is a measure of heat, which is a form of energy. It was originally defined as the amount of heat required to raise the temperature of one pound of water by one degree Fahrenheit. It is also part of the United States customary units. The SI unit for energy is the joule (J); one Btu equals about 1,055\u00a0J (varying within the range of 1,054\u20131,060 J depending on the specific definition of Btu; see below).\nWhile units of heat are often supplanted by energy units in scientific work, they are still used in some fields. For example, in the United States the price of natural gas is quoted in dollars per the amount of natural gas that would give 1 million Btu (1 \"MMBtu\") of heat energy if burned.\nDefinitions.\nA Btu was originally defined as the amount of heat required to raise the temperature of one pound of liquid water by one degree Fahrenheit at a constant pressure of one atmospheric unit. There are several different definitions of the Btu that differ slightly. This reflects the fact that the temperature change of a mass of water due to the addition of a specific amount of heat (calculated in energy units, usually joules) depends slightly upon the water's initial temperature. As seen in the table below, definitions of the Btu based on different water temperatures vary by up to 0.5%.\nPrefixes.\nUnits of kBtu are used in building energy use tracking and heating system sizing. Energy Use Index (EUI) represents kBtu per square foot of conditioned floor area. \"k\" stands for 1,000.\nThe unit MBtu is used in natural gas and other industries to indicate 1,000 Btu. However, there is an ambiguity in that the metric system (SI) uses the prefix \"M\" to indicate 'Mega-', one million (1,000,000). Even so, \"MMBtu\" is often used to indicate one million Btu particularly in the oil and gas industry.\nEnergy analysts accustomed to the metric \"k\" ('kilo-') for 1,000 are more likely to use MBtu to represent one million, especially in documents where M represents one million in other energy or cost units, such as MW, MWh and $.\nThe unit 'therm' is used to represent 100,000 Btu. A decatherm is 10 therms or one million Btu. The unit \"quad\" is commonly used to represent one quadrillion (1015) Btu.\nConversions.\nOne Btu is approximately:\nA Btu can be approximated as the heat produced by burning a single wooden kitchen match or as the amount of energy it takes to lift a weight .\nBtu conversion factors.\nFor purposes of , the following conversion factors apply:\nBtu/h.\nThe SI unit of power for heating and cooling systems is the watt. Btu \"per hour\" (Btu/h) is sometimes used in North America and the United Kingdom\u2014the latter for air conditioning mainly, though \"Btu/h\" is sometimes abbreviated to just \"Btu\". \"MBH\"\u2014thousands of Btu per hour\u2014is also common.\nAssociated units.\nThe Btu should not be confused with the Board of Trade Unit (BTU), an obsolete UK synonym for kilowatt hour ().\nThe Btu is often used to express the conversion-efficiency of heat into electrical energy in power plants. Figures are quoted in terms of the quantity of heat in Btu required to generate 1\u00a0kW\u22c5h of electrical energy. A typical coal-fired power plant works at , an efficiency of 32\u201333%.\nThe centigrade heat unit (CHU) is the amount of heat required to raise the temperature of of water by one Celsius degree. It is equal to 1.8\u00a0Btu or 1,899 joules. In 1974, this unit was \"still sometimes used\" in the United Kingdom as an alternative to Btu.\nAnother legacy unit for energy in the metric system is the calorie, which is defined as the amount of heat required to raise the temperature of one gram of water by one degree Celsius.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "4497", "revid": "42820208", "url": "https://en.wikipedia.org/wiki?curid=4497", "title": "Bugatti", "text": "1909\u20131963 French car manufacturer\nAutomobiles Ettore Bugatti was a French manufacturer of high-performance automobiles. The company was founded in 1909 in the then-German city of Molsheim, Alsace, by the Italian-born industrial designer Ettore Bugatti. The cars were known for their design beauty and numerous race victories. Famous Bugatti automobiles include the Type 35 Grand Prix cars, the Type 41 \"Royale\", the Type 57 \"Atlantic\" and the Type 55 sports car. \nThe death of Ettore Bugatti in 1947 proved to be a severe blow to the marque, and the death of his son Jean in 1939 meant that there was no successor to lead the factory. With no more than about 8,000 cars made, the company struggled financially, and it released one last model in the 1950s before eventually being purchased for its airplane parts business in 1963.\nIn 1987, an Italian entrepreneur bought the brand name and revived it as Bugatti Automobili S.p.A. The name is owned by Bugatti Rimac since 2021. \nA film about the founding of Bugatti is being produced by Andrea Iervolino.\nUnder Ettore Bugatti.\nThe founder Ettore Bugatti was born in Milan, Italy, and the automobile company that bears his name was founded in 1909 in Molsheim located in the Alsace region which was part of the German Empire from 1871 to 1919. The company was known both for the level of detail of its engineering in its automobiles, and for the artistic manner in which the designs were executed, given the artistic nature of Ettore's family (his father, Carlo Bugatti (1856\u20131940), was an important Art Nouveau furniture and jewelry designer).\nWorld War I and its aftermath.\nDuring the war Ettore Bugatti was sent away, initially to Milan and later to Paris, but as soon as hostilities had been concluded he returned to his factory at Molsheim. Less than four months after the Versailles Treaty formalised the transfer of Alsace from Germany to France, Bugatti was able to obtain, at the last minute, a stand at the 15th Paris motor show in October 1919. He exhibited three light cars, all of them closely based on their pre-war equivalents, and each fitted with the same overhead camshaft 4-cylinder 1,368cc engine with four valves per cylinder. Smallest of the three was a \"Type 13\" with a racing body (constructed by the Bugatti themselves) and using a chassis with a wheelbase. The others were a \"Type 22\" and a \"Type 23\" with wheelbases of respectively.\nRacing successes.\nThe company also enjoyed great success in early Grand Prix motor racing: in 1929, a privately entered Bugatti won the first ever Monaco Grand Prix. Bugatti's racing success culminated with driver Jean-Pierre Wimille winning the 24 hours of Le Mans twice (in 1937 with Robert Benoist and in 1939 with Pierre Veyron).\nBugatti cars were extremely successful in racing. The little Bugatti Type 10 swept the top four positions at its first race. The 1924 Bugatti Type 35 is one of the most successful racing cars - developed by Bugatti with master engineer and racing driver Jean Chassagne who also drove it in the car's first ever Grand Prix in 1924 Lyon. Bugattis swept to victory in the Targa Florio for five years straight from 1925 through 1929. Louis Chiron held the most podiums in Bugatti cars, and the modern marque revival Bugatti Automobiles S.A.S. named the 1999 Bugatti 18/3 Chiron concept car in his honour. But it was the final racing success at Le Mans that is most remembered\u2014Jean-Pierre Wimille and Pierre Veyron won the 1939 race with just one car and meagre resources.\nAeroplane racing.\nIn the 1930s, Ettore Bugatti got involved in the creation of a racer airplane, hoping to beat the Germans in the Deutsch de la Meurthe prize. This would be the Bugatti 100P, which never flew. It was designed by Belgian engineer Louis de Monge who had already applied Bugatti Brescia engines in his \"Type 7.5\" lifting body.\nRailcar.\nEttore Bugatti also designed a successful motorised railcar, the Autorail Bugatti.\nFamily tragedy.\nThe death of Ettore Bugatti's son, Jean Bugatti, on 11 August 1939 marked a turning point in the company's fortunes as he died while testing a Type 57 tank-bodied race car near the Molsheim factory.\nAfter World War II.\nWorld War II left the Molsheim factory in ruins and the company lost control of the property. During the war, Bugatti planned a new factory at Levallois, a northwestern suburb of Paris. After the war, Bugatti designed and planned to build a series of new cars, including the Type 73 road car and Type 73C single seat racing car, but in all Bugatti built only five Type 73 cars.\nDevelopment of a 375\u00a0cc supercharged car was stopped when Ettore Bugatti died on 21 August 1947. Following his death, the business declined further and made its last appearance as a business in its own right at a Paris Motor Show in October 1952.\nAfter a long decline, the original incarnation of Bugatti ceased operations in 1952.\nDesign.\nBugatti models are known to focus on design. Engine blocks were hand scraped to ensure that the surfaces were flat so that gaskets were not required for sealing, and many of the exposed surfaces of the engine compartment featured \"guilloch\u00e9\" finishes on them. Safety wires were threaded through most fasteners in intricately laced patterns. Rather than bolt the springs to the axles as most manufacturers did, Bugatti's axles were forged such that the spring passed through an opening in the axle, a much more elegant solution requiring fewer parts. Bugatti himself described his competitor Bentley's cars as \"the world's fastest lorries\" for focusing on durability. According to Bugatti, \"weight was the enemy\".\nGallery.\nNotable finds in the modern era.\nRelatives of Harold Carr found a rare 1937 Bugatti Type 57S Atalante when cataloguing the doctor's belongings after his death in 2009. Carr's Type 57S is notable because it was originally owned by British race car driver Earl Howe. Because much of the car's original equipment is intact, it can be restored without relying on replacement parts.\nOn 10 July 2009, a 1925 Bugatti Brescia Type 22 which had lain at the bottom of Lake Maggiore on the border of Switzerland and Italy for 75 years was recovered from the lake. The Mullin Museum in Oxnard, California bought it at auction for $351,343 at Bonham's R\u00e9tromobile sale in Paris in 2010.\nAttempts at revival.\nThe company attempted a comeback under Roland Bugatti in the mid-1950s with the mid-engined Type 251 race car. Designed with help from Gioacchino Colombo, the car failed to perform to expectations and the company's attempts at automobile production were halted.\nIn the 1960s, Virgil Exner designed a Bugatti as part of his \"Revival Cars\" project. A show version of this car was actually built by Ghia using the last Bugatti Type 101 chassis, and was shown at the 1965 Turin Motor Show. Finance was not forthcoming, and Exner then turned his attention to a revival of Stutz.\nBugatti continued manufacturing airplane parts and was sold to Hispano-Suiza, also a former auto maker turned aircraft supplier, in 1963. Snecma took over Hispano-Suiza in 1968. After acquiring Messier, Snecma merged Messier and Bugatti into Messier-Bugatti in 1977.\nModern revivals.\nBugatti Automobili S.p.A. (1987\u20131995).\nItalian entrepreneur Romano Artioli acquired the Bugatti brand in 1987, and established Bugatti Automobili S.p.A.. Artioli commissioned architect Giampaolo Benedini to design the factory which was built in Campogalliano, Modena, Italy. Construction of the plant began in 1988, alongside the development of the first model, and it was inaugurated two years later\u2014in 1990. By 1989, the plans for the new Bugatti revival were presented by Paolo Stanzani and Marcello Gandini, designers of the Lamborghini Miura and Lamborghini Countach.\nThe first production vehicle was the Bugatti EB110 GT which featured a 3.5-litre, 5-valve per cylinder, quad-turbocharged 60\u00b0 V12 engine, a six-speed gearbox, and four-wheel drive. Stanzani proposed an aluminium honeycomb chassis, which was used for all early prototypes. He and president Artioli clashed over engineering decisions so Stanzani left the project and Artioli sought Nicola Materazzi to replace him in June 1990. Materazzi, who had been the chief designer for the Ferrari 288 GTO and Ferrari F40 replaced the aluminium chassis with a carbon fibre one manufactured by Aerospatiale and also altered the torque distribution of the car from 40:60 to 27:73. He remained Director until late 1992.\nRacing car designer Mauro Forghieri served as Bugatti's technical director from 1993 through 1994. On 27 August 1993, through his holding company, ACBN Holdings S.A. of Luxembourg, Romano Artioli purchased Lotus Cars from General Motors. Plans were made to list Bugatti shares on international stock exchanges.\nBugatti presented a prototype large saloon called the EB112 in 1993.\nPerhaps the most famous Bugatti EB110 owner was seven-time Formula One World Champion racing driver Michael Schumacher who purchased an EB110 in 1994. Schumacher sold his EB110, which had been repaired after a severe 1994 crash, to Modena Motorsport, a Ferrari service and race preparation garage in Germany.\nBy the time the EB110 came to market, the North American and European economies were in recession. Poor economic conditions caused the company to fail and operations ceased in September 1995. A model specific to the US market called the \"Bugatti America\" was in the preparatory stages when the company ceased operations.\nBugatti's liquidators sold Lotus Cars to Proton of Malaysia. German firm Dauer Racing purchased the EB110 licence and remaining parts stock in 1997 in order to produce five more EB110 SS vehicles. These five SS versions of the EB110 were greatly refined by Dauer. The Campogalliano factory was sold to a furniture-making company, which became defunct prior to moving in, leaving the building unoccupied. After Dauer stopped producing cars in 2011, Toscana-Motors GmbH of Germany purchased the remaining parts stock from Dauer.\nEx vice-president Jean-Marc Borel and ex-employees Federico Trombi, Gianni Sighinolfi and Nicola Materazzi established the B Engineering company and designed and built the Edonis using the chassis and engine from the Bugatti EB110 SS, but simplifying the turbocharging system and driveline (from 4WD to 2WD).\nBugatti Automobiles S.A.S. (1998\u2013present).\nPre-Veyron.\nVolkswagen Group acquired the Bugatti brand in 1998. Bugatti Automobiles S.A.S. commissioned Giorgetto Giugiaro of ItalDesign to produce Bugatti Automobiles's first concept vehicle, the EB118, a coup\u00e9 that debuted at the 1998 Paris Auto Show. The EB118 concept featured a , W-18 engine. After its Paris debut, the EB118 concept was shown again in 1999 at the Geneva Auto Show and the Tokyo Motor Show. Bugatti introduced its next concepts, the EB 218 at the 1999 Geneva Motor Show and the 18/3 Chiron at the 1999 Frankfurt Motor Show (IAA).\nVeyron era (2005\u20132015).\nBugatti Automobiles S.A.S. began assembling its first regular-production vehicle, the Bugatti Veyron 16.4 (the 1001 PS super car with an 8-litre W-16 engine with four turbochargers) in September 2005 at the Bugatti Molsheim, France assembly \"studio\". On 23 February 2015, Bugatti sold its last Veyron Grand Sport Vitesse, which was named La Finale.\nChiron era (2016\u2013present).\nThe Bugatti Chiron is a mid-engined, two-seated sports car, designed by Achim Anscheidt, developed as the successor to the Bugatti Veyron. The Chiron was first revealed at the Geneva Motor Show on March 1, 2016.\nIn February 2024, Bugatti announced the successor to the Chiron, which will use a V16 hybrid-electric powertrain. In June 2024 the successor was confirmed as the Bugatti Tourbillon.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "4498", "revid": "48958926", "url": "https://en.wikipedia.org/wiki?curid=4498", "title": "Benchmark", "text": "Benchmark may refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "4499", "revid": "2214", "url": "https://en.wikipedia.org/wiki?curid=4499", "title": "Band", "text": "Band or BAND may refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "4501", "revid": "7903804", "url": "https://en.wikipedia.org/wiki?curid=4501", "title": "Black Death", "text": "1346\u20131353 pandemic in Eurasia and North Africa\nThe Black Death was a bubonic plague pandemic that occurred in Europe from 1346 to 1353. It was one of the most fatal pandemics in human history; as many as 50 million people perished, perhaps 50% of Europe's 14th-century population. The disease is caused by the bacterium \"Yersinia pestis\" and spread by fleas and through the air. One of the most significant events in European history, the Black Death had far-reaching population, economic, and cultural impacts. It was the beginning of the second plague pandemic. The plague created religious, social and economic upheavals, with profound effects on the course of European history.\nThe origin of the Black Death is disputed. Genetic analysis suggests \"Yersinia pestis\" bacteria evolved approximately 7,000 years ago, at the beginning of the Neolithic, with flea-mediated strains emerging around 3,800 years ago during the late Bronze Age. The immediate territorial origins of the Black Death and its outbreak remain unclear, with some evidence pointing towards Central Asia, China, the Middle East, and Europe. The pandemic was reportedly first introduced to Europe during the siege of the Genoese trading port of Kaffa in Crimea by the Golden Horde army of Jani Beg in 1347. From Crimea, it was most likely carried by fleas living on the black rats that travelled on Genoese ships, spreading through the Mediterranean Basin and reaching North Africa, West Asia, and the rest of Europe via Constantinople, Sicily, and the Italian Peninsula. There is evidence that once it came ashore, the Black Death mainly spread from person-to-person as pneumonic plague, thus explaining the quick inland spread of the epidemic, which was faster than would be expected if the primary vector was rat fleas causing bubonic plague. In 2022, it was discovered that there was a sudden surge of deaths in what is today Kyrgyzstan from the Black Death in the late 1330s; when combined with genetic evidence, this implies that the initial spread may have pre-dated, by nearly two decades, the 14th-century Mongol conquests previously postulated as the cause.\nThe Black Death was the second great natural disaster to strike Europe during the Late Middle Ages (the first one being the Great Famine of 1315\u20131317) and is estimated to have killed 30% to 60% of the European population, as well as approximately 33% of the population of the Middle East. There were further outbreaks throughout the Late Middle Ages and, also due to other contributing factors (the crisis of the late Middle Ages), the European population did not regain its 14th century level until the 16th century. Outbreaks of the plague recurred around the world until the early 19th century.\nNames.\nEuropean writers contemporary with the plague described the disease in Latin as or ; ; . In English prior to the 18th century, the event was called the \"pestilence\" or \"great pestilence\", \"the plague\" or the \"great death\". Subsequent to the pandemic \"the \"furste moreyn\"\" (first murrain) or \"first pestilence\" was applied, to distinguish the mid-14th century phenomenon from other infectious diseases and epidemics of plague.\nThe 1347 pandemic plague was not referred to specifically as \"black,\" at the time, in any European language. The expression \"black death\" had occasionally been applied to other fatal or dangerous diseases. In English, \"Black death\" was not used to describe this plague pandemic, however, until the 1750s; the term is first attested in 1755, where it translated . \nThis expression \u2014 as a proper name for the pandemic \u2014 had been popularized by Swedish and Danish chroniclers in the 15th and early 16th centuries, and in the 16th and 17th centuries, it was transferred to other languages as a calque: , , and . Previously, most European languages had named the pandemic a variant or calque of the .\nThe phrase 'black death' \u2013 describing Death as black \u2013 is very old. Homer used it in the Odyssey to describe the monstrous Scylla, with her mouths \"full of black Death\" (). Seneca the Younger may have been the first to describe an epidemic as 'black death', () but only in reference to the acute lethality and dark prognosis of disease. The 12th\u201313th century French physician Gilles de Corbeil had already used to refer to a \"pestilential fever\" () in his work \"On the Signs and Symptoms of Diseases\" (). The phrase , was used in 1350 by Simon de Covino (or Couvin), a Belgian astronomer, in his poem \"On the Judgement of the Sun at a Feast of Saturn\" (), which attributes the plague to an astrological conjunction of Jupiter and Saturn. His use of the phrase is not connected unambiguously with the plague pandemic of 1347 and appears to refer to the fatal outcome of disease.\nThe historian Elizabeth Penrose, writing under the pen-name \"Mrs Markham\", described the 14th-century outbreak as the \"black death\" in 1823. The historian Cardinal Francis Aidan Gasquet wrote about the Great Pestilence in 1893 and suggested that it had been \"some form of the ordinary Eastern or bubonic plague\". In 1908, Gasquet said use of the name for the 14th-century epidemic first appeared in a 1631 book on Danish history by J.\u00a0I. Pontanus: \"Commonly and from its effects, they called it the black death\" ().\nPrevious plague epidemics.\nResearch from 2017 suggests plague first infected humans in Europe and Asia in the Late Neolithic-Early Bronze Age. Research in 2018 found evidence of \"Yersinia pestis\" in an ancient Swedish tomb, which may have been associated with the \"Neolithic decline\" around 3000 BCE, in which European populations fell significantly. This \"Y. pestis\" may have been different from more modern types, with bubonic plague transmissible by fleas first known from Bronze Age remains near Samara.\nThe symptoms of bubonic plague are first attested in a fragment of Rufus of Ephesus preserved by Oribasius; these ancient medical authorities suggest bubonic plague had appeared in the Roman Empire before the reign of Trajan, six centuries before arriving at Pelusium in the reign of Justinian I. In 2013, researchers confirmed earlier speculation that the cause of the Plague of Justinian (541\u2013549 CE, with recurrences until 750) was \"Y\". \"pestis\". This is known as the first plague pandemic. In 610, the Chinese physician Chao Yuanfang described a \"malignant bubo\" \"coming in abruptly with high fever together with the appearance of a bundle of nodes beneath the tissue.\" The Chinese physician Sun Simo who died in 652 also mentioned a \"malignant bubo\" and plague that was common in Lingnan (Guangzhou). Ole J\u00f8rgen Benedictow believes that this indicates it was an offshoot of the first plague pandemic which made its way eastward to Chinese territory by around 600.\n14th-century plague.\nCauses.\nEarly theory.\nA report by the Medical Faculty of Paris stated that a conjunction of planets had caused \"a great pestilence in the air\" (miasma theory). Muslim religious scholars taught that the pandemic was a \"martyrdom and mercy\" from God, assuring the believer's place in paradise. For non-believers, it was a punishment. Some Muslim doctors cautioned against trying to prevent or treat a disease sent by God. Others adopted preventive measures and treatments for plague used by Europeans. These Muslim doctors also depended on the writings of the ancient Greeks.\nPredominant modern theory.\nDue to climate change in Asia, rodents began to flee the dried-out grasslands to more populated areas, spreading the disease. The plague disease, caused by the bacterium \"Yersinia pestis\", is enzootic (commonly present) in populations of fleas carried by ground rodents, including marmots, in various areas, including Central Asia, Kurdistan, West Asia, North India, Uganda, and the western United States.\n\"Y. pestis\" was discovered by Alexandre Yersin, a pupil of Louis Pasteur, during an epidemic of bubonic plague in Hong Kong in 1894; Yersin also proved this bacterium was present in rodents and suggested the rat was the main vehicle of transmission. The mechanism by which \"Y. pestis\" is usually transmitted was established in 1898 by Paul-Louis Simond and was found to involve the bites of fleas whose midguts had become obstructed by replicating \"Y. pestis\" several days after feeding on an infected host. This blockage starves the fleas, drives them to aggressive feeding behaviour, and causes them to try to clear the blockage via regurgitation, resulting in thousands of plague bacteria flushing into the feeding site and infecting the host. The bubonic plague mechanism was also dependent on two populations of rodents: one resistant to the disease, which act as hosts, keeping the disease endemic, and a second that lacks resistance. When the second population dies, the fleas move on to other hosts, including people, thus creating a human epidemic.\nDNA evidence.\nDefinitive confirmation of the role of \"Y. pestis\" arrived in 2010 with a publication in \"PLOS Pathogens\" by Haensch et al. They assessed the presence of DNA/RNA with polymerase chain reaction (PCR) techniques for \"Y. pestis\" from the tooth sockets in human skeletons from mass graves in northern, central and southern Europe that were associated archaeologically with the Black Death and subsequent resurgences. The authors concluded that this new research, together with prior analyses from the south of France and Germany, \"ends the debate about the cause of the Black Death, and unambiguously demonstrates that \"Y. pestis\" was the causative agent of the epidemic plague that devastated Europe during the Middle Ages\". In 2011 these results were further confirmed with genetic evidence derived from Black Death victims in the East Smithfield burial site in England. Schuenemann et al. concluded in 2011 \"that the Black Death in medieval Europe was caused by a variant of \"Y. pestis\" that may no longer exist\".\nLater in 2011, Bos et al. reported in \"Nature\" the first draft genome of \"Y. pestis\" from plague victims from the same East Smithfield cemetery and indicated that the strain that caused the Black Death is ancestral to most modern strains of \"Y. pestis\".\nLater genomic papers have further confirmed the phylogenetic placement of the \"Y. pestis\" strain responsible for the Black Death as both the ancestor of later plague epidemics\u2014including the third plague pandemic\u2014and the descendant of the strain responsible for the Plague of Justinian. In addition, plague genomes from prehistory have been recovered.\nDNA taken from 25 skeletons from 14th-century London showed that plague is a strain of \"Y. pestis\" almost identical to that which hit Madagascar in 2013. Further DNA evidence also proves the role of \"Y. pestis\" and traces the source to the Tian Shan mountains in Kyrgyzstan.\nAlternative explanations.\nResearchers are hampered by a lack of reliable statistics from this period. Most work has been done on the spread of the disease in England, where estimates of overall population at the start of the plague vary by over 100%, as no census was undertaken in England between the time of publication of the Domesday Book of 1086 and the poll tax of the year 1377. Estimates of plague victims are usually extrapolated from figures for the clergy.\nMathematical modelling is used to match the spreading patterns and the means of transmission. In 2018 researchers suggested an alternative model in which \"\"the disease was spread from human fleas and body lice to other people\".\" The second model claims to better fit the trends of the plague's death toll, as the rat-flea-human hypothesis would have produced a delayed but very high spike in deaths, contradicting historical death data. The Oriental rat flea has poor survival in cooler climates and reevaluation suggests the human flea was the principal vector of plague epidemics in Northern Europe.\nLars Wall\u00f8e argued that these authors \"take it for granted that Simond's infection model, black rat \u2192 rat flea \u2192 human, which was developed to explain the spread of plague in India, is the only way an epidemic of \"Yersinia pestis\" infection could spread\". Similarly, Monica Green has argued that greater attention is needed to the range of (especially non-commensal) animals that might be involved in the transmission of plague.\nArchaeologist Barney Sloane has argued that there is insufficient evidence of the extinction of numerous rats in the archaeological record of the medieval waterfront in London, and that the disease spread too quickly to support the thesis that \"Y. pestis\" was spread from fleas on rats; he argues that transmission must have been person to person. This theory is supported by research in 2018 which suggested transmission was more likely by body lice and fleas during the second plague pandemic.\nSummary.\nAcademic debate continues, but no single alternative explanation for the plague's spread has achieved widespread acceptance. Many scholars arguing for \"Y. pestis\" as the major agent of the pandemic suggest that its extent and symptoms can be explained by a combination of bubonic plague with other diseases, including typhus, smallpox, and respiratory infections. In addition to the bubonic infection, others point to additional septicemic and pneumonic forms of plague, which lengthen the duration of outbreaks throughout the seasons and help account for its high mortality rate and additional recorded symptoms. In 2014, Public Health England announced the results of an examination of 25 bodies exhumed in the Clerkenwell area of London, as well as of wills registered in London during the period, which supported the pneumonic hypothesis. Currently, while osteoarcheologists have conclusively verified the presence of \"Y. pestis\" bacteria in burial sites across northern Europe through examination of bones and dental pulp, no other epidemic pathogen has been discovered to bolster the alternative explanations.\nTransmission.\nLack of hygiene.\nThe importance of hygiene was not recognized until the 19th century and the germ theory of disease. Until then streets were usually unhygienic, with live animals and human parasites facilitating the spread of transmissible disease.\nBy the early 14th century, so much filth had collected inside urban Europe that French and Italian cities were naming streets after human waste. In medieval Paris, several street names were inspired by merde, the French word for \"shit\". There were rue Merdeux, rue Merdelet, rue Merdusson, rue des Merdons and rue Merdiere\u2014as well as a rue du Pipi. Pigs, cattle, chickens, geese, goats and horses roamed the streets of medieval London and Paris.\nMedieval homeowners were supposed to police their housefronts, including removing animal dung, but most urbanites were careless. William E. Cosner, a resident of the London suburb of Farringdon Without, received a complaint alleging that \"men could not pass [by his house] for the stink [of] . . . horse dung and horse piss.\" One irate Londoner complained that the runoff from the local slaughterhouse had made his garden \"stinking and putrid\", while another charged that the blood from slain animals flooded nearby streets and lanes, \"making a foul corruption and abominable sight to all dwelling near.\" In much of medieval Europe, sanitation legislation consisted of an ordinance requiring homeowners to shout, \"Look out below!\" three times before dumping a full chamber pot into the street.\nEarly Christians considered bathing a temptation. With this danger in mind, St. Benedict declared, \"To those who are well, and especially to the young, bathing shall seldom be permitted.\" St. Agnes took the injunction to heart and died without ever bathing.\nTerritorial origins.\nAccording to a team of medical geneticists led by Mark Achtman, \"Yersinia pestis\" \"evolved in or near China\" over 2,600 years ago. Later research by a team led by Galina Eroshenko placed its origins more specifically in the Tian Shan mountains on the border between Kyrgyzstan and China. However more recent research notes that the previous sampling contained East Asian bias and that sampling since then has discovered strains of \"Y. pestis\" in the Caucasus region previously thought to be restricted to China. There is also no physical or specific textual evidence of the Black Death in 14th century China. As a result, China's place in the sequence of the plague's spread is still debated to this day. According to Charles Creighton, records of epidemics in 14th-century China suggest nothing more than typhus and major Chinese outbreaks of epidemic disease post-date the European epidemic by several years. The earliest Chinese descriptions of the bubonic plague do not appear until the 1640s.\nNestorian gravesites dating from 1338 to 1339 near Issyk-Kul have inscriptions referring to plague, which has led some historians and epidemiologists to think they mark the outbreak of the epidemic; this is supported by recent direct findings of \"Y. pestis\" DNA in teeth samples from graves in the area with inscriptions referring to \"pestilence\" as the cause of death. Epidemics killed an estimated 25\u00a0million across Asia during the fifteen\u00a0years before the Black Death reached Constantinople in 1347.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The evidence does not suggest, at least at present, that these mortality crises were caused by plague. Although some scholars, including McNeill and Cao, see the 1333 outbreak as a prelude to the outbreaks in Europe from the late 1340s to the early 1350s, scholars of the Yuan and Ming periods remain skeptical about such an interpretation. Nonetheless, the remarkably high mortality rates during the Datong mortality should discourage us from rejecting the possibility of localized/regional outbreaks of plague in different parts of China, albeit differing in scale from, and unrelated to, the pandemic mortality of the Black Death. What we lack is any indication of a plague pandemic that engulfed vast territories of the Yuan Empire and later moved into western Eurasia through Central Asia.\u2014\u200a\nAccording to John Norris, evidence from Issyk-Kul indicates a small sporadic outbreak characteristic of transmission from rodents to humans with no wide-scale impact. According to Achtman, the dating of the plague suggests that it was not carried along the Silk Road, and its widespread appearance in that region probably postdates the European outbreak. Additionally, the Silk Road had already been heavily disrupted before the spread of the Black Death; Western and Middle Eastern traders found it difficult to trade on the Silk Road by 1325 and impossible by 1340, making its role in the spread of plague less likely. There are no records of the symptoms of the Black Death from Mongol sources or writings from travelers east of the Black Sea prior to the Crimean outbreak in 1346.\nOthers still favor an origin in China. The theory of Chinese origin implicates the Silk Road, the disease possibly spreading alongside Mongol armies and traders, or possibly arriving via ship\u2014however, this theory is still contested. It is speculated that rats aboard Zheng He's ships in the 15th century may have carried the plague to Southeast Asia, India, and Africa.\nResearch on the Delhi Sultanate and the Yuan dynasty shows no evidence of any serious epidemic in fourteenth-century India and no specific evidence of plague in 14th-century China, suggesting that the Black Death may not have reached these regions. Ole Benedictow argues that since the first clear reports of the Black Death come from Kaffa, the Black Death most likely originated in the nearby plague focus on the northwestern shore of the Caspian Sea.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Demographic historians estimate that China's population fell by at least 15 per cent, and perhaps as much as a third, between 1340 and 1370. This population loss coincided with the Black Death that ravaged Europe and much of the Islamic world in 1347\u201352. However, there is a conspicuous lack of evidence for pandemic disease on the scale of the Black Death in China at this time. War and famine \u2013 and the diseases that typically accompanied them \u2013 probably were the main causes of mortality in the final decades of Mongol rule.\u2014\u200a\nMonica Green suggests that other parts of Eurasia outside the west do not contain the same evidence of the Black Death, because there were actually four strains of \"Yersinia pestis\" that became predominant in different parts of the world. Mongol records of illness such as food poisoning may have been referring to the Black Death. Another theory is that the plague originated near Europe and cycled through the Mediterranean, Northern Europe and Russia before making its way to China. Other historians, such as John Norris and Ole Benedictaw, believe the plague likely originated in Europe or the Middle East, and never reached China. Norris specifically argues for an origin in Kurdistan rather than Central Asia.\nEuropean outbreak.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\n The seventh year after it began, it came to England and first began in the towns and ports joining on the seacoasts, in Dorsetshire, where, as in other counties, it made the country quite void of inhabitants so that there were almost none left alive.\n... But at length it came to Gloucester, yea even to Oxford and to London, and finally it spread over all England and so wasted the people that scarce the tenth person of any sort was left alive.\n Geoffrey the Baker, \"Chronicon Angliae\"\nPlague was reportedly first introduced to Europe via Genoese traders from their port city of Kaffa in the Crimea in 1347. During a protracted siege of the city in 1345\u20131346, the Mongol Golden Horde army of Jani Beg\u2014whose mainly Tatar troops were suffering from the disease\u2014catapulted infected corpses over the city walls of Kaffa to infect the inhabitants, though it is also likely that infected rats travelled across the siege lines to spread the epidemic to the inhabitants. As the disease took hold, Genoese traders fled across the Black Sea to Constantinople, where the disease first arrived in Europe in summer 1347.\nThe epidemic there killed the 13-year-old son of the Byzantine emperor, John VI Kantakouzenos, who wrote a description of the disease modelled on Thucydides's account of the 5th century BCE Plague of Athens, noting the spread of the Black Death by ship between maritime cities. Nicephorus Gregoras, while writing to Demetrios Kydones, described the rising death toll, the futility of medicine, and the panic of the citizens. The first outbreak in Constantinople lasted a year, but the disease recurred ten times before 1400.\nCarried by twelve Genoese galleys, plague arrived by ship in Sicily in October 1347; the disease spread rapidly all over the island. Galleys from Kaffa reached Genoa and Venice in January 1348, but it was the outbreak in Pisa a few weeks later that was the entry point into northern Italy. Towards the end of January, one of the galleys expelled from Italy arrived in Marseilles.\nFrom Italy, the disease spread northwest across Europe, striking France, Spain, Portugal, and England by June 1348, then spreading east and north through Germany, Scotland and Scandinavia from 1348 to 1350. It was introduced into Norway in 1349 when a ship landed at Ask\u00f8y, then spread to Bj\u00f8rgvin (modern Bergen). Finally, it spread to northern Russia in 1352 and reached Moscow in 1353. Plague was less common in parts of Europe with less-established trade relations, including the majority of the Basque Country, isolated parts of Belgium and the Netherlands, and isolated Alpine villages throughout the continent.\nAccording to some epidemiologists, periods of unfavorable weather decimated plague-infected rodent populations, forcing their fleas onto alternative hosts, inducing plague outbreaks which often peaked in the hot summers of the Mediterranean and during the cool autumn months of the southern Baltic region. Among many other culprits of plague contagiousness, pre-existing malnutrition weakened the immune response, contributing to an immense decline in European population.\nWest Asian and North African outbreak.\nThe disease struck various regions in the Middle East and North Africa during the pandemic, leading to serious depopulation and permanent change in both economic and social structures. \nBy autumn 1347, plague had reached Alexandria in Egypt, transmitted by sea from Constantinople via a single merchant ship carrying slaves. By late summer 1348, it reached Cairo, capital of the Mamluk Sultanate, cultural center of the Islamic world, and the largest city in the Mediterranean Basin; the Bahriyya child sultan an-Nasir Hasan fled and more than a third of the 600,000 residents died. The Nile was choked with corpses despite Cairo having a medieval hospital, the late 13th-century bimaristan of the Qalawun complex. The historian al-Maqrizi described the abundant work for grave-diggers and practitioners of funeral rites; plague recurred in Cairo more than fifty times over the following one and a half centuries.\nDuring 1347, the disease travelled eastward to Gaza by April; by July it had reached Damascus, and in October plague had broken out in Aleppo. That year, in the territory of modern Lebanon, Syria, Israel, and Palestine, the cities of Ascalon, Acre, Jerusalem, Sidon, and Homs were all infected. In 1348\u20131349, the disease reached Antioch. The city's residents fled to the north, but most of them ended up dying during the journey. Within two years, the plague had spread throughout the Islamic world, from Arabia across North Africa.\nThe pandemic spread westwards from Alexandria along the African coast, while in April 1348 Tunis was infected by ship from Sicily. Tunis was then under attack by an army from Morocco; this army dispersed in 1348 and brought the contagion with them to Morocco, whose epidemic may also have been seeded from the Islamic city of Almer\u00eda in al-Andalus.\nMecca became infected in 1348 by pilgrims performing the Hajj. In 1351 or 1352, the Rasulid sultan of the Yemen, al-Mujahid Ali, was released from Mamluk captivity in Egypt and carried plague with him on his return home. During 1349, records show the city of Mosul suffered a massive epidemic, and the city of Baghdad experienced a second round of the disease.\nSigns and symptoms.\nBubonic plague.\nSymptoms of the plague include fever of , headaches, painful aching joints, nausea and vomiting, and a general feeling of malaise. Left untreated, 80% of victims die within eight days.\nContemporary accounts of the pandemic are varied and often imprecise. The most commonly noted symptom was the appearance of buboes (or \"gavocciolos\") in the groin, neck and armpits, which oozed pus and bled when opened. Boccaccio's description:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;In men and women alike it first betrayed itself by the emergence of certain tumours in the groin or armpits, some of which grew as large as a common apple, others as an egg\u00a0... From the two said parts of the body this deadly \"gavocciolo\" soon began to propagate and spread itself in all directions indifferently; after which the form of the malady began to change, black spots or livid making their appearance in many cases on the arm or the thigh or elsewhere, now few and large, now minute and numerous. As the \"gavocciolo\" had been and still was an infallible token of approaching death, such also were these spots on whomsoever they showed themselves.\nThis was followed by acute fever and vomiting of blood. Most people died two to seven days after initial infection. Freckle-like spots and rashes, which may have been caused by flea-bites, were identified as another potential sign of plague.\nPneumonic plague.\nLodewijk Heyligen, whose master Cardinal Giovanni Colonna died of plague in 1348, noted a distinct form of the disease, pneumonic plague, that infected the lungs and led to respiratory problems. Symptoms include fever, cough and blood-tinged sputum. As the disease progresses, sputum becomes free-flowing and bright red. Pneumonic plague has a mortality rate of 90\u201395%.\nSepticemic plague.\nSepticemic plague is the least common of the three forms, with an untreated mortality rate near 100%. Symptoms are high fevers and purple skin patches (purpura due to disseminated intravascular coagulation). In cases of pneumonic and particularly septicemic plague, the progress of the disease is so rapid that there would often be no time for the development of the enlarged lymph nodes that were noted as buboes.\nConsequences.\nDeaths.\nThere are no exact figures for the death toll; the rate varied widely by locality. Urban centers with higher populations suffered longer periods of abnormal mortality. Some estimate that it may have killed between 75,000,000 and 200,000,000 people in Eurasia.&lt;ref name=\"ABC/Reuters\"&gt;&lt;/ref&gt; A study published in 2022 of pollen samples across Europe from 1250 to 1450 was used to estimate changes in agricultural output before and after the Black Death. The authors found great variability in different regions, with evidence for high mortality in areas of Scandinavia, France, western Germany, Greece, and central Italy, but uninterrupted agricultural growth in central and eastern Europe, Iberia, and Ireland. The authors concluded that \"the pandemic was immensely destructive in some areas, but in others it had a far lighter touch ... [the study methodology] invalidates histories of the Black Death that assume Y. pestis was uniformly prevalent, or nearly so, across Europe and that the pandemic had a devastating demographic impact everywhere.\"\nThe Black Death killed, by various estimations, from 25 to 60% of Europe's population. Robert Gottfried writes that as early as 1351, \"agents for Pope Clement VI calculated the number of dead in Christian Europe at 23,840,000. With a preplague population of about 75 million, Clement's figure accounts for mortality of 31%-a rate about midway between the 50% mortality estimated for East Anglia, Tuscany, and parts of Scandinavia, and the less-than-15% morbidity for Bohemia and Galicia. And it is unerringly close to Froissart's claim that \"a third of the world died,\" a measurement probably drawn from St. John's figure of mortality from plague in the Book of Revelation, a favorite medieval source of information.\" Ole J. Benedictow proposes 60% mortality rate for Europe as a whole based on available data, with up to 80% based on poor nutritional conditions in the 14th century. According to medieval historian Philip Daileader, it is likely that over four years, 45\u201350% of the European population died of plague.\nThe overwhelming number of deaths in Europe sometimes made mass burials necessary, and some sites had hundreds or thousands of bodies. The mass burial sites that have been excavated have allowed archaeologists to continue interpreting and defining the biological, sociological, historical, and anthropological implications of the Black Death. The mortality rate of the Black Death in the 14th century was far greater than the worst 20th-century outbreaks of \"Y. pestis\" plague, which occurred in India and killed as much as 3% of the population of certain cities.\nIn 1348, the disease spread so rapidly that nearly a third of the European population perished before any physicians or government authorities had time to reflect upon its origins. In crowded cities, it was not uncommon for as much as 50% of the population to die. Half of Paris' population of 100,000 people died. In Italy, the population of Florence was reduced from between 110,000 and 120,000 inhabitants in 1338 to 50,000 in 1351. At least 60% of the population of Hamburg and Bremen perished, and a similar percentage of Londoners may have died from the disease as well, leaving a death toll of approximately 62,000 between 1346 and 1353. Florence's tax records suggest that 80% of the city's population died within four months in 1348. Before 1350, there were about 170,000 settlements in Germany, and this was reduced by nearly 40,000 by 1450. The disease bypassed some areas, with the most isolated areas being less vulnerable to contagion. Plague did not appear in Flanders until the turn of the 15th century, and the impact was less severe on the populations of Hainaut, Finland, northern Germany, and areas of Poland. Monks, nuns, and priests were especially hard-hit since they cared for people ill with the plague. The level of mortality in the rest of Eastern Europe was likely similar to that of Western Europe in the first outbreak, with descriptions suggesting a similar effect on Russian towns, and the cycles of plague in Russia being roughly equivalent.\nIn 1382, the physician to the Avignon Papacy, Raimundo Chalmel de Vinario (), observed the decreasing mortality rate of successive outbreaks of plague in 1347\u20131348, 1362, 1371 and 1382 in his treatise \"On Epidemics\" (). In the first outbreak, two thirds of the population contracted the illness and most patients died; in the next, half the population became ill but only some died; by the third, a tenth were affected and many survived; while by the fourth occurrence, only one in twenty people were sickened and most of them survived. By the 1380s in Europe, the plague predominantly affected children. Chalmel de Vinario recognised that bloodletting was ineffective (though he continued to prescribe bleeding for members of the Roman Curia, whom he disliked), and said that all true cases of plague were caused by astrological factors and were incurable; he was never able to effect a cure.\nThe populations of some Italian cities, notably Florence, did not regain their pre-14th century size until the 19th century. Italian chronicler Agnolo di Tura recorded his experience from Siena, where plague arrived in May 1348:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Father abandoned child, wife husband, one brother another; for this illness seemed to strike through the breath and sight. And so they died. And none could be found to bury the dead for money or friendship. Members of a household brought their dead to a ditch as best they could, without priest, without divine offices ... great pits were dug and piled deep with the multitude of dead. And they died by the hundreds both day and night ... And as soon as those ditches were filled more were dug ... And I, Agnolo di Tura ... buried my five children with my own hands. And there were also those who were so sparsely covered with earth that the dogs dragged them forth and devoured many bodies throughout the city. There was no one who wept for any death, for all awaited death. And so many died that all believed it was the end of the world.\nThe most widely accepted estimate for the Middle East, including Iraq, Iran, and Syria, during this time, is for a death toll of about a third of the population. The Black Death killed about 40% of Egypt's population. In Cairo, with a population numbering as many as 600,000, and possibly the largest city west of China, between one third and 40% of the inhabitants died within eight months. By the 18th century, the population of Cairo was halved from its numbers in 1347.\nEconomic.\nIt has been suggested that the Black Death, like other outbreaks through history, disproportionately affected the poorest people and those already in worse physical condition than the wealthier citizens. \nBut along with population decline from the pandemic, wages soared in response to a subsequent labour shortage. In some places rents collapsed (e.g., lettings \"used to bring in \u00a35, and now but \u00a31.\") \nHowever, many labourers, artisans, and craftsmen\u2014those living from money-wages alone\u2014suffered a reduction in real incomes owing to rampant inflation. Landowners were also pushed to substitute monetary rents for labour services in an effort to keep tenants. Taxes and tithes became difficult to collect, with living poor refusing to cover the share of the rich deceased, because many properties were empty and unfarmed, and because tax-collectors, where they could be employed, refused to go to plague spots. \nThe trade disruptions in the Mongol Empire caused by the Black Death was one of the reasons for its collapse.\nEnvironmental.\nA study performed by Thomas Van Hoof of the Utrecht University suggests that the innumerable deaths brought on by the pandemic cooled the climate by freeing up land and triggering reforestation. This may have led to the Little Ice Age.\nPersecutions.\nRenewed religious fervor and fanaticism increased in the wake of the Black Death. Some Europeans targeted \"various groups such as Jews, friars, foreigners, beggars, pilgrims\", lepers, and Romani, blaming them for the crisis. Lepers, and others with skin diseases such as acne or psoriasis, were killed throughout Europe.\nBecause 14th-century healers and governments were at a loss to explain or stop the disease, Europeans turned to astrological forces, earthquakes and the poisoning of wells by Jews as possible reasons for outbreaks. Many believed the epidemic was a punishment by God for their sins, and could be relieved by winning God's forgiveness.\nThere were many attacks against Jewish communities. In the Strasbourg massacre of February 1349, about 2,000 Jews were murdered. In August 1349, the Jewish communities in Mainz and Cologne were annihilated. By 1351, 60 major and 150 smaller Jewish communities had been destroyed. During this period many Jews relocated to Poland, where they received a welcome from King Casimir the Great.\nSocial.\nOne theory that has been advanced is that the Black Death's devastation of Florence, between 1348 and 1350, resulted in a shift in the world view of people in 14th-century Italy that ultimately led to the Renaissance. Italy was particularly badly hit by the pandemic, and the resulting familiarity with death may have caused thinkers to dwell more on their lives on Earth, rather than on spirituality and the afterlife. It has also been argued that the Black Death prompted a new wave of piety, manifested in the sponsorship of religious works of art.\nThis does not fully explain why the Renaissance occurred in Italy in the 14th century; the Renaissance's emergence was most likely the result of the complex interaction of the above factors, in combination with an influx of Greek scholars after the fall of the Byzantine Empire. As a result of the drastic reduction in the populace the value of the working class increased, and commoners came to enjoy more freedom. To answer the increased need for labour, workers travelled in search of the most favorable position economically.\nPrior to the emergence of the Black Death, the continent was considered a feudalistic society, composed of fiefs and city-states frequently managed by the Catholic Church. The pandemic completely restructured both religion and political forces; survivors began to turn to other forms of spirituality and the power dynamics of the fiefs and city-states crumbled. The survivors of the pandemic found not only that the prices of food were lower but also that lands were more abundant, and many of them inherited property from their dead relatives, and this probably contributed to the destabilization of feudalism.\nThe word \"quarantine\" has its roots in this period, though the practice of isolating people to prevent the spread of disease is older. In the city-state of Ragusa (modern Dubrovnik, Croatia), a thirty-day isolation period was implemented in 1377 for new arrivals to the city from plague-affected areas. The isolation period was later extended to forty days, and given the name \"quarantino\" from the Italian word for \"forty\".\nAll institutions were affected. Smaller monasteries and convents became unviable and closed. Up to half parish churches lost their priest, apart from the parishioners. Religious sensibilities changed:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\"[...]looking back into the past, the history of the Church during the Middle Ages in England appears one continuous and stately progress. It is much nearer to the truth to say that in 1351 the whole ecclesiastical system was wholly disorganised, or, indeed, more than half ruined, and that everything had to be built up anew.[...] To secure the most necessary public ministrations of the rites of religion the most inadequately-prepared subjects had to be accepted, and even these could be obtained only in insufficient numbers.[...]The immediate effect on the people was a religious paralysis. Instead of turning men to God the scourge turned them to despair[...] In time the religious sense and feeling revived, but in many respects it took a new tone, and its manifestations ran in new channels[...]characterised by a devotional and more self-reflective cast than previously.[...]The new religious spirit found outward expression in the multitude of guilds which sprang into existence at this time, in the remarkable and almost, as it may seem to some, extravagant development of certain pious practices, in the singular spread of a more personal devotion to the Blessed Sacrament, to the Blessed Virgin, to the Five Wounds, to the Holy Name, and other such manifestations of a more tender or more familiar piety.[...]At the close of the fourteenth century and during the course of the fifteenth the supply of ornaments, furniture, plate, statues painted or in highly decked \"coats,\" with which the churches were literally encumbered as time went on, proved a striking contrast to the comparative simplicity which characterised former days, as witnessed by a comparison of inventories.[...]In fact, the fifteenth century witnessed the beginnings of a great middle-class movement, which can be distinctly traced to the effect of the great pestilence[...]\u2014\u200a\nRecurrences.\nSecond plague pandemic.\nThe plague repeatedly returned to haunt Europe and the Mediterranean throughout the 14th to 17th centuries. According to Jean-No\u00ebl Biraben, the plague was present somewhere in Europe in every year between 1346 and 1671 (although some researchers have cautions about the uncritical use of Biraben's data). The second pandemic was particularly widespread in the following years: 1360\u20131363; 1374; 1400; 1438\u20131439; 1456\u20131457; 1464\u20131466; 1481\u20131485; 1500\u20131503; 1518\u20131531; 1544\u20131548; 1563\u20131566; 1573\u20131588; 1596\u20131599; 1602\u20131611; 1623\u20131640; 1644\u20131654; and 1664\u20131667. Subsequent outbreaks, though severe, marked the plague's retreat from most of Europe (18th\u00a0century) and North Africa (19th\u00a0century).\nHistorian George Sussman argued that the plague had not occurred in East Africa until the 20th century. However, other sources suggest that the second pandemic did indeed reach sub-Saharan Africa.\nAccording to historian Geoffrey Parker, \"France alone, it is estimated that at least two million people died from the disease between 1600 and 1670, no fewer than 750,000 of them (almost five percent of the kingdom's population) during the severe epidemic of 1628-1632.\" In the first half of the 17th century, a plague killed some 1.7 million people in Italy. More than 1.25 million deaths resulted from the extreme incidence of plague in 17th-century Spain.\nThe Black Death ravaged much of the Islamic world. Plague could be found in the Islamic world almost every year between 1500 and 1850. Sometimes the outbreaks affected small areas, while other outbreaks affected multiple regions. Plague repeatedly struck the cities of North Africa. Algiers lost 30,000\u201350,000 inhabitants to it in 1620\u20131621, and again in 1654\u20131657, 1665, 1691, and 1740\u20131742. Cairo suffered more than fifty plague epidemics within 150 years from the plague's first appearance, with the final outbreak of the second pandemic there in the 1840s. Plague remained a major event in Ottoman society until the second quarter of the 19th century. Between 1701 and 1750, thirty-seven larger and smaller epidemics were recorded in Constantinople, and an additional thirty-one between 1751 and 1800. Baghdad has suffered severely from visitations of the plague, and sometimes two-thirds of its population died.\nThird plague pandemic.\nThe third plague pandemic (1855\u20131960) started in China in the mid-19th century, spreading to all inhabited continents and killing 10 million people in India alone. The investigation of the pathogen that caused the 19th-century plague was begun by teams of scientists who visited Hong Kong in 1894, among whom was the French-Swiss bacteriologist Alexandre Yersin, for whom the pathogen was named.\nTwelve plague outbreaks in Australia between 1900 and 1925 resulted in over 1,000 deaths, chiefly in Sydney. This led to the establishment of a Public Health Department there which undertook some leading-edge research on plague transmission from rat fleas to humans via the bacillus \"Yersinia pestis\".\nThe first North American plague epidemic was the San Francisco plague of 1900\u20131904, followed by another outbreak in 1907\u20131908.\nModern-day.\nModern treatment methods include insecticides, the use of antibiotics, and a plague vaccine. It is feared that the plague bacterium could develop drug resistance and again become a major health threat. One case of a drug-resistant form of the bacterium was found in Madagascar in 1995. Another outbreak in Madagascar was reported in November 2014. In October 2017, the deadliest outbreak of the plague in modern times hit Madagascar, killing 170 people and infecting thousands.\nAn estimate of the case fatality rate for the modern plague, after the introduction of antibiotics, is 11%, although it may be higher in underdeveloped regions.\nFootnotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nBibliography.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "4502", "revid": "50865928", "url": "https://en.wikipedia.org/wiki?curid=4502", "title": "Biotechnology", "text": "Use of living systems and organisms to develop or make useful products\nBiotechnology is a multidisciplinary field that involves the integration of natural sciences and engineering sciences in order to achieve the application of organisms and parts thereof for products and services. Specialists in the field are known as biotechnologists.\nThe term \"biotechnology\" was first used by K\u00e1roly Ereky in 1919 to refer to the production of products from raw materials with the aid of living organisms. The core principle of biotechnology involves harnessing biological systems and organisms, such as bacteria, yeast, and plants, to perform specific tasks or produce valuable substances.\nBiotechnology has had a significant impact on many areas of society, from medicine to agriculture to environmental science. One of the key techniques used in biotechnology is genetic engineering, which allows scientists to modify the genetic makeup of organisms to achieve desired outcomes. This can involve inserting genes from one organism into another, and consequently, creating new traits or modifying existing ones.\nOther important techniques used in biotechnology include tissue culture, which allows researchers to grow cells and tissues in the lab for research and medical purposes, and fermentation, which is used to produce a wide range of products such as beer, wine, and cheese.\nThe applications of biotechnology are diverse and have led to the development of products like life-saving drugs, biofuels, genetically modified crops, and innovative materials. It has also been used to address environmental challenges, such as developing biodegradable plastics and using microorganisms to clean up contaminated sites.\nBiotechnology is a rapidly evolving field with significant potential to address pressing global challenges and improve the quality of life for people around the world; however, despite its numerous benefits, it also poses ethical and societal challenges, such as questions around genetic modification and intellectual property rights. As a result, there is ongoing debate and regulation surrounding the use and application of biotechnology in various industries and fields.\nBiotechnology encompasses a wide range of procedures for modifying living organisms for human purposes, going back to domestication of animals, the cultivation of plants, and \"improvements\" to these through breeding programs that employ artificial selection and hybridization. Modern usage also includes genetic engineering, as well as cell and tissue culture technologies. The American Chemical Society defines \"biotechnology\" as the application of biological organisms, systems, or processes by various industries to learning about the science of life and the improvement of the value of materials and organisms, such as pharmaceuticals, crops, and livestock. As per the European Federation of Biotechnology, biotechnology is the integration of natural science and organisms, cells, parts thereof, and molecular analogues for products and services. Biotechnology is based on the basic biological sciences (e.g., molecular biology, biochemistry, cell biology, embryology, genetics, microbiology) and conversely provides methods to support and perform basic research in biology.\nBiotechnology is the research and development in the laboratory using bioinformatics for exploration, extraction, exploitation, and production from any living organisms and any source of biomass by means of biochemical engineering where high value-added products could be planned (reproduced by biosynthesis, for example), forecasted, formulated, developed, manufactured, and marketed for the purpose of sustainable operations (for the return from bottomless initial investment on R &amp; D) and gaining durable patents rights (for exclusives rights for sales, and prior to this to receive national and international approval from the results on animal experiment and human experiment, especially on the pharmaceutical branch of biotechnology to prevent any undetected side-effects or safety concerns by using the products). The utilization of biological processes, organisms or systems to produce products that are anticipated to improve human lives is termed biotechnology.\nBy contrast, bioengineering is generally thought of as a related field that more heavily emphasizes higher systems approaches (not necessarily the altering or using of biological materials \"directly\") for interfacing with and utilizing living things. Bioengineering is the application of the principles of engineering and natural sciences to tissues, cells, and molecules. This can be considered as the use of knowledge from working with and manipulating biology to achieve a result that can improve functions in plants and animals. Relatedly, biomedical engineering is an overlapping field that often draws upon and applies \"biotechnology\" (by various definitions), especially in certain sub-fields of biomedical or chemical engineering such as tissue engineering, biopharmaceutical engineering, and genetic engineering.\nHistory.\nMany forms of human-derived agriculture fit the broad definition of \"utilizing a biotechnological system to make products\". The cultivation of plants may be viewed as the earliest biotechnological enterprise.\nAgriculture has been theorized to have become the dominant way of producing food since the Neolithic Revolution. Through early biotechnology, the earliest farmers selected and bred the best-suited crops (e.g., those with the highest yields) to produce enough food to support a growing population. As crops and fields became increasingly large and difficult to maintain, it was discovered that specific organisms and their by-products could effectively fertilize, restore nitrogen, and control pests. Throughout the history of agriculture, farmers have inadvertently altered the genetics of their crops through introducing them to new environments and breeding them with other plants \u2014 one of the first forms of biotechnology.\nThese processes were also included in the early fermentation of beer. These processes were introduced in early Mesopotamia, Egypt, China and India, and still use the same basic biological methods. In brewing, malted grains (containing enzymes) convert starch from grains into sugar and then adding specific yeasts to produce beer. In this process, carbohydrates in the grains broke down into alcohols, such as ethanol. Later, other cultures developed the process of lactic acid fermentation, which produced other preserved foods, such as soy sauce. Fermentation was also used in this time period to produce leavened bread. Although the process of fermentation was not fully understood until Louis Pasteur's work in 1857, it is still the first use of biotechnology to convert a food source into another form.\nBefore the time of Charles Darwin's work and life, animal and plant scientists had already used selective breeding. Darwin added to that body of work with his scientific observations about the ability of science to change species. These accounts contributed to Darwin's theory of natural selection.\nFor thousands of years, humans have used selective breeding to improve the production of crops and livestock to use them for food. In selective breeding, organisms with desirable characteristics are mated to produce offspring with the same characteristics. For example, this technique was used with corn to produce the largest and sweetest crops.\nIn the early twentieth century scientists gained a greater understanding of microbiology and explored ways of manufacturing specific products. In 1917, Chaim Weizmann first used a pure microbiological culture in an industrial process, that of manufacturing corn starch using \"Clostridium acetobutylicum,\" to produce acetone, which the United Kingdom desperately needed to manufacture explosives during World War I.\nBiotechnology has also led to the development of antibiotics. In 1928, Alexander Fleming discovered the mold \"Penicillium\". His work led to the purification of the antibiotic formed by the mold by Howard Florey, Ernst Boris Chain and Norman Heatley \u2013 to form what we today know as penicillin. In 1940, penicillin became available for medicinal use to treat bacterial infections in humans.\nThe field of modern biotechnology is generally thought of as having been born in 1971 when Paul Berg's (Stanford) experiments in gene splicing had early success. Herbert W. Boyer (Univ. Calif. at San Francisco) and Stanley N. Cohen (Stanford) significantly advanced the new technology in 1972 by transferring genetic material into a bacterium, such that the imported material would be reproduced. The commercial viability of a biotechnology industry was significantly expanded on June 16, 1980, when the United States Supreme Court ruled that a genetically modified microorganism could be patented in the case of \"Diamond v. Chakrabarty\". Indian-born Ananda Chakrabarty, working for General Electric, had modified a bacterium (of the genus \"Pseudomonas\") capable of breaking down crude oil, which he proposed to use in treating oil spills. (Chakrabarty's work did not involve gene manipulation but rather the transfer of entire organelles between strains of the \"Pseudomonas\" bacterium).\nThe MOSFET was invented at Bell Labs between 1955 and 1960, Two years later, Leland C. Clark and Champ Lyons invented the first biosensor in 1962. Biosensor MOSFETs were later developed, and they have since been widely used to measure physical, chemical, biological and environmental parameters. The first BioFET was the ion-sensitive field-effect transistor (ISFET), invented by Piet Bergveld in 1970. It is a special type of MOSFET, where the metal gate is replaced by an ion-sensitive membrane, electrolyte solution and reference electrode. The ISFET is widely used in biomedical applications, such as the detection of DNA hybridization, biomarker detection from blood, antibody detection, glucose measurement, pH sensing, and genetic technology.\nBy the mid-1980s, other BioFETs had been developed, including the gas sensor FET (GASFET), pressure sensor FET (PRESSFET), chemical field-effect transistor (ChemFET), reference ISFET (REFET), enzyme-modified FET (ENFET) and immunologically modified FET (IMFET). By the early 2000s, BioFETs such as the DNA field-effect transistor (DNAFET), gene-modified FET (GenFET) and cell-potential BioFET (CPFET) had been developed.\nA factor influencing the biotechnology sector's success is improved intellectual property rights legislation\u2014and enforcement\u2014worldwide, as well as strengthened demand for medical and pharmaceutical products.\nRising demand for biofuels is expected to be good news for the biotechnology sector, with the Department of Energy estimating ethanol usage could reduce U.S. petroleum-derived fuel consumption by up to 30% by 2030. The biotechnology sector has allowed the U.S. farming industry to rapidly increase its supply of corn and soybeans\u2014the main inputs into biofuels\u2014by developing genetically modified seeds that resist pests and drought. By increasing farm productivity, biotechnology boosts biofuel production.\nExamples.\nBiotechnology has applications in four major industrial areas, including health care (medical), crop production and agriculture, non-food (industrial) uses of crops and other products (e.g., biodegradable plastics, vegetable oil, biofuels), and environmental uses.\nFor example, one application of biotechnology is the directed use of microorganisms for the manufacture of organic products (examples include beer and milk products). Another example is using naturally present bacteria by the mining industry in bioleaching. Biotechnology is also used to recycle, treat waste, clean up sites contaminated by industrial activities (bioremediation), and also to produce biological weapons.\nA series of derived terms have been coined to identify several branches of biotechnology, for example:\nMedicine.\nIn medicine, modern biotechnology has many applications in areas such as pharmaceutical drug discoveries and production, pharmacogenomics, and genetic testing (or genetic screening). In 2021, nearly 40% of the total company value of pharmaceutical biotech companies worldwide were active in Oncology with Neurology and Rare Diseases being the other two big applications.\nPharmacogenomics (a combination of pharmacology and genomics) is the technology that analyses how genetic makeup affects an individual's response to drugs. Researchers in the field investigate the influence of genetic variation on drug responses in patients by correlating gene expression or single-nucleotide polymorphisms with a drug's efficacy or toxicity. The purpose of pharmacogenomics is to develop rational means to optimize drug therapy, with respect to the patients' genotype, to ensure maximum efficacy with minimal adverse effects. Such approaches promise the advent of \"personalized medicine\"; in which drugs and drug combinations are optimized for each individual's unique genetic makeup.\nBiotechnology has contributed to the discovery and manufacturing of traditional small molecule pharmaceutical drugs as well as drugs that are the product of biotechnology \u2013 biopharmaceutics. Modern biotechnology can be used to manufacture existing medicines relatively easily and cheaply. The first genetically engineered products were medicines designed to treat human diseases. To cite one example, in 1978 Genentech developed synthetic humanized insulin by joining its gene with a plasmid vector inserted into the bacterium \"Escherichia coli\". Insulin, widely used for the treatment of diabetes, was previously extracted from the pancreas of abattoir animals (cattle or pigs). The genetically engineered bacteria are able to produce large quantities of synthetic human insulin at relatively low cost. Biotechnology has also enabled emerging therapeutics like gene therapy. The application of biotechnology to basic science (for example through the Human Genome Project) has also dramatically improved our understanding of biology and as our scientific knowledge of normal and disease biology has increased, our ability to develop new medicines to treat previously untreatable diseases has increased as well.\nGenetic testing allows the genetic diagnosis of vulnerabilities to inherited diseases, and can also be used to determine a child's parentage (genetic mother and father) or in general a person's ancestry. In addition to studying chromosomes to the level of individual genes, genetic testing in a broader sense includes biochemical tests for the possible presence of genetic diseases, or mutant forms of genes associated with increased risk of developing genetic disorders. Genetic testing identifies changes in chromosomes, genes, or proteins. Most of the time, testing is used to find changes that are associated with inherited disorders. The results of a genetic test can confirm or rule out a suspected genetic condition or help determine a person's chance of developing or passing on a genetic disorder. As of 2011 several hundred genetic tests were in use. Since genetic testing may open up ethical or psychological problems, genetic testing is often accompanied by genetic counseling.\nAgriculture.\nGenetically modified crops (\"GM crops\", or \"biotech crops\") are plants used in agriculture, the DNA of which has been modified with genetic engineering techniques. In most cases, the main aim is to introduce a new trait that does not occur naturally in the species. Biotechnology firms can contribute to future food security by improving the nutrition and viability of urban agriculture. Furthermore, the protection of intellectual property rights encourages private sector investment in agrobiotechnology.\nExamples in food crops include resistance to certain pests, diseases, stressful environmental conditions, resistance to chemical treatments (e.g. resistance to a herbicide), reduction of spoilage, or improving the nutrient profile of the crop. Examples in non-food crops include production of pharmaceutical agents, biofuels, and other industrially useful goods, as well as for bioremediation.\nFarmers have widely adopted GM technology. Between 1996 and 2011, the total surface area of land cultivated with GM crops had increased by a factor of 94, from . 10% of the world's crop lands were planted with GM crops in 2010. As of 2011, 11 different transgenic crops were grown commercially on in 29 countries such as the US, Brazil, Argentina, India, Canada, China, Paraguay, Pakistan, South Africa, Uruguay, Bolivia, Australia, Philippines, Myanmar, Burkina Faso, Mexico, and Spain.\nGenetically modified foods are foods produced from organisms that have had specific changes introduced into their DNA with the methods of genetic engineering. These techniques have allowed for the introduction of new crop traits as well as a far greater control over a food's genetic structure than previously afforded by methods such as selective breeding and mutation breeding. Commercial sale of genetically modified foods began in 1994, when Calgene first marketed its Flavr Savr delayed ripening tomato. To date most genetic modification of foods have primarily focused on cash crops in high demand by farmers such as soybean, corn, canola, and cotton seed oil. These have been engineered for resistance to pathogens and herbicides and better nutrient profiles. GM livestock have also been experimentally developed; in November 2013 none were available on the market, but in 2015 the FDA approved the first GM salmon for commercial production and consumption.\nThere is a scientific consensus that currently available food derived from GM crops poses no greater risk to human health than conventional food, but that each GM food needs to be tested on a case-by-case basis before introduction. Nonetheless, members of the public are much less likely than scientists to perceive GM foods as safe. The legal and regulatory status of GM foods varies by country, with some nations banning or restricting them, and others permitting them with widely differing degrees of regulation.\nGM crops also provide a number of ecological benefits, if not used in excess. Insect-resistant crops have proven to lower pesticide usage, therefore reducing the environmental impact of pesticides as a whole. However, opponents have objected to GM crops per se on several grounds, including environmental concerns, whether food produced from GM crops is safe, whether GM crops are needed to address the world's food needs, and economic concerns raised by the fact these organisms are subject to intellectual property law.\nBiotechnology has several applications in the realm of food security. Crops like Golden rice are engineered to have higher nutritional content, and there is potential for food products with longer shelf lives. Though not a form of agricultural biotechnology, vaccines can help prevent diseases found in animal agriculture. Additionally, agricultural biotechnology can expedite breeding processes in order to yield faster results and provide greater quantities of food. Transgenic biofortification in cereals has been considered as a promising method to combat malnutrition in India and other countries.\nIndustrial.\nIndustrial biotechnology (known mainly in Europe as white biotechnology) is the application of biotechnology for industrial purposes, including industrial fermentation. It includes the practice of using cells such as microorganisms, or components of cells like enzymes, to generate industrially useful products in sectors such as chemicals, food and feed, detergents, paper and pulp, textiles and biofuels. In the current decades, significant progress has been done in creating genetically modified organisms (GMOs) that enhance the diversity of applications and economical viability of industrial biotechnology. By using renewable raw materials to produce a variety of chemicals and fuels, industrial biotechnology is actively advancing towards lowering greenhouse gas emissions and moving away from a petrochemical-based economy.\nSynthetic biology is considered one of the essential cornerstones in industrial biotechnology due to its financial and sustainable contribution to the manufacturing sector. Jointly biotechnology and synthetic biology play a crucial role in generating cost-effective products with nature-friendly features by using bio-based production instead of fossil-based. Synthetic biology can be used to engineer model microorganisms, such as \"Escherichia coli\", by genome editing tools to enhance their ability to produce bio-based products, such as bioproduction of medicines and biofuels. For instance, \"E. coli\" and \"Saccharomyces cerevisiae\" in a consortium could be used as industrial microbes to produce precursors of the chemotherapeutic agent paclitaxel by applying the metabolic engineering in a co-culture approach to exploit the benefits from the two microbes.\nAnother example of synthetic biology applications in industrial biotechnology is the re-engineering of the metabolic pathways of \"E. coli\" by CRISPR and CRISPRi systems toward the production of a chemical known as 1,4-butanediol, which is used in fiber manufacturing. In order to produce 1,4-butanediol, the authors alter the metabolic regulation of the \"Escherichia coli\" by CRISPR to induce point mutation in the \"glt\"A gene, knockout of the \"sad\" gene, and knock-in six genes (\"cat\"1, \"suc\"D, \"4hbd\", \"cat\"2, \"bld\", and \"bdh\"). Whereas CRISPRi system used to knockdown the three competing genes (\"gab\"D, \"ybg\"C, and \"tes\"B) that affect the biosynthesis pathway of 1,4-butanediol. Consequently, the yield of 1,4-butanediol significantly increased from 0.9 to 1.8 g/L.\nEnvironmental.\nEnvironmental biotechnology includes various disciplines that play an essential role in reducing environmental waste and providing environmentally safe processes, such as biofiltration and biodegradation. The environment can be affected by biotechnologies, both positively and adversely. Vallero and others have argued that the difference between beneficial biotechnology (e.g., bioremediation is to clean up an oil spill or hazard chemical leak) versus the adverse effects stemming from biotechnological enterprises (e.g., flow of genetic material from transgenic organisms into wild strains) can be seen as applications and implications, respectively. Cleaning up environmental wastes is an example of an application of environmental biotechnology; whereas loss of biodiversity or loss of containment of a harmful microbe are examples of environmental implications of biotechnology.\nMany cities have installed CityTrees, which use biotechnology to filter pollutants from urban atmospheres.\nRegulation.\nThe regulation of genetic engineering concerns approaches taken by governments to assess and manage the risks associated with the use of genetic engineering technology, and the development and release of genetically modified organisms (GMO), including genetically modified crops and genetically modified fish. There are differences in the regulation of GMOs between countries, with some of the most marked differences occurring between the US and Europe. Regulation varies in a given country depending on the intended use of the products of the genetic engineering. For example, a crop not intended for food use is generally not reviewed by authorities responsible for food safety. The European Union differentiates between approval for cultivation within the EU and approval for import and processing. While only a few GMOs have been approved for cultivation in the EU a number of GMOs have been approved for import and processing. The cultivation of GMOs has triggered a debate about the coexistence of GM and non-GM crops. Depending on the coexistence regulations, incentives for the cultivation of GM crops differ.\nDatabase for the GMOs used in the EU.\nThe EUginius (European GMO Initiative for a Unified Database System) database is intended to help companies, interested private users and competent authorities to find precise information on the presence, detection and identification of GMOs used in the European Union. The information is provided in English.\nLearning.\nIn 1988, after prompting from the United States Congress, the National Institute of General Medical Sciences (National Institutes of Health) (NIGMS) instituted a funding mechanism for biotechnology training. Universities nationwide compete for these funds to establish Biotechnology Training Programs (BTPs). Each successful application is generally funded for five years then must be competitively renewed. Graduate students in turn compete for acceptance into a BTP; if accepted, then stipend, tuition and health insurance support are provided for two or three years during the course of their PhD thesis work. Nineteen institutions offer NIGMS supported BTPs. Biotechnology training is also offered at the undergraduate level and in community colleges.\nReferences and notes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "4503", "revid": "40781349", "url": "https://en.wikipedia.org/wiki?curid=4503", "title": "Battle of Poitiers", "text": "1356 battle of the Hundred Years' War\nThe Battle of Poitiers was fought on 19September 1356 between a French army commanded by King John\u00a0II and an Anglo-Gascon force under Edward, the Black Prince, during the Hundred Years' War. It took place in western France, south of Poitiers, when approximately 14,000 to 16,000 French attacked a strong defensive position held by 6,000 Anglo-Gascons.\nNineteen years after the start of the war, the Black Prince, eldest son and heir of the English King, set out on a major campaign in south-west France. His army marched from Bergerac to the River Loire, which they were unable to cross. John gathered a large and unusually mobile army and pursued Edward's forces. The Anglo-Gascons had by this point established a strong defensive position near Poitiers, and after unsuccessful negotiations between the two sides, were attacked by the French.\nThe first assault included two units of heavily armoured cavalry, a strong force of crossbowmen as well as many infantry and dismounted men-at-arms. They were driven back by the Anglo-Gascons, who were fighting entirely on foot. A second French attack by 4,000 men-at-arms on foot under John's son and heir Charles, the dauphin, followed. After a prolonged fight this was also repulsed. As the Dauphin's division recoiled there was confusion in the French ranks: about half the men of their third division, under Philip, Duke of Orl\u00e9ans, left the field, taking with them all four of John's sons. Some of those who did not withdraw with Philip launched a weak and unsuccessful third assault. Those Frenchmen remaining gathered around the King and launched a fourth assault against the by now exhausted Anglo-Gascons, again all as infantry. The French sacred banner, the , was unfurled, the signal that no prisoners were to be taken. Battle was again joined, with the French slowly getting the better of it. Then a small, mounted, Anglo-Gascon force of 160 men, who had been sent earlier to threaten the French rear, appeared behind the French. Believing themselves surrounded, some Frenchmen fled, which panicked others, and soon the entire French force collapsed.\nJohn was captured, as were his son Philip and between 2,000 and 3,000 men-at-arms. Approximately 2,500 French men-at-arms were killed. Additionally, either 1,500 or 3,800 French common infantry were killed or captured. The surviving French dispersed, while the Anglo-Gascons continued their withdrawal to Gascony. The following spring a two-year truce was agreed and the Black Prince escorted John to London. Populist revolts broke out across France. Negotiations to end the war and ransom John dragged out. In response Edward launched a further campaign in 1359. During this, both sides compromised and the Treaty of Br\u00e9tigny was agreed in 1360 by which vast areas of France were ceded to England, to be ruled by the Black Prince, and John was ransomed for three million gold \u00e9cu. At the time this seemed to end the war, but the French resumed hostilities in 1369 and recaptured most of the lost territory. The war eventually ended with a French victory in 1453.\n&lt;templatestyles src=\"Template:TOC limit/styles.css\" /&gt;\nBackground.\nSince the Norman Conquest of 1066, English monarchs had held titles and lands within France, the possession of which made them vassals of the kings of France. By the first quarter of the fourteenth century, the only significant French possession still held by the English in France was Gascony in the south-west. But Gascony was disproportionately important: duty levied by the English Crown on wine from Bordeaux, the capital of Gascony, totalled more than all other English customs duties combined and was by far the largest source of state income. Bordeaux had a population of more than 50,000, greater than London's, and Bordeaux was possibly richer. Following a series of disagreements between Philip VI of France (r.\u20091328\u00a0\u2013\u00a01350) and Edward III of England (r.\u20091327\u00a0\u2013\u00a01377), on 24 May 1337 Philip's Great Council agreed that the lands held by EdwardIII in France should be taken back into Philip's hands on the grounds that EdwardIII was in breach of his obligations as a vassal. This marked the start of the Hundred Years' War, which was to last 116 years.\nAlthough Gascony was the cause of the war, EdwardIII was able to spare few resources for its defence. In most campaigning seasons the Gascons had to rely on their own resources and had been hard-pressed by the French. Typically the Gascons could field 3,000 to 6,000 men, the large majority infantry, although up to two-thirds of them would be tied down in garrisoning their fortifications. In 1345 and 1346 Henry, Earl of Lancaster, led a series of successful Anglo-Gascon campaigns in Aquitaine and was able to push the focus of the fighting away from the heart of Gascony.\nThe French port of Calais fell to the English in August 1347 after the Cr\u00e9cy campaign. Shortly after this the Truce of Calais was signed, partially the result of both countries being financially exhausted. The same year the Black Death reached northern France and southern England and is estimated to have killed a third of the population of Western Europe; the death rate was over 40% in southern England. This catastrophe, which lasted until 1350, temporarily halted the fighting. The treaty was extended repeatedly over the years; this did not stop ongoing naval clashes, nor small-scale fighting\u00a0\u2013 which was especially fierce in south-west France\u00a0\u2013 nor occasional fighting on a larger scale.\nA treaty to end the war was negotiated at Gu\u00eenes and signed on 6 April 1354. However, the composition of the inner council of the French king, JohnII (r.\u20091350\u00a0\u2013\u00a01364), changed and sentiment turned against its terms. John decided not to ratify it, and it was clear that from the summer of 1355 both sides would be committed to full-scale war. In April 1355 EdwardIII and his council, with the treasury in an unusually favourable financial position, decided to launch offensives that year in both northern France and Gascony. John attempted to strongly garrison his northern towns and fortifications against the expected descent by EdwardIII, at the same time as assembling a field army; he was unable to, largely because of a lack of money.\nBlack Prince arrives.\nIn 1355 EdwardIII's eldest son, Edward of Woodstock, later known as the Black Prince, was given the Gascon command and began assembling men, shipping and supplies. He arrived in Bordeaux on 20September accompanied by 2,200 English soldiers. The next day he was formally acknowledged as the king's lieutenant in Gascony, with plenipotentiary powers, by the Gascon officials and dignitaries. Gascon nobles reinforced him to a strength of somewhere between 5,000 and 6,000 and provided a bridging train and a substantial supply train.\nEdward set out on 5October on a , which was a large-scale mounted raid. The Anglo-Gascon force marched from Bordeaux to Narbonne\u00a0\u2013 almost on the Mediterranean coast and deep in French-held territory\u00a0\u2013 and back to Gascony. They devastated a wide swathe of French territory and sacked many French towns on the way. John, Count of Armagnac, who commanded the local French forces, avoided battle, and there was little fighting. While no territory was captured, enormous economic damage was done to France; the modern historian Clifford Rogers concluded \"the importance of the economic attrition aspect of the can hardly be exaggerated.\" The expedition returned to Gascony on 2December having marched .\n1356.\nThe English troops resumed the offensive from Gascony after Christmas to great effect. More than 50 French-held towns or fortifications were captured during the following four months, including strategically important towns close to the borders of Gascony, and others more than away. Local French commanders did not attempt countermeasures. Several members of the local French nobility changed allegiance to the English; the Black Prince received homage from them on 24April 1356.\nMoney and enthusiasm for the war were running low in France. The modern historian Jonathan Sumption describes the French national administration as \"fall[ing] apart in jealous acrimony and recrimination\". A contemporary chronicler recorded \"the King of France was severely hated in his own realm\". The town of Arras rebelled and killed loyalists. The major nobles of Normandy refused to pay taxes. On 5April 1356 John arrested the notoriously treacherous CharlesII, king of Navarre, one of the largest landholders in Normandy and nine more of his more outspoken critics; four were summarily executed. The Norman nobles who had not been arrested turned to Edward for assistance.\nSeeing an opportunity, Edward III diverted an expedition planned for Brittany under Henry of Lancaster to Normandy in late June. Lancaster set off with 2,300 men and pillaged and burnt his way eastward across Normandy. King John moved to Rouen with a much stronger force, hoping to intercept Lancaster. After relieving and re-victualling the besieged fortifications of Breteuil and Pont-Audemer the English stormed and sacked the town of Verneuil. John pursued, but bungled several opportunities to bring the English to battle and they escaped. In three weeks the expedition had, with few casualties, seized a large amount of loot including many horses, cemented new alliances, and damaged the French economy and prestige. The French King returned to Breteuil and re-established the siege, where he continued to be distracted from the English preparations for a greater from south-west France.\nPrelude.\nManoeuvres.\nOn 4August 1356 a combined force of 6,000 Gascon and English fighting men headed north from Bergerac. They were accompanied by approximately 4,000 non-combatants. All of the fighting men were mounted, including those who would always fight on foot, such as the archers. On 14August the Anglo-Gascon army separated into three divisions, which moved north abreast of each other and began to systematically devastate the countryside. There would be approximately between the flanking units, enabling them to devastate a band of French territory more than wide, yet be able to unite to face an enemy at approximately a day's notice. They advanced slowly, to facilitate their tasks of looting and destruction. The modern historian David Green describes the progress of the Black Prince's army as \"deliberately destructive, extremely brutal... methodical and sophisticated.\" Several strong castles were assaulted and captured. The populaces of most towns fled, or surrendered at the first sight of Anglo-Gascon troops. Overall, there was little French resistance. If a French field army had been in the area, the Anglo-Gascon forces would have had to stay relatively close together, ready to support each other if attacked. The absence of any such French force enabled the Prince's formations to disperse widely to maximise their destructive effect on the French countryside.\nThe main French army remained in Normandy. Despite it being clear that Breteuil could be neither stormed nor starved, John felt unable to abandon its siege as this would undermine his prestige as a warrior-king. He declined to march against the Black Prince, declaring that the garrison of Breteuil posed a more serious threat. At some point in August an unusually large belfry, or mobile siege tower, was pushed up to the walls of Breteuil and a full-scale assault launched. The defenders set fire to the belfry and repulsed the attack. Sumption describes the French losses in this attack as \"terrible\" and the entire second siege as \"a pointless endeavour\". The historian Kenneth Fowler describes the siege as \"magnificent but archaic\". Eventually John had to give way to the pressure to do something to prevent the destruction being inflicted in south-west France. Sometime around 20August he offered the garrison of Breteuil free passage, a huge bribe and permission to take with them their valuables and goods, which persuaded them to vacate the town. The French army promptly marched south, as all available forces were concentrated against the Black Prince.\nHearing on 28August that John was marching on Tours and was prepared to give battle, the Black Prince moved his three divisions closer together and ordered them to move towards Tours. He was also willing to fight an open battle, if he could do so under the right circumstances. He still hoped to cross the Loire River, both to be able to come to grips with the French army and to link up with either Edward III's or Lancaster's army, if they were in the area. The French royal army from Breteuil had moved to Chartres, where it received reinforcements, particularly of men-at-arms. John sent home nearly all of the infantry contingents, which reduced the French wage bill and left an entirely mounted force that had the mobility and speed to match that of the Black Prince's all-mounted army. Two hundred Scottish picked men-at-arms under William, Lord of Douglas, joined John at Chartres. Once John felt he had an overwhelmingly strong force it set off south towards the Loire, and then south-west along its north bank. Early on 8September the Black Prince's army reached Tours, where he received news that Lancaster was not far to the east, on the other side of the Loire, and hoped to join him soon. The Anglo-Gascons prepared for battle and expected the imminent arrival of the French. But John had crossed the Loire at Blois, to the east of Tours, on 10September, where he was joined by the army of his son John, Count of Poitiers.\nMeanwhile, the anticipated support from England failed to materialise. In early August an Aragonese galley fleet, which had sailed from Barcelona in April, arrived in the English Channel. The fleet hired by the French only contained nine galleys, but it caused panic among the English. Edward's attempts to raise an army to send to France were still underway and shipping was being assembled. The troops gathered were split up to guard the coast and the ships sailing to Southampton to transport the army were ordered to remain in port until the galleys had left. At some point in August Lancaster marched south from eastern Brittany with an army of 2,500 men or more. The unusual height of the Loire and the French control of its bridges meant Lancaster was unable to cross and effect a junction. In early September he abandoned the attempt to force a crossing at Les Ponts-de-C\u00e9 and returned to Brittany where he laid siege to its capital, Rennes.\nStrategy.\nThe Anglo-Gascon army was treading a balance. While there were no large French forces facing them they spread out to loot and despoil the land. But their primary objective was to use the threat of devastation to force, or perhaps persuade, the French army to attack them. The Anglo-Gascons were confident that fighting defensively on ground of their choosing they could defeat a numerically superior French force. In the event of the French being too numerous they were equally confident that they could avoid battle by manoeuvring. The French, aware of this approach, usually attempted to isolate English forces against a river or the sea, where the threat of starvation would force them to take the tactical offensive and attack the French in a prepared position. Once he crossed the Loire, John repeatedly attempted to interpose his army between the Anglo-Gascons and Gascony, so they would be forced to try and fight their way out. Meanwhile, the Black Prince did not wish to rapidly retreat to the safety of Gascony, but to manoeuvre in the vicinity of the French army so as to persuade it to attack on unfavourable terms, without himself becoming cut off. He was aware that John had been eager to fight Lancaster's force in Normandy in June and anticipated this enthusiasm for battle would continue.\nMovement to contact.\nOnce he had crossed the Loire on 10September and been reinforced John moved to cut off the Anglo-Gascon line of retreat. Hearing of this, and losing hope that Lancaster would be able to join him, the Black Prince moved his army some south to Montbazon where he took up a fresh defensive position on 12September. The same day John's son and heir, Charles, the Dauphin, entered Tours, having travelled from Normandy with 1,000 men-at-arms, and H\u00e9lie de Talleyrand-P\u00e9rigord, Cardinal of P\u00e9rigord, arrived at the Black Prince's camp to attempt to negotiate a two-day truce on behalf of Pope Innocent VI. According to differing sources this was to be followed by peace negotiations or an arranged battle. The Black Prince dismissed Talleyrand and, happy to do battle, but concerned that a two-day delay would leave his army with its back to the Loire in an area with few supplies, marched hard and crossed the River Creuse at La Haye on 13September, to the south. John, aware he outnumbered the Anglo-Gascons, was also eager to wipe them out in battle and so similarly ignored Talleyrand. The French army continued to march south parallel to the English, rather than moving directly towards them, with the aim of cutting their lines of retreat and supply. On 14September the English marched south-west to Ch\u00e2tellerault on the Vienne.\nAt Ch\u00e2tellerault the Black Prince felt there were no geographical barriers against which the French could pin his army and that he was occupying an advantageous defensive position. He arrived there on 14September, the day Talleyrand had proposed for the two armies to engage in battle, and waited for the French to come to him. Two days later his scouts reported that John had bypassed his position and was about to cross the Vienne at Chauvigny. At this point the French had lost track of the Anglo-Gascon army and were unaware of its position, but were about to position themselves south of the Anglo-Gascons and directly in their path back to friendly territory. The Black Prince saw an opportunity to attack the French while they were on the march, or possibly even while crossing the Vienne, and so set off at first light on 17September to intercept them, leaving his baggage train behind to follow on as best it could.\nWhen the Anglo-Gascon vanguard reached Chauvigny most of the French army had already crossed and marched on towards Poitiers. A force of 700 men-at-arms of the French rearguard was intercepted near Savigny-L\u00e9vescault. Contemporary accounts note that they were not wearing helmets, suggesting they were completely unarmoured and not expecting battle. They were rapidly routed with 240 killed or captured, including 3 counts taken prisoner. Many Anglo-Gascons pursued the remaining, fleeing, French, although the Black Prince held back most of his army, not wishing to scatter it in the close vicinity of the enemy, and camped at Savigny-L\u00e9vescault. In response, John drew up his army outside Poitiers in battle order.\nNegotiations.\nOn 18September the Anglo-Gascons marched towards Poitiers arrayed for battle. They took up a strong, carefully selected position south of Poitiers on a wooded hill in the and began preparing it for a defensive battle: digging pits to impede the French advance (especially that of mounted troops) and trenches, and forming barricades to fight behind. They hoped that the French would launch an impromptu assault. Instead, Talleyrand rode up to negotiate. The Black Prince was initially disinclined to delay any battle. He was persuaded to discuss terms after Talleyrand pointed out that the two armies were now so close that if the French declined to attack, the Anglo-Gascons would find it almost impossible to withdraw. If they attempted to, the French would attack, aiming to defeat them in detail, and if they stood their position they would run out of supplies before the French. The Anglo-Gascons had to stay concentrated in the presence of the French army, and several days' hard marching had reduced the opportunities to forage. Because of this, food was almost exhausted. Unknown to Talleyrand the Anglo-Gascons were already unable to find sufficient water for their horses.\nAfter lengthy negotiations the Black Prince agreed extensive concessions in exchange for free passage to Gascony. However, they were dependent on the agreement being ratified by his father, EdwardIII. Unknown to Talleyrand or the French, Edward had given his son written permission to, in such circumstances, \"help himself by making a truce or armistice, or in any other way that seems best to him.\" This has caused modern historians to doubt the Prince's sincerity. The French discussed these proposals at length, with John in favour. Several senior advisers felt it would be humiliating to, as they saw it, have at their mercy the Anglo-Gascon army which had devastated so much of France and to tamely allow it to escape. John was persuaded and Talleyrand informed the Black Prince he could expect a battle. Attempts to agree a site for the battle failed, as the French wished the Anglo-Gascons to move out of their strong defensive position and the English wished to remain there. At dawn on 19September Talleyrand again attempted to arrange a truce, but as his army's supplies were already running out the Black Prince rejected this.\nOpposing forces.\nAnglo-Gascon army.\nThe Anglo-Gascon army is generally considered by modern historians to have consisted of 6,000 men: 3,000 men-at-arms, 2,000 English and Welsh longbowmen and 1,000 Gascon infantry. The latter included many equipped with either crossbows or javelins, both classed as light infantry. Some contemporary accounts give lower numbers of 4,800 or 5,000. The division of the men-at-arms between English and Gascons is not recorded, but the previous year, when campaigning with a similarly sized army, 1,000 of the Prince's men-at-arms had been English. All of the Anglo-Gascons travelled on horses, but all or nearly all of them dismounted to fight.\nThe men-at-arms of both armies were, broadly, knights or knights in training. They were drawn from the landed gentry and ranged from great lords to the relatives and attendants of minor landowners. They needed to be able to equip themselves with a full suit of armour and a warhorse. They wore a quilted gambeson under chain mail which covered the body and limbs. This was supplemented by varying amounts of plate armour on the body and limbs, more so for wealthier and more experienced men. Heads were protected by bascinets: open-faced military iron or steel helmets, with mail attached to the lower edge of the helmet to protect the throat, neck and shoulders. A moveable visor (face guard) protected the face. Heater shields, typically made from thin wood overlaid with leather, were carried. The English men-at-arms were all dismounted. The weapons they used are not recorded, but in similar battles they used their lances as pikes, cut them down to use as short spears, or fought with swords and battle-axes.\nThe longbow used by the English and Welsh archers was unique to them; it took up to ten years to master and an experienced archer could discharge up to ten arrows per minute well over . Computer analysis by Warsaw University of Technology in 2017 demonstrated that heavy bodkin point arrows could penetrate typical plate armour of the time at . The depth of penetration would be slight at that range; predicted penetration increased as the range closed or against armour of less than the best quality available at the time. At short range longbow arrows could pierce any practicable thickness of plate armour if they struck at the correct angle. Archers carried one quiver of 24 arrows as standard. There may have been a resupply of ammunition from the wagons to the rear during the battle to at least some longbowmen; the archers also ventured forward during pauses in the fighting to retrieve arrows.\nThe Anglo-Gascons were divided into three divisions or \"battles\". The one on the left was commanded by Thomas, Earl of Warwick, marshal of England and a veteran of the Battle of Crecy, where he had been guardian to the Black Prince. He had as deputies John, Earl of Oxford, and the Gascon lord Jean, Captal de Buch; they were assisted by mostly Gascon lords. As well as 1,000 men-at-arms, Warwick's division contained approximately 1,000 archers. The archers were positioned to the left of the men-at-arms. The right flank was under William, Earl of Salisbury, deputised by Robert, Earl of Suffolk, and Maurice, Baron Berkeley. Salisbury's division, like Warwick's, consisted of about 1,000 men-at-arms and 1,000 Welsh and English longbowmen. Again the archers were positioned on the flank of the men-at-arms, in this case the right. The Black Prince took command of the centre division, which consisted of men-at-arms and Gascon infantry: about 1,000 of each, only the flanking divisions contained longbowmen. He had two veteran campaigners, John Chandos and James Audley, as his deputies. Initially the Prince's force was held back behind the other two divisions as a reserve. Each division deployed four to five men deep. It is possible a further, small, reserve was held back behind the Prince's division.\nFrench army.\nThe French army was made up of between 14,000 and 16,000 men: 10,000 to 12,000 were men-at-arms, 2,000 were crossbowmen and 2,000 were infantrymen who were not classed as men-at-arms. Although most or all of the French had travelled mounted, they all fought dismounted at Poitiers except for two small groups of mounted knights, totalling either 300 or 500. These were selected from the Frenchmen who had the best armour, especially on their horses; horse armour is known as barding and the use of plate armour for this was a recent innovation in Western Europe. Their riders were equipped as the dismounted men-at-arms, apart from the superior quality of their armour. They wielded wooden lances, usually ash, tipped with iron and approximately long; their dismounted colleagues retained their lances, but cut them down to in order to use them as short spears. The crossbowmen wore metal helmets, brigandines (thick leather jerkins with varying amounts of small pieces of plate armour sewn to them) and possibly chain-mail hauberks. Crossbowmen usually fought from behind pavises\u00a0\u2013 very large shields with their own bearers, behind each of which three crossbowmen could shelter. A trained crossbowman could shoot his weapon approximately twice a minute and had a shorter effective range than a longbowman of about .\nThe French army was divided into four battles. The foremost division was led by the constable of France, Walter, Count of Brienne. As well as a large core of French men-at-arms it included 200 Scottish men-at-arms under William Douglas, most of the French infantry and crossbowmen and all of their cavalry. The two small groups of cavalry were each led by one of the two marshals of France: Arnoul d'Audrehem and Jean de Clermont. The leading French were approximately from the English. Behind this was a division led jointly by John's 19-year-old son and heir and John's uncle: Charles, the Dauphin, and Peter, Duke of Bourbon, respectively; Charles was experiencing his first taste of war. This formation consisted entirely of dismounted men-at-arms, 4,000 of them. The third division was led by John's younger brother, Philip, Duke of Orl\u00e9ans, also inexperienced in war, and was made up of approximately 3,200 men-at-arms. The rearmost division, of 2,000 men-at-arms and an uncertain number of crossbowmen, was commanded by the king himself.\nBattle.\nFirst attack.\nThe English had slept in or near their defensive positions and just after dawn\u00a0\u2013 which would have been at 5:40 am\u00a0\u2013 the French drew themselves up in battle order with their leading men about from the English positions. After the two armies had been facing each other for about two hours the French detected movement among the English, and believed the Black Prince's personal standard was withdrawing. There is modern debate as to what movement took place. Some scholars have proposed that the movement was of wagons, escorted by cavalry from Warwick's division; the wagons may have been empty and returning to their laager in the rear, or full and moving to a safer position away from the front line, or both and the start of a staged withdrawal by the English. If the latter their escort may have been most or all of Warwick's division and the movement of the standard was possibly his being mistaken for the Prince's or the Prince moving back as the second part of the disengagement. Another proposal is that the Black Prince deliberately had his troops move to simulate a withdrawal and provoke a French attack. The commanders of the leading French division took the movement to be a full-scale English withdrawal and ordered their men to advance, thinking this movement would effectively be a pursuit, thus starting the fighting.\nAudrehem's cavalry attacked Warwick's division on the English left, while Clermont charged Salisbury's on the right. In both cases the French plan was that they clear away the English archers, while given fire support by their own crossbowmen. However, the archers in Warwick's division were positioned in the edge of a marsh and this terrain prevented the French cavalry from getting to grips with them. The archers in turn found that the French armour and barding prevented them from firing effectively. To get close enough to penetrate the French armour, the longbowmen would have had to leave the protection of the marsh, which would have exposed them to the risk of being ridden down by the French. Instead, they turned their fire on the supporting crossbowmen and, having a superior rate of fire, were able to suppress them. Oxford realised the French horses were mostly only barded on their forequarters. He led some of the archers along the edge of the marsh to a position from which they could shoot into the horses' unprotected hindquarters. The French cavalry took heavy casualties and withdrew; Audrehem was captured.\nOn the English right Clermont advanced more cautiously, not far ahead of Brienne's dismounted troops. He discovered that Salisbury's men were defending a thick hedge with a single passable gap, wide enough for four horses abreast. Already committed to the attack, the French attempted to smash through the men-at-arms defending the gap. The English archers positioned in trenches near and to the right of the hedge are calculated to have fired 50 arrows per second at Clermont's group of cavalry. Gascon crossbowmen joined in; although they had a much lower rate of fire, they could penetrate plate armour at longer ranges. Despite this fire, the cavalry were able to reach the gap in the hedge with few casualties. Here a fierce melee broke out. With the French now halted and at close range, the longbowmen were more effective against them. The French were also heavily outnumbered by the English men-at-arms and were forced back with heavy losses, including Clermont killed.\nThe sources contain only details concerning the rest of the attack by the first French division, made up of a mixed force of French and foreign men-at-arms, and common heavy infantry. The bolts from their supporting crossbowmen were recorded as falling thickly, but with the cavalry repulsed the longbowmen turned against them and, having a superior rate of fire, were able to force them to withdraw despite their use of pavises. The division's leader, Brienne, the constable of France, was killed, as was one of Talleyrand's nephews, Robert of Durazzo, who had accompanied the Cardinal during his negotiations. Douglas either fled to save his life or was badly wounded and carried from the field. Given the heavy French casualties, it is assumed the attack was strongly pressed. As some contemporary sources summarise this phase of the fighting with \"the first French division was defeated by the arrows of the English\" it is also assumed by many modern historians that the longbowmen, still well supplied with ammunition able to punch straight through armour at close range, played a prominent part in the attack's repulse. The Black Prince was infuriated by the participation of Talleyrand's relatives and companions, and when told that a relative of the Cardinal, the ch\u00e2telain d'Emposte, had been captured he ordered him beheaded; he was rapidly persuaded to withdraw the order by his advisers.\nSecond attack.\nThere was no pursuit of the French survivors of the first attack as they retreated. The English were ordered to hold their positions and to take the opportunity to reform, as the next French division was already moving towards them. This, 4,000 strong, attacked vigorously. The French advanced against the steady fire of the English and Welsh archers, which caused many casualties, and were disordered by the retreating members of the first assault. The French had to force their way through the hedge the English were defending, which put them at a disadvantage, but they closed with the Anglo-Gascons in ferocious hand-to-hand fighting which went on for two hours.\nThey massed against two gaps in the hedge, on one occasion succeeding in driving back their opponents and breaking through; a force of archers had been deployed to cover this position and their fire cut down the leading Frenchmen, giving the Anglo-Gascons the opportunity to counter-attack and reform their line. Suffolk, aged almost 60, rode behind the Anglo-Gascon line, shouting encouragement, directing reinforcements to threatened points and telling the archers where to direct their fire. Throughout the battle the experienced English and Gascon commanders were able to manoeuvre and redeploy their troops in a way the French were not. The French commanders, mostly, carried out their orders and their men fought with reckless bravery, but they were inflexible. The Anglo-Gascons were able to respond in the heat of battle to French threats. Sumption describes this as \"remarkable\", David Green refers to \"an extremely flexible tactical response\". The historian Peter Hoskins states that most of the Anglo-Gascons having served together for a year \"contributed to the discipline that the Anglo-Gascons displayed\" and suggests that the French attack was ineptly handled.\nA contemporary French chronicler described this second attack as \"more amazing, harder and more lethal than the others\". An English account states \"Man fought frenziedly against man, each one striving to bring death to his opponent so that he himself might live.\" As the fighting went on, the Black Prince was forced to commit almost all of his reserves to reinforce weak spots. Both sides suffered many casualties. Audley was noted for being wounded in the body, head and face, and fighting on for the English. One of the French joint commanders, Bourbon, was killed, and the Dauphin's standard-bearer was captured. The Dauphin was accompanied by two of his brothers, Louis and John, and the trio's advisers and bodyguards were perturbed by the intensity of the fighting in their vicinity and forced them to withdraw from the front line to a safer position. Seeing this, the rest of the division, exhausted after two hours fighting and already demoralised by the death of Bourbon and the loss of the Dauphin's standard, withdrew as well. There was no panic and the disengagement was orderly. The senior surviving commanders of the division confirmed the movement and the surviving men-at-arms marched away from the Anglo-Gascons.\nIt is unclear if the Anglo-Gascons pursued the French, and if so, to what extent. Some modern historians state that the Anglo-Gascons again remained in their positions, as they had after the repulse of the first French division. Others write of a limited pursuit by individuals breaking ranks or of a full-blooded one by Warwick's division causing many French casualties. In any event, most of the Anglo-Gascons stood their ground, tended their wounded, knifed the French wounded and stripped their bodies and those of the already dead, and recovered what arrows they could find in the immediate vicinity, including those impaling dead and wounded Frenchmen. There were many English and Gascons wounded or dead and those still standing were exhausted from three hours of ferocious and near-continuous fighting.\nThird attack.\nAs the Dauphin's division recoiled there was confusion in the French ranks. The third French division contained 3,200 men-at-arms. Their commander, John's brother the Duke of Orl\u00e9ans, marched away from the battle with half of them and many of the survivors of the first two attacks. The contemporary sources contradict each other regarding the reasons for this. Orl\u00e9ans may have thought that the orderly withdrawal of the Dauphin's division marked a general retreat. There were official accounts after the battle that John had ordered Orl\u00e9ans to escort his four sons to safety, but these were widely disbelieved and rumoured to have been invented after the event to excuse the behaviour of Orl\u00e9ans and the men who had retreated with him. Three of John's four sons, including the Dauphin, did leave the field at this point; one, Philip, returned to his father's side and took part in the final attack. Of the 1,600 men who did not flee the scene, who included some from Orl\u00e9ans' inner circle, many joined the King's division behind. The rest advanced against the Anglo-Gascons and launched a feeble attack, which was repelled easily.\nIn the aftermath of this failure a number, possibly a large number, of men from Warwick's division left their positions and pursued the French. One motivation for this would have been their intention to take prisoners, the ransoming of whom could be extremely lucrative. Many of the English and Welsh archers again scavenged longbow arrows from the immediate vicinity. Of those men-at-arms who did not pursue, the majority were carrying wounds of varying degrees of severity and treating them was a preoccupation.\nFourth attack.\nJohn's fourth French division had started the battle with 2,000 men-at-arms, including 400 picked men under his personal command. Many of the surviving men-at-arms of the first two attacks had rallied to the King, as had many of those from the third division who had not withdrawn with Orl\u00e9ans. Some survivors of the botched third assault also fell back to join the King. These reinforcements probably brought the number of men-at-arms in the division to about 4,000. John's division also had a large but unspecified number of crossbowmen attached to it, and they had been joined by many surviving crossbowmen from the first attack. Modern scholars differ as to whether the French or the Anglo-Gascons had more men at this stage of the battle. This very large division marched across the gap towards the by now exhausted Anglo-Gascons, again all as infantry. The King ordered the French sacred banner, the , to be unfurled, which signalled that no prisoners were to be taken, on pain of death.\nIt was normal for medieval armies to form up in three divisions; having overcome three French divisions, many in the Anglo-Gascon army thought the battle was over. The sight of a further major force, under the royal standard and with the flying, dispirited them. One chronicler reports the Black Prince prayed aloud as this last division approached. The Prince harangued his exhausted men in an attempt to stiffen their morale, but they remained doubtful of their ability to repulse the approaching force. The Anglo-Gascon command group conferred. It seemed probable that if they stood to face a fourth attack they would be defeated. They decided to attempt a stratagem. Perhaps remembering a similar ploy by a French force at the 1349 Battle of Lunalonge it was agreed to send a small mounted group under the Gascon lord Jean, the Captal de Buch, on a circuitous march around the French flank in an attempt to launch a surprise attack on the French rear. The account by one contemporary chronicler that all of the Anglo-Gascon men-at-arms remounted at this point is generally discounted by modern historians. Some modern sources have a force of volunteers led by the wounded Audley mounting and being tasked with launching an attack against King John personally once the two forces came to battle\u00a0\u2013 only 4 men by some modern accounts, 400 in others. The modern historian Michael Jones describes this as a \"suicide mission\". Other modern sources maintain that other than the Captal de Buch's small force all of the Anglo-Gascons remained dismounted.\nThe sight of the Captal de Buch and his men making for the rear further disheartened the Anglo-Gascons, who believed that they were fearfully escaping an inevitable defeat. Some men fled. Concerned his army would break and rout in the face of the French assault, the Black Prince gave the order for a general advance. This bolstered Anglo-Gascon morale and shook the French. Discipline reasserted itself and the Anglo-Gascons moved forward, out of their defensive positions. The French crossbowmen advanced in front of their men-at-arms, and as the English longbowmen on the flanks of the Anglo-Gascon men-at-arms came within range they attempted to establish fire superiority. The French crossbow bolts are said to have \"darkened the sky\". The men firing them were able to shelter behind pavises and the English archers were running short of arrows after the desperate fighting of the morning. Nevertheless, the English were able to largely suppress this fire until the crossbowmen drew aside to let the French men-at-arms through for their final charge. As the English archers expended the last of their ammunition these 4,000 or so men-at-arms attempted to use their shields, ducked their heads against the arrows and charged home into the survivors of the 3,000 English and Gascon men-at-arms who had started the battle. The longbowmen threw their bows aside and joined the melee armed with swords and hand axes.\nBattle was again joined, with fierce fighting. The impetus of the Anglo-Gascon charge was halted by the French, who slowly got the better of the struggle. Rogers is of the opinion that the French would have won this fight if no other factors had intervened. The Anglo-Gascon line was starting to break when it was reinforced by men of Warwick's division returning from their pursuit. This heartened the Anglo-Gascons and discouraged the French. If it occurred, it was at this point that Audley led a cavalry charge aimed directly at the French king. The fighting continued, with the French focused on the opponents in front of them. With the battle in the balance, the Captal de Buch's 160 men arrived undetected in the French rear. His 100 archers dismounted and opened an effective fire into the French rear\u00a0\u2013 a contemporary account states they \"greatly and horribly pierced\" the French\u00a0\u2013 and his 60 mounted men-at-arms charged into the rear of the French line.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\nThen the standards wavered and the standard-bearers fell. Some were trampled, their innards torn open, and others spat out their own teeth. Many were stuck fast to the ground, impaled. Not a few lost whole arms as they stood there. Some died, swallowing in the blood of others, some groaned, crushed beneath the heavy weight of the fallen, mightly souls gave forth fearful lamentations as they departed from wretched bodies.\nGeoffrey le Baker\nThe 2,000 men who had originally made up John's division were all assigned to its front line when it advanced. Men who joined after their original divisions had been defeated in one of the previous three attacks filled in behind them. They were more tired than those in the front ranks and, having already having taken part in a failed assault, their morale was brittle. Dismayed by Warwick's reinforcement and shocked by the Captal de Buch's sudden arrival behind them, some started to run from the field. Once this movement had started others copied them and the division fell apart. Most of the first to run were able to reach their horses and escape, as the Anglo-Gascons concentrated on dealing with their enemies who were still fighting. These were pushed back as the Anglo-Gascons were reinvigorated by the prospect of victory. The French still fighting around their King were forced into a loop of the River Miosson, known as the Champ d'Alexandre. By now they had been surrounded and split into small groups.\nMany of these men were the elite of the French army: John's personal bodyguards, senior nobles or members of the Order of the Star. (The latter had all sworn not to retreat from a battle.) The fighting was brutal as these men refused to surrender. Their cause was clearly hopeless and the Anglo-Gascons were eager to take them prisoner\u00a0\u2013 in order that they could be ransomed\u00a0\u2013 rather than kill them, so many were captured. The standard-bearer of the was killed and the sacred banner captured. Surrounded by enemies, John and his youngest son, Philip, surrendered.\nMopping up.\nFrenchmen who had fled soon after the Captal de Buch's force arrived generally reached their horses and were able to escape. Once John's division was clearly retreating many Anglo-Gascons mounted and pursued. A large number pursued the Frenchmen fleeing towards what they thought was the safety of Poitiers. Its citizens, fearing the Anglo-Gascons, had closed the gates and manned the walls, and refused access. The mounted Anglo-Gascons caught the French soldiers as they milled outside the gate and slaughtered them. The lack of mention of any quarter being offered suggests that the French were common soldiers, rather than men-at-arms whom it would have been financially advantageous to capture in order to hold for ransom. The French camp was overrun by Anglo-Gascon cavalry. Elsewhere the Anglo-Gascons spread out in a helter-skelter chase. French men-at-arms who failed to reach their horses were captured or, occasionally, killed. Those who did mount were frequently pursued: some were caught and captured, some fought off their pursuers, while most escaped. It was evening before the last Anglo-Gascons returned to their camp with their prisoners.\nCasualties.\nAccording to different modern sources 2,000 to 3,000 French men-at-arms and either 500 or 800 common soldiers were taken prisoner during the battle. As well as the King and his youngest son they included the archbishop of Sens, one of the two marshals of France, and the seneschals of Saintonge, Tours and Poitou. Approximately 2,500 French men-at-arms were killed, as were 3,300 common soldiers according to English accounts or 700 by French ones. Among the slain were the French King's uncle; the grand constable of France; the other marshal; the Bishop of Ch\u00e2lons; and John's standard bearer, Geoffroi de Charny. A contemporary opined that the French had suffered \"a great harm, a great pity, and damage irreparable\". The Anglo-Gascons suffered many wounded but reported a mere 40 to 60 killed, of whom only 4 were men-at-arms. Hoskins comments that these \"seem improbably low\". Modern sources estimate Anglo-Gascon fatalities at about 40 men-at-arms and an uncertain but much larger number of bowmen and other infantry.\nAftermath.\nMarch to Bordeaux.\nThe French were concerned the victorious Anglo-Gascons would attempt to storm Poitiers or other towns, or continue their devastation. The Black Prince was more concerned with getting his army with its prisoners and loot safely back to Gascony. He was aware many Frenchmen had survived the battle, but unaware of their state of cohesion or morale. The Anglo-Gascons moved south on 20September and tended the wounded, buried the dead, paroled some of their prisoners, and reorganised their formations. On 21September the Anglo-Gascons continued their interrupted march south, travelling slowly, overladen as they were with plunder and prisoners. On 2 October they entered Libourne and rested while a triumphal entrance was arranged at Bordeaux. Two weeks later the Black Prince escorted John into Bordeaux amid ecstatic scenes.\nPeace.\nThe Black Prince's is described by Rogers as \"the most important campaign of the Hundred Years' War\". In its aftermath English and Gascon forces raided widely across France, against little or no opposition. With no effective central authority France dissolved into near anarchy. In March 1357 a truce was agreed for two years. In April the Black Prince sailed for England, accompanied by his prisoner, John, and landed at Plymouth on 5 May. They proceeded to London and a rapturous reception. Protracted negotiations between John and Edward III led to the First Treaty of London in May 1358, which would have ended the war with a large transfer of French territory to England and the payment of a ransom for John's freedom. The French government was unenthusiastic and was anyway unable to raise the first instalment of the ransom, causing the treaty to lapse. A peasant revolt known as the broke out in northern France during the spring of 1358 and was bloodily put down in June. At length John and Edward agreed the Second Treaty of London, which was similar to the first except that even larger swathes of French territory would be transferred to the English. In May 1359 this was similarly rejected by the Dauphin and the Estates General.\nIn October 1359 Edward III led another campaign in northern France. It was unopposed by French forces but was unable to take any strongly fortified places. Instead the English army spread out and for six months devastated much of the region. Both countries were finding it almost impossible to finance continued hostilities, but neither was inclined to change their attitude to the proposed peace terms. On 13 April 1360, near Chartres, a sharp fall in temperature and a heavy hail storm killed many English baggage horses and some soldiers. Taking this as a sign from God, Edward reopened negotiations, directly with the Dauphin. By 8 May the Treaty of Br\u00e9tigny had been agreed, which largely replicated the First Treaty of London or the Treaty of Gu\u00eenes. By this treaty vast areas of France were ceded to England, to be personally ruled by the Black Prince, and John was ransomed for three million gold \u00e9cu. Rogers states \"Edward gained territories comprising a full third of France, to be held in full sovereignty, along with a huge ransom for the captive King John\u00a0\u2013 his original war aims and much more.\" As well as John, sixteen of the more senior nobles captured at Poitiers were finally released with the sealing of this treaty. At the time it seemed this was the end of the war, but large-scale fighting broke out again in 1369 and the Hundred Years' War did not end until 1453, with a French victory which left only Calais in English hands.\nNotes, citations and sources.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nSources.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "4505", "revid": "27015025", "url": "https://en.wikipedia.org/wiki?curid=4505", "title": "Backbone cabal", "text": "Group of administrators on Usenet\nThe backbone cabal was an informal organization of large-site news server administrators of the worldwide distributed newsgroup-based discussion system Usenet. It existed from about 1983 until around 1988.\nThe cabal was created in an effort to facilitate reliable propagation of new Usenet posts. While in the 1970s and 1980s many news servers only operated during night time to save on the cost of long-distance communication, servers of the backbone cabal were available 24 hours a day. The administrators of these servers gained sufficient influence in the otherwise anarchic Usenet community to be able to push through controversial changes, for instance the Great Renaming of Usenet newsgroups during 1987.\nHistory.\nMary Ann Horton recruited membership in and designed the original physical topology of the Usenet Backbone in 1983. Gene \"Spaf\" Spafford then created an email list of the backbone administrators, plus a few influential posters. This list became known as the Backbone Cabal and served as a \"political (i.e. decision making) backbone\". Other prominent members of the cabal were Brian Reid, Richard Sexton, Chuq von Rospach and Rick Adams.\nIn internet culture.\nDuring most of its existence, the cabal (sometimes capitalized) steadfastly denied its own existence; those involved would often respond \"There is no Cabal\" (sometimes abbreviated as \"TINC\"').\nThe result of this policy was an aura of mystery, even a decade after the cabal mailing list disbanded in late 1988 following an internal fight.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "4506", "revid": "50615552", "url": "https://en.wikipedia.org/wiki?curid=4506", "title": "Bongo (antelope)", "text": "Species of mammal\n&lt;templatestyles src=\"Template:Taxobox/core/styles.css\" /&gt;\nThe bongo (Tragelaphus eurycerus) is a large, mostly nocturnal, forest-dwelling antelope, native to sub-Saharan Africa. Bongos are characterised by a striking reddish-brown coat, black and white markings, white-yellow stripes, and long slightly spiralled horns. It is the only tragelaphid in which both sexes have horns. Bongos have complex social interactions and are found in African dense forest mosaics. They are the third-largest antelope in the world.\nThe western or lowland bongo, \"T.\u00a0e. eurycerus\", faces an ongoing population decline, and the IUCN Antelope Specialist Group considers it to be Near Threatened on the conservation status scale. \nThe eastern or mountain bongo, \"T.\u00a0e. isaaci\", of Kenya, has a coat even more vibrant than that of \"T.\u00a0e. eurycerus\". The mountain bongo is only found in the wild in a few mountain regions of central Kenya. This bongo is classified by the IUCN Antelope Specialist Group as Critically Endangered, with fewer individuals in the wild than in captivity (where it breeds readily). \nIn 2000, the Association of Zoos and Aquariums in the US (AZA) upgraded the bongo to a Species Survival Plan participant and in 2006 added the Bongo Restoration to Mount Kenya Project to its list of the Top Ten Wildlife Conservation Success Stories of the year. As of 2013[ [update]], these successes have been compromised by reports of possibly only 100 mountain bongos left in the wild due to logging and poaching.\nTaxonomy.\nThe scientific name of the bongo is \"Tragelaphus eurycerus\", and it belongs to the genus \"Tragelaphus\" and family Bovidae. It was first described by Irish naturalist William Ogilby in 1837. The generic name \"Tragelaphus\" is composed of two Greek words: \"trag-\", meaning a goat; and \"elaphos\", meaning deer. The specific name \"eurycerus\" originated from the fusion of \"eurus\" (broad, widespread) and \"keras\" (an animal's horn). The common name \"bongo\" originated probably from the Kele language of Gabon. The first known use of the name \"bongo\" in English dates to 1861.\nBongos are further classified into two subspecies: \"T.\u00a0e. eurycerus\", the lowland or western bongo, and the far rarer \"T.\u00a0e. isaaci\", the mountain or eastern bongo, restricted to the mountains of Kenya only. The eastern bongo is larger and heavier than the western bongo. Two other subspecies are described from West and Central Africa, but taxonomic clarification is required. They have been observed to live up to 19 years.\nAppearance.\nBongos are one of the largest of the forest antelopes. In addition to the deep chestnut colour of their coats, they have bright white stripes on their sides to help with camouflage.\nAdults of both sexes are similar in size. Adult height is about at the shoulder and length is , including a tail of . Females weigh around , while males weigh about . Its large size puts it as the third-largest in the Bovidae tribe of Strepsicerotini, behind both the common and greater eland by about , and above the greater kudu by about .\nBoth sexes have heavy spiral horns; those of the male are longer and more massive. All bongos in captivity are from the isolated Aberdare Mountains of central Kenya.\nCoat and body.\nThe bongo sports a bright auburn or chestnut coat, with the neck, chest, and legs generally darker than the rest of the body, especially in males. Coats of male bongos become darker as they age until they reach a dark mahogany-brown colour. Coats of female bongos are usually more brightly coloured than those of males. The eastern bongo is darker in color than the western, and this is especially pronounced in older males which tend to be chestnut brown, especially on the forepart of their bodies.\nThe smooth coat is marked with 10\u201315 vertical white-yellow stripes, spread along the back from the base of the neck to the rump. The number of stripes on each side is rarely the same. It also has a short, bristly, brown ridge of dorsal hair from the shoulder to the rump; the white stripes run into this ridge.\nA white chevron appears between the eyes, with two large white spots on each cheek. Another white chevron occurs where the neck meets the chest. Bongos have no special secretion glands, so rely likely less on scent to find one another than do other similar antelopes. The lips of a bongo are white, topped with a black muzzle.\nHorns.\nBongos have two heavy and slightly spiralled horns that slope over their backs. Bongo males have larger backswept horns, while females have smaller, thinner, and more parallel horns. The size of the horns range between . The horns of bongos are spiraled, and share this trait with those of the related antelope species of nyalas, sitatungas, bushbucks, kudus, and elands. The horns of bongos twist once.\nUnlike deer, which have branched antlers they shed annually, bongos and other antelopes have unbranched horns they keep throughout their lives. \nLike all other horns of antelopes, the core of a bongo's horn is hollow and the outer layer of the horn is made of keratin, the same material that makes up human fingernails, toenails, and hair. The bongo runs gracefully and at full speed through even the thickest tangles of lianas, laying its heavy spiralled horns on its back so the brush cannot impede its flight. Bongos are hunted for their horns by humans.\nSocial organization and behavior.\nLike other forest ungulates, bongos are seldom seen in large groups. Males, called bulls, tend to be solitary, while females with young live in groups of six to eight. Bongos have seldom been seen in herds of more than 20. Gestation is about 285\u00a0days (9.5\u00a0months), with one young per birth, and weaning occurs at six months. Sexual maturity is reached at 24\u201327\u00a0months. The preferred habitat of this species is so dense and difficult to operate in that few Europeans or Americans observed this species until the 1960s.\nAs young males mature and leave their maternal groups, they most often remain solitary, although rarely they join an older male. Adult males of similar size/age tend to avoid one another. Occasionally, they meet and spar with their horns in a ritualised manner and it is rare for serious fights to take place. However, such fights are usually discouraged by visual displays, in which the males bulge their necks, roll their eyes, and hold their horns in a vertical position while slowly pacing back and forth in front of the other male. They seek out females only during mating time. When they are with a herd of females, males do not coerce them or try to restrict their movements as do some other antelopes.\nAlthough mostly nocturnal, they are occasionally active during the day. However, like deer, bongos may exhibit crepuscular behaviour. Bongos are both timid and easily frightened; after a scare, a bongo moves away at considerable speed, even through dense undergrowth. Once they find cover, they stay alert and face away from the disturbance, but peek every now and then to check the situation. The bongo's hindquarters are less conspicuous than the forequarters, and from this position the animal can quickly flee.\nWhen in distress, the bongo emits a bleat. It uses a limited number of vocalisations, mostly grunts and snorts; females have a weak mooing contact-call for their young. Females prefer to use traditional calving grounds restricted to certain areas, where newborn calves lie in hiding for a week or more, receiving short visits by the mother to suckle.\nThe calves grow rapidly and can soon accompany their mothers in the nursery herds. Their horns grow rapidly and begin to show in 3.5 months. They are weaned after six months and reach sexual maturity at about 20 months.\nEcology.\nDistribution and habitat.\nBongos are found in tropical jungles with dense undergrowth up to an altitude of in Central Africa, with isolated populations in Kenya, and these West African countries: Cameroon, the Central African Republic, the Republic of the Congo, the Democratic Republic of the Congo, the Ivory Coast, Equatorial Guinea, Gabon, Ghana, Guinea, Liberia, Sierra Leone, and South Sudan.\nHistorically, bongos are found in three disjunct parts of Africa: East, Central, and West. Today, all three populations' ranges have shrunk in size due to habitat loss for agriculture and uncontrolled timber cutting, as well as hunting for meat.\nBongos favour disturbed forest mosaics that provide fresh, low-level green vegetation. Such habitats may be promoted by heavy browsing by elephants, fires, flooding, tree-felling (natural or by logging), and fallowing. Mass bamboo die-off provides ideal habitat in East Africa. They can live in bamboo forests.\nDiet.\nLike many forest ungulates, bongos are herbivorous browsers and feed on leaves, bushes, vines, bark and pith of rotting trees, grasses/herbs, roots, cereals, and fruits.\nBongos require salt in their diets, and are known to regularly visit natural salt licks. Bongos are also known to eat burnt wood after a storm, a rich source of salt and minerals. This behavior is believed to be a means of getting salts and minerals into their diets. This behavior has also been reported in the okapi. Another similarity to the okapi, though the bongo is unrelated, is that the bongo has a long prehensile tongue which it uses to grasp grasses and leaves.\nSuitable habitats for bongos must have permanent water available. As a large animal, the bongo requires an ample amount of food, and is restricted to areas with abundant year-round growth of herbs and low shrubs.\nPopulation and conservation.\nFew estimates of population density are available. Assuming average population densities of 0.25 animals per km2 in regions where it is known to be common or abundant, and 0.02 per km2 elsewhere, and with a total area of occupancy of , a total population estimate of around 28,000 is suggested. Only about 60% are in protected areas, suggesting the actual numbers of the lowland subspecies may only be in the low tens of thousands. In Kenya, their numbers have declined significantly and on Mount Kenya, they were extirpated within the last decade due to illegal hunting with dogs. Although information on their status in the wild is lacking, lowland bongos are not presently considered endangered.\nBongos are susceptible to diseases such as rinderpest, which almost exterminated the species during the 1890s. \"Tragelaphus eurycerus\" may suffer from goitre. Over the course of the disease, the thyroid glands greatly enlarge (up to 10 x 20\u00a0cm) and may become polycystic. Pathogenesis of goiter in the bongo may reflect a mixture of genetic predisposition coupled with environmental factors, including a period of exposure to a goitrogen. Leopards and spotted hyenas are the primary natural predators (lions are seldom encountered due to differing habitat preferences); pythons sometimes eat bongo calves. Humans prey on them for their pelts, horns, and meat, with the species being a common local source for \"bush meat\". Bongo populations have been greatly reduced by hunting, poaching, and animal trapping, although some bongo refuges exist.\nAlthough bongos are quite easy for humans to catch using snares, many people native to the bongos' habitat believed that if they ate or touched bongo, they would have spasms similar to epileptic seizures. Because of this superstition, bongos were less harmed in their native ranges than expected. However, these taboos are said to no longer to exist, which may account for increased hunting by humans in recent times.\nZoo programmes.\nAn international studbook is maintained to help manage animals held in captivity. Because of its bright colour, it is very popular in zoos and private collections. In North America, over 400 individuals are thought to be held, a population that probably exceeds that of the mountain bongo in the wild.\nIn 2000, the Association of Zoos and Aquariums (AZA) upgraded the bongo to a Species Survival Plan participant, which works to improve the genetic diversity of managed animal populations. The target population for participating zoos and private collections in North America is 250 animals. Through the efforts of zoos in North America, a reintroduction to the population in Kenya is being developed.\nAt least one collaborative effort for reintroduction between North American wildlife facilities has already been carried out. In 2004, 18 eastern bongos born in North American zoos gathered at White Oak Conservation in Yulee, Florida, for release in Kenya. White Oak staff members traveled with the bongos to a Mount Kenya holding facility, where they stayed until being reintroduced.\nConservation.\nIn the last few decades, a rapid decline in the numbers of wild mountain bongo has occurred due to poaching and human pressure on their habitat, with local extinctions reported in Cherang'any and Chepalungu hills, Kenya.\nThe Bongo Surveillance Programme, working alongside the Kenya Wildlife Service, have recorded photos of bongos at remote salt licks in the Aberdare Forests using camera traps, and, by analyzing DNA extracted from dung, have confirmed the presence of bongo in Mount Kenya, Eburru, and Mau forests. The programme estimate as few as 140 animals left in the wild \u2013 spread across four isolated populations. Whilst captive breeding programmes can be viewed as having been successful in ensuring survival of this species in Europe and North America, the situation in the wild has been less promising. Evidence exists of bongo surviving in Kenya. However, these populations are believed to be small, fragmented, and vulnerable to extinction.\nAnimal populations with impoverished genetic diversity are inherently less able to adapt to changes in their environments (such as climate change, disease outbreaks, habitat change, etc.). The isolation of the four remaining small bongo populations, which themselves would appear to be in decline, means a substantial amount of genetic material is lost each generation. Whilst the population remains small, the impact of transfers will be greater, so the establishment of a \"metapopulation management plan\" occurs concurrently with conservation initiatives to enhance \"in situ\" population growth, and this initiative is both urgent and fundamental to the future survival of mountain bongo in the wild.\nThe western/lowland bongo faces an ongoing population decline as habitat destruction and hunting pressures increase with the relentless expansion of human settlement. Its long-term survival will only be assured in areas which receive active protection and management. At present, such areas comprise about 30,000\u00a0km2, and several are in countries where political stability is fragile. Therefore, a realistic possibility exists whereby its status could decline to Threatened in the near future.\nAs the largest and most spectacular forest antelope, the western/lowland bongo is both an important flagship species for protected areas such as national parks, and a major trophy species which has been taken in increasing numbers in Central Africa by sport hunters during the 1990s. Both of these factors are strong incentives to provide effective protection and management of populations.\nTrophy hunting has the potential to provide economic justification for the preservation of larger areas of bongo habitat than national parks, especially in remote regions of Central Africa, where possibilities for commercially successful tourism are very limited.\nThe eastern/mountain bongo's survival in the wild is dependent on more effective protection of the surviving remnant populations in Kenya. If this does not occur, it will eventually become extinct in the wild. The existence of a healthy captive population of this subspecies offers the potential for its reintroduction.\nGroups supporting bongo conservation in Kenya.\nIn 2004, Dr. Jake Veasey, the head of the Department of Animal Management and Conservation at Woburn Safari Park and a member of the European Association of Zoos and Aquariums Population Management Advisory Group, with the assistance of Lindsay Banks, took over responsibility for the management and coordination of the European Endangered Species Programme for the eastern bongo. This includes some 250 animals across Europe and the Middle East.\nAlong with the Rothschild's giraffe, the eastern bongo is arguably one of the most threatened large mammals in Africa, with recent estimates numbering less than 140 animals, below a minimum sustainable viable population. The situation is exacerbated because these animals are spread across four isolated populations. Whilst the bongo endangered species program can be viewed as having been successful in ensuring survival of this species in Europe, it has not yet become actively involved in the conservation of this species in the wild in a coordinated fashion. The plan is to engage in conservation activities in Kenya to assist in reversing the decline of the eastern bongo populations and genetic diversity in Africa, and in particular, applying population management expertise to help ensure the persistence of genetic diversity in the free ranging wild populations.\nTo illustrate significance of genetic diversity loss, assume the average metapopulation size is 35 animals based on 140 animals spread across four populations (140/4=35). Assuming stable populations, these populations will lose 8% of their genetic diversity every decade. By managing all four populations as one, through strategic transfers, gene loss is reduced from 8% to 2% per decade, without any increase in bongo numbers in Kenya. By managing the European and African populations as one \u2013 by strategic exports from Europe combined with \"in situ\" transfers, gene loss is reduced to 0.72% every 100 years, with both populations remaining stable. If populations in Kenya are allowed to grow through the implementation of effective conservation, including strategic transfers, gene loss can be effectively halted in this species and its future secured in the wild.\nThe initial aims of the project are: \nIf effective protection were implemented immediately and bongo populations allowed to expand without transfers, then this would create a bigger population of genetically impoverished bongos. These animals would be less able to adapt to a dynamic environment. Whilst the population remains small, the impact of transfers will be greater. For this reason, the 'metapopulation management plan' must occur concurrently with conservation strategies to enhance \"in situ\" population growth. This initiative is both urgent and fundamental to the future survival of the mountain bongo in the wild.\nIn 2013, Safaricom telecommunications donated money to the Bongo Surveillance Programme to try to keep tabs on what are thought to be the last 100 eastern bongos left in the wild in the Mau Eburu Forest in central Kenya, whose numbers are still declining due to logging of their habitat and illegal poaching.\nMount Kenya Wildlife Conservancy runs a bongo rehabilitation program in collaboration with the Kenya Wildlife Service. The Conservancy aims to prevent extinction of the bongo through breeding and release back into the wild.\nStatus.\nThe IUCN Antelope Specialist Group considers the western or lowland bongo, \"T.\u00a0e. eurycerus\", to be Lower Risk (Near Threatened) and the eastern or mountain bongo, \"T.\u00a0e. isaaci\", of Kenya, to be Critically Endangered. These bongos may be endangered due to human environmental interaction, as well as hunting and illegal actions towards wildlife.\nCITES lists bongos as an Appendix III species, only regulating their exportation from a single country, Ghana. It is not protected by the US Endangered Species Act and is not listed by the USFWS.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "4507", "revid": "50076165", "url": "https://en.wikipedia.org/wiki?curid=4507", "title": "Bunyip", "text": "Mythical creature from Aboriginal mythology\nThe bunyip is a creature from the aboriginal mythology of southeastern Australia, said to lurk in swamps, billabongs, creeks, riverbeds, and waterholes.\nName.\nThe origin of the word \"bunyip\" has been traced to the Wemba-Wemba or Wergaia language of the Aboriginal people of Victoria, in South-Eastern Australia.\nThe word \"bunyip\" is usually translated by Aboriginal Australians today as \"devil\" or \"evil spirit\". This contemporary translation may not accurately represent the role of the bunyip in pre-contact Aboriginal mythology or its possible origins before written accounts were made. Some modern sources allude to a linguistic connection between the bunyip and Bunjil, \"a mythic 'Great Man' who made the mountains, rivers, man, and all the animals\".\nThe word \"bahnyip\" first appeared in the \"Sydney Gazette\" in 1812. It was used by James Ives to describe \"a large black animal like a seal, with a terrible voice which creates terror among the blacks\".\nDistribution.\nThe bunyip is part of traditional Aboriginal beliefs and stories throughout Australia, while its name varies according to tribal nomenclature. In his 2001 book, writer Robert Holden identified at least nine regional variations of the creature known as the bunyip across Aboriginal Australia.\nCharacteristics.\nThe bunyip has been described as amphibious, almost entirely aquatic (there are no reports of the creature being sighted on land), inhabiting lakes, rivers, swamps, lagoons, billabongs, creeks, waterholes, sometimes \"particular waterholes in the riverbeds\".\nPhysical descriptions of bunyips vary widely. George French Angus may have collected a description of a bunyip in his account of a \"water spirit\" from the Moorundi people of the Murray River before 1847, stating it is \"much dreaded by them\u00a0... It inhabits the Murray; but\u00a0... they have some difficulty describing it. Its most usual form\u00a0... is said to be that of an enormous starfish.\" The Challicum bunyip, an outline image of a bunyip carved by Aboriginal people into the bank of Fiery Creek, near Ararat, Victoria, was first recorded by \"The Australasian\" newspaper in 1851. According to the report, the bunyip had been speared after killing an Aboriginal man. Antiquarian Reynell Johns claimed that until the mid-1850s, Aboriginal people made a \"habit of visiting the place annually and retracing the outlines of the figure [of the bunyip] which is about 11 paces long and 4 paces in extreme breadth\". The outline image no longer exists. Robert Brough Smyth's \"Aborigines of Victoria\" (1878) devoted ten pages to the bunyip, but concluded \"in truth little is known among the blacks respecting its form, covering or habits; they appear to have been in such dread of it as to have been unable to take note of its characteristics\". Eug\u00e9nie Louise McNeil recalled from her childhood memory in the 1890s that the bunyip supposedly had a snout like an owl (\"a Mopoke\"), and was probably a nocturnal creature by her estimation.\nThe bunyips presumably seen by witnesses, according to their descriptions, most commonly fit one of two categories: 60% of sightings resemble seals or swimming dogs, and 20% of sightings are of long-necked creatures with small heads; the remaining descriptions are ambiguous beyond categorisation. The seal-dog variety is most often described as being between 4 and 6 feet long with a shaggy black or brown coat. According to reports, these bunyips have round heads resembling a bulldog, prominent ears, no tail, and whiskers like a seal or otter. The long-necked variety is allegedly between 5 and 15 feet long, and is said to have black or brown fur, large ears, small tusks, a head like a horse or emu, an elongated, maned neck about three feet long and with many folds of skin, and a horse-like tail. The bunyip has been described by natives as amphibious, nocturnal, reclusive, and inhabiting lakes, rivers, and swamps. Bunyips, according to Aboriginal mythology, can swim swiftly with fins or flippers, have a loud, roaring call, and feed on crayfish, though some legends portray them as bloodthirsty predators of humans, particularly women and children. As a result, Aboriginal People purposely avoided unfamiliar bodies of water lest there were bunyips lurking in the depths. Bunyip eggs are allegedly laid in platypus nests.\nThe bunyip appears in Ngarrindjeri dreaming as a water spirit called the Mulyawonk, which would get anyone who took more than their fair share of fish from the waterways, or take children if they got too close to the water. The stories taught practical means of ensuring long-term survival for the Ngarrindjeri, embodying care for country and its people.\nDebate over origins.\nThere have been various attempts to understand and explain the origins of the bunyip as a physical entity over the past 150 years. Writing in 1933, Charles Fenner suggested that it was likely that the \"actual origin of the bunyip myth lies in the fact that from time to time seals have made their way up the Murray and Darling (Rivers)\". He provided examples of seals found as far inland as Overland Corner, Loxton, and Conargo and reminded readers that \"the smooth fur, prominent 'apricot' eyes, and the bellowing cry are characteristic of the seal\", especially southern elephant seals and leopard seals.\nAnother suggestion is that the bunyip may be a folk memory of extinct Australian marsupials such as the \"Diprotodon\", \"Zygomaturus\", \"Nototherium\", \"Palorchestes\" or \"Thylacoleo\". This connection was first formally made by Dr George Bennett of the Australian Museum in 1871. In the early 1990s, palaeontologist Pat Vickers-Rich and geologist Neil Archbold also cautiously suggested that Aboriginal legends \"perhaps had stemmed from an acquaintance with prehistoric bones or even living prehistoric animals themselves\u00a0... When confronted with the remains of some of the now extinct Australian marsupials, Aborigines would often identify them as the bunyip.\" They also note that \"legends about the\" mihirung paringmal\" of western Victorian Aborigines\u00a0... may allude to the\u00a0... extinct giant birds the Dromornithidae.\"\nIn a 2017 \"Australian Birdlife\" article, Karl Brandt suggested Aboriginal encounters with the southern cassowary inspired the myth. According to the first written description of the bunyip from 1845, the creature laid pale blue eggs of immense size, possessed deadly claws, powerful hind legs, a brightly coloured chest, and an emu-like head, characteristics shared with the Australian cassowary. As the creature's bill was described as having serrated projections, each \"like the bone of the stingray\", this bunyip was associated with the indigenous people of Far North Queensland, renowned for their spears tipped with stingray barbs and their proximity to the cassowary's Australian range.\nAnother association to the bunyip is the shy Australasian bittern (\"Botaurus poiciloptilus\"). During the breeding season, the male call of this marsh-dwelling bird is a \"low pitched boom\"; hence, it is occasionally called the \"bunyip bird\".\nEarly accounts of European settlers.\nDuring the early settlement of Australia by Europeans, the notion became commonly held that the bunyip was an unknown animal that awaited discovery. Unfamiliar with the sights and sounds of the island continent's peculiar fauna, early Europeans believed that the bunyip described to them was one more strange Australian animal and they sometimes attributed unfamiliar animal calls or cries to it. Scholars suggest also that 19th-century bunyip lore was reinforced by imported European folklore, such as that of the Irish P\u00faca.\nA large number of bunyip sightings occurred during the 1840s and 1850s, particularly in the southeastern colonies of Victoria, New South Wales and South Australia, as European settlers extended their reach. The following is not an exhaustive list of accounts:\nFirst written use of the word \"bunyip\", 1845.\nIn July 1845, \"The Geelong Advertiser\" announced the discovery of fossils found near Geelong, under the headline \"Wonderful Discovery of a new Animal\". This was a continuation of a story on 'fossil remains' from the previous issue. The newspaper continued, \"On the bone being shown to an intelligent black, he at once recognised it as belonging to the bunyip, which he declared he had seen. On being requested to make a drawing of it, he did so without hesitation.\" The account noted a story of an Aboriginal woman being killed by a bunyip and the \"most direct evidence of all\" \u2013 that of a man named Mumbowran \"who showed several deep wounds on his breast made by the claws of the animal\".\nThe account provided this description of the creature:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The Bunyip, then, is represented as uniting the characteristics of a bird and of an alligator. It has a head resembling an emu, with a long bill, at the extremity of which is a transverse projection on each side, with serrated edges like the bone of the stingray. Its body and legs partake of the nature of the alligator. The hind legs are remarkably thick and strong, and the fore legs are much longer, but still of great strength. The extremities are furnished with long claws, but the blacks say its usual method of killing its prey is by hugging it to death. When in the water it swims like a frog, and when on shore it walks on its hind legs with its head erect, in which position it measures twelve or thirteen feet in height.\nShortly after this account appeared, it was repeated in other Australian newspapers. This appears to be the first use of the word \"bunyip\" in a written publication.\nAustralian Museum's bunyip of 1847.\nIn January 1846, a peculiar skull was taken by a settler from the banks of Murrumbidgee River near Balranald, New South Wales. Initial reports suggested that it was the skull of something unknown to science. The squatter who found it remarked, \"all the natives to whom it was shown called [it] a bunyip\". By July 1847, several experts, including W. S. Macleay and Professor Owen, had identified the skull as the deformed foetal skull of a foal or calf. At the same time, the purported bunyip skull was put on display in the Australian Museum (Sydney) for two days. Visitors flocked to see it, and \"The Sydney Morning Herald\" reported that many people spoke out about their \"bunyip sightings\". Reports of this discovery used the phrase 'Kine Pratie' as well as Bunyip. Explorer William Hovell, who examined the skull, also called it a 'katen-pai'.\nIn March of that year, \"a bunyip or an immense Platibus\" (Platypus) was sighted \"sunning himself on the placid bosom of the Yarra, just opposite the Custom House\" in Melbourne. \"Immediately a crowd gathered\" and three men set off by boat \"to secure the stranger\" which \"disappeared\" when they were \"about a yard from him\".\nWilliam Buckley's account of bunyips, 1852.\nAnother early written account is attributed to escaped convict William Buckley in his 1852 biography of thirty years living with the Wathaurong people. His 1852 account records \"in\u00a0... Lake Moodewarri [now Lake Modewarre] as well as in most of the others inland\u00a0... is a\u00a0... very extraordinary amphibious animal, which the natives call Bunyip.\" Buckley's account suggests he saw such a creature on several occasions. He adds, \"I could never see any part, except the back, which appeared to be covered with feathers of a dusky grey colour. It seemed to be about the size of a full grown calf\u00a0... I could never learn from any of the natives that they had seen either the head or tail.\" Buckley also claimed the creature was common in the Barwon River and cites an example he heard of an Aboriginal woman being killed by one. He emphasized the bunyip was believed to have supernatural powers.\nStocqueler's sightings and drawings, 1857.\nIn an article titled, 'The Bunyip', a newspaper reported on the drawings made by Edwin Stocqueler as he travelled on the Murray and Goulburn rivers: 'Amongst the latter drawings we noticed a likeness of the Bunyip, or rather a view of the neck and shoulders of the animal. Mr. Stocqueler informs us that the Bunyip is a large freshwater seal, having two small padules or fins attached to the shoulders, a long swan like neck, a head like a dog, and a curious bag hanging under the jaw, resembling the pouch of the pelican. The animal is covered with hair, like the platypus, and the colour is a glossy black. Mr. Stocqueler saw no less than six of these curious animals at different times; his boat was within thirty feet of one near McGuire's punt on the Goulburn, and he fired at the Bunyip, but did not succeed in capturing him. The smallest appeared to be about five feet in length, and the largest exceeded fifteen feet. The head of the largest was the size of a bullock's head, and three feet out of water. After taking a sketch of the animal, Mr. Stocqueler showed it to several blacks of the Goulburn tribe, who declared that the picture was \"Bunyip's brother,\" meaning a duplicate or likeness of the bunyip. The animals moved against the current, at the rate of about seven miles an hour, and Mr. Stockqueler states that he could have approached close to the specimens he observed, had he not been deterred by the stories of the natives concerning the power and fury of the bunyip, and by the fact that his gun had only a single barrel, and his boat was of a very frail description.'\nThe description varied across newspaper accounts: 'The great Bunyip question seems likely to be brought to a close, as a Mr. Stocqueler, an artist and gentleman, who has come up the Murray in a small boat, states that he saw one, and was enabled to take a drawing of this \"vexed question,\" but could not succeed in catching him. We have seen the sketch, and it puts us in mind of an hybrid between the water mole and the great sea serpent.' 'Mr. Stocqueler, an artist, and his mother are on an expedition down the Murray, for the purpose of making some faithful sketches of the views on this fine stream, as well as of the creatures frequenting it. I have seen some of their productions, and as they pourtray localities with which I am well acquainted, can pronounce the drawings faithful representations. Mother and son go down the stream in a canoe. The lady paints flowers, &amp;c.; the son devotes himself to choice views on the river's side. One of the drawings represents a singular creature, which the artist is unable to classify. It has the appearance in miniature of the famous sea-serpent, as that animal is described by navigators. Mr. Stocqueler was about twenty-five yards distant from it at first sight as it lay placidly on the water. On being observed, the stranger set-off, working his paddles briskly, and rapidly disappeared. Captain Cadell has tried to solve the mystery, but is not yet satisfied as to what the animal really is. Mr. Stocqueler states that there were about two feet of it above water when he first saw it, and he estimated its length at from five to six feet. The worthy Captain says, that unless the creature is the \"Musk Drake\" (so called from giving off a very strong odour of musk), he cannot account for the novelty.'\nStocqueler disputed the newspaper descriptions in a letter; stating that he never called the animal a bunyip, it did not have a swan like neck, and he never said anything about the size of the animal as he never saw the whole body. He went on to write that all would be revealed in his diorama as an 'almost life size portrait of the beast' would be included. The diorama took him four years to paint and was reputed to be a mile (1.6\u00a0km) long and made of 70 individual pictures. The diorama has long since disappeared and may no longer exist.\nFigure of speech and eponymy.\nBy the 1850s, \"bunyip\" was also used as a \"synonym for impostor, pretender, humbug and the like\", although this use of the word is now obsolete in Australian English. The term \"bunyip aristocracy\" was first coined in 1853 to describe Australians aspiring to be aristocrats. In the early 1990s, Prime Minister Paul Keating used this term to describe members of the conservative Liberal Party of Australia opposition.\nThe word \"bunyip\" can still be found in a number of Australian contexts, including place names such as the Bunyip River (which flows into Westernport Bay in southern Victoria) and the town of Bunyip, Victoria.\nIn popular culture and fiction.\nNumerous tales of the bunyip in written literature appeared in the 19th and early 20th centuries. One of the earliest known is a story in Andrew Lang's \"The Brown Fairy Book\" (1904), adapted from a tale collected and published in the Journal of the Anthropological Institute in 1899.\nThe Australian tourism boom of the 1970s brought a renewed interest in bunyip mythology.\nBunyip stories have also been published outside Australia.\nThe Bunyip has been featured in films as well.\nIn the 21st century, the bunyip has been featured in works around the world.\nFootnotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nSources.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "4508", "revid": "26074453", "url": "https://en.wikipedia.org/wiki?curid=4508", "title": "Brabant", "text": "Brabant is a traditional geographical region (or regions) in the Low Countries of Europe. It may refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nOther uses.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "4509", "revid": "629857938", "url": "https://en.wikipedia.org/wiki?curid=4509", "title": "Back-Cover Texts", "text": ""}
{"id": "4512", "revid": "4904587", "url": "https://en.wikipedia.org/wiki?curid=4512", "title": "Boone, North Carolina", "text": "Town in the United States\nBoone is a town in and the county seat of Watauga County, North Carolina, United States. Located in the Blue Ridge Mountains of western North Carolina, Boone is the home of Appalachian State University and the headquarters of the disaster and medical relief organization Samaritan's Purse. The population was 19,092 at the 2020 census.\nThe town is named for famous American pioneer and explorer Daniel Boone, and every summer from 1952 has hosted an outdoor amphitheatre drama, \"Horn in the West\", portraying the British settlement of the area during the American Revolutionary War and featuring the contributions of its namesake. It is the largest community and the economic hub of the seven-county region of Western North Carolina known as the High Country.\nHistory.\n Boone took its name from the famous pioneer and explorer Daniel Boone, who on several occasions camped at a site generally agreed to be within the present city limits. Daniel's nephews, Jesse and Jonathan (sons of brother Israel Boone), were members of the town's first church, Three Forks Baptist, still in existence today.\nBoone was served by the narrow-gauge East Tennessee and Western North Carolina Railroad (nicknamed \"Tweetsie\") until the flood of 1940. The flood washed away much of the tracks and it was decided not to replace them.\nBoone is the home of Appalachian State University, a constituent member of the University of North Carolina. Appalachian State is the sixth-largest university in the seventeen-campus system. Caldwell Community College &amp; Technical Institute also operates a satellite campus in Boone.\n\"Horn in the West\" is a dramatization of the life and times of the early settlers of the mountain area. It features Daniel Boone as one of its characters, and has been performed in an outdoor amphitheater near the town every summer since 1952, except for when COVID-19 necessitated canceling the 2020 performances.\nThe original actor in the role of \"Daniel Boone\" was Ned Austin. His \"Hollywood Star\" stands on a pedestal on King Street in downtown Boone. He was followed in the role by Glenn Causey, who portrayed the rugged frontiersman for 41 years, and whose image is still seen in many of the depictions of Boone featured in the area today.\nBoone is notable for being home to the Junaluska community. Located in the hills just north of Downtown Boone, a free black community has existed in the area since before the Civil War. Although integration in the mid-20th century led to many of the businesses in the neighborhood closing in favor of their downtown counterparts, descendants of the original inhabitants still live in the neighborhood. Junaluska is also home to one of the few majority-African American Mennonite Brethren congregations.\nBoone is a center for bluegrass musicians and Appalachian storytellers. Notable artists associated with Boone include the late Grammy Award-winning bluegrass guitar player Doc Watson and the late guitarist Michael Houser, one of the founding members of and the lead guitarist for the band Widespread Panic, as well as Old Crow Medicine Show, The Blue Rags, and Eric Church, all who are Boone natives.\nThe Blair Farm, Daniel Boone Hotel, Jones House, John Smith Miller House, and US Post Office-Boone are listed on the National Register of Historic Places.\nThe hellbender is an important cultural symbol of the city and is the namesake of various local establishments and products. In 2024, the Boone Town Council and the Center for Biological Diversity installed a large mural of the hellbender in downtown Boone to raise awareness of the species. In January 2024, Boone passed a resolution supporting the inclusion of the hellbender in the Endangered Species Act of 1973 to better protect its habitat.\nGeography and climate.\nBoone has an elevation of above sea level. An earlier survey gave the elevation as 3,332\u00a0ft and since then it has been published as . Boone has the highest elevation of any town of its size (over 10,000 population) east of the Mississippi River. As such, Boone features, depending on the isotherm used, a warm-summer humid continental climate (K\u00f6ppen \"Dfb\"), a rarity for the Southeastern United States, bordering on an oceanic climate (\"Cfb\") and straddles the boundary between USDA Plant Hardiness Zones 6B and 7A; the elevation also results in enhanced precipitation, with of average annual precipitation. Compared to the lower elevations of the Carolinas, winters are long and cold, with frequent sleet and snowfall. The daily average temperature in January is , which gives Boone a winter climate more similar to coastal southern New England rather than the Southeast, where a humid subtropical climate (\"Cfa)\" predominates. Blizzard-like conditions are not unusual during winters. Summers are warm, but far cooler and less humid than lower regions to the south and east, with a July daily average temperature of . Boone receives on average nearly of snowfall annually, far higher than the lowland areas in the rest of North Carolina. On January 21, 1985, the temperature fell to .\nDemographics.\n&lt;templatestyles src=\"US Census population/styles.css\"/&gt;\n2020 census.\nAs of the 2020 United States census, there were 19,092 people, 5,905 households, and 1,641 families residing in the town.\n2000 census.\nAs of the census of 2000, there were 13,472 people, 4,374 households, and 1,237 families residing in the town. The population density was . There were 4,748 housing units at an average density of . The racial makeup of the town was 93.98% White, 3.42% Black or African American, 0.30% Native American, 1.19% Asian, 0.05% Pacific Islander, 0.46% from other races, and 0.60% from two or more races. 1.64% of the population were Hispanic or Latino of any race.\nThere were 4,374 households, out of which 9.6% had children under the age of 18 living with them, 21.0% were married couples living together, 5.6% had a female householder with no husband present, and 71.7% were non-families. 38.4% of all households were made up of individuals, and 7.3% had someone living alone who was 65 years of age or older. The average household size was 1.97 and the average family size was 2.63.\nIn the town, the population was spread out, with 5.8% under 18, 65.9% from 18 to 24, 12.1% from 25 to 44, 9.1% from 45 to 64, and 7.1% who were 65 or older. The median age was 21 years. For every 100 females, there are 95.6 males. For every 100 females age 18 and over, there were 94.7 males.\nThe median income for a household in the town was $20,541, and the median income for a family was $49,762. The per capita income was $12,256. Males had a median income of $28,060 versus $20,000 for females. About 9.2% of families and 37.0% of the population were below the poverty line, including 6.3% of those under the age of 18 and 9.1% of those 65 and older.\nMedia.\nNewspaper.\nBoone is mainly served by three local newspapers:\nA smaller newspaper, \"The Appalachian\", is Appalachian State University's campus newspaper; it sends out email newsletters twice a week on Tuesdays and Thursdays during the regular academic year and publishes a print publication monthly. In addition to the locally printed papers, a monthly entertainment pamphlet, \"Kraut Creek Revival\", has limited circulation and is funded by a Denver, North Carolina\u2013based newspaper.\nLaw and government.\nBoone operates under a mayor\u2013council government. The city council consists of five members. The mayor presides over the council and casts a vote in the event of a tie. As of December\u00a02021[ [update]], the Town Council members were Mayor Tim Futrelle and Councilors: Jon Dalton George (Mayor Pro-Tem), Virginia Roseman, Todd Carter, Edie Tugman, and Dr. Eric Plaag.\nDevelopment.\nIndustrial, commercial, and residential development in Boone is controversial due to its location in the mountains of Appalachia. On October 16, 2009, the town council accepted the \"Boone 2030 Land Use Plan.\" The document is not in any way law, but is used by the town council, board of adjustment, and other committees to guide decision-making as to what types of development are appropriate.\nIn 2009, the North Carolina Department of Transportation began widening 1.1 miles of U.S. 421 (King Street) to a 4-to-6-lane divided highway with a raised concrete median from U.S. 321 (Hardin Street) to east of N.C. 194 (Jefferson Road), including a new entrance and exit to the new Watauga High School, at a cost of $16.2 million. The widening has displaced 25 businesses and 63 residences east of King Street. The project was slated to be completed by December 31, 2011, but construction continued into 2012.\nSports.\nBoone is home to the Appalachian State Mountaineers, which field varsity teams in 17 sports, 7 for men and 10 for women. Appalachian State's football program has been successful with the Mountaineers winning three straight national championships in 2005, 2006, and 2007, the only team in North Carolina, public or private, to win an NCAA national championship in football.\nAside from college sports, Boone also has local baseball and soccer teams. The Boone Bigfoots were formed in 2021 and compete in the Coastal Plain League, a wood-bat collegiate summer baseball league. The Bigfoots play their home games at Beaver Field at Jim and Bettie Smith Stadium. Boone's entry in the National Premier Soccer League is Appalachian FC, which plays home games at ASU Soccer Stadium in the Ted Mackorell Soccer Complex.\nSister city.\nBoone has one sister city, as designated by Sister Cities International:\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "4513", "revid": "44402255", "url": "https://en.wikipedia.org/wiki?curid=4513", "title": "Banshee", "text": "Female spirit in Irish mythology\nA banshee ( ; Modern Irish , from , \"woman of the fairy mound\" or \"fairy woman\") is a female spirit in Irish folklore who heralds the death of a family member, usually by screaming, wailing, shrieking, or keening. Her name is connected to the mythologically important tumuli or \"mounds\" that dot the Irish countryside, which are known as (singular ) in Old Irish.\nDescription.\nSometimes she has long streaming hair, which she may be seen combing, with some legends specifying she can only keen while combing her hair. She wears a grey cloak over a green dress, and her eyes are red from continual weeping. She may be dressed in white with red hair and a ghastly complexion, according to a firsthand account by Ann, Lady Fanshawe in her \"Memoirs\". Lady Wilde in her books provides others:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The size of the banshee is another physical feature that differs between regional accounts. Though some accounts of her standing unnaturally tall are recorded, the majority of tales that describe her height state the banshee's stature as short, anywhere between one foot and four feet. Her exceptional shortness often goes alongside the description of her as an old woman, though it may also be intended to emphasize her state as a fairy creature.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Sometimes the banshee assumes the form of some sweet-singing virgin of the family who died young, and has been given the mission by the invisible powers to become the harbinger of coming doom to her mortal kindred. Or she may be seen at night as a shrouded woman, crouched beneath the trees, lamenting with a veiled face; or flying past in the moonlight, crying bitterly: and the cry of this spirit is mournful beyond all other sounds on earth, and betokens certain death to some member of the family whenever it is heard in the silence of the night.\nIn John O'Brien's Irish-English dictionary, the entry for S\u00edth-Bhr\u00f3g states:\"hence \"bean-s\u00edghe\", plural \"mn\u00e1-s\u00edghe\", she-fairies or women-fairies, credulously supposed by the common people to be so affected to certain families that they are heard to sing mournful lamentations about their houses by night, whenever any of the family labours under a sickness which is to end by death, but no families which are not of an ancient &amp; noble Stock, are believed to be honoured with this fairy privilege\".\nKeening.\nIn Ireland and parts of Scotland, a traditional part of mourning is the keening woman (), who wails a lament \u2014in ('weeping'), pronounced in the Irish dialects of Munster and southern County Galway, in Connacht (except south Galway) and (particularly west) Ulster, and in Ulster, particularly in the traditional dialects of north and east Ulster, including County Louth. This keening woman may in some cases be a professional, and the best keeners would be in high demand.\nIrish legend speaks of a lament being sung by a fairy woman, or banshee. She would sing it when a family member died or was about to die, even if the person had died far away and news of their death had not yet come. In those cases, her wailing would be the first warning the household had of the death. The banshee is also a predictor of death. If someone is about to enter a situation where it is unlikely they will come out alive she will warn people by screaming or wailing, giving rise to a banshee also being known as a wailing woman. The banshee was also associated with the death coach, being said to either summon it with her keening or to travel in tandem with it.\nWhen several banshees appear at once, it indicates the death of someone great or holy. The tales sometimes recounted that the woman, though called a fairy, was a ghost, often of a specific murdered woman, or a mother who died in childbirth.\nIn some parts of Leinster, she is referred to as the ('keening woman') whose wail can be so piercing that it shatters glass. In Scottish folklore, a similar creature is known as the or ('little washerwoman') or ('little washer at the ford') and is seen washing the bloodstained clothes or armour of those who are about to die. In Welsh folklore, a similar creature is known as the cyhyraeth.\nAccounts reach as far back as 1380 to the publication of the \"Cathreim Thoirdhealbhaigh\" (\"Triumphs of Torlough\") by Sean mac Craith. Mentions of banshees can also be found in Norman literature of that time.\nAssociated families.\nSome sources suggest that the banshee laments only the descendants of the \"pure Milesian stock\" of Ireland, with the original belief appearing to associate the folklore with a number of ancient Irish families. According to this tradition, a banshee would not lament or visit someone of Saxon or Norman descent or who came to Ireland later. Most, but not all, surnames associated with banshees have the \"\u00d3\" or \"Mc/Mac\" prefix \u2013 that is, surnames of Goidelic origin, indicating a family native to the Insular Celtic lands rather than those of the Norse, Anglo-Saxon, or Norman. \nThere are some exceptions to this lore, including that a banshee may lament a person who had been \"gifted with music and song\". For example, there are accounts of the Geraldines hearing a banshee \u2013 as they had reputedly become \"more Irish than the Irish themselves\" \u2013 and that the Bunworth Banshee, associated with the Rev. Charles Bunworth (a name of Anglo-Saxon origin), heralded the death of an Irish person who had been a patron to musicians.\nAccording to tradition, some families had their own banshee, with the Ua Briain banshee, named Aibell, being the ruler of 25 other banshees who would always be at her attendance.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "4514", "revid": "45390579", "url": "https://en.wikipedia.org/wiki?curid=4514", "title": "Genetically modified maize", "text": "Genetically modified crop\nGenetically modified maize (corn) is a genetically modified crop. Specific maize strains have been genetically engineered to express agriculturally-desirable traits, including resistance to pests and to herbicides. Maize strains with both traits are now in use in multiple countries. GM maize has also caused controversy with respect to possible health effects, impact on other insects and impact on other plants via gene flow. One strain, called Starlink, was approved only for animal feed in the US but was found in food, leading to a series of recalls starting in 2000.\n&lt;templatestyles src=\"Template:TOC limit/styles.css\" /&gt;\nMarketed products.\nHerbicide-resistant maize.\nCorn varieties resistant to glyphosate herbicides were first commercialized in 1996 by Monsanto, and are known as \"Roundup Ready Corn\". They tolerate the use of Roundup. Bayer CropScience developed \"Liberty Link Corn\" that is resistant to glufosinate. Pioneer Hi-Bred has developed and markets corn hybrids with tolerance to imidazoline herbicides under the trademark \"Clearfield\" \u2013 though in these hybrids, the herbicide-tolerance trait was bred using tissue culture selection and the chemical mutagen ethyl methanesulfonate, not genetic engineering. Consequently, the regulatory framework governing the approval of transgenic crops does not apply for Clearfield.\nAs of 2011, herbicide-resistant GM corn was grown in 14 countries. By 2012, 26 varieties of herbicide-resistant GM maize were authorised for import into the European Union, but such imports remain controversial. Cultivation of herbicide-resistant corn in the EU provides substantial farm-level benefits.\nInsect-resistant corn.\nBt maize/corn.\n&lt;templatestyles src=\"Template:Visible anchor/styles.css\" /&gt;Bt maize/&lt;templatestyles src=\"Template:Visible anchor/styles.css\" /&gt;Bt corn is a variant of maize that has been genetically altered to express one or more proteins from the bacterium \"Bacillus thuringiensis\" including Delta endotoxins. The protein is poisonous to certain insect pests. Spores of the bacillus are widely used in organic gardening, although GM corn is not considered organic. The European corn borer causes about a billion dollars in damage to corn crops each year.\nIn recent years, traits have been added to ward off corn ear worms and root worms, the latter of which annually causes about a billion dollars in damages.\nThe Bt protein is expressed throughout the plant. When a vulnerable insect eats the Bt-containing plant, the protein is activated in its gut, which is alkaline. In the alkaline environment, the protein partially unfolds and is cut by other proteins, forming a toxin that paralyzes the insect's digestive system and forms holes in the gut wall. The insect stops eating within a few hours and eventually starves.\nIn 1996, the first GM maize producing a Bt Cry protein was approved, which killed the European corn borer and related species; subsequent Bt genes were introduced that killed corn rootworm larvae.\nThe Philippine Government has promoted Bt corn, hoping for insect resistance and higher yields.\nApproved Bt genes include single and stacked (event names bracketed) configurations of: Cry1A.105 (MON89034), CryIAb (MON810), CryIF (1507), Cry2Ab (MON89034), Cry3Bb1 (MON863 and MON88017), Cry34Ab1 (59122), Cry35Ab1 (59122), mCry3A (MIR604), and Vip3A (MIR162), in both corn and cotton. Corn genetically modified to produce VIP was first approved in the US in 2010.\nA 2018 study found that Bt-corn protected nearby fields of non-Bt corn and nearby vegetable crops, reducing the use of pesticides on those crops. Data from 1976 to 1996 (before Bt corn was widespread) was compared to data after it was adopted (1996\u20132016). They examined levels of the European corn borer and corn earworm. Their larvae eat a variety of crops, including peppers and green beans. Between 1992 and 2016, the amount of insecticide applied to New Jersey pepper fields decreased by 85 percent. Another factor was the introduction of more effective pesticides that were applied less often.\nSweet Corn.\nGM sweet corn varieties include \"Attribute\", the brand name for insect-resistant sweet corn developed by Syngenta and \"Performance Series\" insect-resistant sweet corn developed by Monsanto.\nCuba.\nWhile Cuba's agriculture is largely focused on organic production, as of 2010, the country had developed a variety of genetically modified corn that is resistant to the palomilla moth.\nDrought-resistant maize.\nIn 2013 Monsanto launched the first transgenic drought tolerance trait in a line of corn hybrids called DroughtGard. The MON 87460 trait is provided by the insertion of the cspB gene from the soil microbe \"Bacillus subtilis\"; it was approved by the USDA in 2011 and by China in 2013.\nHealth Safety.\nIn regular corn crops, insects promote fungal colonization by creating \"wounds,\" or holes, in corn kernels. These wounds are favored by fungal spores for germination, which subsequently leads to mycotoxin accumulation in the crop that can be carcinogenic and toxic to humans and other animals. This can prove to be especially devastating in developing countries with drastic climate patterns such as high temperatures, which favor the development of toxic fungi. In addition, higher mycotoxin levels leads to market rejection or reduced market prices for the grain. GM corn crops encounter fewer insect attacks, and thus, have lower concentrations of mycotoxins. Fewer insect attacks also keep corn ears from being damaged, which increases overall yields.\nProducts in development.\nIn 2007, South African researchers announced the production of transgenic maize resistant to maize streak virus (MSV), although it has not been released as a product. While breeding cultivars for resistance to MSV isn't done in the public, the private sector, international research centers, and national programmes have done all of the breeding. As of 2014, there have been a few MSV-tolerant cultivars released in Africa. A private company \"Seedco\" has released 5 MSV cultivars.\nResearch has been done on adding a single \"E. coli\" gene to maize to enable it to be grown with an essential amino acid (methionine).\nRefuges.\nUS Environmental Protection Agency (EPA) regulations require farmers who plant Bt corn to plant non-Bt corn nearby (called a refuge), with the logic that pests will infest the non-Bt corn and thus will not evolve a resistance to the Bt toxin. Typically, 20% of corn in a grower's fields must be refuge; refuge must be at least 0.5 miles from Bt corn for lepidopteran pests, and refuge for corn rootworm must at least be adjacent to a Bt field. EPA regulations also require seed companies to train farmers how to maintain refuges, to collect data on the refuges and to report that data to the EPA. A study of these reports found that from 2003 to 2005 farmer compliance with keeping refuges was above 90%, but that by 2008 approximately 25% of Bt corn farmers did not keep refuges properly, raising concerns that resistance would develop.\nUnmodified crops received most of the economic benefits of Bt corn in the US in 1996\u20132007, because of the overall reduction of pest populations. This reduction came because females laid eggs on modified and unmodified strains alike, but pest organisms that develop on the modified strain are eliminated.\nSeed bags containing both Bt and refuge seed have been approved by the EPA in the United States. These seed mixtures were marketed as \"Refuge in a Bag\" (RIB) to increase farmer compliance with refuge requirements and reduce additional work needed at planting from having separate Bt and refuge seed bags on hand. The EPA approved a lower percentage of refuge seed in these seed mixtures ranging from 5 to 10%. This strategy is likely to reduce the likelihood of Bt-resistance occurring for corn rootworm, but may increase the risk of resistance for lepidopteran pests, such as European corn borer. Increased concerns for resistance with seed mixtures include partially resistant larvae on a Bt plant being able to move to a susceptible plant to survive or cross pollination of refuge pollen on to Bt plants that can lower the amount of Bt expressed in kernels for ear feeding insects.\nResistance.\nResistant strains of the European corn borer have developed in areas with defective or absent refuge management. In 2012, a Florida field trial demonstrated that army worms were resistant to Bt maize produced by Dupont-Dow; armyworm resistance was first discovered in Puerto Rico in 2006, prompting Dow and DuPont to voluntarily stop selling the product on the island.\nRegulation.\nRegulation of GM crops varies between countries, with some of the most-marked differences occurring between the US and Europe. Regulation varies in a given country depending on intended uses.\nControversy.\nThere is a scientific consensus that currently available food derived from GM crops poses no greater risk to human health than conventional food, but that each GM food needs to be tested on a case-by-case basis before introduction. Nonetheless, members of the public are much less likely than scientists to perceive GM foods as safe. The legal and regulatory status of GM foods varies by country, with some nations banning or restricting them, and others permitting them with widely differing degrees of regulation.\nThe scientific rigor of the studies regarding human health has been disputed due to alleged lack of independence and due to conflicts of interest involving governing bodies and some of those who perform and evaluate the studies. However, no reports of ill effects from GM food have been documented in the human population.\nGM crops provide a number of ecological benefits, but there are also concerns for their overuse, stalled research outside of the Bt seed industry, proper management and issues with Bt resistance arising from their misuse.\nCritics have objected to GM crops on ecological, economic and health grounds. The economic issues derive from those organisms that are subject to intellectual property law, mostly patents. The first generation of GM crops lose patent protection beginning in 2015. Monsanto has claimed it will not pursue farmers who retain seeds of off-patent varieties. These controversies have led to litigation, international trade disputes, protests and to restrictive legislation in most countries.\nIntroduction of Bt maize led to significant reduction of mycotoxin-related poisoning and cancer rates, as they were significantly less prone to contain mycotoxins (29%), fumonisins (31%) and thricotecens (37%), all of which are toxic and carcinogenic.\nEffects on nontarget insects.\nCritics claim that Bt proteins could target predatory and other beneficial or harmless insects as well as the targeted pest. These proteins have been used as organic sprays for insect control in France since 1938 and the USA since 1958 with no ill effects on the environment reported. While \"cyt\" proteins are toxic towards the insect order Diptera (flies), certain \"cry\" proteins selectively target lepidopterans (moths and butterflies), while other \"cyt\" selectively target Coleoptera. As a toxic mechanism, \"cry\" proteins bind to specific receptors on the membranes of mid-gut (epithelial) cells, resulting in rupture of those cells. Any organism that lacks the appropriate gut receptors cannot be affected by the \"cry\" protein, and therefore Bt. Regulatory agencies assess the potential for the transgenic plant to impact nontarget organisms before approving commercial release.\nA 1999 study found that in a lab environment, pollen from Bt maize dusted onto milkweed could harm the monarch butterfly. Several groups later studied the phenomenon in both the field and the laboratory, resulting in a risk assessment that concluded that any risk posed by the corn to butterfly populations under real-world conditions was negligible. A 2002 review of the scientific literature concluded that \"the commercial large-scale cultivation of current Bt\u2013maize hybrids did not pose a significant risk to the monarch population\". A 2007 review found that \"nontarget invertebrates are generally more abundant in Bt cotton and Bt maize fields than in nontransgenic fields managed with insecticides. However, in comparison with insecticide-free control fields, certain nontarget taxa are less abundant in Bt fields.\"\nGene flow.\nGene flow is the transfer of genes and/or alleles from one species to another. Concerns focus on the interaction between GM and other maize varieties in Mexico, and of gene flow into refuges.\nIn 2009 the government of Mexico created a regulatory pathway for genetically modified maize, but because Mexico is the center of diversity for maize, gene flow could affect a large fraction of the world's maize strains. A 2001 report in \"Nature\" presented evidence that Bt maize was cross-breeding with unmodified maize in Mexico. The data in this paper was later described as originating from an artifact. \"Nature\" later stated, \"the evidence available is not sufficient to justify the publication of the original paper\". A 2005 large-scale study failed to find any evidence of contamination in Oaxaca. However, other authors also found evidence of cross-breeding between natural maize and transgenic maize.\nA 2004 study found Bt protein in kernels of refuge corn.\nIn 2017, a large-scale study found \"pervasive presence of transgenes and glyphosate in maize-derived food in Mexico\"\nFood.\nThe French High Council of Biotechnologies Scientific Committee reviewed the 2009 Vend\u00f4mois \"et al.\" study and concluded that it \"presents no admissible scientific element likely to ascribe any haematological, hepatic or renal toxicity to the three re-analysed GMOs.\" However, the French government applies the precautionary principle with respect to GMOs.\nA review by Food Standards Australia New Zealand and others of the same study concluded that the results were due to chance alone.\nA 2011 Canadian study looked at the presence of CryAb1 protein (BT toxin) in non-pregnant women, pregnant women and fetal blood. All groups had detectable levels of the protein, including 93% of pregnant women and 80% of fetuses at concentrations of 0.19 \u00b1 0.30 and 0.04 \u00b1 0.04 mean \u00b1 SD ng/ml, respectively. The paper did not discuss safety implications or find any health problems. FSANZ agency published a comment pointing out a number of inconsistencies in the paper, most notably that it \"does not provide any evidence that GM foods are the source of the protein\".\nIn January 2013, the European Food Safety Authority released all data submitted by Monsanto in relation to the 2003 authorisation of maize genetically modified for glyphosate tolerance.\nStarlink corn recalls.\nStarLink contains Cry9C, which had not previously been used in a GM crop. Starlink's creator, Plant Genetic Systems, had applied to the US Environmental Protection Agency (EPA) to market Starlink for use in animal feed and in human food. However, because the Cry9C protein lasts longer in the digestive system than other Bt proteins, the EPA had concerns about its allergenicity, and PGS did not provide sufficient data to prove that Cry9C was not allergenic. As a result, PGS split its application into separate permits for use in food and use in animal feed. Starlink was approved by the EPA for use in animal feed only in May 1998.\nStarLink corn was subsequently found in food destined for consumption by humans in the US, Japan, and South Korea. This corn became the subject of the widely publicized Starlink corn recall, which started when Taco Bell-branded taco shells sold in supermarkets were found to contain the corn. Sales of StarLink seed were discontinued. The registration for Starlink varieties was voluntarily withdrawn by Aventis in October 2000. Pioneer had been bought by AgrEvo which then became Aventis CropScience at the time of the incident, which was later bought by Bayer.\nFifty-one people reported adverse effects to the FDA; US Centers for Disease Control (CDC), which determined that 28 of them were possibly related to Starlink. However, the CDC studied the blood of these 28 individuals and concluded there was no evidence of hypersensitivity to the Starlink Bt protein.\nA subsequent review of these tests by the Federal Insecticide, Fungicide, and Rodenticide Act Scientific Advisory Panel points out that while \"the negative results decrease the probability that the Cry9C protein is the cause of allergic symptoms in the individuals examined ... in the absence of a positive control and questions regarding the sensitivity and specificity of the assay, it is not possible to assign a negative predictive value to this.\"\nThe US corn supply has been monitored for the presence of the Starlink Bt proteins since 2001.\nIn 2005, aid sent by the UN and the US to Central American nations also contained some StarLink corn. The nations involved, Nicaragua, Honduras, El Salvador and Guatemala refused to accept the aid.\nCorporate espionage.\nOn 19 December 2013 six Chinese citizens were indicted in Iowa on charges of plotting to steal genetically modified seeds worth tens of millions of dollars from Monsanto and DuPont. Mo Hailong, director of international business at the Beijing Dabeinong Technology Group Co., part of the Beijing-based DBN Group, was accused of stealing trade secrets after he was found digging in an Iowa cornfield.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "4516", "revid": "38205273", "url": "https://en.wikipedia.org/wiki?curid=4516", "title": "Body substance isolation", "text": "Body substance isolation is a practice of isolating all body substances (blood, urine, feces, tears, etc.) of individuals undergoing medical treatment, particularly emergency medical treatment of those who might be infected with illnesses such as HIV, or hepatitis so as to reduce as much as possible the chances of transmitting these illnesses. BSI is similar in nature to universal precautions, but goes further in isolating workers from pathogens, including substances now known to carry HIV.\nPlace of body substance isolation practice in history.\nPractice of Universal precautions was introduced in 1985\u201388. In 1987, the practice of Universal precautions was adjusted by a set of rules known as body substance isolation. In 1996, both practices were replaced by the latest approach known as standard precautions (health care). Nowadays and in isolation, practice of body substance isolation has just historical significance.\nBody substance isolation went further than universal precautions in isolating workers from pathogens, including substances now currently known to carry HIV. These pathogens fall into two broad categories, bloodborne (carried in the body fluids) and airborne. The practice of BSI was common in Pre-Hospital care and emergency medical services due to the often unknown nature of the patient and his/her disease or medical conditions. It was a part of the National Standards Curriculum for Prehospital Providers and Firefighters.Types of body substance isolation included:\nIt was postulated that BSI precautions should be practiced in environment where treaters were exposed to bodily fluids, such as:\nSuch infection control techniques that were recommended following the AIDS outbreak in the 1980s. Every patient was treated as if infected and therefore precautions were taken to minimize risk. Other conditions which called for minimizing risks with BSI:\nor any combination of the above.\nFootnotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "4517", "revid": "7852030", "url": "https://en.wikipedia.org/wiki?curid=4517", "title": "Boudica", "text": "Queen of the British Iceni tribe (d. 60/61)\nBoudica or Boudicca (, from Brythonic * 'victory, win' + * 'having' suffix, i.e. 'Victorious Woman', known in Latin chronicles as Boadicea or Boudicea, and in Welsh as , ) was a queen of the ancient British Iceni tribe, who led a failed uprising against the conquering forces of the Roman Empire in AD 60 or 61. She is considered a British national heroine and a symbol of the struggle for justice and independence.\nBoudica's husband Prasutagus, with whom she had two daughters, ruled as a nominally independent ally of Rome. He left his kingdom jointly to his daughters and to the Roman emperor in his will. When he died, his will was ignored, and the kingdom was annexed and his property taken. According to the Roman historian Tacitus, Boudica was flogged and her daughters raped. The historian Cassius Dio wrote that previous imperial donations to influential Britons were confiscated and the Roman financier and philosopher Seneca called in the loans he had forced on the reluctant Britons.\nIn 60/61, Boudica led the Iceni and other British tribes in revolt. They destroyed Camulodunum (modern Colchester), earlier the capital of the Trinovantes, but at that time a for discharged Roman soldiers. Upon hearing of the revolt, the Roman governor Gaius Suetonius Paulinus hurried from the island of Mona (modern Anglesey) to Londinium, the 20-year-old commercial settlement that was the rebels' next target. Unable to defend the settlement, he abandoned it. Boudica's army defeated a detachment of the Legio IX Hispana, and burnt both Londinium and Verulamium. In all, an estimated 70,000\u201380,000 Romans and Britons were killed by Boudica's followers. Suetonius, meanwhile, regrouped his forces, possibly in the West Midlands, and despite being heavily outnumbered, he decisively defeated the Britons. Boudica died, by suicide or illness, shortly afterwards. The crisis of 60/61 caused Nero to consider withdrawing all his imperial forces from Britain, but Suetonius's victory over Boudica confirmed Roman control of the province.\nInterest in these events was revived in the English Renaissance and led to Boudica's fame in the Victorian era and as a cultural symbol in Britain.\nHistorical sources.\nThe Boudican revolt against the Roman Empire is referred to in four works from classical antiquity written by three Roman historians: the \"Agricola\" (c.\u200998) and \"Annals\" (c.\u2009110s) by Tacitus; a mention of the uprising by Suetonius in his \"Lives of the Caesars\" (121); and the longest account, a detailed description of the revolt contained within Cassius Dio's history of the Empire (c.\u2009202\u00a0\u2013 c.\u2009235).\nTacitus wrote some years after the rebellion, but his father-in-law Gnaeus Julius Agricola was an eyewitness to the events, having served in Britain as a tribune under Suetonius Paulinus during this period.\nCassius Dio began his history of Rome and its empire about 140 years after Boudica's death. Much is lost and his account of Boudica survives only in the epitome of an 11th-century Byzantine monk, John Xiphilinus. He provides greater and more lurid detail than Tacitus, but in general his details are often fictitious.\nBoth Tacitus and Dio give an account of battle-speeches given by Boudica, though it is thought that her words were never recorded during her life. Although imaginary, these speeches, designed to provide a comparison for readers of the antagonists' demands and approaches to war, and to portray the Romans as morally superior to their enemy, helped create an image of patriotism that turned Boudica into a legendary figure.\nBackground.\nBoudica was the consort of Prasutagus, king of the Iceni, a tribe who inhabited what is now the English county of Norfolk and parts of the neighbouring counties of Cambridgeshire, Suffolk and Lincolnshire. The Iceni produced some of the earliest known British coins. They had revolted against the Romans in 47 when the Roman governor Publius Ostorius Scapula planned to disarm all the peoples of Britain under Roman control. The Romans allowed the kingdom to retain its independence once the uprising was suppressed.\nEvents leading to the revolt.\nOn his death in AD 60/61, Prasutagus made his two daughters as well as the Roman Emperor Nero his heirs. The Romans ignored the will, and the kingdom was absorbed into the province of Britannia. Catus Decianus, procurator of Britain, was sent to secure the Iceni kingdom for Rome.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\n\"Have we not been robbed entirely of most of our possessions, and those the greatest, while for those that remain we pay taxes? Besides pasturing and tilling for them all our other possessions, do we not pay a yearly tribute for our very bodies? How much better it would be to have been sold to masters once for all than, possessing empty titles of freedom, to have to ransom ourselves every year! How much better to have been slain and to have perished than to go about with a tax on our heads!... Among the rest of mankind death frees even those who are in slavery to others; only in the case of the Romans do the very dead remain alive for their profit. Why is it that, though none of us has any money (how, indeed, could we, or where would we get it?), we are stripped and despoiled like a murderer's victims? And why should the Romans be expected to display moderation as time goes on, when they have behaved toward us in this fashion at the very outset, when all men show consideration even for the beasts they have newly captured?\"\n\u2014Part of a speech Cassius Dio gives Boudica\nThe Romans' next actions were described by Tacitus, who detailed pillaging of the countryside, the ransacking of the king's household, and the brutal treatment of Boudica and her daughters. According to Tacitus, Boudica was flogged and her daughters were raped. These abuses are not mentioned in Dio's account, who instead cites three different causes for the rebellion: the recalling of loans that were given to the Britons by Seneca; Decianus Catus's confiscation of money formerly loaned to the Britons by the Emperor Claudius; and Boudica's own entreaties. The loans were thought by the Iceni to have been repaid by gift exchange.\nDio gives Boudica a speech to her people and their allies reminding them that life was much better before the Roman occupation, stressing that wealth cannot be enjoyed under slavery and placing the blame upon herself for not expelling the Romans as they had done when Julius Caesar invaded. The willingness of those seen as barbarians to sacrifice a higher quality of living under the Romans in exchange for their freedom and personal liberty was an important part of what Dio considered to be motivation for the rebellions.\nUprising.\nAttacks on Camulodunum, Londinium and Verulamium.\nThe first target of the rebels was Camulodunum (modern Colchester), a Roman for retired soldiers. A Roman temple had been erected there to Claudius, at great expense to the local population. Combined with brutal treatment of the Britons by the veterans, this had caused resentment towards the Romans.\nThe Iceni and the Trinovantes comprised an army of 120,000 men. Dio claimed that Boudica called upon the British goddess of victory Andraste to aid her army. Once the revolt had begun, the only Roman troops available to provide assistance, aside from the few within the colony, were 200 auxiliaries located in London, who were not equipped to fight Boudica's army. Camulodunum was captured by the rebels; those inhabitants who survived the initial attack took refuge in the Temple of Claudius for two days before they were killed. Quintus Petillius Cerialis, then commanding the Legio IX \"Hispana\", attempted to relieve Camulodunum, but suffered an overwhelming defeat. The infantry with him were all killed and only the commander and some of his cavalry escaped. After this disaster, Catus Decianus, whose behaviour had provoked the rebellion, fled abroad to Gaul.\nSuetonius was leading a campaign against the island of Mona, off the coast of North Wales. On hearing the news of the Iceni uprising, he left a garrison on Mona and returned to deal with Boudica. He moved quickly with a force of men through hostile territory to Londinium, which he reached before the arrival of Boudica's army but, outnumbered, he decided to abandon the town to the rebels, who burned it down after torturing and killing everyone who had remained. The rebels also sacked the \"municipium\" of Verulamium (modern St Albans), north-west of London, though the extent of its destruction is unclear.\nDio and Tacitus both reported that around 80,000 people were said to have been killed by the rebels. According to Tacitus, the Britons had no interest in taking the Roman population as prisoners, only in slaughter by \"gibbet, fire, or cross\". Dio adds that the noblest women were impaled on spikes and had their breasts cut off and sewn to their mouths, \"to the accompaniment of sacrifices, banquets, and wanton behaviour\" in sacred places, particularly the groves of Andraste.\nDefeat and death.\nSuetonius regrouped his forces. He amassed an army of almost 10,000 men at an unidentified location, and took a stand in a defile (a narrow pass) with a wood behind. The Romans used the terrain to their advantage, launching javelins at the Britons before advancing in a wedge-shaped formation and deploying cavalry.\nAncient sources say, that the Roman army was outnumbered but Boudica's army was crushed, and according to Tacitus, neither the women nor the animals were spared. Tacitus states that Boudica poisoned herself; Dio says she fell sick and died, after which she was given a lavish burial. It has been argued that these accounts are not mutually exclusive.\nName.\n\"Boudica\" may have been an honorific title, in which case the name by which she was known during most of her life is unknown. The English linguist and translator Kenneth Jackson concluded that the name \"Boudica\"\u2014based on later developments in Welsh () and Irish ()\u2014derives from the Proto-Celtic feminine adjective *\"boud\u012bk\u0101\" 'victorious', which in turn is derived from the Celtic word *\"boud\u0101\" 'victory', and that the correct spelling of the name in Common Brittonic (the British Celtic language) is \"\", pronounced . Variations on the historically correct \"Boudica\" include \"Boudicca\", \"Bonduca\", \"Boadicea\", and \"Buduica\". The Gaulish version of her name is attested in inscriptions as \"Boudiga\" in Bordeaux, \"Boudica\" in Lusitania, and \"Bodicca\" in Algeria.\nBoudica's name was spelt incorrectly by Dio, who used \"Buduica\". Her name was also misspelled by Tacitus, who added a second 'c.' After the misspelling was copied by a medieval scribe, further variations began to appear. Along with the second 'c' becoming an 'e,' an 'a' appeared in place of the 'u', which produced the medieval (and most common) version of the name, \"Boadicea\". The true spelling was totally obscured when \"Boadicea\" first appeared in around the 17th century. William Cowper used this spelling in his poem \"Boadicea, an Ode\" (1782), which readapted Boudica's story to fit the context of Britain's rising territorial and political ambitions.\nEarly literature.\nOne of the earliest possible mentions of Boudica (excluding Tacitus' and Dio's accounts) was the 6th-century work by the British monk Gildas. In it, he demonstrates his knowledge of a female leader whom he describes as a \"treacherous lioness\" who \"butchered the governors who had been left to give fuller voice and strength to the endeavours of Roman rule.\"\nBoth Bede's \"Ecclesiastical History of the English People\" (731) and the 9th-century work \"Historia Brittonum\" by the Welsh monk Nennius include references to the uprising of 60/61, but do not mention Boudica.\nNo contemporary description of Boudica exists. Dio, writing more than a century after her death, provided a detailed description of the Iceni queen (translated in 1925): \"In stature she was very tall, in appearance most terrifying, in the glance of her eye most fierce, and her voice was harsh; a great mass of the tawniest hair fell to her hips; around her neck was a large golden necklace; and she wore a tunic of divers colours over which a thick mantle was fastened with a brooch. This was her invariable attire.\"\nRevival and the modern legend.\n16th and 17th century literature.\nDuring the Renaissance the works of Tacitus and Cassius Dio became available in England, after which her status changed as it was interpreted by historians, poets and dramatists. Boudica appeared as 'Voadicia' in a history, \"Anglica Historia\", by the Italian scholar Polydore Vergil, and in the Scottish historian Hector Boece's \"The History and Chronicles of Scotland\" (1526) she is 'Voada'\u2014the first appearance of Boudica in a British publication.\nBoudica was called 'Voadicia' in the English historian Raphael Holinshed's \"Chronicles\", published between 1577 and 1587. A narrative by the Florentine scholar Petruccio Ubaldini in \"The Lives of the Noble Ladies of the Kingdom of England and Scotland\" (1591) includes two female characters, 'Voadicia' and 'Bunduica', both based on Boudica. From the 1570s to the 1590s, when Elizabeth I's England was at war with Spain, Boudica proved to be a valuable asset for the English.\nThe English poet Edmund Spenser used the story of Boudica in his poem \"The Ruines of Time\", involving a story about a British heroine he called 'Bunduca'. A variation of this name was used in the Jacobean play \"Bonduca\" (1612), a tragicomedy that most scholars agree was written by John Fletcher, in which one of the characters was Boudica. A version of that play called \"Bonduca, or the British Heroine\" was set to music by the English composer Henry Purcell in 1695. One of the choruses, \"Britons, Strike Home!\", became a popular patriotic song in Britain during the 18th and 19th centuries.\nDepiction during the 18th and 19th centuries.\nDuring the late 18th century, Boudica was used to develop ideas of English national identity. Illustrations of Boudica during this period\u2014such as in Edward Barnard's \"New, Complete and Authentic History of England\" (1790) and the drawing by Thomas Stothard of the queen as a classical heroine\u2014lacked historical accuracy. The illustration of Boudica by Robert Havell in Charles Hamilton Smith's \"The Costume of the Original Inhabitants of the British Islands from the Earliest Periods to the Sixth Century\" (1815) was an early attempt to depict her in an historically accurate way.\nCowper's 1782 poem \"Boadicea: An Ode\" was the most notable literary work to champion the resistance of the Britons, fostering an \"asexual image of British triumph and heroism.\" It led Boudica to become a cultural icon and national heroine in Britain. Alfred, Lord Tennyson's poem \"Bo\u00e4dic\u00e9a\", which was written in 1859 and published in 1864, drew on Cowper's poem. Depicting the Iceni queen as a violent and bloodthirsty warrior, the poem also forecasted the rise of the British Empire. Tennyson's image of Boudica was taken from the engraving produced in 1812 by Stothard. Another work, the poem \"Boadicea\" (1859) by Francis Barker, contained strongly patriotic and Christian themes.\nA range of Victorian children's books mentioned Boudica; \"Beric the Briton\" (1893), a novel by G. A. Henty, with illustrations by William Parkinson, had a text based on the accounts of Tacitus and Dio.\n\"Boadicea and Her Daughters\", a statue of the queen in her war chariot, complete with anachronistic scythes on the wheel axles, was executed by the sculptor Thomas Thornycroft. He was encouraged by Prince Albert, who lent his horses for use as models. The statue, Thornycroft's most ambitious work, was produced between 1856 and 1871, cast in 1896, and positioned on the Victoria Embankment next to Westminster Bridge in 1902.\n20th century \u2013 present.\nBoudica was once thought to have been buried at a place which lies now between platforms 9 and 10 in King's Cross station in London. There is no evidence for this and it is probably a post-World War II invention. At Colchester Town Hall, a life-sized statue of Boudica stands on the south facade, sculpted by L J Watts in 1902; another depiction of her is in a stained glass window by Clayton and Bell in the council chamber.\nBoudica was adopted by the suffragettes as one of the symbols of the campaign for women's suffrage. In 1908, a \"Boadicea Banner\" was carried in several National Union of Women's Suffrage Societies marches. She appears as a character in \"A Pageant of Great Women\" written by Cicely Hamilton, which opened at the Scala Theatre, London, in November 1909 before a national tour, and she was described in a 1909 pamphlet as \"the eternal feminine... the guardian of the hearth, the avenger of its wrongs upon the defacer and the despoiler\".\nA \"vocal minority\" has claimed Boudica as a Celtic Welsh heroine. A statue of Boudica in the Marble Hall at Cardiff City Hall was among those unveiled by David Lloyd George in 1916, though the choice had gained little support in a public vote. It shows her with her daughters and without warrior trappings.\nPermanent exhibitions describing the Boudican Revolt are at the Museum of London, Colchester Castle Museum and the Verulamium Museum in St Albans. A long distance footpath called Boudica's Way passes through countryside between Norwich and Diss in Norfolk.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "4518", "revid": "30585864", "url": "https://en.wikipedia.org/wiki?curid=4518", "title": "Borneo", "text": "Island in Southeast Asia\nBorneo () is the third-largest island in the world, with an area of , and population of 23,053,723 (2020 national censuses). Situated at the geographic centre of Maritime Southeast Asia, it is one of the Greater Sunda Islands, located north of Java, west of Sulawesi, and east of Sumatra. The island is crossed by the equator, which divides it roughly in half. In Indonesia, the island is also known as Kalimantan, which is also the name of the Indonesian region located on the island.\nThe geology of Borneo was formed beginning in the Mesozoic. It formed part of Sundaland, a region connected to mainland Asia, until it became isolated by sea level rise at the end of the last ice age. With seven unique ecoregions, including large expanses of some of the oldest tropical rainforests in the world, Borneo is rich in biodiversity and endemic species.\nArchaeological evidence suggests Borneo has been inhabited by humans for more than 65,000 years. Borneo is home to hundreds of different Indigenous groups, cultures and languages, loosely grouped under the term \"Dayak\". International trading ports were well established on Borneo by the first millennium. It was later subsumed into the Majapahit Empire. The Sultanate of Sulu later ruled much of the island's North, and at its peak in the 14th century, the Sultanate of Brunei governed most of its coast; meanwhile, Borneo's interior remained largely outside of their control. Borneo was later colonised by the British and Dutch, and occupied by Japan during World War II. \nSince the decolonisation of Asia, the island has been politically divided among three states, with the borders broadly following previous demarcation between the British and Dutch. The sovereign state of Brunei in the north makes up 1% of the territory. Approximately 73% of Borneo is Indonesian territory, and in the north, the East Malaysian states of Sabah and Sarawak make up about 26% of the island. The Malaysian federal territory of Labuan is situated on a small island just off the coast of Borneo. \nThe majority of Borneo's inhabitants reside in coastal cities. It is the site of Indonesia's planned future capital, Nusantara. Major economic sectors include oil and gas, agriculture, timber and tourism. Industrial deforestation in Indonesian and Malaysian Borneo for timber and agricultural conversion has taken place during the past century.\nEtymology.\nWhen the sixteenth-century Portuguese explorer Jorge de Menezes made contact with the indigenous people of Borneo, they referred to their island as \"Pulu K'lemantang\", and this second word became Kalimantan, the name for modern-day Borneo in the Indonesian language. The term \"kelamantan\" is used in Sarawak to refer to a group of people who consume sago in the northern part of the island.\nAccording to Crawfurd, the word \"kelamantan\" is the name of a type of mango (\"Mangifera\"), though he adds that the word is fanciful and unpopular. The local mango, called \"klemantan\", is still widely found in rural Ketapang and surrounding areas of West Kalimantan.\nAnother source states that it derives from the Sanskrit word \"kalamanthana\", meaning \"burning weather\", possibly to describe the island's hot and humid tropical weather. In the Indianized Malay era the name \"Kalamanthana\" was derived from the Sanskrit terms \"kala\" (time or season) and \"manthana\" (churning, kindling, or creating fire by friction), which possibly describes the hot weather.\nInternationally, the island is known as Borneo, a name derived from European contact with the Brunei kingdom in the 16th century, during the Age of Exploration. On a map from around 1601, Brunei city is referred to as Borneo, and the whole island is also labelled Borneo. The name may derive from the Sanskrit word \"\" (), meaning either \"water\" or Varuna, the Hindu god of rain and oceans.\nIn 977, Chinese records began to use the term \"Bo-ni\" to refer to Borneo. In 1225, it was also mentioned by the Chinese official Chau Ju-Kua (\u8d99\u6c5d\u9002). The Javanese manuscript \"Nagarakretagama\", written by Majapahit court poet Mpu Prapanca in 1365, mentions the island as \"Nusa Tanjungnagara\", which means the \"island of the Tanjungpura Kingdom\".\nIn Modern Chinese, the island is called (simp. \u5a46\u7f57\u6d32, \"P\u00f3lu\u00f3 Zh\u014du\"), the first two characters being phonetic and the third referring to a large landmass.\nGeography.\nGeology.\nBorneo was formed through Mesozoic accretion of microcontinental fragments, ophiolite terranes and island arc crust onto a Paleozoic continental core. At the beginning of the Cenozoic, Borneo formed a promontory of Sundaland which partly separated from Asian mainland by the proto-South China Sea. The oceanic part of the proto-South China Sea was subducted during the Paleogene period and a large accretionary complex formed along the northwestern of the island of Borneo. In the early Miocene uplift of the accretionary complex occurred as a result of underthrusting of thinned continental crust in northwest. The uplift may have also resulted from shortening due to the counter-clockwise rotation of Borneo between 20 and 10 mega-annum (Ma) as a consequence of Australia\u2013Southeast Asia collision. Large volumes of sediment were shed into basins, which scattered offshore to the west, north and east of Borneo as well into a Neogene basin which is currently exposed in large areas of eastern and southern Sabah. In southeast Sabah, the Miocene to recent island arc terranes of the Sulu Archipelago extend onshore into Borneo with the older volcanic arc was the result of southeast dipping subduction while the younger volcanics are likely resulted from northwest dipping subduction the Celebes Sea.\nBefore sea levels rose at the end of the last ice age, Borneo was part of the mainland of Asia, forming, with Java and Sumatra, the upland regions of a peninsula that extended east from present day Indochina. The South China Sea and Gulf of Thailand now submerge the former low-lying areas of the peninsula. Deeper waters separating Borneo from neighbouring Sulawesi prevented a land connection to that island, creating the divide known as Wallace's Line between Asian and Australia-New Guinea biological regions. The island today is surrounded by the South China Sea to the north and northwest, the Sulu Sea to the northeast, the Celebes Sea and the Makassar Strait to the east, and the Java Sea and Karimata Strait to the south. To the west of Borneo are the Malay Peninsula and Sumatra. To the south and east are islands of Indonesia: Java and Sulawesi, respectively. To the northeast are the Philippine Islands. With an area of , it is the third-largest island in the world, and is the largest island of Asia (the largest continent). Its highest point is Mount Kinabalu in Sabah, Malaysia, with an elevation of .\nThe largest river system is the Kapuas in West Kalimantan, with a length of . Other major rivers include the Mahakam in East Kalimantan ( long), the Barito, Kahayan, and Mendawai in South Kalimantan (, , and long respectively), Rajang in Sarawak ( long) and Kinabatangan in Sabah ( long). Borneo has significant cave systems. In Sarawak, the Clearwater Cave has one of the world's longest underground rivers while Deer Cave is home to over three million bats, with guano accumulated to over deep. The Gomantong Caves in Sabah has been dubbed as the \"Cockroach Cave\" due to the presence of millions of cockroaches inside the cave. The Gunung Mulu National Park in Sarawak and Sangkulirang-Mangkalihat Karst in East Kalimantan which particularly a karst areas contains thousands of smaller caves.\nEcology.\nThe Borneo rainforest is estimated to be around 140 million years old, making it one of the oldest rainforests in the world. The current dominant tree group, the dipterocarps, has dominated the Borneo lowland rain forests for millions of years. It is the centre of the evolution and distribution of many endemic species of plants and animals, and the rainforest is one of the few remaining natural habitats for the endangered Bornean orangutan. It is an important refuge for many endemic forest species, including the Borneo elephant, the eastern Sumatran rhinoceros, the Bornean clouded leopard, the Bornean rock frog, the hose's palm civet and the dayak fruit bat.\nPeat swamp forests occupy the entire coastline of Borneo. The soil of the peat swamp is comparatively infertile, while it is known to be the home of various bird species such as the hook-billed bulbul, helmeted hornbill and rhinoceros hornbill. There are about 15,000 species of flowering plants with 3,000 species of trees (267 species are dipterocarps), 221 species of terrestrial mammals and 420 species of resident birds in Borneo. There are about 440 freshwater fish species in Borneo (about the same as Sumatra and Java combined). The Borneo river shark is known only from the Kinabatangan River. In 2010, the World Wide Fund for Nature (WWF) stated that 123 species have been discovered in Borneo since the \"Heart of Borneo\" agreement was signed in 2007.\nThe WWF has classified the island into seven distinct ecoregions. Most are lowland regions:\nAccording to analysis of data from Global Forest Watch, the Indonesian portion of Borneo lost of tree cover between 2002 and 2019, of which was primary forest, compared with Malaysian Borneo's of tree cover loss and of primary forest cover loss. As of 2020, Indonesian Borneo accounts for 72% of the island's tree cover, Malaysian Borneo 27%, and Brunei 1%. Primary forest in Indonesia accounts for 44% of Borneo's overall tree cover.\nEnvironmental issues.\nThe island historically had extensive rainforest cover, but the area was reduced due to heavy logging by the Indonesian and Malaysian wood industry, especially with the large demands of raw materials from industrial countries along with the conversion of forest lands for large-scale agricultural purposes. Half of the annual global tropical timber acquisition comes from Borneo. Palm oil plantations have been widely developed and are rapidly encroaching on the last remnants of primary rainforest. Forest fires since 1997, started by the locals to clear the forests for plantations were exacerbated by an exceptionally dry El Ni\u00f1o season, worsening the annual shrinkage of the rainforest. During these fires, hotspots were visible on satellite images and the resulting haze frequently affected Brunei, Indonesia and Malaysia. The haze could also reach southern Thailand, Cambodia, Vietnam and the Philippines as evidenced on the 2015 Southeast Asian haze.\nA study in 2018 found that Bornean orangutans declined by 148,500 individuals from 1999 to 2015.\nTopography.\nList of highest peaks in Borneo by elevation:\nRiver systems.\nList of rivers in Borneo by length:\nHistory.\nEarly history.\nIn the Samang Buat Cave, in Lahad Datu, Sabah, archaeological evidence suggests that human settlement dates back to around 46,000 years ago, confirming Lahad Datu as one of the most important prehistoric centres in Southeast Asia. Intriguingly, tools found in Mansuli Valley, also in Lahad Datu, have been dated as early as 235,000 years ago. \nIn Tingkayu Valley, Kunak, Sabah, archaeological excavations revealed traces of a Palaeolithic community dating from approximately 28,000\u201330,000 years ago. The site, once a prehistoric lake basin, yielded Hoabinhian stone tools that indicate human activity in the area. \nIn Niah Cave, Sarawak, human presence has been dated to around 40,000 years ago. Recent studies in the Trader Cave section of the complex discovered microlithic tools and human remains, dated between 55,000 and 65,000 years ago, making it one of the most important early modern human sites in Southeast Asia.\nIn November 2018, scientists reported the discovery of the oldest known figurative art painting, over 40,000 (perhaps as old as 52,000) years old, of an unknown animal, in the cave of Lubang Jeriji Sal\u00e9h on the island of Borneo. It has been proposed, based on house construction styles, linguistic and genetic evidence, that Madagascar may have been first populated from southern Borneo.\nAccording to ancient Chinese (977), Indian and Japanese manuscripts, western coastal cities of Borneo had become trading ports by the first millennium AD. In Chinese manuscripts, gold, camphor, tortoise shells, hornbill ivory, rhinoceros horn, crane crest, beeswax, lakawood (a scented heartwood and root wood of a thick liana, \"Dalbergia parviflora\"), dragon's blood, rattan, edible bird's nests and various spices were described as among the most valuable items from Borneo. The Indians named Borneo \"Suvarnabhumi\" (Land of Gold), and also \"Karpuradvipa\" (Camphor Island). The Javanese named Borneo \"Puradvipa\" (Diamond Island). Archaeological findings in the Sarawak river delta reveal that the area was a thriving centre of trade between India and China from the 6th century until about 1300.\nStone pillars bearing inscriptions in the Pallava script, found in Kutai along the Mahakam River in East Kalimantan and dating to around the second half of the 4th century, constitute some of the oldest evidence of Hindu influence in Southeast Asia. By the 14th century, Borneo became a vassal state of Majapahit (in present-day Indonesia), later changing its allegiance to the Ming dynasty of China. Pre-Islamic Sulu, then known as Lupah S\u016bg, stretched from Palawan and the Sulu Archipelago in the Philippines, to Sabah, Eastern, and Northern Kalimantan in Borneo. The Sulu Empire rose as a rebellion and reaction against the Majapahit, which had briefly occupied its territory. Islam arrived in the 10th century, brought by Muslim traders who later converted many indigenous peoples in the coastal areas.\nThe Sultanate of Brunei declared independence from Majapahit following the death of the Majapahit emperor in the mid-14th century. During its golden age under the Bolkiah from the 15th to the 17th century, the Bruneian sultanate ruled almost the entire coastal area of Borneo (lending its name to the island due to its influence in the region) and several islands in the southwestern Philippines. During the 1450s, Shari'ful Hashem Syed Abu Bakr, an Arab born in Johor, arrived in Sulu from Malacca. In 1457, he founded the Sultanate of Sulu; he styled himself \"Paduka Maulana Mahasari Sharif Sultan Hashem Abu Bakr\". Following its independence in 1578 from Bruneian control, the Sultanate of Sulu began to expand its thalassocracy to parts of northern Borneo. Both sultanates who ruled northern Borneo had traditionally engaged in trade with China by means of the frequent Chinese junks. Outside of the two thalassocratic states, Borneo's interior remained free from the rule of any kingdoms.\nBritish and Dutch control.\nAfter the fall of Malacca in 1511, Portuguese merchants traded regularly with Borneo, and especially with Brunei from 1530. Having visited Brunei's capital, the Portuguese described the place as surrounded by a stone wall. While Borneo was seen as rich, the Portuguese did not make any attempts to conquer it. The Spanish had sailed from Spanish America and conquered the Brunei's provinces in the Philippines and incorporated it into the Mexico-Centered Viceroyalty of New Spain. The Spanish visit to Brunei led to the Castilian War in 1578. The British began to trade with Sambas of southern Borneo in 1609, while the Dutch only began their trade in 1644: to Banjar and Martapura, also in the southern Borneo. The Dutch tried to settle the island of Balambangan, north of Borneo, in the second half of the 18th century, but withdrew by 1797. In 1812, the sultan in southern Borneo ceded his forts to the British East India Company. The British, led by Stamford Raffles, then tried to establish an intervention in Sambas but failed. Although they managed to defeat the sultanate the next year and declared a blockade on all ports in Borneo except Brunei, Banjarmasin and Pontianak, the project was cancelled by the British governor-general Lord Minto in India as it was too expensive. At the beginning of British and Dutch exploration on the island, they described the island of Borneo as full of head hunters, with the indigenous in the interior practising cannibalism, and the waters around the island infested with pirates, especially between the north eastern Borneo and the southern Philippines. The Malay and Sea Dayak pirates preyed on maritime shipping in the waters between Singapore and Hong Kong from their haven in Borneo, along with the attacks by Illanuns of the Moro pirates from the southern Philippines, such as in the Battle off Mukah.\nThe Dutch began to intervene in the southern part of the island upon resuming contact in 1815, posting \"residents\" to Banjarmasin, Pontianak and Sambas and \"assistant-residents\" to Landak and Mampawa. The Sultanate of Brunei in 1842 granted large parts of land in Sarawak to the British adventurer James Brooke, as a reward for his help in quelling a local rebellion. Brooke established the Raj of Sarawak and was recognised as its rajah after paying a fee to the sultanate. He established a monarchy, and the Brooke dynasty (through his nephew and great-nephew) ruled Sarawak for 100 years; the leaders were known as the White Rajahs. Brooke also acquired the island of Labuan for Great Britain in 1846 through the Treaty of Labuan with the sultan of Brunei, Omar Ali Saifuddin II on 18 December 1846. The region of northern Borneo came under the administration of North Borneo Chartered Company following the acquisition of territory from the Sultanates of Brunei and Sulu by a German businessman and adventurer named Baron von Overbeck, before it was passed to the British Dent brothers (comprising Alfred Dent and Edward Dent). Further expansion by the British continued into the Borneo interior. This led the 26th sultan of Brunei, Hashim Jalilul Alam Aqamaddin to appeal the British to halt such efforts, and as a result a Treaty of Protection was signed in 1888, rendering Brunei a British protectorate.\nBefore the acquisition by the British, the Americans also managed to establish their temporary presence in northwestern Borneo after acquiring a parcel of land from the Sultanate of Brunei. A company known as American Trading Company of Borneo was formed by Joseph William Torrey, Thomas Bradley Harris and several Chinese investors, establishing a colony named \"Ellena\" in the Kimanis area. The colony failed and was abandoned, due to denials of financial backing, especially by the US government, and to diseases and riots among the workers. Before Torrey left, he managed to sell the land to the German businessman, Overbeck. Meanwhile, the Germans under William Frederick Schuck were awarded a parcel of land in northeastern Borneo of the Sandakan Bay from the Sultanate of Sulu where he conducted business and exported large quantities of arms, opium, textiles and tobacco to Sulu before the land was also passed to Overbeck by the sultanate.\nPrior to the recognition of Spanish presence in the Philippine archipelago, a protocol known as the Madrid Protocol of 1885 was signed between the governments of the United Kingdom, Germany and Spain in Madrid to cement Spanish influence and recognise their sovereignty over the Sultanate of Sulu\u2014in return for Spain's relinquishing its claim to the former possessions of the sultanate in northern Borneo. The British administration then established the first railway network in northern Borneo, known as the North Borneo Railway. During this time, the British sponsored a large number of Chinese workers to migrate to northern Borneo to work in European plantation and mines, and the Dutch followed suit to increase their economic production. By 1888, North Borneo, Sarawak and Brunei in northern Borneo had become British protectorate. The area in southern Borneo was made Dutch protectorate in 1891. The Dutch who already claimed the whole Borneo were asked by Britain to delimit their boundaries between the two colonial territories to avoid further conflicts. The British and Dutch governments had signed the Anglo-Dutch Treaty of 1824 to exchange trading ports in Malay Peninsula and Sumatra that were under their controls and assert spheres of influence. This resulted in indirectly establishing British- and Dutch-controlled areas in the north (Malay Peninsula) and south (Sumatra and Riau Islands) respectively.\nIn 1895, Marcus Samuel received a concession in the Kutei area of east Borneo, and based on oil seepages in the Mahakam River delta, Mark Abrahams struck oil in February 1897. This was the discovery of the Sanga Sanga Oil Field, a refinery was built in Balikpapan, and discovery of the Samboja Oil Field followed in 1909. In 1901, the Pamusian Oil Field was discovered on Tarakan, and the Bunyu Oil Field in 1929. Royal Dutch Shell discovered the Miri Oil Field in 1910, and the Seria oil field in 1929.\nWorld War II.\nDuring World War II, Japanese forces gained control and occupied most areas of Borneo from 1941 to 1945. In the first stage of the war, the British saw the Japanese advance to Borneo as motivated by political and territorial ambitions rather than economic factors. The occupation drove many people in the coastal towns to the interior, searching for food and escaping the Japanese. The Chinese residents in Borneo, especially with the Sino-Japanese War in Mainland China mostly resisted the Japanese occupation. Following the formation of resistance movements in northern Borneo such as the Jesselton Revolt, many innocent indigenous and Chinese people were executed by the Japanese for their alleged involvement.\nIn Kalimantan, the Japanese also killed many Malay intellectuals, executing all the Malay sultans of West Kalimantan in the Pontianak incidents, together with Chinese people who were already against the Japanese for suspecting them to be threats. Sultan Muhammad Ibrahim Shafi ud-din II of Sambas was executed in 1944. The sultanate was thereafter suspended and replaced by a Japanese council. The Japanese also set-up \"Pusat Tenaga Rakjat\" (PUTERA) in the Indonesian archipelago in 1943, although it was abolished the following year when it became too nationalistic. Some of the Indonesian nationalist like Sukarno and Hatta who had returned from Dutch exile began to co-operate with the Japanese. Shortly after his release, Sukarno became president of the Central Advisory Council, an advisory council for south Borneo, Celebes, and Lesser Sunda, set up in February 1945.\nAfter the fall of Singapore, the Japanese sent several thousand of British and Australian prisoners of war to camps in Borneo such as Batu Lintang camp. From the Sandakan camp site, only six of some 2,500 prisoners survived after they were forced to march in an event known as the Sandakan Death March. In addition, of the total of 17,488 Javanese labourers brought in by the Japanese during the occupation, only 1,500 survived mainly due to starvation, harsh working conditions and maltreatment. The Dayak and other indigenous people played a role in guerrilla warfare against the occupying forces, particularly in the Kapit Division. They temporarily revived headhunting of Japanese toward the end of the war, with Allied Z Special Unit provided assistance to them. Australia contributed significantly to the liberation of Borneo. The Australian Imperial Force was sent to Borneo to fight off the Japanese. Together with other Allies, the island was completely liberated in 1945.\nRecent history.\nIn May 1945, officials in Tokyo suggested that whether northern Borneo should be included in the proposed new country of Indonesia should be separately determined based on the desires of its indigenous people and following the disposition of Malaya. Sukarno and Mohammad Yamin meanwhile continuously advocated for a Greater Indonesian republic. Towards the end of the war, Japan decided to give an early independence to a new proposed country of Indonesia on 17 July 1945, with an Independence Committee meeting scheduled for 19 August 1945. However, following the surrender of Japan to the Allied forces, the meeting was shelved. Sukarno and Hatta continued the plan by unilaterally declaring independence, although the Dutch tried to retake their colonial possession in Borneo.\nThe southern part of the island achieved its independence through the Proclamation of Indonesian Independence on 17 August 1945. The southern part saw guerrilla conflicts followed by Dutch blockades to cut supplies for nationalist within the region. While nationalist guerrillas supporting the inclusion of southern Borneo in the new Indonesian republic were active in Ketapang, and to lesser extent in Sambas where they rallied with the red-white flag which became the flag of Indonesia, most of the Chinese residents in southern Borneo expected to be liberated by Chinese Nationalist troops from mainland China and to integrate their districts as an overseas province of China. Meanwhile, Sarawak and Sabah in northern Borneo became separate British crown colonies in 1946.\nIn 1961, Prime Minister Tunku Abdul Rahman of the independent Federation of Malaya desired to unite Malaya, the British colonies of Sarawak, North Borneo, Singapore and the protectorate of Brunei under the proposed Federation of Malaysia. The idea was heavily opposed by the governments in both Indonesia and the Philippines as well from communist sympathisers and nationalists in Borneo. Sukarno, as the president of the new republic, perceiving the British trying to maintain their presence in northern Borneo and the Malay Peninsula, decided to launch a military infiltration, later known as the \"confrontation\", from 1962 to 1969. As a response to the growing opposition, the British deployed their armed forces to guard their colonies against Indonesian and communist revolts. Australia and New Zealand also participated in these measures.\nThe Philippines opposed the newly proposed federation, claiming the eastern part of North Borneo (today the Malaysian state of Sabah) as part of its territory as a former possession of the Sultanate of Sulu. The Philippine government mostly based their claim on the Sultanate of Sulu's cession agreement with the British North Borneo Company, as by now the sultanate had come under the jurisdiction of the Philippine republican administration, which therefore should inherit the Sulu former territories. The Philippine government also claimed that the heirs of the sultanate had ceded all their territorial rights to the republic.\nThe Sultanate of Brunei at first welcomed the proposal of a new larger federation. Meanwhile, the Brunei People's Party led by A.M. Azahari desired to reunify Brunei, Sarawak and North Borneo into one federation known as the North Borneo Federation (), where the sultan of Brunei would be the head of state for the federation\u2014though Azahari had his own intention to abolish the Brunei monarchy, to make Brunei more democratic, and to integrate the territory and other former British colonies in Borneo into Indonesia, with the support from the latter government. This directly led to the Brunei Revolt, which thwarted Azahari's attempt and forced him to escape to Indonesia. Brunei withdrew from being part of the new Federation of Malaysia due to some disagreements on other issues while political leaders in Sarawak and North Borneo continued to favour inclusion in a larger federation.\nWith the continuous opposition from Indonesia and the Philippines, the Cobbold Commission was established to discover the feeling of the native populations in northern Borneo; it found the people greatly in favour of federation, with various stipulations. The federation was successfully achieved with the inclusion of northern Borneo through the Malaysia Agreement on 16 September 1963. To this day, the area in northern Borneo is still subjected to attacks by Moro pirates since the 18th century and militant from groups such as Abu Sayyaf since 2000 in the frequent cross border attacks. During the administration of Philippine president Ferdinand Marcos, Marcos made some attempts to destabilise the state of Sabah, although his plan failed and resulted in the Jabidah massacre and later the insurgency in the southern Philippines.\nIn August 2019, Indonesian president Joko Widodo announced a plan to move the capital of Indonesia from Jakarta to a newly established location in the East Kalimantan province in Borneo.\nDemographics.\nThe demonym for Borneo is Bornean.\nBorneo had 23,053,723 inhabitants (in 2020 Censuses), a population density of . Most of the population lives in coastal cities, although the hinterland has small towns and villages along the rivers.\nBorneo is home to a number of different Indigenous peoples and distinct languages and cultures. \"Dayak\" is inconsistently used as a collective term for non-Muslim Austronesian Indigenous peoples from Borneo, encompassing the Iban and Bidayuh in East Malaysia, and the Kayan, Kenyah and Ngaju of Kalimantan. Historically, many Dayaks lived in communal longhouses, lacked class structure and practiced shifting cultivation for subsistence.\nTerritories by population, size, and timezone.\n&lt;templatestyles src=\"Citation/styles.css\"/&gt;a &lt;br&gt;\n&lt;templatestyles src=\"Citation/styles.css\"/&gt;b \nUrbanisation by region.\n&lt;templatestyles src=\"Citation/styles.css\"/&gt;c Data based on the projection in the former territories in East Kalimantan Province (prior to the separation of North Kalimantan in 2012)\nMajor ethnicities by region.\n&lt;templatestyles src=\"Citation/styles.css\"/&gt;d Based on alphabetical order\nAdministration.\nThe island of Borneo is divided administratively by three countries.\nEconomy.\nBorneo's economy depends mainly on agriculture, logging and mining, oil and gas, and ecotourism. Brunei's economy is highly dependent on the oil and gas production sector, and the country has become one of the largest oil producers in Southeast Asia. The Malaysian states of Sabah and Sarawak are both top exporters of timber. Sabah is also known as the agricultural producer of rubber, cacao, and vegetables, and for its fisheries, while Sabah, Sarawak and Labuan export liquefied natural gas (LNG) and petroleum. The Indonesian provinces of Kalimantan are mostly dependent on mining sectors despite also being involved in logging and oil and gas explorations.\nHuman Development Index by territory.\nHDI is a statistic of combined indicators that takes into account life expectancy, health, education and per-capita income.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "4519", "revid": "50461682", "url": "https://en.wikipedia.org/wiki?curid=4519", "title": "Ballpoint pen", "text": "Device dispensing ink over a metal ball at its point\nA ballpoint pen, also known as a biro (British English), ball pen (Bangladeshi, Hong Kong, Indian, Indonesian, Pakistani, Japanese and Philippine English), or dot pen (Nepali English and South Asian English), is a pen that dispenses ink (usually in paste form) over a metal ball at its point, i.e., over a \"ball point\". The metals commonly used are steel, brass, or tungsten carbide. The design was conceived and developed as a cleaner and more reliable alternative to dip pens and fountain pens, and it is now the world's most-used writing instrument; millions are manufactured and sold daily. It has influenced art and graphic design and spawned an artwork genre.\nHistory.\nOrigins.\nThe concept of using a \"ball point\" within a writing instrument to apply ink to paper has existed since the late 19th century. In these inventions, the ink was placed in a thin tube whose end was blocked by a tiny ball, held so that it could not slip into the tube or fall out of the pen.\nThe first patent for a ballpoint pen was issued on 30 October 1888 to John J. Loud, who was attempting to make a writing instrument that would be able to write \"on rough surfaces\u2014such as wood, coarse wrapping paper, and other articles\" which fountain pens could not. Loud's pen had a small rotating steel ball held in place by a socket. Although it could be used to mark rough surfaces such as leather, as Loud intended, it proved too coarse for letter-writing. With no commercial viability, its potential went unexploited, and the patent eventually lapsed.\nThe manufacture of economical, reliable ballpoint pens as are known today arose from experimentation, modern chemistry, and the precision manufacturing capabilities of the early 20th century. Patents filed worldwide during early development are testaments to failed attempts at making the pens commercially viable and widely available. Early ballpoints did not deliver the ink evenly; overflow and clogging were among the obstacles faced by early inventors. If the ball socket were too tight or the ink too thick, it would not reach the paper. If the socket were too loose or the ink too thin, the pen would leak, or the ink would smear. Ink reservoirs pressurized by a piston, spring, capillary action, and gravity would all serve as solutions to ink-delivery and flow problems.\nL\u00e1szl\u00f3 B\u00edr\u00f3, a Hungarian newspaper editor (later a naturalized Argentine) frustrated by the amount of time that he wasted filling up fountain pens and cleaning up smudged pages, noticed that inks used in newspaper printing dried quickly, leaving the paper dry and smudge-free. He decided to create a pen using the same type of ink. B\u00edr\u00f3 enlisted the help of his brother Gy\u00f6rgy, a dentist with useful knowledge of chemistry, to develop viscous ink formulae for new ballpoint designs.\nB\u00edr\u00f3's innovation successfully coupled viscous ink with a ball-and-socket mechanism that allowed controlled flow while preventing ink from drying inside the reservoir. B\u00edr\u00f3 filed for a British patent on 15 June 1938.\nIn 1941, the B\u00edr\u00f3 brothers and a friend, Juan Jorge Meyne, fled Germany and moved to Argentina, where they formed \"B\u00edr\u00f3 Pens of Argentina\" and filed a new patent in 1943. Their pen was sold in Argentina as the \"Birome\", from the names B\u00edr\u00f3 and Meyne, which is how ballpoint pens are still known in that country. This new design was licensed by the British engineer Frederick George Miles and manufactured by his company Miles Aircraft, to be used by Royal Air Force aircrew as the \"Biro\". Ballpoint pens were found to be more versatile than fountain pens, especially in airplanes, where fountain pens were prone to leak.\nB\u00edr\u00f3's patent, and other early patents on ballpoint pens, often used the term \"ball-point fountain pen\".\nPostwar proliferation.\nFollowing World War II, many companies vied to commercially produce their own ballpoint pen design. In pre-war Argentina, success of the Birome ballpoint was limited, but in mid-1945, the Eversharp Co., a maker of mechanical pencils, teamed up with Eberhard Faber Co. to license the rights from Birome for sales in the United States.\nIn 1946, a Spanish firm, Vila Sivill Hermanos, began to make a ballpoint, Regia Continua, and from 1953 to 1957 their factory also made Bic ballpoints, on contract with the French firm Soci\u00e9t\u00e9 Bic.\nDuring the same period, American entrepreneur Milton Reynolds came across a Birome ballpoint pen during a business trip to Buenos Aires, Argentina. Recognizing commercial potential, he purchased several ballpoint samples, returned to the United States, and founded the Reynolds International Pen Company. Reynolds bypassed the Birome patent with sufficient design alterations to obtain an American patent, beating Eversharp and other competitors to introduce the pen to the US market. Debuting at Gimbels department store in New York City on 29 October 1945, for US$12.50 each (1945 US dollar value, about $ in 2024 dollars), \"Reynolds Rocket\" became the first commercially successful ballpoint pen. Reynolds went to great extremes to market the pen, with great success; Gimbel's sold many thousands of pens within one week. In Britain, the Miles-(Harry) Martin pen company was producing the first commercially successful ballpoint pens there by the end of 1945.\nNeither Reynolds' nor Eversharp's ballpoint lived up to consumer expectations in America. Ballpoint pen sales peaked in 1946, and consumer interest subsequently plunged due to market saturation, going from luxury good to fungible consumable. By the early 1950s the ballpoint boom had subsided and Reynolds' company folded.\nPaper Mate pens, among the emerging ballpoint brands of the 1950s, bought the rights to distribute their own ballpoint pens in Canada. Facing concerns about ink-reliability, Paper Mate pioneered new ink formulas and advertised them as \"banker-approved\". In 1954, Parker Pens released \"The Jotter\"\u2014the company's first ballpoint\u2014boasting additional features and technological advances which also included the use of tungsten-carbide textured ball-bearings in their pens. In less than a year, Parker sold several million pens at prices between three and nine dollars. In the 1960s, the failing Eversharp Co. sold its pen division to Parker and ultimately folded.\nMarcel Bich also introduced a ballpoint pen to the American marketplace in the 1950s, licensed from B\u00edr\u00f3 and based on the Argentine designs. Bich shortened his name to Bic in 1953, forming the ballpoint brand Bic now recognized globally. Bic pens struggled until the company launched its \"Writes First Time, Every Time!\" advertising campaign in the 1960s. Competition during this era forced unit prices to drop considerably.\nProduction in China.\nMany industrial sites specialized in pen production were created in China. One important production site is the Fenshui Township. Their ballpoint pen production started in 1974, when the Hangzhou Ballpoint Pen Factory initiated its production using bamboo. The Wengang Township has a long tradition of brush pen production, but all kinds of pens are produced, including ballpoint pens. In 2002, China's Pen Capital was constructed in Wenzhou, with an investment of \u00a5 600 million. AIHAO was one of the first companies to move to the industrial site. Their most famous product is the ball-point pen.\nIn the 2000s, China ballpoint pen production skyrocketed. In 2017, China produced 38 billion ballpoint pens per year, 80% of the global market. But the country had a problem in precision engineering the ballpoint pen tip, which had to be imported from Germany, Switzerland, and Japan for the cost of \u00a5 120 million a year. The subject was criticized by western media. \"Forbes\" argued that the lack of IP protections were the cause of it, as the country wouldn't attract investments in innovation. \"Financial Times\" argued that because of Chinese self-sufficiency policy, companies handled the entire supply chain by themselves, thus creating inefficiency. \"Hong Kong Economic Journal\" declared that \"the day China can produce a 100% homemade ball pen will be the day it truly qualifies as a first-class industrial power\".\nSince 2011, the Ministry of Science and Technology invested $8.7 million in the production of the tips. Beifa Group worked with Taiyuan Iron &amp; Steel Group (TISCO) with no success. In 2016, the Chinese Premier Li Keqiang complained on national television about the quality of Chinese pens. In June 2016, TISCO produced the first national ballpoint pen. In November, TISCO's industry standard was approved by the China Metallurgical Standardization Research Institute and on 10 January 2017 the pens were officially announced. The achievement reached the front-page news, was discussed in talk shows and celebrated on social media.\nInks.\nBallpoint pen ink is normally a paste containing around 25 to 40 percent dye. The dyes are suspended in a mixture of solvents and fatty acids. The most common of the solvents are benzyl alcohol or phenoxyethanol, which mix with the dyes and oils to create a smooth paste that dries quickly. This type of ink is also called \"oil-based ink\". The fatty acids help to lubricate the ball tip while writing. Hybrid inks also contain added lubricants in the ink to provide a smoother writing experience. The drying time of the ink varies depending upon the viscosity of the ink and the diameter of the ball.\nIn general, the more viscous the ink, the faster it will dry, but more writing pressure needs to be applied to dispense ink. Although they are less viscous, hybrid inks have a faster drying time compared to normal ballpoint inks. Also, a larger ball dispenses more ink and thus increases drying time.\nThe dyes used in blue and black ballpoint pens are basic dyes based on triarylmethane and acid dyes derived from diazo compounds or phthalocyanine. Common dyes in blue (and black) ink are Prussian blue, Victoria blue, methyl violet, crystal violet, and phthalocyanine blue. The dye eosin is commonly used for red ink.\nThe inks are resistant to water after drying but can be defaced by certain solvents which include acetone and various alcohols.\nTypes of ballpoint pens.\nBallpoint pens are produced in both disposable and refillable models. Refills allow for the entire internal ink reservoir, including a ballpoint and socket, to be replaced. Such characteristics are usually associated with designer-type pens or those constructed of finer materials. The simplest types of ballpoint pens are disposable and have a cap to cover the tip when the pen is not in use, or a mechanism for retracting the tip, which varies between manufacturers but is usually a spring- or screw-mechanism.\nRollerball pens employ the same ballpoint mechanics, but with the use of water-based inks instead of oil-based inks. Compared to oil-based ballpoints, rollerball pens are said to provide more fluid ink-flow, but the water-based inks will blot if held stationary against the writing surface. Water-based inks also remain wet longer when freshly applied and are thus prone to \"smearing\"\u2014posing problems to left-handed people (or right handed people writing right-to-left script)\u2014and \"running\", should the writing surface become wet.\nSome ballpoint pens use a hybrid ink formulation whose viscosity is lower than that of standard ballpoint ink, but greater than rollerball ink. The ink dries faster than a gel pen to prevent smearing when writing. These pens are better suited for left-handed persons. Examples are the Zebra Surari, Uni-ball Jetstream and Pilot Acroball ranges. These pens are also labelled \"extra smooth\", as they offer a smoother writing experience compared to normal ballpoint pens.\nBallpoint pens with erasable ink were pioneered by the Paper Mate pen company. The ink formulas of erasable ballpoints have properties similar to rubber cement, allowing the ink to be literally rubbed clean from the writing surface before drying and eventually becoming permanent. Erasable ink is much thicker than standard ballpoint inks, requiring pressurized cartridges to facilitate inkflow\u2014meaning they can also write upside-down. Though these pens are equipped with erasers, any eraser will suffice.\nBallpoint tips are fitted with balls whose diameter can vary from 0.28\u00a0mm to 1.6\u00a0mm. The ball diameter does not correspond to the width of the line produced by the pen. The line width depends on various factors like the type of ink and pressure applied. Some standard ball diameters are: 0.3\u00a0mm, 0.38\u00a0mm, 0.4\u00a0mm, 0.5\u00a0mm, 0.7\u00a0mm (fine), 0.8\u00a0mm, 1.0\u00a0mm (medium), 1.2\u00a0mm and 1.4\u00a0mm (broad). Pens with ball diameters as small as 0.18\u00a0mm have been made by Japanese companies, but are extremely rare.\nThe inexpensive, disposable Bic Cristal (also simply \"Bic pen\" or \"Biro\") is reportedly the most widely sold pen in the world. It was the Bic company's first product and is still synonymous with the company name.\nThe Bic Cristal is part of the permanent collection at the Museum of Modern Art (MoMA), acknowledged for its industrial design. The design features in MoMA's \"\", a 2025 exhibition of \"widely recognized design icons [...] highlighting pivotal moments in design history.\"\nIts hexagonal barrel mimics that of a wooden pencil and is transparent, showing the ink level in the reservoir. Originally a sealed streamlined cap, the modern pen cap has a small hole at the top to meet safety standards, helping to prevent suffocation if children suck it into the throat.\nMulti-pens are pens that feature multiple varying colored pen refills. Sometimes ballpoint refills are combined with another non-ballpoint refill, usually a mechanical pencil. Sometimes ballpoint pens combine a ballpoint tip on one end and touchscreen stylus on the other.\nBallpoint pens are sometimes provided free by businesses, such as hotels and banks, printed with a company's name and logo. Ballpoints have also been produced to commemorate events, such as a pen commemorating the 1963 assassination of President John F. Kennedy. These pens, known as \"advertising pens,\" are the same as standard ballpoint pen models, but have become valued among collectors.\nSometimes ballpoint pens are also produced as design objects. With cases made of metal or wood, they become individually styled utility objects.\nUse of ballpoint pens in space.\nIt is generally believed that gravity is needed to coat the ball with ink. In fact most ballpoint pens on the Earth do not work when writing upside-down because the Earth's gravity pulls the ink inside the pen away from the tip of the pen. However, in the microgravity environment of space a regular ballpoint pen can still work, pointed in any direction, because the capillary forces in the ink are stronger than non present gravitational forces.\nThe functionality of a regular ballpoint pen in space was confirmed by ESA astronaut Pedro Duque in 2003.\nTechnology developed by Fisher pens in the United States resulted in the production of what came to be known as the \"Fisher Space Pen\". Space Pens combine a more viscous ink with a pressurized ink reservoir that forces the ink toward the point. Unlike a standard ballpoint's ink container, the rear end of a Space Pen's pressurized reservoir is sealed, eliminating evaporation and leakage, thus allowing the pen to write upside-down, in zero-gravity environments, and underwater. Astronauts have made use of these pens in outer space.\nAs an art medium.\nThe ballpoint pen has proven to be a versatile art medium for both professional artists and amateur doodlers. Low cost, availability, and portability are cited by practitioners as qualities which make this common writing tool a convenient art supply. Some artists use them within mixed-media works, while others use them solely as their medium-of-choice.\nEffects not generally associated with ballpoint pens can be achieved. Traditional pen-and-ink techniques such as stippling and cross-hatching can be used to create half-tones or the illusion of form and volume. For artists whose interests necessitate precision line-work, ballpoints are an obvious attraction; ballpoint pens allow for sharp lines not as effectively executed using a brush. Finely applied, the resulting imagery has been mistaken for airbrushed artwork and photography, causing reactions of disbelief which ballpoint artist Lennie Mace refers to as the \"Wow Factor\".\nFamous 20th-century artists, including Andy Warhol, have utilized the ballpoint pen during their careers. Ballpoint pen artwork continues to attract interest in the 21st century, with many contemporary artists gaining recognition for their specific use of ballpoint pens as a medium. Korean-American artist Il Lee has been creating large-scale, abstract artwork since the late 1970s solely with ballpoint pens. Since the 1980s, Lennie Mace creates imaginative, ballpoint-only artwork of varying content and complexity, applied to unconventional surfaces including wood and denim. The artist coined terms such as \"PENtings\" and \"Media Graffiti\" to describe his varied output. British artist James Mylne has been creating photo-realistic artwork using mostly black ballpoints, sometimes with minimal mixed-media color.\nThe ballpoint pen has several limitations as an art medium. Color availability and sensitivity of ink to light are among concerns of ballpoint pen artists. As a tool that uses ink, marks made with a ballpoint pen can generally not be erased. Additionally, \"blobbing\" ink on the drawing surface and \"skipping\" ink-flow require consideration when drawing with a ballpoint pen. Although the mechanics of ballpoint pens remain relatively unchanged, ink composition has evolved to solve certain problems over the years, resulting in unpredictable sensitivity to light and some extent of fading.\nManufacturing.\nThe common ballpoint pen is a product of mass production, with components produced separately on assembly lines. Basic steps in the manufacturing process include the production of ink formulas, molding of metal and plastic components, and assembly. Marcel Bich (leading to Soci\u00e9t\u00e9 Bic) was involved in developing the production of inexpensive ballpoint pens.\nAlthough designs and construction vary between brands, basic components of all ballpoint pens are universal. The making of a ballpoint pen, specially the tip, is considered a work of precision engineering. Standard components of a ballpoint tip include the freely rotating \"ball\" itself (distributing the ink on the writing surface), a \"socket\" holding the ball in place, small \"ink channels\" that provide ink to the ball through the socket, and a self-contained \"ink reservoir\" supplying ink to the ball. In modern disposable pens, narrow plastic tubes contain the ink, which is compelled downward to the ball by gravity. Brass, steel, or tungsten carbide are used to manufacture the ball bearing-like points, then housed in a brass socket.\nThe function of these components can be observed at a larger scale in the ball-applicator of roll-on antiperspirant. The ballpoint tip delivers the ink to the writing surface while acting as a \"buffer\" between the ink in the reservoir and the air outside, preventing the quick-drying ink from drying inside the reservoir. Modern ballpoints are said to have a two-year shelf life, on average.\nA ballpoint tip that can write comfortably for a long period of time is not easy to produce, as it requires high-precision machinery and thin high-grade steel alloy plates. China, which as of 2017[ [update]] produces about 80 percent of the world's ballpoint pens, relied on imported ballpoint tips and metal alloys before 2017.\nStandards.\nThe International Organization for Standardization has published standards for ball point and roller ball pens:\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "4521", "revid": "42316941", "url": "https://en.wikipedia.org/wiki?curid=4521", "title": "Bubble sort/C", "text": ""}
{"id": "4523", "revid": "1306352", "url": "https://en.wikipedia.org/wiki?curid=4523", "title": "Bipolar spectrum", "text": ""}
{"id": "4524", "revid": "46866511", "url": "https://en.wikipedia.org/wiki?curid=4524", "title": "Burroughs Corporation", "text": "American computer company\nThe Burroughs Corporation was a major American manufacturer of business equipment. The company was founded in 1886 as the American Arithmometer Company by William Seward Burroughs. The company's history paralleled many of the major developments in computing. At its start, it produced mechanical adding machines, and later moved into programmable ledgers and then computers. It was one of the largest producers of mainframe computers in the world, also producing related equipment including typewriters and printers.\nIn the 1960s, the company introduced a range of mainframe computers that were well regarded for their performance running high-level languages. These formed the core of the company's business into the 1970s. At that time the emergence of superminicomputers and the dominance of the IBM System/360 and 370 at the high end led to shrinking markets, and in 1986 the company purchased former competitor Sperry UNIVAC and merged their operations to form Unisys. \nEarly history.\nIn 1886, the American Arithmometer Company was established in St. Louis, Missouri, to produce and sell an adding machine invented by William Seward Burroughs (grandfather of Beat Generation author William S. Burroughs). In 1904, six years after Burroughs's death, the company moved to Detroit and changed its name to the Burroughs Adding Machine Company. It was soon the biggest adding machine company in America.\nEvolving product lines.\nThe adding machine range began with the basic, hand-cranked Class 1 which was only capable of adding. The design included some revolutionary features, foremost of which was the dashpot which governed the speed at which the operating lever could be pulled so allowing the mechanism to operate consistently correctly. The machine also had a full-keyboard with a separate column of keys 1 to 9 for each decade where the keys latch when pressed, with interlocking which prevented more than one key in any decade from being latched. The latching allowed the operator to quickly check that the correct number had been entered before pulling the operating lever. The numbers entered and the final total were printed on a roll of paper at the rear, so there was no danger of the operator writing down the wrong answer and there was a copy of the calculation which could be checked later if necessary.\nThe Class 2 machine, called the \"duplex\" and built in the same basic style, provided a means of keeping two separate totals. The Class 6 machine was built for bookkeeping work and provided the ability for direct subtraction.\nBurroughs released the Class 3 and Class 4 adding machines which were built after the purchase of the Pike Adding Machine Company around 1910. These machines provided a significant improvement over the older models because operators could view the printing on the paper tape. The machines were called \"the visible\" for this improvement.\nIn 1925 Burroughs released a much smaller machine called \"the portable\". Two models were released, the Class 8 (without subtraction) and the Class 9 with subtraction capability. Later models continued to be released with the P600 and top-of-the-range P612 offered some limited programmability based upon the position of the movable carriage. The range was further extended by the inclusion of the Series J ten-key machines which provided a single finger calculation facility, and the Class 5 (later called Series C) key-driven calculators in both manual and electrical assisted comptometers.\nIn the late 1960s, the Burroughs sponsored \"nixi-tube\" provided an electronic display calculator. Burroughs developed a range of adding machines with different capabilities, gradually increasing in their capabilities. A revolutionary adding machine was the \"Sensimatic\", which was able to perform many business functions semi-automatically. It had a moving programmable carriage to maintain ledgers. It could store 9, 18 or 27 balances during the ledger posting operations and worked with a mechanical adder named a Crossfooter. The Sensimatic developed into the \"Sensitronic\" which could store balances on a magnetic stripe which was part of the ledger card. This balance was read into the accumulator when the card was inserted into the carriage. The Sensitronic was followed by the E1000, E2000, E3000, E4000, E6000 and the E8000, which were computer systems supporting card reader/punches and a line printer.\nLater, Burroughs was selling more than adding machines, including typewriters.\nMove into computers.\nThe biggest shift in company history came in 1953: the Burroughs Adding Machine Company was renamed the Burroughs Corporation and began moving into digital computer products, initially for banking institutions. This move began with Burroughs's purchase in June 1956, of the ElectroData Corporation in Pasadena, California, a spinoff of the Consolidated Engineering Corporation which had designed test instruments and had a cooperative relationship with Caltech in Pasadena. ElectroData had built the Datatron 205 and was working on the Datatron 220. The first major computer product that came from this marriage was the B205 tube computer. In 1968 the L and TC series range was produced (e.g. the TC500\u2014Terminal Computer 500) which had a golf ball printer and in the beginning a 1K (64 bit) disk memory. These were popular as branch terminals to the B5500/6500/6700 systems, and sold well in the banking sector, where they were often connected to non-Burroughs mainframes. In conjunction with these products, Burroughs also manufactured an extensive range of cheque processing equipment, normally attached as terminals to a medium systems such as B200/B300 and larger systems such as a B2700 or B1700.\nIn the 1950s, Burroughs worked with the Federal Reserve Bank on the development and computer processing of magnetic ink character recognition (MICR) especially for the processing of bank cheques. Burroughs made special MICR/OCR sorter/readers which attached to their medium systems line of computers (2700/3700/4700) and B200/B300 systems and this entrenched the company in the computer side of the banking industry.\nA force in the computing industry.\nBurroughs was one of the nine major United States computer companies in the 1960s, with IBM the largest, Honeywell, NCR Corporation, Control Data Corporation (CDC), General Electric (GE), Digital Equipment Corporation (DEC), RCA and Sperry Rand (UNIVAC line). In terms of sales, Burroughs was always a distant second to IBM. In fact, IBM's market share was so much larger than all of the others that this group was often referred to as \"IBM and the Seven Dwarves.\" By 1972 when GE and RCA were no longer in the mainframe business, the remaining five companies behind IBM became known as the BUNCH, an acronym based on their initials.\nAt the same time, Burroughs was very much a competitor. Like IBM, Burroughs tried to supply a complete line of products for its customers, including Burroughs-designed printers, disk drives, tape drives, computer printing paper and typewriter ribbons.\nDevelopments and innovations.\nThe Burroughs Corporation developed three highly innovative architectures, based on the design philosophy of \"language-directed design\". Their machine instruction sets favored one or many high level programming languages, such as ALGOL, COBOL or FORTRAN. All three architectures were considered mainframe class machines:\nMany computer scientists consider these series of computers to be technologically groundbreaking. Stack-oriented processors with 48-bit word length where each word was defined as data or program contributed significantly to a secure operating environment, long before spyware and viruses affected computing. The modularity of these large systems was unique: multiple CPUs, multiple memory modules and multiple I/O and Data Comm processors permitted incremental and cost effective growth of system performance and reliability.\nIn industries like banking, where continuous operations was mandatory, Burroughs Large Systems penetrated nearly every large bank, including the Federal Reserve Bank. Burroughs built the backbone switching systems for Society for Worldwide Interbank Financial Telecommunication (SWIFT) which sent its first message in 1977. Unisys is still the provider to SWIFT today.\nMerger with Sperry.\n&lt;templatestyles src=\"Plain image with caption/styles.css\"/&gt; \nLogo of Burroughs Corporation shortly before its merger with Sperry \nIn September 1986, Burroughs Corporation merged with Sperry Corporation to form Unisys. For a time, the combined company retained the Burroughs processors as the A- and V-systems lines. As the market for large systems shifted from proprietary architectures to common servers, the company eventually dropped the V-Series line, although customers continued to use V-series systems as of 2010[ [update]]. As of 2017[ [update]] Unisys continues to develop and market the A-Series, now known as ClearPath.\nBurroughs Payment Systems.\nIn 2010, Unisys sold off its Payment Systems Division to Marlin Equity Partners, a California-based private investment firm, which incorporated it as Burroughs Payment Systems, Inc. (later just Burroughs, Inc.), based in Plymouth, Michigan.\nReferences in popular culture.\nBurroughs B205 hardware has appeared as props in many Hollywood television and film productions from the late 1950s. For example, a B205 console was often shown in the television series \"Batman\" as the \"Bat Computer\"; also as the flight computer in \"Lost in Space\". B205 tape drives were often seen in series such as \"The Time Tunnel\" and \"Voyage to the Bottom of the Sea\".\nBurroughs equipment was also featured in the movie \"The Angry Red Planet\".\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "4526", "revid": "4897226", "url": "https://en.wikipedia.org/wiki?curid=4526", "title": "Brick", "text": "Block or a single unit of a ceramic material used in masonry construction\nA brick is a type of building material used to build walls, pavements, and other elements in masonry construction. Properly, the term \"brick\" denotes a unit primarily composed of clay, but it is now also used informally to denote building units made of other materials or other chemically cured construction blocks.\nBricks can be joined using mortar, adhesives or by interlocking. Bricks are usually produced at brickworks in numerous classes, types, materials, and sizes which vary with region, and are produced in bulk quantities.\n\"Block\" is a similar term referring to a rectangular building unit composed of clay or concrete, but is usually larger than a brick. Lightweight bricks (also called lightweight blocks) are made from expanded clay aggregate.\nFired bricks are one of the longest-lasting and strongest building materials, sometimes referred to as artificial stone, and have been used since c.\u20094000 BC. Air-dried bricks, also known as mudbricks, have a history older than fired bricks, and have an additional ingredient of a mechanical binder such as straw.\nBricks are laid in courses and numerous patterns known as bonds, collectively known as brickwork, and may be laid in various kinds of mortar to hold the bricks together to make a durable structure.\nHistory.\nMiddle East and South Asia.\nThe earliest bricks were dried mudbricks, meaning that they were formed from clay-bearing earth or mud and dried (usually in the sun) until they were strong enough for use. The oldest discovered bricks, originally made from shaped mud and dating before 7500 BC, were found at Tell Aswad, in the upper Tigris region and in southeast Anatolia close to Diyarbakir.\nMudbrick construction was used at \u00c7atalh\u00f6y\u00fck, from c. 7,400 BC.\nMudbrick structures, dating to c. 7,200 BC have been located in Jericho, Jordan Valley. These structures were made up of the first bricks with dimensions of .\nBetween 5000 and 4500 BC, Mesopotamia had discovered fired brick. The standard brick sizes in Mesopotamia followed a general rule: the width of the dried or burned brick would be twice its thickness, and its length would be double its width.\nThe South Asian inhabitants of Mehrgarh also constructed air-dried mudbrick structures between 7000 and 3300 BC and later the ancient Indus Valley cities of Mohenjo-daro, Harappa, and Mehrgarh. Ceramic, or \"fired brick\" was used as early as 3000 BC in early Indus Valley cities like Kalibangan.\nIn the middle of the third millennium BC, there was a rise in monumental baked brick architecture in Indus cities. Examples included the Great Bath at Mohenjo-daro, the fire altars of Kaalibangan, and the granary of Harappa. There was a uniformity to the brick sizes throughout the Indus Valley region, conforming to the 1:2:4, thickness, width, and length ratio. As the Indus civilization began its decline at the start of the second millennium BC, Harappans migrated east, spreading their knowledge of brickmaking technology. This led to the rise of cities like Pataliputra, Kausambi, and Ujjain, where there was an enormous demand for kiln-made bricks.\nBy 604 BC, bricks were the construction materials for architectural wonders such as the Hanging Gardens of Babylon, where glazed fired bricks were put into practice.\nChina.\nThe earliest fired bricks appeared in Neolithic China around 4400 BC at Chengtoushan, a walled settlement of the Daxi culture. These bricks were made of red clay, fired on all sides to above 600\u00a0\u00b0C, and used as flooring for houses. By the Qujialing period (3300 BC), fired bricks were being used to pave roads and as building foundations at Chengtoushan.\nAccording to Lukas Nickel, the use of ceramic pieces for protecting and decorating floors and walls dates back at various cultural sites to 3000-2000 BC and perhaps even before, but these elements should be rather qualified as tiles. For the longest time builders relied on wood, mud and rammed earth, while fired brick and mudbrick played no structural role in architecture. Proper brick construction, for erecting walls and vaults, finally emerges in the third century BC, when baked bricks of regular shape began to be employed for vaulting underground tombs. Hollow brick tomb chambers rose in popularity as builders were forced to adapt due to a lack of readily available wood or stone. The oldest extant brick building above ground is possibly Songyue Pagoda, dated to 523 AD.\nBy the end of the third century BC in China, both hollow and small bricks were available for use in building walls and ceilings. Fired bricks were first mass-produced during the construction of the tomb of China's first Emperor, Qin Shi Huangdi. The floors of the three pits of the Terracotta Army were paved with an estimated 230,000 bricks, with the majority measuring 28x14x7 cm, following a 4:2:1 ratio. The use of fired bricks in Chinese city walls first appeared in the Eastern Han dynasty (25 AD-220 AD). Up until the Middle Ages, buildings in Central Asia were typically built with unbaked bricks. It was only starting in the ninth century CE when buildings were entirely constructed using fired bricks.\nThe carpenter's manual \"Yingzao Fashi\", published in 1103 at the time of the Song dynasty described the brick making process and glazing techniques then in use. Using the 17th-century encyclopaedic text \"Tiangong Kaiwu\", historian Timothy Brook outlined the brick production process of Ming dynasty China: &lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;...the kilnmaster had to make sure that the temperature inside the kiln stayed at a level that caused the clay to shimmer with the colour of molten gold or silver. He also had to know when to quench the kiln with water so as to produce the surface glaze. To anonymous labourers fell the less skilled stages of brick production: mixing clay and water, driving oxen over the mixture to trample it into a thick paste, scooping the paste into standardised wooden frames (to produce a brick roughly 42\u00a0cm long, 20\u00a0cm wide, and 10\u00a0cm thick), smoothing the surfaces with a wire-strung bow, removing them from the frames, printing the fronts and backs with stamps that indicated where the bricks came from and who made them, loading the kilns with fuel (likelier wood than coal), stacking the bricks in the kiln, removing them to cool while the kilns were still hot, and bundling them into pallets for transportation. It was hot, filthy work.\nEurope.\nEarly civilisations around the Mediterranean, including the Ancient Greeks and Romans, adopted the use of fired bricks. By the early first century CE, standardised fired bricks were being heavily produced in Rome. The Roman legions operated mobile kilns, and built large brick structures throughout the Roman Empire, stamping the bricks with the seal of the legion. The Romans used brick for walls, arches, forts, aqueducts, etc. Notable mentions of Roman brick structures are the Herculaneum gate of Pompeii and the baths of Caracalla.\nDuring the Early Middle Ages the use of bricks in construction became popular in Northern Europe, after being introduced there from Northwestern Italy. An independent style of brick architecture, known as brick Gothic (similar to Gothic architecture) flourished in places that lacked indigenous sources of rocks. Examples of this architectural style can be found in modern-day Denmark, Germany, Poland, and Kaliningrad (former East Prussia).\nThis style evolved into the Brick Renaissance as the stylistic changes associated with the Italian Renaissance spread to northern Europe, leading to the adoption of Renaissance elements into brick building. Identifiable attributes included a low-pitched hipped or flat roof, symmetrical facade, round arch entrances and windows, columns and pilasters, and more.\nA clear distinction between the two styles only developed at the transition to Baroque architecture. In L\u00fcbeck, for example, Brick Renaissance is clearly recognisable in buildings equipped with terracotta reliefs by the artist Statius von D\u00fcren, who was also active at Schwerin (Schwerin Castle) and Wismar (F\u00fcrstenhof).\nLong-distance bulk transport of bricks and other construction equipment remained prohibitively expensive until the development of modern transportation infrastructure, with the construction of canal, roads, and railways.\nIndustrial era.\nProduction of bricks increased massively with the onset of the Industrial Revolution and the rise in factory building in England. For reasons of speed and economy, bricks were increasingly preferred as building material to stone, even in areas where the stone was readily available. It was at this time in London that bright red brick was chosen for construction to make the buildings more visible in the heavy fog and to help prevent traffic accidents.\nThe transition from the traditional method of production known as hand-moulding to a mechanised form of mass-production slowly took place during the first half of the nineteenth century. The first brick-making machine was patented by Richard A. Ver Valen of Haverstraw, New York, in 1852. The Bradley &amp; Craven Ltd 'Stiff-Plastic Brickmaking Machine' was patented in 1853. Bradley &amp; Craven went on to be a dominant manufacturer of brickmaking machinery. Henry Clayton, employed at the Atlas Works in Middlesex, England, in 1855, patented a brick-making machine that was capable of producing up to 25,000 bricks daily with minimal supervision. His mechanical apparatus soon achieved widespread attention after it was adopted for use by the South Eastern Railway Company for brick-making at their factory near Folkestone. \nAt the end of the 19th century, the Hudson River region of New York State would become the world's largest brick manufacturing region, with 130 brickyards lining the shores of the Hudson River from Mechanicsville to Haverstraw and employing 8,000 people. At its peak, about 1 billion bricks were produced a year, with many being sent to New York City for use in its construction industry.\nThe demand for high office building construction at the turn of the 20th century led to a much greater use of cast and wrought iron, and later, steel and concrete. The use of brick for skyscraper construction severely limited the size of the building \u2013 the Monadnock Building, built in 1896 in Chicago, required exceptionally thick walls to maintain the structural integrity of its 17 storeys.\nFollowing pioneering work in the 1950s at the Swiss Federal Institute of Technology and the Building Research Establishment in Watford, UK, the use of improved masonry for the construction of tall structures up to 18 storeys high was made viable. However, the use of brick has largely remained restricted to small to medium-sized buildings, as steel and concrete remain superior materials for high-rise construction.\nMethods of manufacture.\nFour basic types of brick are un-fired, fired, chemically set bricks, and compressed earth blocks. Each type is manufactured differently for various purposes.\nMudbrick.\nUnfired bricks, also known as mudbrick, are made from a mixture of silt, clay, sand and other earth materials like gravel and stone, combined with tempers and binding agents such as chopped straw, grasses, tree bark, or dung. Since these bricks are made up of natural materials and only require heat from the Sun to bake, mudbricks have a relatively low embodied energy and carbon footprint.\nThe ingredients are first harvested and added together, with clay content ranging from 30% to 70%. The mixture is broken up with hoes or adzes, and stirred with water to form a homogenous blend. Next, the tempers and binding agents are added in a ratio, roughly one part straw to five parts earth to reduce weight and reinforce the brick by helping reduce shrinkage. However, additional clay could be added to reduce the need for straw, which would prevent the likelihood of insects deteriorating the organic material of the bricks, subsequently weakening the structure. These ingredients are thoroughly mixed together by hand or by treading and are then left to ferment for about a day.\nThe mix is then kneaded with water and molded into rectangular prisms of a desired size. Bricks are lined up and left to dry in the sun for three days on both sides. After the six days, the bricks continue drying until required for use. Typically, longer drying times are preferred, but the average is eight to nine days spanning from initial stages to its application in structures. Unfired bricks could be made in the spring months and left to dry over the summer for use in the autumn. Mudbricks are commonly employed in arid environments to allow for adequate air drying.\nFired brick.\nFired bricks are baked in a kiln which makes them durable. Modern, fired, clay bricks are formed in one of three processes \u2013 soft mud, dry press, or extruded. Depending on the country, either the extruded or soft mud method is the most common, since they are the most economical.\nClay and shale are the raw ingredients in the recipe for a fired brick. They are the product of thousands of years of decomposition and erosion of rocks, such as pegmatite and granite, leading to a material that has properties of being highly chemically stable and inert. Within the clays and shales are the materials of aluminosilicate (pure clay), free silica (quartz), and decomposed rock.\nOne proposed optimal mix is:\nShaping methods.\nThree main methods are used for shaping the raw materials into bricks to be fired:\nKilns.\nIn many modern brickworks, bricks are usually fired in a continuously fired tunnel kiln, in which the bricks are fired as they move slowly through the kiln on conveyors, rails, or kiln cars, which achieves a more consistent brick product. The bricks often have lime, ash, and organic matter added, which accelerates the burning process.\nThe other major kiln type is the Bull's Trench Kiln (BTK), based on a design developed by British engineer W. Bull in the late 19th century.\nAn oval or circular trench is dug, wide, deep, and in circumference. A tall exhaust chimney is constructed in the centre. Half or more of the trench is filled with \"green\" (unfired) bricks which are stacked in an open lattice pattern to allow airflow. The lattice is capped with a roofing layer of finished brick.\nIn operation, new green bricks, along with roofing bricks, are stacked at one end of the brick pile. Historically, a stack of unfired bricks covered for protection from the weather was called a \"hack\". Cooled finished bricks are removed from the other end for transport to their destinations. In the middle, the brick workers create a firing zone by dropping fuel (coal, wood, oil, debris, etc.) through access holes in the roof above the trench. The constant source of fuel maybe grown on the woodlots.6\nThe advantage of the BTK design is a much greater energy efficiency compared with clamp or scove kilns. Sheet metal or boards are used to route the airflow through the brick lattice so that fresh air flows first through the recently burned bricks, heating the air, then through the active burning zone. The air continues through the green brick zone (pre-heating and drying the bricks), and finally out the chimney, where the rising gases create suction that pulls air through the system. The reuse of heated air yields savings in fuel cost.\nAs with the rail process, the BTK process is continuous. A half-dozen labourers working around the clock can fire approximately 15,000\u201325,000 bricks a day. Unlike the rail process, in the BTK process the bricks do not move. Instead, the locations at which the bricks are loaded, fired, and unloaded gradually rotate through the trench.\nInfluences on colour.\nThe colour of fired clay bricks is influenced by the chemical and mineral content of the raw materials, the firing temperature, and the atmosphere in the kiln. For example, pink bricks are the result of a high iron content, while white or yellow bricks have a higher lime content. Most bricks burn to various red hues; as the temperature is increased the colour moves through dark red, purple, and then to brown or grey at around . The names of bricks may reflect their origin and colour, such as London stock brick and Cambridgeshire White. \"Brick tinting\" may be performed to change the colour of bricks to blend-in areas of brickwork with the surrounding masonry.\nAn impervious and ornamental surface may be laid on brick either by salt glazing, in which salt is added during the burning process, or by the use of a slip, which is a glaze material into which the bricks are dipped. Subsequent reheating in the kiln fuses the slip into a glazed surface integral with the brick base.\nChemically set bricks.\nChemically set bricks are not fired but may have the curing process accelerated by the application of heat and pressure in an autoclave.\nCalcium-silicate bricks.\nCalcium-silicate bricks are also called sandlime or flintlime bricks, depending on their ingredients. Rather than being made with clay they are made with lime binding the silicate material. The raw materials for calcium-silicate bricks include lime mixed in a proportion of about 1 to 10 with sand, quartz, crushed flint, or crushed siliceous rock together with mineral colourants. The materials are mixed and left until the lime is completely hydrated; the mixture is then pressed into moulds and cured in an autoclave for three to fourteen hours to speed the chemical hardening. The finished bricks are very accurate and uniform, although the sharp arrises need careful handling to avoid damage to brick and bricklayer. The bricks can be made in a variety of colours; white, black, buff, and grey-blues are common, and pastel shades can be achieved. This type of brick is common in Sweden as well as Russia and other post-Soviet countries, especially in houses built or renovated in the 1970s. A version known as fly ash bricks, manufactured using fly ash, lime, and gypsum (known as the FaL-G process) are common in South Asia. Calcium-silicate bricks are also manufactured in Canada and the United States, and meet the criteria set forth in ASTM C73 \u2013 10 Standard Specification for Calcium Silicate Brick (Sand-Lime Brick).\nConcrete bricks.\nBricks formed from concrete are usually termed as blocks or concrete masonry unit, and are typically pale grey. They are made from a dry, small aggregate concrete which is formed in steel moulds by vibration and compaction in either an \"egglayer\" or static machine. The finished blocks are cured, rather than fired, using low-pressure steam. Concrete bricks and blocks are manufactured in a wide range of shapes, sizes and face treatments \u2013 a number of which simulate the appearance of clay bricks.\nConcrete bricks are available in many colours and as an engineering brick made with sulfate-resisting Portland cement or equivalent. When made with adequate amount of cement they are suitable for harsh environments such as wet conditions and retaining walls. They are made to standards BS 6073, EN 771-3 or ASTM C55. Concrete bricks contract or shrink so they need movement joints every 5 to 6 metres, but are similar to other bricks of similar density in thermal and sound resistance and fire resistance.\nCompressed earth blocks.\nCompressed earth blocks are made mostly from slightly moistened local soils compressed with a mechanical hydraulic press or manual lever press. A small amount of a cement binder may be added, resulting in a \"stabilised compressed earth block\".\nTypes.\nThere are thousands of types of bricks that are named for their use, size, forming method, origin, quality, texture, and/or materials.\nCategorized by manufacture method:\nCategorized by use:\nSpecialized use bricks:\nBricks named for place of origin:\nOptimal dimensions, characteristics, and strength.\nFor efficient handling and laying, bricks must be small enough and light enough to be picked up by the bricklayer using one hand (leaving the other hand free for the trowel). Bricks are usually laid flat, and as a result, the effective limit on the width of a brick is set by the distance which can conveniently be spanned between the thumb and fingers of one hand, normally about . In most cases, the length of a brick is twice its width plus the width of a mortar joint, about or slightly more. This allows bricks to be laid \"bonded\" in a structure which increases stability and strength (for an example, see the illustration of bricks laid in \"English bond\", at the head of this article). The wall is built using alternating courses of \"stretchers\", bricks laid longways, and \"headers\", bricks laid crossways. The headers tie the wall together over its width. In fact, this wall is built in a variation of \"English bond\" called \"English cross bond\" where the successive layers of stretchers are displaced horizontally from each other by half a brick length. In true \"English bond\", the perpendicular lines of the stretcher courses are in line with each other.\nA bigger brick makes for a thicker (and thus more insulating) wall. Historically, this meant that bigger bricks were necessary in colder climates (see for instance the slightly larger size of the Russian brick in table below), while a smaller brick was adequate, and more economical, in warmer regions. A notable illustration of this correlation is the Green Gate in Gdansk; built in 1571 of imported Dutch brick, too small for the colder climate of Gdansk, it was notorious for being a chilly and drafty residence. Nowadays this is no longer an issue, as modern walls typically incorporate specialised insulation materials.\nThe correct brick for a job can be selected from a choice of colour, surface texture, density, weight, absorption, and pore structure, thermal characteristics, thermal and moisture movement, and fire resistance.\nIn England, the length and width of the common brick remained fairly constant from 1625 when the size was regulated by statute at 9 x &lt;templatestyles src=\"Fraction/styles.css\" /&gt;4+1\u20442 x 3 inches (but see brick tax), but the depth has varied from about or smaller in earlier times to about more recently. In the United Kingdom, the usual size of a modern brick (from 1965) is , which, with a nominal mortar joint, forms a \"unit size\" of , for a ratio of 6:3:2.\nIn the United States, modern standard bricks are specified for various uses; The most commonly used is the modular brick has the \"actual dimensions\" of &lt;templatestyles src=\"Fraction/styles.css\" /&gt;7+5\u20448\u00a0 \u00d7 &lt;templatestyles src=\"Fraction/styles.css\" /&gt;3+5\u20448\u00a0 \u00d7 &lt;templatestyles src=\"Fraction/styles.css\" /&gt;2+1\u20444\u00a0inches (194 \u00d7 92 \u00d7 57\u00a0mm). With the standard &lt;templatestyles src=\"Fraction/styles.css\" /&gt;3\u20448 inch mortar joint, this gives the \"nominal dimensions\" of 8 x 4 x &lt;templatestyles src=\"Fraction/styles.css\" /&gt;2+2\u20443 inches which eases the calculation of the number of bricks in a given wall. The 2:1 ratio of modular bricks means that when they turn corners, a 1/2 running bond is formed without needing to cut the brick down or fill the gap with a cut brick; and the height of modular bricks means that a soldier course matches the height of three modular running courses, or one standard CMU course.\nSome brickmakers create innovative sizes and shapes for bricks used for plastering (and therefore not visible on the inside of the building) where their inherent mechanical properties are more important than their visual ones. These bricks are usually slightly larger, but not as large as blocks and offer the following advantages:\nBlocks have a much greater range of sizes. Standard co-ordinating sizes in length and height (in mm) include 400\u00d7200, 450\u00d7150, 450\u00d7200, 450\u00d7225, 450\u00d7300, 600\u00d7150, 600\u00d7200, and 600\u00d7225; depths (work size, mm) include 60, 75, 90, 100, 115, 140, 150, 190, 200, 225, and 250. They are usable across this range as they are lighter than clay bricks. The density of solid clay bricks is around 2000\u00a0kg/m3: this is reduced by frogging, hollow bricks, and so on, but aerated autoclaved concrete, even as a solid brick, can have densities in the range of 450\u2013850\u00a0kg/m3.\nBricks may also be classified as \"solid\" (less than 25% perforations by volume, although the brick may be \"frogged,\" having indentations on one of the longer faces), \"perforated\" (containing a pattern of small holes through the brick, removing no more than 25% of the volume), \"cellular\" (containing a pattern of holes removing more than 20% of the volume, but closed on one face), or \"hollow\" (containing a pattern of large holes removing more than 25% of the brick's volume). Blocks may be solid, cellular or hollow.\nThe term \"frog\" can refer to the indentation or the implement used to make it. Modern brickmakers usually use plastic frogs but in the past they were made of wood.\nThe compressive strength of bricks produced in the United States ranges from about , varying according to the use to which the brick are to be put. In England clay bricks can have strengths of up to 100 MPa, although a common house brick is likely to show a range of 20\u201340 MPa.\nUses.\nBricks are a versatile building material, able to participate in a wide variety of applications, including:\nIn the United States, bricks have been used for both buildings and pavement. Examples of brick use in buildings can be seen in colonial era buildings and other notable structures around the country. Bricks have been used in paving roads and sidewalks especially during the late 19th century and early 20th century. The introduction of asphalt and concrete reduced the use of brick for paving, but they are still sometimes installed as a method of traffic calming or as a decorative surface in pedestrian precincts. For example, in the early 1900s, most of the streets in the city of Grand Rapids, Michigan, were paved with bricks. Today, there are only about 20 blocks of brick-paved streets remaining (totalling less than 0.5 percent of all the streets in the city limits). Much like in Grand Rapids, municipalities across the United States began replacing brick streets with inexpensive asphalt concrete by the mid-20th century.\nIn Northwest Europe, bricks have been used in construction for centuries. Until recently, almost all houses were built almost entirely from bricks. Although many houses are now built using a mixture of concrete blocks and other materials, many houses are skinned with a layer of bricks on the outside for aesthetic appeal.\nBricks in the metallurgy and glass industries are often used for lining furnaces, in particular refractory bricks such as silica, magnesia, chamotte and neutral (chromomagnesite) refractory bricks. This type of brick must have good thermal shock resistance, refractoriness under load, high melting point, and satisfactory porosity. There is a large refractory brick industry, especially in the United Kingdom, Japan, the United States, Belgium and the Netherlands.\nEngineering bricks are used where strength, low water porosity or acid (flue gas) resistance are needed.\nIn the UK a red brick university is one founded in the late 19th or early 20th century. The term is used to refer to such institutions collectively to distinguish them from the older Oxbridge institutions, and refers to the use of bricks, as opposed to stone, in their buildings.\nColombian architect Rogelio Salmona was noted for his extensive use of red bricks in his buildings and for using natural shapes like spirals, radial geometry and curves in his designs.\nLimitations.\nStarting in the 20th century, the use of brickwork declined in some areas due to concerns about earthquakes. Earthquakes such as the San Francisco earthquake of 1906 and the 1933 Long Beach earthquake revealed the weaknesses of unreinforced brick masonry in earthquake-prone areas. During seismic events, the mortar cracks and crumbles, so that the bricks are no longer held together. Brick masonry with steel reinforcement, which helps hold the masonry together during earthquakes, has been used to replace unreinforced bricks in many buildings. Retrofitting older unreinforced masonry structures has been mandated in many jurisdictions. However, similar to steel corrosion in reinforced concrete, rebar rusting will compromise the structural integrity of reinforced brick and ultimately limit the expected lifetime, so there is a trade-off between earthquake safety and longevity to a certain extent.\nAccessibility.\nThe United States Access Board does not specify which materials a sidewalk must be made of in order to be ADA compliant, but states that sidewalks must not have surface variances of greater than . Due to the accessibility challenges of bricks, the Federal Highway Administration recommends against the use of bricks as well as cobblestones in its accessibility guide for sidewalks and crosswalks. The Brick Industry Association maintains standards for making brick more accessible for disabled people, with proper and regular maintenance being necessary to keep brick accessible.\nSome US jurisdictions, such as San Francisco, have taken steps to remove brick sidewalks from certain areas such as Market Street in order to improve accessibility.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "4527", "revid": "50759965", "url": "https://en.wikipedia.org/wiki?curid=4527", "title": "B\u00e9la Bart\u00f3k", "text": "Hungarian composer (1881\u20131945)\nB\u00e9la Viktor J\u00e1nos Bart\u00f3k (; ; 25 March 1881 \u2013 26 September 1945) was a Hungarian composer, pianist and ethnomusicologist. He is considered one of the most important composers of the 20th century; he and Franz Liszt are regarded as Hungary's greatest composers. Among his notable works are the opera \"Bluebeard's Castle\", the ballet \"The Miraculous Mandarin\", \"Music for Strings, Percussion and Celesta\", the Concerto for Orchestra and six string quartets. Through his collection and analytical study of folk music, he was one of the founders of comparative musicology, which later became known as ethnomusicology. Per Anthony Tommasini, Bart\u00f3k \"has empowered generations of subsequent composers to incorporate folk music and classical traditions from whatever culture into their works and was \"a formidable modernist who in the face of Schoenberg\u2019s breathtaking formulations showed another way, forging a language that was an amalgam of tonality, unorthodox scales and atonal wanderings.\"\nBiography.\nChildhood and early years (1881\u20131898).\nBart\u00f3k was born in the Banatian town of Nagyszentmikl\u00f3s in the Kingdom of Hungary (present-day S\u00e2nnicolau Mare, Romania) on 25 March 1881. On his father's side, the Bart\u00f3k family was a Hungarian lower noble family, originating from Borsodszir\u00e1k, Borsod. His paternal grandmother was a Catholic of Bunjevci origin, but considered herself Hungarian. Bart\u00f3k's father (1855\u20131888) was also named B\u00e9la. Bart\u00f3k's mother, Paula (n\u00e9e Voit) (1857\u20131939), spoke Hungarian fluently. A native of Tur\u00f3cszentm\u00e1rton (present-day Martin, Slovakia), she had German, Hungarian and Slovak or Polish ancestry.\nB\u00e9la displayed notable musical talent very early in life. According to his mother, he could distinguish between different dance rhythms that she played on the piano before he learned to speak in complete sentences. By the age of four he was able to play 40 pieces on the piano, and his mother began formally teaching him the next year.\nIn 1888, when he was seven, his father, the director of an agricultural school, died suddenly. His mother then took B\u00e9la and his sister, Erzs\u00e9bet, to live in Nagysz\u0151l\u0151s (present-day Vynohradiv, Ukraine) and then in Pressburg (present-day Bratislava, Slovakia). B\u00e9la gave his first public recital aged 11 in Nagysz\u0151l\u0151s, to positive critical reception. Among the pieces he played was his own first composition, written two years previously: a short piece called \"The Course of the Danube\". Shortly thereafter, L\u00e1szl\u00f3 Erkel accepted him as a pupil.\nEarly musical career (1899\u20131908).\nFrom 1899 to 1903, Bart\u00f3k studied piano under Istv\u00e1n Thom\u00e1n, a former student of Franz Liszt, and composition under J\u00e1nos Koessler at the Royal Academy of Music in Budapest. There he met Zolt\u00e1n Kod\u00e1ly, who made a strong impression on him and became a lifelong friend and colleague. In 1903, Bart\u00f3k wrote his first major orchestral work, \"Kossuth\", a symphonic poem that honored Lajos Kossuth, hero of the Hungarian Revolution of 1848.\nThe music of Richard Strauss, whom he met in 1902 at the Budapest premiere of \"Also sprach Zarathustra\", strongly influenced his early work. When visiting a holiday resort in the summer of 1904, Bart\u00f3k overheard a young nanny, Lidi D\u00f3sa from Kib\u00e9d in Transylvania, sing folk songs to the children in her care. This sparked his lifelong dedication to folk music.\nBeginning in 1907, he came under the influence of French composer Claude Debussy, whose compositions Kod\u00e1ly had brought back from Paris. Bart\u00f3k's large-scale orchestral works were still in the style of Johannes Brahms and Richard Strauss, but he wrote a number of small piano pieces which showed his growing interest in folk music. The first piece to show clear signs of this new interest is the String Quartet No. 1 in A minor (1908), which contains folk-like elements. He began teaching as a piano professor at the Liszt Academy of Music in Budapest. This position freed him from touring Europe as a pianist. Among his notable students were Fritz Reiner, Sir Georg Solti, Gy\u00f6rgy S\u00e1ndor, Ern\u0151 Balogh, Gisela Selden-Goth, and Lili Kraus. After Bart\u00f3k moved to the United States, he taught Jack Beeson and Violet Archer.\nIn 1908, Bartok and Kod\u00e1ly traveled into the countryside to collect and research old Magyar folk melodies. Their growing interest in folk music coincided with a contemporary social interest in traditional national culture. Magyar folk music had previously been categorised as Gypsy music. The classic example is Franz Liszt's \"Hungarian Rhapsodies\" for piano, which he based on popular art songs performed by Romani bands of the time. In contrast, Bart\u00f3k and Kod\u00e1ly discovered that the old Magyar folk melodies were based on pentatonic scales, similar to those in Asian folk traditions, such as those of Central Asia, Anatolia and Siberia.\nBart\u00f3k and Kod\u00e1ly set about incorporating elements of such Magyar peasant music into their compositions. They both frequently quoted folk song melodies \"verbatim\" and wrote pieces derived entirely from authentic songs. An example is Bartok's two volumes entitled \"For Children\" for solo piano, containing 80 folk tunes to which he wrote accompaniment. Bart\u00f3k's style in his art music compositions was a synthesis of folk music, classicism, and modernism. His melodic and harmonic sense was influenced by the folk music of Hungary, Romania, and other nations. He was especially fond of the asymmetrical dance rhythms and pungent harmonies found in Bulgarian music. Most of his early compositions offer a blend of nationalist and late Romantic elements.\nMiddle years and career (1909\u20131939).\nPersonal life.\nIn 1909, at the age of 28, Bart\u00f3k married M\u00e1rta Ziegler (1893\u20131967), aged 16. Their son, B\u00e9la Bart\u00f3k III, was born the next year. After nearly 15 years together, Bart\u00f3k divorced M\u00e1rta in June 1923. Two months after his divorce, he married Ditta P\u00e1sztory (1903\u20131982), a piano student, ten days after proposing to her. She was aged 19, he 42. Their son, P\u00e9ter, was born in 1924.\nRaised as a Catholic, by his early adulthood Bart\u00f3k had become an atheist. He later became attracted to Unitarianism and publicly converted to the Unitarian faith in 1916. Although Bart\u00f3k was not conventionally religious, according to his son B\u00e9la Bart\u00f3k III, \"he was a nature lover: he always mentioned the miraculous order of nature with great reverence\". He had a large collection of insects, one of his main interests outside music. As an adult, B\u00e9la III later became lay president of the Hungarian Unitarian Church.\nOpera.\nIn 1911, Bart\u00f3k wrote what was to be his only opera, \"Bluebeard's Castle\", dedicated to M\u00e1rta. In creating \"Bluebeard's Castle\", Bart\u00f3k uses symbolism to show parallels between unconscious motivation and fate. The opera in showing fate has a strong interaction between the characters and gives the idea that people are not able to control what the outcome will be. He entered it for a prize by the Hungarian Fine Arts Commission, but they rejected his work as not fit for the stage. In 1917 Bart\u00f3k revised the score for the 1918 premi\u00e8re and rewrote the ending. Following the 1919 revolution, in which he actively participated, he was pressured by the Horthy regime to remove the name of librettist B\u00e9la Bal\u00e1zs from the opera, as Bal\u00e1zs was of Jewish origin, was blacklisted, and had left the country for Vienna. \"Bluebeard's Castle\" received only one revival, in 1936, before Bart\u00f3k emigrated. For the remainder of his life, although devoted to Hungary, its people and its culture, he never felt much loyalty to the government or its official establishments.\nFolk music and composition.\nAfter his disappointment over the Fine Arts Commission competition, Bart\u00f3k wrote little for two or three years, preferring to concentrate on collecting and arranging folk music. Bart\u00f3k undertook this task with great skill and persistence; later, the folk music scholar Charles Seeger would describe him as \"one of the greatest field collectors of the first half of the 20th century.\" Bart\u00f3k found the phonograph an essential tool for collecting folk music for its accuracy, objectivity, and manipulability. He collected first in the Carpathian Basin (then the Kingdom of Hungary), where he notated Hungarian, Slovak, Romanian, and Bulgarian folk music. The developmental breakthrough for Bartok arrived when he collaboratively collected folk music with Zolt\u00e1n Kod\u00e1ly through the medium of a phonomotor, on which they studied classification possibilities (for individual folk songs) and recorded hundreds of cylinders. Bartok's compositional command of folk elements is expressed in such an authentic and undiluted a manner because of the scales, sounds, and rhythms that were so much a part of his native Hungary that he automatically saw music in these terms. He also collected in Moldavia, Wallachia, and (in 1913) Algeria. The outbreak of World War\u00a0I forced him to stop the expeditions, but he returned to composing with a ballet called \"The Wooden Prince\" (1914\u20131916) and the String Quartet No.\u00a02 in (1915\u20131917), both influenced by Debussy.\nBart\u00f3k's score for \"The Miraculous Mandarin\", another ballet, was influenced by Igor Stravinsky, Arnold Schoenberg and Richard Strauss. Though started in 1918, the story's sexual content kept it from being performed until 1926. He next wrote his two violin sonatas (written in 1921 and 1922, respectively), which are among his most harmonically and structurally complex pieces.\nIn March 1927, he visited Barcelona and performed the \"Rhapsody for piano\" Sz.\u00a026 with the Orquestra Pau Casals at the Gran Teatre del Liceu. During the same stay, he attended a concert by the Cobla Barcelona at the Palau de la M\u00fasica Catalana. According to the critic Joan Llongueras i Badia, \"he was very interested in the sardanas, above all, the freshness, spontaneity and life of our music\u00a0[...] he wanted to know the mechanism of the tenoras and the tibles, and requested data on the composition of the cobla and extension and characteristics of each instrument\".\nIn 1927\u20131928, Bart\u00f3k wrote his Third and Fourth String Quartets, after which his compositions demonstrated his mature style. Notable examples of this period are \"Music for Strings, Percussion and Celesta\" (1936) and Divertimento for String Orchestra (1939). The Fifth String Quartet was composed in 1934, and the Sixth String Quartet (his last) in 1939. In 1936 he travelled to Turkey to collect and study Turkish folk music. He worked in collaboration with Turkish composer Ahmet Adnan Saygun mostly around Adana.\nWorld War II and final years (1940\u20131945).\nIn 1940, as the European political situation worsened after the outbreak of World War\u00a0II, Bart\u00f3k was increasingly tempted to flee Hungary. He strongly opposed the Nazis and Hungary's alliance with Germany and the Axis powers under the Tripartite Pact. After the Nazis came to power in 1933, Bart\u00f3k refused to give concerts in Germany and broke away from his publisher there. His anti-fascist political views caused him a great deal of trouble with the establishment in Hungary. In his will recorded on 4\u00a0October 1940, he requested that no square or street be named after him until the Budapest squares Oktogon and Kod\u00e1ly k\u00f6r\u00f6nd, or in fact any square or street in Hungary, no longer bore the names of Mussolini or Hitler, as they did at the time he wrote his will. Having first sent his manuscripts out of the country, Bart\u00f3k reluctantly emigrated to the US with his wife, Ditta, in October 1940. They settled in New York City after arriving on the night of 29\u201330\u00a0October by a steamer from Lisbon. After joining them in 1942, their younger son P\u00e9ter Bart\u00f3k enlisted in the United States Navy, where he served in the Pacific during the remainder of the war and later settled in Florida, where he became a recording and sound engineer. His elder son by his first marriage, B\u00e9la Bart\u00f3k III, remained in Hungary and later worked as a railroad official until his retirement in the early 1980s.\nAlthough he became an American citizen in 1945 shortly before his death, Bart\u00f3k never felt fully at home in the United States. He initially found it difficult to compose in his new surroundings. Although he was well known in America as a pianist, ethnomusicologist and teacher, he was not well known as a composer. There was little American interest in his music during his final years. He and his wife Ditta gave some concerts, but demand for them was low. Bart\u00f3k, who had made some recordings in Hungary, also recorded for Columbia Records after he came to the US; many of these recordings (some with Bart\u00f3k's own spoken introductions) were later issued on LP and CD.\nBart\u00f3k was supported by a $3000-yearly research fellowship from Columbia University for several years (more than $32,000 in 2025 dollars). He and Ditta worked on a large collection of Serbian and Croatian folk songs in Columbia's libraries. Bart\u00f3k's economic difficulties during his first years in America were mitigated by publication royalties, teaching and performance tours. While his finances were always precarious, he did not live and die in poverty as was the common myth. He had enough friends and supporters to ensure that there was sufficient money and work available for him to live on. Bart\u00f3k was a proud man and did not easily accept charity. Despite being short on cash at times, he often refused money that his friends offered him out of their own pockets. Although he was not a member of the ASCAP, the society paid for any medical care he needed during his last two years, to which Bart\u00f3k reluctantly agreed. According to Edward Jablonski's 1963 article, \"At no time during Bart\u00f3k's American years did his income amount to less than $4,000 a year\" (about $43,000 in 2025 dollars). The first symptoms of his health problems began late in 1940, when his right shoulder began to show signs of stiffening. In 1942, symptoms increased and he started having bouts of fever. Bart\u00f3k's illness was at first thought to be a recurrence of the tuberculosis he had experienced as a young man, and one of his doctors in New York was Edgar Mayer, director of Will Rogers Memorial Hospital in Saranac Lake, but medical examinations found no underlying disease. Finally, in April 1944, leukemia was diagnosed, but by this time, little could be done.\nAs his body slowly failed, Bart\u00f3k found more creative energy and produced a final set of masterpieces, partly thanks to the violinist Joseph Szigeti and the conductor Fritz Reiner (Reiner had been Bart\u00f3k's friend and champion since his days as Bart\u00f3k's student at the Royal Academy). Bart\u00f3k's last work might well have been the String Quartet No.\u00a06 but for Serge Koussevitzky's commission for the Concerto for Orchestra. Koussevitsky's Boston Symphony Orchestra premiered the work in December 1944 to highly positive reviews. The Concerto for Orchestra quickly became Bart\u00f3k's most popular work, although he did not live to see its full impact.\nIn 1944, he was also commissioned by Yehudi Menuhin to write a Sonata for Solo Violin. In 1945, Bart\u00f3k composed his Piano Concerto No.\u00a03, a graceful and almost neo-classical work, as a surprise 42nd birthday present for Ditta, but he died just over a month before her birthday, with the scoring not quite finished. He had also sketched his Viola Concerto, but had barely started the scoring at his death, leaving completed only the viola part and sketches of the orchestral part.\nB\u00e9la Bart\u00f3k died at age 64 in a hospital in New York City from complications of leukemia (specifically, of secondary polycythemia) on 26\u00a0September 1945. His funeral was attended by only ten people. Aside from his widow and their son, other attendees included Gy\u00f6rgy S\u00e1ndor.\nBart\u00f3k's body was initially interred in Ferncliff Cemetery in Hartsdale, New York. During the final year of communist Hungary in the late 1980s, the Hungarian government, along with his two sons, B\u00e9la III and P\u00e9ter, requested that his remains be exhumed and transferred back to Budapest for burial, where Hungary arranged a state funeral for him on 7\u00a0July 1988. He was re-interred at Budapest's Farkasr\u00e9ti Cemetery, next to the remains of Ditta, who died in 1982, one year after what would have been B\u00e9la Bart\u00f3k's 100th birthday.\nThe two unfinished works were later completed by his pupil Tibor Serly. Gy\u00f6rgy S\u00e1ndor was the soloist in the first performance of the Third Piano Concerto on 8\u00a0February 1946. Ditta P\u00e1sztory-Bart\u00f3k later played and recorded it. The Viola Concerto was revised and published in the 1990s by Bart\u00f3k's son; this version may be closer to what Bart\u00f3k intended. Concurrently, Peter Bart\u00f3k, in association with Argentine musician Nelson Dellamaggiore, worked to reprint and revise past editions of the Third Piano Concerto.\nMusic.\nBart\u00f3k's music reflects two trends that dramatically changed the sound of music in the 20th century: the breakdown of the diatonic system of harmony that had served composers for the previous two hundred years; and the revival of nationalism as a source for musical inspiration, a trend that began with Mikhail Glinka and Anton\u00edn Dvo\u0159\u00e1k in the last half of the 19th century. In his search for new forms of tonality, Bart\u00f3k turned to Hungarian folk music, as well as to other folk music of the Carpathian Basin and even of Algeria and Turkey; in so doing he became influential in that stream of modernism which used indigenous music and techniques.\nOne characteristic style of music is his Night music, which he used mostly in slow movements of multi-movement ensemble or orchestral compositions in his mature period. It is characterised by \"eerie dissonances providing a backdrop to sounds of nature and lonely melodies\". An example is the third movement (Adagio) of his \"Music for Strings, Percussion and Celesta\". His music can be grouped roughly in accordance with the different periods in his life.\nEarly years (1890\u20131902).\nThe works of Bart\u00f3k's youth were written in a classical and early romantic style touched with influences of popular and romani\nmusic. Between 1890 and 1894 (9 to 13 years of age) he wrote 31 piano pieces. Although most of these were simple dance pieces, in these early works Bart\u00f3k began to tackle some more advanced forms, as in his ten-part programmatic \"A Duna foly\u00e1sa\" (\"The Course of the Danube\", 1890\u20131894), which he played in his first public recital in 1892.\nIn Catholic grammar school Bart\u00f3k took to studying the scores of composers \"from Bach to Wagner\", his compositions then advancing in style and taking on similarities to Schumann and Brahms. Following his matriculation into the Budapest Academy in 1890 he composed very little, though he began to work on exercises in orchestration and familiarized himself thoroughly with the operas of Wagner. In 1902 his creative energies were revitalized by the discovery of the music of Richard Strauss, whose tone poem \"Also sprach Zarathustra\", according to Bart\u00f3k, \"stimulated the greatest enthusiasm in me; at last I saw the way that lay before me\". Bart\u00f3k also owned the score to \"A Hero's Life\", which he transcribed for the piano and committed to memory.\nNew influences (1903\u20131911).\nUnder the influence of Strauss, Bart\u00f3k composed in 1903 \"Kossuth\", a symphonic poem in ten tableaux on the subject of the 1848 Hungarian war of independence, reflecting the composers growing interest in musical nationalism. A year later he renewed his opus numbers with the \"Rhapsody for Piano and Orchestra\" serving as Opus\u00a01. Driven by nationalistic fervor and a desire to transcend the influence of prior composers, Bart\u00f3k began a lifelong devotion to folk music, which was sparked by his overhearing nanny Lidi D\u00f3sa's singing of Transylvanian folk songs at a Hungarian resort in 1904. Bart\u00f3k began to collect Magyar peasant melodies, later extending to the folk music of other peoples of the Carpathian Basin, Slovaks, Romanians, Rusyns, Serbs and Croatians. He used fewer and fewer romantic elements, in favour of an idiom that embodied folk music as intrinsic and essential to its style. Later in life he commented on the incorporation of folk and art music:\nThe question is, what are the ways in which peasant music is taken over and becomes transmuted into modern music? We may, for instance, take over a peasant melody unchanged or only slightly varied, write an accompaniment to it and possibly some opening and concluding phrases. This kind of work would show a certain analogy with Bach's treatment of chorales.\u00a0... Another method\u00a0... is the following: the composer does not make use of a real peasant melody but invents his own imitation of such melodies. There is no true difference between this method and the one described above.\u00a0... There is yet a third way\u00a0... Neither peasant melodies nor imitations of peasant melodies can be found in his music, but it is pervaded by the atmosphere of peasant music. In this case we may say, he has completely absorbed the idiom of peasant music which has become his musical mother tongue.\nBart\u00f3k became first acquainted with Debussy's music in 1907 and regarded his music highly. In an interview in 1939 Bart\u00f3k said:\nDebussy's great service to music was to reawaken among all musicians an awareness of harmony and its possibilities. In that, he was just as important as Beethoven, who revealed to us the possibilities of progressive form, or as Bach, who showed us the transcendent significance of counterpoint. Now, what I am always asking myself is this: is it possible to make a synthesis of these three great masters, a living synthesis that will be valid for our time?\nDebussy's influence is present in the Fourteen Bagatelles (1908). These made Ferruccio Busoni exclaim: \"At last something truly new!\" Until 1911, Bart\u00f3k composed widely differing works which ranged from adherence to romantic style, to folk song arrangements and to his modernist opera \"Bluebeard's Castle\". The negative reception of his work led him to focus on folk music research after 1911 and abandon composition with the exception of folk music arrangements.\nInspiration and experimentation (1916\u20131921).\nHis pessimistic attitude towards composing was lifted by the stormy and inspiring contact with Kl\u00e1ra Gombossy in the summer of 1915. This interesting episode in Bart\u00f3k's life remained hidden until it was researched by Denijs Dille between 1979 and 1989. Bart\u00f3k started composing again, including the Suite for piano opus\u00a014 (1916), and \"The Miraculous Mandarin\" (1919) and he completed \"The Wooden Prince\" (1917).\nBart\u00f3k felt the result of World War I as a personal tragedy. Many regions he loved were severed from Hungary: Transylvania, the Banat (where he was born), and Bratislava (Pozsony, where his mother had lived). Additionally, the political relations between Hungary and other successor states to the Austro-Hungarian empire prohibited his folk music research outside of Hungary. Bart\u00f3k also wrote the noteworthy \"Eight Improvisations on Hungarian Peasant Songs\" in 1920 and the sunny \"Dance Suite\" in 1923, the year of his second marriage.\n\"Synthesis of East and West\" (1926\u20131945).\nIn 1926, Bart\u00f3k needed a significant piece for piano and orchestra with which he could tour in Europe and America. He was particularly inspired by American composer Henry Cowell's controversial use of intense tone clusters on the piano while touring western Europe. Bart\u00f3k happened to be present at one of these concerts and (to avoid causing offence) later requested Cowell's permission to use his technique, which Cowell granted. In the preparation for writing his first Piano Concerto, he wrote his Sonata, \"Out of Doors\", and \"Nine Little Pieces\", all for solo piano, and all of which prominently utilize clusters. He increasingly found his own voice in his maturity. The style of his last period\u00a0\u2013 named \"Synthesis of East and West\"\u00a0\u2013 is hard to define let alone to put under one term. In his mature period, Bart\u00f3k wrote relatively few works but most of them are large-scale compositions for large settings. Only his voice works have programmatic titles and his late works often adhere to classical forms.\nAmong Bart\u00f3k's most important works are the six string quartets (1909, 1917, 1927, 1928, 1934, and 1939), the \"Cantata Profana\" (1930), which Bart\u00f3k declared was the work he felt and professed to be his most personal \"credo\", the \"Music for Strings, Percussion and Celesta\" (1936), the Concerto for Orchestra (1943) and the Third Piano Concerto (1945). He made a lasting contribution to the literature for younger students: for his son P\u00e9ter's music lessons, he composed \"Mikrokosmos\", a six-volume collection of graded piano pieces.\nMusical analysis.\nPaul Wilson lists as the most prominent characteristics of Bart\u00f3k's music from late 1920s onwards the influence of the Carpathian basin and European art music, and his changing attitude toward (and use of) tonality, but without the use of the traditional harmonic functions associated with major and minor scales.\nAlthough Bart\u00f3k claimed in his writings that his music was always tonal, he rarely used the chords or scales normally associated with tonality, and so the descriptive resources of tonal theory are of limited use. George and Elliott focus on his alternative methods of signaling tonal centers, via axes of inversional symmetry. Others view Bart\u00f3k's axes of symmetry in terms of atonal analytic protocols. Richard argues that inversional symmetry is often a byproduct of another atonal procedure, the formation of chords from transpositionally related dyads. Atonal pitch-class theory also furnishes resources for exploring polymodal chromaticism, projected sets, privileged patterns, and large set types used as source sets such as the equal tempered twelve tone aggregate, octatonic scale (and alpha chord), the diatonic and \"heptatonia secunda\" seven-note scales, and less often the whole tone scale and the primary pentatonic collection.\nHe rarely used the simple aggregate actively to shape musical structure, though there are notable examples such as the second theme from the first movement of his Second Violin Concerto, of which he commented that he \"wanted to show Schoenberg that one can use all twelve tones and still remain tonal\". More thoroughly, in the first eight measures of the last movement of his Second Quartet, all notes gradually gather with the twelfth (G\u266d) sounding for the first time on the last beat of measure 8, marking the end of the first section. The aggregate is partitioned in the opening of the Third String Quartet with C\u266f\u2013D\u2013D\u266f\u2013E in the accompaniment (strings) while the remaining pitch classes are used in the melody (violin 1) and more often as 7\u201335 (diatonic or \"white-key\" collection) and 5\u201335 (pentatonic or \"black-key\" collection) such as in no. 6 of the \"Eight Improvisations\". There, the primary theme is on the black keys in the left hand, while the right accompanies with triads from the white keys. In measures 50\u201351 in the third movement of the Fourth Quartet, the first violin and cello play black-key chords, while the second violin and viola play stepwise diatonic lines. On the other hand, from as early as the Suite for piano, Op. 14 (1914), he occasionally employed a form of serialism based on compound interval cycles, some of which are maximally distributed, multi-aggregate cycles. Ern\u0151 Lendvai analyses Bart\u00f3k's works as being based on two opposing tonal systems, that of the acoustic scale and the axis system, as well as using the golden section as a structural principle.\nMilton Babbitt, in his 1949 review of Bart\u00f3k's string quartets, criticized Bart\u00f3k for using tonality and non-tonal methods unique to each piece. Babbitt noted that \"Bart\u00f3k's solution was a specific one, it cannot be duplicated\". Bart\u00f3k's use of \"two organizational principles\"\u2014tonality for large scale relationships and the piece-specific method for moment to moment thematic elements\u2014was a problem for Babbitt, who worried that the \"highly attenuated tonality\" requires extreme non-harmonic methods to create a feeling of closure.\nCatalogues.\nThe cataloguing of Bart\u00f3k's works is somewhat complex. Bart\u00f3k assigned opus numbers to his works three times, the last of these series ending with the Sonata for Violin and Piano No. 1, Op. 21 in 1921. He ended this practice because of the difficulty of distinguishing between original works and ethnographic arrangements, and between major and minor works. Since his death, three attempts\u2014two full and one partial\u2014have been made at cataloguing. The first, and still most widely used, is Andr\u00e1s Sz\u0151ll\u0151sy's chronological Sz. numbers, from 1 to 121. Denijs Dille subsequently reorganised the juvenilia (Sz. 1\u201325) thematically, as DD numbers 1 to 77. The most recent catalogue is that of L\u00e1szl\u00f3 Somfai; this is a chronological index with works identified by BB numbers 1 to 129, incorporating corrections based on the B\u00e9la Bart\u00f3k Thematic Catalogue.\nOn 1 January 2016, Bart\u00f3k's works entered the public domain in the European Union.\nDiscography.\nTogether with his like-minded contemporary Zolt\u00e1n Kod\u00e1ly, Bart\u00f3k embarked on an extensive programme of field research to capture the folk and peasant melodies of Magyar, Slovak and Romanian language territories. At first they transcribed the melodies by hand, but later they began to use a phonomotor, a wax cylinder recording machine invented by Thomas Edison. Compilations of Bart\u00f3k's field recordings, interviews, and original piano playing have been released over the years, largely by the Hungarian record label Hungaroton: \nA compilation of field recordings and transcriptions for two violas was also recently released by Tantara Records in 2014.\nOn 18 March 2016 Decca Classics released \"B\u00e9la Bart\u00f3k: The Complete Works\", the first ever complete compilation of all of Bart\u00f3k's compositions, including new recordings of never-before-recorded early piano and vocal works. However, none of the composer's own performances are included in this 32-disc set.\nReferences.\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nSources.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "4528", "revid": "50657366", "url": "https://en.wikipedia.org/wiki?curid=4528", "title": "Bill Haley", "text": "American rock and roll music pioneer (1925\u20131981)\nWilliam John Clifton Haley (; July 6, 1925 \u2013 February 9, 1981) also known as Bill Haley, was an American rock and roll musician. He is credited by many with first popularizing this form of music in the early 1950s with his group Bill Haley &amp; His Comets and million-selling hits such as \"Rock Around the Clock\", \"See You Later, Alligator\", \"Shake, Rattle and Roll\", \"Rocket 88\", \"Skinny Minnie\", and \"Razzle Dazzle\". Haley has sold over 60 million records worldwide. In 1987, he was posthumously inducted into the Rock and Roll Hall of Fame.\nEarly life and career.\nHaley was born July 6, 1925, in Highland Park, Michigan. In 1929, the four-year-old Haley underwent an inner-ear mastoid operation which accidentally severed an optic nerve, leaving him blind in his left eye for the rest of his life. It is said that he adopted his trademark kiss curl over his right eye to draw attention from his left, but it also became his gimmick, and added to his popularity. As a result of the effects of the Great Depression on the Detroit area, his father moved the family to Bethel Township, Pennsylvania, when Bill was seven years old. Haley's father William Albert Haley (1900\u20131956) was from Kentucky and played the banjo and mandolin, and his mother, Maude Green (1895\u20131955), who was originally from Ulverston in Lancashire, England, was a technically accomplished keyboardist with classical training. Haley told the story that when he made a simulated guitar out of cardboard, his parents bought him a real one.\nOne of his first appearances was in 1938 for a Bethel Junior baseball team entertainment event, performing guitar and songs when he was 13 years old.\nAccording to the anonymous sleeve notes accompanying the 1956 Decca album \"Rock Around the Clock\", Haley left home at fifteen with his guitar and spent the next few years poverty-stricken until he joined a group called the Down Homers while they were in Hartford, Connecticut. In 1947, Haley formed his own group, Four Aces of Western Swing, later renamed to the Saddlemen. The group subsequently signed with Dave Miller's Holiday Records and, on June 14, 1951, the Saddlemen recorded a cover of the Delta Cats \"Rocket 88\".\nBill Haley and His Comets.\nDuring the Labor Day weekend in 1952, the Saddlemen were renamed Bill Haley with Haley's Comets. The name was inspired by the supposedly official pronunciation of Halley's Comet and was suggested by Bob Johnson, program director at radio station WPWA where Bill Haley had a live radio program from 12:00noon to 1:00p.m. In 1953, Haley's recording of \"Crazy Man, Crazy\" (co-written by Haley and his bass player, Marshall Lytle, although Lytle would not receive credit until 2001) hit the American charts, peaking at number 12 on \"Billboard\" and number 11 on \"Cash Box\". Some sources indicate that this was the first rock and roll record in history, although rockabilly might be a more appropriate term. By the time this record was released, the group's name had been revised to using the term \"Comets\" instead of \"Saddlemen\".\nIn 1954, Haley recorded \"Rock Around the Clock\". Initially, it was only a moderate success, peaking at number 36 on the \"Cash Box\" pop singles chart and staying on the charts for just two weeks. On re-release, the record reached number one on July 9, 1955.\nHaley had already had a worldwide hit with \"Shake, Rattle and Roll\", another rhythm and blues cover (in this case from Big Joe Turner), which went on to sell a million copies and was the first rock 'n' roll song to enter the UK Singles Chart in December 1954, becoming a gold record. He retained elements of the original (which was slow blues), but sped it up with some country music aspects into the song (specifically, Western swing) and changed up the lyrics. Haley and his band were important in launching the music known as \"Rock and Roll\" to a wider audience after a period of it being considered an underground genre.\nWhen \"Rock Around the Clock\" appeared as the theme song of the 1955 film \"Blackboard Jungle\" starring Glenn Ford, it soared to the top of the American \"Billboard\" chart for eight weeks. The single is commonly used as a convenient line of demarcation between the \"rock era\" and the music industry that preceded it. \"Billboard\" separated its statistical tabulations into 1890\u20131954 and 1955\u2013present. After the record rose to number one, Haley became widely popular with those who had come to embrace the new style of music. With the song's success, the age of rock music began overnight and ended the dominance of the jazz and pop standards performed by Frank Sinatra, Jo Stafford, Perry Como, Bing Crosby, Eddie Fisher, and Patti Page. \"Rock Around the Clock\" was also the first record to sell over one million copies in both Britain and Germany. Danny Cedrone, not a member of The Comets, played the guitar solo on the record, though did not live long enough to see the song's success as he died shortly after the recording following a fall down stairs at his home, aged 33.\nBill Haley and the Comets performed \"Rock Around the Clock\" on the \"Texaco Star Theater\" hosted by Milton Berle on May 31, 1955, on NBC in an\" a cappella\" and lip-synched version. Berle predicted that the song would go number one: \"A group of entertainers who are going right to the top.\" Berle also sang and danced to the song which was performed by the entire cast of the show. This was one of the earliest nationally televised performances by a rock and roll band and provided the new musical genre with a much wider audience.\nBill Haley and the Comets were the first rock and roll act to appear on American musical variety series the \"Ed Sullivan Show\" on August 7, 1955, on CBS in a broadcast that originated from the Shakespeare Festival Theater in Stratford, Connecticut. They performed a live version of \"Rock Around the Clock\" with Franny Beecher on lead guitar and Dick Richards on drums. The band made their second appearance on the show on Sunday, April 28, 1957, performing the songs \"Rudy's Rock\" and \"Forty Cups of Coffee\".\nLater on in 1957, Haley became the first major American rock singer to tour Europe. Haley continued to score hits throughout the 1950s such as \"See You Later, Alligator\" and he starred in the first rock and roll musical films \"Rock Around the Clock\" and \"Don't Knock the Rock\", both in 1956. Haley was already 30 years old, and his popularity was soon eclipsed in the United States by the younger Elvis Presley, but continued to enjoy great popularity in Latin America, Europe, and Australia during the 1960s.\nBill Haley and the Comets appeared on \"American Bandstand\" hosted by Dick Clark on ABC twice in 1957, on the prime time show October 28, 1957, and on the regular daytime show on November 27, 1957. The band also appeared on Dick Clark's \"Saturday Night Beechnut Show\", also known as \"The Dick Clark Show\", a primetime TV series from New York on March 22, 1958, during the first season and on February 20, 1960, performing \"Rock Around the Clock\"; \"Shake, Rattle and Roll\"; and \"Tamiami\".\nPersonal life.\nMarriages.\nHaley was married at least three times:\nChildren.\nHaley had at least ten children. John W. Haley, his eldest son, wrote \"Sound and Glory\", a biography of Haley. His youngest daughter, Gina Haley, is a professional musician based in Texas. Scott Haley is an athlete. His youngest son Pedro is also a musician.\nHe also had a daughter, Martha Maria, from his marriage with Martha Velasco.\nBill Haley Jr., Haley's second son and first with Joan Barbara \"Cuppy\" Haley-Hahn, publishes a regional business magazine. In 2011, he formed a tribute band, performing his father's music and telling the stories behind the songs.\nLater career and death.\nHaley failed to achieve the level of success enjoyed by contemporaries such as Little Richard and Jerry Lee Lewis. According to one source, \"he had conflicted feelings about fame, was extremely private, suffered chronic alcoholism, and troubled relationships\". Having admitted to an alcohol problem in a 1974 radio interview for the BBC, Haley continued to battle alcoholism into the 1970s. Nonetheless, he and his band continued to be a popular touring act, benefiting from a 1950s nostalgia movement that began in the late 1960s and the signing of a lucrative record deal with the European Sonet label. He performed for Queen Elizabeth II at the Royal Variety Performance on November 26, 1979.\nThe October 25, 1980, issue of German tabloid \"Bild\" reported that Haley had a brain tumor. Haley's British manager, Patrick Malynn, was quoted as saying that \"Haley had taken a fit [and] didn't recognize anyone anymore.\" In addition, a doctor who examined Haley said that the tumor was inoperable.\nHaley's widow Martha, who was with him in these troubling times, denied he had a brain tumor, as did his close friend Hugh McCallum. Martha and friends related that Haley did not want to go on the road anymore and that ticket sales for that planned tour of Germany in the fall of 1980 were slow. McCallum said, \"It's my unproven gut feeling that that [the brain tumor] was said to curtail talks about the tour and play the sympathy card.\"\nAt the same time, Haley's alcoholism appeared to be worsening. According to Martha, by this time, she and Haley fought all the time and she told him to stop drinking or move out. Eventually, he moved into a room in their pool house. Martha still took care of him and sometimes, he would come in the house to eat, but he ate very little. \"There were days we never saw him\", said his daughter Martha Maria. In addition to Haley's drinking problems, it was becoming evident that he was also developing serious mental health issues. Martha Maria said, \"It was like sometimes he was drunk even when he wasn't drinking.\" After being picked up by the police in Harlingen, Texas several times for alleged intoxication, Martha had a judge put Haley in the hospital, where he was seen by a psychiatrist, who said Haley's brain was overproducing a chemical, like adrenaline. The doctor prescribed a medication to stop the overproduction, but said Haley would have to stop drinking. Martha said, \"This is pointless.\" She took him home, however, fed him and gave him his first dose. As soon as he felt better, he went back out to his room in the pool house, and the downward spiral continued until his death.\nMedia reports immediately following his death indicated that Haley displayed deranged and erratic behavior in the final weeks of his life. According to a biography of Haley by John Swenson, released in 1982, Haley made a succession of bizarre, mostly monologue late-night phone calls to friends and relatives toward the end of his life in which he was semi-coherent. His first wife has been quoted as saying, \"He would call you and ramble, dwelling on the past...\" The biography also describes Haley painting the windows of his home black, but there is little other information available about his final days.\nHaley died at his home in Harlingen on February9, 1981, aged 55. He was discovered lying motionless on his bed by a friend who had stopped by to visit him. The friend immediately called the police and Haley was pronounced dead at the scene. Haley's death certificate gave \"natural causes, most likely a heart attack\" as being the cause. Following a small funeral service attended by 75 people, Haley was cremated in Brownsville, Texas.\nTributes and legacy.\nHaley has sold over 60 million records worldwide.\nHaley received a star on the Hollywood Walk of Fame at 6350 Hollywood Boulevard on February8, 1960, for his contributions to the music industry.\nIn 1982, Haley's \"Rock Around the Clock\" was inducted into the Grammy Hall of Fame, a special Grammy award established in 1973 to honor recordings at least 25 years old and with \"qualitative or historical significance\". In 2018, it was selected for preservation in the National Recording Registry by the Library of Congress as being \"culturally, historically, or aesthetically significant\".\nHaley was posthumously inducted into the Rock and Roll Hall of Fame in 1987. His son Pedro represented him at the ceremony. The Comets were separately inducted into the Hall of Fame as a group in 2012, after a rule change allowed the induction of backing groups.\nSurviving members of the 1954\u201355 contingent of Haley's Comets reunited in the late 1980s and continued to perform for many years around the world. By 2014, only two members of this particular contingent were still alive (saxophonist Joey Ambrose and drummer Dick Richards), but they continued to perform in Branson and Europe. In 2019, Richards died at the age of 95, followed by Ambrose's death in 2021 aged 87. Ambrose was considered to be the last surviving original member of the Comets. \nIn February 2006, the International Astronomical Union announced the naming of asteroid 79896 Billhaley to mark the 25th anniversary of Haley's death.\nIn March 2007, the Original Comets opened the Bill Haley Museum in Munich, Germany. On October 27, 2007, ex-Comets guitar player Bill Turner opened the Bill Haley Museum for the public.\nIn December 2017, Haley was inducted into the National Rhythm &amp; Blues Hall of Fame.\nFilm portrayals.\nUnlike his contemporaries, Haley has rarely been portrayed on screen. Following the success of \"The Buddy Holly Story\" in 1978, Haley expressed interest in having his life story committed to film, but this ultimately never came to fruition.\nHaley has been portrayed by:\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "4529", "revid": "50327534", "url": "https://en.wikipedia.org/wiki?curid=4529", "title": "Northern bobwhite", "text": "Species of bird\n&lt;templatestyles src=\"Template:Taxobox/core/styles.css\" /&gt;\nThe northern bobwhite (Colinus virginianus), also known as the Virginia quail or (in its home range) bobwhite quail, is a ground-dwelling bird native to Canada, the United States, Mexico, and Cuba, with introduced populations elsewhere in the Caribbean, Europe, and Asia. It is a member of the group of species known as New World quail (Odontophoridae). They were initially placed with the Old World quail in the pheasant family (Phasianidae), but are not particularly closely related. The name \"bobwhite\" is an onomatopoeic derivation from its characteristic whistling call. Despite its secretive nature, the northern bobwhite is one of the most familiar quails in eastern North America, because it is frequently the only quail in its range. Habitat degradation has contributed to the northern bobwhite population in eastern North America declining by roughly 85% from 1966 to 2014. This population decline is apparently range-wide and continuing.\nThere are 20 subspecies of northern bobwhite, many of which are hunted extensively as game birds. One subspecies, the masked bobwhite (\"Colinus virginianus ridgwayi\"), is listed as endangered with wild populations located in the northern Mexican state of Sonora and a reintroduced population in Buenos Aires National Wildlife Refuge in southern Arizona.\nTaxonomy.\nThe northern bobwhite was formally described in 1758 by the Swedish naturalist Carl Linnaeus in the tenth edition of his \"Systema Naturae\" under the binomial name \"Tetrao virginianus\". Linnaeus specified the type location as \"America\" but this has been restricted to the state of Virginia. Linnaeus based his account on the \"American partridge\" that had been described and illustrated by the English naturalist Mark Catesby in his book \"The Natural History of Carolina, Florida and the Bahama Islands\". The northern bobwhite is now one of four species placed in the genus \"Colinus\" that was introduced in 1820 by the German naturalist Georg August Goldfuss.\nSubspecies.\nThere are 20 recognized subspecies in four groups. One subspecies, the Key West bobwhite (\"C. v. insulanus\"), is extinct. The subspecies are listed in taxonomic order:\nThe holotype specimen of \"Ortyx pectoralis\" Gould (https://) is held in the collections of the National Museums Liverpool at the World Museum, with accession number D3713. The specimen died in the aviary at Knowsley Hall, Lancashire and came to the Liverpool national collection via the 13th Earl of Derby's collection, which was bequeathed to the people of Liverpool in 1851.\nDescription.\nThe northern bobwhite is a moderately-sized quail, and is the only small galliform native to eastern North America. The bobwhite can range from in length with a wingspan. As indicated by body mass, weights increase in birds found further north, as corresponds to Bergmann's rule. In Mexico, northern bobwhites weigh from whereas in the north they average and large males can attain as much as . Among standard measurements, the wing chord is , the tail is the culmen is and the tarsus is . It has the typical chunky, rounded shape of a quail. The bill is short, curved and brown-black in color. This species is sexually dimorphic. Males have a white throat and brow stripe bordered by black. The overall rufous plumage has gray mottling on the wings, white scalloped stripes on the flanks, and black scallops on the whitish underparts. The tail is gray.\nThe clear whistle \"bob-WHITE\" or \"bob-bob-WHITE\" call is very recognizable. The syllables are slow and widely spaced, rising in pitch a full octave from beginning to end. Other calls include lisps, peeps, and more rapidly whistled warning calls. \nDistribution and habitat.\nThe northern bobwhite can be found year-round in agricultural fields, grassland, open woodland areas, roadsides and wood edges. Its range covers the southeastern quadrant of the United States from the Great Lakes and southern Minnesota east to New York State and southern Massachusetts, and extending west to southern Nebraska, Kansas, Oklahoma, Colorado front-range foothills to 7,000 feet, and all but westernmost Texas.\nIt is absent from the southern tip of Florida (where the extinct Key West bobwhite subspecies once lived) and the highest elevations of the Appalachian Mountains, but occurs in eastern Mexico and in Cuba, and has been introduced to Hispaniola (both the Dominican Republic and Haiti), the Bahamas, the Turks and Caicos Islands, the U.S. Virgin Islands (formerly), Puerto Rico, France, China, Portugal, and Italy. Isolated populations also have been introduced in the US states of Oregon and Washington. The northern bobwhite has also been introduced to New Zealand.\nThere is no self-sustaining population in Pennsylvania, where the bird is considered extirpated; it is also considered extirpated in the states of New Hampshire and Connecticut. Its distribution in New York has been limited to Suffolk and Nassau Counties on Long Island, as well as potential population pockets in Upstate New York. The bird is considered declining or extirpated throughout much of the Northeastern United States. Similarly, the bird is almost extirpated from Ontario (and Canada as a whole), with the only self-sustaining population confirmed to exist recorded on Walpole Island.\nBehavior and ecology.\nLike most game birds, the northern bobwhite is shy and elusive. When threatened, it will crouch and freeze, relying on camouflage to stay undetected, but will flush into low flight if closely disturbed. It is generally solitary or paired early in the year, but family groups are common in the late summer and winter roosts may have two dozen or more birds in a single covey.\nBreeding.\nThe species was once considered monogamous, but with the advent of radio telemetry, the sexual behavior of bobwhites has better been described as ambisexual polygamy. Either parent may incubate a clutch for 23 days, and the precocial young leave the nest shortly after hatching. The main source of nest failure is predation, with nest success averaging 28% across their range. However, the nest success of stable populations is typically much higher than this average, and the aforementioned estimate includes values for declining populations.\nBrooding behavior varies in that amalgamation (kidnapping, adopting, creching, gang brooding) may occur. An incubating parent may alternatively stay with its young. A hen may re-nest up to four times until she has a successful nest. However, it is extremely rare for bobwhites to hatch more than two successful nests within one nesting season.\nFood and feeding.\nThe northern bobwhite's diet consists of plant material and small invertebrates, such as snails, ticks, grasshoppers, beetles, spiders, crickets, and leafhoppers. Plant sources include seeds, wild berries, partridge peas, and cultivated grains. It forages on the ground in open areas with some spots of taller vegetation.\nOptimal nutrient requirements for bobwhite vary depending on the age of bird and the time of the year. For example, the optimal protein requirement for egg laying hens (23% protein) is much higher than for males (16%).\nRelationship to humans.\nIntroduced populations.\nEuropean Union.\nNorthern bobwhite were introduced into Italy in 1927, and are reported in the plains and hills in the northwest of the country. Other reports from the EU are in France, Spain, and the Balkans. As bobwhites are highly productive and popular aviary subjects, it is reasonable to expect other introductions have been made in other parts of the EU, especially in the U.K. and Ireland, where game-bird breeding, liberation, and naturalization are relatively common practices.\nNew Zealand.\nFrom 1898 to 1902, some 1,300 birds were imported from America and released in many parts of the North and South Islands, from Northland to Southland. The bird was briefly on the Nelson game shooting licence, but: \"It would seem that the committee was a little too eager in placing these Quail on the licence, or the shooters of the day were over-zealous and greedy in their bag limits, for the Virginian Quail, like the Mountain Quail were soon a thing of the past.\" The Taranaki (Acclimatisation) Society released a few in 1900 and was confidant that in a year or two they might offer good sport; two years later, broods were reported and the species was said to be \"steadily increasing\"; but after another two years they seemed \"to have disappeared\" and that was the end of them. The Otago (Acclimatisation) Society imported more in 1948, but these releases did no good. After 1923, no more genuinely wild birds were sighted until 1952, when a small population was found northwest of Wairoa in the Ruapapa Road area. Since then, bobwhite have been found at several localities around Waikaremoana, in farmland, open bush and along roadsides.\nMore birds have been imported into New Zealand by private individuals since the 1990s and a healthy captive population is now held by backyard aviculturists and have been found to be easily cared for and bred and are popular for their song and good looks. A larger proportion of the national captive population belong to a few game preserves and game bird breeders. Though the birds would be self-sustaining in the wild if they were protected; it is tricky to guess what the effect of an annual population subsidy and hunting has on any of the original populations from the Acclimatisation Society releases.\nAn albino hen was present in a covey in Bayview, Hawkes Bay for a couple of seasons sometime around 2000.\nCaptivity.\nHousing.\nBobwhites are generally compatible with most parrots, softbills and doves. This species should, however, be the only ground-dwelling species in the aviary. Most individuals will do little damage to finches, but one should watch that nests are not being crushed when the species perches at night. Single pairs are preferred, unless the birds have been raised together as a group since they were chicks. Some fighting will occur between cocks at breeding time. One cock may be capable of breeding with several hens, but the fertility seems to be highest in the eggs from the \"preferred\" hen. Aviary style is a compromise between what is tolerated by the bird and what is best for the bird. Open parrot-style type aviaries may be used, but some birds will remain flighty and shy in this situation. In a planted aviary, this species will generally settle down to become quite tame and confiding. Parents with chicks will roost on the ground, forming a circular arrangement, with heads facing outwards. In the early morning and late afternoon, the cock will utter his call, which, although not loud, carries well and may offend noise-sensitive neighbors. Most breeding facilities keep birds in breeding groups on wire up off the ground. \nFeeding.\nIn the wild the northern bobwhite feeds on a variety of weed and grass seeds, as well as insects. These are generally collected on the ground or from low foliage. Birds in the aviary are easily catered for with a commercial small seed mix (finch, budgerigar, or small parrot mix) when supplemented with greenfeed. Live food is not usually necessary for breeding, but will be ravenously accepted. High protein foods such as chicken grower crumble are more convenient to supply and will be useful for the stimulation of breeding birds. Extra calcium is required, especially by laying hens; it can be supplied in the form of shell grit, or cuttlefish bone.\nBreeding.\nIf a nesting site and privacy are not provided, hens will lay anywhere within an open aviary. Hens that do this may, in a season, lay upwards of 80 eggs, which can be taken for artificial incubation and the chicks hand-raised. Hens with nesting cover that do make a nest (on the ground) will build up 8\u201325 eggs in a clutch, with eggs being laid daily.\nMutations and hybrids.\nSome captive bobwhite hybrids recorded are between blue quail (scaled quail), Gambel's quail, California quail, and mountain quail.\nStatus.\nThe northern bobwhite is rated as a Near-threatened species by the International Union for Conservation of Nature. The northern bobwhite is threatened across its range due to habitat loss and habitat degradation. Changing land use patterns and changing fire regimes have caused once prime habitat to become unfavorable for the bobwhite.\nMasked bobwhite.\nThe masked bobwhite subspecies, \"C. v. ridgwayi\", is listed as endangered in the U.S. The birds were twice declared extirpated in Arizona in the past century. It was originally endemic to southern Arizona in the U.S., and northern Sonora in Mexico. It is considered a \"Critically Imperiled Subspecies\" by NatureServe.\nThe masked bobwhite was in decline since its discovery in 1884. By 1900, the subspecies was already extinct in the U.S. Populations remained in Mexico, but their study was curtailed by political events in Mexico, including the Mexican Revolution and the last of the Yaqui Wars. A population of the masked bobwhite was finally discovered and studied in Mexico, in 1931 and 1932.\nA native population historically existed in Sonora, but by 2017, its population appeared to be declining, or possibly extinct. A 2017 study recorded no wild sightings of the bird in Sonora. Decline of the species has been attributed to intense livestock grazing in an ecosystem that does not rejuvenate quickly.\nA captive flock was established in Arizona in the 1970s. The George Miksch Sutton Avian Research Center (Sutton Center) became involved with conservation efforts in 2017 to establish a breeding population at the Sutton Center in Oklahoma, in order to reintroduce birds to Buenos Aires National Wildlife Refuge (BANWR). In 2019, biologists from the Sutton Center transported 1,000 chicks by road vehicle to Buenos Aires National Wildlife Refuge. In 2020, a projected total of 1,200 birds will be transported by airplanes to BANWR. These recent actions are supplemental, and in addition to other conservation efforts in the past, seem to aid the subspecies' future conservation efforts.\nIn popular culture.\nIn 2023, the masked bobwhite subspecies will be featured on a United States Postal Service Forever stamp as part of the \"Endangered Species\" set, based on a photograph from Joel Sartore's \"Photo Ark\". The stamp will be dedicated at a ceremony at the National Grasslands Visitor Center in Wall, South Dakota.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "4530", "revid": "41419081", "url": "https://en.wikipedia.org/wiki?curid=4530", "title": "Bluescreen", "text": ""}
{"id": "4531", "revid": "16349307", "url": "https://en.wikipedia.org/wiki?curid=4531", "title": "Bipolar disorder", "text": "Mental disorder that causes periods of depression and abnormally elevated mood\nMedical condition&lt;templatestyles src=\"Template:Infobox/styles-images.css\" /&gt;\nBipolar disorder (BD), previously known as manic depression, is a mental disorder characterized by periods of depression and of abnormally elevated mood that each last from days to weeks, and in some cases months. If the elevated mood is severe or associated with psychosis, it is called \"mania\"; if it does not significantly affect functioning, it is called \"hypomania\". During mania, an individual behaves or feels abnormally energetic, happy, or irritable, and often makes impulsive decisions with little regard for the consequences. There is usually sleep disturbance during manic phases. During periods of depression, the individual may experience crying, have a negative outlook, and demonstrate poor eye contact. Over a period of 20 years, 6% of those with BD died by suicide, with about one-third attempting suicide in their lifetime. Among those with BD, 40\u201350% overall and 78% of adolescents engaged in self-harm.\nWhile the causes of this mood disorder are not clearly understood, genetic and environmental factors are thought to play a role. Genetic factors may account for up to 70\u201390% of the risk of developing BD. Environmental risks include a history of child abuse and long-term stress. The condition is classified as bipolar I disorder if there has been at least one manic episode, with or without depressive episodes, and as bipolar II disorder if there has been at least one hypomanic episode (but no full manic episodes) and one major depressive episode. It is classified as cyclothymia if there are hypomanic episodes with periods of depression that do not meet the criteria for major depressive episodes.\nIf these symptoms are due to drugs or medical problems, they are not diagnosed as BD.\nMood stabilizers, particularly lithium, and anticonvulsants, such as lamotrigine and valproate, as well as atypical antipsychotics are the mainstay of long-term pharmacologic relapse prevention. Antipsychotics are used for acute manic episodes or when mood stabilizers are ineffective or not tolerated, with long-acting injectables available for patients with adherence issues. There is evidence that psychotherapy improves the course of BD. Use of antidepressants in depressive episodes is controversial: they can be effective, but certain classes of antidepressants increase the risk of mania. The treatment of depressive episodes, therefore, is often difficult. Electroconvulsive therapy (ECT) is effective in acute manic and depressive episodes, especially with psychosis or catatonia. Admission to a psychiatric hospital may be required if someone is a risk to themselves or others; involuntary treatment is sometimes necessary if someone refuses treatment.\nBD occurs in approximately 2% of the population. Symptoms most commonly begin between 20-25 years old; an earlier onset is associated with a worse prognosis. Around 30% of people with BD have financial, social or work-related problems due to the condition. BD is among the top 20 causes of disability and leads to substantial societal costs. Due to lifestyle consequences and medication side effects, risk of death from natural causes, such as coronary artery disease, in people with BD is twice the average.\n&lt;templatestyles src=\"Template:TOC limit/styles.css\" /&gt;\nSigns and symptoms.\nLate adolescence and early adulthood are peak years for the onset of bipolar disorder. The condition is characterized by intermittent episodes of mania, commonly (but not in every patient) alternating with bouts of depression, with an absence of symptoms in between. During these episodes, people with bipolar disorder exhibit disruptions in normal mood, psychomotor activity (the level of physical activity that is influenced by mood)\u2014e.g. constant fidgeting during mania or slowed movements during depression\u2014circadian rhythm and cognition. Mania can present with varying levels of mood disturbance, ranging from euphoria, which is associated with \"classic mania\", to dysphoria and irritability. Psychotic symptoms such as delusions or hallucinations may occur in both manic and depressive episodes; their content and nature are consistent with the person's prevailing mood. In some people with bipolar disorder, depressive symptoms predominate, and the episodes of mania are always the more subdued hypomania type.\nAccording to the DSM-5 criteria, mania is distinguished from hypomania by the duration: hypomania is present if elevated mood symptoms persist for at least four consecutive days, while mania is present if such symptoms persist for more than a week. Unlike mania, hypomania is not always associated with impaired functioning. The biological mechanisms responsible for switching from a manic or hypomanic episode to a depressive episode, or vice versa, remain poorly understood.\nManic episodes.\nAlso known as a manic episode, mania is a distinct period of at least one week of elevated or irritable mood, which can range from euphoria to delirium. The core symptom of mania involves an increase in energy of psychomotor activity. Mania can also present with increased self-esteem or grandiosity, racing thoughts, pressured speech that is difficult to interrupt, decreased need for sleep, disinhibited social behavior, increased goal-oriented activities and impaired judgement, which can lead to exhibition of behaviors characterized as impulsive or high-risk, such as hypersexuality or excessive spending. To fit the definition of a manic episode, these behaviors must impair the individual's ability to socialize or work. If untreated, a manic episode usually lasts three to six months.\nIn severe manic episodes, a person can experience psychotic symptoms, where thought content is affected along with mood. They may feel unstoppable, persecuted, or as if they have a special relationship with God, a great mission to accomplish, or other grandiose or delusional ideas. This may lead to violent behavior and, sometimes, hospitalization in an inpatient psychiatric hospital. The severity of manic symptoms can be measured by rating scales such as the Young Mania Rating Scale, though questions remain about the reliability of these scales.\nThe onset of a manic or depressive episode is often foreshadowed by sleep disturbance. Manic individuals often have a history of substance use disorder developed over years as a form of \"self-medication\".\nHypomanic episodes.\nHypomania is the milder form of mania, defined as at least four days of the same criteria as mania, but which does not cause a significant decrease in the individual's ability to socialize or work, lacks psychotic features such as delusions or hallucinations, and does not require psychiatric hospitalization. Overall functioning may actually increase during episodes of hypomania and is thought to serve as a defense mechanism against depression by some. Hypomanic episodes rarely progress to full-blown manic episodes. Some people who experience hypomania show increased creativity, while others are irritable or demonstrate poor judgment.\nHypomania may feel good to some individuals who experience it, though most people who experience hypomania state that the stress of the experience is very painful. People with bipolar disorder who experience hypomania tend to forget the effects of their actions on those around them. Even when family and friends recognize mood swings, the individual will often deny that anything is wrong. If not accompanied by depressive episodes, hypomanic episodes are often not deemed problematic unless the mood changes are uncontrollable or volatile. In individuals with Bipolar II disorder, depressive symptoms typically overlap with hypomania symptoms. These individuals may not be able to identify these specific symptoms as hypomania, rather they view them as typical depression with slight alterations in mood. Most commonly, symptoms continue for time periods from a few weeks to a few months.\nDepressive episodes.\nSymptoms of the depressive phase of bipolar disorder include persistent feelings of sadness, irritability or anger, loss of interest in previously enjoyed activities, excessive or inappropriate guilt, hopelessness, sleeping too much or not enough, changes in appetite or weight, fatigue, problems concentrating, self-loathing or feelings of worthlessness, and thoughts of death or suicide. Although the DSM-5 criteria for diagnosing unipolar and bipolar episodes are the same, some clinical features are more common in the latter, including increased sleep, sudden onset and resolution of symptoms, significant weight gain or loss, and severe episodes after childbirth.\nThe earlier the age of onset, the more likely the first few episodes are to be depressive. For most people with bipolar types 1 and 2, the depressive episodes are much longer than the manic or hypomanic episodes. Since a diagnosis of bipolar disorder requires a manic or hypomanic episode, many affected individuals are initially misdiagnosed as having major depression and treated with prescribed antidepressants.\nMixed affective episodes.\nIn bipolar disorder, a mixed state is an episode during which symptoms of both mania and depression occur simultaneously. Individuals experiencing a mixed state may have manic symptoms such as grandiose thoughts while simultaneously experiencing depressive symptoms such as excessive guilt or feeling suicidal. They are considered to have a higher risk for suicidal behavior as depressive emotions such as hopelessness are often paired with mood swings or difficulties with impulse control. Anxiety disorders occur more frequently as a comorbidity in mixed bipolar episodes than in non-mixed bipolar depression or mania. Substance (including alcohol) use also follows this trend, thereby appearing to depict bipolar symptoms as no more than a consequence of substance use.\nComorbid conditions.\nPeople with bipolar disorder often have other co-existing psychiatric conditions such as anxiety (present in about 71% of people with bipolar disorder), substance abuse (56%), personality disorders (36%) and attention deficit hyperactivity disorder (10\u201320%) which can add to the burden of illness and worsen the prognosis. Certain medical conditions are also more common in people with bipolar disorder as compared to the general population. This includes increased rates of metabolic syndrome (present in 37% of people with bipolar disorder), migraine headaches (35%), obesity (21%) and type 2 diabetes (14%). This contributes to a risk of death that is two times higher in those with bipolar disorder as compared to the general population. Hypothyroidism is also common regardless of drug choice.\nSubstance use disorder is a common comorbidity in bipolar disorder; the subject has been widely reviewed.\nCauses.\nThe causes of bipolar disorder likely vary between individuals and the exact mechanism underlying the disorder remains unclear. Genetic influences are believed to account for 73\u201393% of the risk of developing the disorder indicating a strong hereditary component. The overall heritability of the bipolar spectrum has been estimated at 0.71. Twin studies have been limited by relatively small sample sizes but have indicated a substantial genetic contribution, as well as environmental influence. For bipolar I disorder, the rate at which identical twins (same genes) will both have bipolar I disorder (concordance) is around 40%, compared to about 5% in fraternal twins. A combination of bipolar I, II, and cyclothymia similarly produced rates of 42% and 11% (identical and fraternal twins, respectively). The rates of bipolar II combinations without bipolar I are lower\u2014bipolar II at 23 and 17%, and bipolar II combining with cyclothymia at 33 and 14%\u2014which may reflect relatively higher genetic heterogeneity.\nThe cause of bipolar disorders overlaps with major depressive disorder. When defining concordance as the co-twins having either bipolar disorder or major depression, then the concordance rate rises to 67% in identical twins and 19% in fraternal twins. The relatively low concordance between fraternal twins brought up together suggests that shared family environmental effects are limited, although the ability to detect them has been limited by small sample sizes.\nGenetic.\nBehavioral genetic studies have suggested that many chromosomal regions and candidate genes are related to bipolar disorder susceptibility with each gene exerting a mild to moderate effect. The risk of bipolar disorder is nearly ten-fold higher in first-degree relatives of those with bipolar disorder than in the general population; similarly, the risk of major depressive disorder is three times higher in relatives of those with bipolar disorder than in the general population.\nAlthough the first genetic linkage finding for mania was in 1969, linkage studies have been inconsistent. Findings point strongly to heterogeneity, with different genes implicated in different families. Robust and replicable genome-wide significant associations showed several common single-nucleotide polymorphisms (SNPs) are associated with bipolar disorder, including variants within the genes \"CACNA1C\", \"ODZ4\", and \"NCAN\". The largest and most recent genome-wide association study failed to find any locus that exerts a large effect, reinforcing the idea that no single gene is responsible for bipolar disorder in most cases. Polymorphisms in \"BDNF\", \"DRD4\", \"DAO\", and \"TPH1\" have been frequently associated with bipolar disorder and were initially associated in a meta-analysis, but this association disappeared after correction for multiple testing. On the other hand, two polymorphisms in \"TPH2\" were identified as being associated with bipolar disorder.\nDue to the inconsistent findings in a genome-wide association study, multiple studies have undertaken the approach of analyzing SNPs in biological pathways. Signaling pathways traditionally associated with bipolar disorder that have been supported by these studies include corticotropin-releasing hormone signaling, cardiac \u03b2-adrenergic signaling, phospholipase C signaling, glutamate receptor signaling, cardiac hypertrophy signaling, Wnt signaling, Notch signaling, and endothelin 1 signaling. Of the 16 genes identified in these pathways, three were found to be dysregulated in the dorsolateral prefrontal cortex portion of the brain in post-mortem studies: \"CACNA1C\", \"GNG2\", and \"ITPR2\".\nBipolar disorder is associated with reduced expression of specific DNA repair enzymes and increased levels of oxidative DNA damages. The AKAP11 gene was discovered in 2022 as the first gene linked to bipolar disorder. The exomes of around 14,000 individuals with bipolar disorder were analysed and compared to those without the condition. The findings were combined with data from another study in the Schizophrenia Exome Sequencing Meta-Analysis (SCHEMA), examining the genome sequences of 24,000 people alongside the original 14,000 bipolar disorder cases. This study identified genetic variants, including the AKAP11 gene, associated with an increased risk of bipolar disorder. The AKAP11 gene's interaction with the GSK3B protein, a molecular target of lithium, points to a possible mechanism behind the medication's therapeutic effects.\nEnvironmental.\nPsychosocial factors play a significant role in the development and course of bipolar disorder, and individual psychosocial variables may interact with genetic dispositions. Recent life events and interpersonal relationships likely contribute to the onset and recurrence of bipolar mood episodes, just as they do for unipolar depression. In surveys, 30\u201350% of adults diagnosed with bipolar disorder report traumatic/abusive experiences in childhood, which is associated with earlier onset, a higher rate of suicide attempts, and more co-occurring disorders such as post-traumatic stress disorder. Subtypes of abuse, such as sexual and emotional abuse, also contribute to violent behaviors seen in patients with bipolar disorder. The number of reported stressful events in childhood is higher in those with an adult diagnosis of bipolar spectrum disorder than in those without, particularly events stemming from a harsh environment rather than from the child's own behavior. Acutely, mania can be induced by sleep deprivation in around 30% of people with bipolar disorder.\nNeurological.\nLess commonly, bipolar disorder or a bipolar-like disorder may occur as a result of or in association with a neurological condition or injury including stroke, traumatic brain injury, HIV infection, multiple sclerosis, porphyria, and rarely temporal lobe epilepsy.\nProposed mechanisms.\nThe precise mechanisms that cause bipolar disorder are not well understood. Bipolar disorder is thought to be associated with abnormalities in the structure and function of certain brain areas responsible for cognitive tasks and the processing of emotions. A neurologic model for bipolar disorder proposes that the emotional circuitry of the brain can be divided into two main parts. The ventral system (regulates emotional perception) includes brain structures such as the amygdala, insula, ventral striatum, ventral anterior cingulate cortex, and the prefrontal cortex. The dorsal system (responsible for emotional regulation) includes the hippocampus, dorsal anterior cingulate cortex, and other parts of the prefrontal cortex. The model hypothesizes that bipolar disorder may occur when the ventral system is overactivated and the dorsal system is underactivated. Other models suggest the ability to regulate emotions is disrupted in people with bipolar disorder and that dysfunction of the ventricular prefrontal cortex is crucial to this disruption.\nMeta-analyses of structural MRI studies have shown that certain brain regions (e.g., the left rostral anterior cingulate cortex, fronto-insular cortex, ventral prefrontal cortex, and claustrum) are smaller in people with bipolar disorder, whereas other regions are larger (lateral ventricles, globus pallidus, subgenual anterior cingulate, and the amygdala). Additionally, these meta-analyses found that people with bipolar disorder have higher rates of deep white matter hyperintensities.\nFunctional MRI findings suggest that the ventricular prefrontal cortex regulates the limbic system, especially the amygdala. In people with bipolar disorder, decreased ventricular prefrontal cortex activity allows for the dysregulated activity of the amygdala, which likely contributes to labile mood and poor emotional regulation. Consistent with this, pharmacological treatment of mania returns ventricular prefrontal cortex activity to the levels in non-manic people, suggesting that ventricular prefrontal cortex activity is an indicator of mood state. However, while pharmacological treatment of mania reduces amygdala hyperactivity, it remains more active than the amygdala of those without bipolar disorder, suggesting amygdala activity may be a marker of the disorder rather than the current mood state. Manic and depressive episodes tend to be characterized by dysfunction in different regions of the ventricular prefrontal cortex. Manic episodes appear to be associated with decreased activation of the right ventricular prefrontal cortex whereas depressive episodes are associated with decreased activation of the left ventricular prefrontal cortex. These disruptions often occur during development linked with synaptic pruning dysfunction.\nPeople with bipolar disorder who are in a euthymic mood state show decreased activity in the lingual gyrus compared to people without bipolar disorder. In contrast, they demonstrate decreased activity in the inferior frontal cortex during manic episodes compared to people without the disorder. Similar studies examining the differences in brain activity between people with bipolar disorder and those without did not find a consistent area in the brain that was more or less active when comparing these two groups. People with bipolar have increased activation of left hemisphere ventral limbic areas\u2014which mediate emotional experiences and generation of emotional responses\u2014and decreased activation of right hemisphere cortical structures related to cognition\u2014structures associated with the regulation of emotions. However, further research is needed to consolidate neuroimaging findings, which are often heterogeneous and not consistently reported according to a common standard.\nNeuroscientists have proposed additional models to try to explain the cause of bipolar disorder. One proposed model for bipolar disorder suggests that hypersensitivity of reward circuits consisting of frontostriatal circuits causes mania, and decreased sensitivity of these circuits causes depression. According to the \"kindling\" hypothesis, when people who are genetically predisposed toward bipolar disorder experience stressful events, the stress threshold at which mood changes occur becomes progressively lower, until the episodes eventually start (and recur) spontaneously. There is evidence supporting an association between early-life stress and dysfunction of the hypothalamic-pituitary-adrenal axis leading to its overactivation, which may play a role in the pathogenesis of bipolar disorder. Other brain components that have been proposed to play a role in bipolar disorder are the mitochondria and a sodium ATPase pump. Circadian rhythms and regulation of the hormone melatonin also seem to be altered.\nDopamine, a neurotransmitter responsible for mood cycling, has increased transmission during the manic phase. The dopamine hypothesis states that the increase in dopamine results in secondary homeostatic downregulation of key system elements and receptors such as lower sensitivity of dopaminergic receptors. This results in decreased dopamine transmission characteristic of the depressive phase. The depressive phase ends with homeostatic upregulation potentially restarting the cycle over again. Glutamate is significantly increased within the left dorsolateral prefrontal cortex during the manic phase of bipolar disorder, and returns to normal levels once the phase is over.\nMedications used to treat bipolar may exert their effect by modulating intracellular signaling, such as through depleting myo-inositol levels, inhibition of cAMP signaling, and through altering subunits of the dopamine-associated G-protein. Consistent with this, elevated levels of G\u03b1i, G\u03b1s, and G\u03b1q/11 have been reported in brain and blood samples, along with increased protein kinase A (PKA) expression and sensitivity; typically, PKA activates as part of the intracellular signalling cascade downstream from the detachment of G\u03b1s subunit from the G protein complex.\nDecreased levels of 5-hydroxyindoleacetic acid, a byproduct of serotonin, are present in the cerebrospinal fluid of persons with bipolar disorder during both the depressed and manic phases. Increased dopaminergic activity has been hypothesized in manic states due to the ability of dopamine agonists to stimulate mania in people with bipolar disorder. Decreased sensitivity of regulatory \u03b12 adrenergic receptors as well as increased cell counts in the locus coeruleus indicated increased noradrenergic activity in manic people. Low plasma GABA levels on both sides of the mood spectrum have been found. One review found no difference in monoamine levels, but found abnormal norepinephrine turnover in people with bipolar disorder. Tyrosine depletion was found to reduce the effects of methamphetamine in people with bipolar disorder as well as symptoms of mania, implicating dopamine in mania. VMAT2 binding was found to be increased in one study of people with bipolar mania.\nDiagnosis.\nBipolar disorder is commonly diagnosed during adolescence or early adulthood, but onset can occur throughout life. Its diagnosis is based on the self-reported experiences of the individual, abnormal behavior reported by family members, friends or co-workers, observable signs of illness as assessed by a clinician, and ideally a medical work-up to rule out other causes. Caregiver-scored rating scales, specifically from the mother, have shown to be more accurate than teacher and youth-scored reports in identifying youths with bipolar disorder. Assessment is usually done on an outpatient basis; admission to an inpatient facility is considered if there is a risk to oneself or others.\nThe most widely used criteria for diagnosing bipolar disorder are from the American Psychiatric Association's (APA) \"Diagnostic and Statistical Manual of Mental Disorders\", Fifth Edition (DSM-5) and the World Health Organization's (WHO) \"International Statistical Classification of Diseases and Related Health Problems\", 10th Edition (ICD-10). The ICD-10 criteria are used more often in clinical settings outside of the U.S. while the DSM criteria are used within the U.S. and are the prevailing criteria used internationally in research studies. The DSM-5, published in 2013, includes further and more accurate specifiers compared to its predecessor, the DSM-IV-TR. This work has influenced the eleventh revision of the ICD, which includes the various diagnoses within the bipolar spectrum of the DSM-V.\nSeveral rating scales for the screening and evaluation of bipolar disorder exist, including the Bipolar Spectrum Diagnostic Scale, Mood Disorder Questionnaire, the General Behavior Inventory and the Hypomania Checklist. The use of evaluation scales cannot substitute for a full clinical interview, but they serve to systematize the recollection of symptoms. On the other hand, instruments for screening bipolar disorder tend to have lower sensitivity.\nDifferential diagnosis.\nMental disorders that can mimic bipolar disorder include schizophrenia, major depressive disorder, attention deficit hyperactivity disorder (ADHD), and certain personality disorders, such as borderline personality disorder. A key difference between bipolar disorder and borderline personality disorder is the nature of the mood swings; in contrast to the sustained changes to mood over days to weeks or longer seen in bipolar disorder, those experienced in borderline personality disorder (more accurately called emotional dysregulation) are sudden and often short-lived, and secondary to social stressors.\nAlthough there are no biological tests that are diagnostic of bipolar disorder, blood tests and/or imaging are carried out to investigate whether medical illnesses with clinical presentations similar to that of bipolar disorder are present before making a definitive diagnosis. Neurologic diseases such as multiple sclerosis, complex partial seizures, strokes, brain tumors, Wilson's disease, traumatic brain injury, Huntington's disease, and complex migraines can mimic features of bipolar disorder. An EEG may be used to exclude neurological disorders such as epilepsy, and a CT scan or MRI of the head may be used to exclude brain lesions. Additionally, disorders of the endocrine system such as hypothyroidism, hyperthyroidism, and Cushing's disease are in the differential as is the connective tissue disease systemic lupus erythematosus. Infectious causes of mania that may appear similar to bipolar mania include herpes encephalitis, HIV, influenza, or neurosyphilis. Certain vitamin deficiencies such as pellagra (niacin deficiency), vitamin B12 deficiency, folate deficiency, and Wernicke\u2013Korsakoff syndrome (thiamine deficiency) can also lead to mania. Common medications that can cause manic symptoms include antidepressants, prednisone, Parkinson's disease medications, thyroid hormone, stimulants (including cocaine and methamphetamine), and certain antibiotics.\nBipolar spectrum.\nBipolar spectrum disorders include bipolar I disorder, bipolar II disorder, cyclothymic disorder, and cases where subthreshold symptoms are found to cause clinically significant impairment or distress. These disorders involve major depressive episodes that alternate with manic or hypomanic episodes, or with mixed episodes that feature symptoms of both mood states. The concept of the bipolar spectrum is similar to that of Emil Kraepelin's original concept of manic depressive illness. Bipolar II disorder was established as a diagnosis in 1994 within DSM IV; though debate continues over whether it is a distinct entity, part of a spectrum, or exists at all.\nCriteria and subtypes.\nThe DSM and the ICD characterize bipolar disorder as a spectrum of disorders occurring on a continuum. The DSM-5 and ICD-11 lists three specific subtypes:\nWhen relevant, specifiers for \"peripartum onset\" and \"with rapid cycling\" should be used with any subtype. Individuals who have subthreshold symptoms that cause clinically significant distress or impairment, but do not meet full criteria for one of the three subtypes may be diagnosed with other specified or unspecified bipolar disorder. Other specified bipolar disorder is used when a clinician chooses to explain why the full criteria were not met (e.g., hypomania without a prior major depressive episode). If the condition is thought to have a non-psychiatric medical cause, the diagnosis of \"bipolar and related disorder due to another medical condition\" is made, while \"substance/medication-induced bipolar and related disorder\" is used if a medication is thought to have triggered the condition. \nWhile hyperthymic temperament is not considered a pathological disorder, it is genetically associated with bipolar I and may predispose affected individuals to a manic-depressive episode. Hyperthymic temperament has been described as subsyndromal manifestation within the broader bipolar spectrum. \nRapid cycling.\nMost people who meet criteria for bipolar disorder experience a number of episodes, on average 0.4 to 0.7 per year, lasting three to six months. \"Rapid cycling\", however, is a course specifier that may be applied to any bipolar subtype. It is defined as having four or more mood disturbance episodes within a one-year span. Rapid cycling is usually temporary but is common amongst people with bipolar disorder and affects 25.8\u201345.3% of them at some point in their life. These episodes are separated from each other by a remission (partial or full) for at least two months or a switch in mood polarity (i.e., from a depressive episode to a manic episode or vice versa). The definition of rapid cycling most frequently cited in the literature (including the DSM-V and ICD-11) is that of Dunner and Fieve: at least four major depressive, manic, hypomanic or mixed episodes during a 12-month period. The literature examining the pharmacological treatment of rapid cycling is sparse and there is no clear consensus with respect to its optimal pharmacological management. \"Ultra rapid\" and \"ultradian\" have been applied to faster-cycling types of bipolar disorder. People with the rapid cycling or faster-cycling subtypes of bipolar disorder tend to be more difficult to treat and less responsive to medications than other people with bipolar disorder.\nCoexisting psychiatric conditions.\nThe diagnosis of bipolar disorder can be complicated by coexisting (comorbid) psychiatric conditions including obsessive\u2013compulsive disorder, substance-use disorder, eating disorders, attention deficit hyperactivity disorder, social phobia, premenstrual syndrome (including premenstrual dysphoric disorder), or panic disorder. A thorough longitudinal analysis of symptoms and episodes, assisted if possible by discussions with friends and family members, is crucial to establishing a treatment plan where these comorbidities exist. Children of parents with bipolar disorder more frequently have other mental health problems.\nChildren.\nIn the 1920s, Kraepelin noted that manic episodes are rare before puberty. In general, bipolar disorder in children was not recognized in the first half of the twentieth century. This issue diminished with an increased following of the DSM criteria in the last part of the twentieth century. The diagnosis of childhood bipolar disorder, while formerly controversial, has gained greater acceptance among childhood and adolescent psychiatrists. American children and adolescents diagnosed with bipolar disorder in community hospitals increased 4-fold reaching rates of up to 40% in 10 years around the beginning of the 21st century, while in outpatient clinics it doubled reaching 6%. Studies using DSM criteria show that up to 1% of youth may have bipolar disorder. The DSM-5 has established a diagnosis\u2014disruptive mood dysregulation disorder\u2014that covers children with long-term, persistent irritability that had at times been misdiagnosed as having bipolar disorder, distinct from irritability in bipolar disorder that is restricted to discrete mood episodes.\nAdults.\nBipolar, on average, starts during adulthood. Bipolar 1, on average, starts at the age of 18 years old, and Bipolar 2 starts at age 22 years old on average. However, most delay seeking treatment for an average of 8 years after symptoms start. Bipolar is often misdiagnosed with other psychiatric disorders. There is no definitive association between race, ethnicity, or socioeconomic status (SES). Adults with Bipolar report having a lower quality of life, even outside of a manic or depressive episode. Bipolar can put strain on marriage and other relationships, having a job, and everyday functioning. Bipolar is associated with higher rates of unemployment. Most have trouble keeping a job, which can lead to trouble with accessing healthcare, resulting in a further decline in their mental health due to not receiving treatment such as medicine and therapy.\nElderly.\nBipolar disorder is uncommon in older patients, with a measured lifetime prevalence of 1% in over 60s and a 12-month prevalence of 0.1\u20130.5% in people over 65. Despite this, it is overrepresented in psychiatric admissions, making up 4\u20138% of inpatient admission to aged care psychiatry units, and the incidence of mood disorders is increasing overall with the aging population. Depressive episodes more commonly present with sleep disturbance, fatigue, hopelessness about the future, slowed thinking, and poor concentration and memory; the last three symptoms are seen in what is known as pseudodementia. Clinical features also differ between those with late-onset bipolar disorder and those who developed it early in life; the former group present with milder manic episodes, more prominent cognitive changes and have a background of worse psychosocial functioning, while the latter present more commonly with mixed affective episodes, and have a stronger family history of illness. Older people with bipolar disorder experience cognitive changes, particularly in executive functions such as abstract thinking and switching cognitive sets, as well as concentrating for long periods and decision-making.\nPrevention.\nAttempts at prevention of bipolar disorder have focused on stress (such as childhood adversity or highly conflictual families) which, although not a diagnostically specific causal agent for bipolar, does place genetically and biologically vulnerable individuals at risk for a more severe course of illness. Longitudinal studies have indicated that full-blown manic stages are often preceded by a variety of prodromal clinical features, providing support for the occurrence of an at-risk state of the disorder when an early intervention might prevent its further development and/or improve its outcome.\nManagement.\nThe aim of management is to treat acute episodes safely with medication and work with the patient in long-term maintenance to prevent further episodes and optimise function using a combination of pharmacological and psychotherapeutic techniques. Hospitalization may be required especially with the manic episodes present in bipolar I. This can be voluntary or (local legislation permitting) involuntary. Long-term inpatient stays are now less common due to deinstitutionalization, although these can still occur. Following (or in lieu of) a hospital admission, support services available can include drop-in centers, visits from members of a community mental health team or an Assertive Community Treatment team, supported employment, patient-led support groups, and intensive outpatient programs. These are sometimes referred to as partial-inpatient programs. Compared to the general population, people with bipolar disorder are less likely to frequently engage in physical exercise. Exercise may have physical and mental benefits for people with bipolar disorder, but there is a lack of research.\nPsychosocial.\nPsychotherapy aims to assist a person with bipolar disorder in accepting and understanding their diagnosis, coping with various types of stress, improving their interpersonal relationships, and recognizing prodromal symptoms before full-blown recurrence. Cognitive behavioral therapy (CBT), family-focused therapy, and psychoeducation have the most evidence for efficacy in regard to relapse prevention, while interpersonal and social rhythm therapy and cognitive-behavioral therapy appear the most effective in regard to residual depressive symptoms. Most studies have been based only on bipolar I, however, and treatment during the acute phase can be a particular challenge. Some clinicians emphasize the need to talk with individuals experiencing mania, to develop a therapeutic alliance in support of recovery.\nMedication.\nMedications are often prescribed to help improve symptoms of bipolar disorder. Medications approved for treating bipolar disorder including mood stabilizers, antipsychotics, and certain antidepressants. Sometimes a combination of medications may also be suggested. The choice of medications may differ depending on the bipolar disorder episode type or if the person is experiencing unipolar or bipolar depression. Other factors to consider when deciding on an appropriate treatment approach includes if the person has any comorbidities, their response to previous therapies, adverse effects, and the desire of the person to be treated.\nMood stabilizers.\nLithium and the anticonvulsants carbamazepine, lamotrigine, and valproic acid are classed as mood stabilizers due to their effect on the mood states in bipolar disorder.\nValproate and carbamazepine are teratogenic and should be avoided as a treatment in women of childbearing age, but discontinuation of these medications during pregnancy is associated with a high risk of relapse. Lithium is also teratogenic in the first trimester, though it can be acceptable during this period after careful weighing of benefits and risks.\nThe effectiveness of topiramate is unknown.\nMood stabilizers are used for long-term maintenance but have not demonstrated the ability to quickly treat acute bipolar depression.\nAntipsychotics.\nAntipsychotic medications are effective for short-term treatment of bipolar manic episodes and appear to be superior to lithium and anticonvulsants for this purpose. Atypical antipsychotics such as lurasidone and clozapine are also indicated for bipolar depression refractory to treatment with mood stabilizers. Olanzapine is effective in preventing relapses, although the supporting evidence is weaker than the evidence for lithium. A 2006 review found that haloperidol was an effective treatment for acute mania, limited data supported no difference in overall efficacy between haloperidol, olanzapine or risperidone, and that it could be less effective than aripiprazole.\nAntidepressants.\nAntidepressant monotherapy is not recommended in the treatment of bipolar disorder and does not provide any benefit over mood stabilizers. Atypical antipsychotic medications (e.g., aripiprazole) are preferred over antidepressants to augment the effects of mood stabilizers due to the lack of efficacy of antidepressants in bipolar disorder. Treatment of bipolar disorder using antidepressants may carry a risk of affective switches where a person switches from depression to manic or hypomanic phases or mixed states. There may also be a risk of accelerating cycling between phases when antidepressants are used in bipolar disorder. The risk of affective switches is higher in bipolar I depression; antidepressants are generally avoided in bipolar I disorder or only used with mood stabilizers when they are deemed necessary.\nWhether modern antidepressants cause mania or cycle acceleration in bipolar disorder is highly controversial, as is whether antidepressants provide any benefit over mood stabilizers alone.\nCombined treatment approaches.\nAntipsychotics and mood stabilizers used together are quicker and more effective at treating mania than either class of drug used alone. Some analyses indicate antipsychotics alone are also more effective at treating acute mania. A first-line treatment for depression in bipolar disorder is a combination of olanzapine and fluoxetine.\nOther drugs.\nShort courses of benzodiazepines are used in addition to other medications for calming effect until mood stabilizing become effective. Electroconvulsive therapy (ECT) is an effective form of treatment for acute mood disturbances in those with bipolar disorder, especially when psychotic or catatonic features are displayed. ECT is also recommended for use in pregnant women with bipolar disorder. A single intravenous dose of ketamine may produce a rapid but transient antidepressant effect in bipolar depression, although the evidence is of low to very low certainty, and evidence for other glutamate receptor modulators or for sustained remission and safety remains inconclusive. Gabapentin and pregabalin are not proven to be effective for treating bipolar disorder.\nChildren.\nTreating bipolar disorder in children involves medication and psychotherapy. The literature and research on the effects of psychosocial therapy on bipolar spectrum disorders are scarce, making it difficult to determine the efficacy of various therapies. Mood stabilizers and atypical antipsychotics are commonly prescribed. Among the former, lithium is the only compound approved by the FDA for children. Psychological treatment combines normally education on the disease, group therapy, and cognitive behavioral therapy. Long-term medication is often needed.\nResistance to treatment.\nThe poor response from some bipolar patients to treatment has given evidence to the concept of treatment-resistant bipolar disorder. Guidelines to the definition of treatment-resistant bipolar disorder and evidence-based options for its management were reviewed in 2020.\nManagement of obesity.\nA large proportion (approximately 68%) of people who seek treatment for bipolar disorder are obese or overweight and managing obesity is important for reducing the risk of other health conditions that are associated with obesity. Management approaches include non-pharmacological, pharmacological, and surgical. Examples of non-pharmacological include dietary interventions, exercise, behavioral therapies, or combined approaches. Pharmacological approaches include weight-loss medications or changing medications already being prescribed. Some people with bipolar disorder who have obesity may also be eligible for bariatric surgery. The effectiveness of these various approaches to improving or managing obesity in people with bipolar disorder is not clear.\nPrognosis.\nA lifelong condition with periods of partial or full recovery in between recurrent episodes of relapse, bipolar disorder is considered to be a major health problem worldwide because of the increased rates of disability and premature mortality. It is also associated with co-occurring psychiatric and medical problems, higher rates of death from natural causes (e.g., cardiovascular disease), and high rates of initial under- or misdiagnosis, causing a delay in appropriate treatment and contributing to poorer prognoses. When compared to the general population, people with bipolar disorder also have higher rates of other serious medical comorbidities including diabetes mellitus, respiratory diseases, HIV, and hepatitis C virus infection. After a diagnosis is made, it remains difficult to achieve complete remission of all symptoms with the currently available psychiatric medications and symptoms often become progressively more severe over time.\nCompliance with medications is one of the most significant factors that can decrease the rate and severity of relapse and have a positive impact on overall prognosis. However, the types of medications used in treating BD commonly cause side effects and more than 75% of individuals with BD inconsistently take their medications for various reasons. Of the various types of the disorder, rapid cycling (four or more episodes in one year) is associated with the worst prognosis due to higher rates of self-harm and suicide. Individuals diagnosed with bipolar who have a family history of bipolar disorder are at a greater risk for more frequent manic/hypomanic episodes. Early onset and psychotic features are also associated with worse outcomes, as well as subtypes that are nonresponsive to lithium.\nEarly recognition and intervention also improve prognosis as the symptoms in earlier stages are less severe and more responsive to treatment. Onset after adolescence is connected to better prognoses for both genders, and being male is a protective factor against higher levels of depression. For women, better social functioning before developing bipolar disorder and being a parent are protective towards suicide attempts.\nFunctioning.\nChanges in cognitive processes and abilities are seen in mood disorders, with those of bipolar disorder being greater than those in major depressive disorder. These include reduced attentional and executive capabilities and impaired memory. People with bipolar disorder often experience a decline in cognitive functioning during (or possibly before) their first episode, after which a certain degree of cognitive dysfunction typically becomes permanent, with more severe impairment during acute phases and moderate impairment during periods of remission. As a result, two-thirds of people with BD continue to experience impaired psychosocial functioning in between episodes even when their mood symptoms are in full remission. A similar pattern is seen in both BD-I and BD-II, but people with BD-II experience a lesser degree of impairment.\nWhen bipolar disorder occurs in children, it severely and adversely affects their psychosocial development. Children and adolescents with bipolar disorder have higher rates of significant difficulties with substance use disorders, psychosis, academic difficulties, behavioral problems, social difficulties, and legal problems. Cognitive deficits typically increase over the course of the illness. Higher degrees of impairment correlate with the number of previous manic episodes and hospitalizations, and with the presence of psychotic symptoms. Early intervention can slow the progression of cognitive impairment, while treatment at later stages can help reduce distress and negative consequences related to cognitive dysfunction.\nDespite the overly ambitious goals that are frequently part of manic episodes, symptoms of mania undermine the ability to achieve these goals and often interfere with an individual's social and occupational functioning. One-third of people with BD remain unemployed for one year following a hospitalization for mania. Depressive symptoms during and between episodes, which occur much more frequently for most people than hypomanic or manic symptoms over the course of illness, are associated with lower functional recovery in between episodes, including unemployment or underemployment for both BD-I and BD-II. However, the course of illness (duration, age of onset, number of hospitalizations, and the presence or not of rapid cycling) and cognitive performance are the best predictors of employment outcomes in individuals with bipolar disorder, followed by symptoms of depression and years of education.\nRecovery and recurrence.\nA naturalistic study in 2003 by Tohen and coworkers from the first admission for mania or mixed episode (representing the hospitalized and therefore most severe cases) found that 50% achieved syndromal recovery (no longer meeting criteria for the diagnosis) within six weeks and 98% within two years. Within two years, 72% achieved symptomatic recovery (no symptoms at all) and 43% achieved functional recovery (regaining of prior occupational and residential status). However, 40% went on to experience a new episode of mania or depression within 2 years of syndromal recovery, and 19% switched phases without recovery.\nSymptoms preceding a relapse (prodromal), especially those related to mania, can be reliably identified by people with bipolar disorder. There have been intents to teach patients coping strategies when noticing such symptoms with encouraging results.\nSuicide.\nBipolar disorder can cause suicidal ideation that leads to suicide attempts. Individuals whose bipolar disorder begins with a depressive or mixed affective episode seem to have a poorer prognosis and an increased risk of suicide. One out of two people with bipolar disorder attempt suicide at least once during their lifetime and many attempts are successfully completed. The annual average suicide rate is 0.4\u20131.4%, which is 30 to 60 times greater than that of the general population. The number of deaths from suicide in bipolar disorder is between 18 and 25 times higher than would be expected in similarly aged people without bipolar disorder. The lifetime risk of suicide is much higher in those with bipolar disorder, with an estimated 34% of people attempting suicide and 15\u201320% dying by suicide.\nRisk factors for suicide attempts and death from suicide in people with bipolar disorder include older age, prior suicide attempts, a depressive or mixed index episode (first episode), a manic index episode with psychotic symptoms, hopelessness or psychomotor agitation present during the episodes, co-existing anxiety disorder, a first degree relative with a mood disorder or suicide, interpersonal conflicts, occupational problems, bereavement or social isolation.\nEpidemiology.\nBipolar disorder is the sixth leading cause of disability worldwide and has a lifetime prevalence of about 1 to 3% in the general population. However, a reanalysis of data from the National Epidemiological Catchment Area survey in the United States suggested that 0.8% of the population experience a manic episode at least once (the diagnostic threshold for bipolar I) and a further 0.5% have a hypomanic episode (the diagnostic threshold for bipolar II or cyclothymia). Including sub-threshold diagnostic criteria, such as one or two symptoms over a short time-period, an additional 5.1% of the population, adding up to a total of 6.4%, were classified as having a bipolar spectrum disorder. A more recent analysis of data from a second US National Comorbidity Survey found that 1% met lifetime prevalence criteria for bipolar I, 1.1% for bipolar II, and 2.4% for subthreshold symptoms. Estimates vary about how many children and young adults have bipolar disorder. These estimates range from 0.6 to 15% depending on differing settings, methods, and referral settings, raising suspicions of overdiagnosis. One meta-analysis of bipolar disorder in young people worldwide estimated that about 1.8% of people between the ages of seven and 21 have bipolar disorder. Similar to adults, bipolar disorder in children and adolescents is thought to occur at a similar frequency in boys and girls.\nThere are conceptual and methodological limitations and variations in the findings. Prevalence studies of bipolar disorder are typically carried out by lay interviewers who follow fully structured/fixed interview schemes; responses to single items from such interviews may have limited validity. In addition, diagnoses (and therefore estimates of prevalence) vary depending on whether a categorical or spectrum approach is used. This consideration has led to concerns about the potential for both underdiagnosis and overdiagnosis.\nThe incidence of bipolar disorder is similar in men and women as well as across different cultures and ethnic groups. A 2000 study by the World Health Organization found that prevalence and incidence of bipolar disorder are very similar across the world. Age-standardized prevalence per 100,000 ranged from 421.0 in South Asia to 481.7 in Africa and Europe for men and from 450.3 in Africa and Europe to 491.6 in Oceania for women. However, severity may differ widely across the globe. Disability-adjusted life year rates, for example, appear to be higher in developing countries, where medical coverage may be poorer and medication less available. Within the United States, Asian Americans have significantly lower rates than their African American and European American counterparts. In 2017, the Global Burden of Disease Study estimated there were 4.5 million new cases and a total of 45.5 million cases globally.\nHomelessness and housing instability.\nPrevalence.\nStudies have shown that bipolar disorder occurs at significantly higher rates among people experiencing homelessness compared with the general population. A 2024 meta-analysis and systematic review estimates that there is a global prevalence of approximately 8% of bipolar disorder amongst homeless individuals, which is several times higher than the population averages. Earlier reviews also found elevated rates as high as 6%-9%, but estimates vary depending on diagnostic criteria and design. Researchers state that methodological differences- such as inconsistent definitions of homelessness and small sample sizes- may contribute to the wide range of reported prevalence rates.\nRisk factors.\nBipolar disorder is associated with several risk factors for homelessness, including incarceration, substance use, and socioeconomic instability. In the United States, it was reported that in veterans with bipolar disorder, 55% reported being homeless at some point in their lives, and 12% had been homeless within the last four weeks. Homelessness was also highly associated with prior incarceration and co-occurring substance use, which highlights the cyclical relationship between social instability and mental illness.\nAdditionally, individuals with bipolar disorder who are experiencing homelessness often have an early onset of illness, more frequent manic or depressive episodes, and poor adherence to medication. This can increase the likelihood of relapse and the loss of housing.Veterans and individuals who have been to correctional or psychiatric settings are especially at risk. This highlights that the lack of post-discharge support contributes to the chronic cycles of instability.\nSocial determinants like poverty, unemployment, and stigma also increase vulnerability to both bipolar disorder and homelessness.Once you are homeless, factors like stress, sleep deprivation, and exposure to unsafe environments are very prevalent and can worsen mood symptoms, making lasting recovery and reintegration even more difficult.\nAccess to care.\nPeople who are experiencing homelessness face significant barriers to consistent and quality mental health treatment. A study of over 10,000 patients with serious mental illness in the public health system found that homeless patients were less likely to have insurance, the ability to maintain continuous care, and more likely to rely on emergency services in comparison to housed individuals. Disruptions in care contribute to poor participation in treatment plans, higher rates of psychiatric hospitalization, and worsened long-term outcomes. Individuals with bipolar disorder require consistent medication management and therapeutic monitoring, but unstable living conditions make meeting these needs quite difficult. Unable to refill medications, attend appointments, or engage in therapy.\nLimitations.\nThe research on the prevalence of bipolar disorder in the homeless population is limited by the varying definitions of homelessness and challenges in keeping up with individuals on the move. and the variations in diagnostic methods across studies. As a result of this, current estimates of the prevalence of bipolar disorder in the homeless population may be underestimated. Expanding integrated models of care that combine psychiatric treatment with housing and social services has been suggested as a potential approach to improving long-term stability and reducing emergency service use.\nHistory.\nIn the early 1800s, French psychiatrist Jean-\u00c9tienne Dominique Esquirol's lypemania, one of his affective monomanias, was the first elaboration on what was to become modern depression. The basis of the current conceptualization of bipolar illness can be traced back to the 1850s. In 1850, Jean-Pierre Falret described \"circular insanity\" (', ); the lecture was summarized in 1851 in the ' (\"Hospital Gazette\"). Three years later, in 1854, Jules-Gabriel-Fran\u00e7ois Baillarger (1809\u20131890) described to the French Imperial Acad\u00e9mie Nationale de M\u00e9decine a biphasic mental illness causing recurrent oscillations between mania and melancholia, which he termed (, \"madness in double form\"). Baillarger's original paper, \"\", appeared in the medical journal \"Annales m\u00e9dico-psychologiques\" (\"Medico-psychological annals\") in 1854.\nThese concepts were developed by the German psychiatrist Emil Kraepelin (1856\u20131926), who, using Kahlbaum's concept of cyclothymia, categorized and studied the natural course of untreated bipolar patients. He coined the term \"manic depressive psychosis\", after noting that periods of acute illness, manic or depressive, were generally punctuated by relatively symptom-free intervals where the patient was able to function normally.\nThe term \"manic\u2013depressive \"reaction\"\" appeared in the first version of the DSM in 1952, influenced by the legacy of Adolf Meyer. Subtyping into \"unipolar\" depressive disorders and bipolar disorders has its origin in Karl Kleist's concept \u2013 since 1911 \u2013 of unipolar and bipolar affective disorders, which was used by Karl Leonhard in 1957 to differentiate between unipolar and bipolar disorder in depression. These subtypes have been regarded as separate conditions since publication of the DSM-III. The subtypes bipolar II and rapid cycling have been included since the DSM-IV, based on work from the 1970s by David Dunner, Elliot Gershon, Frederick Goodwin, Ronald Fieve, and Joseph Fleiss.\nSociety and culture.\nCost.\nThe United States spent approximately $202.1 billion on people diagnosed with bipolar I disorder (excluding other subtypes of bipolar disorder and undiagnosed people) in 2015. One analysis estimated that the United Kingdom spent approximately \u00a35.2 billion on the disorder in 2007. In addition to the economic costs, bipolar disorder is a leading cause of disability and lost productivity worldwide. People with bipolar disorder are generally more disabled, have a lower level of functioning, longer duration of illness, and increased rates of work absenteeism and decreased productivity when compared to people experiencing other mental health disorders. The decrease in the productivity seen in those who care for people with bipolar disorder also significantly contributes to these costs.\nAdvocacy.\nThere are widespread issues with social stigma, stereotypes, and prejudice against individuals with a diagnosis of bipolar disorder. In 2000, actress Carrie Fisher went public with her bipolar disorder diagnosis. She became one of the most well-recognized advocates for people with bipolar disorder in the public eye and fiercely advocated to eliminate the stigma surrounding mental illnesses, including bipolar disorder. Stephen Fried, who has written extensively on the topic, noted that Fisher helped to draw attention to the disorder's chronicity, relapsing nature, and that bipolar disorder relapses do not indicate a lack of discipline or moral shortcomings. Since being diagnosed at age 37, actor Stephen Fry has pushed to raise awareness of the condition, with his 2006 documentary \"\". In an effort to ease the social stigma associated with bipolar disorder, the orchestra conductor Ronald Braunstein cofounded the ME/2 Orchestra with his wife Caroline Whiddon in 2011. Braunstein was diagnosed with bipolar disorder in 1985 and his concerts with the ME/2 Orchestra were conceived in order to create a welcoming performance environment for his musical colleagues, while also raising public awareness about mental illness.\nNotable cases.\nNumerous authors have written about bipolar disorder and many successful people have openly discussed their experience with it. Kay Redfield Jamison, a clinical psychologist and professor of psychiatry at the Johns Hopkins University School of Medicine, profiled her own bipolar disorder in her memoir \"An Unquiet Mind\" (1995). It is likely that Grigory Potemkin, Russian statesman and alleged husband of Catherine the Great, suffered from some kind of bipolar disorder. Several celebrities have also publicly shared that they have bipolar disorder; in addition to Carrie Fisher and Stephen Fry these include Catherine Zeta-Jones, Mariah Carey, Kanye West, Jane Pauley, Demi Lovato, Selena Gomez, and Russell Brand.\nMedia portrayals.\nSeveral dramatic works have portrayed characters with traits suggestive of the diagnosis which have been the subject of discussion by psychiatrists and film experts alike.\nIn \"Mr. Jones\" (1993), the titular character (Richard Gere) swings from a manic episode into a depressive phase and back again, spending time in a psychiatric hospital and displaying many of the features of the syndrome. In \"The Mosquito Coast\" (1986), Allie Fox (Harrison Ford) displays some features including recklessness, grandiosity, increased goal-directed activity and mood lability, as well as some paranoia. Psychiatrists have suggested that Willy Loman, the main character in Arthur Miller's classic play \"Death of a Salesman\", has bipolar disorder.\nThe 2009 drama \"90210\" featured a character, Silver, who was diagnosed with bipolar disorder. Stacey Slater, a character from the BBC soap \"EastEnders\", has been diagnosed with the disorder. The storyline was developed as part of the BBC's Headroom campaign. The Channel 4 soap \"Brookside\" had earlier featured a story about bipolar disorder when the character Jimmy Corkhill was diagnosed with the condition. 2011 Showtime's political thriller drama \"Homeland\" protagonist Carrie Mathison has bipolar disorder, which she has kept secret since her school days. The 2014 ABC medical drama, \"Black Box\", featured a world-renowned neuroscientist with bipolar disorder.\nIn the TV series \"Dave\", the eponymous main character, played by Lil Dicky as a fictionalized version of himself, is an aspiring rapper. Lil Dicky's real-life hype man GaTa also plays himself. In one episode, after being off his medication and having an episode, GaTa tearfully confesses to having bipolar disorder. GaTa has bipolar disorder in real life but, like his character in the show, he is able to manage it with medication.\nSince 2024, Nicola Coughlan, has co-starred alongside Lydia West, in the British Channel 4 dark television comedy-drama \"Big Mood. \"Coughlan portrays the leading role of Maggie who was diagnosed with bipolar disorder. In a series about two best friends navigating friendship amidst a mental health crisis.\nCreativity.\nA link between mental illness and professional success or creativity has been suggested, including in accounts by Socrates, Seneca the Younger, and Cesare Lombroso. Despite prominence in popular culture, the link between creativity and bipolar has not been rigorously studied. This area of study also is likely affected by confirmation bias. Some evidence suggests that some heritable component of bipolar disorder overlaps with heritable components of creativity. Probands of people with bipolar disorder are more likely to be professionally successful, as well as to demonstrate temperamental traits similar to bipolar disorder. Furthermore, while studies of the frequency of bipolar disorder in creative population samples have been conflicting, full-blown bipolar disorder in creative samples is rare.\nExplanatory notes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nCited texts.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "4536", "revid": "12197093", "url": "https://en.wikipedia.org/wiki?curid=4536", "title": "Blitz", "text": "Blitz, German for \"lightning\", may refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "4537", "revid": "50454883", "url": "https://en.wikipedia.org/wiki?curid=4537", "title": "Burt Lancaster", "text": "American actor (1913\u20131994)\nBurton Stephen Lancaster (November 2, 1913 \u2013 October 20, 1994) was an American actor. Initially known for playing tough characters with tender hearts, he went on to achieve success with more complex and challenging roles over a 45-year career in films and television series. Lancaster was a four-time nominee for the Academy Award for Best Actor (winning once), and he also won two BAFTA Awards, one Golden Globe Award for Best Lead Actor, one Silver Bear, one Volpi Cup and two David di Donatello awards. The American Film Institute ranks Lancaster as #19 of the greatest male stars of classic Hollywood cinema.\nLancaster performed as a circus acrobat in the 1930s. At the age of 32 and after serving in World War II, he landed a role in a Broadway play and drew the attention of a Hollywood agent. His appearance in film noir \"The Killers\" in 1946 with Ava Gardner was a critical success and launched both of their careers. In 1948, Lancaster starred alongside Barbara Stanwyck in the commercially and critically acclaimed film \"Sorry, Wrong Number\", where he portrayed the husband to her bedridden invalid character. In 1953, Lancaster played the illicit lover of Deborah Kerr in the military drama \"From Here to Eternity\". A box office smash, it won eight Academy Awards, including Best Picture, and landed a Best Actor nomination for Lancaster.\nLater in the 1950s, he starred in \"The Rainmaker\" (1956) with Katharine Hepburn, earning a Best Actor Golden Globe nomination, and in 1957 he starred in \"Gunfight at the O.K. Corral\" (1957) with frequent co-star Kirk Douglas. During the 1950s, his production company Hecht-Hill-Lancaster was highly successful, with Lancaster acting in films such as: \"Trapeze\" (1956), a box office smash in which he used his acrobatic skills and for which he won the Silver Bear for Best Actor; \"Sweet Smell of Success\" (1957), a dark drama now considered a classic; \"Run Silent, Run Deep\" (1958), a World War II submarine drama with Clark Gable; and \"Separate Tables\" (1958), a hotel-set drama which received seven Oscar nominations.\nIn the early 1960s, Lancaster starred in a string of critically successful films, each in very disparate roles. Playing a charismatic con-man religious revivalist in \"Elmer Gantry\" in 1960 won him the Academy Award and the Golden Globe for Best Actor. Lancaster played a Nazi war criminal in 1961 in the all-star war crimes trial film \"Judgment at Nuremberg\". Playing a bird expert prisoner in \"Birdman of Alcatraz\" in 1962, he earned the BAFTA Award for Best Foreign Actor and his third Oscar nomination. In 1963, Lancaster traveled to Italy to star as an Italian prince in Visconti's epic period drama \"The Leopard\". In 1964, he played a US Air Force general who, opposed by a colonel played by Douglas, tries to overthrow the President in \"Seven Days in May\". Then, in 1966, he played an explosives expert in the western \"The Professionals\". Although the reception of his 1968 film \"The Swimmer\" was initially lackluster upon release, in the years after it has grown in stature critically and attained a cult following.\nIn 1970, Lancaster starred in the box-office hit, air-disaster drama \"Airport\". In 1974, he starred in another Visconti film, \"Conversation Piece\". He experienced a career resurgence in 1980 with the crime-romance \"Atlantic City\", winning the BAFTA for Best Actor and landing his fourth Oscar nomination. Starting in the late 1970s, he also appeared in television mini-series, including the award-winning \"Separate but Equal\" with Sidney Poitier. He continued acting into his late 70s, until a stroke in 1990 forced him to retire; four years later he died from a heart attack. His final film role was as Moonlight Graham in \"Field of Dreams\" (1989).\nEarly life.\nLancaster was born on November 2, 1913, in New York City, at his parents' home at 209 East 106th Street, the son of Elizabeth (\"n\u00e9e\" Roberts) and mailman James Lancaster. Both of his parents were Protestants of working-class background. All four of his grandparents were immigrants from the province of Ulster, Ireland. His maternal side was from Belfast.\nLancaster grew up in East Harlem, New York City. He developed a great interest and skill in gymnastics while attending DeWitt Clinton High School, where he was a basketball star. Before he graduated from DeWitt Clinton, his mother died of a cerebral hemorrhage. Lancaster was accepted by New York University with an athletic scholarship, but dropped out.\nCircus career.\nAt the age of 9, Lancaster met Nick Cravat with whom he developed a lifelong partnership. Together, they learned to act in local theatre productions and circus arts at Union Settlement, one of the city's oldest settlement houses. In the 1930s, they formed the acrobat duo \"Lang and Cravat\" and soon joined the Kay Brothers circus. However, in 1939, an injury forced Lancaster to give up the profession, with great regret. He then found temporary work, first as a salesman for Marshall Field's and then as a singing waiter in various restaurants.\nWorld War II service.\nAfter the United States entered World War II, Lancaster joined the United States Army in January 1943 and performed with the Army's 21st Special Services Division, one of the military units organized to follow the troops on the ground and provide USO entertainment to maintain morale. He served in the Fifth Army in Italy under General Mark Clark from 1943 to 1945. He was discharged in October 1945 as an entertainment specialist with the rank of technician fifth grade.\nActing career.\nBroadway.\nLancaster returned to New York after his Army service. Although initially unenthusiastic about acting, Lancaster was encouraged to audition for a Broadway play by a producer who saw him in an elevator while he was visiting his then-girlfriend at work. The audition was successful and Lancaster was cast in Harry Brown's \"A Sound of Hunting\" (1945). The show ran for only three weeks, but his performance attracted the interest of a Hollywood agent, Harold Hecht. Lancaster had other offers but Hecht promised him the opportunity to produce their own movies within five years of hitting Hollywood.\nThrough Hecht, Lancaster was brought to the attention of producer Hal B. Wallis. Lancaster left New York and moved to Los Angeles. Wallis signed him to a non-exclusive eight-movie contract.\nHal Wallis.\nLancaster's first filmed movie was \"Desert Fury\" for Wallis in 1947, where Lancaster was billed after John Hodiak and Lizabeth Scott. It was directed by Lewis Allen.\nThen producer Mark Hellinger approached him to star in 1946's \"The Killers\", which was completed and released prior to \"Desert Fury\". Directed by Robert Siodmak, it was a great commercial and critical success and launched Lancaster and his co-star Ava Gardner to stardom. It has since come to be regarded as a classic.\nHellinger used Lancaster again on \"Brute Force\" in 1947, a prison drama written by Richard Brooks and directed by Jules Dassin. It was also well received. Wallis released his films through Paramount, and so Lancaster and other Wallis contractees made cameos in \"Variety Girl\" in 1947.\nLancaster's next film was a thriller for Wallis in 1947, \"I Walk Alone\", co-starring Lizabeth Scott and a young Kirk Douglas, who was also under contract to Wallis. \"Variety\" listed it as one of the top grossers of the year, taking in more than $2 million.\nIn 1948, Lancaster had a change of pace with the film adaptation of Arthur Miller's \"All My Sons\", made at Universal Pictures with Edward G. Robinson. His third film for Wallis was an adaptation of \"Sorry, Wrong Number\" in 1948, with Barbara Stanwyck.\nNorma Productions.\nHecht kept to his promise to Lancaster to turn producer. The two of them formed a company, Norma Productions, and did a deal with Universal to make a thriller about a disturbed G.I. in London, \"Kiss the Blood Off My Hands\" in 1948, with Joan Fontaine and directed by Norman Foster. It made a profit of only $50,000, but was critically acclaimed.\nBack in Hollywood, Lancaster made another film noir with Siodmak, \"Criss Cross\", in 1949. It was originally going to be produced by Hellinger and when Hellinger died, another took over. Tony Curtis made an early appearance.\nLancaster appeared in a fourth picture for Wallis, \"Rope of Sand\", in 1949.\nNorma Productions signed a three-picture deal with Warner Bros. The first was 1950's \"The Flame and the Arrow\", a swashbuckler movie, in which Lancaster drew on his circus skills. Nick Cravat had a supporting role and the film was a huge commercial success, making $6 million. It was Warners' most popular film of the year and established an entirely new image for Lancaster.\nLancaster was borrowed by 20th Century Fox for \"Mister 880\" in 1950, a comedy crime romance film with Edmund Gwenn. MGM put him in a popular Western, \"Vengeance Valley\" in 1951, then he went to Warners to play the title role in the biopic \"Jim Thorpe \u2013 All-American\", also in 1951.\nHalburt.\nNorma signed a deal with Columbia Pictures to make two films through a Norma subsidiary, Halburt. The first film was 1951's \"Ten Tall Men\", where Lancaster was a member of the French Foreign Legion. Robert Aldrich worked on the movie as a production manager.\nThe second was 1952's \"The First Time\", a comedy which was the directorial debut of Frank Tashlin. It was meant to star Lancaster but he wound up not appearing in the film\u00a0\u2013 the first of their productions in which he did not act.\nHecht-Lancaster Productions.\nIn 1951, the actor/producer duo changed the company's name to Hecht-Lancaster Productions. The first film under the new name was another swashbuckler: 1952's \"The Crimson Pirate\", directed by Siodmak. Again, co-starring Nick Cravat, it was extremely popular. Taking the premise of The Flame and the Arrow a step further, it allowed the pair to, not only emphasise the absurdity of the story with more spectacle and comical situations but to demonstrate they were able to perform their own circus skills-based stunts without relying on stuntmen quite as much as most Hollywood stars. As if to downplay this, Lancaster himself speaks to the audience in the opening scene over footage of Lancaster performing a dangerous rope swing from one of his pirate ship's masts to the other. \"\u2026in a pirate world, believe only what you see.\" The footage is then reversed to show a near impossible backwards swing to the first mast again, from which he proclaims \"No, believe HALF of what you see.\"\nLancaster changed pace once more by doing a straight dramatic part in 1952's \"Come Back, Little Sheba\", based on a Broadway hit, with Shirley Booth, produced by Wallis and directed by Daniel Mann.\nAlternating with adventure films, he went into \"South Sea Woman\" in 1952 at Warners. Part of the Norma-Warners contract was that Lancaster had to appear in some non-Norma films, of which this was one.\nIn 1954, for his own company, Lancaster produced and starred in \"His Majesty O'Keefe\", a South Sea island tale shot in Fiji. It was co-written by James Hill, who would soon become a part of the Hecht-Lancaster partnership.\nUnited Artists.\nHecht and Lancaster left Warners for United Artists, for what began as a two-picture deal, the first of which was to be 1954's \"Apache\", starring Lancaster as a Native American.\nThey followed it with another Western in 1954, \"Vera Cruz\", co-starring Gary Cooper and produced by Hill. Both films were directed by Robert Aldrich and were hugely popular.\nUnited Artists signed Hecht-Lancaster to a multi-picture contract, to make seven films over two years. These included films in which Lancaster did not act. Their first was \"Marty\" in 1955, based on Paddy Chayefsky's TV play starring Ernest Borgnine and directed by Delbert Mann. It won both the Best Picture Oscar and the Palme d'Or award at Cannes and Borgnine an Best Actor Oscar. It also earned $2 million on a budget of $350,000. \"Vera Cruz\" had been a huge success, but \"Marty\" secured Hecht-Lancaster as one of the most successful independent production companies in Hollywood at the time. \"Marty\" star Borgnine was under contract to Hecht-Lancaster and was unhappy about his lack of upcoming roles, especially after only receiving some seven lines in 1957's \"Sweet Smell of Success\" and half of his normal pay for \"Marty\". He eventually sued for breach of contract to gain back some of this money in 1957.\nWithout Hill, Hecht and Lancaster produced \"The Kentuckian\" in 1955. It was directed by Lancaster in his directorial debut, and he also played a lead role. Lancaster disliked directing and only did it once more, on 1974's \"The Midnight Man\".\nLancaster still had commitments with Wallis, and made \"The Rose Tattoo\" for him in 1955, starring with Anna Magnani and Daniel Mann directing. It was very popular at the box office and critically acclaimed, winning Magnani an Oscar.\nHecht-Hill-Lancaster.\nIn 1955, Hill was made an equal partner in Hecht-Lancaster, with his name added to the production company. Hecht-Hill-Lancaster (HHL) released their first film \"Trapeze\" in 1956, with Lancaster performing many of his own stunts. The film, co-starring Tony Curtis and Gina Lollobrigida, went on to become the production company's top box office success, and United Artists expanded its deal with HHL.\nIn 1956, Lancaster and Hecht partnered with Loring Buzzell and entered the music industry with the music publishing companies Leigh Music, Hecht-Lancaster &amp; Buzzell Music, Calyork Music and Colby Music and the record labels Calyork Records and Maine Records.\nThe HHL team impressed Hollywood with its success; as \"Life\" wrote in 1957, \"[a]fter the independent production of a baker's dozen of pictures, it has yet to have its first flop ... (They were also good pictures.).\" In late 1957, they announced they would make ten films worth $14 million in 1958.\nLancaster made two films for Wallis to complete his eight-film commitment for that contract: \"The Rainmaker\" (1956) with Katharine Hepburn, which earned Lancaster a Golden Globe nomination for Best Actor; and \"Gunfight at the O.K. Corral\" (1957) with Kirk Douglas, which was a huge commercial hit directed by John Sturges.\nLancaster re-teamed with Tony Curtis in 1957 for \"Sweet Smell of Success\", a co-production between Hecht-Hill-Lancaster and Curtis' own company with wife Janet Leigh, Curtleigh Productions. The movie, directed by Alexander Mackendrick, was a critical success but a commercial disappointment. Over the years it has come to be regarded as one of Lancaster's greatest films.\nHHL produced seven additional films in the late 1950s. Four starred Lancaster: \"Run Silent, Run Deep\" (1958), a Robert Wise directed war film with Clark Gable, which was mildly popular; \"Separate Tables\" (1958) a hotel-set drama with Kerr and Rita Hayworth (who married James Hill), which received an Oscar nomination for Best Picture and Oscar awards for lead actor David Niven and supporting actress Wendy Hiller, and was both a critical and commercial success; \"The Devil's Disciple\" (1959), with Douglas and Laurence Olivier, which lost money (and saw Lancaster fire Mackendrick during shooting); and the Western \"The Unforgiven\" (1960), with Audrey Hepburn, which was a critical and commercial disappointment.\nThree were made without Lancaster, all of which lost money: \"The Bachelor Party\" (1957), from another TV play by Chayefsky, and directed by Delbert Mann; \"Take a Giant Step\" (1959), about a black student; and \"Summer of the Seventeenth Doll\" (1960), from an Australian play, shot on location in Australia and Britain. Lancaster was originally announced as the lead for \"Doll\" but did not appear in the final film.\nThe Hecht-Hill-Lancaster Productions company dissolved in 1960 after Hill ruptured his relationship with both Hecht and Lancaster. Hill went on to produce a single additional film, \"The Happy Thieves\", in a new production company, Hillworth Productions, co-owned with his wife Rita Hayworth.\nHecht and Lancaster.\nLancaster played the title role in \"Elmer Gantry\" (1960), written and directed by Richard Brooks for United Artists. The film received five Academy Award nominations, including Best Picture and Best Actor. Lancaster won the 1960 Academy Award for Best Actor, a Golden Globe Award, and the New York Film Critics Award for his performance.\nHecht and Lancaster worked together on \"The Young Savages\" (1961), directed by John Frankenheimer and produced by Hecht. Sydney Pollack worked as a dialogue coach.\nLancaster starred in \"Judgment at Nuremberg\" (1961) for Stanley Kramer, alongside Spencer Tracy, Richard Widmark and a number of other stars. The film was both a commercial and critical success, receiving eleven Oscar nominations, including Best Picture.\nHe then did another film with Hecht and Frankenheimer (replacing Charles Crichton), \"Birdman of Alcatraz\" (1962), a largely fictionalized biography. In it he plays Robert Stroud, a federal prisoner incarcerated for life for two murders, who begins to collect birds and over time becomes an expert in bird diseases, even publishing a book. The film shows Stroud transferred to the maximum security Alcatraz prison where he is not allowed to keep birds and as he ages he gets married, markets bird remedies, helps stop a prison rebellion, and writes a book on the history of the U.S. penal system, but never gets paroled.\nThe sympathetic performance earned Lancaster a Best Actor Oscar nomination, a BAFTA Award for Best Actor, and a Golden Globe nomination for Best Actor in a Dramatic Role. Hecht went on to produce five films without Lancaster's assistance, through his company Harold Hecht Films Productions between 1961 and 1967, including another Academy Award winner, \"Cat Ballou\", starring Lee Marvin and Jane Fonda.\nCollaborations with younger filmmakers.\nLancaster made \"A Child Is Waiting\" (1963) with Judy Garland. It was produced by Kramer and directed by John Cassavetes.\nHe went to Italy to star in \"The Leopard\" (1963) for Luchino Visconti, co-starring Alain Delon and Claudia Cardinale. It was one of Lancaster's favorite films and was a big hit in France but failed in the US (though the version released was much truncated).\nHe had a small role in \"The List of Adrian Messenger\" (1963) for producer/star Kirk Douglas, and then did two for Frankenheimer: \"Seven Days in May\" (1964), a political thriller with Douglas, and \"The Train\" (1964), a World War Two action film (Lancaster had Frankenheimer replace Arthur Penn several days into filming).\nLancaster starred in \"The Hallelujah Trail\" (1965), a comic Western produced and directed by John Sturges which failed to recoup its large cost.\nHe had a big hit with \"The Professionals\" (1966), a Western directed by Brooks and also starring Lee Marvin.\nIn 1966, at the age of 52, Lancaster appeared nude in director Frank Perry's film \"The Swimmer\" (1968), in what the critic Roger Ebert called \"his finest performance\". Prior to working on \"The Swimmer\", Lancaster was terrified of the water because he did not know how to swim. In preparation for the film, he took swimming lessons from UCLA swim coach Bob Horn. Filming was difficult and clashes between Lancaster and Perry led to Sydney Pollack coming in to do some filming. The film was not released until 1968, when it proved to be a commercial failure, though Lancaster remained proud of the movie and his performance.\nNorlan Productions.\nIn 1967, Lancaster formed a new partnership with Roland Kibbee, who had already worked as a writer on five Lancaster projects: \"Ten Tall Men\", \"The Crimson Pirate\", \"Three Sailors and a Girl\" (in which Lancaster made a cameo appearance), \"Vera Cruz\", and \"The Devil's Disciple\".\nThrough Norlan Productions, Lancaster and Kibbee produced \"The Scalphunters\" in 1968, directed by Sydney Pollack.\nLancaster followed it with another film from Pollack, \"Castle Keep\" in 1969, which was a big flop. So was \"The Gypsy Moths\", for Frankenheimer, also in 1969.\n1970s.\nLancaster had one of the biggest successes of his career with \"Airport\" in 1970, starring alongside Dean Martin, George Kennedy, Van Heflin, Helen Hayes, Maureen Stapleton, Barbara Hale, Jean Seberg, and Jacqueline Bisset. The Ross Hunter film received nine Academy Award nominations, including one for Best Picture. It became one of the biggest box-office hits of 1970 and, at that time, reportedly the highest-grossing film in the history of Universal Pictures.\nHe then went into a series of Westerns: \"Lawman\" in 1971, directed by Michael Winner; \"Valdez Is Coming\" in 1971, for Norlan; and \"Ulzana's Raid\" in 1972, directed by Aldrich and produced by himself and Hecht. None were particularly popular but \"Ulzana's Raid\" has become a cult film.\nLancaster did two thrillers, both 1973: \"Scorpio\" with Winner and \"Executive Action\".\nLancaster returned to directing in 1974 with \"The Midnight Man\", which he also wrote and produced with Kibee.\nHe made a second film with Visconti, \"Conversation Piece\" in 1974 and played the title role in the TV series \"Moses the Lawgiver\", also in 1974.\nLancaster was one of many names in 1975's \"1900\", directed by Bernardo Bertolucci, and he had a cameo in 1976's \"Buffalo Bill and the Indians, or Sitting Bull's History Lesson\" for Robert Altman.\nHe played Shimon Peres in the TV movie \"Victory at Entebbe\" in 1977 and had a supporting role in \"The Cassandra Crossing\" in 1976. He made a fourth and final film with Aldrich, \"Twilight's Last Gleaming\" in 1977, and had the title role in 1977's \"The Island of Dr. Moreau\".\nLancaster was top-billed in \"Go Tell the Spartans\" in 1978, a Vietnam War film; Lancaster admired the script so much that he took a reduced fee and donated money to help the movie to be completed. He was in \"Zulu Dawn\" in 1979.\n1980s.\nLancaster began the 1980s with a highly acclaimed performance alongside Susan Sarandon in \"Atlantic City\" in 1980, directed by Louis Malle. The film received five Oscar nominations, including Best Picture and a Best Actor nomination for Lancaster.\nHe had key roles in \"Cattle Annie and Little Britches\" in 1981, \"The Skin\" in 1982 with Cardinale, \"Marco Polo\", also in 1982, and \"Local Hero\" in 1983.\nBy now, Lancaster was mostly a character actor in features, as in \"The Osterman Weekend\" in 1983, but he was the lead in the TV movie \"Scandal Sheet\" in 1985.\nHe was in \"Little Treasure\" in 1985, directed by Alan Sharp, who had written \"Ulzana's Raid\"; \"On Wings of Eagles\" for TV in 1986, as Bull Simons; 1986's made for TV \"Barnum\" starred him in the title role; \"Tough Guys\" reunited him on the big screen with Kirk Douglas in 1986; \"\" (in German V\u00e4ter und S\u00f6hne \u2013 Eine deutsche Trag\u00f6die) in 1986 for German TV; 1987's \"Control\" made in Italy; \"Rocket Gibraltar\" in 1988, and \"The Jeweller's Shop\" in 1989.\nHis first critical success in a while was \"Field of Dreams\" in 1989, in which he played a supporting role as Moonlight Graham. He was also in the miniseries \"The Betrothed\" in 1989.\nLater career.\nLancaster's final performances included TV miniseries \"The Phantom of the Opera\" (1990); \"\" (1990) as Leon Klinghoffer based on the 1985 hijacking incident; and \"Separate But Equal\" (1991) with Sidney Poitier.\nFrequent collaborators.\nLancaster appeared in a total of seventeen films produced by his agent, Harold Hecht. Eight of these were co-produced by James Hill. He also appeared in eight films produced by Hal B. Wallis and two with producer Mark Hellinger. Although Lancaster's work alongside Kirk Douglas was known as that of a successful pair of actors, Douglas, in fact, produced four films for the pair, through his production companies Bryna Productions and Joel Productions. Roland Kibbee also produced three Lancaster films, and Lancaster was also cast in two Stanley Kramer productions.\nKirk Douglas.\nKirk Douglas starred in seven films across the decades with Burt Lancaster: \"I Walk Alone\" (1948), \"Gunfight at the O.K. Corral\" (1957), \"The Devil's Disciple\" (1959), \"The List of Adrian Messenger\" (1963), \"Seven Days in May\" (1964), \"Victory at Entebbe\" (1976) and \"Tough Guys\" (1986), which fixed the notion of the pair as something of a team in the public imagination. Douglas was always billed under Lancaster in these movies but, with the exception of \"I Walk Alone\", in which Douglas played a villain, their roles were usually more or less the same size. Both actors arrived in Hollywood at about the same time, and first appeared together in the fourth film for each, albeit with Douglas in a supporting role. They both became actor-producers who sought out independent Hollywood careers.\nJohn Frankenheimer.\nJohn Frankenheimer directed five films with Lancaster: \"The Young Savages\" (1961), \"Birdman of Alcatraz\" (1962), \"Seven Days in May\" (1964), \"The Train\" (1964), and \"The Gypsy Moths\" (1969).\nOther repeat collaborators.\nHe was directed four times by Robert Aldrich, three times each by Robert Siodmak and Sydney Pollack, and twice each by Byron Haskin, Daniel Mann, John Sturges, John Huston, Richard Brooks, Alexander Mackendrick, Luchino Visconti, and Michael Winner.\nRoland Kibbee wrote for seven Lancaster films. Lancaster used makeup veteran Robert Schiffer in twenty credited films, hiring Schiffer on nearly all of the films he produced.\nPolitical activism.\nLancaster was a vocal supporter of progressive and liberal political causes. He frequently spoke out in support of racial and other minorities. As a result, he was often a target of FBI investigations. He was named in President Richard Nixon's 1973 \"Enemies List\".\nA vocal opponent of the Vietnam War, he helped pay for the successful defense of a soldier accused of \"fragging\" (i.e., murdering) another soldier during war-time. In 1968, Lancaster actively supported the presidential candidacy of anti-war Senator Eugene McCarthy of Minnesota, and frequently spoke on his behalf during the Democratic primaries.\nLancaster was also active in anti-death penalty activism. He campaigned heavily for George McGovern in the 1972 United States presidential election.\nIn 1985, Lancaster joined the fight against AIDS after fellow movie star Rock Hudson contracted the disease. Lancaster delivered Hudson's last words at the Commitment to Life fundraiser at a time when the stigma surrounding AIDS was at its height.\nOf his political opinions, frequent co-star Tony Curtis said: \"Here's this great big aggressive guy that looks like a ding-dong athlete playing these big tough guys and he has the soul of\u2014who were those first philosophers of equality?\u2014Socrates, Plato. He was a Greek philosopher with a sense that everybody was equal.\"\nActor and SAG president Ed Asner said he showed everybody in Hollywood \"how to be a liberal with balls\".\nHollywood Ten.\nIn 1947, Lancaster reportedly signed a statement release by the National Council of Arts, Sciences and Professions (NCASP) asking Congress to abolish the House Un-American Activities Committee (HUAC). He was also a member of the short-lived Committee for the First Amendment, formed in support of the Hollywood Ten. He was one of 26 movie stars who flew to Washington in October 1947 to protest against the HUAC hearings. The committee's \"Hollywood Fights Back\" broadcasts on ABC Radio Network were two 30-minute programs that took place on October 27 and November 2, 1947, during which committee members voiced their opposition to the HUAC hearings. Many members faced blacklisting and backlash due to their involvement in the committee. Lancaster was listed in anti-communist literature as a fellow traveler.\nCivil rights movement.\nHe and his second wife, Norma, hosted a fundraiser for Martin Luther King Jr. and the Student Diversity Leadership Conference (SDLC) ahead of the historic March on Washington in 1963. He attended the march, where he was one of the speakers. He flew in from France for the event, where he was shooting \"The Train\", and flew back again the next day, despite a reported fear of flying.\nOn August 28, 1963, at the March on Washington Lancaster \"read the speech that James Baldwin was supposed to make,\" because (as Malcolm X said in a speech delivered in Detroit at the King Solomon Baptist Church in late 1963) \"they wouldn't let Baldwin get up there because they know Baldwin is liable to say anything.\"\nACLU.\nIn 1968, Lancaster was elected to serve as chairman of the Roger Baldwin Foundation, a newly formed fund-raising arm of the American Civil Liberties Union of Southern California. His co-chairs were Frank Sinatra and Irving L. Lichtenstein. In October 1968, he hosted a party at his home to raise money for the ACLU to use for the defense of the more than four hundred people arrested at the 1968 Democratic National Convention. Throughout the years, he remained an ardent supporter and a fundraiser for the organization.\nWhile serving as a member of the five-person ACLU Foundation executive committee, he cast the key vote to retain Ramona Ripston as executive director of the Southern California affiliate, a position she would build into a powerful advocacy force in Los Angeles politics. Ripston later recalled: \"There was a feeling that a woman couldn't run the ACLU foundation, nor have access to the books. The vote finally came down to two 'yes' and two 'no.' Who had the deciding vote? Burt. He had a scotch or two and finally he said, 'I think she should be executive director.' I always loved him for that.\"\nWhen President George H. W. Bush derided Democratic candidate Michael Dukakis as a \"card-carrying member of the ACLU\", Lancaster was one of the supporters featured in the organization's first television advertising campaign stating: \"I'm a card-carrying member of the ACLU\" and \"No one agrees with every single thing they've done. But no one can disagree with the guiding principle\u2014with liberty and justice for all.'\" He also campaigned for Michael Dukakis in the 1988 United States presidential election.\nPersonal life.\nMarriages and relationships.\nLancaster guarded his personal life and attempted to keep it private despite his stardom. He was married three times and had five children.\nHis first marriage was to June Ernst, a trapeze acrobat. Ernst was the daughter of a renowned female aerialist and an accomplished acrobat herself. After they were married, he performed with her family and her until their separation in the late 1930s. When they divorced is unclear. Contemporary reports listed 1940, but subsequent biographers have suggested dates as late as 1946, delaying his marriage to his second wife.\nHe met second wife Norma Anderson (1917\u20131988) when the stenographer substituted for an ill actress in a USO production for the troops in Italy. Reportedly, on seeing Lancaster in the crowd on her way to town from the airport, she turned to an officer and asked, \"Who is that good-looking officer and is he married?\" The officer set up a blind date between the two for that evening. They married in 1946. Norma was active in political causes with an entire room in their Bel Air home devoted to her major interest, the League of Woman Voters, crammed with printing presses and all the necessary supplies for mass mailings.\nShe was a life-long member of the NAACP. The couple held a fundraiser for Martin Luther King Jr. and the Southern Christian Leadership Conference ahead of the 1963 March on Washington. All five of his children were with Anderson, including Bill. It was a troubled marriage. The pair separated in 1966, and divorced in 1969.\nIn 1966, Lancaster began a long-term relationship with hairdresser Jackie Bone, who worked on \"The Professionals\". The relationship was tempestuous, with Bone once smashing a wine bottle over Lancaster's head at a dinner with Sydney Pollack and Peter Falk. Reportedly, they eventually split up after her religious conversion, which Lancaster believed he could not share with her.\nHis third marriage, to Susan Martin, lasted from September 1990 until his death in 1994.\nAccording to biographer Kate Buford in \"\", Lancaster was devotedly loyal to his friends and family. Old friends from his childhood remained his friends for life.\nPossible affairs.\nSome media outlets and authors have written that Lancaster was bisexual, and had relationships with both men and women. Friends said he claimed he was romantically involved with Deborah Kerr during the filming of \"From Here to Eternity\" in 1953. However, Kerr stated that while there was a spark of attraction, nothing ever happened. He reportedly had an affair with Joan Blondell.\nIn her 1980 autobiography, Shelley Winters claimed to have had a two-year affair with him, during which time he was considering separation from his wife. In his Hollywood memoirs, friend Farley Granger recalled an incident when Lancaster and he had to come to Winters' rescue one evening when she had inadvertently overdosed on alcohol and sleeping pills. She broke up with him for \"cheating on her with his wife\" after she heard reports of his wife's third or fourth pregnancy.\nReligion.\nDespite his Protestant background and upbringing, Lancaster identified as an atheist later in life.\nLater years.\nAs Lancaster reached his 60s, he began to be affected by cardiovascular disease. In January 1980, he had complications from a routine gall bladder operation (that he barely survived). In 1983, following two minor heart attacks, he underwent an emergency quadruple coronary bypass. He continued to act, however, and to engage in public activism. In 1988, he attended a congressional hearing in Washington, DC, with former colleagues who included James Stewart and Ginger Rogers to protest against media magnate Ted Turner's plan to colorize various black-and-white films from the 1930s and 1940s. On November 30, 1990, when he was 77, a stroke left him partially paralyzed and largely unable to speak, ending his acting career.\nDeath.\nLancaster died at his apartment in Century City, Los Angeles, after having a third heart attack at 4:50 am on October 20, 1994, age 80. His body was cremated, and his ashes were scattered under a large oak tree in Westwood Memorial Park, which is located in Westwood Village, California. A small, square ground plaque amid several others, inscribed \"Burt Lancaster 1913\u20131994\", marks the location. As he had requested, no memorial or funeral service was held for him.\nLegacy.\nThe centennial of Lancaster's birth was honored at New York City's Film Society of Lincoln Center in May 2013 with the screening of 12 of the actor's best-known films, from \"The Killers\" to \"Atlantic City\".\nLancaster has a star on the Hollywood Walk of Fame, at 6801 Hollywood Boulevard.\nFilmography and awards.\nLancaster was nominated for the Oscar for Best Actor in a Leading Role in 1954 for \"From Here to Eternity\", in 1961 for \"Elmer Gantry\", in 1964 for \"Birdman of Alcatraz\", and in 1982 for \"Atlantic City\". He won the Oscar in 1961. Lancaster's leading role in Luchino Visconti's 1963 canonical \"The Leopard\" began a series of roles with important European art film directors that included roles in Bernardo Bertolucci's \"1900\" and Louis Malle's \"Atlantic City\" as well as Visconti's \"Conversation Piece\".\nBox office ranking.\nFor a number of years exhibitors voted Lancaster among the most popular stars:\nIn other media.\nSpanish music group Hombres G released an album named \"La cagaste, Burt Lancaster\" (\"You messed up, Burt Lancaster\") in 1986.\nThomas Hart Benton painted a scene from \"The Kentuckian\" as part of the film's marketing. Lancaster posed for the painting, also known as \"The Kentuckian\".\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nBibliography.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "4540", "revid": "7611264", "url": "https://en.wikipedia.org/wiki?curid=4540", "title": "Balts", "text": "Group of peoples in northern Europe\nThe Balts or Baltic peoples (, ) are a group of peoples inhabiting the eastern coast of the Baltic Sea who speak Baltic languages. Among the Baltic peoples are modern-day Lithuanians (including Samogitians) and Latvians (including Latgalians) \u2014 all East Balts \u2014 as well as the Old Prussians, Curonians, Sudovians, Skalvians, Yotvingians and Galindians \u2014 the Western Balts \u2014 whose languages and cultures are now extinct, but made a large influence on the living branches, especially on literary Lithuanian language.\nThe Balts are descended from a group of Proto-Indo-European tribes who settled the area between the lower Vistula and southeast shore of the Baltic Sea and upper Daugava and Dnieper rivers, and which over time became differentiated into West and East Balts. In the fifth century CE, parts of the eastern Baltic coast began to be settled by the ancestors of the Western Balts, whereas the East Balts lived in modern-day Belarus, Ukraine and Russia. In the first millennium CE, large migrations of the Balts occurred. By the 13th and 14th centuries, the East Balts shrank to the general area that the present-day Balts and Belarusians inhabit.\nBaltic languages belong to the Balto-Slavic branch of the Indo-European languages. One of the features of Baltic languages is the number of conservative or archaic features retained.\nEtymology.\nMedieval German chronicler Adam of Bremen in the latter part of the 11th century AD was the first writer to use the term \"Baltic\" in reference to the sea of that name. Before him various ancient places names, such as Balcia, were used in reference to a supposed island in the Baltic Sea.\nIn Germanic languages there was some form of the toponym East Sea until after about the year 1600, when maps in English began to label it as the Baltic Sea. By 1840, German nobles of the Governorate of Livonia adopted the term \"Balts\" to distinguish themselves from Germans of Germany. They spoke an exclusive dialect, Baltic German, which was regarded by many as the language of the Balts until 1919.\nIn 1845, Georg Heinrich Ferdinand Nesselmann proposed a distinct language group for Latvian, Lithuanian, and Old Prussian, which he termed Baltic. The term became prevalent after Latvia and Lithuania gained independence in 1918. Up until the early 20th century, either \"Latvian\" or \"Lithuanian\" could be used to mean the entire language family.\nHistory.\nOrigins.\nThe Balts or Baltic peoples, defined as speakers of one of the Baltic languages, a branch of the Indo-European language family, are descended from a group of Indo-European tribes who settled the area between the lower Vistula and southeast shore of the Baltic Sea and upper Daugava and Dnieper rivers. The Baltic languages, especially Lithuanian, retain a number of conservative or archaic features, perhaps because the areas in which they are spoken are geographically consolidated and have low rates of immigration.\nSome of the major authorities on Balts, such as Kazimieras B\u016bga, Max Vasmer, Vladimir Toporov and Oleg Trubachyov, in conducting etymological studies of eastern European river names, were able to identify in certain regions names of specifically Baltic provenance, which most likely indicate where the Balts lived in prehistoric times. According to Vladimir Toporov and Oleg Trubachyov, the eastern boundary of the Balts in the prehistoric times were the upper reaches of the Volga, Moskva, and Oka rivers, while the southern border was the Seym river. This information is summarized and synthesized by Marija Gimbutas in \"The Balts\" (1963) to obtain a likely proto-Baltic homeland. Its borders are approximately: from a line on the Pomeranian coast eastward to include or nearly include the present-day sites of Berlin, Warsaw, Kyiv, and Kursk, northward through Moscow to the River Berzha, westward in an irregular line to the coast of the Gulf of Riga, north of Riga. \nHowever, other scholars such as Endre Bojt (1999) reject the presumption that there ever was such a thing as a clear, single \"Baltic \"Urheimat\"\": 'The references to the Balts at various \"Urheimat\" locations across the centuries are often of doubtful authenticity, those concerning the Balts furthest to the West are the more trustworthy among them. (...) It is wise to group the particulars of Baltic history according to the interests that moved the pens of the authors of our sources.'\nProto-history.\nThe area of Baltic habitation shrank due to assimilation by other groups, and invasions. According to one of the theories which has gained considerable traction over the years, one of the western Baltic tribes, the Galindians, Galindae, or Goliad, migrated to the area around modern-day Moscow, Russia around the fourth century AD.\nOver time the Balts became differentiated into West and East Balts. In the fifth century AD parts of the eastern Baltic coast began to be settled by the ancestors of the Western Balts: Brus/Pr\u016bsa (\"Old Prussians\"), Sudovians/Jotvingians, Scalvians, Nadruvians, and Curonians. The East Balts, including the hypothesised Dniepr Balts, were living in modern-day Belarus, Ukraine and Russia.\nGermanic peoples lived to the west of the Baltic homelands; by the first century AD, the Goths had stabilized their kingdom from the mouth of the Vistula, south to Dacia. As Roman domination collapsed in the first half of the first millennium CE in Northern and Eastern Europe, large migrations of the Balts occurred \u2014 first, the Galindae or Galindians towards the east, and later, East Balts towards the west. In the eighth century, Slavic tribes from the Volga regions appeared. By the 13th and 14th centuries, they reached the general area that the present-day Balts and Belarusians inhabit. Many other Eastern and Southern Balts either assimilated with other Balts, or Slavs in the fourth\u2013seventh centuries and were gradually slavicized.\nMiddle Ages.\nIn the 12th and 13th centuries, internal struggles and invasions by Ruthenians and Poles, and later the expansion of the Teutonic Order, resulted in an almost complete annihilation of the Galindians, Curonians, and Yotvingians. Gradually, Old Prussians became Germanized or Lithuanized between the 15th and 17th centuries, especially after the Reformation in Prussia. The cultures of the Lithuanians and Latgalians/Latvians survived and became the ancestors of the populations of the modern-day countries of Latvia and Lithuania.\nOld Prussian was closely related to the other extinct Western Baltic languages, Curonian, Galindian and Sudovian. It is more distantly related to the surviving Eastern Baltic languages, Lithuanian and Latvian. Compare the Prussian word \"seme\" (\"zem\u0113\"), Latvian \"zeme\", the Lithuanian \"\u017eem\u0117\" (\"land\" in English).\nModern era.\nIn the modern era, the Balts \u2014 primarily Lithuanians and Latvians \u2014 have sustained a unique cultural and linguistic identity along the eastern shores of the Baltic Sea, speaking the only surviving Eastern Baltic languages, Lithuanian and Latvian, which are among the most conservative Indo\u2011European tongues and retain archaic features from their Proto\u2011Indo\u2011European roots. Following nearly five decades of Soviet rule, Lithuania and Latvia restored their independence in 1990\u20131991 and subsequently pursued integration with Western institutions, culminating in accession to both the European Union and NATO in 2004. In the 21st century, these two Baltic nations have established stable democracies with parliamentary systems, preserved local languages and traditions, and address common economic, political and cultural priorities.\nCulture.\nThe Balts originally practiced Baltic religion. They were gradually Christianized as a result of the Northern Crusades of the Middle Ages. Baltic peoples such as the Latvians, Lithuanians and Old Prussians had their distinct mythologies. The Lithuanians have close historic ties to Poland, and many of them are Roman Catholic. The Latvians have close historic ties to Northern Germany and Scandinavia, and many of them are irreligious. In recent times, the Baltic religion has been revived in Baltic neopaganism.\nGenetics.\nThe Balts are included in the \"North European\" gene cluster together with the Germanic peoples, some Slavic groups (the Poles and Northern Russians) and Baltic Finnic peoples.\nSaag et a. (2017) detected that the eastern Baltic in the Mesolithic was inhabited primarily by Western Hunter-Gatherers (WHGs). Their paternal haplogroups were mostly types of I2a and R1b, while their maternal haplogroups were mostly types of U5, U4 and U2. These people carried a high frequency of the derived HERC2 allele which codes for light eye color and possess an increased frequency of the derived alleles for SLC45A2 and SLC24A5, coding for lighter skin color.\nBaltic hunter-gatherers still displayed a slightly larger amount of WHG ancestry than Scandinavian Hunter-Gatherers (SHGs). WHG ancestry in the Baltic was particularly high among hunter-gatherers in Latvia and Lithuania. Unlike other parts of Europe, the hunter-gatherers of the eastern Baltic do not appear to have mixed much with Early European Farmers (EEFs) arriving from Anatolia.\nDuring the Neolithic, increasing admixture from Eastern Hunter-Gatherers (EHGs) is detected. The paternal haplogroups of EHGs was mostly types of R1a, while their maternal haplogroups appears to have been almost exclusively types of U5, U4, and U2.\nThe rise of the Corded Ware culture in the eastern Baltic in the Chalcolithic and Bronze Age is accompanied by a significant infusion of steppe ancestry and EEF ancestry into the eastern Baltic gene pool. In the aftermath of the Corded Ware expansion, local hunter-gatherer ancestry experienced a resurgence.\nHaplogroup N reached the eastern Baltic only in the Late Bronze Age, probably with the speakers of the Uralic languages.\nModern-day Balts have a lower amount of EEF ancestry, and a higher amount of WHG ancestry, than any other population in Europe.\nList of Baltic peoples.\nModern-day Baltic peoples\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "4541", "revid": "17618788", "url": "https://en.wikipedia.org/wiki?curid=4541", "title": "Burnt-in timecode", "text": "Burnt-in timecode (often abbreviated to BITC by analogy to VITC) is a human-readable on-screen version of the timecode information for a piece of material superimposed on a video image. BITC is sometimes used in conjunction with \"real\" machine-readable timecode but more often used in copies of original material onto a nonbroadcast format such as VHS so that the VHS copies can be traced back to their master tape and the original timecodes easily located. \nMany professional VTRs can \"burn\" (overlay) the tape timecode onto one of their outputs. This output (which usually also displays the setup menu or on-screen display) is known as the \"super out\" or \"monitor out\". The \"character\" switch or menu item turns this behaviour on or off. The \"character\" function also displays the timecode on the preview monitors in linear editing suites.\nVideotapes that are recorded with timecode numbers overlaid on the video are referred to as \"window dubs\", named after the \"window\" that displays the burnt-in timecode on-screen.\nWhen editing was done using magnetic tapes that were subject to damage from excessive wear, it was common to use a window dub as a working copy for the majority of the editing process. Editing decisions would be made using a window dub, and no specialized equipment was needed to write down an edit decision list, which would then be replicated from the high-quality masters.\nTimecode can also be superimposed on video using a dedicated overlay device, often called a \"window dub inserter\". This inputs a video signal and its separate timecode audio signal, reads the timecode, superimposes the timecode display over the video, and outputs the combined display (usually via composite), all in real time. Stand-alone timecode generators/readers often have the window dub function built in. \nSome consumer cameras, in particular DV cameras, can \"burn\" (overlay) the tape timecode onto the composite output. This output is typically semitransparent and may include other tape information. It is usually activated by turning on the \"display\" info in one of the camera's submenus. While not as \"professional\" as an overlay created by a professional VCR, it is a cheap alternative that is just as accurate.\nTimecode is stored in the metadata areas of captured DV AVI files, and some software is able to \"burn\" (overlay) this into the video frames. For example, DVMP Pro is able to \"burn\" timecode or other items of DV metadata (such as date and time, iris, shutter speed, gain, white balance mode, etc.) into DV AVI files.\nOCR techniques can be used to read BITC in situations where other forms of timecode are not available.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "4542", "revid": "28862934", "url": "https://en.wikipedia.org/wiki?curid=4542", "title": "Bra\u2013ket notation", "text": "Notation for quantum states\nThe Bra\u2013ket notation or Dirac notation is a notation for linear algebra and linear operators on complex vector spaces together with their dual spaces both in the finite- and infinite-dimensional cases. It is specifically designed to ease the types of calculations that frequently arise in quantum mechanics. It is now of ubiquitous usage in that subject.\nThe bra\u2013ket notation was created by Paul Dirac in his paper, \"A New Notation for Quantum Mechanics\" from 1939. The name comes from the English word \"bracket\".\nQuantum mechanics.\nIn quantum mechanics and quantum computing, bra\u2013ket notation is used ubiquitously to denote quantum states. The notation uses angle brackets, formula_1 and formula_2, and a vertical bar formula_3. Mathematically it denotes a vector, formula_4, in an abstract (complex) vector space formula_5, and physically it represents a state of some quantum system.\nA bra is of the form formula_6. Mathematically it denotes a linear form formula_7, i.e. a linear map that maps each vector in formula_5 to a number in the complex plane formula_9. Letting the linear functional formula_10 act on a vector formula_11 is written as formula_12.\nAssume that on formula_5 there exists an inner product formula_14 with antilinear first argument, which makes formula_5 an inner product space. Then with this inner product each vector formula_16 can be identified with a corresponding linear form, by placing the vector in the anti-linear first slot of the inner product: formula_17. The correspondence between these notations is then formula_18. The linear form formula_19 is a covector to formula_20, and the set of all covectors forms a subspace of the dual vector space formula_21, to the initial vector space formula_5. The purpose of this linear form formula_19 can now be understood in terms of making projections onto the state formula_24 to find how linearly dependent two states are, etc.\nFor the vector space formula_25, kets can be identified with column vectors, and bras with row vectors. Combinations of bras, kets, and linear operators are interpreted using matrix multiplication. If formula_25 has the standard Hermitian inner product formula_27, under this identification, the identification of kets and bras and vice versa provided by the inner product is taking the Hermitian conjugate (denoted formula_28).\nIt is common to suppress the vector or linear form from the bra\u2013ket notation and only use a label inside the typography for the bra or ket. For example, the spin operator formula_29 on a two-dimensional space formula_30 of spinors has eigenvalues formula_31 with eigenspinors formula_32. In bra\u2013ket notation, this is typically denoted as formula_33, and formula_34. As above, kets and bras with the same label are interpreted as kets and bras corresponding to each other using the inner product. In particular, when also identified with row and column vectors, kets and bras with the same label are identified with Hermitian conjugate column and row vectors.\nBra\u2013ket notation was effectively established in 1939 by Paul Dirac; it is thus also known as Dirac notation, despite the notation having a precursor in Hermann Grassmann's use of formula_35 for inner products nearly 100 years earlier.\nVector spaces.\nVectors vs kets.\nIn mathematics, the term \"vector\" is used for an element of any vector space. In physics, however, the term \"vector\" tends to refer almost exclusively to quantities like displacement or velocity, which have components that relate directly to the three dimensions of space, or relativistically, to the four of spacetime. Such vectors are typically denoted with over arrows (formula_36), boldface (formula_37) or indices (formula_38).\nIn quantum mechanics, a quantum state is typically represented as an element of a complex Hilbert space, for example, the infinite-dimensional vector space of all possible wavefunctions (square integrable functions mapping each point of 3D space to a complex number) or some more abstract Hilbert space constructed more algebraically. To distinguish this type of vector from those described above, it is common and useful in physics to denote an element formula_39 of an abstract complex vector space as a ket formula_20, to refer to it as a \"ket\" rather than as a vector, and to pronounce it \"ket-formula_39\" or \"ket-A\" for .\nSymbols, letters, numbers, or even words\u2014whatever serves as a convenient label\u2014can be used as the label inside a ket, with the formula_42 making clear that the label indicates a vector in vector space. In other words, the symbol \"\" has a recognizable mathematical meaning as to the kind of variable being represented, while just the \"\"A\"\" by itself does not. For example, is not necessarily equal to . Nevertheless, for convenience, there is usually some logical scheme behind the labels inside kets, such as the common practice of labeling energy eigenkets in quantum mechanics through a listing of their quantum numbers. At its simplest, the label inside the ket is the eigenvalue of a physical operator, such as formula_43, formula_44, formula_45, etc.\nNotation.\nSince kets are just vectors in a Hermitian vector space, they can be manipulated using the usual rules of linear algebra. For example:\nformula_46\nNote how the last line above involves infinitely many different kets, one for each real number \"x\".\nSince the ket is an element of a vector space, a bra formula_47 is an element of its dual space, i.e. a bra is a linear functional which is a linear map from the vector space to the complex numbers. Thus, it is useful to think of kets and bras as being elements of different vector spaces (see below however) with both being different useful concepts.\nA bra formula_19 and a ket formula_49 (i.e. a functional and a vector), can be combined to an operator formula_50 of rank one with outer product\nformula_51\nInner product and bra\u2013ket identification on Hilbert space.\nThe bra\u2013ket notation is particularly useful in Hilbert spaces which have an inner product that allows Hermitian conjugation and identifying a vector with a continuous linear functional, i.e. a ket with a bra, and vice versa (see Riesz representation theorem). The inner product on Hilbert space formula_52 (with the first argument anti linear as preferred by physicists) is fully equivalent to an (anti-linear) identification between the space of kets and that of bras in the bra\u2013ket notation: for a vector ket formula_53 define a functional (i.e. bra) formula_54 by\nformula_55\nBras and kets as row and column vectors.\nIn the simple case where we consider the vector space formula_25, a ket can be identified with a column vector, and a bra as a row vector. If, moreover, we use the standard Hermitian inner product on formula_25, the bra corresponding to a ket, in particular a bra and a ket with the same label are conjugate transpose. Moreover, conventions are set up in such a way that writing bras, kets, and linear operators next to each other simply imply matrix multiplication. In particular the outer product formula_58 of a column and a row vector ket and bra can be identified with matrix multiplication (column vector times row vector equals matrix).\nFor a finite-dimensional vector space, using a fixed orthonormal basis, the inner product can be written as a matrix multiplication of a row vector with a column vector:\nformula_59\nBased on this, the bras and kets can be defined as:\nformula_60\nand then it is understood that a bra next to a ket implies matrix multiplication.\nThe conjugate transpose (also called \"Hermitian conjugate\") of a bra is the corresponding ket and vice versa:\nformula_61\nbecause if one starts with the bra\nformula_62\nthen performs a complex conjugation, and then a matrix transpose, one ends up with the ket\nformula_63\nWriting elements of a finite dimensional (or mutatis mutandis, countably infinite) vector space as a column vector of numbers requires picking a basis. Picking a basis is not always helpful because quantum mechanics calculations involve frequently switching between different bases (e.g. position basis, momentum basis, energy eigenbasis), and one can write something like \"\" without committing to any particular basis. In situations involving two different important basis vectors, the basis vectors can be taken in the notation explicitly and here will be referred simply as \"\" and \"\".\nNon-normalizable states and non-Hilbert spaces.\nBra\u2013ket notation can be used even if the vector space is not a Hilbert space.\nIn quantum mechanics, it is common practice to write down kets which have infinite norm, i.e. non-normalizable wavefunctions. Examples include states whose wavefunctions are Dirac delta functions or infinite plane waves. These do not, technically, belong to the Hilbert space itself. However, the definition of \"Hilbert space\" can be broadened to accommodate these states (see the Gelfand\u2013Naimark\u2013Segal construction or rigged Hilbert spaces). The bra\u2013ket notation continues to work in an analogous way in this more general context.\nBanach spaces are a different generalization of Hilbert spaces. In a Banach space , the vectors may be notated by kets and the continuous linear functionals by bras. Over any vector space without a given topology, we may still notate the vectors by kets and the linear functionals by bras. In these more general contexts, the bracket does not have the meaning of an inner product, because the Riesz representation theorem does not apply.\nUsage in quantum mechanics.\nThe mathematical structure of quantum mechanics is based in large part on linear algebra:\nSince virtually every calculation in quantum mechanics involves vectors and linear operators, it can involve, and often does involve, bra\u2013ket notation. A few examples follow:\nSpinless position\u2013space wave function.\nThe Hilbert space of a spin-0 point particle can be represented in terms of a \"position basis\" , where the label r extends over the set of all points in position space. These states satisfy the eigenvalue equation for the position operator:\nformula_64\nThe position states are \"generalized eigenvectors\", not elements of the Hilbert space itself, and do not form a countable orthonormal basis. However, as the Hilbert space is separable, it does admit a countable dense subset within the domain of definition of its wavefunctions. That is, starting from any ket in this Hilbert space, one may \"define\" a complex scalar function of r, known as a wavefunction,\nformula_65\nOn the left-hand side, \u03a8(r) is a function mapping any point in space to a complex number; on the right-hand side,\nformula_66 \nis a ket consisting of a superposition of kets with relative coefficients specified by that function.\nIt is then customary to define linear operators acting on wavefunctions in terms of linear operators acting on kets, by\nformula_67\nFor instance, the momentum operator formula_68 has the following coordinate representation,\nformula_69\nOne occasionally even encounters an expression such as formula_70, though this is something of an abuse of notation. The differential operator must be understood to be an abstract operator, acting on kets, that has the effect of differentiating wavefunctions once the expression is projected onto the position basis, formula_71\neven though, in the momentum basis, this operator amounts to a mere multiplication operator (by \"i\u0127\"p). That is, to say,\nformula_72\nor\nformula_73\nOverlap of states.\nIn quantum mechanics the expression is typically interpreted as the probability amplitude for the state \"\u03c8\" to collapse into the state \"\u03c6\". Mathematically, this means the coefficient for the projection of \"\u03c8\" onto \"\u03c6\". It is also described as the projection of state \"\u03c8\" onto state \"\u03c6\".\nChanging basis for a spin-1/2 particle.\nA stationary spin-&lt;templatestyles src=\"Fraction/styles.css\" /&gt;1\u20442 particle has a two-dimensional Hilbert space. One orthonormal basis is:\nformula_74\nwhere is the state with a definite value of the spin operator \"Sz\" equal to +&lt;templatestyles src=\"Fraction/styles.css\" /&gt;1\u20442 and is the state with a definite value of the spin operator \"Sz\" equal to \u2212&lt;templatestyles src=\"Fraction/styles.css\" /&gt;1\u20442.\nSince these are a basis, \"any\" quantum state of the particle can be expressed as a linear combination (i.e., quantum superposition) of these two states:\nformula_75\nwhere \"a\u03c8\" and \"b\u03c8\" are complex numbers.\nA \"different\" basis for the same Hilbert space is:\nformula_76\ndefined in terms of \"Sx\" rather than \"Sz\".\nAgain, \"any\" state of the particle can be expressed as a linear combination of these two:\nformula_77\nIn vector form, you might write\nformula_78\ndepending on which basis you are using. In other words, the \"coordinates\" of a vector depend on the basis used.\nThere is a mathematical relationship between formula_79, formula_80, formula_81 and formula_82; see change of basis.\nPitfalls and ambiguous uses.\nThere are some conventions and uses of notation that may be confusing or ambiguous for the non-initiated or early student.\nSeparation of inner product and vectors.\nA cause for confusion is that the notation does not separate the inner-product operation from the notation for a (bra) vector. If a (dual space) bra-vector is constructed as a linear combination of other bra-vectors (for instance when expressing it in some basis) the notation creates some ambiguity and hides mathematical details. We can compare bra\u2013ket notation to using bold for vectors, such as formula_83, and formula_14 for the inner product. Consider the following dual space bra-vector in the basis formula_85, where formula_86 are the complex number coefficients of formula_87:\nformula_88\nIt has to be determined by convention if the complex numbers formula_86 are inside or outside of the inner product, and each convention gives different results.\nformula_90\nformula_91\nReuse of symbols.\nIt is common to use the same symbol for \"labels\" and \"constants\". For example, formula_92, where the symbol formula_93 is used simultaneously as the \"name of the operator\" formula_94, its \"eigenvector\" formula_95 and the associated \"eigenvalue\" formula_93. Sometimes the \"hat\" is also dropped for operators, and one can see notation such as formula_97.\nHermitian conjugate of kets.\nIt is common to see the usage formula_98, where the dagger (formula_99) corresponds to the Hermitian conjugate. This is however not correct in a technical sense, since the ket, formula_100, represents a vector in a complex Hilbert-space formula_101, and the bra, formula_102, is a linear functional on vectors in formula_101. In other words, formula_100 is just a vector, while formula_102 is the combination of a vector and an inner product.\nOperations inside bras and kets.\nThis is done for a fast notation of scaling vectors. For instance, if the vector formula_106 is scaled by formula_107, it may be denoted formula_108. This can be ambiguous since formula_93 is simply a label for a state, and not a mathematical object on which operations can be performed. This usage is more common when denoting vectors as tensor products, where part of the labels are moved outside the designed slot, e.g. formula_110.\nLinear operators.\nLinear operators acting on kets.\nA linear operator is a map that inputs a ket and outputs a ket. (In order to be called \"linear\", it is required to have certain properties.) In other words, if formula_111 is a linear operator and formula_100 is a ket-vector, then formula_113 is another ket-vector.\nIn an formula_114-dimensional Hilbert space, we can impose a basis on the space and represent formula_100 in terms of its coordinates as a formula_116 column vector. Using the same basis for formula_111, it is represented by an formula_118 complex matrix. The ket-vector formula_113 can now be computed by matrix multiplication.\nLinear operators are ubiquitous in the theory of quantum mechanics. For example, observable physical quantities are represented by self-adjoint operators, such as energy or momentum, whereas transformative processes are represented by unitary linear operators such as rotation or the progression of time.\nLinear operators acting on bras.\nOperators can also be viewed as acting on bras \"from the right hand side\". Specifically, if A is a linear operator and is a bra, then is another bra defined by the rule\nformula_120\nformula_121\nIn an \"N\"-dimensional Hilbert space, can be written as a 1 \u00d7 \"N\" row vector, and A (as in the previous section) is an \"N\" \u00d7 \"N\" matrix. Then the bra can be computed by normal matrix multiplication.\nIf the same state vector appears on both bra and ket side,\nformula_122\nthen this expression gives the expectation value, or mean or average value, of the observable represented by operator A for the physical system in the state .\nOuter products.\nA convenient way to define linear operators on a Hilbert space is given by the outer product: if is a bra and is a ket, the outer product\nformula_123\ndenotes the rank-one operator with the rule \nformula_124\nFor a finite-dimensional vector space, the outer product can be understood as simple matrix multiplication:\nformula_125\nThe outer product is an \"N\" \u00d7 \"N\" matrix, as expected for a linear operator.\nOne of the uses of the outer product is to construct projection operators. Given a ket of norm 1, the orthogonal projection onto the subspace spanned by is\nformula_126\nThis is an idempotent in the algebra of observables that acts on the Hilbert space.\nHermitian conjugate operator.\nJust as kets and bras can be transformed into each other (making into ), the element from the dual space corresponding to \"A\"|\"\u03c8\"\u27e9 is , where \"A\"\u2020 denotes the Hermitian conjugate (or adjoint) of the operator \"A\". In other words,\nformula_127\nIf \"A\" is expressed as an \"N\" \u00d7 \"N\" matrix, then \"A\"\u2020 is its conjugate transpose.\nProperties.\nBra\u2013ket notation was designed to facilitate the formal manipulation of linear-algebraic expressions. Some of the properties that allow this manipulation are listed herein. In what follows, \"c\"1 and \"c\"2 denote arbitrary complex numbers, \"c\"* denotes the complex conjugate of \"c\", \"A\" and \"B\" denote arbitrary linear operators, and these properties are to hold for any choice of bras and kets.\nAssociativity.\nGiven any expression involving complex numbers, bras, kets, inner products, outer products, and/or linear operators (but not addition), written in bra\u2013ket notation, the parenthetical groupings do not matter (i.e., the associative property holds). For example:\nformula_130\nand so forth. The expressions on the right (with no parentheses whatsoever) are allowed to be written unambiguously \"because\" of the equalities on the left. Note that the associative property does \"not\" hold for expressions that include nonlinear operators, such as the antilinear time reversal operator in physics.\nHermitian conjugation.\nBra\u2013ket notation makes it particularly easy to compute the Hermitian conjugate (also called \"dagger\", and denoted \u2020) of expressions. The formal rules are:\nThese rules are sufficient to formally write the Hermitian conjugate of any such expression; some examples are as follows:\nComposite bras and kets.\nTwo Hilbert spaces \"V\" and \"W\" may form a third space \"V\" \u2297 \"W\" by a tensor product. In quantum mechanics, this is used for describing composite systems. If a system is composed of two subsystems described in \"V\" and \"W\" respectively, then the Hilbert space of the entire system is the tensor product of the two spaces. (The exception to this is if the subsystems are actually identical particles. In that case, the situation is a little more complicated.)\nIf is a ket in \"V\" and is a ket in \"W\", the tensor product of the two kets is a ket in \"V\" \u2297 \"W\". This is written in various notations:\nformula_137\nSee quantum entanglement and the EPR paradox for applications of this product.\nThe unit operator.\nConsider a complete orthonormal system (\"basis\"),\nformula_138\nfor a Hilbert space \"H\", with respect to the norm from an inner product .\nFrom basic functional analysis, it is known that any ket formula_139 can also be written as\nformula_140\nwith the inner product on the Hilbert space.\nFrom the commutativity of kets with (complex) scalars, it follows that\nformula_141\nmust be the \"identity operator\", which sends each vector to itself.\nThis, then, can be inserted in any expression without affecting its value; for example\nformula_142\nwhere, in the last line, the Einstein summation convention has been used to avoid clutter.\nIn quantum mechanics, it often occurs that little or no information about the inner product of two arbitrary (state) kets is present, while it is still possible to say something about the expansion coefficients \u27e8\"\u03c8\"|\"ei\"\u27e9 = \u27e8\"ei\"|\"\u03c8\"\u27e9* and of those vectors with respect to a specific (orthonormalized) basis. In this case, it is particularly useful to insert the unit operator into the bracket one time or more.\nFor more information, see Resolution of the identity,\nformula_143 where formula_144\nSince \u27e8\"x\"\u2032|\"x\"\u27e9 = \"\u03b4\"(\"x\" \u2212 \"x\"\u2032), plane waves follow, formula_145\nIn his book (1958), Ch. III.20, Dirac defines the \"standard ket\" which, up to a normalization, is the translationally invariant momentum eigenstate formula_146 in the momentum representation, i.e., formula_147. Consequently, the corresponding wavefunction is a constant, formula_148, and \nformula_149 as well as formula_150\nTypically, when all matrix elements of an operator such as formula_151 are available, this resolution serves to reconstitute the full operator,\nformula_152\nNotation used by mathematicians.\nThe object physicists are considering when using bra\u2013ket notation is a Hilbert space (a complete inner product space).\nLet formula_153 be a Hilbert space and \"h\" \u2208 H a vector in . What physicists would denote by is the vector itself. That is,\nformula_154\nLet be the dual space of . This is the space of linear functionals on . The embedding formula_155 is defined by formula_156, where for every \"h\" \u2208 H the linear functional formula_157 satisfies for every \"g\" \u2208 H the functional equation formula_158.\nNotational confusion arises when identifying \"\u03c6h\" and \"g\" with and respectively. This is because of literal symbolic substitutions. Let formula_159 and let \"g\" = G = |\"g\"\u27e9. This gives\nformula_160\nOne ignores the parentheses and removes the double bars.\nMoreover, mathematicians usually write the dual entity not at the first place, as the physicists do, but at the second one, and they usually use not an asterisk but an overline (which the physicists reserve for averages and the Dirac spinor adjoint) to denote complex conjugate numbers; i.e., for scalar products mathematicians usually write\nformula_161\nwhereas physicists would write for the same quantity\nformula_162\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "4543", "revid": "3138265", "url": "https://en.wikipedia.org/wiki?curid=4543", "title": "Blue", "text": "Colour between violet and cyan on the visible spectrum of light\nBlue is one of the three primary colours in the RGB (additive) colour model, as well as in the RYB colour model (traditional colour theory). It lies between violet and cyan on the spectrum of visible light. The term \"blue\" generally describes colours perceived by humans observing light with a dominant wavelength between approximately 450 and 495\u00a0nanometres. The clear daytime sky and the deep sea appear blue because of an optical effect known as Rayleigh scattering. An optical effect called the Tyndall effect explains blue eyes. Distant objects appear more blue because of another optical effect called aerial perspective.\nBlue has been an important colour in art and decoration since ancient times. The semi-precious stone lapis lazuli was used in ancient Egypt for jewellery and ornament and later, in the Renaissance, to make the pigment ultramarine, the most expensive of all pigments. In the eighth century Chinese artists used cobalt blue to colour fine blue and white porcelain. In the Middle Ages, European artists used it in the windows of cathedrals. Europeans wore clothing coloured with the vegetable dye woad until it was replaced by the finer indigo from America. In the 19th century, synthetic blue dyes and pigments gradually replaced organic dyes and mineral pigments. Dark blue became a common colour for military uniforms and later, in the late 20th century, for business suits. Because blue has commonly been associated with harmony, it was chosen as the colour of the flags of the United Nations and the European Union.\nIn the United States and Europe, blue is the colour that both men and women are most likely to choose as their favourite, with at least one recent survey showing the same across several other countries, including China, Malaysia, and Indonesia. Past surveys in the US and Europe have found that blue is the colour most commonly associated with harmony, confidence, masculinity, knowledge, intelligence, calmness, distance, infinity, the imagination, cold, and sadness.\nEtymology and linguistics.\nThe modern English word \"blue\" comes from Middle English or , from the Old French , a word of Germanic origin, related to the Old High German word (meaning 'shimmering, lustrous'). In heraldry, the word \"azure\" is used for \"blue\".\nIn Russian, Mongolian, Irish, and some other languages, there is no single word for blue, but rather different words for light blue (Russian: , ) and dark blue (Russian: , ) (see Colour term).\nSeveral languages, including Japanese and Lakota Sioux, use the same word to describe blue and green. For example, in Vietnamese, the colour of both tree leaves and the sky is . In Japanese, the word for blue (, ) is often used for colours that English speakers would refer to as green, such as the colour of a traffic signal meaning \"go\". In Lakota, the word is used for both blue and green, the two colours not being distinguished in older Lakota (for more on this subject, see Blue\u2013green distinction in language).\nLinguistic research indicates that languages do not begin by having a word for the colour blue. Colour names often developed individually in natural languages, typically beginning with black and white (or dark and light), and then adding red, and only much later \u2013 usually as the last main category of colour accepted in a language \u2013 adding the colour blue, probably when blue pigments could be manufactured reliably in the culture using that language.\nOptics and colour theory.\nThe term \"blue\" generally describes colours perceived by humans observing light with a dominant wavelength between approximately 450 and 495\u00a0nanometres. Blues with a higher frequency and thus a shorter wavelength gradually look more violet, while those with a lower frequency and a longer wavelength gradually appear more cyan. Purer blues are in the middle of this range, e.g., around 470\u00a0nanometres.\nIsaac Newton included blue as one of the seven colours in his first description of the visible spectrum. He chose seven colours because that was the number of notes in the musical scale, which he believed was related to the optical spectrum. He included indigo, the hue between blue and violet, as one of the separate colours, though today it would be categorised as blue.\nIn painting and traditional colour theory, blue is one of the three primary colours (red, yellow, blue), which can be mixed to form a wide gamut of colours (although the modern CMY model is able to achieve a much wider gamut). Red and blue mixed together form violet, blue and yellow together form green. Mixing all three primary colours together produces a dark brown. From the Renaissance onward, painters used this system to create their colours (see RYB colour model).\nThe RYB model was used for colour printing by Jacob Christoph Le Blon as early as 1725. Later, printers discovered that more accurate colours could be created by using combinations of cyan, magenta, yellow, and black ink, put onto separate inked plates and then overlaid one at a time onto paper. This method could produce almost all the colours in the spectrum with reasonable accuracy.\nOn the HSV colour wheel, the complement of blue is yellow; that is, a colour corresponding to an equal mixture of red and green light. On a colour wheel based on traditional colour theory (RYB) where blue was considered a primary colour, its complementary colour is considered to be orange.\nLED.\nIn 1993, high-brightness blue LEDs were demonstrated by Shuji Nakamura of Nichia Corporation. In parallel, Isamu Akasaki and Hiroshi Amano of Nagoya University were working on a new development which revolutionised LED lighting.\nNakamura was awarded the 2006 Millennium Technology Prize for his invention.\nNakamura, Hiroshi Amano and Isamu Akasaki were awarded the Nobel Prize in Physics in 2014 for the invention of an efficient blue LED.\nLasers.\nLasers emitting in the blue region of the spectrum became widely available to the public in 2010 with the release of inexpensive high-powered 445\u2013447\u00a0nm laser diode technology. Previously the blue wavelengths were accessible only through DPSS which are comparatively expensive and inefficient, but still widely used by scientists for applications including optogenetics, Raman spectroscopy, and particle image velocimetry, due to their superior beam quality. Blue gas lasers are also still commonly used for holography, DNA sequencing, optical pumping, among other scientific and medical applications.\nShades and variations.\nBlue is the colour of light between violet and cyan on the visible spectrum. Hues of blue include indigo and ultramarine, closer to violet; pure blue, without any mixture of other colours; Azure, which is a lighter shade of blue, similar to the colour of the sky; Cyan, which is midway in the spectrum between blue and green, and the other blue-greens such as turquoise, teal, and aquamarine.\nBlue also varies in shade or tint; darker shades of blue contain black or grey, while lighter tints contain white. Darker shades of blue include ultramarine, cobalt blue, navy blue, and Prussian blue; while lighter tints include sky blue, azure, and Egyptian blue (for a more complete list see the List of colours).\nAs a structural colour.\nIn nature, many blue phenomena arise from structural colouration, the result of interference between reflections from two or more surfaces of thin films, combined with refraction as light enters and exits such films. The geometry then determines that at certain angles, the light reflected from both surfaces interferes constructively, while at other angles, the light interferes destructively. Diverse colours therefore appear despite the absence of colourants.\nColourants.\nArtificial blues.\nEgyptian blue, the first artificial pigment, was produced in the third millennium BC in Ancient Egypt. It is produced by heating pulverised sand, copper, and natron. It was used in tomb paintings and funereal objects to protect the dead in their afterlife. Prior to the 1700s, blue colourants for artwork were mainly based on lapis lazuli and the related mineral ultramarine. A breakthrough occurred in 1709 when German druggist and pigment maker Johann Jacob Diesbach discovered Prussian blue. The new blue arose from experiments involving heating dried blood with iron sulphides and was initially called Berliner Blau. By 1710 it was being used by the French painter Antoine Watteau, and later his successor Nicolas Lancret. It became immensely popular for the manufacture of wallpaper, and in the 19th century was widely used by French impressionist painters. Beginning in the 1820s, Prussian blue was imported into Japan through the port of Nagasaki. It was called \"bero-ai\", or Berlin blue, and it became popular because it did not fade like traditional Japanese blue pigment, \"ai-gami\", made from the dayflower. Prussian blue was used by both Hokusai, in his wave paintings, and Hiroshige.\nIn 1799 a French chemist, Louis Jacques Th\u00e9nard, made a synthetic cobalt blue pigment which became immensely popular with painters.\nIn 1824 the Societ\u00e9 pour l'Encouragement d'Industrie in France offered a prize for the invention of an artificial ultramarine which could rival the natural colour made from lapis lazuli. The prize was won in 1826 by a chemist named Jean Baptiste Guimet, but he refused to reveal the formula of his colour. In 1828, another scientist, Christian Gmelin then a professor of chemistry in T\u00fcbingen, found the process and published his formula. This was the beginning of new industry to manufacture artificial ultramarine, which eventually almost completely replaced the natural product.\nIn 1878 German chemists synthesised indigo. This product rapidly replaced natural indigo, wiping out vast farms growing indigo. It is now the blue of blue jeans. As the pace of organic chemistry accelerated, a succession of synthetic blue dyes were discovered including Indanthrone blue, which had even greater resistance to fading during washing or in the sun, and copper phthalocyanine.\nDyes for textiles and food.\n Woad and true indigo were once used but since the early 1900s, all indigo is synthetic. Produced on an industrial scale, indigo is the blue of blue jeans. Blue dyes are organic compounds, both synthetic and natural.\nFor food, the triarylmethane dye Brilliant blue FCF is used for candies. The search continues for stable, natural blue dyes suitable for the food industry.\nVarious raspberry-flavoured foods are dyed blue. This was done to distinguish strawberry, watermelon and raspberry-flavoured foods. The company ICEE used Blue No. 1 for their blue raspberry ICEEs.\nPigments for painting and glass.\nBlue pigments were once produced from minerals, especially lapis lazuli and its close relative ultramarine. These minerals were crushed, ground into powder, and then mixed with a quick-drying binding agent, such as egg yolk (tempera painting); or with a slow-drying oil, such as linseed oil, for oil painting. Two inorganic but synthetic blue pigments are cerulean blue (primarily cobalt(II) stanate: ) and Prussian blue (milori blue: primarily ). The chromophore in blue glass and glazes is cobalt(II). Diverse cobalt(II) salts such as cobalt carbonate or cobalt(II) aluminate are mixed with the silica prior to firing. The cobalt occupies sites otherwise filled with silicon.\nInks.\nMethyl blue is the dominant blue pigment in inks used in pens. Blueprinting involves the production of Prussian blue in situ.\nInorganic compounds.\nCertain metal ions characteristically form blue solutions or blue salts. Of some practical importance, cobalt is used to make the deep blue glazes and glasses. It substitutes for silicon or aluminium ions in these materials. Cobalt is the blue chromophore in stained glass windows, such as those in Gothic cathedrals and in Chinese porcelain beginning in the Tang dynasty. Copper(II) (Cu2+) also produces many blue compounds, including the commercial algicide copper(II) sulphate (CuSO4.5H2O). Similarly, vanadyl salts and solutions are often blue, e.g. vanadyl sulphate.\nIn nature.\nSky and sea.\nWhen sunlight passes through the atmosphere, the blue wavelengths are scattered more widely by the oxygen and nitrogen molecules, and more blue comes to our eyes. This effect is called Rayleigh scattering, after Lord Rayleigh and confirmed by Albert Einstein in 1911.\nThe sea is seen as blue for largely the same reason: the water absorbs the longer wavelengths of red and reflects and scatters the blue, which comes to the eye of the viewer. The deeper the observer goes, the darker the blue becomes. In the open sea, only about 1% of light penetrates to a depth of 200\u00a0metres (see underwater and euphotic depth).\nThe colour of the sea is also affected by the colour of the sky, reflected by particles in the water; and by algae and plant life in the water, which can make it look green; or by sediment, which can make it look brown.\nThe farther away an object is, the more blue it often appears to the eye. For example, mountains in the distance often appear blue. This is the effect of atmospheric perspective; the farther an object is away from the viewer, the less contrast there is between the object and its background colour, which is usually blue. In a painting where different parts of the composition are blue, green and red, the blue will appear to be more distant, and the red closer to the viewer. The cooler a colour is, the more distant it seems. Blue light is scattered more than other wavelengths by the gases in the atmosphere, hence our \"blue planet\".\nMinerals.\nSome of the most desirable gems are blue, including sapphire and tanzanite. Compounds of copper(II) are characteristically blue and so are many copper-containing minerals.\nAzurite (, with a deep blue colour, was once employed in medieval years, but it is unstable pigment, losing its colour especially under dry conditions. Lapis lazuli, mined in Afghanistan for more than three thousand years, was used for jewellery and ornaments, and later was crushed and powdered and used as a pigment. The more it was ground, the lighter the blue colour became. Natural ultramarine, made by grinding lapis lazuli into a fine powder, was the finest available blue pigment in the Middle Ages and the Renaissance. It was extremely expensive, and in Italian Renaissance art, it was often reserved for the robes of the Virgin Mary.\nPlants and fungi.\nIntense efforts have focused on blue flowers and the possibility that natural blue colourants could be used as food dyes. Commonly, blue colours in plants are anthocyanins: \"the largest group of water-soluble pigments found widespread in the plant kingdom\". In the few plants that exploit structural colouration, brilliant colours are produced by structures within cells. The most brilliant blue colouration known in any living tissue is found in the marble berries of \"Pollia condensata\", where a spiral structure of cellulose fibrils scattering blue light. The fruit of quandong (\"Santalum acuminatum\") can appear blue owing to the same effect.\nAnimals.\nBlue-pigmented animals are relatively rare. Examples of which include butterflies of the genus \"Nessaea\", where blue is created by pterobilin. Other blue pigments of animal origin include phorcabilin, used by other butterflies in \"Graphium\" and \"Papilio\" (specifically \"P. phorcas\" and \"P. weiskei\"), and sarpedobilin, which is used by \"Graphium sarpedon\". Blue-pigmented organelles, known as \"cyanosomes\", exist in the chromatophores of at least two fish species, the mandarin fish and the picturesque dragonet. More commonly, blueness in animals is a structural colouration; an optical interference effect induced by organised nanometre-sized scales or fibres. Examples include the plumage of several birds like the blue jay and indigo bunting, the scales of butterflies like the morpho butterfly, collagen fibres in the skin of some species of monkey and opossum, and the iridophore cells in some fish and frogs.\nEyes.\nBlue eyes do not actually contain any blue pigment. Eye colour is determined by two factors: the pigmentation of the eye's iris and the scattering of light by the turbid medium in the stroma of the iris. In humans, the pigmentation of the iris varies from light brown to black. The appearance of blue, green, and hazel eyes results from the Tyndall scattering of light in the stroma, an optical effect similar to what accounts for the blueness of the sky. The irises of the eyes of people with blue eyes contain less dark melanin than those of people with brown eyes, which means that they absorb less short-wavelength blue light, which is instead reflected out to the viewer. Eye colour also varies depending on the lighting conditions, especially for lighter-coloured eyes.\nBlue eyes are most common in Ireland, the Baltic Sea area and Northern Europe, and are also found in Eastern, Central, and Southern Europe. Blue eyes are also found in parts of Western Asia, most notably in Afghanistan, Syria, Iraq, and Iran. In Estonia, 99% of people have blue eyes. In Denmark in 1978, only 8% of the population had brown eyes, though through immigration, today that number is about 11%. In Germany, about 75% have blue eyes.\nIn the United States, as of 2006, 1 out of every 6 people, or 16.6% of the total population, and 22.3% of the white population, have blue eyes, compared with about half of Americans born in 1900, and a third of Americans born in 1950. Blue eyes are becoming less common among American children. In the US, males are 3\u20135% more likely to have blue eyes than females.\nHistory.\nIn the ancient world.\nAs early as the 7th millennium BC, lapis lazuli was mined in the Sar-i Sang mines, in Shortugai, and in other mines in Badakhshan province in northeast Afghanistan.\nLapis lazuli artefacts, dated to 7570 BC, have been found at Bhirrana, which is the oldest site of Indus Valley civilisation. Lapis was highly valued by the Indus Valley Civilisation (7570\u20131900 BC). Lapis beads have been found at Neolithic burials in Mehrgarh, the Caucasus, and as far away as Mauritania. It was used in the funeral mask of Tutankhamun (1341\u20131323 BC).\nA term for Blue was relatively rare in many forms of ancient art and decoration, and even in ancient literature. The Ancient Greek poets described the sea as green, brown or \"the colour of wine\". The colour is mentioned several times in the Hebrew Bible as 'tekhelet'. Reds, blacks, browns, and ochres are found in cave paintings from the Upper Paleolithic period, but not blue. Blue was also not used for dyeing fabric until long after red, ochre, pink, and purple. This is probably due to the perennial difficulty of making blue dyes and pigments. On the other hand, the rarity of blue pigment made it even more valuable.\nThe earliest known blue dyes were made from plants \u2013 woad in Europe, indigo in Asia and Africa, while blue pigments were made from minerals, usually either lapis lazuli or azurite, and required more. Blue glazes posed still another challenge since the early blue dyes and pigments were not thermally robust. In c.\u20092500 BC, the blue glaze Egyptian blue was introduced for ceramics, as well as many other objects. The Greeks imported indigo dye from India, calling it indikon, and they painted with Egyptian blue. Blue was not one of the four primary colours for Greek painting described by Pliny the Elder (red, yellow, black, and white). For the Romans, blue was the colour of mourning, as well as the colour of barbarians. The Celts and Germans reportedly dyed their faces blue to frighten their enemies, and tinted their hair blue when they grew old. The Romans made extensive use of indigo and Egyptian blue pigment, as evidenced, in part, by frescos in Pompeii.\nThe Romans had many words for varieties of blue, including , , , , , , , and , but two words, both of foreign origin, became the most enduring; , from the Germanic word \"blau\", which eventually became \"bleu\" or blue; and , from the Arabic word , which became azure.\nBlue was widely used in the decoration of churches in the Byzantine Empire. By contrast, in the Islamic world, blue was of secondary to green, believed to be the favourite colour of the Prophet Mohammed. At certain times in Moorish Spain and other parts of the Islamic world, blue was the colour worn by Christians and Jews, because only Muslims were allowed to wear white and green.\nIn the Middle Ages.\nIn the art and life of Europe during the early Middle Ages, blue played a minor role. This changed dramatically between 1130 and 1140 in Paris, when the Abbe Suger rebuilt the Saint Denis Basilica. Suger considered that light was the visible manifestation of the Holy Spirit. He installed stained glass windows coloured with cobalt, which, combined with the light from the red glass, filled the church with a bluish violet light. The church became the marvel of the Christian world, and the colour became known as the . In the years that followed even more elegant blue stained glass windows were installed in other churches, including at Chartres Cathedral and Sainte-Chapelle in Paris.\nIn the 12th century the Roman Catholic Church dictated that painters in Italy (and the rest of Europe consequently) to paint the Virgin Mary with blue, which became associated with holiness, humility and virtue. In medieval paintings, blue was used to attract the attention of the viewer to the Virgin Mary. Paintings of the mythical King Arthur began to show him dressed in blue. The coat of arms of the kings of France became an azure or light blue shield, sprinkled with golden fleur-de-lis or lilies. Blue had come from obscurity to become the royal colour.\nRenaissance through 18th century.\nBlue came into wider use beginning in the Renaissance, when artists began to paint the world with perspective, depth, shadows, and light from a single source. In Renaissance paintings, artists tried to create harmonies between blue and red, lightening the blue with lead white paint and adding shadows and highlights. Raphael was a master of this technique, carefully balancing the reds and the blues so no one colour dominated the picture.\nUltramarine was the most prestigious blue of the Renaissance, being more expensive than gold. Wealthy art patrons commissioned works with the most expensive blues possible. In 1616 Richard Sackville commissioned a portrait of himself by Isaac Oliver with three different blues, including ultramarine pigment for his stockings.\nAn industry for the manufacture of fine blue and white pottery began in the 14th century in Jingdezhen, China, using white Chinese porcelain decorated with patterns of cobalt blue, imported from Persia. It was first made for the family of the Emperor of China, then was exported around the world, with designs for export adapted to European subjects and tastes. The Chinese blue style was also adapted by Dutch craftsmen in Delft and English craftsmen in Staffordshire in the 17th-18th centuries. in the 18th century, blue and white porcelains were produced by Josiah Wedgwood and other British craftsmen.\n19th-20th century.\nThe early 19th century saw the ancestor of the modern blue business suit, created by Beau Brummel (1776\u20131840), who set fashion at the London Court. It also saw the invention of blue jeans, a highly popular form of workers's costume, invented in 1853 by Jacob W. Davis who used metal rivets to strengthen blue denim work clothing in the California gold fields. The invention was funded by San Francisco entrepreneur Levi Strauss, and spread around the world.\nRecognising the emotional power of blue, many artists made it the central element of paintings in the 19th and 20th centuries. They included Pablo Picasso, Pavel Kuznetsov and the Blue Rose art group, and Kandinsky and Der Blaue Reiter (The Blue Rider) school. Henri Matisse expressed deep emotions with blue, \"A certain blue penetrates your soul.\" In the second half of the 20th century, painters of the abstract expressionist movement use blues to inspire ideas and emotions. Painter Mark Rothko observed that colour was \"only an instrument;\" his interest was \"in expressing human emotions tragedy, ecstasy, doom, and so on\".\nIn society and culture.\nUniforms.\nIn the 17th century. The Prince-Elector of Brandenburg, Frederick William I of Prussia, chose Prussian blue as the new colour of Prussian military uniforms, because it was made with Woad, a local crop, rather than Indigo, which was produced by the colonies of Brandenburg's rival, England. It was worn by the German army until World War I, with the exception of the soldiers of Bavaria, who wore sky-blue.\nIn 1748, the Royal Navy adopted a dark shade of blue for the uniform of officers. It was first known as marine blue, now known as navy blue. The militia organised by George Washington selected blue and buff, the colours of the British Whig Party. Blue continued to be the colour of the field uniform of the US Army until 1902, and is still the colour of the dress uniform.\nIn the 19th century, police in the United Kingdom, including the Metropolitan Police and the City of London Police also adopted a navy blue uniform. Similar traditions were embraced in France and Austria. It was also adopted at about the same time for the uniforms of the officers of the New York City Police Department.\nGender.\nBlue is used to represent males. Beginning as a trend the mid-19th century and applying primarily to clothing, gendered associations with blue became more widespread from the 1950s. The colour became associated with males after World War II.\nSports.\nIn sports, blue is widely represented in uniforms in part because the majority of national teams wear the colours of their national flag. For example, the national men's football team of France are known as \"Les Bleus\" (the Blues). Similarly, Argentina, Italy, and Uruguay wear blue shirts. The Asian Football Confederation and the Oceania Football Confederation use blue text on their logos. Blue is well represented in baseball (Blue Jays), basketball, and American football, and Ice hockey. The Indian national cricket team wears blue uniform during One day international matches, as such the team is also referred to as \"Men in Blue\".\nPolitics.\nUnlike red or green, blue was not strongly associated with any particular country, religion or political movement. As the colour of harmony, it was chosen as the colour for the flags of the United Nations, the European Union, and NATO. In politics, blue is often used as the colour of conservative parties, contrasting with the red associated with left-wing parties. Some conservative parties that use the colour blue include the Conservative Party (UK), Conservative Party of Canada, Liberal Party of Australia, Liberal Party of Brazil, and Likud of Israel. However, in some countries, blue is not associated main conservative party. In the United States, the liberal Democratic Party is associated with blue, while the conservative Republican Party is associated with red. US states which have been won by the Democratic Party in four consecutive presidential elections are termed \"blue states\", while those that have been won by the Republican Party are termed \"red states\". South Korea also uses this colour model, with the Democratic Party on the left using blue and the People Power Party on the right using red.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "4544", "revid": "698799", "url": "https://en.wikipedia.org/wiki?curid=4544", "title": "Blind Willie McTell", "text": "Piedmont blues and ragtime singer and guitarist (1898\u20131959)\nBlind Willie McTell (born William Samuel McTier; May 5, 1898 \u2013 August 19, 1959) was an American Piedmont blues and ragtime singer, songwriter and guitarist. He played in a fluid, syncopated finger picking guitar style common among many East Coast, Piedmont blues players. Like his Atlanta contemporaries, he came to use twelve-string guitars exclusively. McTell was also adept at slide guitar, unusual among ragtime bluesmen. He sang in a smooth and often laid-back tenor which differed greatly from the harsher voices of many Delta bluesmen such as Charley Patton. He performed in various musical styles including blues, ragtime, religious music, and hokum and recorded more than 120 titles during fourteen recording sessions.\nHe was born William Samuel McTier in the Happy Valley community outside Thomson, Georgia. In his recordings of \"Lay Some Flowers on My Grave\", \"Lord, Send Me an Angel\" and \"Statesboro Blues\", he pronounces his surname \"MacTell\" with the stress on the first syllable. He learned to play the guitar in his early teens from his mother and from relatives and neighbors in Statesboro where his family had moved. He was a popular performer on the streets of several Georgia cities, including Augusta and Atlanta where he made his first recordings, eight songs, for Victor Records in 1927 including \"Statesboro Blues.\" . He never had a major hit record but he had a prolific recording career with different labels and under different names in the 1920s and '30s. McTell was active in the 1940s and '50s playing at house rent parties, on street corners, at fish fries, on the medicine and tent show circuit, playing on the streets of Atlanta, often with his longtime friend, Curley Weaver as well as hoboing through the South and East. He made his last recordings in 1956 at an impromptu session recorded by an Atlanta record store owner. He died three years later, having lived for years with diabetes and alcoholism. Despite his lack of commercial success, he was one of the few blues musicians of his generation who continued to actively play and record during the 1940s and '50s. He did not live to see the American folk music revival when many other bluesmen were rediscovered.\nBiography.\nMost sources give the date of his birth as 1898 but researchers Bob Eagle and Eric LeBlanc suggest 1903 on the basis of his entry in the 1910 census. McTell was born blind in one eye and lost his remaining vision by late childhood. He attended schools for the blind in Georgia, New York and Michigan and showed proficiency in music from an early age, learning to read and write music in braille, first playing the harmonica and accordion and turning to the six-string guitar in his early teens. His family was rich in music; both of his parents and an uncle played the guitar and he and bluesman and gospel pioneer Thomas A. Dorsey were cousins. \nMcTell's father left the family when Willie was young. After his mother died, in the 1920s, he left his hometown and became an itinerant songster. Like Lead Belly, another songster who began his career on the streets, McTell favored the twelve-string guitar whose greater volume made it suitable for outdoor playing. In the years before World War II, McTell traveled and performed widely, recording for several labels under different names: Blind Willie McTell for Victor and Decca, Blind Sammie for Columbia, Georgia Bill for Okeh, Hot Shot Willie for Victor, Blind Willie for Vocalion and Bluebird, Barrelhouse Sammie for Atlantic, and Pig &amp; Whistle Red for Regal Records. The name \"Pig &amp; Whistle\" was a reference to a chain of barbecue restaurants in Atlanta; McTell often played for tips in the parking lot of a Pig 'n Whistle restaurant. He also played behind a nearby building that later became Ray Lee's Blue Lantern Lounge. \nMcTell married Ruth Kate Williams, now better known as Kate McTell, in 1934. She accompanied him on stage and on several recordings before becoming a nurse in 1939. For most of their marriage, from 1942 until his death, they lived apart, she in Fort Gordon, near Augusta, and he working around Atlanta.\nIn 1940, John Lomax, a Classics professor at the University of Texas at Austin and his wife, Ruby Terrill Lomax, interviewed and recorded McTell for the Archive of American Folk Song of the Library of Congress in a two-hour session held in their hotel room in Atlanta. These recordings captured McTell's distinctive musical style which bridges the gap between the country blues of the early part of the 20th century and the more conventionally melodious, ragtime-influenced East Coast, Piedmont blues sound. The Lomaxes also elicited from him traditional songs (such as \"The Boll Weevil\" and \"John Henry\") and spirituals (such as \"Amazing Grace\"), which were not part of his usual repertoire. In the interview, John Lomax is heard asking if McTell knows any \"complaining\" songs (an earlier term for protest songs), to which he replies somewhat uncomfortably and evasively that he does not. The Library of Congress paid McTell $10, the equivalent of $154.56 in 2011, for this two-hour session. The material from this 1940 session was issued in 1960 as an LP and later as a CD under the somewhat misleading title \"The Complete Library of Congress Recordings\" notwithstanding the fact that it omitted some of Lomax's interactions showing kindness to him and entirely omitting the contributions of Ruby Terrill Lomax.\nAhmet Ertegun visited Atlanta in 1949 in search of blues artists for this new Atlantic Records label and after finding McTell playing on the street, arranged a recording session. Some of the songs were released on 78 rpm discs but sold poorly. The complete session was released in 1972 as \"Atlanta Twelve-String\". McTell recorded for Regal Records in 1949 but these recordings also met with less commercial success than his previous works. He continued to perform around Atlanta but his career was cut short by ill health, mostly due to diabetes and alcoholism. In 1956, an Atlanta record store owner, Edward Rhodes, discovered McTell playing in the street for quarters and enticed him into his store with a bottle of bourbon where he captured 13 songs on a tape recorder which Prestige Records/Bluesville Records posthumously released as his \"Last Session\". From 1957 to 1959, McTell was a preacher at Mt. Zion Baptist Church in Atlanta.\nBlind Willie McTell died of a stroke in Milledgeville, Georgia, in 1959, at the age of 61. He was buried at Jones Grove Church, near Thomson, Georgia, his birthplace. Author David Fulmer, who in 1992 was working on \"Blind Willie's Blues\", a documentary about McTell, arranged to have a blue marble gravestone erected on his resting place. McTell was inducted into the Blues Foundation's Blues Hall of Fame in 1981 and the Georgia Music Hall of Fame in 1990.\nInfluence.\n McTell's influence extended over a wide variety of artists. His most famous song, \"Statesboro Blues\" was adapted by Taj Mahal with Jesse Ed Davis on slide guitar, then covered and frequently performed by the Allman Brothers Band. It also shows up on Canned Heat's \"Goin' Up the Country\" album. A short list of some of the artists who have performed the song includes David Bromberg, Dave Van Ronk, The Devil Makes Three, Chris Smither and Ralph McTell, who changed his name because he liked the song. Ry Cooder covered McTell's \"Married Man's a Fool\" on his 1973 album, \"Paradise and Lunch\". Jack White, of the White Stripes, considers McTell an influence; the White Stripes album \"De Stijl\" (2000) is dedicated to him and features a cover of his song \"Southern Can Is Mine\". The White Stripes also covered McTell's \"Lord, Send Me an Angel\", releasing it as a single in 2000. In 2013, Jack White's Third Man Records teamed up with Document Records to issue \"The Complete Recorded Works in Chronological Order of Charley Patton, Blind Willie McTell and the Mississippi Sheiks\".\nBob Dylan paid tribute to McTell on at least four occasions. In his 1965 song \"Highway 61 Revisited\", the second verse begins, \"Georgia Sam, he had a bloody nose\", an allusion to one of McTell's many recording names (Note: there is no evidence that he used this name on any recordings). Dylan's song \"Blind Willie McTell\" was recorded in 1983 and released in 1991 on \"The Bootleg Series Volumes 1-3\". Dylan also recorded covers of McTell's \"Broke Down Engine\" and \"Delia\" on his 1993 album, \"World Gone Wrong\"; Dylan's song \"Po' Boy\", on the album \"Love and Theft\" (2001), contains the lyric \"had to go to Florida dodging them Georgia laws\", which comes from McTell's \"Kill It Kid\".\nThe Bath-based band Kill It Kid is named after the song of the same title.\nA billiards bar and concert venue in Statesboro, Georgia, was named Blind Willie's in the 1990s. The venue is now closed but remains a fond memory for Georgia Southern University students at the time.\nAnother Blind Willie's bar in the Virginia-Highlands neighborhood of Atlanta named after McTell that features blues musicians and bands. The Blind Willie McTell Blues Festival is held annually in Thomson, Georgia.\nIn 1996, the novelist and former music journalist David Fulmer released \"Blind Willie's Blues\", a 53-minute documentary about McTell\u2019s life, times, and music, with interviews with African-American history professor Daphne Duval Harrison, blues musician Taj Mahal, guitarist Stefan Grossman, Atlantic Records founder Ahmet Ertegun, McTell's former brother-in-law Rev. A.J. Williams, and Edward Rhodes, who produced McTell's \"Last Sessions\" recording. In late 2023, the film was remastered by the Southeastern Folklife Collection at Valdosta State University and is currently streaming on YouTube.\nFootnotes.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
