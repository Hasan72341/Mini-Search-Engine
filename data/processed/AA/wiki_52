{"id": "5726", "revid": "7903804", "url": "https://en.wikipedia.org/wiki?curid=5726", "title": "Crane shot", "text": "Cinematic shot taken with a camera mounted on a moving crane\nIn filmmaking and video production, a crane shot is a shot taken by a camera on a moving crane or jib. Filmmaker D. W. Griffith created the first crane for his 1916 epic film \"Intolerance\", with famed special effects pioneer Eiji Tsuburaya later constructing the first iron camera crane which is still adapted worldwide today. Most cranes accommodate both the camera and an operator, but some can be moved by remote control. Crane shots are often found in what are supposed to be emotional or suspenseful scenes. One example of this technique is the shots taken by remote cranes in the car-chase sequence of the 1985 film \"To Live and Die in L.A\". Some filmmakers place the camera on a boom arm simply to make it easier to move around between ordinary set-ups.\nHistory.\nD. W. Griffith designed the first camera crane for his 1916 epic film \"Intolerance\". His crane measured 140 feet tall and ascended on six four-wheeled railroad trucks. In 1929, future special effects pioneer Eiji Tsuburaya constructed a smaller replica of Griffith's wooden camera crane without blueprints or manuals. Although his wooden crane collapsed shortly after its completion, Tsuburaya created the first-ever iron shooting crane in October 1934, and an adaptation of this crane is still used worldwide today.\nCamera crane types.\nCamera cranes may be small, medium, or large, depending on the load capacity and length of the loading arm. Historically, the first camera crane provided for lifting the camera together with the operator, and sometimes an assistant. The range of motion of the boom was restricted because of the high load capacity and the need to ensure operator safety. In recent years a camera crane boom tripod with a remote control has become popular. It carries on the boom only a movie or television camera without an operator and allows shooting from difficult positions as a small load capacity makes it possible to achieve a long reach of the crane boom and relative freedom of movement. The operator controls the camera from the ground through a motorized panoramic head, using remote control and video surveillance by watching the image on the monitor. A separate category consists of telescopic camera cranes. These devices allow setting an arbitrary trajectory of the camera, eliminating the characteristic jib crane radial displacement that comes with traditional spanning shots.\nLarge camera cranes are almost indistinguishable from the usual boom-type cranes, with the exception of special equipment for smoothly moving the boom and controlling noise. Small camera cranes and crane-trucks have a lightweight construction, often without a mechanical drive. The valves are controlled manually by balancing the load-specific counterweight, facilitating manipulation. To improve usability and repeatability of movement of the crane in different takes, the axis of rotation arrows are provided with limbs and a pointer. In some cases, the camera crane is mounted on a dolly for even greater camera mobility. Such devices are called crane trolleys. In modern films robotic cranes allow use of multiple actuators for high-accuracy repeated movement of the camera in trick photography. These devices are called tap-robots; some sources use the term motion control.\nManufacturers.\nThe major supplier of cranes in the cinema of the United States throughout the 1940s, 1950s, and 1960s was the Chapman Company (later Chapman-Leonard of North Hollywood), supplanted by dozens of similar manufacturers around the world. The traditional design provided seats for both the director and the camera operator, and sometimes a third seat for the cinematographer as well. Large weights on the back of the crane compensate for the weight of the people riding the crane and must be adjusted carefully to avoid the possibility of accidents. During the 1960s, the tallest crane was the Chapman Titan crane, a massive design over 20 feet high that won an Academy Scientific &amp; Engineering award. \nDuring the last few years, camera cranes have been miniaturized and costs have dropped so dramatically that most aspiring film makers have access to these tools. What was once a \"Hollywood\" effect is now available for under $400. Manufacturers of camera cranes include ABC-Products, Cambo, Filmotechnic, Polecam, Panther and Matthews Studio Equipment, Sevenoak, and Newton Nordic.\nCamera crane technique.\nMost such cranes were manually operated, requiring an experienced boom operator who knew how to vertically raise, lower, and \"crab\" the camera alongside actors while the crane platform rolled on separate tracks. The crane operator and camera operator had to precisely coordinate their moves so that focus, pan, and camera position all started and stopped at the same time, requiring great skill and rehearsal. On the back of the crane is a counter weight. This allows the crane to smooth action while in motion with minimal effort.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "5729", "revid": "33565674", "url": "https://en.wikipedia.org/wiki?curid=5729", "title": "Chariots of Fire", "text": "1981 film by Hugh Hudson\nChariots of Fire is a 1981 historical sports drama film directed by Hugh Hudson, written by Colin Welland and produced by David Puttnam. It is based on the true story of two British athletes in the 1924 Olympics: Eric Liddell, a devout Scottish Christian who runs for the glory of God, and Harold Abrahams, an English Jew who runs to overcome prejudice. Ian Charleson and Ben Cross star as Liddell and Abrahams respectively, alongside Nigel Havers, Ian Holm, John Gielgud, Lindsay Anderson, Cheryl Campbell, Alice Krige, Brad Davis and Dennis Christopher in supporting roles. Kenneth Branagh and Stephen Fry make their debuts in minor roles.\n\"Chariots of Fire\" was nominated for seven Academy Awards and won four, including Best Picture, Best Original Screenplay and Best Original Score for Vangelis's electronic theme tune. At the 35th British Academy Film Awards, the film was nominated in 11 categories and won in three, including Best Film. It is ranked 19th in the British Film Institute's list of Top 100 British films. The film won the People's Choice Award at the 6th Toronto International Film Festival.\nThe film's title was inspired by the line \"Bring me my Chariot of fire!\" from the William Blake poem adapted into the British hymn and unofficial English anthem \"Jerusalem\"; the hymn is heard at the end of the film.\nPlot.\nDuring a 1978 funeral service in London in honour of the life of Harold Abrahams, presided over by his former colleague Lord Andrew Lindsay, there is a flashback to his youth, when he was running along a beach with a group of athletes.\nIn 1919, Harold Abrahams enters the University of Cambridge, where he experiences antisemitism but enjoys participating in the Gilbert and Sullivan club. He becomes the first person to complete the Trinity Great Court Run, running around the college courtyard in the time it takes for the clock to strike 12, and achieves victories in various national running competitions. Although focused on his running, he falls in love with Sybil Gordon, a leading Gilbert and Sullivan soprano.\nEric Liddell, born in China to Scottish missionary parents, is in Scotland. His devout sister Jennie disapproves of Liddell's plans to pursue competitive running. Liddell sees running as a way of glorifying God before returning to China to work as a missionary. When they first race against each other, Liddell beats Abrahams. Abrahams takes it poorly, but Sam Mussabini, a professional trainer he had approached earlier, offers to take him on to improve his technique. This attracts criticism from the Cambridge college masters, who assert that it is not gentlemanly for an amateur to \"play the tradesman\" by employing a professional coach. Abrahams dismisses this concern, interpreting it as cover for antisemitic and class-based prejudice. When Liddell accidentally misses a church prayer meeting because of his running, Jennie upbraids him and accuses him of no longer caring about God. Eric tells her that, though he intends to return eventually to the China mission, he feels divinely inspired when he runs and that not to run would be to dishonour God.\nAfter years of training and racing, the two athletes are accepted to represent Great Britain in the 1924 Olympics in Paris. Also accepted are Abrahams's Cambridge friends, Andrew Lindsay, Aubrey Montague, and Henry Stallard. While boarding the boat to France for the Olympics, Liddell learns the his 100-metre heats will be on a Sunday. Despite intense pressure from the Prince of Wales and the British Olympic Committee, he refuses to run the race on the Lord's Day. A solution is found thanks to Liddell's teammate Lindsay, who, having already won a silver medal in the 400 metres hurdles, offers his place in the 400-metre race on the following Thursday to Liddell. Liddell's religious convictions in the face of national athletic pride make headlines around the world; he delivers a sermon at the Paris Church of Scotland that Sunday.\nAbrahams is badly beaten by the heavily favoured United States runners in the 200-metre race. He knows his last chance for a medal will be the 100 metres. He competes in the race and wins. His coach Mussabini, who was barred from the stadium, is overcome that the years' dedication and training have paid off. Now Abrahams can get on with his life and reunite with his girlfriend Sybil, whom he has neglected for the sake of running. Liddell defeats the American favourites in the 400-metre race and wins the gold medal. The British team returns home triumphant.\nA textual epilogue reveals that Abrahams married Sybil and became a leading figure in British athletics, while Liddell went on to do missionary work and was mourned by all of Scotland after his death in Japanese-occupied China.\nCast.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;* Ben Cross as Harold Abrahams, a Jewish student at Cambridge University\nOther actors in smaller roles include John Young as Eric and Jennie's father Reverend J.D. Liddell, Yvonne Gilan as their mother Mary Liddell, Benny Young as their older brother Rob Liddell, Yves Beneyton as French runner G\u00e9o Andr\u00e9, Philip O'Brien as American coach George Collins, Stephen Mallatratt as Tom Watson, Patrick Doyle as Jimmie and Ruby Wax as Bunty. Kenneth Branagh, who worked as a set gofer, appears as an extra in the Cambridge Society Day sequence. Stephen Fry has a likewise uncredited role as a Gilbert-and-Sullivan Club singer.\nProduction.\nScreenplay.\nProducer David Puttnam was looking for a story in the mould of \"A Man for All Seasons\" (1966), regarding someone who follows his conscience, and felt that sport provided clear situations in this sense. He discovered Eric Liddell's story by accident in 1977, when he happened upon \"An Approved History of the Olympic Games\", a reference book on the Olympics, while housebound from the flu, in a rented house in Malibu.\nScreenwriter Colin Welland, commissioned by Puttnam, did an enormous amount of research for his Academy Award-winning script. Among other things, he took out advertisements in London newspapers seeking memories of the 1924 Olympics, went to the National Film Archives for pictures and footage of the 1924 Olympics, and interviewed everyone involved who was still alive. Welland just missed Harold Abrahams, who died on 14 January 1978, but he did attend Abrahams' February 1978 memorial service, which inspired the present-day framing device of the film. Aubrey Montague's son Andy saw Welland's newspaper ad and sent him copies of the letters his father had sent home \u2013 which gave Welland something to use as a narrative bridge in the film. Except for changes in the greetings of the letters from \"Darling Mummy\" to \"Dear Mum\" and the change from Oxford to Cambridge, all of the readings from Montague's letters are from the originals.\nWelland's original script also featured, in addition to Eric Liddell and Harold Abrahams, a third protagonist, 1924 Olympic gold medallist Douglas Lowe, who was presented as a privileged aristocratic athlete. However, Lowe refused to have anything to do with the film, and his character was written out and replaced by the fictional character of Lord Andrew Lindsay.\nInitial financing towards development costs was provided by Goldcrest Films, who then sold the project to Mohamed Al-Fayed's Allied Stars, but kept a percentage of the profits.\nIan Charleson wrote Eric Liddell's speech to the post-race workingmen's crowd at the Scotland v. Ireland races. Charleson, who had studied the Bible intensively in preparation for the role, told director Hugh Hudson that he didn't feel the portentous and sanctimonious scripted speech was either authentic or inspiring. Hudson and Welland allowed him to write words he personally found inspirational instead.\nPuttnam chose Hugh Hudson, a multiple award-winning advertising and documentary filmmaker who had never helmed a feature film, to direct \"Chariots of Fire\". Hudson and Puttnam had known each other since the 1960s when Puttnam was an advertising executive and Hudson was making films for ad agencies. In 1977, Hudson had also been second-unit director on the Puttnam-produced film \"Midnight Express\".\nCasting.\nDirector Hugh Hudson was determined to cast young, unknown actors in all the major roles of the film, and to back them up by using veterans like John Gielgud, Lindsay Anderson and Ian Holm as their supporting cast. Hudson and producer David Puttnam did months of fruitless searching for the perfect actor to play Eric Liddell. They then saw Scottish stage actor Ian Charleson performing the role of Pierre in the Royal Shakespeare Company's production of \"Piaf\", and knew immediately they had found their man. Unbeknownst to them, Charleson had heard about the film from his father, and desperately wanted to play the part, feeling it would \"fit like a kid glove\".\nBen Cross, who plays Harold Abrahams, was discovered while playing Billy Flynn in \"Chicago\". In addition to having a natural pugnaciousness, he had the desired ability to sing and play the piano. Cross was thrilled to be cast, and said he was moved to tears by the film's script.\n20th Century-Fox, which put up half of the production budget in exchange for distribution rights outside of North America, insisted on having a couple of notable American names in the cast. Thus the small parts of the two American champion runners, Jackson Scholz and Charley Paddock, were cast with recent headliners: Brad Davis had recently starred in \"Midnight Express\" (also produced by Puttnam) and Dennis Christopher had recently starred, as young bicycle racer Dave Stohler, in the popular indie film \"Breaking Away\".\nAll of the actors portraying runners underwent an intensive three-month training regimen with renowned running coach Tom McNab. This training and isolation of the actors also created a strong bond and sense of camaraderie among them.\nFilming.\nThe beach scenes showing the athletes running towards the Carlton Hotel at Broadstairs, Kent, were shot in Scotland on West Sands, St Andrews next to the 18th hole of the Old Course at St Andrews Links. A plaque now commemorates the filming. The impact of these scenes (as the athletes run in slow motion to Vangelis' music) prompted Broadstairs town council to commemorate them with a seafront plaque.\nAll of the indoor Cambridge scenes were actually filmed at Hugh Hudson's alma mater Eton College, because Cambridge refused filming rights, fearing depictions of anti-Semitism. The Cambridge administration greatly regretted the decision after the film's enormous success.\nLiverpool Town Hall was the setting for the scenes depicting the British Embassy in Paris. The Colombes Olympic Stadium in Paris was represented by the Oval Sports Centre, Bebington, Merseyside. The nearby Woodside ferry terminal was used to represent the embarkation scenes set in Dover. The railway station scenes were filmed in York, using locomotives from the National Railway Museum. The filming of the Scotland\u2013France international athletic meeting took place at Goldenacre Sports Ground in Edinburgh, owned by George Heriot's School, while the Scotland\u2013Ireland meeting was at the nearby Inverleith Sports Ground. The scene depicting a performance of \"The Mikado\" was filmed in the Royal Court Theatre, Liverpool, with members of the D'Oyly Carte Opera Company who were on tour.\nEditing.\nThe film was slightly altered for the U.S. audience. A brief scene depicting a pre-Olympics cricket game between Abrahams, Liddell, Montague (Nicholas Farrell), and the rest of the British track team appears shortly after the beginning of the original film. For the American audience, this scene was deleted. In the U.S., to avoid the initial G rating, which had been strongly associated with children's films and might have hindered box office sales, a different scene was used \u2013 one depicting Abrahams and Montague arriving at a Cambridge railway station and encountering two First World War veterans who use an obscenity \u2013 in order to be given a PG rating. An off-camera retort of, \"Win it for Israel\" among exhortations of fellow students of Abrahams before he takes on the challenge of The Great Court Run was absent from the final cuts theatrically distributed in the U.S. However, they can be heard in versions broadcast on such cable outlets as TCM.\nSoundtrack.\nAlthough the film is a period piece set in the 1920s, the Academy Award-winning original soundtrack composed by Vangelis (credited as Vangelis Papathanassiou) uses a contemporary 1980s electronic sound, with a strong use of synthesizer and piano among other instruments. This was a departure from earlier period films, which employed sweeping orchestral instrumentals. The title theme of the film has been used in subsequent films and television shows during slow-motion segments.\nVangelis, a Greek-born electronic composer who moved to Paris in the late 1960s, had been living in London since 1974. Director Hugh Hudson had collaborated with him on documentaries and commercials, and was also particularly impressed with his 1979 albums \"Op\u00e9ra sauvage\" and \"China\". David Puttnam also greatly admired Vangelis's body of work, having originally selected his compositions for his previous film \"Midnight Express\". Hudson made the choice for Vangelis and for a modern score: \"I knew we needed a piece which was anachronistic to the period to give it a feel of modernity. It was a risky idea but we went with it rather than have a period symphonic score.\" The soundtrack had a personal significance to Vangelis: after composing the theme he told Puttnam, \"My father is a runner, and this is an anthem to him.\"\nHudson originally wanted Vangelis's 1977 tune \"L'Enfant\", from his \"Opera Sauvage\" album, to be the title theme of the film, and the beach running sequence was actually filmed with \"L'Enfant\" playing on loudspeakers for the runners to pace to. Vangelis finally convinced Hudson he could create a new and better piece for the film's main theme \u2013 and when he played the \"Chariots of Fire\" theme for Hudson, it was agreed the new tune was unquestionably better. The \"L'Enfant\" melody still made it into the film: when the athletes reach Paris and enter the stadium, a brass band marches through the field, and first plays a modified, acoustic performance of the piece. Vangelis's electronic \"L'Enfant\" track eventually was used prominently in the 1982 film \"The Year of Living Dangerously\".\nSome pieces of Vangelis's music in the film did not end up on the film's soundtrack album. One of them is the background music to the race Eric Liddell runs in the Scottish highlands. This piece is a version of \"Hymne\", the original version of which appears on Vangelis's 1979 album, \"Op\u00e9ra sauvage\". Various versions are also included on Vangelis's compilation albums \"Themes\", \"Portraits\", and \"\", though none of these include the version used in the film.\nFive lively Gilbert and Sullivan tunes also appear in the soundtrack, and serve as jaunty period music which counterpoints Vangelis's modern electronic score. These are: \"He is an Englishman\" from \"H.M.S. Pinafore\", \"Three Little Maids From School Are We\" from \"The Mikado\", \"With Catlike Tread\" from \"The Pirates of Penzance\", \"The Soldiers of Our Queen\" from \"Patience\", and \"There Lived a King\" from \"The Gondoliers\".\nThe film also incorporates a major traditional work: \"Jerusalem\", sung by a British choir at the 1978 funeral of Harold Abrahams. The words, written by William Blake in 1804\u201308, were set to music by Hubert Parry in 1916 as a celebration of England. This hymn has been described as \"England's unofficial national anthem\", concludes the film and inspired its title. A handful of other traditional anthems and hymns and period-appropriate instrumental ballroom-dance music round out the film's soundtrack.\nRelease.\nThe film was distributed by 20th Century-Fox and selected for the 1981 Royal Film Performance with its premiere on 30 March 1981 at the Odeon Haymarket before opening to the public the following day. It opened in Edinburgh on 4 April and in Oxford and Cambridge on 5 April with other openings in Manchester and Liverpool before expanding further in May into 20 additional London cinemas and 11 others nationally. It was shown in competition at the 1981 Cannes Film Festival on 20 May.\nThe film was distributed by The Ladd Company through Warner Bros. in North America and released on 25 September 1981 in Los Angeles, California and in the New York Film Festival, on 26 September 1981 in New York and on 9 April 1982 in the United States.\nIn October 2025, the film was screened as part of a tribute to David Puttnam at the 20th Rome Film Festival.\nReception.\nSince its release, \"Chariots of Fire\" has received generally positive reviews from critics. As of 2024[ [update]], the film holds an 84% rating from the review aggregator website Rotten Tomatoes, based on 117 reviews, with a weighted average of 7.8/10. The site's consensus reads: \"Decidedly slower and less limber than the Olympic runners at the center of its story, \"Chariots of Fire\" nevertheless manages to make effectively stirring use of its spiritual and patriotic themes.\" On Metacritic, the film has a score of 78 out of 100 based on 19 critics' reviews.\nFor its 2012 re-release, Kate Muir of \"The Times\" gave the film five stars, writing: \"In a time when drug tests and synthetic fibres have replaced gumption and moral fibre, the tale of two runners competing against each other in the 1924 Olympics has a simple, undiminished power. From the opening scene of pale young men racing barefoot along the beach, full of hope and elation, backed by Vangelis's now famous anthem, the film is utterly compelling.\"\nIn its first four weeks at the Odeon Haymarket it grossed \u00a3106,484. The film was the highest-grossing British film for the year with theatrical rentals of \u00a31,859,480. Its gross of almost $59 million in the United States and Canada made it the highest-grossing film import into the US (i.e. a film without any US input) at the time, surpassing \"Meatballs\"' $43 million.\nThe film was included by the Vatican in a list of important films compiled in 1995, under the category of \"Values\".\nIn 2024, filmmaker Christopher Nolan cited it as one of his favorite films and as one of the sources of inspiration for his film \"Dunkirk\" (2017).\nAwards and nominations.\nThe film was nominated for seven Academy Awards, winning four (including Best Picture). When accepting his Oscar for Best Original Screenplay, Colin Welland famously announced \"The British are coming\". It was the first film released by Warner Bros. to win Best Picture since \"My Fair Lady\" in 1964.\nAmerican Film Institute recognition\nOther honours\nHistorical accuracy.\n\"Chariots of Fire\" is a film about achieving victory through self sacrifice and moral courage. While the producers' intent was to make a cinematic work that was historically authentic, the film was not intended to be historically accurate. Numerous liberties were taken with the actual historical chronology, the inclusion and exclusion of notable people, and the creation of fictional scenes for dramatic purpose, plot pacing and exposition.\nCharacters.\nThe film depicts Abrahams as attending Gonville and Caius College, Cambridge, with three other Olympic athletes: Henry Stallard (Daniel Gerroll), Aubrey Montague, and Lord Andrew Lindsay (Nigel Havers). However, whereas Abrahams and Stallard were indeed students there, Montague attended Oxford and not Cambridge. Aubrey Montague sent daily letters to his mother about his time at Oxford and the Olympics; these letters were the basis of Montague's narration in the film.\nThe character of Lindsay was based partially on David Cecil (Lord Burghley), a significant figure in the history of British athletics. Although Burghley did attend Cambridge, he was not a contemporary of Harold Abrahams, as Abrahams was an undergraduate from 1919 to 1923 and Burghley was at Cambridge from 1923 to 1927. One scene in the film depicts the Burghley-based \"Lindsay\" as practising hurdles on his estate with full champagne glasses placed on each hurdle \u2013 this was something the wealthy Burghley did, although he used matchboxes instead of champagne glasses. Burghley was not willing to be involved in the film and the fictional character of Lindsay was created when Douglas Lowe, who was Britain's third athletics gold medallist in the 1924 Olympics, also declined.\nAnother scene in the film recreates the Great Court Run, in which the runners attempt to run around the perimeter of the Great Court at Trinity College, Cambridge in the time it takes the clock to strike 12 at midday. The film shows Abrahams performing the feat for the first time in history. In fact, Abrahams never attempted this race, and at the time of filming the only person on record known to have succeeded was Lord Burghley, in 1927. In \"Chariots of Fire\", Lindsay, who is based on Lord Burghley, runs the Great Court Run with Abrahams in order to spur him on, and crosses the finish line just a moment too late. Since the film's release, the Great Court Run has also been successfully run by Trinity undergraduate Sam Dobin, in October 2007.\nIn the film, Eric Liddell is tripped up by a Frenchman in the 400-metre event of a Scotland\u2013France international athletic meeting. He recovers, makes up a 20-metre deficit, and wins. This was based on fact; the actual race was the 440 yards at a Triangular Contest meet between Scotland, England, and Ireland at Stoke-on-Trent in England in July 1923. His achievement was remarkable as he had already won the 100- and 220-yard events that day. Also unmentioned with regard to Liddell is that it was he who introduced Abrahams to Sam Mussabini. This is alluded to: in the film, Abrahams first encounters Mussabini (Ian Holm) while he is watching Liddell race.\nAbrahams and Liddell did race against each other twice, but not as depicted in the film, which shows Liddell winning the final of the 100 yards against a shattered Abrahams at the 1923 AAA Championship at Stamford Bridge. In fact, they raced only in a heat of the 220 yards, which Liddell won, five yards ahead of Abrahams, who did not progress to the final. In the 100 yards, Abrahams was eliminated in the heats and did not race against Liddell, who won the finals of both races the next day. They also raced against each other in the 200 m final at the 1924 Olympics, and this was also not shown in the film.\nAbrahams' fianc\u00e9e is misidentified as Sybil Gordon (Alice Krige), a soprano with the D'Oyly Carte Opera Company. In fact, in 1936, Abrahams married Sybil Evers, who also performed with D'Oyly Carte, but they did not meet until 1934. Also, in the film, Sybil is depicted as singing the role of Yum-Yum in \"The Mikado\", but neither Gordon nor Evers ever sang that role with D'Oyly Carte, although Evers was known for her charm in singing Peep-Bo, one of the two other \"little maids from school\". Harold Abrahams' love of and heavy involvement with Gilbert and Sullivan, as depicted in the film, is factual.\nLiddell's sister Jennie (Cheryl Campbell) was several years younger than she was portrayed in the film. Her disapproval of Liddell's track career was creative licence; she actually fully supported his sporting work. Jenny Liddell Somerville cooperated fully with the making of the film and has a brief cameo in the Paris Church of Scotland during Liddell's sermon.\nAt the memorial service for Harold Abrahams, which opens the film, Lord Lindsay mentions that he and Aubrey Montague are the only members of the 1924 Olympic team still alive. However, Montague died in 1948, 30 years before Abrahams' death.\nParis Olympics 1924.\nIn the film, the 100m bronze medallist is a character called Tom Watson (Stephen Mallatratt); the real medallist was Arthur Porritt of New Zealand, who refused permission for his name to be used in the film, allegedly out of modesty, and his wish was accepted by the film's producers, even though his permission was not necessary. However, the brief back-story given for Watson, who is called up to the New Zealand team from the University of Oxford, substantially matches Porritt's history. With the exception of Porritt, all the runners in the 100m final are identified correctly when they line up for inspection by the Prince of Wales.\nJackson Scholz is depicted as handing Liddell an inspirational Bible-quotation message before the 400 metres final: \"It says in the Old Book, 'He that honors me, I will honor.' Good luck.\" In reality, the note was from members of the British team, and was handed to Liddell before the race by his attending masseur at the team's Paris hotel. For dramatic purposes, screenwriter Welland asked Scholz if he could be depicted handing the note, and Scholz readily agreed, saying \"Yes, great, as long as it makes me look good.\"\nThe events surrounding Liddell's refusal to race on a Sunday were changed for dramatic purposes. In the film, he does not learn that the 100-metre heat is to be held on the Christian Sabbath until he is boarding the boat to Paris. In fact, the schedule was made public several months in advance; Liddell did, however, face immense pressure to run on that Sunday and to compete in the 100 metres, and was called before a grilling by the British Olympic Committee, the Prince of Wales, and other grandees; his refusal to run made headlines around the world.\nThe decision to change races was, even so, made well before embarking to Paris, and Liddell spent the intervening months training for the 400 metres, an event in which his times were modest by international standards. Liddell's success in the Olympic 400m was thus largely unexpected.\nThe film depicts Lindsay, having already won a medal in the 400-metre hurdles, giving up his place in the 400-metre race for Liddell. In fact, Burghley, on whom Lindsay is loosely based, was eliminated in the heats of the 110 hurdles (he went on to win a gold medal in the 400-metre hurdles at the 1928 Olympics), and was not entered for the 400 metres.\nThe film reverses the order of Abrahams' 100m and 200m races at the Olympics. In reality, after winning the 100 metres race, Abrahams ran the 200 metres but finished last, Jackson Scholz taking the gold medal. In the film, before his triumph in the 100m, Abrahams is shown losing the 200m and being scolded by Mussabini. During the following scene in which Abrahams speaks with his friend Montague while receiving a massage from Mussabini, a French newspaper clipping shows Scholz and Charley Paddock with a headline stating that the 200 metres was a triumph for the United States. In the same conversation, Abrahams laments getting \"beaten out of sight\" in the 200. The film thus has Abrahams overcoming the disappointment of losing the 200 by going on to win the 100, a reversal of the real order.\nEric Liddell actually also ran in the 200m race, and finished third, behind Paddock and Scholz. This was the only time in reality that Liddell and Abrahams competed in the same finals race. While their meeting in the 1923 AAA Championship in the film was fictitious, Liddell's record win in that race did spur Abrahams to train even harder.\nAbrahams also won a silver medal as an opening runner for the 4 x 100 metres relay team, not shown in the film, and Aubrey Montague placed sixth in the steeplechase, as depicted.\nLondon Olympics' 2012 revival.\n\"Chariots of Fire\" became a recurring theme in promotions for the 2012 Summer Olympics in London. The film's theme was featured at the opening of the 2012 London New Year's fireworks celebrating the Olympics. The runners who first tested the new Olympic Park were spurred on by the \"Chariots of Fire\" theme, and the music was also used as a fanfare for the carriers of the Olympic flame on parts of its route through the UK. The beach-running sequence was also recreated at St Andrews and filmed as part of the Olympic torch relay.\nThe film's theme was also performed by the London Symphony Orchestra, conducted by Simon Rattle, during the Opening Ceremony of the games; the performance was accompanied by a comedy skit by Rowan Atkinson (as Mr. Bean) which included the opening beach-running footage from the film. The film's theme was again played during each medal ceremony of the 2012 Olympics (including, ironically, those events held on Sunday).\nAs an official part of the London 2012 Festival celebrations, a new digitally re-mastered version of the film screened in 150 cinemas throughout the UK. The re-release began 13 July 2012, two weeks before the opening ceremony of the London Olympics.\nA Blu-ray of the film was released on 10 July 2012 in North America, and was released 16 July 2012 in the UK. The release includes nearly an hour of special features, a CD sampler, and a 32-page \"digibook\".\nStage adaptation.\nA stage adaptation of \"Chariots of Fire\" was mounted in honour of the 2012 Olympics. The play, \"Chariots of Fire\", which was adapted by playwright Mike Bartlett and included the Vangelis score, ran from 9 May to 16 June 2012 at London's Hampstead Theatre, and transferred to the Gielgud Theatre in the West End on 23 June, where it ran until 5 January 2013. It starred Jack Lowden as Eric Liddell and James McArdle as Harold Abrahams, and Edward Hall directed. Stage designer Miriam Buether transformed each theatre into an Olympic stadium, and composer Jason Carr wrote additional music. Vangelis also created several new pieces of music for the production.\nThe stage version for the London Olympic year was the idea of the film's director, Hugh Hudson, who co-produced the play; he stated, \"Issues of faith, of refusal to compromise, standing up for one's beliefs, achieving something for the sake of it, with passion, and not just for fame or financial gain, are even more vital today.\"\nAnother play, \"Running for Glory\", written by Philip Dart, based on the 1924 Olympics, and focusing on Abrahams and Liddell, toured parts of Britain from 25 February to 1 April 2012. It starred Nicholas Jacobs as Harold Abrahams and Tom Micklem as Eric Liddell.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "5731", "revid": "45789152", "url": "https://en.wikipedia.org/wiki?curid=5731", "title": "Capitalist", "text": ""}
{"id": "5734", "revid": "50340963", "url": "https://en.wikipedia.org/wiki?curid=5734", "title": "Consequentialism", "text": "Ethical theory based on consequences\nIn moral philosophy, consequentialism is a class of normative, teleological ethical theories that holds that the consequences of one's conduct are the ultimate basis for judgement about the rightness or wrongness of that conduct. Thus, from a consequentialist standpoint, a morally right act (including omission from acting) is one that will produce a good outcome. Consequentialism, along with eudaimonism, falls under the broader category of teleological ethics, a group of views which claim that the moral value of any act consists in its tendency to produce things of intrinsic value. Consequentialists hold in general that an act is right \"if and only if\" the act (or in some views, the rule under which it falls) will produce, will probably produce, or is intended to produce, a greater balance of good over evil than any available alternative. Different consequentialist theories differ in how they define moral goods, with chief candidates including pleasure, the absence of pain, the satisfaction of one's preferences, and broader notions of the \"general good\".\nConsequentialism is usually contrasted with deontological ethics (or deontology): deontology, in which rules and moral duty are central, derives the rightness or wrongness of one's conduct from the character of the behaviour itself, rather than the outcomes of the conduct. It is also contrasted with both virtue ethics, which is concerned with the character of the agent rather than on the nature or consequences of the act (or omission) itself, and pragmatic ethics, which treats morality like science: advancing collectively as a society over the course of many lifetimes, such that any moral criterion is subject to revision.\nSome argue that consequentialist theories (such as utilitarianism) and deontological theories (such as Kantian ethics) are not necessarily mutually exclusive. For example, T. M. Scanlon advances the idea that human rights, which are commonly considered to be deontological in nature, can only be justified with reference to the consequences of having those rights. Similarly, Robert Nozick argued for a theory that is mostly consequentialist, but incorporates inviolable \"side-constraints\" which restrict the sort of actions agents are permitted to do. Derek Parfit argued that, in practice, when understood properly, rule consequentialism, Kantian deontology, and contractualism would all end up prescribing the same behavior.\nEtymology.\nThe term \"consequentialism\" was coined by G. E. M. Anscombe in her essay \"Modern Moral Philosophy\" in 1958. However, the meaning of the word has changed over the time since Anscombe used it: in the sense she coined it, she had explicitly placed J. S. Mill in the nonconsequentialist and W. D. Ross in the consequentialist camp, whereas, in the contemporary sense of the word, they would be classified the other way round. This is due to changes in the meaning of the word, not due to changes in perceptions of W.D. Ross's and J.S. Mill's views.\nClassification.\nOne common view is to classify consequentialism, together with virtue ethics, under a broader label of \"teleological ethics\". Proponents of teleological ethics (Greek: \"telos\", 'end, purpose' and \"logos\", 'science') argue that the moral value of any act consists in its tendency to produce things of intrinsic value, meaning that an act is right \"if and only if\" it, or the rule under which it falls, produces, will probably produce, or is intended to produce, a greater balance of good over evil than any alternative act. This concept is exemplified by the famous aphorism, \"the end justifies the means,\" variously attributed to Machiavelli or Ovid i.e. if a goal is morally important enough, any method of achieving it is acceptable.\nTeleological ethical theories are contrasted with deontological ethical theories, which hold that acts themselves are \"inherently\" good or bad, rather than good or bad because of extrinsic factors (such as the act's consequences or the moral character of the person who acts).\nForms of consequentialism.\nUtilitarianism.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Nature has placed mankind under the governance of two sovereign masters, pain and pleasure. It is for them alone to point out what we ought to do, as well as to determine what we shall do. On the one hand the standard of right and wrong, on the other the chain of causes and effects, are fastened to their throne. They govern us in all we do, in all we say, in all we think...\u2014\u200a\nIn summary, Jeremy Bentham states that people are driven by their interests and their fears, but their interests take precedence over their fears; their interests are carried out in accordance with how people view the consequences that might be involved with their interests. \"Happiness\", in this account, is defined as the maximization of pleasure and the minimization of pain. It can be argued that the existence of phenomenal consciousness and \"qualia\" is required for the experience of pleasure or pain to have an ethical significance.\nHistorically, \"hedonistic utilitarianism\" is the paradigmatic example of a consequentialist moral theory. This form of utilitarianism holds that what matters is to aggregate happiness; the happiness of everyone, and not the happiness of any particular person. John Stuart Mill, in his exposition of hedonistic utilitarianism, proposed a hierarchy of pleasures, meaning that the pursuit of certain kinds of pleasure is more highly valued than the pursuit of other pleasures. However, some contemporary utilitarians, such as Peter Singer, are concerned with maximizing the satisfaction of preferences, hence \"preference utilitarianism\". Other contemporary forms of utilitarianism mirror the forms of consequentialism outlined below.\nRule consequentialism.\nIn general, consequentialist theories focus on actions. However, this need not be the case. Rule consequentialism is a theory that is sometimes seen as an attempt to reconcile consequentialism with deontology, or rules-based ethics\u2014and in some cases, this is stated as a criticism of rule consequentialism. Like deontology, rule consequentialism holds that moral behavior involves following certain rules. However, rule consequentialism chooses rules based on the consequences that the selection of those rules has. Rule consequentialism exists in the forms of rule utilitarianism and rule egoism.\nVarious theorists are split as to whether the rules are the only determinant of moral behavior or not. For example, Robert Nozick held that a certain set of minimal rules, which he calls \"side-constraints,\" are necessary to ensure appropriate actions. There are also differences as to how absolute these moral rules are. Thus, while Nozick's side-constraints are absolute restrictions on behavior, Amartya Sen proposes a theory that recognizes the importance of certain rules, but these rules are not absolute. That is, they may be violated if strict adherence to the rule would lead to much more undesirable consequences.\nOne of the most common objections to rule-consequentialism is that it is incoherent, because it is based on the consequentialist principle that what we should be concerned with is maximizing the good, but then it tells us not to act to maximize the good, but to follow rules (even in cases where we know that breaking the rule could produce better results).\nIn \"Ideal Code, Real World\", Brad Hooker avoids this objection by not basing his form of rule-consequentialism on the ideal of maximizing the good. He writes:\n[T]he best argument for rule-consequentialism is not that it derives from an overarching commitment to maximise the good. The best argument for rule-consequentialism is that it does a better job than its rivals of matching and tying together our moral convictions, as well as offering us help with our moral disagreements and uncertainties.\nDerek Parfit described Hooker's book as the \"best statement and defence, so far, of one of the most important moral theories.\"\nState consequentialism.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Mozi, \"Mozi\" (5th century BC) (Chapter 8: Against Music Part I)\n\"State consequentialism\", also known as \"Mohist consequentialism\", is an ethical theory that evaluates the moral worth of an action based on how much it contributes to the welfare of a state. According to the \"Stanford Encyclopedia of Philosophy\", Mohist consequentialism, dating back to the 5th century BCE, is the \"world's earliest form of consequentialism, a remarkably sophisticated version based on a plurality of intrinsic goods taken as constitutive of human welfare.\"\nUnlike utilitarianism, which views utility as the sole moral good, \"the basic goods in Mohist consequentialist thinking are...order, material wealth, and increase in population.\" The word \"order\" refers to Mozi's stance against warfare and violence, which he viewed as pointless and a threat to social stability; \"material wealth\" of Mohist consequentialism refers to basic needs, like shelter and clothing; and \"increase in population\" relates to the time of Mozi, war and famine were common, and population growth was seen as a moral necessity for a harmonious society. In \"The Cambridge History of Ancient China\", Stanford sinologist David Shepherd Nivison writes that the moral goods of Mohism \"are interrelated: more basic wealth, then more reproduction; more people, then more production and wealth...if people have plenty, they would be good, filial, kind, and so on unproblematically.\"\nThe Mohists believed that morality is based on \"promoting the benefit of all under heaven and eliminating harm to all under heaven.\" In contrast to Jeremy Bentham's views, state consequentialism is not utilitarian because it is not hedonistic or individualistic. The importance of outcomes that are good for the community outweigh the importance of individual pleasure and pain. The term \"state consequentialism\" has also been applied to the political philosophy of the Confucian philosopher Xunzi. On the other hand, \"legalist\" Han Fei \"is motivated almost totally from the ruler's point of view.\"\nEthical egoism.\nEthical egoism can be understood as a consequentialist theory according to which the consequences for the individual agent are taken to matter more than any other result. Thus, egoism will prescribe actions that may be beneficial, detrimental, or neutral to the welfare of others. Some, like Henry Sidgwick, argue that a certain degree of egoism \"promotes\" the general welfare of society for two reasons: because individuals know how to please themselves best, and because if everyone were an austere altruist then general welfare would inevitably decrease.\nTwo-level consequentialism.\nThe two-level approach involves engaging in critical reasoning and considering all the possible ramifications of one's actions before making an ethical decision, but reverting to generally reliable moral rules when one is not in a position to stand back and examine the dilemma as a whole. In practice, this equates to adhering to rule consequentialism when one can only reason on an intuitive level, and to act consequentialism when in a position to stand back and reason on a more critical level.\nThis position can be described as a reconciliation between \"act consequentialism\"\u2014in which the morality of an action is determined by that action's effects\u2014and \"rule consequentialism\"\u2014in which moral behavior is derived from following rules that lead to positive outcomes.\nThe two-level approach to consequentialism is most often associated with R. M. Hare and Peter Singer.\nMotive consequentialism.\nAnother consequentialist application view is motive consequentialism, which looks at whether the state of affairs that results from the motive to choose an action is better or at least as good as each alternative state of affairs that would have resulted from alternative actions. This version gives relevance to the motive of an act and links it to its consequences. An act can therefore not be wrong if the decision to act was based on a right motive. A possible inference is that one can not be blamed for mistaken judgments if the motivation was to do good.\nIssues.\nAction guidance.\nOne important characteristic of many normative moral theories such as consequentialism is the ability to produce practical moral judgements. At the very least, any moral theory needs to define the standpoint from which the goodness of the consequences are to be determined. What is primarily at stake here is the \"responsibility\" of the agent.\nThe ideal observer.\nOne common tactic among consequentialists, particularly those committed to an altruistic (selfless) account of consequentialism, is to employ an ideal, neutral observer from which moral judgements can be made. John Rawls, a critic of utilitarianism, argues that utilitarianism, in common with other forms of consequentialism, relies on the perspective of such an ideal observer. The particular characteristics of this ideal observer can vary from an omniscient observer, who would grasp all the consequences of any action, to an ideally informed observer, who knows as much as could reasonably be expected, but not necessarily all the circumstances or all the possible consequences. Consequentialist theories that adopt this paradigm hold that right action is the action that will bring about the best consequences from this ideal observer's perspective.\nThe real observer.\nIn practice, it is very difficult, and at times arguably impossible, to adopt the point of view of an ideal observer. Individual moral agents do not know everything about their particular situations, and thus do not know all the possible consequences of their potential actions. For this reason, some theorists have argued that consequentialist theories can only require agents to choose the best action in line with what they know about the situation. However, if this approach is na\u00efvely adopted, then moral agents who, for example, recklessly fail to reflect on their situation, and act in a way that brings about terrible results, could be said to be acting in a morally justifiable way. Acting in a situation without first informing oneself of the circumstances of the situation can lead to even the most well-intended actions yielding miserable consequences. As a result, it could be argued that there is a moral imperative for agents to inform themselves as much as possible about a situation before judging the appropriate course of action. This imperative, of course, is derived from consequential thinking: a better-informed agent is able to bring about better consequences.\nActs and omissions.\nSince pure consequentialism holds that an action is to be judged solely by its result, most consequentialist theories hold that a deliberate action is no different from a deliberate decision not to act. This contrasts with the \"acts and omissions doctrine\", which is upheld by some medical ethicists and some religions: it asserts there is a significant moral distinction between acts and deliberate non-actions which lead to the same outcome. This contrast is brought out in issues such as voluntary euthanasia.\nActualism and possibilism.\nThe normative status of an action depends on its consequences according to consequentialism. The consequences of the actions of an agent may include other actions by this agent. Actualism and possibilism disagree on how later possible actions impact the normative status of the current action by the same agent. Actualists assert that it is only relevant what the agent \"would\" actually do later for assessing the value of an alternative. Possibilists, on the other hand, hold that we should also take into account what the agent \"could\" do, even if she would not do it.\nFor example, assume that Gifre has the choice between two alternatives, eating a cookie or not eating anything. Having eaten the first cookie, Gifre could stop eating cookies, which is the best alternative. But after having tasted one cookie, Gifre would freely decide to continue eating cookies until the whole bag is finished, which would result in a terrible stomach ache and would be the worst alternative. Not eating any cookies at all, on the other hand, would be the second-best alternative. Now the question is: should Gifre eat the first cookie or not? Actualists are only concerned with the actual consequences. According to them, Gifre should not eat any cookies at all since it is better than the alternative leading to a stomach ache. Possibilists, however, contend that the best possible course of action involves eating the first cookie and this is therefore what Gifre should do.\nOne counterintuitive consequence of actualism is that agents can avoid moral obligations simply by having an imperfect moral character. For example, a lazy person might justify rejecting a request to help a friend by arguing that, due to her lazy character, she would not have done the work anyway, even if she had accepted the request. By rejecting the offer right away, she managed at least not to waste anyone's time. Actualists might even consider her behavior praiseworthy since she did what, according to actualism, she ought to have done. This seems to be a very easy way to \"get off the hook\" that is avoided by possibilism. But possibilism has to face the objection that in some cases it sanctions and even recommends what actually leads to the worst outcome.\nDouglas W. Portmore has suggested that these and other problems of actualism and possibilism can be avoided by constraining what counts as a genuine alternative for the agent. On his view, it is a requirement that the agent has rational control over the event in question. For example, eating only one cookie and stopping afterward only is an option for Gifre if she has the rational capacity to repress her temptation to continue eating. If the temptation is irrepressible then this course of action is not considered to be an option and is therefore not relevant when assessing what the best alternative is. Portmore suggests that, given this adjustment, we should prefer a view very closely associated with \"possibilism\" called \"maximalism\".\nConsequences for whom.\nMoral action always has consequences for certain people or things. Varieties of consequentialism can be differentiated by the beneficiary of the good consequences. That is, one might ask \"Consequences for whom?\"\nAgent-focused or agent-neutral.\nA fundamental distinction can be drawn between theories which require that agents act for ends perhaps disconnected from their own interests and drives, and theories which permit that agents act for ends in which they have some personal interest or motivation. These are called \"agent-neutral\" and \"agent-focused\" theories respectively.\nAgent-neutral consequentialism ignores the specific value a state of affairs has for any particular agent. Thus, in an agent-neutral theory, an actor's personal goals do not count any more than anyone else's goals in evaluating what action the actor should take. Agent-focused consequentialism, on the other hand, focuses on the particular needs of the moral agent. Thus, in an agent-focused account, such as one that Peter Railton outlines, the agent might be concerned with the general welfare, but the agent is \"more\" concerned with the immediate welfare of herself and her friends and family.\nThese two approaches could be reconciled by acknowledging the tension between an agent's interests as an individual and as a member of various groups, and seeking to somehow optimize among all of these interests. For example, it may be meaningful to speak of an action as being good for someone as an individual, but bad for them as a citizen of their town.\nNon-humans.\nMany consequentialist theories may seem primarily concerned with human beings and their relationships with other human beings. However, some philosophers argue that we should not limit our ethical consideration to the interests of human beings alone. Jeremy Bentham, who is regarded as the founder of utilitarianism, argues that animals can experience pleasure and pain, thus demanding that 'non-human animals' should be a serious object of moral concern.\nMore recently, Peter Singer has argued that it is unreasonable that we do not give equal consideration to the interests of animals as to those of human beings when we choose the way we are to treat them. Such equal consideration does not necessarily imply identical treatment of humans and non-humans, any more than it necessarily implies identical treatment of all humans.\nValue of consequences.\nOne way to divide various consequentialisms is by the types of consequences that are taken to matter most, that is, which consequences count as good states of affairs. According to utilitarianism, a good action is one that results in an increase in pleasure, and the best action is one that results in the most pleasure for the greatest number. Closely related is eudaimonic consequentialism, according to which a full, flourishing life, which may or may not be the same as enjoying a great deal of pleasure, is the ultimate aim. Similarly, one might adopt an aesthetic consequentialism, in which the ultimate aim is to produce beauty. However, one might fix on non-psychological goods as the relevant effect. Thus, one might pursue an increase in material equality or political liberty instead of something like the more ephemeral \"pleasure\". Other theories adopt a package of several goods, all to be promoted equally. As the consequentialist approach contains an inherent assumption that the outcomes of a moral decision can be quantified in terms of \"goodness\" or \"badness,\" or at least put in order of increasing preference, it is an especially suited moral theory for a probabilistic and decision theoretical approach.\nCriticisms.\nG. E. M. Anscombe objects to the consequentialism of Sidgwick on the grounds that the moral worth of an action is premised on the predictive capabilities of the individual, relieving them of the responsibility for the \"badness\" of an act should they \"make out a case for not having foreseen\" negative consequences.\nImmanuel Kant makes a similar argument against consequentialism in the case of the inquiring murder. The example asks whether or not it would be right to give false statement to an inquiring murderer in order to misdirect the individual away from the intended victim. He argues, in On a Supposed Right to Tell Lies from Benevolent Motives, that lying from \"benevolent motives,\" here the motive to maximize the good consequences by protecting the intended victim, should then make the liar responsible for the consequences of the act. For example, it could be that by misdirecting the inquiring murder away from where one thought the intended victim was actually directed the murder to the intended victim. That such an act is immoral mirrors Anscombe's objection to Sidgwick that his consequentialism would problematically absolve the consequentalist of moral responsibility when the consequentalist fails to foresee the true consequences of an act.\nThe future amplification of the effects of small decisions is an important factor that makes it more difficult to predict the ethical value of consequences, even though most would agree that only predictable consequences are charged with a moral responsibility.\nBernard Williams has argued that consequentialism is alienating because it requires moral agents to put too much distance between themselves and their own projects and commitments. Williams argues that consequentialism requires moral agents to take a strictly impersonal view of all actions, since it is only the consequences, and not who produces them, that are said to matter. Williams argues that this demands too much of moral agents\u2014since (he claims) consequentialism demands that they be willing to sacrifice any and all personal projects and commitments in any given circumstance in order to pursue the most beneficent course of action possible. He argues further that consequentialism fails to make sense of intuitions that it can matter whether or not someone is personally the author of a particular consequence. For example, that participating in a crime can matter, even if the crime would have been committed anyway, or would even have been worse, without the agent's participation.\nSome consequentialists\u2014most notably Peter Railton\u2014have attempted to develop a form of consequentialism that acknowledges and avoids the objections raised by Williams. Railton argues that Williams's criticisms can be avoided by adopting a form of consequentialism in which moral decisions are to be determined by the sort of life that they express. On his account, the agent should choose the sort of life that will, on the whole, produce the best overall effects.\nNotable consequentialists.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "5735", "revid": "1794611", "url": "https://en.wikipedia.org/wiki?curid=5735", "title": "Conscription", "text": "Compulsory enrollment into national or military service\nConscription, also known as the draft in American English, is the practice in which the compulsory enlistment in a national service, mainly a military service, is enforced by law. Conscription dates back to antiquity and it continues in some countries to the present day under various names. The modern system of near-universal national conscription for young men dates to the French Revolution in the 1790s, where it became the basis of a very large and powerful military. Most European nations later copied the system in peacetime, so that men at a certain age would serve 1 to 8 years on active duty and then transfer to the reserve force. In the early 2000, Norway and Sweden became the first nations to conscript women on the same legal terms as men. Denmark has committed to implement a similar system shortly.\nConscription is controversial for a range of reasons, including conscientious objection to military engagements on religious or philosophical grounds; political objection, for example to service for a disliked government or unpopular war; sexism, in that historically only men have been subject to the draft; and ideological objection, for example, to a perceived violation of individual rights. Those conscripted may evade service, sometimes by leaving the country, and seeking asylum in another country. Some selection systems accommodate these attitudes by providing alternative service outside combat-operations roles or even outside the military, such as (alternative civil service) in Finland and (compulsory community service) in Austria and Switzerland. Several countries conscript male soldiers not only for armed forces, but also for paramilitary agencies, which are dedicated to police-like \"domestic-only\" service like internal troops, border guards or \"non-combat\" rescue duties like civil defence.\nAs of 2025, many states no longer conscript their citizens, relying instead upon professional militaries with volunteers. The ability to rely on such an arrangement, however, presupposes some degree of predictability with regard to both war-fighting requirements and the scope of hostilities. Many states that have abolished conscription still, therefore, reserve the power to resume conscription during wartime or times of crisis. States involved in wars or interstate rivalries are most likely to implement conscription, and democracies are less likely than autocracies to implement conscription. With a few exceptions, such as Singapore and Egypt, former British colonies are less likely to have conscription, as they are influenced by British anti-conscription norms that can be traced back to the English Civil War; the United Kingdom abolished conscription in 1960. Conscription in the United States has not been enforced since 1973. Conscription was ended in most European countries during, or shortly after, the Cold war period, with the system still being in force in Scandinavian countries, Finland, Switzerland, Austria, Greece, Cyprus, Turkey and several countries of the former Eastern Bloc.\nHistory.\nIn pre-modern times.\nIlkum.\nAround the reign of Hammurabi (1791\u20131750 BC), the Babylonian Empire used a system of conscription called \"Ilkum\". Under that system those eligible were required to serve in the royal army in time of war. During times of peace they were instead required to provide labour for other activities of the state. In return for this service, people subject to it gained the right to hold land. It is possible that this right was not to hold land \"per se\" but specific land supplied by the state.\nVarious forms of avoiding military service are recorded. While it was outlawed by the Code of Hammurabi, the hiring of substitutes appears to have been practiced both before and after the creation of the code. Later records show that Ilkum commitments could become regularly traded. In other places, people simply left their towns to avoid their Ilkum service. Another option was to sell Ilkum lands and the commitments along with them. With the exception of a few exempted classes, this was forbidden by the Code of Hammurabi.\nRoman Dilectus.\nSee Early Roman army.\nMedieval period.\nMedieval levies.\nUnder the feudal laws on the European continent, landowners in the medieval period enforced a system whereby all peasants, freemen commoners and noblemen aged 15 to 60 living in the countryside or in urban centers, were summoned for military duty when required by either the king or the local lord, bringing along the weapons and armor according to their wealth. These levies fought as footmen, sergeants, and men at arms under local superiors appointed by the king or the local lord such as the arri\u00e8re-ban in France. Arri\u00e8re-ban denoted a general levy, where all able-bodied males age 15 to 60 living in the Kingdom of France were summoned to go to war by the King (or the constable and the marshals). Men were summoned by the bailiff (or the s\u00e9n\u00e9chal in the south). Bailiffs were military and political administrators installed by the King to steward and govern a specific area of a province following the king's commands and orders. The men summoned in this way were then summoned by the lieutenant who was the King's representative and military governor over an entire province comprising many bailiwicks, seneschalties and castellanies. All men from the richest noble to the poorest commoner were summoned under the arri\u00e8re-ban and they were supposed to present themselves to the King or his officials.\nIn medieval Scandinavia the \"lei\u00f0angr\" (Old Norse), \"leidang\" (Norwegian), \"leding\", (Danish), \"ledung\" (Swedish), \"lichting\" (Dutch), \"expeditio\" (Latin) or sometimes \"le\u00feing\" (Old English), was a levy of free farmers conscripted into coastal fleets for seasonal excursions and in defence of the realm.\nThe bulk of the Anglo-Saxon English army, called the \"fyrd\", was composed of part-time English soldiers drawn from the freemen of each county. In the 690s laws of Ine of Wessex, three levels of fines are imposed on different social classes for neglecting military service.\nSome modern writers claim military service in Europe was restricted to the landowning minor nobility. These thegns were the land-holding aristocracy of the time and were required to serve with their own armour and weapons for a certain number of days each year. The historian David Sturdy has cautioned about regarding the \"fyrd\" as a precursor to a modern national army composed of all ranks of society, describing it as a \"ridiculous fantasy\":\nThe persistent old belief that peasants and small farmers gathered to form a national army or \"fyrd\" is a strange delusion dreamt up by antiquarians in the late eighteenth or early nineteenth centuries to justify universal military conscription.\nIn feudal Japan the shogun decree of 1393 exempted money lenders from religious or military levies, in return for a yearly tax. The \u014cnin War weakened the shogun and levies were imposed again on money lenders. This overlordism was arbitrary and unpredictable for commoners. While the money lenders were not poor, several overlords tapped them for income. Levies became necessary for the survival of the overlord, allowing the lord to impose taxes at will. These levies included \"tansen\" tax on agricultural land for ceremonial expenses. Y\"akubu takumai\" tax was raised on all land to rebuild the Ise Grand Shrine, and \"munabechisen\" tax was imposed on all houses. At the time, land in Kyoto was acquired by commoners through usury and in 1422 the shogun threatened to repossess the land of those commoners who failed to pay their levies.\nMilitary slavery.\nThe system of military slaves was widely used in the Middle East, beginning with the creation of the corps of Turkic slave-soldiers (\"ghulams\" or \"mamluks\") by the Abbasid caliph al-Mu'tasim in the 820s and 830s. The Mamluks (; (singular), , \"mam\u0101l\u012bk\" (plural); translated as \"one who is owned\", meaning \"slave\") were non-Arab, ethnically diverse (mostly Turkic, Caucasian, Eastern and Southeastern European) enslaved mercenaries, slave-soldiers, and freed slaves who were assigned high-ranking military and administrative duties, serving the ruling Arab and Ottoman dynasties in the Muslim world. The most enduring Mamluk realm was the knightly military class in medieval Egypt, which developed from the ranks of slave-soldiers. Originally the Mamluks were slaves of Turkic origins from the Eurasian Steppe, but the institution of military slavery spread to include Circassians, Abkhazians, Georgians, Armenians, Russians, and Hungarians, as well as peoples from the Balkans such as Albanians, Greeks, and South Slavs (\"see\" Saqaliba). They also recruited from the Egyptians. The \"Mamluk/\u00adGhulam Phe\u00adnom\u00adenon\", as David Ayalon dubbed the creation of the specific warrior class, was of great political importance; for one thing, it endured for nearly 1,000 years, from the 9th century to the early 19th century.\nOver time, Mamluks became a powerful military knightly class in various Muslim societies that were controlled by dynastic Arab rulers. Particularly in Egypt and Syria, but also in the Ottoman Empire, Levant, Mesopotamia, and India, mamluks held political and military power. In some cases, they attained the rank of sultan, while in others they held regional power as \"emirs\" or \"beys\". Most notably, Mamluk factions seized the sultanate centered on Egypt and Syria, and controlled it as the Mamluk Sultanate (1250\u20131517). The Mamluk Sultanate famously defeated the Ilkhanate at the Battle of Ain Jalut. They had earlier fought the western European Christian Crusaders in 1154\u20131169 and 1213\u20131221, effectively driving them out of Egypt and the Levant. In 1302 the Mamluk Sultanate formally expelled the last Crusaders from the Levant, ending the era of the Crusades. While Mamluks were purchased as property, their status was above ordinary slaves, who were not allowed to carry weapons or perform certain tasks. In places such as Egypt, from the Ayyubid dynasty to the time of Muhammad Ali of Egypt, mamluks were considered to be \"true lords\" and \"true warriors\", with social status above the general population in Egypt and the Levant. In a sense, they were like enslaved mercenaries.\nIn the middle of the 14th century, Ottoman sultan Murad I developed personal troops to be loyal to him, with a slave army called the \"Kap\u0131kulu\". The first units in the Janissary Corps were formed from prisoners of war and slaves, probably as a result of the sultan taking his traditional one-fifth share of his army's plunder in kind rather than monetarily; however, the continuing exploitation and enslavement of \"dhimmi\" peoples (i.e., non-Muslims), predominantly Balkan Christians, constituted a continuing abuse of subject populations. For a while, the Ottoman government supplied the Janissary Corps with recruits from the \"dev\u015firme\" system of child levy enslavement. Children were drafted at a young age and soon turned into slave-soldiers in an attempt to make them loyal to the Ottoman sultan. The social status of \"dev\u015firme\" recruits took on an immediate positive change, acquiring a greater guarantee of governmental rights and financial opportunities. In poor areas officials were bribed by parents to make them take their sons, thus they would have better chances in life. Initially, the Ottoman recruiters favoured Greeks and Albanians. The Ottoman Empire began its expansion into Europe by invading the European portions of the Byzantine Empire in the 14th and 15th centuries up until the capture of Constantinople in 1453, establishing Islam as the state religion of the newly founded empire. The Ottoman Turks further expanded into Southeastern Europe and consolidated their political power by invading and conquering huge portions of the Serbian Empire, Bulgarian Empire, and the remaining territories of the Byzantine Empire in the 14th and 15th centuries. As borders of the Ottoman Empire expanded, the \"dev\u015firme\" system of child levy enslavement was extended to include Armenians, Bulgarians, Croats, Hungarians, Serbs, and later Bosniaks, and, in rare instances, Romanians, Georgians, Circassians, Ukrainians, Poles, and southern Russians. A number of distinguished military commanders of the Ottomans, and most of the imperial administrators and upper-level officials of the Empire, such as Pargal\u0131 \u0130brahim Pasha and Sokollu Mehmet Pa\u015fa, were recruited in this way. By 1609, the Sultan's \"Kap\u0131kulu\" forces increased to about 100,000.\nThe slave trade in the Ottoman Empire supplied the ranks of the Ottoman army between the 15th and 19th centuries. They were useful in preventing both the slave rebellions and the breakup of the Empire itself, especially due to the rising tide of nationalism among European peoples in its Balkan provinces from the 17th century onwards. Along with the Balkans, the Black Sea Region remained a significant source of high-value slaves for the Ottomans. Throughout the 16th to 19th centuries, the Barbary States sent pirates to raid nearby parts of Europe in order to capture Christian slaves to sell at slave markets in the Muslim world, primarily in North Africa and the Ottoman Empire, throughout the Renaissance and early modern period. According to historian Robert Davis, from the 16th to 19th centuries, Barbary pirates captured 1 million to 1.25 million Europeans as slaves, although these numbers are disputed. These slaves were captured mainly from the crews of captured vessels, from coastal villages in Spain and Portugal, and from farther places like the Italian Peninsula, France, or England, the Netherlands, Ireland, the Azores Islands, and even Iceland. For a long time, until the early 18th century, the Crimean Khanate maintained a massive slave trade with the Ottoman Empire and the Middle East. The Crimean Tatars frequently mounted raids into the Danubian Principalities, Poland\u2013Lithuania, and Russia to enslave people whom they could capture.\nApart from the effect of a lengthy period under Ottoman domination, many of the subject populations were periodically and forcefully converted to Islam as a result of a deliberate move by the Ottoman Turks as part of a policy of ensuring the loyalty of the population against a potential Venetian invasion. However, Islam was spread by force in the areas under the control of the Ottoman sultan through the \"dev\u015firme\" system of child levy enslavement, by which indigenous European Christian boys from the Balkans (predominantly Albanians, Bulgarians, Croats, Greeks, Romanians, Serbs, and Ukrainians) were taken, levied, subjected to forced circumcision and forced conversion to Islam, and incorporated into the Ottoman army, and \"jizya\" taxes. Radushev states that the recruitment system based on child levy can be bisected into two periods: its first, or classical period, encompassing those first two centuries of regular execution and utilization to supply recruits; and a second, or modern period, which more focuses on its gradual change, decline, and ultimate abandonment, beginning in the 17th century.\nIn later years, Ottoman sultans turned to the Barbary Pirates to supply the Janissary Corps. Their attacks on ships off the coast of Africa or in the Mediterranean, and subsequent capture of able-bodied men for ransom or sale provided some captives for the Ottoman state. From the 17th century onwards, the \"dev\u015firme\" system became obsolete. Eventually, the Ottoman sultan turned to foreign volunteers from the warrior clans of Circassians in southern Russia to fill the Janissary Corps. As a whole the system began to break down, the loyalty of the Jannissaries became increasingly suspect. The Janissary Corps was abolished by Mahmud II in 1826 in the Auspicious Incident, in which 6,000 or more were executed. On the western coast of Africa, Berber Muslims captured non-Muslims to put to work as laborers. In Morocco, the Berbers looked south rather than north. The Moroccan sultan Moulay Ismail, called \"the Bloodthirsty\" (1672\u20131727), employed a corps of 150,000 black slaves, called the \"Black Guard\". He used them to coerce the country into submission.\nIn modern times.\nModern conscription, the massed military enrollment of national citizens (), was devised during the French Revolution, to enable the Republic to defend itself from the attacks of European monarchies. Deputy Jean-Baptiste Jourdan gave its name to the 5 September 1798 Act, whose first article stated: \"Any Frenchman is a soldier and owes himself to the defense of the nation.\" It enabled the creation of the , what Napoleon Bonaparte called \"the nation in arms\", which overwhelmed European professional armies that often numbered only into the low tens of thousands. More than 2.6\u00a0million men were inducted into the French military in this way between the years 1800 and 1813.\nThe defeat of the Prussian Army in particular shocked the Prussian establishment, which had believed it was invincible after the victories of Frederick the Great. The Prussians were used to relying on superior organization and tactical factors such as order of battle to focus superior troops against inferior ones. Given approximately equivalent forces, as was generally the case with professional armies, these factors showed considerable importance. However, they became considerably less important when the Prussian armies faced Napoleon's forces that outnumbered their own in some cases by more than ten to one. Scharnhorst advocated adopting the , the military conscription used by France. The was the beginning of short-term compulsory service in Prussia, as opposed to the long-term conscription previously used.\nIn the Russian Empire, the military service time \"owed\" by serfs was 25 years at the beginning of the 19th century. In 1834 it was decreased to 20 years. The recruits were to be not younger than 17 and not older than 35. In 1874 Russia introduced universal male conscription in the modern pattern, an innovation only made possible by the abolition of serfdom in 1861. New military law decreed that all male Russian subjects, when they reached the age of 20, were eligible to serve in the military for six years.\nIn the decades prior to World War I universal male conscription along broadly Prussian lines became the norm for European armies, and those modeled on them. By 1914 the only substantial armies still completely dependent on voluntary enlistment were those of Britain and the United States. Some colonial powers such as France reserved their conscript armies for home service while maintaining professional units for overseas duties.\nWorld Wars.\nThe range of eligible ages for conscripting was expanded to meet national demand during the World Wars.\nIn the United States, the Selective Service System drafted men for World War I initially in an age range from 21 to 30 but expanded its eligibility in 1918 to an age range of 18 to 45. In the case of a widespread mobilization of forces where service includes homefront defense, ages of conscripts may range much higher, with the oldest conscripts serving in roles requiring lesser mobility.\nExpanded-age conscription was common during the Second World War: in Britain, it was commonly known as \"call-up\" and extended to age 51. Nazi Germany termed it (\"People's Storm\") and included boys as young as 16 and men as old as 60. During the Second World War, both Britain and the Soviet Union conscripted women. The United States was on the verge of drafting women into the Nurse Corps because it anticipated it would need the extra personnel for its planned invasion of Japan. However, the Japanese surrendered and the idea was abandoned.\nDuring the Great Patriotic War, the Red Army conscripted nearly 30 million men.\nArguments against conscription.\nSexism.\nMen's rights activists, feminists, and opponents of discrimination against men have criticized military conscription, or compulsory military service, as sexist. The National Coalition for Men, a men's rights group, sued the US Selective Service System in 2019, leading to it being declared unconstitutional by a US Federal Judge. The federal district judge's opinion was unanimously overturned on appeal to the U.S. Court of Appeals for the 5th Circuit. In September 2021, the House of Representatives passed the annual Defense Authorization Act, which included an amendment that states that \"all Americans between the ages of 18 and 25 must register for selective service.\" This amendment omitted the word \"male\", which would have extended a potential draft to women; however, the amendment was removed before the National Defense Authorization Act was passed.\nFeminists have argued, first, that military conscription is sexist because wars serve the interests of what they view as the patriarchy; second, that the military is a sexist institution and that conscripts are therefore indoctrinated into sexism; and third, that conscription of men normalizes violence by men as socially acceptable. Feminists have been organizers and participants in resistance to conscription in several countries.\nConscription has also been criticized on the ground that, historically, only men have been subjected to conscription. Men who opt out or are deemed unfit for military service must often perform alternative service, such as Zivildienst in Austria, Germany and Switzerland, or pay extra taxes, whereas women do not have these obligations. In the US, men who do not register with the Selective Service cannot apply for citizenship, receive federal financial aid, grants or loans, be employed by the federal government, be admitted to public colleges or universities, or, in some states, obtain a driver's license.\nInvoluntary servitude.\nMany American libertarians oppose conscription and call for the abolition of the Selective Service System, arguing that impressment of individuals into the armed forces amounts to involuntary servitude. For example, Ron Paul, a former U.S. Libertarian Party presidential nominee, has said that conscription \"is wrongly associated with patriotism, when it really represents slavery and involuntary servitude\". The philosopher Ayn Rand opposed conscription, opining that \"of all the statist violations of individual rights in a mixed economy, the military draft is the worst. It is an abrogation of rights. It negates man's fundamental right\u2014the right to life\u2014and establishes the fundamental principle of statism: that a man's life belongs to the state, and the state may claim it by compelling him to sacrifice it in battle.\"\nIn 1917, a number of radicals and anarchists, including Emma Goldman, challenged the new draft law in federal court, arguing that it was a violation of the Thirteenth Amendment's prohibition against slavery and involuntary servitude. However, the Supreme Court unanimously upheld the constitutionality of the draft act in the case of \"Arver v. United States\" on 7 January 1918, on the ground that the Constitution gives Congress the power to declare war and to raise and support armies. The Court also relied on the principle of the reciprocal rights and duties of citizens. \"It may not be doubted that the very conception of a just government in its duty to the citizen includes the reciprocal obligation of the citizen to render military service in case of need and the right to compel.\"\nEconomic.\nIt can be argued that in a cost-to-benefit ratio, conscription during peacetime is not worthwhile. Months or years of service performed by the most fit and capable subtract from the productivity of the economy; add to this the cost of training them, and in some countries paying them. Compared to these extensive costs, some would argue there is very little benefit; if there ever was a war then conscription and basic training could be completed quickly, and in any case there is little threat of a war in most countries with conscription. In the United States, every male resident is required by law to register with the Selective Service System within 30 days following his 18th birthday and be available for a draft; this is often accomplished automatically by a motor vehicle department during licensing or by voter registration.\nAccording to Milton Friedman the cost of conscription can be related to the parable of the broken window in anti-draft arguments. The cost of the work, military service, does not disappear even if no salary is paid. The work effort of the conscripts is effectively wasted, as an unwilling workforce is extremely inefficient. The impact is especially severe in wartime, when civilian professionals are forced to fight as amateur soldiers. Not only is the work effort of the conscripts wasted and productivity lost, but professionally skilled conscripts are also difficult to replace in the civilian workforce. Every soldier conscripted in the army is taken away from his civilian work, and away from contributing to the economy which funds the military. This may be less a problem in an agrarian or pre-industrialized state where the level of education is generally low, and where a worker is easily replaced by another. However, this is potentially more costly in a post-industrial society where educational levels are high and where the workforce is sophisticated and a replacement for a conscripted specialist is difficult to find. Even more dire economic consequences result if the professional conscripted as an amateur soldier is killed or maimed for life; his work effort and productivity are lost.\nArguments for conscription.\nPolitical and moral motives.\nClassical republicans promoted conscription as a tool for maintaining civilian control of the military, thereby preventing usurpation by a select class of warriors or mercenaries. Jean Jacques Rousseau argued vehemently against professional armies since he believed that it was the right and privilege of every citizen to participate to the defense of the whole society and that it was a mark of moral decline to leave the business to professionals. He based his belief upon the development of the Roman Republic, which came to an end at the same time as the Roman Army changed from a conscript to a professional force. Similarly, Aristotle linked the division of armed service among the populace intimately with the political order of the state. Niccol\u00f2 Machiavelli argued strongly for political regimes to enlist their own subjects in the army throughout his works, such as The Prince and The Discourses on Livy, among his other writings.\nOther proponents, such as William James, consider both mandatory military and national service as ways of instilling maturity in young adults. Some proponents, such as Jonathan Alter and Mickey Kaus, support a draft in order to reinforce social equality, create social consciousness, break down class divisions and allow young adults to immerse themselves in public enterprise. This justification forms the basis of Israel's People's Army Model. Charles Rangel called for the reinstatement of the draft during the Iraq War not because he seriously expected it to be adopted but to stress how the socioeconomic restratification meant that very few children of upper-class Americans served in the all-volunteer American armed forces.\nConscription has also been used for nation-building and immigrant integration.\nEconomic and resource efficiency.\nIt is estimated by the British military that in a professional military, a company deployed for active duty in peacekeeping corresponds to three inactive companies at home. Salaries for each are paid from the military budget. In contrast, volunteers from a trained reserve are in their civilian jobs when they are not deployed.\nUnder the total defense doctrine, conscription paired with periodic refresher training ensures that the entire able-bodied population of a country can be mobilized to defend against invasion or assist civil authorities during emergencies. For this reason, some European countries have reintroduced or debated reintroducing conscription during the onset of the Russian invasion of Ukraine.\nMilitary Keynesians often argue for conscription as a job guarantee. For example, it was more financially beneficial for less-educated young Portuguese men born in 1967 to participate in conscription than to participate in the highly competitive job market with men of the same age who continued to higher education.\nDrafting of women.\nThroughout history, women have only been conscripted to join armed forces in a few countries, in contrast to the universal practice of conscription from among the male population. The traditional view has been that military service is a test of manhood and a rite of passage from boyhood into manhood. In recent years, this position has been challenged on the basis that it violates gender equality, and some countries, have extended conscription obligations to women.\nIn 2006, eight countries (China, Eritrea, Israel, Green Libya, Malaysia, North Korea, Peru, and Taiwan) conscripted women into military service.\nNorway introduced female conscription in 2015, making it the first NATO member to have a legally compulsory national service for both men and women, and the first country in the world to draft women on the same formal terms as men. In practice only motivated volunteers are selected to join the army in Norway.\nSweden introduced female conscription in 2010, but because the national conscription system was suspended that same year, it only came into effect in 2017, once compulsory service (for both genders) was reinstated. This made Sweden the second nation in Europe to draft women, and the second in the world (after Norway) to draft women on the same formal terms as men.\nDenmark has extended conscription to women from 2027 but then brought forward military service to 2025, also on a gender-neutral model.\nIsrael has universal female conscription and has a similar percentage of female conscription to male. Since the founding of the IDF, female conscription was implemented but was limited to mostly non combative roles. Since 2000, more diverse role were opened for women and 92% of the roles are opened for them.\nIn China, military law allows for the conscription of men and women, but in practice people serving are volunteers, given that China's large population (of over a billion) permits meeting its military targets with volunteers. Nevertheless, provinces reserve their right to conscript people, if their quotas are not met by volunteers.\nSudanese law allows for conscription of women, but this is not implemented in practice.\nIn the United Kingdom during World War II, beginning in 1941, women were brought into the scope of conscription but, as all women with dependent children were exempt and many women were informally left in occupations such as nursing or teaching, the number conscripted was relatively few. Most women who were conscripted were sent to the factories, although some were part of the Auxiliary Territorial Service (ATS), Women's Land Army, and other women's services. None were assigned to combat roles unless they volunteered. In contemporary United Kingdom, in July 2016, all exclusions on women serving in Ground Close Combat (GCC) roles were lifted.\nIn the Soviet Union, there was never conscription of women for the armed forces, but the severe disruption of normal life and the high proportion of civilians affected by World War II after the German invasion attracted many volunteers for \"The Great Patriotic War\". Medical doctors of both sexes could and would be conscripted (as officers). Also, the Soviet university education system required Department of Chemistry students of both sexes to complete an ROTC course in NBC defense, and such female reservist officers could be conscripted in times of war.\nThe United States came close to drafting women into the Nurse Corps in preparation for a planned invasion of Japan.\nIn 1981 in the United States, several men filed lawsuit in the case \"Rostker v. Goldberg\", alleging that the Selective Service Act of 1948 violates the Due Process Clause of the Fifth Amendment by requiring that only men register with the Selective Service System (SSS). The Supreme Court eventually upheld the Act, stating that \"the argument for registering women was based on considerations of equity, but Congress was entitled, in the exercise of its constitutional powers, to focus on the question of military need, rather than 'equity.'\" In 2013, Judge Gray H. Miller of the United States District Court for the Southern District of Texas ruled that the Service's men-only requirement was unconstitutional, as while at the time \"Rostker\" was decided, women were banned from serving in combat, the situation had since changed with the 2013 and 2015 restriction removals. Miller's opinion was reversed by the Fifth Circuit, stating that only the Supreme Court could overturn the Supreme Court precedence from \"Rostker\". The Supreme Court considered but declined to review the Fifth Circuit's ruling in June 2021. In an opinion authored by Justice Sonia Sotomayor and joined by Justices Stephen Breyer and Brett Kavanaugh, the three justices agreed that the male-only draft was likely unconstitutional given the changes in the military's stance on the roles, but because Congress had been reviewing and evaluating legislation to eliminate its male-only draft requirement via the National Commission on Military, National, and Public Service (NCMNPS) since 2016, it would have been inappropriate for the Court to act at that time.\nOn 1 October 1999, in Taiwan, the Judicial Yuan of the Republic of China in its Interpretation 490 considered that the physical differences between males and females and the derived role differentiation in their respective social functions and lives would not make drafting only males a violation of the Constitution of the Republic of China. Though women are not conscripted in Taiwan, transsexual persons are exempt.\nIn 2018, the Netherlands started including women in its draft registration system, although conscription is not currently enforced for either sex. France and Portugal, where conscription was abolished, extended their symbolic, mandatory day of information on the armed forces for young people - called Defence and Citizenship Day in France and Day of National Defence in Portugal \u2013 to women in 1997 and 2008, respectively; at the same time, the military registry of both countries and obligation of military service in case of war was extended to women.\nConscription of people with disabilities.\nConscription for autistic people.\nMilitary authorities generally consider autistic individuals unfit for service, while neurodiversity advocates argue that they can be well-suited for military roles.\nConscientious objection.\nA conscientious objector is an individual whose personal beliefs are incompatible with military service, or, more often, with any role in the armed forces. In some countries, conscientious objectors have special legal status, which augments their conscription duties. For example, Sweden allows conscientious objectors to choose a service in the weapons-free civil defense.\nThe reasons for refusing to serve in the military are varied. Some people are conscientious objectors for religious reasons. In particular, the members of the historic peace churches are pacifist by doctrine, and Jehovah's Witnesses, while not strictly pacifists, refuse to participate in the armed forces on the ground that they believe that Christians should be neutral in international conflicts.\nBy country.\nAustria.\nEvery male citizen of the Republic of Austria from the age of 17 up to 50, specialists up to 65 years is liable to military service. However, besides mobilization, conscription calls to a six-month long basic military training in the can be done up to the age of 35. For men refusing to undergo this training, a nine-month lasting community service is mandatory.\nBelgium.\nBelgium abolished the conscription in 1994. The last conscripts left active service in February 1995. To this day (2019), a small minority of the Belgian citizens supports the idea of reintroducing military conscription, for both men and women.\nBulgaria.\nBulgaria had conscription for males above 18 until it was ended in 2008. Due to a shortfall in the army of some 5,500 soldiers, parts of the former ruling coalition have expressed their support for the return of conscription, most notably Krasimir Karakachanov. Opposition towards this idea from the main coalition partner, GERB, saw a compromise in 2018, where instead of conscription, Bulgaria could have possibly introduced a voluntary military service by 2019 where young citizens can volunteer for a period of 6 to 9 months, receiving a basic wage. However, this has not gone forward.\nCambodia.\nSince the signing of the Peace Accord in 1993, there has been no official conscription in Cambodia. Also the National Assembly has repeatedly rejected to reintroduce it due to popular resentment. However, in November 2006, it was reintroduced. Although mandatory for all males between the ages of 18 and 30 (with some sources stating up to age 35), less than 20% of those in the age group are recruited amidst a downsizing of the armed forces.\nCanada.\nCompulsory service in a sedentary militia was practiced in Canada as early as 1669. In peacetime, compulsory service was typically limited to attending an annual muster, although the Canadian militia was mobilized for longer periods during wartime. Compulsory service in the sedentary militia continued until the early 1880s when Canada's sedentary Reserve Militia system fell into disuse. The legislative provision that formally made every male inhabitant aged 16 to 60 member of the Reserve Militia was removed in 1904, replaced with provisions that made them theoretically \"liable to serve in the militia\".\nConscription into a full-time military service had only been instituted twice by the government of Canada, during both world wars. Conscription into the Canadian Expeditionary Force was practiced in the last year of the First World War in 1918. During the Second World War, conscription for home defence was introduced in 1940 and for overseas service in 1944. Conscription has not been practiced in Canada since the end of the Second World War in 1945.\nChina.\nUniversal conscription in China dates back to the State of Qin, which eventually became the Qin Empire of 221 BC. Following unification, historical records show that a total of 300,000 conscript soldiers and 500,000 conscript labourers constructed the Great Wall of China. In the following dynasties, universal conscription was abolished and reintroduced on numerous occasions.\nAs of 2011[ [update]], universal military conscription is theoretically mandatory in China, and reinforced by law. However, due to the large population of China and large pool of candidates available for recruitment, the People's Liberation Army has always had sufficient volunteers, so conscription has not been required in practice.\nCyprus.\nMilitary service in Cyprus has a deep rooted history entangled with the Cyprus problem. Military service in the Cypriot National Guard is mandatory for all male citizens of the Republic of Cyprus, as well as any male non-citizens born of a parent of Greek Cypriot descent, lasting from the 1 January of the year in which they turn 18 years of age to 31 December, of the year in which they turn 50. All male residents of Cyprus who are of military age (16 and over) are required to obtain an exit visa from the Ministry of Defense. Currently, military conscription in Cyprus lasts up to 14 months.\nDenmark.\nConscription is known in Denmark since the Viking Age, where one man out of every 10 had to serve the king. Frederick IV of Denmark changed the law in 1710 to every 4th man. The men were chosen by the landowner and it was seen as a penalty.\nSince 12 February 1849, every physically fit man must do military service. According to \u00a781 in the Constitution of Denmark, which was promulgated in 1849: Every male person able to carry arms shall be liable with his person to contribute to the defence of his country under such rules as are laid down by Statute. \u2014 Constitution of DenmarkThe legislation about compulsory military service is articulated in the Danish Law of Conscription. National service takes 4\u201312 months. It is possible to postpone the duty when one is still in full-time education. Every male turning 18 will be drafted to the 'Day of Defence', where they will be introduced to the Danish military and their health will be tested. Physically unfit persons are not required to do military service. It is only compulsory for men, while women are free to choose to join the Danish army. Almost all of the men have been volunteers in recent years, 96.9% of the total number of recruits having been volunteers in the 2015 draft.\nAfter lottery, one can become a conscientious objector. Total objection (refusal from alternative civilian service) results in up to 4 months jailtime according to the law. However, in 2014 a Danish man, who signed up for the service and objected later, got only 14 days of home arrest.\nEstonia.\nEstonia adopted a policy of \"ajateenistus\" (literally \"time service\") in late 1991, having inherited the concept from Soviet legislature. \nAccording to \u00a7124 of the 1992 constitution, \"Estonian citizens have a duty to participate in national defence on the bases and pursuant to a procedure provided by a law\", which in practice means that men aged 18\u201327 are subject to the draft.\nIn the formative years, conscripts had to serve an 18-month term. An amendment passed in 1994 shortened this to 12 months. Further revisions in 2003 established an eleven-month term for draftees trained as NCOs and drivers, and an eight-month term for rank &amp; file. Under the current system, the yearly draft is divided into three \"waves\" \u2013 separate batches of eleven-month conscripts start their service in January and July while those selected for an eight-month term are brought in on October. An estimated 3200 people go through conscript service every year.\nFrom 2013, women have been able to voluntarily join the conscription under the same conditions as men, the only difference being the norms of the general fitness tests and a 90-day window during which women can leave the service.\nConscripts serve in all branches of the Estonian Defence Forces except the air force which only relies on paid professionals due to its highly technical nature and security concerns. Historically, draftees could also be assigned to the border guard (before it switched to an all-volunteer model in 2000), of the police force (disbanded in 1997) or three militarized rescue companies within the Estonian Rescue Board (disbanded in 2004).\nFinland.\nConscription in Finland is part of a general compulsion for national military service for all adult males (; ) defined in the 127\u00a7 of the Constitution of Finland.\nConscription can take the form of military or of civilian service. According to 2021 data, 65% of Finnish males entered and finished the military service. The number of female volunteers to annually enter armed service had stabilised at approximately 300. The service period is 165, 255 or 347 days for the rank and file conscripts and 347 days for conscripts trained as NCOs or reserve officers. The length of civilian service is always twelve months. Those electing to serve unarmed in duties where unarmed service is possible serve either nine or twelve months, depending on their training.\nAny Finnish male citizen who refuses to perform both military and civilian service faces a penalty of 173 days in prison, minus any served days. Such sentences are usually served fully in prison, with no parole. Jehovah's Witnesses are no longer exempted from service as of 27 February 2019. The inhabitants of demilitarized \u00c5land are exempt from military service. By the Conscription Act of 1951, they are, however, required to serve a time at a local institution, like the coast guard. However, until such service has been arranged, they are freed from service obligation. The non-military service of \u00c5land has not been arranged since the introduction of the act, and there are no plans to institute it. The inhabitants of \u00c5land can also volunteer for military service on the mainland. As of 1995, women are permitted to serve on a voluntary basis and pursue careers in the military after their initial voluntary military service.\nThe military service takes place in Finnish Defence Forces or in the Finnish Border Guard. All services of the Finnish Defence Forces train conscripts. However, the Border Guard trains conscripts only in land-based units, not in coast guard detachments or in the Border Guard Air Wing. Civilian service may take place in the Civilian Service Center in Lapinj\u00e4rvi or in an accepted non-profit organization of educational, social or medical nature.\nGermany.\nBetween 1956 and 2011 conscription was mandatory for all male citizens in the German federal armed forces (), as well as for the Federal Border Guard () in the 1970s (see Border Guard Service). With the end of the Cold War the German government drastically reduced the size of its armed forces. The low demand for conscripts led to the suspension of compulsory conscription in 2011. Since then, only volunteer professionals serve in the .\nIn 2025, Germany began steps towards potentially reintroducing conscription, which had been suspended in 2011. The new policy included compulsory questionnaires for 18-year-old men. Extending the conscription system to women, which is discussed, would require a constitutional change. The government aimes to raise troop numbers to meet NATO commitments, including plans for an additional 100,000 personnel by 2029.\nHowever, Defense Minister Boris Pistorius explained that, for the time being, mandatory conscription would not return \"in the immediate future.\"\nGreece.\nSince 1914 Greece has been enforcing mandatory military service, currently lasting 12 months (but historically up to 36 months) for all adult men. Citizens discharged from active service are normally placed in the reserve and are subject to periodic recalls of 1\u201310 days at irregular intervals.\nUniversal conscription was introduced in Greece during the military reforms of 1909, although various forms of selective conscription had been in place earlier. In more recent years, conscription was associated with the state of general mobilisation declared on 20 July 1974, due to the crisis in Cyprus (the mobilisation was formally ended on 18 December 2002).\nThe duration of military service has historically ranged between 9 and 36 months depending on various factors either particular to the conscript or the political situation in the Eastern Mediterranean. Although women are employed by the Greek army as officers and soldiers, they are not obliged to enlist. Soldiers receive no health insurance, but they are provided with medical support during their army service, including hospitalization costs.\nGreece enforces conscription for all male citizens aged between 19 and 45. In August 2009, duration of the mandatory service was reduced from 12 months as it was before to 9 months for the army, but remained at 12 months for the navy and the air force. The number of conscripts allocated to the latter two has been greatly reduced aiming at full professionalization. Nevertheless, mandatory military service at the army was once again raised to 12 months in March 2021, unless served in units in Evros or the North Aegean islands where duration was kept at 9 months. Although full professionalization is under consideration, severe financial difficulties and mismanagement, including delays and reduced rates in the hiring of professional soldiers, as well as widespread abuse of the deferment process, has resulted in the postponement of such a plan.\nIran.\nIn Iran, all men who reach the age of 18 must do about two years of compulsory military service in the IR police department or Iranian army or Islamic Revolutionary Guard Corps. Before the 1979 revolution, women could serve in the military. However, after the establishment of the Islamic Republic, some Ayatollahs considered women's military service to be disrespectful to women by the Pahlavi government and banned women's military service in Iran. Therefore, Iranian women and girls were completely exempted from military service, which caused Iranian men and boys to oppose.\nIn Iran, men who refuse to go to military service are deprived of their citizenship rights, such as employment, health insurance, continuing their education at university, finding a job, going abroad, opening a bank account, etc. Iranian men have so far opposed mandatory military service and demanded that military service in Iran become a job like in other countries, but the Islamic Republic is opposed to this demand. Some Iranian military commanders consider the elimination of conscription or improving the condition of soldiers as a security issue and one of Ali Khamenei's powers as the commander-in-chief of the armed forces, so they treat it with caution. In Iran, usually wealthy people are exempted from conscription. Some other men can be exempted from conscription due to their fathers serving in the Iran-Iraq war.\nIsrael.\nThere is a mandatory military service for all men and women in Israel who are fit and 18 years old. Men must serve 32 months while women serve 24 months, with the vast majority of conscripts being Jewish.\nSome Israeli citizens are exempt from mandatory service:\nAll of the exempt above are eligible to volunteer to the Israel Defense Forces (IDF), as long as they declare so.\nMale Druze and male Circassian Israeli citizens are liable for conscription, in accordance with agreement set by their community leaders (their community leaders however signed a clause in which all female Druze and female Circassian are exempt from service).\nA few male Bedouin Israeli citizens choose to enlist to the Israeli military in every draft (despite their Muslim-Arab background that exempt them from conscription).\nLithuania.\nLithuania abolished its conscription in 2008. In May 2015, the Lithuanian parliament voted to reintroduce conscription and the conscripts started their training in August 2015. From 2015 to 2017 there were enough volunteers to avoid drafting civilians.\nLuxembourg.\nLuxembourg practiced military conscription from 1948 until 1967.\nMoldova.\nMoldova has a 12-month conscription for all males between 18 and 27 years. However, a citizen who completed a military training course at a military department is exempted from conscription.\nNetherlands.\nConscription, which was called \"Service Duty\" () in the Netherlands, was first employed in 1810 by French occupying forces. Napoleon's brother Louis Bonaparte, who was King of Holland from 1806 to 1810, had tried to introduce conscription a few years earlier, unsuccessfully. Every man aged 20 years or older had to enlist. By means of drawing lots it was decided who had to undertake service in the French army. It was possible to arrange a substitute against payment.\nLater on, conscription was used for all men over the age of 18. Postponement was possible, due to study, for example. Conscientious objectors could perform an alternative civilian service instead of military service. For various reasons, this forced military service was criticized at the end of the twentieth century. Since the Cold War was over, so was the direct threat of a war. Instead, the Dutch army was employed in more and more peacekeeping operations. The complexity and danger of these missions made the use of conscripts controversial. Furthermore, the conscription system was thought to be unfair as only men were drafted.\nIn the European part of Netherlands, compulsory attendance has been officially suspended since 1 May 1997. Between 1991 and 1996, the Dutch armed forces phased out their conscript personnel and converted to an all-professional force. The last conscript troops were inducted in 1995, and demobilized in 1996. The suspension means that citizens are no longer forced to serve in the armed forces, as long as it is not required for the safety of the country. Since then, the Dutch army has become an all-professional force. However, to this day, every male and \u2013 from January 2020 onward \u2013 female citizen aged 17 gets a letter in which they are told that they have been registered but do not have to present themselves for service.\nNorway.\nConscription was constitutionally established the 12 April 1907 with \"Kongeriket Norges Grunnlov \u00a7 119.\". \nAs of March\u00a02016[ [update]], Norway currently employs a weak form of mandatory military service for men and women. In practice recruits are not forced to serve, instead only those who are motivated are selected. About 60,000 Norwegians are available for conscription every year, but only 8,000 to 10,000 are conscripted. Since 1985, women have been able to enlist for voluntary service as regular recruits. On 14 June 2013 the Norwegian Parliament voted to extend conscription to women, resulting in universal conscription in effect from 2015. This made Norway the first NATO member and first European country to make national service compulsory for both sexes. In earlier times, up until at least the early 2000s, all men aged 19\u201344 were subject to mandatory service, with good reasons required to avoid becoming drafted. There is a right of conscientious objection. As of 2020 Norway did not reach gender equity in conscription with only 33% of all conscripted being women.\nIn addition to the military service, the Norwegian government draft a total of 8,000 men and women between 18 and 55 to non-military Civil defence duty. (Not to be confused with Alternative civilian service.) Former service in the military does not exclude anyone from later being drafted to the Civil defence, but an upper limit of total 19 months of service applies. Neglecting mobilisation orders to training exercises and actual incidents, may impose fines.\nRussia.\nThe Russian Armed Forces draw personnel from various sources. In addition to conscripts, the 2022 Russian mobilization on account of the Russian invasion of Ukraine revealed Russian irregular units in Ukraine and Russian penal military units as sources of manpower. This adds to the BARS (Russia), the National Guard of Russia and the Russian volunteer battalions.\nSerbia.\nAs of 2011[ [update]], Serbia no longer practises mandatory military service. Prior to this, mandatory military service lasted 6 months for men. Conscientious objectors could however opt for 9 months of civil service instead.\nOn 15 December 2010, the Parliament of Serbia voted to suspend mandatory military service. The decision fully came into force on 1 January 2011.\nIn September 2024, Prime Minister Milo\u0161 Vu\u010devi\u0107 announced that conscription will return in September 2025 with the mandatory military service lasting 75 days. Civil service will still be possible as an alternative.\nSouth Africa.\nThere was mandatory military conscription for all white men in South Africa from 1968 until the end of apartheid in 1994. Under South African defense law, young white men had to undergo two years' continuous military training after they leave school, after which they had to serve 720 days in occasional military duty over the next 12 years. The End Conscription Campaign began in 1983 in opposition to the requirement. In the same year the National Party government announced plans to extend conscription to white immigrants in the country.\nSweden.\nSweden had conscription () for men between 1901 and 2010. During the last few decades it was selective. Since 1980, women have been allowed to sign up by choice, and, if passing the tests, do military training together with male conscripts. Since 1989 women have been allowed to serve in all military positions and units, including combat.\nIn 2010, conscription was made gender-neutral, meaning both women and men would be conscripted on equal terms. The conscription system was simultaneously deactivated in peacetime. Seven years later, referencing increased military threat, the Swedish Government reactivated military conscription. Beginning in 2018, both men and women are conscripted.\nTaiwan.\nTaiwan, officially the Republic of China (ROC), maintains an active conscription system. All qualified male citizens of military age are now obligated to receive 4-month of military training. In December 2022, President Tsai Ing-wen led the government to announce the reinstatement of the mandatory 1-year active duty military service from January 2024.\nTurkey.\nThe Conscription Law of the Ottoman Empire was introduced just before the WW1 and has stayed in force with Turkey as well. Conscription applies to all male citizens from 21 to 41 years of age. It can be served either; 6-months unpaid as a private, 12-month paid as an officer or NCO (dependent on the level of education) and as a one-month service in exchange of a certain fee which also applies to the citizens who live abroad.\nTurks with multiple citizenship are exempt from conscription if they have already served in the armed forces of another country. Women and LGBT citizens are not drafted but can enlist as officers or NCOs on-demand.\nUnited Kingdom.\nThe United Kingdom introduced conscription to full-time military service for the first time in January 1916 (the eighteenth month of World War I) and abolished it in 1920. Ireland, then part of the United Kingdom, was exempted from the original 1916 military service legislation, and although further legislation in 1918 gave power for an extension of conscription to Ireland, the power was never put into effect.\nConscription was reintroduced in 1939, in the lead up to World War II, and continued in force until 1963. Northern Ireland was exempted from conscription legislation throughout the whole period.\nIn all, eight million men were conscripted during both World Wars, as well as several hundred thousand younger single women. The introduction of conscription in May 1939, before the war began, was partly due to pressure from the French, who emphasized the need for a large British army to oppose the Germans. From early 1942 unmarried women age 20\u201330 were conscripted (unmarried women who had dependent children aged 14 or younger, including those who had illegitimate children or were widows with children were excluded). Most women who were conscripted were sent to the factories, but they could volunteer for the Auxiliary Territorial Service (ATS) and other women's services. Some women served in the Women's Land Army: initially volunteers but later conscription was introduced. However, women who were already working in a skilled job considered helpful to the war effort, such as a General Post Office telephonist, were told to continue working as before. None was assigned to combat roles unless she volunteered. By 1943 women were liable to some form of directed labour up to age 51. During the Second World War, 1.4\u00a0million British men volunteered for service and 3.2\u00a0million were conscripted. Conscripts comprised 50% of the Royal Air Force, 60% of the Royal Navy and 80% of the British Army.\nThe abolition of conscription in Britain was announced on 4 April 1957, by new prime minister Harold Macmillan, with the last conscripts being recruited three years later.\nUnited States.\nConscription in the United States ended in 1973, but males aged between 18 and 25 are required to register with the Selective Service System to enable a reintroduction of conscription if necessary. President Gerald Ford had suspended mandatory draft registration in 1975, but President Jimmy Carter reinstated that requirement when the Soviet Union intervened in Afghanistan five years later. Consequently, Selective Service registration is still required of almost all young men. There have been no prosecutions for violations of the draft registration law since 1986. Males between the ages of 17 and 45, and female members of the US National Guard may be conscripted for federal militia service pursuant to 10 U.S. Code \u00a7 246 and the Militia Clauses of the United States Constitution.\nIn February 2019, the United States District Court for the Southern District of Texas ruled that male-only conscription registration breached the Fourteenth Amendment's equal protection clause. In \"National Coalition for Men v. Selective Service System\", a case brought by a non-profit men's rights organization the National Coalition for Men against the U.S. Selective Service System, judge Gray H. Miller issued a declaratory judgment that the male-only registration requirement is unconstitutional, though did not specify what action the government should take. That ruling was reversed by the Fifth Circuit. In June 2021, the U.S. Supreme Court declined to review the decision by the Court of Appeals.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "5736", "revid": "27823944", "url": "https://en.wikipedia.org/wiki?curid=5736", "title": "Catherine Coleman", "text": "American astronaut, chemist, engineer and USAF colonel (born 1960)\nCatherine Grace \"Cady\" Coleman (born December 14, 1960) is an American chemist, engineer, former United States Air Force colonel, and retired NASA astronaut. She is a veteran of two Space Shuttle missions, and departed the International Space Station on May 23, 2011, as a crew member of Expedition 27 after logging 159 days in space.\nEducation.\nColeman graduated from Wilbert Tucker Woodson High School, Fairfax, Virginia, in 1978. In 1978\u20131979, she was an exchange student at R\u00f8yken Upper Secondary School in Norway with the AFS Intercultural Programs. She received a B.S. degree in chemistry from the Massachusetts Institute of Technology (MIT) in 1983 and was commissioned as graduate of the Air Force Reserve Officer Training Corps (Air Force ROTC)., then received a Ph.D. degree in polymer science and engineering from the University of Massachusetts Amherst in 1991. She was advised by Professor Thomas J. McCarthy on her doctorate. As an undergraduate, she was a member of the intercollegiate rowing crew and was a resident of Baker House.\nMilitary career.\nColeman continued to pursue her PhD at the University of Massachusetts Amherst as a second lieutenant. In 1988, she entered active duty at Wright-Patterson Air Force Base as a research chemist. During her work, she participated as a surface analysis consultant on the NASA Long Duration Exposure Facility experiment. In 1991, she received her doctorate in polymer science and engineering. She retired from the Air Force in November 2009 as a colonel.\nNASA career.\nColeman was selected by NASA in 1992 to join the NASA Astronaut Corps. In 1995, she was a member of the STS-73 crew on the scientific mission USML-2 with experiments including biotechnology, combustion science, and the physics of fluids. STS-93 was Coleman's second space flight in 1999. She was mission specialist in charge of deploying the Chandra X-ray Observatory and its Inertial Upper Stage out of the shuttle's cargo bay.\nColeman served as Chief of Robotics for the Astronaut Office, to include robotic arm operations and training for all Space Shuttle and International Space Station missions. In October 2004, Coleman served as an aquanaut during the NEEMO 7 mission aboard the Aquarius underwater laboratory, living and working underwater for eleven days.\nColeman was assigned as a backup U.S. crew member for Expeditions 19, 20 and 21 and served as a backup crew member for Expeditions 24 and 25 as part of her training for Expedition 26.\nColeman launched on December 15, 2010 (December 16, 2010 Baikonur time), aboard Soyuz TMA-20 to join the Expedition 26 mission aboard the International Space Station. She retired from NASA on December 1, 2016.\nSpaceflight experience.\nSTS-73 on Space Shuttle \"Columbia\" (October 20 to November 5, 1995) was the second United States Microgravity Laboratory (USML-2) mission. The mission focused on materials science, biotechnology, combustion science, the physics of fluids, and numerous scientific experiments housed in the pressurized Spacelab module. In completing her first space flight, Coleman orbited the Earth 256 times, traveled over 6 million miles, and logged a total of 15 days, 21 hours, 52 minutes and 21 seconds in space.\nSTS-93 on \"Columbia\" (July 22 to 27, 1999) was a five-day mission during which Coleman was the lead mission specialist for the deployment of the Chandra X-ray Observatory. Designed to conduct comprehensive studies of the universe, the telescope will enable scientists to study exotic phenomena such as exploding stars, quasars, and black holes. Mission duration was 118 hours and 50 minutes.\nSoyuz TMA-20 / Expedition 26/27 (December 15, 2010, to May 23, 2011) was an extended duration mission to the International Space Station.\nPersonal.\nColeman is married to glass artist Josh Simpson who lives in Massachusetts. They have two sons Jamey (born 2002) and Cady. She is part of the band Bandella, which also includes fellow NASA astronaut Stephen Robinson, Canadian astronaut Chris Hadfield, and Micki Pettit (wife of the astronaut Donald Pettit). Coleman is a flute player and has taken several flutes with her to the ISS, including a pennywhistle from Paddy Moloney of The Chieftains, an old Irish flute from Matt Molloy of The Chieftains, and a flute from Ian Anderson of Jethro Tull (band). On February 15, 2011, she played one of the instruments live from orbit on National Public Radio. \nOn April 12, 2011, she played a duet with Ian Anderson to honour Yuri Gagarin's 50th anniversary of his flight. She first recorded her part, which later on Anderson joined while on tour in Perm. \nOn May 13 of that year, Coleman delivered a taped commencement address to the class of 2011 at the University of Massachusetts Amherst.\nAs do many other astronauts, Coleman holds an amateur radio license (callsign: KC5ZTH).\nAs of 2015, she is also known to be working as a guest speaker at the Baylor College of Medicine, for the children's program \"Saturday Morning Science\".\nIn 2018, she gave a graduation address to Carter Lynch, the sole graduate of Cuttyhunk Elementary School, on Cuttyhunk Island, Massachusetts.\nIn 2019 the Irish postal service An Post issued a set of commemorative stamps for the 50th anniversary of the Apollo Moon landings, Catherine Coleman is featured alongside fellow astronauts Neil Armstrong, Michael Collins, and Eileen Collins.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "5737", "revid": "72499", "url": "https://en.wikipedia.org/wiki?curid=5737", "title": "Cross cutting", "text": ""}
{"id": "5738", "revid": "28481209", "url": "https://en.wikipedia.org/wiki?curid=5738", "title": "Cervix", "text": "Lower part of the uterus in the female reproductive system\nThe cervix (pl.: cervices) or uterine cervix () is a dynamic fibromuscular sexual organ of the female reproductive system that connects the vagina with the uterine cavity. The human female cervix has been documented anatomically since at least the time of Hippocrates, over 2,000 years ago. The cervix is approximately long with a diameter of approximately and tends to be described as a cylindrical shape, although the front and back walls of the cervix are contiguous. The size of the cervix changes throughout a female's life cycle. For example, females in the fertile years of their reproductive cycle tend to have larger cervixes than postmenopausal females; likewise, females who have produced offspring have a larger cervix than those who have not.\nIn relation to the vagina, the part of the cervix that opens into the uterus is called the \"internal os\" while the opening of the cervix into the vagina is called the \"external os\". Between those extremes is the conduit commonly called the cervical canal. The lower part of the cervix, known as the vaginal portion of the cervix (or ectocervix), bulges into the top of the vagina. The endocervix borders the uterus. The cervical conduit has at least two types of epithelium (lining): the endocervical lining is glandular epithelia that lines the endocervix with a single layer of column-shaped cells; while the ectocervical part of the conduit contains squamous epithelium. Squamous epithelia line the conduit with multiple layers of cells topped with flat cells. These two linings converge at the squamocolumnar junction (SCJ). This junction changes location dynamically throughout a female's life. The cervix is the organ that allows epithelia to flow from a female's uterus and out through her vagina at menstruation. Menstruation releases epithelia from a female\u2019s uterus with every period of her fertile years, unless pregnancy occurs.\nSeveral methods of contraception aim to prevent fertilization by blocking the conduit, including cervical caps and cervical diaphragms, preventing the passage of sperm through the cervix. Other approaches include methods that observe cervical mucus, such as the Creighton Model and Billings method. Cervical mucus's consistency changes during menstrual periods, which may signal ovulation.\nDuring vaginal childbirth, the cervix must flatten and dilate to allow the foetus to progress along the birth canal. Midwives and doctors use the extent of cervical dilation to assist decision-making during childbirth.\nCervical infections with the human papillomavirus (HPV) can cause changes in the epithelium, which can lead to cancer of the cervix. Cervical cytology tests can detect cervical cancer and its precursors to enable early, successful treatment. Ways to avoid HPV include avoiding heterosexual sex, using penile condoms, and receiving the HPV vaccination. HPV vaccines, developed in the early 21st century, reduce the risk of developing cervical cancer by preventing infections from the main cancer-causing strains of HPV.\nStructure.\nThe cervix is part of the female reproductive system. Around in length, it is the lower, narrower part of the uterus, continuous above with the broader upper part\u2014or body\u2014of the uterus. The lower end of the cervix bulges through the anterior wall of the vagina, and is referred to as the vaginal portion of the cervix (or ectocervix), while the rest of the cervix above the vagina is called the supravaginal portion of cervix. A central canal, known as the cervical canal, runs along its length and connects the cavity of the body of the uterus with the lumen of the vagina. The openings are known as the internal os and external orifice of the uterus (or external os), respectively. The mucosa lining the cervical canal is known as the endocervix, and the mucosa covering the ectocervix is known as the exocervix. The cervix has an inner mucosal layer, a thick layer of smooth muscle, and posteriorly the supravaginal portion has a serosal covering consisting of connective tissue and overlying peritoneum.\nIn front of the upper part of the cervix lies the bladder, separated from it by cellular connective tissue known as parametrium, which also extends over the sides of the cervix. To the rear, the supravaginal cervix is covered by peritoneum, which runs onto the back of the vaginal wall and then turns upwards and onto the rectum, forming the recto-uterine pouch. The cervix is more tightly connected to surrounding structures than the rest of the uterus.\nThe cervical canal varies greatly in length and width between women or throughout a woman's life, and it can measure 8\u00a0mm (0.3\u00a0inch) at its widest diameter in premenopausal adults. It is wider in the middle and narrower at each end. The anterior and posterior walls of the canal each have a vertical fold, from which ridges run diagonally upwards and laterally. These are known as \"palmate folds\", due to their resemblance to a palm leaf. The anterior and posterior ridges are arranged so that they interlock with each other and close the canal. They are often effaced after pregnancy.\nThe ectocervix (also known as the vaginal portion of the cervix) has a convex, elliptical shape and projects into the cervix between the anterior and posterior vaginal fornices. On the rounded part of the ectocervix is a small, depressed external opening, connecting the cervix with the vagina. The size and shape of the ectocervix and the external opening (external os) can vary according to age, hormonal state, and whether childbirth has taken place. In women who have not had a vaginal delivery, the external opening is small and circular, and in women who have had a vaginal delivery, it is slit-like. On average, the ectocervix is long and wide.\nBlood is supplied to the cervix by the descending branch of the uterine artery and drains into the uterine vein. The pelvic splanchnic nerves, emerging as S2\u2013S3, transmit the sensation of pain from the cervix to the brain. These nerves travel along the uterosacral ligaments, which pass from the uterus to the anterior sacrum.\nThree channels facilitate lymphatic drainage from the cervix. The anterior and lateral cervix drains to nodes along the uterine arteries, travelling along the cardinal ligaments at the base of the broad ligament to the external iliac lymph nodes and ultimately the paraaortic lymph nodes. The posterior and lateral cervix drains along the uterine arteries to the internal iliac lymph nodes and ultimately the paraaortic lymph nodes, and the posterior section of the cervix drains to the obturator and presacral lymph nodes. However, there are variations as lymphatic drainage from the cervix travels to different sets of pelvic nodes in some people. This has implications in scanning nodes for involvement in cervical cancer.\nAfter menstruation and directly under the influence of estrogen, the cervix undergoes a series of changes in position and texture. During most of the menstrual cycle, the cervix remains firm and is positioned low and closed. However, as ovulation approaches, the cervix becomes softer and rises to open in response to the higher levels of estrogen present. These changes are also accompanied by changes in cervical mucus, described below.\nDevelopment.\nAs a component of the female reproductive system, the cervix is derived from the two paramesonephric ducts (also called M\u00fcllerian ducts), which develop around the sixth week of embryogenesis. During development, the outer parts of the two ducts fuse, forming a single urogenital canal that will become the vagina, cervix and uterus. The cervix grows in size at a smaller rate than the body of the uterus, so the relative size of the cervix over time decreases, decreasing from being much larger than the body of the uterus in fetal life, twice as large during childhood, and decreasing to its adult size, smaller than the uterus, after puberty. Previously, it was thought that during fetal development, the original squamous epithelium of the cervix is derived from the urogenital sinus, and the original columnar epithelium is derived from the paramesonephric duct. The point at which these two original epithelia meet is called the original squamocolumnar junction. New studies show, however, that all the cervical as well as large part of the vaginal epithelium are derived from M\u00fcllerian duct tissue and that phenotypic differences might be due to other causes.\nHistology.\nThe endocervical mucosa is about thick and lined with a single layer of columnar mucous cells. It contains numerous tubular mucous glands, which empty viscous alkaline mucus into the lumen. In contrast, the ectocervix is covered with nonkeratinized stratified squamous epithelium, which resembles the squamous epithelium lining the vagina. The junction between these two types of epithelia is called the squamocolumnar junction. Underlying both types of epithelium is a tough layer of collagen. The mucosa of the endocervix is not shed during menstruation. The cervix has more fibrous tissue, including collagen and elastin, than the rest of the uterus.\nIn prepubertal girls, the functional squamocolumnar junction is just within the cervical canal. Upon entering puberty, due to hormonal influence, and during pregnancy, the columnar epithelium extends outward over the ectocervix as the cervix everts. Hence, this also causes the squamocolumnar junction to move outwards onto the vaginal portion of the cervix, where it is exposed to the acidic vaginal environment. The exposed columnar epithelium can undergo physiological metaplasia and change to tougher metaplastic squamous epithelium in days or weeks, which is very similar to the original squamous epithelium when mature. The new squamocolumnar junction is therefore internal to the original squamocolumnar junction, and the zone of unstable epithelium between the two junctions is called the \"transformation zone\" of the cervix. Histologically, the transformation zone is generally defined as surface squamous epithelium with surface columnar epithelium or stromal glands/crypts, or both.\nAfter menopause, the uterine structures involute, and the functional squamocolumnar junction moves into the cervical canal.\nNabothian cysts (or Nabothian follicles) form in the transformation zone where the lining of metaplastic epithelium has replaced mucous epithelium and caused a strangulation of the outlet of some of the mucous glands. A buildup of mucus in the glands forms Nabothian cysts, usually less than about in diameter, which are considered physiological rather than pathological. Both gland openings and Nabothian cysts are helpful to identify the transformation zone.\nFunction.\nFertility.\nThe cervical canal is a pathway through which sperm enter the uterus after being induced by estradiol after penile-vaginal intercourse, and some forms of artificial insemination. Some sperm remains in cervical crypts, infoldings of the endocervix, which act as a reservoir, releasing sperm over several hours and maximising the chances of fertilisation. A theory states the cervical and uterine contractions during orgasm draw semen into the uterus. Although the \"upsuck theory\" has been generally accepted for some years, it has been disputed due to lack of evidence, small sample size, and methodological errors.\nSome methods of fertility awareness, such as the Creighton model and the Billings method involve estimating a woman's periods of fertility and infertility by observing physiological changes in her body. Among these changes are several involving the quality of her cervical mucus: the sensation it causes at the vulva, its elasticity (\"Spinnbarkeit\"), its transparency, and the presence of ferning.\nCervical mucus.\nSeveral hundred mucus-secreting crypts in the endocervix produce 20\u201360\u00a0mg of cervical mucus a day, increasing to 600\u00a0mg around the time of ovulation. The viscosity and water content vary during the menstrual cycle; cervical mucus is composed of around 93% water, reaching 98% at midcycle. It contains electrolytes such as calcium, sodium, and potassium; organic components such as glucose, amino acids, and soluble proteins; trace elements including zinc, copper, iron, manganese, and selenium; free fatty acids; enzymes such as amylase; and prostaglandins. Its consistency is determined by the influence of the hormones estrogen and progesterone. In the follicular phase of the menstrual cycle, estrogen dominates and cervical mucus gradually becomes thinner, hitting its lowest viscosity at ovulation. At midcycle, around the time of ovulation\u2014a period of high estrogen levels\u2014 the mucus is thin and serous to allow sperm to enter the uterus and is more alkaline and, hence, more hospitable to sperm. It is also higher in electrolytes, which results in the \"ferning\" pattern that can be observed in drying mucus under low magnification; as the mucus dries, the salts crystallize, resembling the leaves of a fern. The mucus has a stretchy character described as \"Spinnbarkeit\" most prominent around ovulation.\nAt other times in the cycle, the mucus is thick and more acidic due to the effects of progesterone. This \"infertile\" mucus acts as a barrier to keep sperm from entering the uterus. Women taking an oral contraceptive pill also have thick mucus from the effects of progesterone. Thick mucus also prevents pathogens from interfering with a nascent pregnancy.\nA cervical mucus plug, called the operculum, forms inside the cervical canal during pregnancy. This provides a protective seal for the uterus against the entry of pathogens and leakage of uterine fluids. The mucus plug is also known to have antibacterial properties. This plug is released as the cervix dilates, either during the first stage of childbirth or shortly before. It is visible as a blood-tinged mucous discharge.\nChildbirth.\nThe cervix plays a major role in childbirth. As the fetus descends within the uterus in preparation for birth, the presenting part, usually the head, rests on and is supported by the cervix. As labour progresses, the cervix becomes softer and shorter, begins to dilate, and withdraws to face the anterior of the body. The support the cervix provides to the fetal head starts to give way when the uterus begins its contractions. During childbirth, the cervix must dilate to a diameter of more than to accommodate the head of the fetus as it descends from the uterus to the vagina. In becoming wider, the cervix also becomes shorter, a phenomenon known as effacement.\nAlong with other factors, midwives and doctors use the extent of cervical dilation to assist decision-making during childbirth. Generally, the active first stage of labour, when the uterine contractions become strong and regular, begins when the cervical dilation is more than . The second phase of labor begins when the cervix has dilated to , which is regarded as its fullest dilation, and is when active pushing and contractions push the baby along the birth canal leading to the birth of the baby. The number of past vaginal deliveries is a strong factor in influencing how rapidly the cervix can dilate in labour. The time taken for the cervix to dilate and efface is one factor used in reporting systems such as the Bishop score, used to recommend whether interventions such as a forceps delivery, induction, or Caesarean section should be used in childbirth.\nCervical incompetence is a condition in which shortening of the cervix due to dilation and thinning occurs before term pregnancy. Short cervical length is the strongest predictor of preterm birth.\nContraception.\nSeveral methods of contraception involve the cervix. Cervical diaphragms are reusable, firm-rimmed plastic devices inserted by a woman before intercourse that cover the cervix. Pressure against the walls of the vagina maintain the position of the diaphragm, and it acts as a physical barrier to prevent the entry of sperm into the uterus, preventing fertilisation. Cervical caps are a similar method, although they are smaller and adhere to the cervix by suction. Diaphragms and caps are often used in conjunction with spermicides. In one year, 12% of women using the diaphragm will undergo an unintended pregnancy, and with optimal use this falls to 6%. Efficacy rates are lower for the cap, with 18% of women undergoing an unintended pregnancy, and 10\u201313% with optimal use. Most types of progestogen-only pills are effective as a contraceptive because they thicken cervical mucus, making it difficult for sperm to pass along the cervical canal. In addition, they may also sometimes prevent ovulation. In contrast, contraceptive pills that contain both oestrogen and progesterone, the combined oral contraceptive pills, work mainly by preventing ovulation. They also thicken cervical mucus and thin the lining of the uterus, enhancing their effectiveness.\nClinical significance.\nCancer.\nIn 2008, cervical cancer was the third-most common cancer in women worldwide, with rates varying geographically from less than one to more than 50 cases per 100,000 women. It is a leading cause of cancer-related death in poor countries, where delayed diagnosis leading to poor outcomes is common. The introduction of routine screening has resulted in fewer cases of (and deaths from) cervical cancer, however this has mainly taken place in developed countries. Most developing countries have limited or no screening, and 85% of the global burden occurs there.\nCervical cancer nearly always involves human papillomavirus (HPV) infection. HPV is a virus with numerous strains, several of which predispose to precancerous changes in the cervical epithelium, particularly in the transformation zone, which is the most common area for cervical cancer to start. HPV vaccines, such as Gardasil and Cervarix, reduce the incidence of cervical cancer, by inoculating against the viral strains involved in cancer development.\nPotentially precancerous changes in the cervix can be detected by cervical screening, using methods including a Pap smear (also called a cervical smear), in which epithelial cells are scraped from the surface of the cervix and examined under a microscope. The colposcope, an instrument used to see a magnified view of the cervix, was invented in 1925. The Pap smear was developed by Georgios Papanikolaou in 1928. A LEEP procedure using a heated loop of platinum to excise a patch of cervical tissue was developed by Aurel Babes in 1927. In some parts of the developed world, including the UK, the Pap test has been superseded with liquid-based cytology.\nAn inexpensive, cost-effective and practical alternative in poorer countries is visual inspection with acetic acid (VIA). Instituting and sustaining cytology-based programs in these regions can be difficult, due to the need for trained personnel, equipment and facilities and difficulties in follow-up. With VIA, results and treatment can be available on the same day. As a screening test, VIA is comparable to cervical cytology in accurately identifying precancerous lesions.\nA result of dysplasia is usually further investigated, such as by taking a cone biopsy, which may also remove the cancerous lesion. Cervical intraepithelial neoplasia is a possible result of the biopsy and represents dysplastic changes that may eventually progress to invasive cancer. Most cases of cervical cancer are detected in this way, without having caused any symptoms. When symptoms occur, they may include vaginal bleeding, discharge, or discomfort.\nInflammation.\nInflammation of the cervix is referred to as cervicitis. This inflammation may be of the endocervix or ectocervix. When associated with the endocervix, it is associated with a mucous vaginal discharge and sexually transmitted infections such as chlamydia and gonorrhoea. As many as half of pregnant women having a gonorrheal infection of the cervix are asymptomatic. Other causes include overgrowth of the commensal flora of the vagina. When associated with the ectocervix, inflammation may be caused by the herpes simplex virus. Inflammation is often investigated through directly visualising the cervix using a speculum, which may appear whiteish due to exudate, and by taking a Pap smear and examining for causal bacteria. Special tests may be used to identify particular bacteria. If the inflammation is due to a bacterium, then antibiotics may be given as treatment.\nAnatomical abnormalities.\nCervical stenosis is an abnormally narrow cervical canal, typically associated with trauma caused by removal of tissue for investigation or treatment of cancer, or cervical cancer itself. Diethylstilbestrol, used from 1938 to 1971 to prevent preterm labour and miscarriage, is also strongly associated with the development of cervical stenosis and other abnormalities in the daughters of the exposed women. Other abnormalities include: vaginal adenosis, in which the squamous epithelium of the ectocervix becomes columnar; cancers such as clear cell adenocarcinomas; cervical ridges and hoods; and development of a cockscomb cervix appearance, which is the condition wherein, as the name suggests, the cervix of the uterus is shaped like a cockscomb. About one-third of women born to diethylstilbestrol-treated mothers (i.e., in-utero exposure) develop a cockscomb cervix.\nEnlarged folds or ridges of cervical stroma (fibrous tissues) and epithelium constitute a cockscomb cervix. Similarly, cockscomb polyps lining the cervix are usually considered or grouped into the same overarching description. It is in and of itself considered a benign abnormality; its presence, however, is usually indicative of DES exposure, and as such, women who experience these abnormalities should be aware of their increased risk of associated pathologies.\nCervical agenesis is a rare congenital condition in which the cervix completely fails to develop, often associated with the concurrent failure of the vagina to develop. Other congenital cervical abnormalities exist, often associated with abnormalities of the vagina and uterus. The cervix may be duplicated in situations such as bicornuate uterus and uterine didelphys.\nCervical polyps, which are benign overgrowths of endocervical tissue, if present, may cause bleeding, or a benign overgrowth may be present in the cervical canal. Cervical ectropion refers to the horizontal overgrowth of the endocervical columnar lining in a one-cell-thick layer over the ectocervix.\nAnimals.\nFemale marsupials have paired uteri and cervices. Most eutherian (placental) mammal species have a single cervix and a single, bipartite or bicornuate uterus. Lagomorphs, rodents, aardvarks, and hyraxes have a duplex uterus and two cervices. Lagomorphs and rodents share many morphological characteristics and are grouped together in the clade Glires. Anteaters of the family Myrmecophagidae are unusual in that they lack a defined cervix; they are thought to have lost the characteristic rather than other mammals developing a cervix on more than one lineage. In domestic pigs, the cervix contains a series of five interdigitating pads that hold the boar's corkscrew-shaped penis during copulation.\nEtymology and pronunciation.\nThe word \"cervix\" () came to English from Latin , which means \"neck\". Like its English translation, the Latin word can refer not only to the neck [of the body], but also to an analogous narrowed part of an object. Thus, the term (literally \"neck of the uterus\") is used in Latin to refer to the uterine cervix, but in English, the word \"cervix\" used alone usually refers to it. The first attested use of the word in English to refer to the cervix of the uterus was in 1702. The adjective \"cervical\" may refer either to the neck (as in \"cervical vertebrae\" or \"cervical lymph nodes\") or to the uterine cervix (as in \"cervical cap\" or \"cervical cancer\").\nThe Latin word was in turn used to translate the Greek word (), \"neck\". The cervix was documented in anatomical literature in at least the time of Hippocrates; cervical cancer was first described more than 2,000 years ago, with descriptions provided by both Hippocrates and Aretaeus. Greek writers usually used the term () to refer to the cervical canal; however, there was some variation in the sense of these two words.\nReferences.\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "5739", "revid": "38717964", "url": "https://en.wikipedia.org/wiki?curid=5739", "title": "Compiler", "text": "Software that translates code from one programming language to another\nIn computing, a compiler is software that translates computer code written in one programming language (the \"source\" language) into another language (the \"target\" language). The name \"compiler\" is primarily used for programs that translate source code from a high-level programming language to a low-level programming language (e.g. assembly language, object code, or machine code) to create an executable program.\nThere are many different types of compilers which produce output in different useful forms. A \"cross-compiler\" produces code for a different CPU or operating system than the one on which the cross-compiler itself runs. A \"bootstrap compiler\" is often a temporary compiler, used for compiling a more permanent or better optimized compiler for a language.\nRelated software include \"decompilers\", programs that translate from low-level languages to higher level ones; programs that translate between high-level languages, usually called \"source-to-source compilers\" or \"transpilers\"; language \"rewriters\", usually programs that translate the form of expressions without a change of language; and \"compiler-compilers\", compilers that produce compilers (or parts of them), often in a generic and reusable way so as to be able to produce many differing compilers.\nA compiler is likely to perform some or all of the following operations, often called phases: preprocessing, lexical analysis, parsing, semantic analysis (syntax-directed translation), conversion of input programs to an intermediate representation, code optimization and machine specific code generation. Compilers generally implement these phases as modular components, promoting efficient design and correctness of transformations of source input to target output. Program faults caused by incorrect compiler behavior can be very difficult to track down and work around; therefore, compiler implementers invest significant effort to ensure compiler correctness.\nComparison with interpreter.\nWith respect to making source code runnable, an interpreter provides a similar function as a compiler, but via a different mechanism. An interpreter executes code without converting it to machine code. Therefore, some interpreters execute source code while others execute an intermediate form such as bytecode.\nHence a program compiled to native code tends to run faster than when interpreted. Environments with a bytecode-intermediate-form tends toward intermediate-speed. While Just-in-time compilation allows for native execution speed with a one-time startup processing time cost.\nFor low-level programming languages, such as assembly and C, it is typical that they are compiled, especially when speed is a significant concern, rather than being cross-platform supported. So that for such languages, there are more one-to-one correspondences between the source code and the resulting machine code, making it easier for programmers to control the use of hardware.\nIn theory; a programming language can be used via either a compiler or an interpreter, but in practice, each language tends to be used with only one or the other. Nonetheless, it is possible to write a compiler for a language that is commonly interpreted. For example, Common Lisp can be compiled to Java bytecode (and then interpreted by the Java virtual machine), as well as C code (then compiled to native machine code), or directly to native code.\nHistory.\nTheoretical computing concepts developed by scientists, mathematicians, and engineers formed the basis of digital modern computing development during World War II. Primitive binary languages evolved because digital devices only understand ones and zeros and the circuit patterns in the underlying machine architecture. In the late 1940s, assembly languages were created to offer a more workable abstraction of the computer architectures. Limited memory capacity of early computers led to substantial technical challenges when the first compilers were designed. Therefore, the compilation process needed to be divided into several small programs. The front end programs produce the analysis products used by the back end programs to generate target code. As computer technology provided more resources, compiler designs could align better with the compilation process.\nIt is usually more productive for a programmer to use a high-level language, so the development of high-level languages followed naturally from the capabilities offered by digital computers. High-level languages are formal languages that are strictly defined by their syntax and semantics which form the high-level language architecture. Elements of these formal languages include:\nThe sentences in a language may be defined by a set of rules called a grammar.\nBackus\u2013Naur form (BNF) describes the syntax of \"sentences\" of a language. It was developed by John Backus and used for the syntax of Algol 60. The ideas derive from the context-free grammar concepts by linguist Noam Chomsky. \"BNF and its extensions have become standard tools for describing the syntax of programming notations. In many cases, parts of compilers are generated automatically from a BNF description.\"\nBetween 1942 and 1945, Konrad Zuse designed the first (algorithmic) programming language for computers called (\"Plan Calculus\"). Zuse also envisioned a (\"Plan assembly device\") to automatically translate the mathematical formulation of a program into machine-readable punched film stock. While no actual implementation occurred until the 1970s, it presented concepts later seen in APL designed by Ken Iverson in the late 1950s. APL is a language for mathematical computations.\nBetween 1949 and 1951, Heinz Rutishauser proposed Superplan, a high-level language and automatic translator. His ideas were later refined by Friedrich L. Bauer and Klaus Samelson.\nHigh-level language design during the formative years of digital computing provided useful programming tools for a variety of applications:\nCompiler technology evolved from the need for a strictly defined transformation of the high-level source program into a low-level target program for the digital computer. The compiler could be viewed as a front end to deal with the analysis of the source code and a back end to synthesize the analysis into the target code. Optimization between the front end and back end could produce more efficient target code.\nSome early milestones in the development of compiler technology:\nEarly operating systems and software were written in assembly language. In the 1960s and early 1970s, the use of high-level languages for system programming was still controversial due to resource limitations. However, several research and industry efforts began the shift toward high-level systems programming languages, for example, BCPL, BLISS, B, and C.\nBCPL (Basic Combined Programming Language) designed in 1966 by Martin Richards at the University of Cambridge was originally developed as a compiler writing tool. Several compilers have been implemented, Richards' book provides insights to the language and its compiler. BCPL was not only an influential systems programming language that is still used in research but also provided a basis for the design of B and C languages.\nBLISS (Basic Language for Implementation of System Software) was developed for a Digital Equipment Corporation (DEC) PDP-10 computer by W. A. Wulf's Carnegie Mellon University (CMU) research team. The CMU team went on to develop BLISS-11 compiler one year later in 1970.\nMultics (Multiplexed Information and Computing Service), a time-sharing operating system project, involved MIT, Bell Labs, General Electric (later Honeywell) and was led by Fernando Corbat\u00f3 from MIT. Multics was written in the PL/I language developed by IBM and IBM User Group. IBM's goal was to satisfy business, scientific, and systems programming requirements. There were other languages that could have been considered but PL/I offered the most complete solution even though it had not been implemented. For the first few years of the Multics project, a subset of the language could be compiled to assembly language with the Early PL/I (EPL) compiler by Doug McIlory and Bob Morris from Bell Labs. EPL supported the project until a boot-strapping compiler for the full PL/I could be developed.\nBell Labs left the Multics project in 1969, and developed a system programming language B based on BCPL concepts, written by Dennis Ritchie and Ken Thompson. Ritchie created a boot-strapping compiler for B and wrote Unics (Uniplexed Information and Computing Service) operating system for a PDP-7 in B. Unics eventually became spelled Unix.\nBell Labs started the development and expansion of C based on B and BCPL. The BCPL compiler had been transported to Multics by Bell Labs and BCPL was a preferred language at Bell Labs. Initially, a front-end program to Bell Labs' B compiler was used while a C compiler was developed. In 1971, a new PDP-11 provided the resource to define extensions to B and rewrite the compiler. By 1973 the design of C language was essentially complete and the Unix kernel for a PDP-11 was rewritten in C. Steve Johnson started development of Portable C Compiler (PCC) to support retargeting of C compilers to new machines.\nObject-oriented programming (OOP) offered some interesting possibilities for application development and maintenance. OOP concepts go further back but were part of LISP and Simula language science. Bell Labs became interested in OOP with the development of C++. C++ was first used in 1980 for systems programming. The initial design leveraged C language systems programming capabilities with Simula concepts. Object-oriented facilities were added in 1983. The Cfront program implemented a C++ front-end for C84 language compiler. In subsequent years several C++ compilers were developed as C++ popularity grew.\nIn many application domains, the idea of using a higher-level language quickly caught on. Because of the expanding functionality supported by newer programming languages and the increasing complexity of computer architectures, compilers became more complex.\nDARPA (Defense Advanced Research Projects Agency) sponsored a compiler project with Wulf's CMU research team in 1970. The Production Quality Compiler-Compiler PQCC design would produce a Production Quality Compiler (PQC) from formal definitions of source language and the target. PQCC tried to extend the term compiler-compiler beyond the traditional meaning as a parser generator (e.g., Yacc) without much success. PQCC might more properly be referred to as a compiler generator.\nPQCC research into code generation process sought to build a truly automatic compiler-writing system. The effort discovered and designed the phase structure of the PQC. The BLISS-11 compiler provided the initial structure. The phases included analyses (front end), intermediate translation to virtual machine (middle end), and translation to the target (back end). TCOL was developed for the PQCC research to handle language specific constructs in the intermediate representation. Variations of TCOL supported various languages. The PQCC project investigated techniques of automated compiler construction. The design concepts proved useful in optimizing compilers and compilers for the (since 1995, object-oriented) programming language Ada.\nThe Ada \"STONEMAN\" document formalized the program support environment (APSE) along with the kernel (KAPSE) and minimal (MAPSE). An Ada interpreter NYU/ED supported development and standardization efforts with the American National Standards Institute (ANSI) and the International Standards Organization (ISO). Initial Ada compiler development by the U.S. Military Services included the compilers in a complete integrated design environment along the lines of the \"STONEMAN\" document. Army and Navy worked on the Ada Language System (ALS) project targeted to DEC/VAX architecture while the Air Force started on the Ada Integrated Environment (AIE) targeted to IBM 370 series. While the projects did not provide the desired results, they did contribute to the overall effort on Ada development.\nOther Ada compiler efforts got underway in Britain at the University of York and in Germany at the University of Karlsruhe. In the U. S., Verdix (later acquired by Rational) delivered the Verdix Ada Development System (VADS) to the Army. VADS provided a set of development tools including a compiler. Unix/VADS could be hosted on a variety of Unix platforms such as DEC Ultrix and the Sun 3/60 Solaris targeted to Motorola 68020 in an Army CECOM evaluation. There were soon many Ada compilers available that passed the Ada Validation tests. The Free Software Foundation GNU project developed the GNU Compiler Collection (GCC) which provides a core capability to support multiple languages and targets. The Ada version GNAT is one of the most widely used Ada compilers. GNAT is free but there is also commercial support, for example, AdaCore, was founded in 1994 to provide commercial software solutions for Ada. GNAT Pro includes the GNU GCC based GNAT with a tool suite to provide an integrated development environment.\nHigh-level languages continued to drive compiler research and development. Focus areas included optimization and automatic code generation. Trends in programming languages and development environments influenced compiler technology. More compilers became included in language distributions (PERL, Java Development Kit) and as a component of an IDE (VADS, Eclipse, Ada Pro). The interrelationship and interdependence of technologies grew. The advent of web services promoted growth of web languages and scripting languages. Scripts trace back to the early days of Command Line Interfaces (CLI) where the user could enter commands to be executed by the system. User Shell concepts developed with languages to write shell programs. Early Windows designs offered a simple batch programming capability. The conventional transformation of these language used an interpreter. While not widely used, Bash and Batch compilers have been written. More recently sophisticated interpreted languages became part of the developers tool kit. Modern scripting languages include PHP, Python, Ruby and Lua. (Lua is widely used in game development.) All of these have interpreter and compiler support.\n\"When the field of compiling began in the late 50s, its focus was limited to the translation of high-level language programs into machine code ... The compiler field is increasingly intertwined with other disciplines including computer architecture, programming languages, formal methods, software engineering, and computer security.\" The \"Compiler Research: The Next 50 Years\" article noted the importance of object-oriented languages and Java. Security and parallel computing were cited among the future research targets.\nCompiler construction.\nA compiler implements a formal transformation from a high-level source program to a low-level target program. Compiler design can define an end-to-end solution or tackle a defined subset that interfaces with other compilation tools e.g. preprocessors, assemblers, linkers. Design requirements include rigorously defined interfaces both internally between compiler components and externally between supporting toolsets.\nIn the early days, the approach taken to compiler design was directly affected by the complexity of the computer language to be processed, the experience of the person(s) designing it, and the resources available. Resource limitations led to the need to pass through the source code more than once.\nA compiler for a relatively simple language written by one person might be a single, monolithic piece of software. However, as the source language grows in complexity the design may be split into a number of interdependent phases. Separate phases provide design improvements that focus development on the functions in the compilation process.\nOne-pass vs multi-pass compilers.\nClassifying compilers by number of passes has its background in the hardware resource limitations of computers. Compiling involves performing much work and early computers did not have enough memory to contain one program that did all of this work. As a result, compilers were split up into smaller programs which each made a pass over the source (or some representation of it) performing some of the required analysis and translations.\nThe ability to compile in a single pass has classically been seen as a benefit because it simplifies the job of writing a compiler and one-pass compilers generally perform compilations faster than multi-pass compilers. Thus, partly driven by the resource limitations of early systems, many early languages were specifically designed so that they could be compiled in a single pass (e.g., Pascal).\nIn some cases, the design of a language feature may require a compiler to perform more than one pass over the source. For instance, consider a declaration appearing on line 20 of the source which affects the translation of a statement appearing on line 10. In this case, the first pass needs to gather information about declarations appearing after statements that they affect, with the actual translation happening during a subsequent pass.\nThe disadvantage of compiling in a single pass is that it is not possible to perform many of the sophisticated optimizations needed to generate high quality code. It can be difficult to count exactly how many passes an optimizing compiler makes. For instance, different phases of optimization may analyse one expression many times but only analyse another expression once.\nSplitting a compiler up into small programs is a technique used by researchers interested in producing provably correct compilers. Proving the correctness of a set of small programs often requires less effort than proving the correctness of a larger, single, equivalent program.\nThree-stage compiler structure.\nRegardless of the exact number of phases in the compiler design, the phases can be assigned to one of three stages. The stages include a front end, a middle end, and a back end.\nThis front/middle/back-end approach makes it possible to combine front ends for different languages with back ends for different CPUs while sharing the optimizations of the middle end. Practical examples of this approach are the GNU Compiler Collection, Clang (LLVM-based C/C++ compiler), and the Amsterdam Compiler Kit, which have multiple front-ends, shared optimizations and multiple back-ends.\nFront end.\nThe front end analyzes the source code to build an internal representation of the program, called the intermediate representation (IR). It also manages the symbol table, a data structure mapping each symbol in the source code to associated information such as location, type and scope.\nWhile the frontend can be a single monolithic function or program, as in a scannerless parser, it was traditionally implemented and analyzed as several phases, which may execute sequentially or concurrently. This method is favored due to its modularity and separation of concerns. Most commonly, the frontend is broken into three phases: lexical analysis (also known as lexing or scanning), syntax analysis (also known as scanning or parsing), and semantic analysis. Lexing and parsing comprise the syntactic analysis (word syntax and phrase syntax, respectively), and in simple cases, these modules (the lexer and parser) can be automatically generated from a grammar for the language, though in more complex cases these require manual modification. The lexical grammar and phrase grammar are usually context-free grammars, which simplifies analysis significantly, with context-sensitivity handled at the semantic analysis phase. The semantic analysis phase is generally more complex and written by hand, but can be partially or fully automated using attribute grammars. These phases themselves can be further broken down: lexing as scanning and evaluating, and parsing as building a concrete syntax tree (CST, parse tree) and then transforming it into an abstract syntax tree (AST, syntax tree). In some cases additional phases are used, notably \"line reconstruction\" and \"preprocessing,\" but these are rare.\nThe main phases of the front end include the following:\nMiddle end.\nThe middle end, also known as \"optimizer,\" performs optimizations on the intermediate representation in order to improve the performance and the quality of the produced machine code. The middle end contains those optimizations that are independent of the CPU architecture being targeted.\nThe main phases of the middle end include the following:\nCompiler analysis is the prerequisite for any compiler optimization, and they tightly work together. For example, dependence analysis is crucial for loop transformation.\nThe scope of compiler analysis and optimizations vary greatly; their scope may range from operating within a basic block, to whole procedures, or even the whole program. There is a trade-off between the granularity of the optimizations and the cost of compilation. For example, peephole optimizations are fast to perform during compilation but only affect a small local fragment of the code, and can be performed independently of the context in which the code fragment appears. In contrast, interprocedural optimization requires more compilation time and memory space, but enable optimizations that are only possible by considering the behavior of multiple functions simultaneously.\nInterprocedural analysis and optimizations are common in modern commercial compilers from HP, IBM, SGI, Intel, Microsoft, and Sun Microsystems. The free software GCC was criticized for a long time for lacking powerful interprocedural optimizations, but it is changing in this respect. Another open source compiler with full analysis and optimization infrastructure is Open64, which is used by many organizations for research and commercial purposes.\nDue to the extra time and space needed for compiler analysis and optimizations, some compilers skip them by default. Users have to use compilation options to explicitly tell the compiler which optimizations should be enabled.\nBack end.\nThe back end is responsible for the CPU architecture specific optimizations and for code generation.\nThe main phases of the back end include the following:\nCompiler correctness.\nCompiler correctness is the branch of software engineering that deals with trying to show that a compiler behaves according to its language specification. Techniques include developing the compiler using formal methods and using rigorous testing (often called compiler validation) on an existing compiler.\nCompiled vis-\u00e0-vis interpreted languages.\nHigher-level programming languages usually appear with a type of translation in mind: either designed as compiled language or interpreted language. However, in practice there is rarely anything about a language that \"requires\" it to be exclusively compiled or exclusively interpreted, although it is possible to design languages that rely on re-interpretation at run time. The categorization usually reflects the most popular or widespread implementations of a language \u2013 for instance, BASIC is sometimes called an interpreted language, and C a compiled one, despite the existence of BASIC compilers and C interpreters.\nInterpretation does not replace compilation completely. It only hides it from the user and makes it gradual. Even though an interpreter can itself be interpreted, a set of directly executed machine instructions is needed somewhere at the bottom of the execution stack (see machine language).\nFurthermore, for optimization compilers can contain interpreter functionality, and interpreters may include ahead of time compilation techniques. For example, where an expression can be executed during compilation and the results inserted into the output program, then it prevents it having to be recalculated each time the program runs, which can greatly speed up the final program. Modern trends toward just-in-time compilation and bytecode interpretation at times blur the traditional categorizations of compilers and interpreters even further. Meta-tracing is an automated compiler synthesis approach which takes this further and can be used to synthesize a compiler from a language interpreter.\nSome language specifications spell out that implementations \"must\" include a compilation facility; for example, Common Lisp. However, there is nothing inherent in the definition of Common Lisp that stops it from being interpreted. Other languages have features that are very easy to implement in an interpreter, but make writing a compiler much harder; for example, APL, SNOBOL4, and many scripting languages allow programs to construct arbitrary source code at runtime with regular string operations, and then execute that code by passing it to a special evaluation function. To implement these features in a compiled language, programs must usually be shipped with a runtime library that includes a version of the compiler itself.\nTypes.\nOne classification of compilers is by the platform on which their generated code executes. This is known as the \"target platform.\"\nA \"native\" or \"hosted\" compiler is one whose output is intended to directly run on the same type of computer and operating system that the compiler itself runs on. The output of a cross compiler is designed to run on a different platform. Cross compilers are often used when developing software for embedded systems that are not intended to support a software development environment.\nThe output of a compiler that produces code for a virtual machine (VM) may or may not be executed on the same platform as the compiler that produced it. For this reason, such compilers are not usually classified as native or cross compilers.\nThe lower level language that is the target of a compiler may itself be a high-level programming language. C, viewed by some as a sort of portable assembly language, is frequently the target language of such compilers. For example, Cfront, the original compiler for C++, used C as its target language. The C code generated by such a compiler is usually not intended to be readable and maintained by humans, so indent style and creating pretty C intermediate code are ignored. Some of the features of C that make it a good target language include the codice_1 directive, which can be generated by the compiler to support debugging of the original source, and the wide platform support available with C compilers.\nWhile a common compiler type outputs machine code, there are many other types:\n\"Assemblers,\" which translate human readable assembly language to the machine code instructions executed by hardware, are not considered compilers. (The inverse program that translates machine code to assembly language is called a disassembler.)\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nNotes and references.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "5741", "revid": "269251", "url": "https://en.wikipedia.org/wiki?curid=5741", "title": "Monetary policy of central banks", "text": ""}
{"id": "5742", "revid": "41526883", "url": "https://en.wikipedia.org/wiki?curid=5742", "title": "Castrato", "text": "Male singer who is castrated to maintain a high voice\nA castrato (Italian; pl.: castrati) is a male singer who underwent castration before puberty in order to retain a singing voice equivalent to that of a soprano, mezzo-soprano, or contralto. The voice can also occur in one who, due to an endocrinological condition, never reaches sexual maturity.\nCastration before puberty (or in its early stages) prevents the larynx from being transformed by the normal physiological events of puberty. As a result, the vocal range of prepubescence (shared by both sexes) is largely retained, and the voice develops into adulthood in a unique way. Prepubescent castration for this purpose diminished greatly in the late 18th century.\nMethods of castration used to terminate the onset of puberty varied. Methods involved using opium to medically induce a coma, then submerging the boy into an ice or milk bath where the procedure of either twisting the testicles until they atrophied, or complete removal via surgical cutting was performed (however the complete removal of the testicles was not a popularly used technique). The procedure was usually done to boys around the age of 8\u201310; recovery time from the procedure took around two weeks. The means by which future singers were prepared could lead to premature death. To prevent the child from experiencing the intense pain of castration, many were inadvertently administered lethal doses of opium or some other narcotic, or were killed by overlong compression of the carotid artery in the neck (intended to render them unconscious during the castration procedure). \nThe geographical locations of where these procedures took place is not known specifically. During the 18th century, the music historian Charles Burney was sent from pillar to post in search of places where the operation was carried out: I enquired throughout Italy at what place boys were chiefly qualified for singing by castration, but could get no certain intelligence. I was told at Milan that it was at Venice; at Venice that it was at Bologna; but at Bologna the fact was denied, and I was referred to Florence; from Florence to Rome, and from Rome I was sent to Naples. The operation most certainly is against the law in all these places, as well as against nature; and all the Italians are so much ashamed of it, that in every province they transfer it some other.\nAs a castrato's body grew, his lack of testosterone meant that his epiphyses (bone-joints) did not harden in the normal manner. Thus, the limbs of the castrati often grew unusually long, as did their ribs. This, combined with intensive training, gave them unrivaled lung power and breath capacity. Operating through small, child-sized vocal cords, their voices were also extraordinarily flexible, and quite different from the equivalent adult female voice. Their vocal range was higher than that of the uncastrated adult male. Listening to the only surviving recordings of a castrato (see below), one can hear that the lower part of the voice sounds like a \"super-high\" tenor, with a more falsetto-like upper register above that.\nCastrati were rarely referred to as such: in the 18th century, the euphemism \"musico\" (pl.: \"musici\") was much more generally used, although it usually carried derogatory implications; another synonym was \"evirato\", literally meaning \"emasculated\". Eunuch is a more general term since, historically, many eunuchs were castrated after puberty and thus the castration had no effect on their voices.\nHistory.\nCastration as a means of subjugation, enslavement or other punishment has a very long history, dating back to ancient Sumer. In a Western context, eunuch singers are known to have existed from the early Byzantine Empire. In Constantinople around 400 AD, the empress Aelia Eudoxia had a eunuch choir-master, Brison, who may have established the use of castrati in Byzantine choirs, though whether Brison himself was a singer and whether he had colleagues who were eunuch singers is not certain. By the 9th century, eunuch singers were well-known (most in the choir of Hagia Sophia) and remained so until the sack of Constantinople by the Western forces of the Fourth Crusade in 1204. Their fate from then until their reappearance in Italy more than three hundred years later is not clear. It seems likely that the Spanish tradition of soprano falsettists may have hidden castrati. Much of Spain was under Muslim rulers during the Middle Ages, and castration had a history going back to the ancient Near East. Stereotypically, eunuchs served as harem guards, but they were also valued as high-level political appointees since they could not start a dynasty which would threaten the ruler.\nEuropean classical tradition.\nCastrati first appeared in Italy in the mid-16th century, though at first the terms describing them were not always clear. The phrase \"soprano maschio\" (male soprano), which could also mean falsettist, occurs in the \"Due Dialoghi della Musica\" (Two dialogues upon music) of Luigi Dentice, an Oratorian priest, published in Rome in 1553. On 9 November 1555 Cardinal Ippolito II d'Este (famed as the builder of the Villa d'Este at Tivoli), wrote to Guglielmo Gonzaga, Duke of Mantua (1538\u20131587), that he has heard that the Duke was interested in his \"cantoretti\" (little singers) and offered to send him two, so that he could choose one for his own service. This is a rare term but probably does equate to \"castrato\". The Cardinal's nephew, Alfonso II d'Este, Duke of Ferrara, was another early enthusiast, inquiring about castrati in 1556. There were certainly castrati in the Sistine Chapel choir in 1558, although not described as such: on 27 April of that year, Hernando Bustamante, a Spaniard from Palencia, was admitted (the first castrati so termed who joined the Sistine choir were Pietro Paolo Folignato and Girolamo Rossini, admitted in 1599). Surprisingly, considering the later French distaste for castrati, they certainly existed in France at this time also, being known of in Paris, Orl\u00e9ans, Picardy and Normandy, though they were not abundant: the King of France himself had difficulty in obtaining them. By 1574, there were castrati in the Ducal court chapel at Munich, where the Kapellmeister (music director) was the famous Orlando di Lasso. In 1589, by the bull \"Cum pro nostro pastorali munere\", Pope Sixtus V re-organised the choir of St Peter's, Rome specifically to include castrati.\nThus the castrati came to supplant both boys (whose voices broke after only a few years) and falsettists (whose voices were weaker and less reliable) from the top line in such choirs. Women were banned by the Pauline dictum \"mulieres in ecclesiis taceant\" (\"let women keep silent in the churches\"; see I Corinthians, ch. 14, v. 34).\nThe Italian castrati were often rumored to have unusually long lives, but a 1993 study found that their lifespans were average.\nOpera.\nAlthough the castrato (or musico) predates opera, there is some evidence that castrati had parts in the earliest operas. In the first performance of Monteverdi's \"Orfeo\" (1607), for example, they played subsidiary roles, including Speranza and (possibly) that of Euridice. Although female roles were performed by castrati in some of the papal states, this was increasingly rare; by 1680, they had supplanted normal male voices in lead roles, and retained their position as \"primo uomo\" for about a hundred years; an Italian opera not featuring at least one renowned castrato in a lead part would be doomed to fail. Because of the popularity of Italian opera throughout 18th-century Europe (except France), singers such as Ferri, Farinelli, Senesino and Pacchierotti became the first operatic superstars, earning enormous fees and hysterical public adulation. The strictly hierarchical organisation of \"opera seria\" favoured their high voices as symbols of heroic virtue, though they were frequently mocked for their strange appearance and bad acting. In his 1755 \"Reflections upon theatrical expression in tragedy\", Roger Pickering wrote:\nFarinelli drew every Body to the Haymarket. What a Pipe! What Modulation! What Extasy to the Ear! But, Heavens! What Clumsiness! What Stupidity! What Offence to the Eye! Reader, if of the City, thou mayest probably have seen in the Fields of Islington or Mile-End or, If thou art in the environs of St James', thou must have observed in the Park with what Ease and Agility a cow, heavy with calf, has rose up at the command of the Milk-woman's foot: thus from the mossy bank sprang the DIVINE FARINELLI.The training of the boys was rigorous. The regimen of one singing school in Rome (c. 1700) consisted of one hour of singing difficult and awkward pieces, one hour practising trills, one hour practising ornamented passaggi, one hour of singing exercises in their teacher's presence and in front of a mirror so as to avoid unnecessary movement of the body or facial grimaces, and one hour of literary study; all this, moreover, before lunch. After, half an hour would be devoted to musical theory, another to writing counterpoint, an hour copying down the same from dictation, and another hour of literary study. During the remainder of the day, the young castrati had to find time to practice their harpsichord playing, and to compose vocal music, either sacred or secular depending on their inclination. This demanding schedule meant that, if sufficiently talented, they were able to make a debut in their mid-teens with a perfect technique and a voice of a flexibility and power no woman or ordinary male singer could match.\nMany castrati came from poor homes and were castrated by their parents in the hope that their child might be successful and lift them from poverty (this was the case with Senesino). There are, though, records of some young boys asking to be operated on to preserve their voices (e.g. Caffarelli, who was from a wealthy family: his grandmother gave him the income from two vineyards to pay for his studies). Caffarelli was also typical of many castrati in being famous for tantrums on and off-stage, and for amorous adventures with noble ladies. Some, as described by Casanova, preferred gentlemen (noble or otherwise).\nAccording to John Rosselli, the total number of castrati alive at any given time during the height of their existence cannot be ascertained. He estimates that \"several hundred\" of them existed at any given time between 1630 and 1750. Approximately 100 existed in Rome in 1694, but the possibility that was a decline from earlier in the century cannot be ruled out. Only a small percentage of boys castrated to preserve their voices had successful careers on the operatic stage; the better \"also-rans\" sang in cathedral or church choirs, but because of their marked appearance and the ban on their marrying, there was little room for them in society outside a musical context.\nThe castrati came in for a great amount of scurrilous and unkind abuse, and as their fame increased, so did the hatred of them. They were often castigated as malign creatures who lured men into homosexuality. There were homosexual castrati, as Casanova's accounts of 18th-century Italy bear witness. He mentions meeting an abb\u00e9 whom he took for a girl in disguise, only later discovering that \"she\" was a famous castrato. In Rome in 1762 he attended a performance at which the prima donna was a castrato, \"the favourite pathic\" of Cardinal Borghese, who dined every evening with his protector. From his behaviour on stage \"it was obvious that he hoped to inspire the love of those who liked him as a man, and probably would not have done so as a woman\".\nDecline.\nBy the late 18th century, changes in operatic taste and social attitudes spelled the end for castrati. They lingered on past the end of the \"ancien r\u00e9gime\", which their style of opera parallels, and two of their number, Pacchierotti and Crescentini, performed before Napoleon. The last great operatic castrato was Giovanni Battista Velluti (1781\u20131861), who performed the last operatic castrato role ever written: Armando in \"Il crociato in Egitto\" by Meyerbeer (Venice, 1824). Soon after this they were replaced definitively as the first men of the operatic stage by a new breed of heroic tenor, as first incarnated by the Frenchman Gilbert-Louis Duprez, the earliest so-called \"king of the high Cs\". His successors have included such singers as Enrico Tamberlik, Jean de Reszke, Francesco Tamagno, Enrico Caruso, Giovanni Martinelli, Beniamino Gigli, Jussi Bj\u00f6rling, Franco Corelli and Luciano Pavarotti, among others.\nAfter the unification of Italy in 1861, \"eviration\" was officially made illegal, as the new Italian state had adopted the previous penal code of the Kingdom of Sardinia, which expressly forbade the practice. In 1878, Pope Leo XIII prohibited the hiring of new castrati by the church: only in the Sistine Chapel and in other papal basilicas in Rome did a few castrati linger. A group photo of the Sistine Choir taken in 1898 shows that by then only six remained, plus the \"Direttore Perpetuo\", the fine soprano castrato Domenico Mustaf\u00e0. In 1902, a ruling was extracted from Pope Leo that no further castrati should be admitted. The official end to the castrati came on St. Cecilia's Day, 22 November 1903, when the new pope, Pius X, issued his \"motu proprio\", \"Tra le Sollecitudini\" (\"Amongst the Cares\"), which contained this instruction: \"Whenever\u00a0... it is desirable to employ the high voices of sopranos and contraltos, these parts must be taken by boys, according to the most ancient usage of the Church.\"\nThe last Sistine castrato to survive was Alessandro Moreschi, the only castrato to have made solo recordings. While an interesting historical record, these discs of his give us only a glimpse of the castrato voice. Although he had been renowned as \"The Angel of Rome\" at the beginning of his career, some would say he was past his prime when the recordings were made in 1902 and 1904 and he never attempted to sing opera. Domenico Salvatori, a castrato who was contemporary with Moreschi, made some ensemble recordings with him but has no surviving solo recordings. The recording technology of the day was not of modern high quality. Salvatori died in 1909; Moreschi retired officially in March 1913, and died in 1922.\nThe Catholic Church's involvement in the castrato phenomenon has long been controversial, and there have recently been calls for it to issue an official apology for its role. As early as 1748, Pope Benedict XIV tried to ban castrati from churches, but such was their popularity at the time that he realised that doing so might result in a drastic decline in church attendance.\nThe rumours of another castrato sequestered in the Vatican for the personal delectation of the Pontiff until as recently as 1959 have been proven false. The singer in question was a pupil of Moreschi's, Domenico Mancini, such a successful imitator of his teacher's voice that even Lorenzo Perosi, Direttore Perpetuo of the Sistine Choir from 1898 to 1956 and a strenuous opponent of the practice of castrato singers, thought he was a castrato. Mancini was in fact a moderately skillful falsettist and professional double bass player.\nModern castrati and similar voices.\nA male can retain his child voice if it never changes during puberty. The retained voice can be the treble voice shared by both sexes in childhood and is the same as a boy soprano voice. But as evidence shows, many castrati, such as Senesino and Caffarelli, were actually altos (mezzo-soprano) \u2013 not sopranos. So-called \"natural\" or \"endocrinological castrati\" are born with hormonal anomalies, such as Klinefelter's syndrome and Kallmann's syndrome, or have undergone unusual physical or medical events during their early lives that reproduce the vocal effects of castration without being castrated.\nJimmy Scott, Radu Marian and Javier Medina are examples of this type of high male voice via endocrinological conditions. Michael Maniaci is somewhat different, in that he has no hormonal or other anomalies, but claims that his voice did not \"break\" in the usual manner, leaving him still able to sing in the soprano register. Other uncastrated male adults sing soprano, generally using some form of falsetto but in a much higher range than most countertenors. Examples are Aris Christofellis, J\u00f6rg Waschinski, and Ghio Nannini.\nHowever, it is believed the castrati possessed more of a tenorial chest register (the aria \"Navigante che non spera\" in Leonardo Vinci's opera \"Il Medo\", written for Farinelli, requires notes down to C3, 131\u00a0Hz). Similar low-voiced singing can be heard from the jazz vocalist Jimmy Scott, whose range matches approximately that used by female blues singers. High-pitched singer Jordan Smith has demonstrated having more of a tenorial chest register.\nActor Chris Colfer has stated in interviews that when his voice began to change at puberty, he sang in a high voice \"constantly\" in an effort to retain his range. Actor and singer Alex Newell has soprano range. Voice actor Walter Tetley may or may not have been a \"castrato\"; Bill Scott, a co-worker of Tetley's during their later work in television, once half-jokingly quipped that Tetley's mother \"had him fixed\" to protect the child star's voice-acting career. Tetley never did personally divulge the exact reason for his condition, which left him with the voice of a preteen boy for his entire adult life. Botanist George Washington Carver was noted for his high voice, believed to be the result of pertussis and croup infections in his childhood that stunted his growth.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "5743", "revid": "27823944", "url": "https://en.wikipedia.org/wiki?curid=5743", "title": "Counting-out game", "text": "Children's method of selecting a person\nA counting-out game or counting-out rhyme is a simple method of 'randomly' selecting a person from a group, often used by children for the purpose of playing another game. It usually requires no materials, and is achieved with spoken words or hand gestures. The historian Henry Carrington Bolton suggested in his 1888 book \"Counting Out Rhymes of Children\" that the custom of counting out originated in the \"superstitious practices of divination by lots.\"\nMany such methods involve one person pointing at each participant in a circle of players while reciting a rhyme. A new person is pointed at as each word is said. The player who is selected at the conclusion of the rhyme is \"it\" or \"out\". In an alternate version, the circle of players may each put two feet in and at the conclusion of the rhyme, that player removes one foot and the rhyme starts over with the next person. In this case, the first player that has both feet removed is \"it\" or \"out\". In theory the result of a counting rhyme is determined entirely by the starting selection (and would result in a modulo operation), but in practice they are often accepted as random selections because the number of words has not been calculated beforehand, so the result is unknown until someone is selected.\nA variant of counting-out game, known as the Josephus problem, represents a famous theoretical problem in mathematics and computer science.\nExamples.\nSeveral simple games can be played to select one person from a group, either as a straightforward winner, or as someone who is eliminated. Rock, Paper, Scissors, Odd or Even and Blue Shoe require no materials and are played using hand gestures, although with the former it is possible for a player to win or lose through skill rather than luck. Coin flipping and drawing straws are fair methods of randomly determining a player. Fizz Buzz is a spoken word game where if a player slips up and speaks a word out of sequence, they are eliminated.\nCultural references.\nMarx Brothers.\nA scene in the Marx Brothers movie \"Duck Soup\" plays on the fact that counting-out games are not really random. Faced with selecting someone to go on a dangerous mission, the character Chicolini (Chico Marx) chants:\n\"Rrringspot, vonza, twoza, zig-zag-zav, popti, vinaga, [tin-lie, tav,] harem, scarem, merchan, tarem, teir, tore...\"\nonly to stop as he realizes he is about to select himself. He then says, \"I did it wrong. Wait, wait, I start here\", and repeats the chant\u2014with the same result. After that, he says, \"That's no good too. I got it!\" and reduces the chant to\n\"Rrringspot, buck!\"\nAnd with this version he finally manages to \"randomly\" select someone else.\nSeinfeld.\nA version of a counting game \"ink-a-dink\" features in the \"Seinfeld\" episode \"The Statue.\" The relevant scene includes a discussion between the characters of Jerry and George if the person who is \"it\" is the \"winner\" or the \"loser\": \n JERRY: Alright, let's go. Hey, you know, you owe me one.\n GEORGE: What?\n JERRY: The Ink-a-dink.. you were \"It\".\n GEORGE: \"It\"'s bad?\n JERRY: \"It\"'s very bad.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "5746", "revid": "6917124", "url": "https://en.wikipedia.org/wiki?curid=5746", "title": "Cryptography/Hashfunction", "text": ""}
{"id": "5747", "revid": "36767729", "url": "https://en.wikipedia.org/wiki?curid=5747", "title": "Cryptography/Key", "text": ""}
{"id": "5749", "revid": "27015025", "url": "https://en.wikipedia.org/wiki?curid=5749", "title": "Key size", "text": "Number of bits in a key used by a cryptographic algorithm\nIn cryptography, key size or key length refers to the number of bits in a key used by a cryptographic algorithm (such as a cipher).\nKey length defines the upper-bound on an algorithm's security (i.e. a logarithmic measure of the fastest known attack against an algorithm), because the security of all algorithms can be violated by brute-force attacks. Ideally, the lower-bound on an algorithm's security is by design equal to the key length (that is, the algorithm's design does not detract from the degree of security inherent in the key length).\nMost symmetric-key algorithms are designed to have security equal to their key length. However, after design, a new attack might be discovered. For instance, Triple DES was designed to have a 168-bit key, but an attack of complexity 2112 is now known (i.e. Triple DES now only has 112 bits of security, and of the 168 bits in the key the attack has rendered 56 'ineffective' towards security). Nevertheless, as long as the security (understood as \"the amount of effort it would take to gain access\") is sufficient for a particular application, then it does not matter if key length and security coincide. This is important for asymmetric-key algorithms, because no such algorithm is known to satisfy this property; elliptic curve cryptography comes the closest with an effective security of roughly half its key length.\nSignificance.\nKeys are used to control the operation of a cipher so that only the correct key can convert encrypted text (ciphertext) to plaintext. All commonly used ciphers are based on publicly known algorithms or are open source and so it is only the difficulty of obtaining the key that determines security of the system, provided that there is no analytic attack (i.e. a \"structural weakness\" in the algorithms or protocols used), and assuming that the key is not otherwise available (such as via theft, extortion, or compromise of computer systems). The widely accepted notion that the security of the system should depend on the key alone has been explicitly formulated by Auguste Kerckhoffs (in the 1880s) and Claude Shannon (in the 1940s); the statements are known as Kerckhoffs' principle and Shannon's Maxim respectively.\nA key should, therefore, be large enough that a brute-force attack (possible against any encryption algorithm) is infeasible \u2013 i.e. would take too long and/or would take too much memory to execute. Shannon's work on information theory showed that to achieve so-called 'perfect secrecy', the key length must be at least as large as the message and only used once (this algorithm is called the one-time pad). In light of this, and the practical difficulty of managing such long keys, modern cryptographic practice has discarded the notion of perfect secrecy as a requirement for encryption, and instead focuses on computational security, under which the computational requirements of breaking an encrypted text must be infeasible for an attacker.\nKey size and encryption system.\nEncryption systems are often grouped into families. Common families include symmetric systems (e.g. AES) and asymmetric systems (e.g. RSA and Elliptic-curve cryptography [ECC]). They may be grouped according to the central algorithm used (e.g. ECC and Feistel ciphers). Because each of these has a different level of cryptographic complexity, it is usual to have different key sizes for the same level of security, depending upon the algorithm used. For example, the security available with a 1024-bit key using asymmetric RSA is considered approximately equal in security to an 80-bit key in a symmetric algorithm.\nThe actual degree of security achieved over time varies, as more computational power and more powerful mathematical analytic methods become available. For this reason, cryptologists tend to look at indicators that an algorithm or key length shows signs of potential vulnerability, to move to longer key sizes or more difficult algorithms. For example, as of \u00a02007[ [update]], a 1039-bit integer was factored with the special number field sieve using 400 computers over 11 months. The factored number was of a special form; the special number field sieve cannot be used on RSA keys. The computation is roughly equivalent to breaking a 700 bit RSA key. However, this might be an advance warning that 1024 bit RSA keys used in secure online commerce should be deprecated, since they may become breakable in the foreseeable future. Cryptography professor Arjen Lenstra observed that \"Last time, it took nine years for us to generalize from a special to a nonspecial, hard-to-factor number\" and when asked whether 1024-bit RSA keys are dead, said: \"The answer to that question is an unqualified yes.\"\nThe 2015 Logjam attack revealed additional dangers in using Diffie-Hellman key exchange when only one or a few common 1024-bit or smaller prime moduli are in use. This practice, somewhat common at the time, allows large amounts of communications to be compromised at the expense of attacking a small number of primes.\nBrute-force attack.\nEven if a symmetric cipher is currently unbreakable by exploiting structural weaknesses in its algorithm, it may be possible to run through the entire space of keys in what is known as a brute-force attack. Because longer symmetric keys require exponentially more work to brute force search, a sufficiently long symmetric key makes this line of attack impractical.\nWith a key of length \"n\" bits, there are 2n possible keys. This number grows very rapidly as \"n\" increases. The large number of operations (2128) required to try all possible 128-bit keys is widely considered out of reach for conventional digital computing techniques for the foreseeable future. However, a quantum computer capable of running Grover's algorithm would be able to search the possible keys more efficiently. If a suitably sized quantum computer would reduce a 128-bit key down to 64-bit security, roughly a DES equivalent. This is one of the reasons why AES supports key lengths of 256 bits and longer.\nSymmetric algorithm key lengths.\nIBM's Lucifer cipher was selected in 1974 as the base for what would become the Data Encryption Standard. Lucifer's key length was reduced from 128 bits to 56 bits, which the NSA and NIST argued was sufficient for non-governmental protection at the time. The NSA has major computing resources and a large budget; some cryptographers including Whitfield Diffie and Martin Hellman complained that this made the cipher so weak that NSA computers would be able to break a DES key in a day through brute force parallel computing. The NSA disputed this, claiming that brute-forcing DES would take them \"something like 91 years\".\nHowever, by the late 90s, it became clear that DES could be cracked in a few days' time-frame with custom-built hardware such as could be purchased by a large corporation or government. The book \"Cracking DES\" (O'Reilly and Associates) tells of the successful ability in 1998 to break 56-bit DES by a brute-force attack mounted by a cyber civil rights group with limited resources; see EFF DES cracker. Even before that demonstration, 56 bits was considered insufficient length for symmetric algorithm keys for general use. Because of this, DES was replaced in most security applications by Triple DES, which has 112 bits of security when using 168-bit keys (triple key).\nThe Advanced Encryption Standard published in 2001 uses key sizes of 128, 192 or 256 bits. Many observers consider 128 bits sufficient for the foreseeable future for symmetric algorithms of AES's quality until quantum computers become available. However, as of 2015, the U.S. National Security Agency has issued guidance that it plans to switch to quantum computing resistant algorithms and now requires 256-bit AES keys for data classified up to Top Secret.\nIn 2003, the U.S. National Institute for Standards and Technology, NIST proposed phasing out 80-bit keys by 2015. At 2005, 80-bit keys were allowed only until 2010.\nSince 2015, NIST guidance says that \"the use of keys that provide less than 112 bits of security strength for key agreement is now disallowed.\" NIST approved symmetric encryption algorithms include three-key Triple DES, and AES. Approvals for two-key Triple DES and Skipjack were withdrawn in 2015; the NSA's Skipjack algorithm used in its Fortezza program employs 80-bit keys.\nAsymmetric algorithm key lengths.\nThe effectiveness of public key cryptosystems depends on the intractability (computational and theoretical) of certain mathematical problems such as integer factorization. These problems are time-consuming to solve, but usually faster than trying all possible keys by brute force. Thus, asymmetric keys must be longer for equivalent resistance to attack than symmetric algorithm keys. The most common methods are assumed to be weak against sufficiently powerful quantum computers in the future.\nSince 2015, NIST recommends a minimum of 2048-bit keys for RSA, an update to the widely accepted recommendation of a 1024-bit minimum since at least 2002.\n1024-bit RSA keys are equivalent in strength to 80-bit symmetric keys, 2048-bit RSA keys to 112-bit symmetric keys, 3072-bit RSA keys to 128-bit symmetric keys, and 15360-bit RSA keys to 256-bit symmetric keys. In 2003, RSA Security claimed that 1024-bit keys were likely to become crackable sometime between 2006 and 2010, while 2048-bit keys are sufficient until 2030. As of 2020[ [update]] the largest RSA key publicly known to be cracked is RSA-250 with 829 bits.\nThe Finite Field Diffie-Hellman algorithm has roughly the same key strength as RSA for the same key sizes. The work factor for breaking Diffie-Hellman is based on the discrete logarithm problem, which is related to the integer factorization problem on which RSA's strength is based. Thus, a 2048-bit Diffie-Hellman key has about the same strength as a 2048-bit RSA key.\nElliptic-curve cryptography (ECC) is an alternative set of asymmetric algorithms that is equivalently secure with shorter keys, requiring only approximately twice the bits as the equivalent symmetric algorithm. A 256-bit Elliptic-curve Diffie\u2013Hellman (ECDH) key has approximately the same safety factor as a 128-bit AES key. A message encrypted with an elliptic key algorithm using a 109-bit long key was broken in 2004.\nThe NSA previously recommended 256-bit ECC for protecting classified information up to the SECRET level, and 384-bit for TOP SECRET; In 2015 it announced plans to transition to quantum-resistant algorithms by 2024, and until then recommends 384-bit for all classified information.\nEffect of quantum computing attacks on key strength.\nThe two best known quantum computing attacks are based on Shor's algorithm and Grover's algorithm. Of the two, Shor's offers the greater risk to current security systems.\nDerivatives of Shor's algorithm are widely conjectured to be effective against all mainstream public-key algorithms including RSA, Diffie-Hellman and elliptic curve cryptography. According to Professor Gilles Brassard, an expert in quantum computing: \"The time needed to factor an RSA integer is the same order as the time needed to use that same integer as modulus for a single RSA encryption. In other words, it takes no more time to break RSA on a quantum computer (up to a multiplicative constant) than to use it legitimately on a classical computer.\" The general consensus is that these public key algorithms are insecure at any key size if sufficiently large quantum computers capable of running Shor's algorithm become available. The implication of this attack is that all data encrypted using current standards based security systems such as the ubiquitous SSL used to protect e-commerce and Internet banking and SSH used to protect access to sensitive computing systems is at risk. Encrypted data protected using public-key algorithms can be archived and may be broken at a later time, commonly known as retroactive/retrospective decryption or \"harvest now, decrypt later\".\nMainstream symmetric ciphers (such as AES or Twofish) and collision resistant hash functions (such as SHA) are widely conjectured to offer greater security against known quantum computing attacks. They are widely thought most vulnerable to Grover's algorithm. Bennett, Bernstein, Brassard, and Vazirani proved in 1996 that a brute-force key search on a quantum computer cannot be faster than roughly 2\"n\"/2 invocations of the underlying cryptographic algorithm, compared with roughly 2\"n\" in the classical case. Thus in the presence of large quantum computers an \"n\"-bit key can provide at least \"n\"/2 bits of security. Quantum brute force is easily defeated by doubling the key length, which has little extra computational cost in ordinary use. This implies that at least a 256-bit symmetric key is required to achieve 128-bit security rating against a quantum computer. As mentioned above, the NSA announced in 2015 that it plans to transition to quantum-resistant algorithms.\nIn a 2016 Quantum Computing FAQ, the NSA affirmed:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nIn a 2022 press release, the NSA notified:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nSince September 2022, the NSA has been transitioning from the Commercial National Security Algorithm Suite (now referred to as CNSA 1.0), originally launched in January 2016, to the Commercial National Security Algorithm Suite 2.0 (CNSA 2.0), both summarized below:\nCNSA 2.0\nCNSA 1.0\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "5750", "revid": "42184458", "url": "https://en.wikipedia.org/wiki?curid=5750", "title": "Cognitive behavioral therapy", "text": "Type of therapy to improve mental health\nCognitive behavioral therapy (CBT) is a form of psychotherapy that aims to reduce symptoms of various mental health conditions, primarily depression, and disorders such as PTSD and anxiety disorders. This therapy focuses on challenging unhelpful and irrational negative thoughts and beliefs, referred to as 'self-talk' and replacing them with more rational positive self-talk. This alteration in a person's thinking produces less anxiety and depression. It was developed by psychoanalyst Aaron Beck in the 1950's. \nCognitive behavioral therapy focuses on challenging and changing cognitive distortions (thoughts, beliefs, and attitudes) and their associated behaviors in order to improve emotional regulation and help the individual develop coping strategies to address problems. Though originally designed as an approach to treat depression, CBT is often prescribed for the evidence-informed treatment of many mental health and other conditions, including OCD, generalized anxiety disorder, substance use disorders, marital problems, ADHD, and eating disorders. CBT includes a number of cognitive or behavioral psychotherapies that treat defined psychopathologies using evidence-based techniques and strategies.\nCBT is a common form of talk therapy based on the combination of the basic principles from behavioral and cognitive psychology. It is different from other approaches to psychotherapy, such as the psychoanalytic approach, where the therapist looks for the unconscious meaning behind the behaviors and then formulates a diagnosis. Instead, CBT is a \"problem-focused\" and \"action-oriented\" form of therapy, meaning it is used to treat specific problems related to a diagnosed mental disorder. The therapist's role is to assist the client in finding and practicing effective strategies to address the identified goals and to alleviate symptoms of the disorder. CBT is based on the belief that thought distortions and maladaptive behaviors play a role in the development and maintenance of many psychological disorders and that symptoms and associated distress can be reduced by teaching new information-processing skills and coping mechanisms.\nWhen compared to psychoactive medications, review studies have found CBT alone to be as effective for treating less severe forms of depression, and borderline personality disorder. Some research suggests that CBT is most effective when combined with medication for treating mental disorders such as major depressive disorder. CBT is recommended as the first line of treatment for the majority of psychological disorders in children and adolescents, including aggression and conduct disorder. Researchers have found that other \"bona fide\" therapeutic interventions were equally effective for treating certain conditions in adults. Along with interpersonal psychotherapy (IPT), CBT is recommended in treatment guidelines as a psychosocial treatment of choice. It is recommended by the American Psychiatric Association, the American Psychological Association, and the British National Health Service. Critics argue CBT's benefits are overstated, citing small or declining effects, high dropouts, neoliberal influences, and methodological flaws, though it remains widely used and considered safe.\nHistory.\nPhilosophy.\nPrecursors of certain fundamental aspects of CBT have been identified in various ancient philosophical traditions, particularly Stoicism. Stoic philosophers, particularly Epictetus, believed logic could be used to identify and discard false beliefs that lead to destructive emotions, which has influenced the way modern cognitive-behavioral therapists identify cognitive distortions that contribute to depression and anxiety. Aaron T. Beck's original treatment manual for depression states, \"The philosophical origins of cognitive therapy can be traced back to the Stoic philosophers\". Another example of Stoic influence on cognitive theorists is the influence of Epictetus on Albert Ellis. A key philosophical figure who influenced the development of CBT was John Stuart Mill through his creation of Associationism, a predecessor of classical conditioning and behavioral theory.\nPrinciples originating from Buddhism have significantly impacted the evolution of various new forms of CBT, including dialectical behavior therapy, mindfulness-based cognitive therapy, spirituality-based CBT, and compassion-focused therapy.\nThe modern roots of CBT can be traced to the development of behavior therapy in the early 20th century, the development of cognitive therapy in the 1960s, and the subsequent merging of the two.\nBehavioral therapy.\nGroundbreaking work in behaviorism began with John B. Watson and Rosalie Rayner's studies of conditioning in 1920. Behaviorally-centered therapeutic approaches appeared as early as 1924 with Mary Cover Jones' work dedicated to the unlearning of fears in children. These were the antecedents of the development of Joseph Wolpe's behavioral therapy in the 1950s. It was the work of Wolpe and Watson, which was based on Ivan Pavlov's work on learning and conditioning, that influenced Hans Eysenck and Arnold Lazarus to develop new behavioral therapy techniques based on classical conditioning.\nDuring the 1950s and 1960s, behavioral therapy became widely used by researchers in the United States, the United Kingdom, and South Africa. Their inspiration was by the behaviorist learning theory of Ivan Pavlov, John B. Watson, and Clark L. Hull.\nIn Britain, Joseph Wolpe, who applied the findings of animal experiments to his method of systematic desensitization, applied behavioral research to the treatment of neurotic disorders. Wolpe's therapeutic efforts were precursors to today's fear reduction techniques. British psychologist Hans Eysenck presented behavior therapy as a constructive alternative.\nAt the same time as Eysenck's work, B. F. Skinner and his associates were beginning to have an impact with their work on operant conditioning. Skinner's work was referred to as radical behaviorism and avoided anything related to cognition. However, Julian Rotter in 1954 and Albert Bandura in 1969 contributed to behavior therapy with their works on social learning theory by demonstrating the effects of cognition on learning and behavior modification. The work of Claire Weekes in dealing with anxiety disorders in the 1960s is also seen as a prototype of behavior therapy.\nThe emphasis on behavioral factors has been described as the \"first wave\" of CBT.\nCognitive therapy.\nOne of the first therapists to address cognition in psychotherapy was Alfred Adler, notably with his idea of basic mistakes and how they contributed to creation of unhealthy behavioral and life goals.Abraham Low believed that someone's thoughts were best changed by changing their actions. Adler and Low influenced the work of Albert Ellis, who developed the earliest cognitive-based psychotherapy called rational emotive behavioral therapy, or REBT. The first version of REBT was announced to the public in 1956.\nIn the late 1950s, Aaron Beck was conducting free association sessions in his psychoanalytic practice. During these sessions, Beck noticed that thoughts were not as unconscious as Freud had previously theorized, and that certain types of thinking may be the culprits of emotional distress. It was from this hypothesis that Beck developed cognitive therapy, and called these thoughts \"automatic thoughts\". He first published his new methodology in 1967, and his first treatment manual in 1979. Beck has been referred to as \"the father of cognitive behavioral therapy\".\nIt was these two therapies, rational emotive therapy, and cognitive therapy, that started the \"second wave\" of CBT, which emphasized cognitive factors.\nMerger of behavioral and cognitive therapies.\nAlthough the early behavioral approaches were successful in many so-called neurotic disorders, they had little success in treating depression. Behaviorism was also losing popularity due to the cognitive revolution. The therapeutic approaches of Albert Ellis and Aaron T. Beck gained popularity among behavior therapists, despite the earlier behaviorist rejection of mentalistic concepts like thoughts and cognitions. Both of these systems included behavioral elements and interventions, with the primary focus being on problems in the present.\nIn initial studies, cognitive therapy was often contrasted with behavioral treatments to see which was most effective. During the 1980s and 1990s, cognitive and behavioral techniques were merged into cognitive behavioral therapy. Pivotal to this merging was the successful development of treatments for panic disorder by David M. Clark in the UK and David H. Barlow in the US.\nOver time, cognitive behavior therapy came to be known not only as a therapy, but as an umbrella term for all cognitive-based psychotherapies. These therapies include, but are not limited to, REBT, cognitive therapy, acceptance and commitment therapy, dialectical behavior therapy, metacognitive therapy, metacognitive training, reality therapy/choice theory, cognitive processing therapy, EMDR, and multimodal therapy.\nThis blending of theoretical and technical foundations from both behavior and cognitive therapies constituted the \"third wave\" of CBT. The most prominent therapies of this third wave are dialectical behavior therapy and acceptance and commitment therapy. Despite the increasing popularity of third-wave treatment approaches, reviews of studies reveal there may be no difference in the effectiveness compared with non-third wave CBT for the treatment of depression.\nIn the late 1990s, Melanie Fennell published a refined model in \"Behavioural and Cognitive Psychotherapy\" on a cognitive approach to low self-esteem. In line with Beck's 1976 general cognitive approach, it proposed that life experiences interact with temperament in the development of beliefs about the self.\nMedical uses.\nIn adults, CBT has been shown to be an effective part of treatment plans for anxiety disorders, body dysmorphic disorder, depression, eating disorders, chronic low back pain, personality disorders, psychosis, schizophrenia, substance use disorders, and bipolar disorder. It is also effective as part of treatment plans in the adjustment, depression, and anxiety associated with fibromyalgia, and as part of the treatment after spinal cord injuries.\nIn children or adolescents, CBT is an effective part of treatment plans for anxiety disorders, body dysmorphic disorder, depression and suicidality, eating disorders and obesity, obsessive\u2013compulsive disorder (OCD), post-traumatic stress disorder (PTSD), tic disorders, trichotillomania, and other repetitive behavior disorders. CBT has also been used to help improve a variety of childhood disorders, including depressive disorders and various anxiety disorders. CBT has shown to be the most effective intervention for people exposed to adverse childhood experiences in the form of abuse or neglect.\nCriticism of CBT sometimes focuses on implementations (such as the UK IAPT) which may result initially in low quality therapy being offered by poorly trained practitioners. However, evidence supports the effectiveness of CBT for anxiety and depression.\nEvidence suggests that the addition of hypnotherapy as an adjunct to CBT improves treatment efficacy for a variety of clinical issues.\nThe United Kingdom's National Institute for Health and Care Excellence (NICE) recommends CBT in the treatment plans for a number of mental health difficulties, including PTSD, OCD, bulimia nervosa, and clinical depression.\nDepression and anxiety disorders.\nCognitive behavioral therapy has been shown as an effective treatment for clinical depression. Among psychotherapeutic approaches for major depressive disorder, cognitive behavioral therapy and interpersonal psychotherapy are recommended by clinical practice guidelines including The American Psychiatric Association Practice (APA) Guidelines (April 2000), and the APA endorsed Veteran Affairs clinical practice guideline.\nCBT has been shown to be effective in the treatment of adults with anxiety disorders. There is also evidence that using CBT to treat children and adolescents with anxiety disorders was probably more effective (in the short term) than wait list or no treatment and more effective than attention control treatment approaches. Some meta-analyses find CBT more effective than psychodynamic therapy and equal to other therapies in treating anxiety and depression. A 2013 meta-analysis suggested that CBT, interpersonal therapy, and problem-solving therapy outperformed psychodynamic psychotherapy and behavioral activation in the treatment of depression. According to a 2004 review by INSERM of three methods, cognitive behavioral therapy was either proven or presumed to be an effective therapy on several mental disorders. This included depression, panic disorder, post-traumatic stress, and other anxiety disorders.\nA systematic review of CBT in depression and anxiety disorders concluded that \"CBT delivered in primary care, especially including computer- or Internet-based self-help programs, is potentially more effective than usual care and could be delivered effectively by primary care therapists.\"\nA 2024 systematic review found that exposure and response prevention (ERP), a specific form of cognitive behavioral therapy, is considered a first-line treatment for pediatric obsessive\u2013compulsive disorder (OCD). Research indicates that ERP is effective in both in-person and remote settings, providing flexibility in treatment delivery without compromising efficacy.\nAccording to \"The Anxiety and Worry Workbook:\" \"The Cognitive Behavioral Solution\" by Clark and Beck:\nTheoretical approaches.\nOne etiological theory of depression is Aaron T. Beck's cognitive theory of depression. His theory states that depressed people think the way they do because their thinking is biased towards negative interpretations. Beck's theory rests on the aspect of cognitive behavioral therapy known as schemata. Schemata are the mental maps used to integrate new information into memories and to organize existing information in the mind. An example of a schema would be a person hearing the word \"dog\" and picturing different versions of the animal that they have grouped together in their mind. According to this theory, depressed people acquire a negative schema of the world in childhood and adolescence as an effect of stressful life events, and the negative schema is activated later in life when the person encounters similar situations.\nBeck also described a negative cognitive triad. The cognitive triad is made up of the depressed individual's negative evaluations of themselves, the world, and the future. Beck suggested that these negative evaluations derive from the negative schemata and cognitive biases of the person. According to this theory, depressed people have views such as \"I never do a good job\", \"It is impossible to have a good day\", and \"things will never get better\". A negative schema helps give rise to the cognitive bias, and the cognitive bias helps fuel the negative schema. Beck further proposed that depressed people often have the following cognitive biases: arbitrary inference, selective abstraction, overgeneralization, magnification, and minimization. These cognitive biases are quick to make negative, generalized, and personal inferences of the self, thus fueling the negative schema.\nOn the other hand, a positive cognitive triad relates to a person's positive evaluations of themself, the world, and the future. More specifically, a positive cognitive triad requires self-esteem when viewing oneself and hope for the future. A person with a positive cognitive triad has a positive schema used for viewing themself in addition to a positive schema for the world and for the future. Cognitive behavioral research suggests a positive cognitive triad bolsters resilience, or the ability to cope with stressful events. Increased levels of resilience is associated with greater resistance to depression.\nAnother major theoretical approach to cognitive behavioral therapy treatment is the concept of Locus of Control outlined in Julian Rotter's Social Learning Theory. Locus of control refers to the degree to which an individual's sense of control is either internal or external. An internal locus of control exists when an individual views an outcome of a particular action as being reliant on themselves and their personal attributes whereas an external locus of control exists when an individual views other's or some outside, intangible force such as luck or fate as being responsible for the outcome of a particular action.\nA basic concept in some CBT treatments used in anxiety disorders is \"in vivo\" exposure. CBT-exposure therapy refers to the direct confrontation of feared objects, activities, or situations by a patient. For example, a woman with PTSD who fears the location where she was assaulted may be assisted by her therapist in going to that location and directly confronting those fears. Likewise, a person with a social anxiety disorder who fears public speaking may be instructed to directly confront those fears by giving a speech. This \"two-factor\" model is often credited to O. Hobart Mowrer. Through exposure to the stimulus, this harmful conditioning can be \"unlearned\" (referred to as extinction and habituation).\nCBT for children with phobias is normally delivered over multiple sessions, but one-session treatment has been shown to be equally effective and is cheaper.\nSpecialized forms of CBT.\nCBT-SP, an adaptation of CBT for suicide prevention (SP), was specifically designed for treating youths who are severely depressed and who have recently attempted suicide within the past 90 days, and was found to be effective, feasible, and acceptable.\nAcceptance and commitment therapy (ACT) is a specialist branch of CBT (sometimes referred to as contextual CBT). ACT uses mindfulness and acceptance interventions and has been found to have a greater longevity in therapeutic outcomes. In a study with anxiety, CBT and ACT improved similarly across all outcomes from pre- to post-treatment. However, during a 12-month follow-up, ACT proved to be more effective, showing that it is a highly viable lasting treatment model for anxiety disorders.\nComputerized CBT (CCBT) has been proven to be effective by randomized controlled and other trials in treating depression and anxiety disorders, including children. Some research has found similar effectiveness to an intervention of informational websites and weekly telephone calls. CCBT was found to be equally effective as face-to-face CBT in adolescent anxiety.\nCombined with other treatments.\nStudies have provided evidence that when examining animals and humans, that glucocorticoids may lead to a more successful extinction learning during exposure therapy for anxiety disorders. For instance, glucocorticoids can prevent aversive learning episodes from being retrieved and heighten reinforcement of memory traces creating a non-fearful reaction in feared situations. A combination of glucocorticoids and exposure therapy may be a better-improved treatment for treating people with anxiety disorders.\nPrevention.\nFor anxiety disorders, use of CBT with people at risk has significantly reduced the number of episodes of generalized anxiety disorder and other anxiety symptoms, and also given significant improvements in explanatory style, hopelessness, and dysfunctional attitudes. In another study, 3% of the group receiving the CBT intervention developed generalized anxiety disorder by 12 months postintervention compared with 14% in the control group. Individuals with subthreshold levels of panic disorder significantly benefitted from use of CBT. Use of CBT was found to significantly reduce social anxiety prevalence.\nFor depressive disorders, a stepped-care intervention (watchful waiting, CBT and medication if appropriate) achieved a 50% lower incidence rate in a patient group aged 75 or older. Another depression study found a neutral effect compared to personal, social, and health education, and usual school provision, and included a comment on potential for increased depression scores from people who have received CBT due to greater self recognition and acknowledgement of existing symptoms of depression and negative thinking styles. A further study also saw a neutral result. A meta-study of the Coping with Depression course, a cognitive behavioral intervention delivered by a psychoeducational method, saw a 38% reduction in risk of major depression.\nBipolar disorder.\nMany studies show CBT, combined with pharmacotherapy, is effective in improving depressive symptoms, mania severity and psychosocial functioning with mild to moderate effects, and that it is better than medication alone.\nINSERM's 2004 review found that CBT is an effective therapy for several mental disorders, including bipolar disorder. This included schizophrenia, depression, bipolar disorder, panic disorder, post-traumatic stress, anxiety disorders, bulimia, anorexia, personality disorders and alcohol dependency.\nPsychosis.\nIn long-term psychoses, CBT is used to complement medication and is adapted to meet individual needs. Interventions particularly related to these conditions include exploring reality testing, changing delusions and hallucinations, examining factors which precipitate relapse, and managing relapses. Meta-analyses confirm the effectiveness of metacognitive training (MCT) for the improvement of positive symptoms (e.g., delusions). \nFor people at risk of psychosis, in 2014 the UK National Institute for Health and Care Excellence (NICE) recommended preventive CBT.\nSchizophrenia.\nINSERM's 2004 review found that CBT is an effective therapy for several mental disorders, including schizophrenia.\nA Cochrane review reported CBT had \"no effect on long\u2010term risk of relapse\" and no additional effect above standard care. A 2015 systematic review investigated the effects of CBT compared with other psychosocial therapies for people with schizophrenia and determined that there is no clear advantage over other, often less expensive, interventions but acknowledged that better quality evidence is needed before firm conclusions can be drawn.\nAddiction and substance use disorders.\nPathological and problem gambling.\nCBT is also used for pathological and problem gambling. The percentage of people who problem gamble is 1\u20133% around the world. Cognitive behavioral therapy develops skills for relapse prevention and someone can learn to control their mind and manage high-risk cases. There is evidence of efficacy of CBT for treating pathological and problem gambling at immediate follow up, however the longer term efficacy of CBT for it is currently unknown.\nSmoking cessation.\nCBT looks at the habit of smoking cigarettes as a learned behavior, which later evolves into a coping strategy to handle daily stressors. Since smoking is often easily accessible and quickly allows the user to feel good, it can take precedence over other coping strategies, and eventually work its way into everyday life during non-stressful events as well. CBT aims to target the function of the behavior, as it can vary between individuals, and works to inject other coping mechanisms in place of smoking. CBT also aims to support individuals with strong cravings, which are a major reported reason for relapse during treatment.\nA 2008 controlled study out of Stanford University School of Medicine suggested CBT may be an effective tool to help maintain abstinence. The results of 304 random adult participants were tracked over the course of one year. During this program, some participants were provided medication, CBT, 24-hour phone support, or some combination of the three methods. At 20 weeks, the participants who received CBT had a 45% abstinence rate, versus non-CBT participants, who had a 29% abstinence rate. Overall, the study concluded that emphasizing cognitive and behavioral strategies to support smoking cessation can help individuals build tools for long term smoking abstinence.\nMental health history can affect the outcomes of treatment. Individuals with a history of depressive disorders had a lower rate of success when using CBT alone to combat smoking addiction.\nA 2019 Cochrane review was unable to find sufficient evidence to differentiate effects between CBT and hypnosis for smoking cessation and highlighted that a review of the current research showed variable results for both modalities.\nSubstance use disorders.\nStudies have shown CBT to be an effective treatment for substance use disorders. For individuals with substance use disorders, CBT aims to reframe maladaptive thoughts, such as denial, minimizing and catastrophizing thought patterns, with healthier narratives. Specific techniques include identifying potential triggers and developing coping mechanisms to manage high-risk situations. Research has shown CBT to be particularly effective when combined with other therapy-based treatments or medication.\nINSERM's 2004 review found that CBT is an effective therapy for several mental disorders, including alcohol dependency.\nInternet addiction.\nResearch has identified Internet addiction as a new clinical disorder that causes relational, occupational, and social problems. CBT has been suggested as the treatment of choice for Internet addiction, and addiction recovery in general has used CBT as part of treatment planning.\nEating disorders.\nThough many forms of treatment can support individuals with eating disorders, CBT is proven to be a more effective treatment than medications and interpersonal psychotherapy alone. CBT aims to combat major causes of distress such as negative cognitions surrounding body weight, shape and size. CBT therapists also work with individuals to regulate strong emotions and thoughts that lead to dangerous compensatory behaviors. CBT is the first line of treatment for bulimia nervosa, and non-specific eating disorders. While there is evidence to support the efficacy of CBT for bulimia nervosa and binging, the evidence is somewhat variable and limited by small study sizes. INSERM's 2004 review found that CBT is an effective therapy for several mental disorders, including bulimia and anorexia nervosa.\nWith autistic adults.\nEmerging evidence for cognitive behavioral interventions aimed at reducing symptoms of depression, anxiety, and obsessive-compulsive disorder in autistic adults without intellectual disability has been identified through a systematic review. While the research was focused on adults, cognitive behavioral interventions have also been beneficial to autistic children. A 2021 Cochrane review found limited evidence regarding the efficacy of CBT for obsessive-compulsive disorder in adults with Autism Spectrum Disorder stating a need for further study.\nDementia and mild cognitive impairment.\nA Cochrane review in 2022 found that adults with dementia and mild cognitive impairment (MCI) who experience symptoms of depression may benefit from CBT, whereas other counselling or supportive interventions might not improve symptoms significantly. Across 5 different psychometric scales, where higher scores indicate severity of depression, adults receiving CBT reported somewhat lower mood scores than those receiving usual care for dementia and MCI overall. In this review, a sub-group analysis found clinically significant benefits only among those diagnosed with dementia, rather than MCI.\nThe likelihood of remission from depression also appeared to be 84% higher following CBT, though the evidence for this was less certain. Anxiety, cognition and other neuropsychiatric symptoms were not significantly improved following CBT, however this review did find moderate evidence of improved quality of life and daily living activity scores in those with dementia and MCI.\nPost-traumatic stress.\nCognitive behavioral therapy interventions may have some benefits for people who have post-traumatic stress related to surviving rape, sexual abuse, or sexual assault. There is strong evidence that CBT-exposure therapy can reduce PTSD symptoms and lead to the loss of a PTSD diagnosis. In addition, CBT has also been shown to be effective for post-traumatic stress disorder in very young children (3 to 6 years of age). There is lower quality evidence that CBT may be more effective than other psychotherapies in reducing symptoms of posttraumatic stress disorder in children and adolescents.\nOther uses.\nEvidence suggests a possible role for CBT in the treatment of attention deficit hyperactivity disorder (ADHD), hypochondriasis, and bipolar disorder, but more study is needed and results should be interpreted with caution. Moderate evidence from a 2024 systematic review supports the effectiveness of CBT and neurofeedback as part of psychosocial interventions for improving ADHD symptoms in children and adolescents.\nCBT has been studied as an aid in the treatment of anxiety associated with stuttering. Initial studies have shown CBT to be effective in reducing social anxiety in adults who stutter, but not in reducing stuttering frequency.\nThere is some evidence that CBT is superior in the long-term to benzodiazepines and the nonbenzodiazepines in the treatment and management of insomnia. Computerized CBT (CCBT) has been proven to be effective by randomized controlled and other trials in treating insomnia. Some research has found similar effectiveness to an intervention of informational websites and weekly telephone calls. CCBT was found to be equally effective as face-to-face CBT in insomnia.\nA Cochrane review of interventions aimed at preventing psychological stress in healthcare workers found that CBT was more effective than no intervention but no more effective than alternative stress-reduction interventions.\nCochrane Reviews have found no convincing evidence that CBT training helps foster care providers manage difficult behaviors in the youths under their care, nor was it helpful in treating people who abuse their intimate partners.\nCBT has been applied in both clinical and non-clinical environments to treat disorders such as personality disorders and behavioral problems. INSERM's 2004 review found that CBT is an effective therapy for personality disorders.\nCBT has been used with other researchers as well to minimize chronic pain and help relieve symptoms from those suffering from irritable bowel syndrome (IBS).\nIndividuals with medical conditions.\nIn the case of people with metastatic breast cancer, data is limited but CBT and other psychosocial interventions might help with psychological outcomes and pain management. There is also some evidence that CBT may help reduce insomnia in cancer patients. \nThere is some evidence that using CBT for symptomatic management of non-specific chest pain is probably effective in the short term. However, the findings were limited by small trials and the evidence was considered of questionable quality. Cochrane reviews have found no evidence that CBT is effective for tinnitus, although there appears to be an effect on management of associated depression and quality of life in this condition. CBT combined with hypnosis and distraction reduces self-reported pain in children.\nThere is limited evidence to support CBT's use in managing the impact of multiple sclerosis, sleep disturbances related to aging, and dysmenorrhea, but more study is needed and results should be interpreted with caution.\nPreviously CBT has been considered as moderately effective for treating myalgic encephalomyelitis/chronic fatigue syndrome (ME/CFS), however a National Institutes of Health Pathways to Prevention Workshop stated that in respect of improving treatment options for ME/CFS that the modest benefit from cognitive behavioral therapy should be studied as an adjunct to other methods. The Centres for Disease Control advice on the treatment of ME/CFS makes no reference to CBT while the National Institute for Health and Care Excellence states that cognitive behavioral therapy (CBT) has sometimes been assumed to be a cure for ME/CFS, however, it should only be offered to support people who live with ME/CFS to manage their symptoms, improve their functioning and reduce the distress associated with having a chronic illness. \nAge.\nCBT is used to help people of all ages, but the therapy should be adjusted based on the age of the patient with whom the therapist is dealing. Older individuals in particular have certain characteristics that need to be acknowledged and the therapy altered to account for these differences thanks to age. Of the small number of studies examining CBT for the management of depression in older people, there is currently no strong support.\nDescription.\nMainstream cognitive behavioral therapy assumes that changing maladaptive thinking leads to change in behavior and affect, but recent variants emphasize changes in one's relationship to maladaptive thinking rather than changes in thinking itself.\nCognitive distortions.\nTherapists use CBT techniques to help people challenge their patterns and beliefs and replace errors in thinking, known as cognitive distortions with \"more realistic and effective thoughts, thus decreasing emotional distress and self-defeating behavior\". Cognitive distortions can be either a pseudo-discrimination belief or an overgeneralization of something. CBT techniques may also be used to help individuals take a more open, mindful, and aware posture toward cognitive distortions so as to diminish their impact.\nMainstream CBT helps individuals replace \"maladaptive... coping skills, cognitions, emotions and behaviors with more adaptive ones\", by challenging an individual's way of thinking and the way that they react to certain habits or behaviors, but there is still controversy about the degree to which these traditional cognitive elements account for the effects seen with CBT over and above the earlier behavioral elements such as exposure and skills training.\nAssumptions.\nChaloult, Ngo, Cousineau and Goulet have attempted to identify the main assumptions of cognitive therapy used in CBT based on the research literature (Beck; Walen and Wessler; Beck, Emery and Greenberg, and Auger). They describe fourteen assumptions:\nThese steps largely involve learning about the CBT model; making links between thoughts, emotions, behaviors, and physiological reactions; noticing when dysfunctional emotions occur; learning to question the thoughts associated with these emotions; replacing irrational thoughts with others more grounded in reality; modifying behaviors based on new interpretations of events; and, in some cases, learning to recognize and change the major beliefs and attitudes underlying cognitive distortions.\nChaloult, Ngo, Cousineau and Goulet have also described the assumptions of behavioral therapy as used in CBT. They refer to the work of Agras, Prochaska and Norcross, and Kirk. The assumptions are:\nTogether, these sets of assumptions cover the cognitive and behavioral aspects of CBT.\nPhases in therapy.\nCBT can be seen as having six phases:\nThese steps are based on a system created by Kanfer and Saslow. After identifying the behaviors that need changing, whether they be in excess or deficit, and treatment has occurred, the psychologist must identify whether or not the intervention succeeded. For example, \"If the goal was to decrease the behavior, then there should be a decrease relative to the baseline. If the critical behavior remains at or above the baseline, then the intervention has failed.\"\nThe steps in the assessment phase include:\nThe re-conceptualization phase makes up much of the \"cognitive\" portion of CBT.\nDelivery protocols.\nThere are different protocols for delivering cognitive behavioral therapy, with important similarities among them. Use of the term CBT may refer to different interventions, including \"self-instructions (e.g. distraction, imagery, motivational self-talk), relaxation and/or biofeedback, development of adaptive coping strategies (e.g. minimizing negative or self-defeating thoughts), changing maladaptive beliefs about pain, and goal setting\". Treatment is sometimes manualized, with brief, direct, and time-limited treatments for individual psychological disorders that are specific technique-driven. CBT is used in both individual and group settings, and the techniques are often adapted for self-help applications. Some clinicians and researchers are cognitively oriented (e.g. cognitive restructuring), while others are more behaviorally oriented (e.g. \"in vivo\" exposure therapy). Interventions such as imaginal exposure therapy combine both approaches.\nRelated techniques.\nCBT may be delivered in conjunction with a variety of diverse but related techniques such as exposure therapy, stress inoculation, cognitive processing therapy, cognitive therapy, metacognitive therapy, metacognitive training, relaxation training, dialectical behavior therapy, and acceptance and commitment therapy. Some practitioners promote a form of mindful cognitive therapy which includes a greater emphasis on self-awareness as part of the therapeutic process.\nMethods of access.\nTherapist.\nA typical CBT program would consist of face-to-face sessions between patient and therapist, made up of 6\u201318 sessions of around an hour each with a gap of 1\u20133 weeks between sessions. This initial program might be followed by some booster sessions, for instance after one month and three months. CBT has also been found to be effective if patient and therapist type in real time to each other over computer links.\nCognitive-behavioral therapy is most closely allied with the scientist\u2013practitioner model in which clinical practice and research are informed by a scientific perspective, clear operationalization of the problem, and an emphasis on measurement, including measuring changes in cognition and behavior and the attainment of goals. These are often met through \"homework\" assignments in which the patient and the therapist work together to craft an assignment to complete before the next session. The completion of these assignments\u00a0\u2013 which can be as simple as a person with depression attending some kind of social event\u00a0\u2013 indicates a dedication to treatment compliance and a desire to change. The therapists can then logically gauge the next step of treatment based on how thoroughly the patient completes the assignment. Effective cognitive behavioral therapy is dependent on a therapeutic alliance between the healthcare practitioner and the person seeking assistance. Unlike many other forms of psychotherapy, the patient is very involved in CBT. For example, an anxious patient may be asked to talk to a stranger as a homework assignment, but if that is too difficult, he or she can work out an easier assignment first. The therapist needs to be flexible and willing to listen to the patient rather than acting as an authority figure.\nComputerized or Internet-delivered (CCBT).\nComputerized cognitive behavioral therapy (CCBT) has been described by NICE as a \"generic term for delivering CBT via an interactive computer interface delivered by a personal computer, internet, or interactive voice response system\", instead of face-to-face with a human therapist. It is also known as internet-delivered cognitive behavioral therapy or ICBT. CCBT has potential to improve access to evidence-based therapies, and to overcome the prohibitive costs and lack of availability sometimes associated with retaining a human therapist. In this context, it is important not to confuse CBT with 'computer-based training', which nowadays is more commonly referred to as e-Learning.\nAlthough improvements in both research quality and treatment adherence is required before advocating for the global dissemination of CCBT, it has been found in meta-studies to be cost-effective and often cheaper than usual care, including for anxiety and PTSD. Studies have shown that individuals with social anxiety and depression experienced improvement with online CBT-based methods. A study assessing an online version of CBT for people with mild-to-moderate PTSD found that the online approach was as effective as, and cheaper than, the same therapy given face-to-face. A review of current CCBT research in the treatment of OCD in children found this interface to hold great potential for future treatment of OCD in youths and adolescent populations. Additionally, most internet interventions for post-traumatic stress disorder use CCBT. CCBT is also predisposed to treating mood disorders amongst non-heterosexual populations, who may avoid face-to-face therapy from fear of stigma. However presently CCBT programs seldom cater to these populations.\nIn February 2006 NICE recommended that CCBT be made available for use within the NHS across England and Wales for patients presenting with mild-to-moderate depression, rather than immediately opting for antidepressant medication, and CCBT is made available by some health systems. The 2009 NICE guideline recognized that there are likely to be a number of computerized CBT products that are useful to patients, but removed endorsement of any specific product.\nSmartphone app-delivered.\nAnother new method of access is the use of mobile app or smartphone applications to deliver self-help or guided CBT. Technology companies are developing mobile-based artificial intelligence chatbot applications in delivering CBT as an early intervention to support mental health, to build psychological resilience, and to promote emotional well-being. Artificial intelligence (AI) text-based conversational application delivered securely and privately over smartphone devices have the ability to scale globally and offer contextual and always-available support. Active research is underway including real-world data studies that measure effectiveness and engagement of text-based smartphone chatbot apps for delivery of CBT using a text-based conversational interface. Recent market research and analysis of over 500 online mental healthcare solutions identified 3 key challenges in this market: quality of the content, guidance of the user and personalisation.\nA study compared CBT alone with a mindfulness-based therapy combined with CBT, both delivered via an app. It found that mindfulness-based self-help reduced the severity of depression more than CBT self-help in the short-term. Overall, NHS costs for the mindfulness approach were \u00a3500 less per person than for CBT.\nReading self-help materials.\nEnabling patients to read self-help CBT guides has been shown to be effective by some studies. However one study found a negative effect in patients who tended to ruminate, and another meta-analysis found that the benefit was only significant when the self-help was guided (e.g. by a medical professional).\nGroup educational course.\nPatient participation in group courses has been shown to be effective. In a meta-analysis reviewing evidence-based treatment of OCD in children, individual CBT was found to be more efficacious than group CBT.\nTypes.\nBrief cognitive behavioral therapy.\nBrief cognitive behavioral therapy (BCBT) is a form of CBT which has been developed for situations in which there are time constraints on the therapy sessions and specifically for those struggling with suicidal ideation and/or making suicide attempts. BCBT was based on Rudd's proposed \"suicidal mode\", an elaboration of Beck's modal theory. BCBT takes place over a couple of sessions that can last up to 12 accumulated hours by design. This technique was first implemented and developed with soldiers on active duty by Dr. M. David Rudd to prevent suicide.\nBreakdown of treatment\nCognitive emotional behavioral therapy.\nCognitive emotional behavioral therapy (CEBT) is a form of CBT developed initially for individuals with eating disorders but now used with a range of problems including anxiety, depression, obsessive compulsive disorder (OCD), post-traumatic stress disorder (PTSD) and anger problems. It combines aspects of CBT and dialectical behavioral therapy and aims to improve understanding and tolerance of emotions in order to facilitate the therapeutic process. It is frequently used as a \"pretreatment\" to prepare and better equip individuals for longer-term therapy.\nStructured cognitive behavioral training.\nStructured cognitive-behavioral training (SCBT) is a cognitive-based process with core philosophies that draw heavily from CBT. Like CBT, SCBT asserts that behavior is inextricably related to beliefs, thoughts, and emotions. SCBT also builds on core CBT philosophy by incorporating other well-known modalities in the fields of behavioral health and psychology: most notably, Albert Ellis's rational emotive behavior therapy. SCBT differs from CBT in two distinct ways. First, SCBT is delivered in a highly regimented format. Second, SCBT is a predetermined and finite training process that becomes personalized by the input of the participant. SCBT is designed to bring a participant to a specific result in a specific period of time. SCBT has been used to challenge addictive behavior, particularly with substances such as tobacco, alcohol and food, and to manage diabetes and subdue stress and anxiety. SCBT has also been used in the field of criminal psychology in the effort to reduce recidivism.\nMoral reconation therapy.\nMoral reconation therapy, a type of CBT used to help felons overcome antisocial personality disorder (ASPD), slightly decreases the risk of further offending. It is generally implemented in a group format because of the risk of offenders with ASPD being given one-on-one therapy reinforces narcissistic behavioral characteristics, and can be used in correctional or outpatient settings. Groups usually meet weekly for two to six months.\nStress inoculation training.\nThis type of therapy uses a blend of cognitive, behavioral, and certain humanistic training techniques to target the stressors of the client. This is usually used to help clients better cope with their stress or anxiety after stressful events. This is a three-phase process that trains the client to use skills that they already have to better adapt to their current stressors. The first phase is an interview phase that includes psychological testing, client self-monitoring, and a variety of reading materials. This allows the therapist to individually tailor the training process to the client. Clients learn how to categorize problems into emotion-focused or problem-focused so that they can better treat their negative situations. This phase ultimately prepares the client to eventually confront and reflect upon their current reactions to stressors, before looking at ways to change their reactions and emotions to their stressors. The focus is conceptualization.\nThe second phase emphasizes the aspect of skills acquisition and rehearsal that continues from the earlier phase of conceptualization. The client is taught skills that help them cope with their stressors. These skills are then practiced in the space of therapy. These skills involve self-regulation, problem-solving, interpersonal communication skills, etc.\nThe third and final phase is the application and following through of the skills learned in the training process. This gives the client opportunities to apply their learned skills to a wide range of stressors. Activities include role-playing, imagery, modeling, etc. In the end, the client will have been trained on a preventive basis to inoculate personal, chronic, and future stressors by breaking down their stressors into problems they will address in long-term, short-term, and intermediate coping goals.\nActivity-guided CBT: Group-knitting.\nA recently developed group therapy model, based on CBT, integrates knitting into the therapeutic process and has been proven to yield reliable and promising results. The foundation for this novel approach to CBT is the frequently emphasized notion that therapy success depends on how embedded the therapy method is in the patients' natural routine. Similar to standard group-based CBT, patients meet once a week in a group of 10 to 15 patients and knit together under the instruction of a trained psychologist or mental health professional. Central for the therapy is the patient's imaginative ability to assign each part of the wool to a certain thought. During the therapy, the wool is carefully knitted, creating a knitted piece of any form. This therapeutic process teaches the patient to meaningfully align thought, by (physically) creating a coherent knitted piece. Moreover, since CBT emphasizes the behavior as a result of cognition, the knitting illustrates how thoughts (which are tried to be imaginary tight to the wool) materialize into the reality surrounding us.\nMindfulness-based cognitive behavioral hypnotherapy.\nMindfulness-based cognitive behavioral hypnotherapy (MCBH) is a form of CBT that focuses on awareness in a reflective approach, addressing subconscious tendencies. It is more the process that contains three phases for achieving wanted goals and integrates the principles of mindfulness and cognitive-behavioral techniques with the transformative potential of hypnotherapy.\nUnified Protocol.\nThe Unified Protocol for Transdiagnostic Treatment of Emotional Disorders (UP) is a form of CBT, developed by David H. Barlow and researchers at Boston University, that can be applied to a range of anxiety disorders. The rationale is that anxiety and depression disorders often occur together due to common underlying causes and can efficiently be treated together.\nThe UP includes a common set of components:\nThe UP has been shown to produce equivalent results to single-diagnosis protocols for specific disorders, such as OCD and social anxiety disorder.\nSeveral studies have shown that the UP is easier to disseminate as compared to single-diagnosis protocols.\nCulturally adapted CBT\nThe study of psychotherapy across races, religions, and cultures, or \"ethno-psycho-therapy\", is a relatively new discipline\nCriticisms.\nRelative effectiveness.\nThe research conducted for CBT has been a topic of sustained controversy. While some researchers write that CBT is more effective than other treatments, many other researchers and practitioners have questioned the validity of such claims. For example, one study determined CBT to be superior to other treatments in treating anxiety and depression. However, researchers responding directly to that study conducted a re-analysis and found no evidence of CBT being superior to other, non-CBT treatments, and conducted an analysis of thirteen other CBT clinical trials and determined that they failed to provide evidence of CBT superiority. Another example is the \u00a35 million PACE trial, of which the results were claimed to show that CBT, and graded exercise therapy (GET) cured Myalgic encephalomyelitis/chronic fatigue syndrome. But, when the PACE results were later comprehensively reanalyzed and subjects followed-up, it was found that the CBT and GET treatments were \"not\" effective and possibly not safe. The PACE study's design was riddled with design flaws such as lacking both single and double blinding and engaging in the retrospective manipulation of primary outcome measures while systematically ignoring ME/CFS sufferers' negative health outcomes as a consequences of engaging in CBT and GET . In cases where CBT has been reported to be statistically better than other psychological interventions in terms of primary outcome measures, effect sizes were small and suggested that those differences were clinically meaningless and insignificant. Nonetheless, CBT remains widely recognized for its structured approach to identifying and modifying maladaptive cognitive appraisals, which has been associated with improved emotional regulation in individuals with mood and anxiety disorders. Moreover, on secondary outcomes (i.e., measures of general functioning) no significant differences have been typically found between CBT and other treatments.\nA major criticism has been that clinical studies of CBT efficacy (or any psychotherapy) are not double-blind (i.e., either the subjects or the therapists in psychotherapy studies are not blind to the type of treatment). They may be single-blinded, i.e. the rater may not know the treatment the patient received, but neither the patients nor the therapists are blinded to the type of therapy given (two out of three of the persons involved in the trial, i.e., all of the persons involved in the treatment, are unblinded). The patient is an active participant in correcting negative distorted thoughts, thus quite aware of the treatment group they are in.\nThe importance of double-blinding was shown in a meta-analysis that examined the effectiveness of CBT when placebo control and blindness were factored in. Pooled data from published trials of CBT in schizophrenia, major depressive disorder (MDD), and bipolar disorder that used controls for non-specific effects of intervention were analyzed. This study concluded that CBT is no better than non-specific control interventions in the treatment of schizophrenia and does not reduce relapse rates; treatment effects are small in treatment studies of MDD, and it is not an effective treatment strategy for prevention of relapse in bipolar disorder. For MDD, the authors note that the pooled effect size was very low.\nDeclining effectiveness.\nAdditionally, a 2015 meta-analysis revealed that the positive effects of CBT on depression have been declining since 1977. The overall results showed two different declines in effect sizes: 1) an overall decline between 1977 and 2014, and 2) a steeper decline between 1995 and 2014. Additional sub-analysis revealed that CBT studies where therapists in the test group were instructed to adhere to the Beck CBT manual had a steeper decline in effect sizes since 1977 than studies where therapists in the test group were instructed to use CBT without a manual. The authors reported that they were unsure why the effects were declining but did list inadequate therapist training, failure to adhere to a manual, lack of therapist experience, and patients' hope and faith in its efficacy waning as potential reasons. The authors did mention that the current study was limited to depressive disorders only.\nHigh drop-out rates.\nFurthermore, other researchers write that CBT studies have high drop-out rates compared to other treatments. One meta-analysis found that CBT drop-out rates were 17% higher than those of other therapies. This high drop-out rate is also evident in the treatment of several disorders, particularly the eating disorder anorexia nervosa, which is commonly treated with CBT. Those treated with CBT have a high chance of dropping out of therapy before completion and reverting to their anorexia behaviors.\nOther researchers analyzing treatments for youths who self-injure found similar drop-out rates in CBT and DBT groups. In this study, the researchers analyzed several clinical trials that measured the efficacy of CBT administered to youths who self-injure. The researchers concluded that none of them were found to be efficacious.\nPhilosophical concerns with CBT methods.\nThe methods employed in CBT research have not been the only criticisms; some individuals have called its theory and therapy into question.\nSlife and Williams write that one of the hidden assumptions in CBT is that of determinism, or the absence of free will. They argue that CBT holds that external stimuli from the environment enter the mind, causing different thoughts that cause emotional states: nowhere in CBT theory is agency, or free will, accounted for.\nAnother criticism of CBT theory, especially as applied to major depressive disorder (MDD), is that it confounds the symptoms of the disorder with its causes. Other criticisms include that CBT may view people as stupid or can address only simple or superficial problems.\nSide effects.\nCBT is generally regarded as having very few if any side effects. Calls have been made by some for more appraisal of possible side effects of CBT. Many randomized trials of psychological interventions like CBT do not monitor potential harms to the patient. In contrast, randomized trials of pharmacological interventions are much more likely to take adverse effects into consideration.\nA 2017 meta-analysis revealed that adverse events are not common in children receiving CBT and, furthermore, that CBT is associated with fewer dropouts than either placebo or medications. Nevertheless, CBT therapists do sometimes report 'unwanted events' and side effects in their outpatients with \"negative wellbeing/distress\" being the most frequent.\nSociety and culture.\nThe UK's National Health Service announced in 2008 that more therapists would be trained to provide CBT at government expense as part of an initiative called Improving Access to Psychological Therapies (IAPT). The NICE said that CBT would become the mainstay of treatment for non-severe depression, with medication used only in cases where CBT had failed. Therapists complained that the data does not fully support the attention and funding CBT receives. Psychotherapist and professor Andrew Samuels stated that this constitutes \"a coup, a power play by a community that has suddenly found itself on the brink of corralling an enormous amount of money\u00a0... Everyone has been seduced by CBT's apparent cheapness.\"\nThe UK Council for Psychotherapy issued a press release in 2012 saying that the IAPT's policies were undermining traditional psychotherapy and criticized proposals that would limit some approved therapies to CBT, claiming that they restricted patients to \"a watered-down version of cognitive behavioural therapy (CBT), often delivered by very lightly trained staff\".\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "5751", "revid": "5563803", "url": "https://en.wikipedia.org/wiki?curid=5751", "title": "Chinese language", "text": "Sino-Tibetan language\n&lt;templatestyles src=\"Template:Infobox/styles-images.css\" /&gt;\nChinese (spoken: , written: ) is an umbrella term for Sinitic languages in the Sino-Tibetan language family, widely recognized as a group of language varieties, spoken natively by the ethnic Han Chinese majority and many minority ethnic groups in China, as well as by various communities of the Chinese diaspora. Approximately 1.39\u00a0billion people, or 17% of the global population, speak one of the Chinese languages as their first language.\nThe Chinese languages form the Sinitic branch of the Sino-Tibetan language family. The Chinese government considers the spoken varieties of the Chinese languages dialects of a single language. However, their lack of mutual intelligibility means they are considered to be separate languages in a family by linguists. Investigation of the historical relationships among the varieties of Chinese is ongoing. Currently, most classifications posit 7 to 13 main regional groups based on phonetic developments from Middle Chinese, of which the most spoken by far is Mandarin with 66%, or around 800\u00a0million speakers, followed by Min (75\u00a0million, e.g., Southern Min), Wu (74\u00a0million, e.g., Shanghainese), and Yue (68\u00a0million, e.g., Cantonese). These branches are unintelligible to each other, and many of their subgroups are unintelligible with the other varieties within the same branch (e.g., Southern Min). There are, however, transitional areas where varieties from different branches share enough features for some limited intelligibility, including New Xiang with Southwestern Mandarin, Xuanzhou Wu Chinese with Lower Yangtze Mandarin, Jin with Central Plains Mandarin and certain divergent dialects of Hakka with Gan. All varieties of Chinese are tonal at least to some degree, and are largely analytic.\nThe earliest attested written Chinese consists of the oracle bone inscriptions created during the Shang dynasty c.\u20091250\u00a0BCE. The phonetic categories of Old Chinese can be reconstructed from the rhymes of ancient poetry. During the Northern and Southern period, Middle Chinese went through several sound changes and split into several varieties following prolonged geographic and political separation. The \"Qieyun\", a rhyme dictionary, recorded a compromise between the pronunciations of different regions. The royal courts of the Ming and early Qing dynasties operated using a koin\u00e9 language known as \"Guanhua\", based on the Nanjing dialect of Mandarin.\nStandard Chinese is an official language of both the People's Republic of China and the Republic of China (Taiwan), one of the four official languages of Singapore, and one of the six official languages of the United Nations. Standard Chinese is based on the Beijing dialect of Mandarin and was first officially adopted in the 1930s. The language is written primarily using a logography of Chinese characters, largely shared by readers who may otherwise speak mutually unintelligible varieties. Since the 1950s, the use of simplified characters has been promoted by the government of the People's Republic of China, with Singapore officially adopting them in 1976. Traditional characters are used in Taiwan, Hong Kong, Macau, and among Chinese-speaking communities overseas.\nClassification.\nLinguists classify all varieties of Chinese as part of the Sino-Tibetan language family, together with Burmese, Tibetan and many other languages spoken in the Himalayas and the Southeast Asian Massif. Although the relationship was first proposed in the early 19th century and is now broadly accepted, reconstruction of Sino-Tibetan is much less developed than that of families such as Indo-European or Austroasiatic. Difficulties have included the great diversity of the languages, the lack of inflection in many of them, and the effects of language contact. In addition, many of the smaller languages are spoken in mountainous areas that are difficult to reach and are often also sensitive border zones. Without a secure reconstruction of Proto-Sino-Tibetan, the higher-level structure of the family remains unclear. A top-level branching into Chinese and Tibeto-Burman languages is often assumed, but has not been convincingly demonstrated.\nHistory.\nThe first written records appeared over 3,000 years ago during the Shang dynasty. As the language evolved over this period, the various local varieties became mutually unintelligible. In reaction, central governments have repeatedly sought to promulgate a unified standard.\nOld and Middle Chinese.\nThe earliest examples of Old Chinese are divinatory inscriptions on oracle bones dated to c.\u20091250\u00a0BCE, during the Late Shang. The next attested stage came from inscriptions on bronze artifacts dating to the Western Zhou period (1046\u2013771\u00a0BCE), the \"Classic of Poetry\" and portions of the \"Book of Documents\" and \"I Ching\". Scholars have attempted to reconstruct the phonology of Old Chinese by comparing later varieties of Chinese with the rhyming practice of the \"Classic of Poetry\" and the phonetic elements found in the majority of Chinese characters. Although many of the finer details remain unclear, most scholars agree that Old Chinese differs from Middle Chinese in lacking retroflex and palatal obstruents but having initial consonant clusters of some sort, and in having voiceless nasals and liquids. Most recent reconstructions also describe an atonal language with consonant clusters at the end of the syllable, developing into tone distinctions in Middle Chinese. Several derivational affixes have also been identified, but the language lacks inflection, and indicated grammatical relationships using word order and grammatical particles.\nMiddle Chinese was the language used during Northern and Southern dynasties and the Sui, Tang, and Song dynasties (6th\u201310th centuries). It can be divided into an early period, reflected by the \"Qieyun\" rhyme dictionary (601), and a late period in the 10th century, reflected by rhyme tables such as the constructed by ancient Chinese philologists as a guide to the \"Qieyun\" system. These works define phonological categories but with little hint of what sounds they represent. Linguists have identified these sounds by comparing the categories with pronunciations in modern varieties of Chinese, borrowed Chinese words in Vietnamese, Korean, and Japanese, and transcription evidence. The resulting system is very complex, with a large number of consonants and vowels, but they are probably not all distinguished in any single dialect. Most linguists now believe it represents a diasystem encompassing 6th-century northern and southern standards for reading the classics.\nClassical and vernacular written forms.\nThe complex relationship between spoken and written Chinese is an example of diglossia: as spoken, Chinese varieties have evolved at different rates, while the written language used throughout China changed comparatively little, crystallizing into a prestige form known as Classical or Literary Chinese. Literature written distinctly in the Classical form began to emerge during the Spring and Autumn period. Its use in writing remained nearly universal until the late 19th century, culminating with the widespread adoption of written vernacular Chinese with the May Fourth Movement beginning in 1919.\nRise of northern dialects.\nAfter the fall of the Northern Song dynasty and subsequent reign of the Jurchen Jin and Mongol Yuan dynasties in northern China, a common speech (now called Old Mandarin) developed based on the dialects of the North China Plain around the capital.\nThe 1324 \"Zhongyuan Yinyun\" was a dictionary that codified the rhyming conventions of new \"sanqu\" verse form in this language.\nTogether with the slightly later \"Menggu Ziyun\", this dictionary describes a language with many of the features characteristic of modern Mandarin dialects.\nUntil the early 20th century, most Chinese people only spoke their local language. Thus, as a practical measure, officials of the Ming and Qing dynasties carried out the administration of the empire using a common language based on Mandarin varieties, known as . For most of this period, this language was a koin\u00e9 based on dialects spoken in the Nanjing area, though not identical to any single dialect. By the middle of the 19th century, the Beijing dialect had become dominant and was essential for any business with the imperial court.\nIn the 1930s, a standard national language (), was adopted. After much dispute between proponents of northern and southern languages and an abortive attempt at an artificial pronunciation, the National Language Unification Commission finally settled on the Beijing dialect in 1932. The People's Republic founded in 1949 retained this standard but renamed it . The national language is now used in education, the media, and formal situations in both mainland China and Taiwan.\nIn Hong Kong and Macau, Cantonese is the dominant spoken language due to cultural influence from Guangdong immigrants and colonial-era policies, and is used in education, media, formal speech, and everyday life\u2014though Mandarin is increasingly taught in schools due to the mainland's growing influence.\nInfluence.\nHistorically, the Chinese languages spread to neighbors through a variety of means. Northern Vietnam was incorporated into the Han dynasty (202\u00a0BCE\u00a0\u2013 220\u00a0CE) in 111\u00a0BCE, marking the beginning of a period of Chinese control that ran almost continuously for a millennium. The Four Commanderies of Han were established in northern Korea in the 1st century\u00a0BCE but disintegrated in the following centuries. Chinese Buddhism spread over East Asia between the 2nd and 5th centuries\u00a0CE, and with it the study of scriptures and literature in Literary Chinese. Later, strong central governments modeled on Chinese institutions were established in Korea, Japan, and Vietnam, with Literary Chinese serving as the language of administration and scholarship, a position it would retain until the late 19th century in Korea and (to a lesser extent) Japan, and the early 20th century in Vietnam. Scholars from different lands could communicate, albeit only in writing, using Literary Chinese.\nAlthough they used Chinese solely for written communication, each country had its own tradition of reading texts aloud using what are known as Sino-Xenic pronunciations. Chinese words with these pronunciations were also extensively imported into the Korean, Japanese and Vietnamese languages, and today comprise over half of their vocabularies. This massive influx led to changes in the phonological structure of the languages, contributing to the development of moraic structure in Japanese and the disruption of vowel harmony in Korean.\nBorrowed Chinese morphemes have been used extensively in all these languages to coin compound words for new concepts, in a similar way to the use of Latin and Ancient Greek roots in European languages. Many new compounds, or new meanings for old phrases, were created in the late 19th and early 20th centuries to name Western concepts and artifacts. These coinages, written in shared Chinese characters, have then been borrowed freely between languages. They have even been accepted into Chinese, a language usually resistant to loanwords, because their foreign origin was hidden by their written form. Often different compounds for the same concept were in circulation for some time before a winner emerged, and sometimes the final choice differed between countries. The proportion of vocabulary of Chinese origin thus tends to be greater in technical, abstract, or formal language. For example, in Japan, Sino-Japanese words account for about 35% of the words in entertainment magazines, over half the words in newspapers, and 60% of the words in science magazines.\nVietnam, Korea, and Japan each developed writing systems for their own languages, initially based on Chinese characters, but later replaced with the alphabet for Korean and supplemented with syllabaries for Japanese, while Vietnamese continued to be written with the complex script. However, these were limited to popular literature until the late 19th century. Today Japanese is written with a composite script using both Chinese characters called kanji, and kana. Korean is written exclusively with hangul in North Korea, although knowledge of the supplementary Chinese characters called hanja is still required, and hanja are increasingly rarely used in South Korea. As a result of its historical colonization by France, Vietnamese now uses the Latin-based Vietnamese alphabet.\nEnglish words of Chinese origin include \"tea\" from Hokkien , \"dim sum\" from Cantonese , and \"kumquat\" from Cantonese .\nVarieties.\nThe sinologist Jerry Norman has estimated that there are hundreds of mutually unintelligible varieties of Chinese. These varieties form a dialect continuum, in which differences in speech generally become more pronounced as distances increase, though the rate of change varies immensely. Generally, mountainous South China exhibits more linguistic diversity than the North China Plain. Until the late 20th century, Chinese emigrants to Southeast Asia and North America came from southeast coastal areas, where Min, Hakka, and Yue dialects were spoken. Specifically, most Chinese immigrants to North America until the mid-20th century spoke Taishanese, a variety of Yue from a small coastal area around Taishan, Guangdong.\nIn parts of South China, the dialect of a major city may be only marginally intelligible to its neighbors. For example, Wuzhou and Taishan are located approximately and away from Guangzhou respectively, but the Yue variety spoken in Wuzhou is more similar to the Guangzhou dialect than is Taishanese. Wuzhou is located directly upstream from Guangzhou on the Pearl River, whereas Taishan is to Guangzhou's southwest, with the two cities separated by several river valleys. In parts of Fujian, the speech of some neighbouring counties or villages is mutually unintelligible.\nGrouping.\nLocal varieties of Chinese are conventionally classified into seven dialect groups, largely based on the different evolution of Middle Chinese voiced initials:\n&lt;templatestyles src=\"Pie chart/styles.css\"/&gt;\nThe classification of Li Rong, which is used in the \"Language Atlas of China\" (1987), distinguishes three further groups:\nSome varieties remain unclassified, including the Danzhou dialect on Hainan, Waxianghua spoken in western Hunan, and Shaozhou Tuhua spoken in northern Guangdong.\nStandard Chinese.\nStandard Chinese is the standard language of China (where it is called ) and Taiwan, and one of the four official languages of Singapore (where it is called either or ). Standard Chinese is based on the Beijing dialect of Mandarin. The governments of both China and Taiwan intend for speakers of all Chinese speech varieties to use it as a common language of communication. Therefore, it is used in government agencies, in the media, and as a language of instruction in schools.\nDiglossia is common among Chinese speakers. For example, a Shanghai resident may speak both Standard Chinese and Shanghainese; if they grew up elsewhere, they are also likely fluent in the dialect of their home region. In addition to Standard Chinese, a majority of Taiwanese people also speak Taiwanese Hokkien (also called ), Hakka, or an Austronesian language. A speaker in Taiwan may mix pronunciations and vocabulary from Standard Chinese and other languages of Taiwan in everyday speech. In part due to traditional cultural ties with Guangdong, Cantonese is used as an everyday language in Hong Kong and Macau.\nNomenclature.\nThe designation of various Chinese branches remains controversial. Some linguists and most ordinary Chinese people consider all the spoken varieties as one single language, as speakers share a common national identity and a common written form. Others instead argue that it is inappropriate to refer to major branches of Chinese such as Mandarin, Wu, and so on as \"dialects\" because the mutual unintelligibility between them is too great. However, calling major Chinese branches \"languages\" would also be wrong under the same criterion, since a branch such as Wu, itself contains many mutually unintelligible varieties, and could not be properly called a single language.\nThere are also viewpoints pointing out that linguists often ignore mutual intelligibility when varieties share intelligibility with a central variety (i.e. prestige variety, such as Standard Mandarin), as the issue requires some careful handling when mutual intelligibility is inconsistent with language identity.\nThe Chinese government's official Chinese designation for the major branches of Chinese is , whereas the more closely related varieties within these are called .\nBecause of the difficulties involved in determining the difference between language and dialect, other terms have been proposed. These include \"topolect\", \"lect\", \"vernacular\", \"regional\", and \"variety\".\nPhonology.\nSyllables in the Chinese languages have some unique characteristics. They are tightly related to the morphology and also to the characters of the writing system, and phonologically they are structured according to fixed rules.\nThe structure of each syllable consists of a nucleus that has a vowel (which can be a monophthong, diphthong, or even a triphthong in certain varieties), preceded by an onset (a single consonant, or consonant + glide; a zero onset is also possible), and followed (optionally) by a coda consonant; a syllable also carries a tone. There are some instances where a vowel is not used as a nucleus. An example of this is in Cantonese, where the nasal sonorant consonants and can stand alone as their own syllable.\nIn Mandarin much more than in other spoken varieties, most syllables tend to be open syllables, meaning they have no coda (assuming that a final glide is not analyzed as a coda), but syllables that do have codas are restricted to nasals , , , the retroflex approximant , and voiceless stops , , , or . Some varieties allow most of these codas, whereas others, such as Standard Chinese, are limited to only , , and .\nThe number of sounds in the different spoken dialects varies, but in general, there has been a tendency to a reduction in sounds from Middle Chinese. The Mandarin dialects in particular have experienced a dramatic decrease in sounds and so have far more polysyllabic words than most other spoken varieties. The total number of syllables in some varieties is therefore only about a thousand, including tonal variation, which is only about an eighth as many as English.\nTones.\nAll varieties of spoken Chinese use tones to distinguish words. A few dialects of north China may have as few as three tones, while some dialects in south China have up to 6 or 12 tones, depending on how one counts. One exception from this is Shanghainese which has reduced the set of tones to a two-toned pitch accent system much like modern Japanese.\nA very common example used to illustrate the use of tones in Chinese is the application of the four tones of Standard Chinese, along with the neutral tone, to the syllable . The tones are exemplified by the following five Chinese words:\nIn contrast, Standard Cantonese has six tones. Historically, finals that end in a stop consonant were considered to be \"checked tones\" and thus counted separately for a total of nine tones. However, they are considered to be duplicates in modern linguistics and are no longer counted as such:\nGrammar.\nChinese is often described as a 'monosyllabic' language. However, this is only partially correct. It is largely accurate when describing Old and Middle Chinese; in Classical Chinese, around 90% of words consist of a single character that corresponds one-to-one with a \"morpheme\", the smallest unit of meaning in a language. In modern varieties, it usually remains the case that morphemes are monosyllabic\u2014in contrast, English has many multi-syllable morphemes, both bound and free, such as 'seven', 'elephant', 'para-' and '-able'. Some of the more conservative modern varieties, usually found in the south, have largely monosyllabic words, especially with basic vocabulary. However, most nouns, adjectives, and verbs in modern Mandarin are disyllabic. A significant cause of this is phonetic erosion: sound changes over time have steadily reduced the number of possible syllables in the language's inventory. In modern Mandarin, there are only around 1,200 possible syllables, including the tonal distinctions, compared with about 5,000 in Vietnamese (still a largely monosyllabic language), and over 8,000 in English.\nMost modern varieties tend to form new words through polysyllabic compounds. In some cases, monosyllabic words have become disyllabic formed from different characters without the use of compounding, as in from ; this is especially common in Jin varieties. This phonological collapse has led to a corresponding increase in the number of homophones. As an example, the small \"Langenscheidt Pocket Chinese Dictionary\" lists six words that are commonly pronounced as in Standard Chinese:\nIn modern spoken Mandarin, however, tremendous ambiguity would result if all of these words could be used as-is. The 20th century Yuen Ren Chao poem \"Lion-Eating Poet in the Stone Den\" exploits this, consisting of 92 characters all pronounced . As such, most of these words have been replaced in speech, if not in writing, with less ambiguous disyllabic compounds. Only the first one, , normally appears in monosyllabic form in spoken Mandarin; the rest are normally used in the polysyllabic forms of\nrespectively. In each, the homophone was disambiguated by the addition of another morpheme, typically either a near-synonym or some sort of generic word (e.g., 'head', 'thing'), the purpose of which is to indicate which of the possible meanings of the other, homophonic syllable is specifically meant.\nHowever, when one of the above words forms part of a compound, the disambiguating syllable is generally dropped and the resulting word is still disyllabic. For example, alone, and not , appears in compounds as meaning 'stone' such as , , , , and . Although many single-syllable morphemes () can stand alone as individual words, they more often than not form multi-syllable compounds known as , which more closely resembles the traditional Western notion of a word. A Chinese can consist of more than one character\u2013morpheme, usually two, but there can be three or more.\nExamples of Chinese words of more than two syllables include , , and .\nAll varieties of modern Chinese are analytic languages: they depend on syntax (word order and sentence structure), rather than inflectional morphology (changes in the form of a word), to indicate a word's function within a sentence. In other words, Chinese has very few grammatical inflections\u2014it possesses no tenses, no voices, no grammatical number, and only a few articles. They make heavy use of grammatical particles to indicate aspect and mood. In Mandarin, this involves the use of particles such as , , and .\nChinese has a subject\u2013verb\u2013object word order, and, like many other languages of East Asia, makes frequent use of the topic\u2013comment construction to form sentences. Chinese also has an extensive system of classifiers and measure words, another trait shared with neighboring languages such as Japanese and Korean. Other notable grammatical features common to all the spoken varieties of Chinese include the use of serial verb construction, pronoun dropping, and the related subject dropping. Although the grammars of the spoken varieties share many traits, they do possess differences.\nVocabulary.\nThe entire Chinese character corpus since antiquity comprises well over 50,000 characters, of which only roughly 10,000 are in use and only about 3,000 are frequently used in Chinese media and newspapers. However, Chinese characters should not be confused with Chinese words. Because most Chinese words are made up of two or more characters, there are many more Chinese words than characters. A more accurate equivalent for a Chinese character is the morpheme, as characters represent the smallest grammatical units with individual meanings in the Chinese language.\nEstimates of the total number of Chinese words and lexicalized phrases vary greatly. The \"Hanyu Da Zidian\", a compendium of Chinese characters, includes 54,678 head entries for characters, including oracle bone versions. The \"Zhonghua Zihai\" (1994) contains 85,568 head entries for character definitions and is the largest reference work based purely on character and its literary variants. The CC-CEDICT project (2010) contains 97,404 contemporary entries including idioms, technology terms, and names of political figures, businesses, and products. The 2009 version of the Webster's Digital Chinese Dictionary (WDCD), based on CC-CEDICT, contains over 84,000 entries.\nThe most comprehensive pure linguistic Chinese-language dictionary, the 12-volume \"Hanyu Da Cidian\", records more than 23,000 head Chinese characters and gives over 370,000 definitions. The 1999 revised \"Cihai\", a multi-volume encyclopedic dictionary reference work, gives 122,836 vocabulary entry definitions under 19,485 Chinese characters, including proper names, phrases, and common zoological, geographical, sociological, scientific, and technical terms.\nThe 2016 edition of \"Xiandai Hanyu Cidian\", an authoritative one-volume dictionary on modern standard Chinese language as used in mainland China, has 13,000 head characters and defines 70,000 words.\nLoanwords.\nLike many other languages, Chinese has absorbed a sizable number of loanwords from other cultures. Most Chinese words are formed out of native Chinese morphemes, including words describing imported objects and ideas. However, direct phonetic borrowing of foreign words has gone on since ancient times.\nSome early Indo-European loanwords in Chinese have been proposed, notably , , and perhaps , , , and .\nAncient words borrowed from along the Silk Road during the Old Chinese period include , , and . Some words were borrowed from Buddhist scriptures, including and . Other words came from nomadic peoples to the north, such as . Words borrowed from the peoples along the Silk Road, such as , generally have Persian etymologies. Buddhist terminology is generally derived from Sanskrit or Pali, the liturgical languages of northern India. Words borrowed from the nomadic tribes of the Gobi, Mongolian or northeast regions generally have Altaic etymologies, such as , the Chinese lute, or , but from exactly which source is not always clear.\nModern borrowings.\nModern neologisms are primarily translated into Chinese in one of three ways: free translation (calques), phonetic translation (by sound), or a combination of the two. Today, it is much more common to use existing Chinese morphemes to coin new words to represent imported concepts, such as technical expressions and international scientific vocabulary, wherein the Latin and Greek components are usually converted one-for-one into the corresponding Chinese characters. The word 'telephone' was initially loaned phonetically as (; Shanghainese )\u2014this word was widely used in Shanghai during the 1920s, but the later , built out of native Chinese morphemes became prevalent. Other examples include\nOccasionally, compromises between the transliteration and translation approaches become accepted, such as from + . Sometimes translations are designed so that they sound like the original while incorporating Chinese morphemes (phono-semantic matching), such as for the video game character 'Mario'. This is often done for commercial purposes, for example for 'Pentium' and for 'Subway'.\nForeign words, mainly proper nouns, continue to enter the Chinese language by transcription according to their pronunciations. This is done by employing Chinese characters with similar pronunciations. For example, 'Israel' becomes , and 'Paris' becomes . A rather small number of direct transliterations have survived as common words, including , , , , , and . The bulk of these words were originally coined in Shanghai during the early 20th century and later loaned from there into Mandarin, hence their Mandarin pronunciations occasionally being quite divergent from the English. For example, in Shanghainese and sound more like their English counterparts. Cantonese differs from Mandarin with some transliterations, such as and .\nWestern foreign words representing Western concepts have influenced Chinese since the 20th century through transcription. From French, and were borrowed for 'ballet' and 'champagne' respectively; was borrowed from Italian 'coffee'. The influence of English is particularly pronounced: from the early 20th century, many English words were borrowed into Shanghainese, such as and the aforementioned . Later, American soft power gave rise to , , and . Contemporary colloquial Cantonese has distinct loanwords from English, such as , , , and . With the rising popularity of the Internet, there is a current vogue in China for coining English transliterations, for example, , , and . In Taiwan, some of these transliterations are different, such as and for 'blog'.\nAnother result of English influence on Chinese is the appearance of so-called spelled with letters from the English alphabet. These have appeared in colloquial usage, as well as in magazines and newspapers, and on websites and television:\nSince the 20th century, another source of words has been kanji: Japan re-molded European concepts and inventions into , and many of these words have been re-loaned into modern Chinese. Other terms were coined by the Japanese by giving new senses to existing Chinese terms or by referring to expressions used in classical Chinese literature. For example, ; in Japanese, which in the original Chinese meant 'the workings of the state', narrowed to 'economy' in Japanese; this narrowed definition was then re-imported into Chinese. As a result, these terms are virtually indistinguishable from native Chinese words: indeed, there is some dispute over some of these terms as to whether the Japanese or Chinese coined them first. As a result of this loaning, Chinese, Korean, Japanese, and Vietnamese share a corpus of linguistic terms describing modern terminology, paralleling the similar corpus of terms built from Greco-Latin and shared among European languages.\nWriting system.\nThe Chinese orthography centers on Chinese characters, which are written within imaginary square blocks, traditionally arranged in vertical columns, read from top to bottom down a column, and right to left across columns, despite alternative arrangement with rows of characters from left to right within a row and from top to bottom across rows (like English and other Western writing systems) having become more popular since the 20th century. Chinese characters denote morphemes independent of phonetic variation in different languages. Thus the character is pronounced as in Standard Chinese, in Cantonese and in Hokkien, a form of Min.\nMost modern written Chinese is in the form of written vernacular Chinese, based on spoken Standard Chinese, regardless of dialectical background. Written vernacular Chinese largely replaced Literary Chinese in the early 20th century as the country's standard written language. However, vocabularies from different Chinese-speaking areas have diverged, and the divergence can be observed in written Chinese.\nDue to the divergence of variants, some unique morphemes are not found in Standard Chinese. Characters rarely used in Standard Chinese have also been created or inherited from archaic literary standards to represent these unique morphemes. For example, characters like and are actively used in Cantonese and Hakka, while being archaic or unused in standard written Chinese. The most prominent example of a non-Standard Chinese orthography is Written Cantonese, which is used in tabloids and on the internet among Cantonese speakers in Hong Kong and elsewhere.\nChinese had no uniform system of phonetic transcription until the mid-20th century, although enunciation patterns were recorded in early rhyme dictionaries and dictionaries. Early Indian translators, working in Sanskrit and Pali, were the first to attempt to describe the sounds and enunciation patterns of Chinese in a foreign language. After the 15th century, the efforts of Jesuits and Western court missionaries resulted in some Latin character transcription/writing systems, based on various variants of Chinese languages. Some of these Latin character-based systems are still being used to write various Chinese variants in the modern era.\nIn Hunan, women in certain areas write their local Chinese language variant in N\u00fcshu, a syllabary derived from Chinese characters. The Dungan language, considered by many a dialect of Mandarin, is nowadays written in Cyrillic and was previously written in the Arabic script. The Dungan people are primarily Muslim and live mainly in Kazakhstan, Kyrgyzstan, and Russia; many Hui people, living mainly in China, also speak the language.\nChinese characters.\nEach Chinese character represents a monosyllabic Chinese word or morpheme. In 100 CE, the famed Han dynasty scholar Xu Shen classified characters into six categories: pictographs, simple ideographs, compound ideographs, phonetic loans, phonetic compounds, and derivative characters. Only 4% were categorized as pictographs, including many of the simplest characters, such as , , , and . Between 80% and 90% were classified as phonetic compounds such as , combining a phonetic component with a semantic component of the radical , a reduced form of . Almost all characters created since have been made using this format. The 18th-century \"Kangxi Dictionary\" classified characters under a now-common set of 214 radicals.\nModern characters are styled after the regular script. Various other written styles are also used in Chinese calligraphy, including seal script, cursive script and clerical script. Calligraphy artists can write in Traditional and Simplified characters, but they tend to use Traditional characters for traditional art.\nThere are currently two systems for Chinese characters. Traditional characters, used in Hong Kong, Taiwan, Macau, and many overseas Chinese-speaking communities, largely take their form from received character forms dating back to the late Han dynasty and standardized during the Ming. Simplified characters, introduced by the People's Republic of China (PRC) in 1954 to promote mass literacy, simplifies most complex traditional glyphs to fewer strokes, especially by adopting common cursive shorthand variants and merging characters with similar pronunciations to the one with the least strokes, among other methods. Singapore, which has a large Chinese community, was the second nation to officially adopt simplified characters\u2014first by creating its own simplified characters, then by adopting entirely the PRC simplified characters. It has also become the de facto standard for younger ethnic Chinese in Malaysia.\nThe Internet provides practice reading each of these systems, and most Chinese readers are capable of, if not necessarily comfortable with, reading the alternative system through experience and guesswork.\nA well-educated Chinese reader today recognizes approximately 4,000 to 6,000 characters; approximately 3,000 characters are required to read a mainland newspaper. The PRC defines literacy amongst workers as a knowledge of 2,000 characters, though this would be only functional literacy. School children typically learn around 2,000 characters whereas scholars may memorize up to 10,000. A large unabridged dictionary like the \"Kangxi\" dictionary, contains over 40,000 characters, including obscure, variant, rare, and archaic characters; fewer than a quarter of these characters are now commonly used.\nRomanization.\nRomanization is the process of transcribing a language into the Latin script. There are many systems of romanization for the Chinese varieties, due to the lack of a native phonetic transcription until modern times. Chinese is first known to have been written in Latin characters by Western Christian missionaries in the 16th century.\nToday the most common romanization for Standard Chinese is Hanyu Pinyin, introduced in 1956 by the PRC, and later adopted by Singapore and Taiwan. Pinyin is almost universally employed now for teaching standard spoken Chinese in schools and universities across the Americas, Australia, and Europe. Chinese parents also use Pinyin to teach their children the sounds and tones of new words. In school books that teach Chinese, the pinyin romanization is often shown below a picture of the thing the word represents, with the Chinese character alongside.\nThe second-most common romanization system, the Wade\u2013Giles, was invented by Thomas Wade in 1859 and modified by Herbert Giles in 1892. As this system approximates the phonology of Mandarin Chinese into English consonants and vowels\u2013it is largely an anglicization, it may be particularly helpful for beginner Chinese speakers of an English-speaking background. Wade\u2013Giles was found in academic use in the United States, particularly before the 1980s, and was widely used in Taiwan until 2009.\nWhen used within European texts, the tone transcriptions in both pinyin and Wade\u2013Giles are often left out for simplicity; Wade\u2013Giles's extensive use of apostrophes is also usually omitted. Thus, most Western readers will be much more familiar with \"Beijing\" than they will be with (pinyin), and with than (Wade\u2013Giles). This simplification presents syllables as homophones which are not, and therefore exaggerates the number of homophones almost by a factor of four.\nFor comparison:\nOther systems include Gwoyeu Romatzyh, the French EFEO, the Yale system (invented for use by US troops during World War II), as well as distinct systems for the phonetic requirements of Cantonese, Min Nan, Hakka, and other varieties.\nOther phonetic transcriptions.\nChinese varieties have been phonetically transcribed into many other writing systems over the centuries. The 'Phags-pa script, for example, has been very helpful in reconstructing the pronunciations of premodern forms of Chinese. Bopomofo (or \"zhuyin\") is a semi-syllabary that is still widely used in Taiwan to aid standard pronunciation. There are also at least two systems of cyrillization for Chinese. The most widespread is the Palladius system.\nAs a foreign language.\nWith the growing importance and influence of China's economy globally, Standard Chinese instruction has been gaining popularity in schools throughout East Asia, Southeast Asia, and the Western world.\nBesides Mandarin, Cantonese is the only other Chinese language that is widely taught as a foreign language, largely due to the economic and cultural influence of Hong Kong and its widespread usage among significant Overseas Chinese communities.\nIn 1991, there were 2,000 foreign learners taking China's official Chinese Proficiency Test, called Hanyu Shuiping Kaoshi (HSK), comparable to the English Cambridge Certificate, but by 2005 the number of candidates had risen sharply to 117,660 and in 2010 to 750,000.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nSources.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "5753", "revid": "42056547", "url": "https://en.wikipedia.org/wiki?curid=5753", "title": "Coitus", "text": ""}
{"id": "5759", "revid": "50994656", "url": "https://en.wikipedia.org/wiki?curid=5759", "title": "Complex analysis", "text": "Branch of mathematics studying functions of a complex variable\nComplex analysis, traditionally known as the theory of functions of a complex variable, is the branch of mathematical analysis that investigates functions of a complex variable of complex numbers. It is helpful in many branches of mathematics, including real analysis, algebraic geometry, number theory, analytic combinatorics, and applied mathematics, as well as in physics, including the branches of hydrodynamics, thermodynamics, quantum mechanics, and twistor theory. By extension, use of complex analysis also has applications in engineering fields such as nuclear, aerospace, mechanical and electrical engineering.\nAt first glance, complex analysis is the study of holomorphic functions that are the differentiable functions of a complex variable. By contrast with the real case, a holomorphic functions is always infinitely differentiable and equal to the sum of its Taylor series in some neighborhood of each point of its domain.\nThis makes methods and results of complex analysis significantly different from that of real analysis. In particular, contrarily, with the real case, the domain of every holomorphic function can be uniquely extended to almost the whole complex plane. This implies that the study of real analytic functions needs often the power of complex analysis. This is, in particular, the case in analytic combinatorics.\nHistory.\nComplex analysis is one of the classical branches in mathematics, with roots in the 18th century and just prior. Important mathematicians associated with complex numbers include Euler, Gauss, Riemann, Cauchy, Weierstrass, and many more in the 20th century. Complex analysis, in particular the theory of conformal mappings, has many physical applications and is also used throughout analytic number theory. In modern times, it has become very popular through a new boost from complex dynamics and the pictures of fractals produced by iterating holomorphic functions. Another important application of complex analysis is in string theory which examines conformal invariants in quantum field theory.\nComplex functions.\nA complex function is a function from complex numbers to complex numbers. In other words, it is a function that has a subset of the complex numbers as a domain and the complex numbers as a codomain. Complex functions are generally assumed to have a domain that contains a nonempty open subset of the complex plane.\nFor any complex function, the values formula_1 from the domain and their images formula_2 in the range may be separated into real and imaginary parts:\n formula_3\nwhere formula_4 are all real-valued.\nIn other words, a complex function formula_5 may be decomposed into two real-valued functions (formula_6, formula_7) of two real variables (formula_8, formula_9):\n formula_10 and formula_11\nA complex function is continuous if and only if its associated vector-valued function of teo variables is also continuous. However, this identification does not extend to differentiability. The definition of the derivative of a complex function is very similar to that of a real function, but the differentiability of the associated real function of two variables does not implies that the derivative of the complex function exists. In particular, if a complex function has a derivative,it has derivatives of every order and equals the sum of its Taylor series in a neighborhood of every point of its domain. \nIt follows that two differentiable functions that are equal in a neighborhood of a point are equal on the intersection of their domain if the domains are connected. The latter property is the basis of the principle of analytic continuation which allows extending every real or complex analytic function in a unique way for getting a complex analytic function whose domain is the whole complex plane with a finite number of curve arcs removed. Many basic and special complex functions are defined in this way, including the complex exponential function, complex logarithm functions, and trigonometric functions.\nHolomorphic functions.\nComplex functions that are differentiable at every point of an open subset formula_12 of the complex plane are said to be \"holomorphic on\" formula_12. In the context of complex analysis, the derivative of formula_14 at formula_15 is defined to be\n formula_16\nSuperficially, this definition is formally analogous to that of the derivative of a real function. However, complex derivatives and differentiable functions behave in significantly different ways compared to their real counterparts. In particular, for this limit to exist, the value of the difference quotient must approach the same complex number, regardless of the manner in which we approach formula_15 in the complex plane. Consequently, complex differentiability has much stronger implications than real differentiability. For instance, holomorphic functions are infinitely differentiable, whereas the existence of the \"n\"th derivative need not imply the existence of the (\"n\" + 1)th derivative for real functions. Furthermore, all holomorphic functions satisfy the stronger condition of analyticity, meaning that the function is, at every point in its domain, locally given by a convergent power series. In essence, this means that functions holomorphic on formula_12 can be approximated arbitrarily well by polynomials in some neighborhood of every point in formula_12. This stands in sharp contrast to differentiable real functions; there are infinitely differentiable real functions that are \"nowhere\" analytic; see .\nMost elementary functions, including the exponential function, the trigonometric functions, and all polynomial functions, extended appropriately to complex arguments as functions formula_20, are holomorphic over the entire complex plane, making them \"entire functions\", while rational functions formula_21, where \"p\" and \"q\" are polynomials, are holomorphic on domains that exclude points where \"q\" is zero. Such functions that are holomorphic everywhere except a set of isolated points are known as \"meromorphic functions\". On the other hand, the functions formula_22, formula_23 are not holomorphic anywhere on the complex plane, as can be shown by their failure to satisfy the Cauchy\u2013Riemann conditions (see below).\nAn important property of holomorphic functions is the relationship between the partial derivatives of their real and imaginary components, known as the Cauchy\u2013Riemann conditions. If formula_5, defined by where formula_25, is holomorphic on a region formula_12, then for all formula_27,\nformula_28\nIn terms of the real and imaginary parts of the function, \"u\" and \"v\", this is equivalent to the pair of equations formula_29 and formula_30, where the subscripts indicate partial differentiation. However, the Cauchy\u2013Riemann conditions do not characterize holomorphic functions, without additional continuity conditions (see Looman\u2013Menchoff theorem).\nHolomorphic functions exhibit some remarkable features. For instance, Picard's theorem asserts that the range of an entire function can take only three possible forms: formula_31, formula_32, or formula_33 for some formula_34. In other words, if two distinct complex numbers formula_1 and formula_36 are not in the range of an entire function formula_14, then formula_14 is a constant function. Moreover, a holomorphic function on a connected open set is determined by its restriction to any nonempty open subset.\nMajor results.\nOne of the central tools in complex analysis is the line integral. The line integral around a closed path of a function that is holomorphic everywhere inside the area bounded by the closed path is always zero, as is stated by the Cauchy integral theorem. The values of such a holomorphic function inside a disk can be computed by a path integral on the disk's boundary (as shown in Cauchy's integral formula). Path integrals in the complex plane are often used to determine complicated real integrals, and here the theory of residues among others is applicable (see methods of contour integration). A \"pole\" (or isolated singularity) of a function is a point where the function's value becomes unbounded, or \"blows up\". If a function has such a pole, then one can compute the function's residue there, which can be used to compute path integrals involving the function; this is the content of the powerful residue theorem. The remarkable behavior of holomorphic functions near essential singularities is described by Picard's theorem. Functions that have only poles but no essential singularities are called meromorphic. Laurent series are the complex-valued equivalent to Taylor series, but can be used to study the behavior of functions near singularities through infinite sums of more well understood functions, such as polynomials.\nA bounded function that is holomorphic in the entire complex plane must be constant; this is Liouville's theorem. It can be used to provide a natural and short proof for the fundamental theorem of algebra which states that the field of complex numbers is algebraically closed.\nIf a function is holomorphic throughout a connected domain then its values are fully determined by its values on any smaller subdomain. The function on the larger domain is said to be analytically continued from its values on the smaller domain. This allows the extension of the definition of functions, such as the Riemann zeta function, which are initially defined in terms of infinite sums that converge only on limited domains to almost the entire complex plane. Sometimes, as in the case of the natural logarithm, it is impossible to analytically continue a holomorphic function to a non-simply connected domain in the complex plane but it is possible to extend it to a holomorphic function on a closely related surface known as a Riemann surface.\nAll this refers to complex analysis in one variable. There is also a very rich theory of complex analysis in more than one complex dimension in which the analytic properties such as power series expansion carry over whereas most of the geometric properties of holomorphic functions in one complex dimension (such as conformality) do not carry over. The Riemann mapping theorem about the conformal relationship of certain domains in the complex plane, which may be the most important result in the one-dimensional theory, fails dramatically in higher dimensions.\nA major application of certain complex spaces is in quantum mechanics as wave functions.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "5760", "revid": "7769175", "url": "https://en.wikipedia.org/wiki?curid=5760", "title": "History of China", "text": "The history of China spans several millennia across a wide geographical area. Each region now considered part of the Chinese world has experienced periods of unity, fracture, prosperity, and strife. Chinese civilization first emerged in the Yellow River valley, which along with the Yangtze basin constitutes the geographic core of the Chinese cultural sphere. China maintains a rich diversity of ethnic and linguistic people groups. The traditional lens for viewing Chinese history is the dynastic cycle: imperial dynasties rise and fall, and are ascribed certain achievements. This lens also tends to assume Chinese civilization can be traced as an unbroken thread many thousands of years into the past, making it one of the cradles of civilization. At various times, states representative of a dominant Chinese culture have directly controlled areas stretching as far west as the Tian Shan, the Tarim Basin, and the Himalayas, as far north as the Sayan Mountains, and as far south as the delta of the Red River.\nThe Neolithic period saw increasingly complex polities begin to emerge along the Yellow and Yangtze rivers. The Erlitou culture in the central plains of China is sometimes identified with the Xia dynasty (3rd millennium\u00a0BC) of traditional Chinese historiography. The earliest surviving written Chinese dates to roughly 1250\u00a0BC, consisting of divinations inscribed on oracle bones. Chinese bronze inscriptions, ritual texts dedicated to ancestors, form another large corpus of early Chinese writing. The earliest strata of received literature in Chinese include poetry, divination, and records of official speeches. China is believed to be one of a very few loci of independent invention of writing, and the earliest surviving records display an already-mature written language. The culture remembered by the earliest extant literature is that of the Zhou dynasty (c.\u20091046\u00a0\u2013 256\u00a0BC), China's Axial Age, during which the Mandate of Heaven was introduced, and foundations laid for philosophies such as Confucianism, Taoism, Legalism, and \"Wuxing\".\nChina was first united under a single imperial state by Qin Shi Huang in 221\u00a0BC. Orthography, weights, measures, and law were all standardized. Shortly thereafter, China entered its classical era with the Han dynasty (202\u00a0BC\u00a0\u2013 220\u00a0AD), marking a critical period. A term for the Chinese language is still \"Han language\", and the dominant Chinese ethnic group is known as Han Chinese. The Chinese empire reached some of its farthest geographical extents during this period. Confucianism was officially sanctioned and its core texts were edited into their received forms. Wealthy landholding families independent of the ancient aristocracy began to wield significant power. Han technology can be considered on par with that of the contemporaneous Roman Empire: mass production of paper aided the proliferation of written documents, and the written language of this period was employed for millennia afterwards. China became known internationally for its sericulture. When the Han imperial order finally collapsed after four centuries, China entered an equally lengthy period of disunity, during which Buddhism began to have a significant impact on Chinese culture, while calligraphy, art, historiography, and storytelling flourished. Wealthy families in some cases became more powerful than the central government. The Yangtze River valley was incorporated into the dominant cultural sphere.\nA period of unity began in 581 with the Sui dynasty, which soon gave way to the long-lived Tang dynasty (608\u2013907), regarded as another Chinese golden age. The Tang dynasty saw flourishing developments in science, technology, poetry, economics, and geographical influence. China's only officially recognized empress, Wu Zetian, reigned during the dynasty's first century. Buddhism was adopted by Tang emperors. \"Tang people\" is the other common demonym for the Han ethnic group. After the Tang fractured, the Song dynasty (960\u20131279) saw the maximal extent of imperial Chinese cosmopolitan development. Mechanical printing was introduced, and many of the earliest surviving witnesses of certain texts are wood-block prints from this era. Song scientific advancement led the world, and the imperial examination system gave ideological structure to the political bureaucracy. Confucianism and Taoism were fully knit together in Neo-Confucianism.\nEventually, the Mongol Empire conquered all of China, establishing the Yuan dynasty in 1271. Contact with Europe began to increase during this time. Achievements under the subsequent Ming dynasty (1368\u20131644) include global exploration, fine porcelain, and many extant public works projects, such as those restoring the Grand Canal and Great Wall. Three of the four Classic Chinese Novels were written during the Ming. The Qing dynasty that succeeded the Ming was ruled by ethnic Manchu people. The Qianlong emperor (r. 1735\u20131796) commissioned a complete encyclopaedia of imperial libraries, totaling nearly a billion words. Imperial China reached its greatest territorial extent during the Qing, but China came into increasing conflict with European powers, culminating in the Opium Wars and subsequent unequal treaties.\nThe 1911 Xinhai Revolution, led by Sun Yat-sen and others, created the Republic of China. From 1927 to 1949, a costly civil war roiled between the Republican government under Chiang Kai-shek and the Communist-aligned Chinese Red Army, interrupted by the industrialized Empire of Japan invading the divided country until its defeat in the Second World War.\nAfter the Communist victory, Mao Zedong proclaimed the establishment of the People's Republic of China (PRC) in 1949, with the ROC retreating to Taiwan. Both governments still claim sole legitimacy of the entire mainland area. The PRC has slowly accumulated the majority of diplomatic recognition, and Taiwan's status remains disputed to this day. From 1966 to 1976, the Cultural Revolution in mainland China helped consolidate Mao's power towards the end of his life. After his death, the government began economic reforms under Deng Xiaoping, and became the world's fastest-growing major economy. China had been the most populous nation in the world for decades since its unification, until it was surpassed by India in 2023.\nPrehistory.\nPaleolithic (1.7 Ma \u2013 12 ka).\nThe archaic human species of \"Homo erectus\" arrived in Eurasia sometime between 1.3 and 1.8 million years ago (Ma) and numerous remains of its subspecies have been found in what is now China. The oldest of these is the southwestern Yuanmou Man (; in Yunnan), dated to c. 1.7 Ma, which lived in a mixed bushland-forest environment alongside chalicotheres, deer, the elephant \"Stegodon\", rhinos, cattle, pigs, and the giant short-faced hyena. The better-known Peking Man (; near Beijing) of 700,000\u2013400,000 BP, was discovered in the Zhoukoudian cave alongside scrapers, choppers, and, dated slightly later, points, burins, and awls. Other \"Homo erectus\" fossils have been found widely throughout the region, including the northwestern Lantian Man in Shaanxi, as well minor specimens in northeastern Liaoning and southern Guangdong. The dates of most Paleolithic sites were long debated but have been more reliably established based on modern magnetostratigraphy: Majuangou at 1.66\u20131.55 Ma, Lanpo at 1.6 Ma, Xiaochangliang at 1.36 Ma, Xiantai at 1.36 Ma, Banshan at 1.32 Ma, Feiliang at 1.2 Ma and Donggutuo at 1.1 Ma. Evidence of fire use by \"Homo erectus\" occurred between 1\u20131.8\u00a0million years BP at the archaeological site of Xihoudu, Shanxi Province.\nThe circumstances surrounding the evolution of \"Homo erectus\" to contemporary \"H. sapiens\" is debated; the three main theories include the dominant \"Out of Africa\" theory (OOA), the regional continuity model and the admixture variant of the OOA hypothesis. Regardless, the earliest modern humans have been dated to China at 120,000\u201380,000 BP based on fossilized teeth discovered in Fuyan Cave of Dao County, Hunan. The larger animals which lived alongside these humans include the extinct \"Ailuropoda baconi\" panda, the \"Crocuta ultima\" hyena, the \"Stegodon\", and the giant tapir. Evidence of Middle Palaeolithic Levallois technology has been found in the lithic assemblage of Guanyindong Cave site in southwest China, dated to approximately 170,000\u201380,000 years ago.\nNeolithic.\nThe Neolithic Age in China is considered to have begun about 10,000 years ago. Because the Neolithic is conventionally defined by the presence of agriculture, it follows that the Neolithic began at different times in the various regions of what is now China. Agriculture in China developed gradually, with initial domestication of a few grains and animals gradually expanding with the addition of many others over subsequent millennia. The earliest evidence of cultivated rice, found by the Yangtze River, was carbon-dated to 8,000 years ago. Early evidence for millet agriculture in the Yellow River valley was radiocarbon-dated to about 7000 BC. The Jiahu site is one of the best preserved early agricultural villages (7000 to 5800 BC). At Damaidi in Ningxia, 3,172 cliff carvings dating to 6000\u20135000 BC have been discovered, \"featuring 8,453 individual characters such as the sun, moon, stars, gods and scenes of hunting or grazing\", according to researcher Li Xiangshi. Written symbols, sometimes called proto-writing, were found at the site of Jiahu, which is dated around 7000 BC, Damaidi around 6000 BC, Dadiwan from 5800 BC to 5400 BC, and Banpo dating from the 5th millennium BC. With agriculture came increased population, the ability to store and redistribute crops, and the potential to support specialist craftsmen and administrators, which may have existed at late Neolithic sites like Taosi and the Liangzhu culture in the Yangtze delta. The cultures of the middle and late Neolithic in the central Yellow River valley are known, respectively, as the Yangshao culture (5000 BC to 3000 BC) and the Longshan culture (3000 BC to 2000 BC). Pigs and dogs were the earliest-domesticated animals in the region, and after about 3000 BC domesticated cattle and sheep arrived from Western Asia. Wheat also arrived at this time but remained a minor crop. Fruit such as peaches, cherries and oranges, as well as chickens and various vegetables, were also domesticated in Neolithic China.\nBronze Age.\nBronze artifacts have been found at the Majiayao culture site (between 3100 and 2700\u00a0BC). The Bronze Age is also represented at the Lower Xiajiadian culture (2200\u20131600\u00a0BC) site in northeast China. Sanxingdui located in what is now Sichuan is believed to be the site of a major ancient city, of a previously unknown Bronze Age culture (between 2000 and 1200\u00a0BC). The site was first discovered in 1929 and then re-discovered in 1986. Chinese archaeologists have identified the Sanxingdui culture to be part of the state of Shu, linking the artifacts found at the site to its early legendary kings. The graves at Mogou revealed a high level of violence in the Qijia culture.\nFerrous metallurgy begins to appear in the late 6th century in the Yangtze valley. A bronze hatchet with a blade of meteoric iron excavated near the city of Gaocheng in Shijiazhuang (now Hebei) has been dated to the 14th century\u00a0BC. An Iron Age culture of the Tibetan Plateau has tentatively been associated with the Zhang Zhung culture described in early Tibetan writings.\nAncient China.\nChinese historians in later periods were accustomed to the notion of one dynasty succeeding another, but the political situation in early China was much more complicated. Hence, as some scholars of China suggest, the Xia and the Shang can refer to political entities that existed concurrently, just as the early Zhou existed at the same time as the Shang. This bears similarities to how China, both contemporaneously and later, has been divided into states that were not one region, legally or culturally.\nThe earliest period once considered historical was the legendary era of the sage-emperors Yao, Shun, and Yu. Traditionally, the abdication system was prominent in this period, with Yao yielding his throne to Shun, who abdicated to Yu, who founded the Xia dynasty.\nXia dynasty (c. 2070 \u2013 c. 1600 BC).\nThe Xia dynasty (c.\u20092070\u00a0\u2013 c.\u20091600 BC) is the earliest of the three dynasties described in much later traditional historiography, which includes the \"Bamboo Annals\" and Sima Qian's \"Shiji\" (c.\u200991\u00a0BC). The Xia is generally considered mythical by Western scholars, but in China it is usually associated with the early Bronze Age site at Erlitou (1900\u20131500\u00a0BC) in Henan that was excavated in 1959. Since no writing was excavated at Erlitou or any other contemporaneous site, there is not enough evidence to prove whether the Xia dynasty ever existed. Some archaeologists claim that the Erlitou site was the capital of the Xia. In any case, the site of Erlitou had a level of political organization that would not be incompatible with the legends of Xia recorded in later texts. More importantly, the Erlitou site has the earliest evidence for an elite who conducted rituals using cast bronze vessels, which would later be adopted by the Shang and Zhou.\nShang dynasty (c. 1600 \u2013 c. 1046 BC).\nBoth archaeological evidence like oracle bones and bronzes, as well as transmitted texts attest the historical existence of the Shang dynasty (c.\u20091600\u00a0\u2013 c.\u20091046\u00a0BC). Findings from the earlier Shang period come from excavations at Erligang (modern Zhengzhou). Findings have been found at Yinxu (near modern Anyang, Henan), the site of the final Shang capital during the Late Shang period (c.\u20091250\u20131050\u00a0BC). The findings at Anyang include the earliest written record of the Chinese so far discovered: inscriptions of divination records in ancient Chinese writing on the bones or shells of animals\u2014the oracle bones, dating from c.\u20091250\u00a0\u2013 c.\u20091046\u00a0BC.\nA series of at least twenty-nine kings reigned over the Shang dynasty. Throughout their reigns, according to the \"Shiji\", the capital city was moved six times. The final and most important move was to Yin during the reign of Wu Ding c.\u20091250\u00a0BC. The term Yin dynasty has been synonymous with the Shang dynasty in history, although it has lately been used to refer specifically to the latter half of the Shang dynasty.\nAlthough written records found at Anyang confirm the existence of the Shang dynasty, Western scholars are often hesitant to associate settlements that are contemporaneous with the Anyang settlement with the Shang dynasty. For example, archaeological findings at Sanxingdui suggest a technologically advanced civilization culturally unlike Anyang. The evidence is inconclusive in proving how far the Shang realm extended from Anyang. The leading hypothesis is that Anyang, ruled by the same Shang in the official history, coexisted and traded with numerous other culturally diverse settlements in the area that is now referred to as China proper.\nZhou dynasty (1046\u2013256 BC).\nThe Zhou dynasty (1046 BC to about 256 BC) is the longest-lasting dynasty in Chinese history, though its power declined steadily over the almost eight centuries of its existence. In the late 2nd millennium BC, the Zhou dynasty arose in the Wei River valley of modern western Shaanxi Province, where they were appointed Western Protectors by the Shang. A coalition led by the ruler of the Zhou, King Wu, defeated the Shang at the Battle of Muye. They took over most of the central and lower Yellow River valley and enfeoffed their relatives and allies in semi-independent states across the region. Several of these states eventually became more powerful than the Zhou kings.\nThe kings of Zhou invoked the concept of the Mandate of Heaven to legitimize their rule, a concept that was influential for almost every succeeding dynasty. Like Shangdi, Heaven (\"tian\") ruled over all the other gods, and it decided who would rule China. It was believed that a ruler lost the Mandate of Heaven when natural disasters occurred in great number, and when, more realistically, the sovereign had apparently lost his concern for the people. In response, the royal house would be overthrown, and a new house would rule, having been granted the Mandate of Heaven.\nThe Zhou established two capitals Zongzhou (near modern Xi'an) and Chengzhou (Luoyang), with the king's court moving between them regularly. The Zhou alliance gradually expanded eastward into Shandong, southeastward into the Huai River valley, and southward into the Yangtze River valley.\nSpring and Autumn period (722\u2013476 BC).\nIn 771 BC, King You and his forces were defeated in the Battle of Mount Li by rebel states and Quanrong barbarians. The rebel aristocrats established a new ruler, King Ping, in Luoyang, beginning the second major phase of the Zhou dynasty: the Eastern Zhou period, which is divided into the Spring and Autumn and Warring States periods. The former period is named after the famous \"Spring and Autumn Annals\". The sharply reduced political authority of the royal house left a power vacuum at the center of the Zhou culture sphere. The Zhou kings had delegated local political authority to hundreds of settlement states, some of them only as large as a walled town and surrounding land. These states began to fight against one another and vie for hegemony. The more powerful states tended to conquer and incorporate the weaker ones, so the number of states declined over time. By the 6th century BC most small states had disappeared by being annexed and just a few large and powerful principalities remained. Some southern states, such as Chu and Wu, claimed independence from the Zhou, who undertook wars against some of them (Wu and Yue). Many new cities were established in this period and society gradually became more urbanized and commercialized. Many famous individuals such as Laozi, Confucius and Sun Tzu lived during this chaotic period.\nConflict in this period occurred both between and within states. Warfare between states forced the surviving states to develop better administrations to mobilize more soldiers and resources. Within states there was constant jockeying between elite families. For example, the three most powerful families in the Jin state\u2014Zhao, Wei and Han\u2014eventually overthrew the ruling family and partitioned the state between them.\nThe Hundred Schools of Thought of classical Chinese philosophy began blossoming during this period and the subsequent Warring States period. Such influential intellectual movements as Confucianism, Taoism, Legalism and Mohism were founded, partly in response to the changing political world. The first two philosophical thoughts would have an enormous influence on Chinese culture.\nWarring States period (476\u2013221 BC).\nAfter further political consolidations, seven prominent states remained during the 5th centuryBC. The years in which these states battled each other is known as the Warring States period. Though the Zhou king nominally remained as such until 256BC, he was largely a figurehead that held little real power.\nNumerous developments were made during this period in the areas of culture and mathematics\u2014including the \"Zuo Zhuan\" within the \"Spring and Autumn Annals\" (a literary work summarizing the preceding Spring and Autumn period), and the bundle of 21 bamboo slips from the Tsinghua collection, dated to 305BC\u2014being the world's earliest known example of a two-digit, base-10 multiplication table. The Tsinghua collection indicates that sophisticated commercial arithmetic was already established during this period.\nAs neighboring territories of the seven states were annexed (including areas of modern Sichuan and Liaoning), they were now to be governed under an administrative system of commanderies and prefectures. This system had been in use elsewhere since the Spring and Autumn period, and its influence on administration would prove resilient\u2014its terminology can still be seen in the contemporaneous \"sheng\" and \"xian\" (\"provinces\" and \"counties\") of contemporary China.\nThe state of Qin became dominant in the waning decades of the Warring States period, conquering the Shu capital of Jinsha on the Chengdu Plain; and then eventually driving Chu from its place in the Han River valley. Qin imitated the administrative reforms of the other states, thereby becoming a powerhouse. Its final expansion began during the reign of Ying Zheng, ultimately unifying the other six regional powers, and enabling him to proclaim himself as China's first emperor\u2014known to history as Qin Shi Huang.\nImperial era.\nEarly imperial China.\nQin dynasty (221\u2013206 BC).\nYing Zheng's establishment of the Qin dynasty () in 221 BC effectively formalised the region as a true empire for the first time in Chinese history, rather than a state, and its pivotal status probably led to \"Qin\" () later evolving into the Western term \"China\". To emphasise his sole rule, Zheng proclaimed himself (\u59cb\u7687\u5e1d; \"First Emperor\"); the title, derived from Chinese mythology, became the standard for subsequent rulers. Based in Xianyang, the empire was a centralized bureaucratic monarchy, a governing scheme which dominated the future of Imperial China. In an effort to improve the Zhou's perceived failures, this system consisted of more than 36 commanderies (; ), made up of counties (; ) and progressively smaller divisions, each with a local leader.\nMany aspects of society were informed by Legalism, a state ideology promoted by the emperor and his chancellor Li Si that was introduced at an earlier time by Shang Yang. In legal matters this philosophy emphasised mutual responsibility in disputes and severe punishments for crime, while economic practices included the general encouragement of agriculture and repression of trade. Reforms occurred in weights and measures, writing styles (seal script) and metal currency (Ban Liang), all of which were standardized. Traditionally, Qin Shi Huang is regarded as ordering a mass burning of books and the live burial of scholars under the guise of Legalism, though contemporary scholars express considerable doubt on the historicity of this event. Despite its importance, Legalism was probably supplemented in non-political matters by Confucianism for social and moral beliefs and the five-element Wuxing () theories for cosmological thought.\nThe Qin administration kept exhaustive records on their population, collecting information on their sex, age, social status and residence. Commoners, who made up over 90% of the population, \"suffered harsh treatment\" according to the historian Patricia Buckley Ebrey, as they were often conscripted into forced labor for the empire's construction projects. This included a massive system of imperial highways in 220 BC, which ranged around altogether. Other major construction projects were assigned to the general Meng Tian, who concurrently led a successful campaign against the northern Xiongnu peoples (210s BC), reportedly with 300,000 troops. Under Qin Shi Huang's orders, Meng supervised the combining of numerous ancient walls into what came to be known as the Great Wall of China and oversaw the building of a straight highway between northern and southern China. The emperor also oversaw the construction of his monumental mausoleum, which includes the well known Terracotta Army.\nAfter Qin Shi Huang's death the Qin government drastically deteriorated and eventually capitulated in 207 BC after the Qin capital was captured and sacked by rebels, which would ultimately lead to the establishment of the Han Empire.\nHan dynasty (206 BC \u2013 AD 220).\nWestern Han.\nThe Han dynasty was founded by Liu Bang, who emerged victorious in the Chu\u2013Han Contention that followed the fall of the Qin dynasty. A golden age in Chinese history, the Han dynasty's long period of stability and prosperity consolidated the foundation of China as a unified state under a central imperial bureaucracy, which was to last intermittently for most of the next two millennia. During the Han dynasty, territory of China was extended to most of the China proper and to areas far west. Confucianism was officially elevated to orthodox status and was to shape the subsequent Chinese civilization. Art, culture and science all advanced to unprecedented heights. With the profound and lasting impacts of this period of Chinese history, the dynasty name \"Han\" had been taken as the name of the Chinese people, now the dominant ethnic group in modern China, and had been commonly used to refer to Chinese language and written characters.\nAfter the initial laissez-faire policies of Emperors Wen and Jing, the ambitious Emperor Wu brought the empire to its zenith. To consolidate his power, he disenfranchised the majority of imperial relatives, appointing military governors to control their former lands. As a further step, he extended patronage to Confucianism, which emphasizes stability and order in a well-structured society. Imperial Universities were established to support its study. At the urging of his Legalist advisors, however, he also strengthened the fiscal structure of the dynasty with government monopolies.\nMajor military campaigns were launched to weaken the nomadic Xiongnu Empire, limiting their influence north of the Great Wall. Along with the diplomatic efforts led by Zhang Qian, the sphere of influence of the Han Empire extended to the states in the Tarim Basin, opened up the Silk Road that connected China to the west, stimulating bilateral trade and cultural exchange. To the south, various small kingdoms far beyond the Yangtze River Valley were formally incorporated into the empire.\nEmperor Wu also dispatched a series of military campaigns against the Baiyue tribes. The Han annexed Minyue in 135 BC and 111 BC, Nanyue in 111 BC, and Dian in 109 BC. Migration and military expeditions led to the cultural assimilation of the south. It also brought the Han into contact with kingdoms in Southeast Asia, introducing diplomacy and trade.\nAfter Emperor Wu the empire slipped into gradual stagnation and decline. Economically, the state treasury was strained by excessive campaigns and projects, while land acquisitions by elite families gradually drained the tax base. Various consort clans exerted increasing control over strings of incompetent emperors and eventually the dynasty was briefly interrupted by the usurpation of Wang Mang.\nXin dynasty.\nIn AD 9 the usurper Wang Mang claimed that the Mandate of Heaven called for the end of the Han dynasty and the rise of his own, and he founded the short-lived Xin dynasty. Wang Mang started an extensive program of land and other economic reforms, including the outlawing of slavery and land nationalization and redistribution. These programs, however, were never supported by the landholding families, because they favored the peasants. The instability of power brought about chaos, uprisings, and loss of territories. This was compounded by mass flooding of the Yellow River; silt buildup caused it to split into two channels and displaced large numbers of farmers. Wang Mang was eventually killed in Weiyang Palace by an enraged peasant mob in AD 23.\nEastern Han.\nEmperor Guangwu reinstated the Han dynasty with the support of landholding and merchant families at Luoyang, \"east\" of the former capital Xi'an. Thus, this new era is termed the Eastern Han dynasty. With the capable administrations of Emperors Ming and Zhang, former glories of the dynasty were reclaimed, with brilliant military and cultural achievements. The Xiongnu Empire was decisively defeated. The diplomat and general Ban Chao further expanded the conquests across the Pamirs to the shores of the Caspian Sea, thus reopening the Silk Road, and bringing trade, foreign cultures, along with the arrival of Buddhism. With extensive connections with the west, the first of several Roman embassies to China were recorded in Chinese sources, coming from the sea route in AD 166, and a second one in AD 284.\nThe Eastern Han dynasty was one of the most prolific eras of science and technology in ancient China, notably the historic invention of papermaking by Cai Lun, and the numerous scientific and mathematical contributions by the famous polymath Zhang Heng.\nSix Dynasties.\nThree Kingdoms (AD 220\u2013280).\nBy the 2nd century, the empire declined amidst land acquisitions, invasions, and feuding between consort clans and eunuchs. The Yellow Turban Rebellion broke out in AD 184, ushering in an era of warlords. In the ensuing turmoil, three states emerged, trying to gain predominance and reunify the land, giving this historical period its name. The classic historical novel \"Romance of the Three Kingdoms\" dramatizes events of this period.\nThe warlord Cao Cao reunified the north in 208, and in 220 his son accepted the abdication of Emperor Xian of Han, thus initiating the Wei dynasty. Soon, Wei's rivals Shu and Wu proclaimed their independence. This period was characterized by a gradual decentralization of the state that had existed during the Qin and Han dynasties, and an increase in the power of great families.\nIn 266, the Jin dynasty overthrew the Wei and later unified the country in 280, but this union was short-lived.\nJin dynasty (AD 266\u2013420).\nThe Jin dynasty reunited China proper for the first time since the end of the Han dynasty, ending the Three Kingdoms era. However, the Jin dynasty was severely weakened by the War of the Eight Princes and lost control of northern China after non-Han Chinese settlers rebelled and captured Luoyang and Chang'an. In 317, the Jin prince Sima Rui, based in modern-day Nanjing, became emperor and continued the dynasty, now known as the Eastern Jin, which held southern China for another century. Prior to this move, historians refer to the Jin dynasty as the Western Jin.\nSixteen Kingdoms (AD 304\u2013439).\nNorthern China fragmented into a series of independent states known as the Sixteen Kingdoms, most of which were founded by Xiongnu, Xianbei, Jie, Di and Qiang rulers. These non-Han peoples were ancestors of the Turks, Mongols, and Tibetans. Many had, to some extent, been \"sinicized\" long before their ascent to power. In fact, some of them, notably the Qiang and the Xiongnu, had already been allowed to live in the frontier regions within the Great Wall since late Han times. During this period, warfare ravaged the north and prompted large-scale Han Chinese migration south to the Yangtze River Basin and Delta.\nNorthern and Southern dynasties (AD 420\u2013589).\nIn the early 5th century China entered a period known as the Northern and Southern dynasties, in which parallel regimes ruled the northern and southern halves of the country. In the south, the Eastern Jin gave way to the Liu Song, Southern Qi, Liang and finally Chen. Each of these Southern dynasties were led by Han Chinese ruling families and used Jiankang (modern Nanjing) as the capital. They held off attacks from the north and preserved many aspects of Chinese civilization, while northern barbarian regimes began to sinify.\nIn the north the last of the Sixteen Kingdoms was extinguished in 439 by the Northern Wei, a kingdom founded by the Xianbei, a nomadic people who unified northern China. The Northern Wei eventually split into the Eastern and Western Wei, which then became the Northern Qi and Northern Zhou. These regimes were dominated by Xianbei or Han Chinese who had married into Xianbei families. During this period most Xianbei people adopted Han surnames, eventually leading to complete assimilation into the Han.\nDespite the division of the country, Buddhism spread throughout the land. In southern China, fierce debates about whether Buddhism should be allowed were held frequently by the royal court and nobles. By the end of the era, Buddhists and Taoists had become much more tolerant of each other.\nMid-imperial China.\nSui dynasty (581\u2013618).\nThe short-lived Sui dynasty was a pivotal period in Chinese history. Founded by Emperor Wen in 581 in succession of the Northern Zhou, the Sui went on to conquer the Southern Chen in 589 to reunify China, ending three centuries of political division. The Sui pioneered many new institutions, including the government system of Three Departments and Six Ministries, imperial examinations for selecting officials from commoners, while improved on the systems of fubing system of the army conscription and the equal-field system of land distributions. These policies, which were adopted by later dynasties, brought enormous population growth, and amassed excessive wealth to the state. Standardized coinage was enforced throughout the unified empire. Buddhism took root as a prominent religion and was supported officially. Sui China was known for its numerous mega-construction projects. Intended for grains shipment and transporting troops, the Grand Canal was constructed, linking the capitals Daxing (Chang'an) and Luoyang to the wealthy southeast region, and in another route, to the northeast border. The Great Wall was also expanded, while series of military conquests and diplomatic maneuvers further pacified its borders. However, the massive invasions of the Korean Peninsula during the Goguryeo\u2013Sui War failed disastrously, triggering widespread revolts that led to the fall of the dynasty.\nTang dynasty (618\u2013907).\nThe Tang dynasty was a golden age of Chinese civilization, a prosperous, stable, and creative period with significant developments in culture, art, literature, particularly poetry, and technology. Buddhism became the predominant religion for the common people. Chang'an (modern Xi'an), the national capital, was the largest city in the world during its time.\nThe first emperor, Emperor Gaozu, came to the throne on 18 June 618, placed there by his son, Li Shimin, who became the second emperor, Taizong, one of the greatest emperors in Chinese history. Combined military conquests and diplomatic maneuvers reduced threats from Central Asian tribes, extended the border, and brought neighboring states into a tributary system. Military victories in the Tarim Basin kept the Silk Road open, connecting Chang'an to Central Asia and areas far to the west. In the south, lucrative maritime trade routes from port cities such as Guangzhou connected with distant countries, and foreign merchants settled in China, encouraging a cosmopolitan culture. The Tang culture and social systems were observed and adapted by neighboring countries, most notably Japan. Internally the Grand Canal linked the political heartland in Chang'an to the agricultural and economic centers in the eastern and southern parts of the empire. Xuanzang, a Chinese Buddhist monk, scholar, traveller, and translator travelled to India on his own and returned with \"over six hundred Mahayana and Hinayana texts, seven statues of the Buddha and more than a hundred sarira relics.\"\nThe prosperity of the early Tang dynasty was abetted by a centralized bureaucracy. The government was organized as \"Three Departments and Six Ministries\" to separately draft, review, and implement policies. These departments were run by royal family members and landed aristocrats, but as the dynasty wore on, were joined or replaced by scholar officials selected by imperial examinations, setting patterns for later dynasties.\nUnder the Tang \"equal-field system\" all land was owned by the Emperor and granted to each family according to household size. Men granted land were conscripted for military service for a fixed period each year, a military policy known as the \"fubing\" system. These policies stimulated a rapid growth in productivity and a significant army without much burden on the state treasury. By the dynasty's midpoint, however, standing armies had replaced conscription, and land was continuously falling into the hands of private owners and religious institutions granted exemptions.\nThe dynasty continued to flourish under the rule of Empress Wu Zetian, the only official empress regnant in Chinese history, and reached its zenith during the long reign of Emperor Xuanzong, who oversaw an empire that stretched from the Pacific to the Aral Sea with at least 50 million people. There were vibrant artistic and cultural creations, including works of the greatest Chinese poets, Li Bai and Du Fu.\nAt the zenith of prosperity of the empire, the An Lushan Rebellion from 755 to 763 was a watershed event. War, disease, and economic disruption devastated the population and drastically weakened the central imperial government. Upon suppression of the rebellion, regional military governors, known as \"jiedushi\", gained increasingly autonomous status as the central government lost its ability to control them. With loss of revenue from land tax, the central imperial government came to rely heavily on its salt monopoly. Externally, former submissive states raided the empire and the vast border territories were lost for centuries. Nevertheless, civil society recovered and thrived amidst the weakened imperial bureaucracy.\nIn late Tang period the empire was worn out by recurring revolts of the regional military governors, while scholar-officials engaged in fierce factional strife and corrupted eunuchs amassed immense power. Catastrophically, the Huang Chao Rebellion, from 874 to 884, devastated the entire empire for a decade. The sack of the southern port Guangzhou in 879 was followed by the massacre of most of its inhabitants, especially the large foreign merchant enclaves. By 881, both capitals, Luoyang and Chang'an, fell successively. The reliance on ethnic Han and Turkic warlords in suppressing the rebellion increased their power and influence. Consequently, the fall of the dynasty following Zhu Wen's usurpation led to an era of division.\nIn 808, 30,000 Shatuo under Zhuye Jinzhong defected from the Tibetans to Tang China and the Tibetans punished them by killing Zhuye Jinzhong as they were chasing them. The Uyghurs also fought against an alliance of Shatuo and Tibetans at Beshbalik. The Shatuo Turks under Zhuye Chixin (Li Guochang) served the Tang dynasty in fighting against their fellow Turkic people in the Uyghur Khaganate. In 839, when the Uyghur khaganate (Huigu) general Jueluowu (\u6398\u7f85\u52ff) rose against the rule of then-reigning Zhangxin Khan, he elicited the help from Zhuye Chixin by giving Zhuye 300 horses, and together, they defeated Zhangxin Khan, who then committed suicide, precipitating the subsequent collapse of the Uyghur Khaganate. In the next few years, when Uyghur Khaganate remnants tried to raid Tang borders, the Shatuo participated extensively in counterattacking the Uyghur Khaganate with other tribes loyal to Tang. In 843, Zhuye Chixin, under the command of the Han Chinese officer Shi Xiong with Tuyuhun, Tangut and Han Chinese troops, participated in a raid against the Uyghur khaganate that led to the slaughter of Uyghur forces at Shahu mountain.\nFive Dynasties and Ten Kingdoms (907\u2013960).\nThe period of political disunity between the Tang and the Song, known as the Five Dynasties and Ten Kingdoms period, lasted from 907 to 960. During this half-century, China was in all respects a multi-state system. Five regimes, namely, (Later) Liang, Tang, Jin, Han and Zhou, rapidly succeeded one another in control of the traditional Imperial heartland in northern China. Among the regimes, rulers of (Later) Tang, Jin and Han were sinicized Shatuo Turks, which ruled over an ethnic majority of Han Chinese in the north. More stable and smaller regimes of mostly ethnic Han rulers coexisted in south and western China over the period, cumulatively constituted the \"Ten Kingdoms\".\nAmidst political chaos in the north, the strategic Sixteen Prefectures (region along today's Great Wall) were ceded to the emerging Khitan Liao dynasty, which drastically weakened the defense of China proper against northern nomadic empires. To the south, Vietnam gained lasting independence after being a Chinese prefecture for many centuries. With wars dominating in Northern China, there were mass southward migrations of population, which further enhanced the southward shift of cultural and economic centers in China. The era ended with the coup of Later Zhou general Zhao Kuangyin, and the establishment of the Song dynasty in 960, which eventually annihilated the remains of the \"Ten Kingdoms\" and reunified China.\nLate imperial China.\nSong, Liao, Jin, and Western Xia dynasties (960\u20131279).\nIn 960, the Song dynasty was founded by Emperor Taizu, with its capital established in Kaifeng (then known as Bianjing). In 979, the Song dynasty reunified most of China proper, while large swaths of the outer territories were occupied by sinicized nomadic empires. The Khitan Liao dynasty, which lasted from 907 to 1125, ruled over Manchuria, Mongolia, and parts of Northern China. Meanwhile, in what are now the north-western Chinese provinces of Gansu, Shaanxi, and Ningxia, the Tangut tribes founded the Western Xia dynasty from 1032 to 1227.\nAiming to recover the strategic sixteen prefectures lost in the previous dynasty, campaigns were launched against the Liao dynasty in the early Song period, which all ended in failure. Then in 1004, the Liao cavalry swept over the exposed North China Plain and reached the outskirts of Kaifeng, forcing the Song's submission and then agreement to the Chanyuan Treaty, which imposed heavy annual tributes from the Song treasury. The treaty was a significant reversal of Chinese dominance of the traditional tributary system. Yet the annual outflow of Song's silver to the Liao was paid back through the purchase of Chinese goods and products, which expanded the Song economy, and replenished its treasury. This dampened the incentive for the Song to further campaign against the Liao. Meanwhile, this cross-border trade and contact induced further sinicization within the Liao Empire, at the expense of its military might which was derived from its nomadic lifestyle. Similar treaties and social-economical consequences occurred in Song's relations with the Jin dynasty.\nWithin the Liao Empire the Jurchen tribes revolted against their overlords to establish the Jin dynasty in 1115. In 1125, the devastating Jin cataphract annihilated the Liao dynasty, while remnants of Liao court members fled to Central Asia to found the Qara Khitai Empire (Western Liao dynasty). Jin's invasion of the Song dynasty followed swiftly. In 1127, Kaifeng was sacked, a massive catastrophe known as the Jingkang Incident, ending the Northern Song dynasty. Later the entire north of China was conquered. The surviving members of the Song court regrouped in the new capital city of Hangzhou, and initiated the Southern Song dynasty, which ruled territories south of the Huai River. In the ensuing years, the territory and population of China were divided between the Song dynasty, the Jin dynasty and the Western Xia dynasty. The era ended with the Mongol conquest, as Western Xia fell in 1227, the Jin dynasty in 1234, and finally the Southern Song dynasty in 1279.\nDespite its military weakness, the Song dynasty is widely considered to be the high point of classical Chinese civilization. The Song economy, facilitated by technological advancement, had reached a level of sophistication probably unseen in world history before its time. The population soared to over 100 million and the living standards of common people improved tremendously due to improvements in rice cultivation and the wide availability of coal for production. The capital cities of Kaifeng and subsequently Hangzhou were both the most populous cities in the world for their time, and encouraged vibrant civil societies unmatched by previous Chinese dynasties. Although land trading routes to the far west were blocked by nomadic empires, there was extensive maritime trade with neighbouring states, such as in South-east Asia, which facilitated the use of Song coinage as the de facto currency of exchange. Giant wooden vessels equipped with compasses traveled throughout the China Seas and northern Indian Ocean. The concept of insurance was practised by merchants to hedge the risks of such long-haul maritime shipments. With prosperous economic activities, the historically first use of paper currency emerged in the western city of Chengdu, as a cheaper supplement to the existing copper coins.\nThe Song dynasty was considered to be the golden age of great advancements in science and technology of China, thanks to innovative scholar-officials such as Su Song (1020\u20131101) and Shen Kuo (1031\u20131095). Inventions such as the hydro-mechanical astronomical clock, the first continuous and endless power-transmitting chain, woodblock printing and paper money were all invented during the Song dynasty, further cementing its status.\nThere was court intrigue between the political reformers and conservatives, led by the chancellors Wang Anshi and Sima Guang, respectively. By the mid-to-late 13th century, the Chinese had adopted the dogma of Neo-Confucian philosophy formulated by Zhu Xi. Enormous literary works were compiled during the Song dynasty, such as the innovative historical narrative \"Zizhi Tongjian\" (\"Comprehensive Mirror to Aid in Government\"). The invention of movable-type printing further facilitated the spread of knowledge. Culture and the arts flourished, with grandiose artworks such as \"Along the River During the Qingming Festival\" and \"Eighteen Songs of a Nomad Flute\", along with great Buddhist painters such as the prolific Lin Tinggui.\nThe Song dynasty was also a period of major innovation in the history of warfare. Gunpowder, while invented in the Tang dynasty, was first put into practical use on the battlefield by the Song army, inspiring a succession of new firearms and siege engines designs. During the Southern Song dynasty, as its survival hinged decisively on guarding the Yangtze and Huai River against the cavalry forces from the north, the first standing navy in China was assembled in 1132, with its admiral's headquarters established at Dinghai. Paddle-wheel warships equipped with trebuchets could launch incendiary bombs made of gunpowder and lime to effect, as recorded in Song's victory over the invading Jin forces at the Battle of Tangdao in the East China Sea, and the Battle of Caishi on the Yangtze River in 1161.\nThe advances in civilisation during the Song dynasty came to an abrupt end following the devastating Mongol conquest of the North and subsequently other areas of the empire, during which the population sharply dwindled, with a marked contraction in economy. Despite viciously halting Mongol advances for more than three decades, the Southern Song capital Hangzhou fell in 1276, followed by the final annihilation of the Song standing navy at the Battle of Yamen in 1279.\nYuan dynasty (1271\u20131368).\nThe Yuan dynasty was formally proclaimed in 1271, when the Great Khan of Mongol, Kublai Khan, one of the grandsons of Genghis Khan, assumed the additional title of Emperor of China, and considered his inherited part of the Mongol Empire as a Chinese dynasty. In the preceding decades, the Mongols had conquered the Jin dynasty in Northern China, and the Southern Song dynasty fell in 1279 after a protracted and bloody war. The Mongol Yuan dynasty became the first conquest dynasty in Chinese history to rule the entirety of China proper and its population as an ethnic minority. The dynasty also directly controlled the Mongol heartland and other regions, inheriting the largest share of territory of the eastern Mongol empire, which roughly coincided with the modern area of China and nearby regions in East Asia. Further expansion of the empire was halted after defeats in the invasions of Japan and Vietnam. Following the previous Jin dynasty, the capital of Yuan dynasty was established at Khanbaliq (also known as Dadu, modern-day Beijing). The Grand Canal was reconstructed to connect the remote capital city to lively economic hubs in southern part of China, setting the precedence and foundation for Beijing to largely remain as the capital of the successive regimes of the unified Chinese mainland.\nA series of Mongol civil wars in the late 13th century led to the division of the Mongol Empire. In 1304 the emperors of the Yuan dynasty were upheld as the nominal Khagan over western khanates (the Chagatai Khanate, the Golden Horde and the Ilkhanate), which nonetheless remained \"de facto\" autonomous. The era was known as \"Pax Mongolica\", when much of the Asian continent was ruled by the Mongols. For the first and only time in history, the Silk Road was controlled entirely by a single state, facilitating the flow of people, trade, and cultural exchange. A network of roads and a postal system were established to connect the vast empire. Lucrative maritime trade, developed from the previous Song dynasty, continued to flourish, with Quanzhou and Hangzhou emerging as the largest ports in the world. Adventurous travelers from the far west, most notably the Venetian, Marco Polo, would settle in China for decades. Upon his return, his detail travel record inspired generations of medieval Europeans with the splendors of the far East. The Yuan dynasty was the first ancient economy, where paper currency, known at the time as \"Jiaochao\", was used as the predominant medium of exchange. Its unrestricted issuance in the late Yuan dynasty inflicted hyperinflation, which eventually brought the downfall of the dynasty.\nWhile the Mongol rulers of the Yuan dynasty adopted substantially to Chinese culture, their sinicization was of lesser extent compared to earlier conquest dynasties in Chinese history. For preserving racial superiority as the conqueror and ruling class, traditional nomadic customs and heritage from the Mongolian Steppe were held in high regard. On the other hand, the Mongol rulers also adopted flexibly to a variety of cultures from many advanced civilizations within the vast empire. Traditional social structure and culture in China underwent immense transform during the Mongol dominance. Large groups of foreign migrants settled in China, who enjoyed elevated social status over the majority Han Chinese, while enriching Chinese culture with foreign elements. The class of scholar officials and intellectuals, traditional bearers of elite Chinese culture, lost substantial social status. This stimulated the development of culture of the common folks. There were prolific works in \"zaju\" variety shows and literary songs (\"sanqu\"), which were written in a distinctive poetry style known as \"qu\". Novels of vernacular style gained unprecedented status and popularity.\nBefore the Mongol invasion, Chinese dynasties reported approximately 120 million inhabitants; after the conquest had been completed in 1279, the 1300 census reported roughly 60 million people. This major decline is not necessarily due only to Mongol killings. Scholars such as Frederick W. Mote argue that the wide drop in numbers reflects an administrative failure to record rather than an actual decrease; others such as Timothy Brook argue that the Mongols created a system of enserfment among a huge portion of the Chinese populace, causing many to disappear from the census altogether; other historians including William McNeill and David Morgan consider that plague was the main factor behind the demographic decline during this period. In the 14th century China suffered additional depredations from epidemics of plague, estimated to have killed around a quarter of the population of China.\nThroughout the Yuan dynasty, there was some general sentiment among the populace against the Mongol dominance. Yet rather than the nationalist cause, it was mainly strings of natural disasters and incompetent, corrupt governance that triggered widespread peasant uprisings since the 1340s. After the massive naval engagement at Lake Poyang, Zhu Yuanzhang prevailed over other rebel forces in the south. He proclaimed himself emperor and founded the Ming dynasty in 1368. The same year his northern expedition army captured the capital Khanbaliq. The Yuan remnants fled back to Mongolia and sustained the regime, but the period of Yuan dominance was effectively over for good. Other Mongol Khanates in Central Asia continued to exist after the fall of Yuan dynasty in China.\nMing dynasty (1368\u20131644).\nThe Ming dynasty was founded by Zhu Yuanzhang in 1368, who proclaimed himself as the Hongwu Emperor. The capital was initially set at Nanjing, and was later moved to Beijing from Yongle Emperor's reign onward.\nUrbanization increased as the population grew and as the division of labor grew more complex. Large urban centers, such as Nanjing and Beijing, also contributed to the growth of private industry. In particular, small-scale industries grew up, often specializing in paper, silk, cotton, and porcelain goods. For the most part, however, relatively small urban centers with markets proliferated around the country. Town markets mainly traded food, with some necessary manufactures such as pins or oil.\nDespite the xenophobia and intellectual introspection characteristic of the increasingly popular new school of neo-Confucianism, China under the early Ming dynasty was not isolated. Foreign trade and other contacts with the outside world, particularly Japan, increased considerably. Chinese merchants explored all of the Indian Ocean, reaching East Africa with the voyages of Zheng He.\nThe Hongwu Emperor, being the only founder of a Chinese dynasty who was also of peasant origin, had laid the foundation of a state that relied fundamentally in agriculture. Commerce and trade, which flourished in the previous Song and Yuan dynasties, were less emphasized. Neo-feudal landholdings of the Song and Mongol periods were expropriated by the Ming rulers. Land estates were confiscated by the government, fragmented, and rented out. Private slavery was forbidden. Consequently, after the death of the Yongle Emperor, independent peasant landholders predominated in Chinese agriculture. These laws might have paved the way to removing the worst of the poverty during the previous regimes. Towards later era of the Ming dynasty, with declining government control, commerce, trade and private industries revived.\nThe dynasty had a strong and complex central government that unified and controlled the empire. The emperor's role became more autocratic, although Hongwu Emperor necessarily continued to use what he called the \"Grand Secretariat\" to assist with the immense paperwork of the bureaucracy, including memorials (petitions and recommendations to the throne), imperial edicts in reply, reports of various kinds, and tax records. It was this same bureaucracy that later prevented the Ming government from being able to adapt to changes in society, and eventually led to its decline.\nThe Yongle Emperor strenuously tried to extend China's influence beyond its borders by demanding other rulers send ambassadors to China to present tribute. A large navy was built, including four-masted ships displacing 1,500\u00a0tons. A standing army of 1\u00a0million troops was created. The Chinese armies conquered and occupied Vietnam for around 20 years, while the Chinese fleet sailed the China seas and the Indian Ocean, cruising as far as the east coast of Africa. The Chinese gained influence in eastern Moghulistan. Several maritime Asian nations sent envoys with tribute for the Chinese emperor. Domestically, the Grand Canal was expanded and became a stimulus to domestic trade. Over 100,000\u00a0tons of iron per year were produced. Many books were printed using movable type. The imperial palace in Beijing's Forbidden City reached its current splendor. It was also during these centuries that the potential of south China came to be fully exploited. New crops were widely cultivated and industries such as those producing porcelain and textiles flourished.\nIn 1449 Esen Tayisi led an Oirat Mongol invasion of northern China which culminated in the capture of the Zhengtong Emperor at Tumu. Since then, the Ming became on the defensive on the northern frontier, which led to the Ming Great Wall being built. Most of what remains of the Great Wall of China today was either built or repaired by the Ming. The brick and granite work was enlarged, the watchtowers were redesigned, and cannons were placed along its length.\nAt sea the Ming became increasingly isolationist after the death of the Yongle Emperor. The treasure voyages which sailed the Indian Ocean were discontinued, and the maritime prohibition laws were set in place banning the Chinese from sailing abroad. European traders who reached China in the midst of the Age of Discovery were repeatedly rebuked in their requests for trade, with the Portuguese being repulsed by the Ming navy at Tuen Mun in 1521 and again in 1522. Domestic and foreign demands for overseas trade, deemed illegal by the state, led to widespread \"wokou\" piracy attacking the southeastern coastline during the rule of the Jiajing Emperor (1507\u20131567), which only subsided after the opening of ports in Guangdong and Fujian and much military suppression. In addition to raids from Japan by the \"wokou\", raids from Taiwan and the Philippines by the Pisheye also ravaged the southern coasts. The Portuguese were allowed to settle in Macau in 1557 for trade, which remained in Portuguese hands until 1999. After the Spanish invasion of the Philippines, trade with the Spanish at Manila imported large quantities of Mexican and Peruvian silver from the Spanish Americas to China. The Dutch entry into the Chinese seas was also met with fierce resistance, with the Dutch being chased off the Penghu islands in the Sino-Dutch conflicts of 1622\u20131624 and were forced to settle in Taiwan instead. The Dutch in Taiwan fought with the Ming in the Battle of Liaoluo Bay in 1633 and lost, and eventually surrendered to the Ming loyalist Koxinga in 1662, after the fall of the Ming dynasty.\nIn 1556, during the rule of the Jiajing Emperor, the Shaanxi earthquake killed about 830,000 people, the deadliest earthquake of all time.\nThe Ming dynasty intervened deeply in the Japanese invasions of Korea (1592\u20131598), which ended with the withdrawal of all invading Japanese forces in Korea, and the restoration of the Joseon dynasty, its traditional ally and tributary state. The regional hegemony of the Ming dynasty was preserved at a toll on its resources. Coincidentally, with Ming's control in Manchuria in decline, the Manchu (Jurchen) tribes, under their chieftain Nurhaci, broke away from Ming's rule, and emerged as a powerful, unified state, which was later proclaimed as the Qing dynasty. It went on to subdue the much weakened Korea as its tributary, conquered Mongolia, and expanded its territory to the outskirt of the Great Wall. The most elite army of the Ming dynasty was to station at the Shanhai Pass to guard the last stronghold against the Manchus, which weakened its suppression of internal peasants uprisings.\nQing dynasty (1644\u20131912).\nThe Qing dynasty (1644\u20131912) was the last imperial dynasty in China. Founded by the Manchus, it was the second conquest dynasty to rule the entirety of China proper, and roughly doubled the territory controlled by the Ming. The Manchus were formerly known as Jurchens, residing in the northeastern part of the Ming territory outside the Great Wall. They emerged as the major threat to the late Ming dynasty after Nurhaci united all Jurchen tribes and his son, Hong Taiji, declared the founding of the Qing dynasty in 1636. The Qing dynasty set up the Eight Banners system that provided the basic framework for the Qing military conquest. Li Zicheng's peasant rebellion captured Beijing in 1644 and the Chongzhen Emperor, the last Ming emperor, committed suicide. The Manchus allied with the Ming general Wu Sangui to seize Beijing, which was made the capital of the Qing dynasty, and then proceeded to subdue the Ming remnants in the south. During the Ming-Qing transition, when the Ming dynasty and later the Southern Ming, the emerging Qing dynasty, and several other factions like the Shun dynasty and Xi dynasty founded by peasant revolt leaders fought against each another, which, along with innumerable natural disasters at that time such as those caused by the Little Ice Age and epidemics like the Great Plague during the last decade of the Ming dynasty, caused enormous loss of lives and significant harm to the economy. In total, these decades saw the loss of as many as 25 million lives, but the Qing appeared to have restored China's imperial power and inaugurate another flowering of the arts. The early Manchu emperors combined traditions of Inner Asian rule with Confucian norms of traditional Chinese government and were considered a Chinese dynasty.\nThe Manchus enforced a queue order, forcing Han Chinese men to adopt the Manchu queue hairstyle. Officials were required to wear Manchu-style clothing \"Changshan\" (bannermen dress and \"Tangzhuang\"), but ordinary Han civilians were allowed to wear traditional Han clothing. Bannermen could not undertake trade or manual labor; they had to petition to be removed from banner status. They were considered aristocracy and were given annual pensions, land, and allotments of cloth. The Kangxi Emperor ordered the creation of the \"Kangxi Dictionary\", the most complete dictionary of Chinese characters that had been compiled.\nOver the next half-century, all areas previously under the Ming dynasty were consolidated under the Qing. Conquests in Central Asia in the eighteenth century extended territorial control. Between 1673 and 1681, the Kangxi Emperor suppressed the Revolt of the Three Feudatories, an uprising of three generals in Southern China who had been denied hereditary rule of large fiefdoms granted by the previous emperor. In 1683, the Qing staged an amphibious assault on southern Taiwan, bringing down the rebel Kingdom of Tungning, which was founded by the Ming loyalist Koxinga (Zheng Chenggong) in 1662 after the fall of the Southern Ming, and had served as a base for continued Ming resistance in Southern China. The Qing defeated the Russians at Albazin, resulting in the Treaty of Nerchinsk.\nBy the end of Qianlong Emperor's long reign in 1796, the Qing Empire was at its zenith. The Qing ruled more than one-third of the world's population, and had the largest economy in the world. By area it was one of the largest empires ever.\nIn the 19th century the empire was internally restive and externally threatened by western powers. The defeat by the British Empire in the First Opium War (1840) led to the Treaty of Nanking (1842), under which Hong Kong was ceded to Britain and importation of opium (produced by British Empire territories) was allowed. Opium usage continued to grow in China, adversely affecting societal stability. Subsequent military defeats and unequal treaties with other western powers continued even after the fall of the Qing dynasty.\nInternally the Taiping Rebellion (1851\u20131864), a Christian religious movement led by the \"Heavenly King\" Hong Xiuquan swept from the south to establish the Taiping Heavenly Kingdom and controlled roughly a third of China proper for over a decade. The court in desperation empowered Han Chinese officials such as Zeng Guofan to raise local armies. After initial defeats, Zeng crushed the rebels in the Third Battle of Nanking in 1864. This was one of the largest wars in the 19th century in troop involvement; there was massive loss of life, with a death toll of about 20 million. A string of civil disturbances followed, including the Punti\u2013Hakka Clan Wars, Nian Rebellion, Dungan Revolt, and Panthay Rebellion. All rebellions were ultimately put down, but at enormous cost and with millions dead, seriously weakening the central imperial authority. China never rebuilt a strong central army, and many local officials used their military power to effectively rule independently in their provinces.\nYet the dynasty appeared to recover in the Tongzhi Restoration (1860\u20131872), led by Manchu royal family reformers and Han Chinese officials such as Zeng Guofan and his proteges Li Hongzhang and Zuo Zongtang. Their Self-Strengthening Movement made effective institutional reforms, imported Western factories and communications technology, with prime emphasis on strengthening the military. However, the reform was undermined by official rivalries, cynicism, and quarrels within the imperial family. The defeat of Yuan Shikai's modernized \"Beiyang Fleet\" in the First Sino-Japanese War (1894\u20131895) led to the formation of the New Army. The Guangxu Emperor, advised by Kang Youwei, then launched a comprehensive reform effort, the Hundred Days' Reform (1898). Empress Dowager Cixi, however, feared that precipitous change would lead to bureaucratic opposition and foreign intervention and quickly suppressed it.\nIn the summer of 1900, the Boxer Uprising opposed foreign influence and murdered Chinese Christians and foreign missionaries. When Boxers entered Beijing, the Qing government ordered all foreigners to leave, but they and many Chinese Christians were besieged in the foreign legations quarter. An Eight-Nation Alliance sent the Seymour Expedition of Japanese, Russian, British, Italian, German, French, American, and Austrian troops to relieve the siege, but they were routed and forced to retreat by Boxer and Qing troops at the Battle of Langfang. After the Alliance's attack on the Dagu Forts, the court declared war on the Alliance and authorised the Boxers to join with imperial armies. After fierce fighting at Tianjin, the Alliance formed the second, much larger Gaselee Expedition and finally reached Beijing; the Empress Dowager evacuated to Xi'an. The Boxer Protocol ended the war, exacting a tremendous indemnity.\nThe Qing court then instituted administrative and legal reforms known as the late Qing reforms, including abolition of the examination system. But young officials, military officers, and students debated reform, perhaps a constitutional monarchy, or the overthrow of the dynasty and the creation of a republic. They were inspired by an emerging public opinion formed by intellectuals such as Liang Qichao and the revolutionary ideas of Sun Yat-sen. A localised military uprising, the Wuchang uprising, began on 10 October 1911, in Wuchang (today part of Wuhan), and soon spread. The Republic of China was proclaimed on 1 January 1912, ending 2,000 years of dynastic rule.\nModern China.\nRepublic of China (since 1912).\nThe provisional government of the Republic of China was formed in Nanjing on 12 March 1912. Sun Yat-sen became President of the Republic of China, but he turned power over to Yuan Shikai, who commanded the New Army. Over the next few years, Yuan proceeded to abolish the national and provincial assemblies, and declared himself as the emperor of Empire of China in late 1915, in the style of an absolute monarchy. Yuan's imperial ambitions were fiercely opposed by his subordinates; faced with the rapidly growing prospect of violent rebellion, he abdicated in March 1916 and died of natural causes in June.\nYuan's death in 1916 left a power vacuum; the republican government (that had been nearly brought to its knees by his policies) was all but shattered. This opened the way for the Warlord Era, during which much of China was ruled by shifting coalitions of competing provincial military leaders and the Beiyang government, ushering in a short-lived period of uncertainty. Intellectuals, disappointed in the failure of the Republic, launched the New Culture Movement.\nIn 1919, the May Fourth Movement began as a response to the pro-Japanese terms imposed on China by the Treaty of Versailles following World War I. It quickly became a nationwide protest movement. The protests were a moral success as the cabinet fell and China refused to sign the Treaty of Versailles, which had awarded German holdings of Shandong to Japan. Memory of the mistreatment at Versailles fuels resentment into the 21st century.\nPolitical and intellectual ferment waxed strong throughout the 1920s and 1930s. According to Patricia Ebrey:\nNationalism, patriotism, progress, science, democracy, and freedom were the goals; imperialism, feudalism, warlordism, autocracy, patriarchy, and blind adherence to tradition were the enemies. Intellectuals struggled with how to be strong and modern and yet Chinese, how to preserve China as a political entity in the world of competing nations.\nIn the 1920s Sun Yat-sen established a revolutionary base in Guangzhou and set out to unite the fragmented nation. He welcomed assistance from the Soviet Union (itself fresh from Lenin's Communist takeover) and he entered into an alliance with the fledgling Chinese Communist Party (CCP). After Sun's death from cancer in 1925, one of his prot\u00e9g\u00e9s, Chiang Kai-shek, seized control of the Nationalist Party (KMT) and succeeded in bringing most of south and central China under its rule in the Northern Expedition (1926\u20131927). Having defeated the warlords in the south and central China by military force, Chiang was able to secure the nominal allegiance of the warlords in the North and establish the Nationalist government in Nanjing. In 1927, Chiang turned on the CCP and relentlessly purged the Communists elements in his NRA. In 1934, driven from their mountain bases such as the Chinese Soviet Republic, the CCP forces embarked on the Long March across China's most desolate terrain to the northwest, a feat transformed into legend, where they established a guerrilla base at Yan'an in Shaanxi. During the Long March, the communists reorganised under a new leader, Mao Zedong (Mao Tse-tung).\nThe bitter Chinese Civil War between the Nationalists and the Communists continued, openly or clandestinely, through the 14-year-long Japanese occupation of various parts of the country (1931\u20131945). The two Chinese parties nominally formed a United Front to oppose the Japanese in 1937, during the Second Sino-Japanese War (1937\u20131945), which became a part of World War II, although this alliance was tenuous at best and disagreements, sometimes violent, between the forces were still common. Japanese forces committed numerous war atrocities against the civilian population, including biological warfare (see Unit 731) and the Three Alls Policy (\"Sank\u014d Sakusen\"), namely being: \"Kill All, Burn All and Loot All\". During the war, China was recognized as one of the Allied \"Big Four\" in the Declaration by United Nations, as a tribute to its enduring struggle against the invading Japanese. China was one of the four major Allies of World War II, and was later considered one of the primary victors in the war.\nFollowing the defeat of Japan in 1945, the war between the Nationalist government forces and the CCP resumed, after failed attempts at reconciliation and a negotiated settlement. By 1949, the CCP had established control over most of the country. Odd Arne Westad says the Communists won the Civil War because they made fewer military mistakes than Chiang, and because in his search for a powerful centralized government, Chiang antagonised too many interest groups in China. Furthermore, his party was weakened in the war against the Japanese. Meanwhile, the Communists told different groups, such as peasants, exactly what they wanted to hear, and cloaked themselves in the cover of Chinese Nationalism. During the civil war both the Nationalists and Communists carried out mass atrocities, with millions of non-combatants killed by both sides. These included deaths from forced conscription and massacres.\nThe Nationalists were slowly routed towards the South. When the Nationalist government forces were defeated by CCP forces in mainland China in 1949, the Nationalist government fled to Taiwan with its forces, along with Chiang and a large number of their supporters; the Nationalist government had taken effective control of Taiwan at the end of WWII as part of the overall Japanese surrender, when Japanese troops in Taiwan surrendered to the Republic of China troops there.\nUntil the early 1970s the ROC was recognised as the sole legitimate government of China by the United Nations, the United States and most Western nations, refusing to recognise the PRC on account of its status as a communist nation during the Cold War. This changed in 1971 when the PRC was seated in the United Nations, replacing the ROC. The KMT ruled Taiwan under martial law until 1987, with the stated goal of being vigilant against Communist infiltration and preparing to retake mainland China. Therefore, political dissent was not tolerated during that period, and crackdowns against dissidents were common.\nIn the 1990s the ROC underwent a major democratic reform, beginning with the 1991 resignation of the members of the Legislative Yuan and National Assembly elected in 1947. These groups were originally created to represent mainland China constituencies. Also lifted were the restrictions on the use of Taiwanese languages in the broadcast media and in schools. In 1996, the ROC held its first direct presidential election, and the incumbent president, KMT candidate Lee Teng-hui, was elected. In 2000, the KMT status as the ruling party ended when the DPP took power, only to regain its status in the 2008 election by Ma Ying-jeou.\nDue to the controversial nature of Taiwan's political status, the ROC is currently recognised by merely 12 UN member states and the Holy See as of 2024[ [update]] as the legitimate government of \"China\".\nPeople's Republic of China (since 1949).\nMajor combat in the Chinese Civil War ended in 1949 with the KMT pulling out of the mainland, with the government relocating to Taipei and maintaining control only over a few islands. The CCP was left in control of mainland China. On 1 October 1949, Mao Zedong proclaimed the People's Republic of China. \"Communist China\" and \"Red China\" were two common names for the PRC.\nThe PRC was shaped by a series of campaigns and five-year plans. The Great Leap Forward, a radical campaign that encompassed numerous attempted economic and social reforms, resulted in tens of millions of deaths. Mao's government carried out mass executions of landowners, instituted collectivisation and implemented the Laogai camp system. Execution, deaths from forced labor and other atrocities resulted in millions of deaths under Mao. In 1966 Mao and his allies launched the Cultural Revolution, which continued until Mao's death a decade later. The Cultural Revolution, motivated by power struggles within the Party and a fear of the Soviet Union, led to a major upheaval in Chinese society.\nFollowing the Sino-Soviet split and motivated by concerns of invasion by either the Soviet Union or the United States, China initiated the Third Front campaign to develop national defense and industrial infrastructure in its rugged interior.44 Through its distribution of infrastructure, industry, and human capital around the country, the Third Front created favorable conditions for subsequent market development and private enterprise.177\nIn 1972, at the peak of the Sino-Soviet split, Mao and Zhou Enlai met U.S. president Richard Nixon in Beijing to establish relations with the US. In the same year, the PRC was admitted to the United Nations in place of the Republic of China, with permanent membership of the Security Council.\nA power struggle followed Mao's death in 1976. The Gang of Four were arrested and blamed for the excesses of the Cultural Revolution, marking the end of a turbulent political era in China. Deng Xiaoping outmaneuvered Mao's anointed successor chairman Hua Guofeng, and gradually emerged as the \"de facto\" leader over the next few years.\nDeng Xiaoping was the Paramount Leader of China from 1978 to 1992, although he never became the head of the party or state, and his influence within the Party led the country to significant economic reforms. The CCP subsequently loosened governmental control over citizens' personal lives and the communes were disbanded with many peasants receiving multiple land leases, which greatly increased incentives and agricultural production. In addition, there were many free market areas opened. The most successful free market area was Shenzhen. It is located in Guangdong and the property tax free area still exists today. This turn of events marked China's transition from a planned economy to a mixed economy with an increasingly open market environment, a system termed by some as market socialism, and officially by the CCP as Socialism with Chinese characteristics. The PRC adopted its current constitution on 4 December 1982.\nIn 1989 the death of former general secretary Hu Yaobang helped to spark the Tiananmen Square protests of that year, during which students and others campaigned for several months, speaking out against corruption and in favour of greater political reform, including democratic rights and freedom of speech. However, they were eventually put down on 4 June when Army troops and vehicles entered and forcibly cleared the square, resulting in considerable numbers of fatalities. This event was widely reported, and brought worldwide condemnation and sanctions against the communist government.\nCCP general secretary and PRC president Jiang Zemin and PRC premier Zhu Rongji, both former mayors of Shanghai, led post-Tiananmen PRC in the 1990s. Under Jiang and Zhu's ten years of administration, the PRC's economic performance pulled an estimated 150\u00a0million peasants out of poverty and sustained an average annual gross domestic product growth rate of 11.2%. The country formally joined the World Trade Organization in 2001. By 1997 and 1999, former European colonies of British Hong Kong and Portuguese Macau became the Hong Kong and Macau special administrative regions of the People's Republic of China, respectively.\nAlthough the PRC needed economic growth to spur its development, the government began to worry that rapid economic growth was degrading the country's natural resources and environment. Another concern was that certain sectors of society were not sufficiently benefiting from the PRC's economic development; one example of this was the wide gap between urban and rural areas in terms of development and prevalence of updated infrastructure. As a result, under former CCP general secretary and President Hu Jintao and Premier Wen Jiabao, the PRC initiated policies to address issues of equitable distribution of resources, but the outcome was not known as of 2014[ [update]]. More than 40\u00a0million farmers were displaced from their land, usually for economic development, contributing to 87,000 demonstrations and riots across China in 2005. For much of the PRC's population, living standards improved very substantially and freedom increased, but political controls remained tight and rural areas poor.\nSince 2017, the Chinese government has been engaged in a harsh crackdown in Xinjiang, with around one million Uyghurs and other ethnic and religion minorities being detained in internment camps aimed at changing the political thinking of detainees, their identities, and their religious beliefs, in what some described as a genocide or crimes against humanity. According to reports, political indoctrination, torture, physical and psychological abuse, forced sterilization, sexual abuse, and forced labor are common in these facilities. The use of these centers appears to have ended in 2019 following international pressure. Academic Kerry Brown attributes their closures beginning in late 2019 to the expense required to operate them.138 China has repeatedly denied this, asserting that the West has never been able to produce reliably-sourced satellite footage of any such detainment or resulting detention of minority groups. Although no comprehensive independent surveys of such centres have been performed as of June 2024, spot checks by journalists have found such sites converted or abandoned. In 2023, Amnesty International said that they were \"witnessing more and more arbitrary detention\", but that detained individuals were being moved from the camps into the formal prison system.\nThe novel coronavirus SARS-CoV-2, which causes the disease COVID-19, was first detected in Wuhan, Hubei in 2019 and led to a global pandemic, causing the majority of the world to enter a period of lockdown for at least a year following.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nSources.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "5762", "revid": "11096", "url": "https://en.wikipedia.org/wiki?curid=5762", "title": "Civil engineering", "text": "Engineering discipline focused on physical infrastructure\nCivil engineering is a professional engineering discipline that deals with the design, construction, and maintenance of the physical and naturally built environment, including public works such as roads, bridges, canals, dams, airports, sewage systems, pipelines, structural components of buildings, and railways.\nCivil engineering is traditionally broken into a number of sub-disciplines. It is considered the second-oldest engineering discipline after military engineering, and it is defined to distinguish non-military engineering from military engineering. Civil engineering can take place in the public sector from municipal public works departments through to federal government agencies, and in the private sector from locally based firms to \"Fortune\" Global 500 companies.\nHistory.\nCivil engineering as a discipline.\nCivil engineering is the application of physical and scientific principles for solving the problems of society, and its history is intricately linked to advances in the understanding of physics and mathematics throughout history. Because civil engineering is a broad profession, including several specialized sub-disciplines, its history is linked to knowledge of structures, materials science, geography, geology, soils, hydrology, environmental science, mechanics, project management, and other fields.\nThroughout ancient and medieval history most architectural design and construction was carried out by artisans, such as stonemasons and carpenters, rising to the role of master builder. Knowledge was retained in craft guilds and seldom supplanted by advances. Structures, roads, and infrastructure that existed were repetitive, and increases in scale were incremental.\nOne of the earliest examples of a scientific approach to physical and mathematical problems applicable to civil engineering is the work of Archimedes in the 3rd century BC, including Archimedes' principle, which underpins our understanding of buoyancy, and practical solutions such as Archimedes' screw. Brahmagupta, an Indian mathematician, used arithmetic in the 7th century AD, based on Hindu-Arabic numerals, for excavation (volume) computations.\nCivil engineering profession.\nEngineering has been an aspect of life since the beginnings of human existence. The earliest practice of civil engineering may have commenced between 4000 and 2000 BC in ancient Egypt, the Indus Valley civilization, and Mesopotamia (ancient Iraq) when humans started to abandon a nomadic existence, creating a need for the construction of shelter. During this time, transportation became increasingly important leading to the development of the wheel and sailing.\nUntil modern times there was no clear distinction between civil engineering and architecture, and the term engineer and architect were mainly geographical variations referring to the same occupation, and often used interchangeably. The constructions of pyramids in Egypt (c.\u20092700\u20132500 BC) constitute some of the first instances of large structure constructions in history. Other ancient historic civil engineering constructions include the Qanat water management system in modern-day Iran (the oldest is older than 3000 years and longer than ), the Parthenon by Iktinos in Ancient Greece (447\u2013438 BC), the Appian Way by Roman engineers (c.\u2009312 BC), the Great Wall of China by General Meng T'ien under orders from Ch'in Emperor Shih Huang Ti (c.\u2009220 BC) and the stupas constructed in ancient Sri Lanka like the Jetavanaramaya and the extensive irrigation works in Anuradhapura. The Romans developed civil structures throughout their empire, including especially aqueducts, insulae, harbors, bridges, dams and roads.\nIn the 18th century, the term civil engineering was coined to incorporate all things civilian as opposed to military engineering. In 1747, the first institution for the teaching of civil engineering, the \u00c9cole Nationale des Ponts et Chauss\u00e9es, was established in France; and more examples followed in other European countries, like Spain (Escuela T\u00e9cnica Superior de Ingenieros de Caminos, Canales y Puertos). The first self-proclaimed civil engineer was John Smeaton, who constructed the Eddystone Lighthouse. In 1771 Smeaton and some of his colleagues formed the Smeatonian Society of Civil Engineers, a group of leaders of the profession who met informally over dinner. Though there was evidence of some technical meetings, it was little more than a social society.\nIn 1818 the Institution of Civil Engineers was founded in London, and in 1820 the eminent engineer Thomas Telford became its first president. The institution received a Royal charter in 1828, formally recognising civil engineering as a profession. Its charter defined civil engineering as:&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nCivil engineering education.\nThe first private college to teach civil engineering in the United States was Norwich University, founded in 1819 by Captain Alden Partridge. The first degree in civil engineering in the United States was awarded by Rensselaer Polytechnic Institute in 1835. The first such degree to be awarded to a woman was granted by Cornell University to Nora Stanton Blatch in 1905.\nIn the UK during the early 19th century, the division between civil engineering and military engineering (served by the Royal Military Academy, Woolwich), coupled with the demands of the Industrial Revolution, spawned new engineering education initiatives: the Class of Civil Engineering and Mining was founded at King's College London in 1838, mainly as a response to the growth of the railway system and the need for more qualified engineers, the private College for Civil Engineers in Putney was established in 1839, and the UK's first Chair of Engineering was established at the University of Glasgow in 1840.\nEducation.\n\"Civil engineers\" typically possess an academic degree in civil engineering. The length of study is three to five years, and the completed degree is designated as a bachelor of technology, or a bachelor of engineering. The curriculum generally includes classes in physics, mathematics, project management, design and specific topics in civil engineering. After taking basic courses in most sub-disciplines of civil engineering, they move on to specialize in one or more sub-disciplines at advanced levels. While an undergraduate degree (BEng/BSc) normally provides successful students with industry-accredited qualifications, some academic institutions offer post-graduate degrees (MEng/MSc), which allow students to further specialize in their particular area of interest.\nPracticing engineers.\nIn most countries, a bachelor's degree in engineering represents the first step towards professional certification, and a professional body certifies the degree program. After completing a certified degree program, the engineer must satisfy a range of requirements including work experience and exam requirements before being certified. Once certified, the engineer is designated as a professional engineer (in the United States, Canada and South Africa), a chartered engineer (in most Commonwealth countries), a chartered professional engineer (in Australia and New Zealand), or a European engineer (in most countries of the European Union). There are international agreements between relevant professional bodies to allow engineers to practice across national borders.\nThe benefits of certification vary depending upon location. For example, in the United States and Canada, \"only a licensed professional engineer may prepare, sign and seal, and submit engineering plans and drawings to a public authority for approval, or seal engineering work for public and private clients.\" This requirement is enforced under provincial law such as the Engineers Act in Quebec. No such legislation has been enacted in other countries including the United Kingdom. In Australia, state licensing of engineers is limited to the state of Queensland. Almost all certifying bodies maintain a code of ethics which all members must abide by.\nEngineers must obey contract law in their contractual relationships with other parties. In cases where an engineer's work fails, they may be subject to the law of tort of negligence, and in extreme cases, criminal charges. An engineer's work must also comply with numerous other rules and regulations such as building codes and environmental law.\nSub-disciplines.\nThere are a number of sub-disciplines within the broad field of civil engineering. General civil engineers work closely with surveyors and specialized civil engineers to design grading, drainage, pavement, water supply, sewer service, dams, electric and communications supply. General civil engineering is also referred to as site engineering, a branch of civil engineering that primarily focuses on converting a tract of land from one usage to another. Site engineers spend time visiting project sites, meeting with stakeholders, and preparing construction plans. Civil engineers apply the principles of geotechnical engineering, structural engineering, environmental engineering, transportation engineering and construction engineering to residential, commercial, industrial and public works projects of all sizes and levels of construction.\nCoastal engineering.\n\"Coastal engineering\" is concerned with managing coastal areas. In some jurisdictions, the terms sea defense and coastal protection mean defense against flooding and erosion, respectively. Coastal defense is the more traditional term, but coastal management has become popular as well.\nConstruction engineering.\n\"Construction engineering\" involves planning and execution, transportation of materials, and site development based on hydraulic, environmental, structural, and geotechnical engineering. As construction firms tend to have higher business risk than other types of civil engineering firms, construction engineers often engage in more business-like transactions, such as drafting and reviewing contracts, analyze and evaluating logistical operations, and monitoring supply prices.\nEarthquake engineering.\n\"Earthquake engineering\" involves designing structures to withstand hazardous earthquake exposures. Earthquake engineering is a sub-discipline of structural engineering. The main objectives of earthquake engineering are to understand interaction of structures on the shaky ground; foresee the consequences of possible earthquakes; and design, construct and maintain structures to perform at earthquake in compliance with building codes.\nEnvironmental engineering.\n\"Environmental engineering\" is the contemporary term for sanitary engineering, though sanitary engineering traditionally had not included much of the hazardous waste management and environmental remediation work covered by environmental engineering. Public health engineering and environmental health engineering are other terms being used.\nEnvironmental engineering deals with treatment of chemical, biological, or thermal wastes, purification of water and air, and remediation of contaminated sites after waste disposal or accidental contamination. Among the topics covered by environmental engineering are pollutant transport, water purification, waste water treatment, air pollution, solid waste treatment, recycling, and hazardous waste management. Environmental engineers administer pollution reduction, green engineering, and industrial ecology. Environmental engineers also compile information on environmental consequences of proposed actions.\nForensic engineering.\n\"Forensic engineering\" is the investigation of materials, products, structures or components that fail or do not operate or function as intended, causing personal injury or damage to property. The consequences of failure are dealt with by the law of product liability. The field also deals with retracing processes and procedures leading to accidents in operation of vehicles or machinery. The subject is applied most commonly in civil law cases, although it may be of use in criminal law cases. Generally the purpose of a Forensic engineering investigation is to locate cause or causes of failure with a view to improve performance or life of a component, or to assist a court in determining the facts of an accident. It can also involve investigation of intellectual property claims, especially patents.\nGeotechnical engineering.\n\"Geotechnical engineering\" studies rock and soil supporting civil engineering systems. Knowledge from the field of soil science, materials science, mechanics, and hydraulics is applied to safely and economically design foundations, retaining walls, and other structures. Environmental efforts to protect groundwater and safely maintain landfills have spawned a new area of research called geo-environmental engineering.\nIdentification of soil properties presents challenges to geotechnical engineers. Boundary conditions are often well defined in other branches of civil engineering, but unlike steel or concrete, the material properties and behavior of soil are difficult to predict due to its variability and limitation on investigation. Furthermore, soil exhibits nonlinear (stress-dependent) strength, stiffness, and dilatancy (volume change associated with application of shear stress), making studying soil mechanics all the more difficult. Geotechnical engineers frequently work with professional geologists, Geological Engineering professionals and soil scientists.\nMaterials science and engineering.\n\"Materials science\" is closely related to civil engineering. It studies fundamental characteristics of materials, and deals with ceramics such as concrete and mix asphalt concrete, strong metals such as aluminum and steel, and thermosetting polymers including polymethylmethacrylate (PMMA) and carbon fibers.\n\"Materials engineering\" involves protection and prevention (paints and finishes). Alloying combines two types of metals to produce another metal with desired properties. It incorporates elements of applied physics and chemistry. With recent media attention on nanoscience and nanotechnology, materials engineering has been at the forefront of academic research. It is also an important part of forensic engineering and failure analysis.\nSite development and planning.\n\"Site development\", also known as \"site planning\", is focused on the planning and development potential of a site as well as addressing possible impacts from permitting issues and environmental challenges.\nStructural engineering.\n\"Structural engineering\" is concerned with the structural design and structural analysis of buildings, bridges, towers, flyovers (overpasses), tunnels, off shore structures like oil and gas fields in the sea, aerostructure and other structures. This involves identifying the loads which act upon a structure and the forces and stresses which arise within that structure due to those loads, and then designing the structure to successfully support and resist those loads. The loads can be self weight of the structures, other dead load, live loads, moving (wheel) load, wind load, earthquake load, load from temperature change etc. The structural engineer must design structures to be safe for their users and to successfully fulfill the function they are designed for (to be \"serviceable\"). Due to the nature of some loading conditions, sub-disciplines within structural engineering have emerged, including wind engineering and earthquake engineering.\nDesign considerations will include strength, stiffness, and stability of the structure when subjected to loads which may be static, such as furniture or self-weight, or dynamic, such as wind, seismic, crowd or vehicle loads, or transitory, such as temporary construction loads or impact. Other considerations include cost, constructibility, safety, aesthetics and sustainability.\nSurveying.\n\"Surveying\" is the process by which a surveyor measures certain dimensions that occur on or near the surface of the Earth. Surveying equipment such as levels and theodolites are used for accurate measurement of angular deviation, horizontal, vertical and slope distances. With computerization, electronic distance measurement (EDM), total stations, GPS surveying and laser scanning have to a large extent supplanted traditional instruments. Data collected by survey measurement is converted into a graphical representation of the Earth's surface in the form of a map. This information is then used by civil engineers, contractors and realtors to design from, build on, and trade, respectively. Elements of a structure must be sized and positioned in relation to each other and to site boundaries and adjacent structures.\nAlthough surveying is a distinct profession with separate qualifications and licensing arrangements, civil engineers are trained in the basics of surveying and mapping, as well as geographic information systems. Surveyors also lay out the routes of railways, tramway tracks, highways, roads, pipelines and streets as well as position other infrastructure, such as harbors, before construction.\nIn the United States, Canada, the United Kingdom and most Commonwealth countries land surveying is considered to be a separate and distinct profession. Land surveyors are not considered to be engineers, and have their own professional associations and licensing requirements. The services of a licensed land surveyor are generally required for boundary surveys (to establish the boundaries of a parcel using its legal description) and subdivision plans (a plot or map based on a survey of a parcel of land, with boundary lines drawn inside the larger parcel to indicate the creation of new boundary lines and roads), both of which are generally referred to as Cadastral surveying. They collect data on important geological features below and on the land.\nConstruction surveying is generally performed by specialized technicians. Unlike land surveyors, the resulting plan does not have legal status. Construction surveyors perform the following tasks:\nTransportation engineering.\n\"Transportation engineering\" is concerned with moving people and goods efficiently, safely, and in a manner conducive to a vibrant community. This involves specifying, designing, constructing, and maintaining transportation infrastructure which includes streets, canals, highways, rail systems, airports, ports, and mass transit. It includes areas such as transportation design, transportation planning, traffic engineering, some aspects of urban engineering, queueing theory, pavement engineering, Intelligent Transportation System (ITS), and infrastructure management.\nMunicipal or urban engineering.\n\"Municipal engineering\" is concerned with municipal infrastructure. This involves specifying, designing, constructing, and maintaining streets, sidewalks, water supply networks, sewers, street lighting, municipal solid waste management and disposal, storage depots for various bulk materials used for maintenance and public works (salt, sand, etc.), public parks and cycling infrastructure. In the case of underground utility networks, it may also include the civil portion (conduits and access chambers) of the local distribution networks of electrical and telecommunications services. It can also include the optimization of waste collection and bus service networks. Some of these disciplines overlap with other civil engineering specialties, however municipal engineering focuses on the coordination of these infrastructure networks and services, as they are often built simultaneously, and managed by the same municipal authority. Municipal engineers may also design the site civil works for large buildings, industrial plants or campuses (i.e. access roads, parking lots, potable water supply, treatment or pretreatment of waste water, site drainage, etc.)\nWater resources engineering.\n\"Water resources engineering\" is concerned with the collection and management of water (as a natural resource). As a discipline, it therefore combines elements of hydrology, environmental science, meteorology, conservation, and resource management. This area of civil engineering relates to the prediction and management of both the quality and the quantity of water in both underground (aquifers) and above ground (lakes, rivers, and streams) resources. Water resource engineers analyze and model very small to very large areas of the earth to predict the amount and content of water as it flows into, through, or out of a facility. However, the actual design of the facility may be left to other engineers.\n\"Hydraulic engineering\" concerns the flow and conveyance of fluids, principally water. This area of civil engineering is intimately related to the design of pipelines, water supply network, drainage facilities (including bridges, dams, channels, culverts, levees, storm sewers), and canals. Hydraulic engineers design these facilities using the concepts of fluid pressure, fluid statics, fluid dynamics, and hydraulics, among others.\nCivil engineering systems.\nCivil engineering systems is a discipline that promotes using systems thinking to manage complexity and change in civil engineering within its broader public context. It posits that the proper development of civil engineering infrastructure requires a holistic, coherent understanding of the relationships between all of the crucial factors that contribute to successful projects while at the same time emphasizing the importance of attention to technical detail. Its purpose is to help integrate the entire civil engineering project life cycle from conception, through planning, designing, making, operating to decommissioning.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nAssociations.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "5763", "revid": "13286072", "url": "https://en.wikipedia.org/wiki?curid=5763", "title": "Cantonese (disambiguation)", "text": "Cantonese is a language originating in Canton, Guangdong.\nCantonese may also refer to:\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "5764", "revid": "40192293", "url": "https://en.wikipedia.org/wiki?curid=5764", "title": "Charles Chaplin", "text": ""}
{"id": "5765", "revid": "44248157", "url": "https://en.wikipedia.org/wiki?curid=5765", "title": "\u00c7atalh\u00f6y\u00fck", "text": "Archaeological site in Turkey\n\u00c7atalh\u00f6y\u00fck (English: Chatalhoyuk; , ; ; also \"\u00c7atal H\u00f6y\u00fck\" and \"\u00c7atal H\u00fcy\u00fck\"; from Turkish \"\u00e7atal\" \"fork\" + \"h\u00f6y\u00fck\" \"tumulus\") is a tell (a mounded accretion resulting from long-term human settlement) of a very large Neolithic and Chalcolithic proto-city settlement in southern Anatolia, which existed from approximately 7500 BC to 5600 BC and flourished around 7000 BC. In July 2012, it was inscribed as a UNESCO World Heritage Site. \u00c7atalh\u00f6y\u00fck overlooks the Konya Plain, southeast of the present-day city of Konya (ancient Iconium) in Turkey, approximately from the twin-coned volcano of Mount Hasan.\nArchaeology.\nThe site of \u00c7atalh\u00f6y\u00fck consists of two mounds separated by an extinct channel of the \u00c7ar\u015famba River.\nlying about to the west. Occupied in the Early Chalcolithic period beginning roughly 5600 BC. The original excavator used a periodization of 12 levels numbered 1-12. The current excavator\nreplaced this with a different alphabetic schema involving levels A-Z.\nThe site was noted by James Mellaart in 1958 during a regional survey of the Konya Plain. He later led a team which excavated there for four seasons between 1961 and 1965. These excavations revealed this section of Anatolia as a centre of advanced culture in the Neolithic period. Excavation revealed 18 successive layers of buildings signifying various stages of the settlement and eras of history. It has been strongly suggested that a number of the\npurported wall paintings and drawings of \"lost\" figurines, many which have been use in other publications, were actually fabricated by Mellaart.\nMellaart was banned from Turkey for his involvement in the Dorak affair, in which he published drawings of supposedly important Bronze Age artifacts that later went missing. After this scandal, the site lay idle until 1993, when excavations began under the leadership of Ian Hodder, then at the University of Cambridge. The Hodder-led excavations ended in 2018. The first two seasons of work were surface surveys with excavation beginning in 1995. Hodder, a former student of Mellaart, chose the site as the first \"real world\" test of his controversial theory of post-processual archaeology. The site has always had a strong research emphasis upon engagement with digital methodologies, driven by the project's experimental and reflexive methodological framework. According to Mickel, Hodder's \u00c7atalh\u00f6y\u00fck Research Project (\u00c7RP) established itself as a site for progressive methodologies\u00a0\u2013 in terms of adaptable and democratized recording, integration of computerized technologies, sampling strategies, and community involvement.\"\nAt the Western Mound, upon which Mellart had only opened two trenches, in 1961, Jonathan Last and\nCatriona Gibson excavated in 1998. In 2006 two teams began work in the West Mound,\none under the direction of Bur\u00e7in Erdo\u011fu and the other under the direction of Peter Biehl and Eva Rosenstock.\nExcavations continue under the direction of Ali Umut T\u00fcrkcan from Anadolu University.\nIn August 2025, archaeologists led by Prof. Dr. Arkadiusz Marciniak of Pozna\u0144 University revealed a mortuary structure referred to as the \u201cHouse of the Dead\u201d or \u201cSpiritual House\u201d. The team uncovered a building where the remains of 20 individuals were placed beneath the floor, suggesting a ritual use. The discovery also included a large ceremonial structure adorned with painted walls and supported by fourteen platforms, as well as a smaller, plastered structure.\nFinds at the site, from the Neolithic layers, included a number of textiles which are rarely preserved in early sites. Most were found in a burial context, often burnt, and all fragments. A number of lithics, almost all of obsidian, were found in those levels\nwith the most numerous types being blades, flakes, projectile points, scrappers, daggers, and sickle blades. A number of\nNeolithic skeletons were also recovered, many from intramural inhumations and in many cases, secondary burials. Over 2,500 \"casually baked\" Neolithic clay figurines have been found, mostly animal but including 187 human.\nCulture.\n \n\u00c7atalh\u00f6y\u00fck was composed entirely of domestic buildings with no obvious public buildings. While some of the larger rooms have rather ornate murals, the purpose of others remains unclear.\nInitial estimates suggested an average population of between 5,000 and 7,000. However, more recent work using revised ideas of the distribution of residential buildings, and employing archaeological and ethnographic data exploring building use, suggests that between 600 and 800 people would have lived at \u00c7atalh\u00f6y\u00fck East during an average year during the Middle phase (6700\u20136500 BC). Genetic studies published during 2025 indicate that the social organization began with a culture organized along matrilocality and matrilineality and that the households passed from mother to daughter.\nThe sites were set up as large numbers of buildings clustered together. Households looked to their neighbors for help, trade, and possible marriage for their children. The inhabitants lived in mudbrick houses that were crammed together in an aggregate structure. No footpaths or streets were used between the dwellings, which were clustered in a honeycomb-like maze. Most were accessed by holes in the ceiling and doors on the side of the houses, with doors reached by ladders and stairs. The rooftops were effectively streets. The ceiling openings also served as the only source of ventilation, allowing smoke from the houses' open hearths and ovens to escape. \nHouses had plaster interiors accessed by squared-off timber ladders or steep stairs. These were usually on the south wall of the room, as were cooking hearths and ovens. The main rooms contained raised platforms that may have been used for a range of domestic activities. Typical houses contained two rooms for everyday activity, such as cooking and crafting. All interior walls and platforms were plastered to a smooth finish. Ancillary rooms were used as storage, and were accessed through low openings from main rooms.\nAll rooms were kept scrupulously clean. Archaeologists identified very little rubbish in the buildings, finding middens outside the ruins, with sewage and food waste, as well as significant amounts of ash from burning wood, reeds, and animal dung. In good weather, many daily activities may also have taken place on the rooftops, which may have formed a plaza. In later periods, large communal ovens appear to have been built on these rooftops. Over time, houses were renewed by partial demolition and rebuilding on a foundation of rubble, which was how the mound was gradually built up. As many as eighteen levels of settlement have been uncovered.\nAs a part of ritual life, the people of \u00c7atalh\u00f6y\u00fck buried their dead within the village. Human remains have been found in pits beneath the floors and especially beneath hearths, the platforms within the main rooms, and beds. Bodies were tightly flexed before burial and were often placed in baskets or wound and wrapped in reed mats. Disarticulated bones in some graves suggest that bodies may have been exposed in the open air for a time before the bones were gathered and buried. In some cases, graves were disturbed, and the individual's head removed from the skeleton. These heads may have been used in rituals, as some were found in other areas of the community. In a woman's grave, spinning whorls were recovered and in a man's grave, stone axes. Some skulls were plastered and painted with ochre to recreate faces, a custom more characteristic of Neolithic sites in Syria and Neolithic Jericho than at sites closer by.\nVivid murals and figurines are found throughout the settlement on interior and exterior walls. Distinctive clay figurines of women, notably the Seated Woman of \u00c7atalh\u00f6y\u00fck, have been found in the upper levels of the site. Although no identifiable temples have been found, the graves, murals, and figurines suggest that the people of \u00c7atalh\u00f6y\u00fck had a religion rich in symbols. Rooms with concentrations of these items may have been shrines or public meeting areas. Predominant images include men with erect phalluses, hunting scenes, red images of the now extinct aurochs (wild cattle) and stags, and vultures swooping down on headless figures. Relief figures are carved on walls, such as of lionesses facing one another.\nHeads of animals, especially of cattle, were mounted on walls. A painting of the village, with the twin mountain peaks of Hasan Da\u011f in the background, is frequently cited as the world's oldest map, and the first landscape painting. However, some archaeologists question this interpretation. Stephanie Meece, for example, argues that it is more likely a painting of a leopard skin instead of a volcano, and a decorative geometric design instead of a map.\nReligion.\nA feature of \u00c7atalh\u00f6y\u00fck are its female figurines. Mellaart, the original excavator, argued that these carefully made figurines, carved and molded from marble, blue and brown limestone, schist, calcite, basalt, alabaster, and clay, represented a female deity. Although a male deity existed as well, \"statues of a female deity far outnumber those of the male deity, who moreover, does not appear to be represented at all after Level\u00a0VI\". To date, eighteen levels have been identified. These figurines were found primarily in areas Mellaart believed to be shrines. The stately goddess seated on a throne flanked by two lionesses was found in a grain bin, which Mellaart suggests might have been a means of ensuring the harvest or protecting the food supply.\nWhereas Mellaart excavated nearly two hundred buildings in four seasons, the current excavator, Ian Hodder, spent an entire season excavating one building alone. Hodder and his team, in 2004 and 2005, began to believe that the patterns suggested by Mellaart were false. They found one similar figurine, but the vast majority did not imitate the Mother Goddess style that Mellaart suggested. Instead of a Mother Goddess culture, Hodder points out that the site gives little indication of a matriarchy or patriarchy.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nIn an article in the \"Turkish Daily News\", Hodder is reported as denying that \u00c7atalh\u00f6y\u00fck was a matriarchal society and quoted as saying \"When we look at what they eat and drink and at their social statues, we see that men and women had the same social status. There was a balance of power. Another example is the skulls found. If one's social status was of high importance in \u00c7atalh\u00f6y\u00fck, the body and head were separated after death. The number of female and male skulls found during the excavations is almost equal.\" In another article in the \"Hurriyet Daily News\" Hodder is reported to say \"We have learned that men and women were equally approached\".\nIn a report in September 2009 on the discovery of around 2000 figurines Hodder is quoted as saying:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\u00c7atalh\u00f6y\u00fck was excavated in the 1960s in a methodical way, but not using the full range of natural science techniques that are available to us today. Sir James Mellaart who excavated the site in the 1960s came up with all sorts of ideas about the way the site was organized and how it was lived in and so on ... We've now started working there since the mid 1990s and come up with very different ideas about the site. One of the most obvious examples of that is that \u00c7atalh\u00f6y\u00fck is perhaps best known for the idea of the mother goddess. But our work more recently has tended to show that in fact there is very little evidence of a mother goddess and very little evidence of some sort of female-based matriarchy. That's just one of the many myths that the modern scientific work is undermining.\nProfessor Lynn Meskell explained that while the original excavations had found only 200 figures, the new excavations had uncovered 2,000 figures, most of which depicted animals, and fewer than 5% of the figurines depicted women.\nEstonian folklorist Uku Masing has suggested as early as in 1976, that \u00c7atalh\u00f6y\u00fck was probably a hunting and gathering religion and the Mother Goddess figurine did not represent a female deity. He implied that perhaps a longer period of time was needed to develop symbols for agricultural rites. His theory was developed in the paper \"Some remarks on the mythology of the people of Catal H\u00fcy\u00fck\".\nEconomy.\n\u00c7atalh\u00f6y\u00fck has strong evidence of an egalitarian society, as no houses with distinctive features (belonging to royalty or religious hierarchy for example) have been found so far. The most recent investigations also reveal little social distinction based on gender, with men and women receiving equivalent nutrition and seeming to have equal social status, as typically found in Paleolithic cultures. Children observed domestic areas. They learned how to perform rituals and how to build or repair houses by watching the adults make statues, beads, and other objects.\n\u00c7atalh\u00f6y\u00fck's spatial layout may be due to the close kin relations exhibited amongst the people. It can be seen, in the layout, that the people were \"divided into two groups who lived on opposite sides of the town, separated by a gully.\" Furthermore, because no nearby towns were found from which marriage partners could be drawn, \"this spatial separation must have marked two intermarrying kinship groups.\" This would help explain how a settlement so early on would become so large.\nIn the upper levels of the site, it becomes apparent that the people of \u00c7atalh\u00f6y\u00fck were honing skills in agriculture and the domestication of animals. Female figurines have been found within bins used for storage of cereals, such as wheat and barley, and the figurines are presumed to be of a deity protecting the grain. Peas were also grown, and almonds, pistachios, and fruit were harvested from trees in the surrounding hills. Sheep were domesticated and evidence suggests the beginning of cattle domestication as well. However, hunting continued to be a major source of food for the community. Pottery and obsidian tools appear to have been major industries; obsidian tools were probably both used and also traded for items such as Mediterranean sea shells and flint from Syria. Noting the lack of hierarchy and economic inequality, historian and anti-capitalist author Murray Bookchin has argued that \u00c7atalh\u00f6y\u00fck was an early example of anarcho-communism.\nConversely, a 2014 paper argues that the picture of \u00c7atalh\u00f6y\u00fck is more complex and that while there seemed to have been an egalitarian distribution of cooking tools and some stone tools, unbroken quern-stones and storage units were more unevenly distributed. Private possessions existed but shared tools also existed. It was also suggested that \u00c7atalh\u00f6y\u00fck was becoming less egalitarian, with greater inter-generational wealth transmission.\nMuseum.\nIn 2023 a new state-of-the-art museum has opened on the site, constructed by the Konya municipality. In October 2024 a bookshop and cafe was added to the site. Non-Turkish visitors are charged five euros per person for entry. There are numerous visitor-activated information kiosks, some of which provide information in English as well as Turkish. Full information on all aspects of the various discoveries is available in eight rooms, including an underground reconstruction of a typical dwelling used by people of 90 centuries ago.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "5766", "revid": "10406357", "url": "https://en.wikipedia.org/wiki?curid=5766", "title": "Clement Attlee", "text": "Prime Minister of the United Kingdom from 1945 to 1951\nClement Richard Attlee, 1st Earl Attlee (3 January 1883\u00a0\u2013 8 October 1967), was a British statesman who was Prime Minister of the United Kingdom from 1945 to 1951 and Leader of the Labour Party from 1935 to 1955. Attlee was Deputy Prime Minister during the wartime coalition government under Winston Churchill, and Leader of the Opposition on three occasions: from 1935 to 1940, briefly in 1945 and from 1951 to 1955. He remains the longest serving Labour leader.\nAttlee was born into an upper middle class family, the son of a wealthy London solicitor. After attending Haileybury College and the University of Oxford, he practised as a barrister. The volunteer work he carried out in London's East End exposed him to poverty, and his political views shifted leftwards thereafter. He joined the Independent Labour Party, gave up his legal career, and began lecturing at the London School of Economics; with his work briefly interrupted by service as an officer in the First World War. In 1919, he became mayor of Stepney and in 1922 was elected to Parliament as the Member for Limehouse. Attlee served in the first Labour minority government led by Ramsay MacDonald in 1924, and then joined the Cabinet during MacDonald's second minority (1929\u20131931). After retaining his seat in Labour's landslide defeat of 1931, he became the party's Deputy Leader. Elected Leader of the Labour Party in 1935, and at first advocating pacificism and opposing re-armament, he became a critic of Neville Chamberlain's policy of appeasement in the lead-up to the Second World War. Attlee took Labour into the wartime coalition government in 1940 and served under Winston Churchill, initially as Lord Privy Seal and then as deputy prime minister from 1942.\nThe Labour Party, led by Attlee, won a landslide victory in the 1945 general election, on their post-war recovery platform. They inherited a country close to bankruptcy following the Second World War and beset by food, housing and resource shortages. Attlee led the construction of the first Labour majority government, which aimed to maintain full employment, a mixed economy and a greatly enlarged system of social services provided by the state. To this end, it undertook the nationalisation of public utilities and major industries, and implemented wide-ranging social reforms, including the passing of the National Insurance Act 1946 and National Assistance Act 1948, the formation of the National Health Service (NHS) in 1948, and the enlargement of public subsidies for council house building. His government also reformed trade union legislation, working practices and children's services; it created the National Parks system, passed the New Towns Act 1946 and established the town and country planning system. Attlee's foreign policy focused on decolonisation efforts, including the partition of India (1947), the independence of Burma and Ceylon, and the dissolution of the British mandates of Palestine and independence of Transjordan. Attlee and Ernest Bevin encouraged the United States to take a vigorous role in the Cold War. He supported the Marshall Plan to rebuild Western Europe with American money and, in 1949, promoted the NATO military alliance against the Soviet bloc. After leading Labour to a narrow victory at the 1950 general election, he sent British troops to fight alongside South Korea in the Korean War.\nDespite his social reforms and economic programme, the pre-existing wartime shortages of food, housing and resources persisted throughout his premiership, alongside recurrent currency crises and dependence on US aid. His party was narrowly defeated by the Conservatives in the 1951 general election, despite winning the most votes. He continued as Labour leader but retired after losing the 1955 general election and was elevated to the House of Lords, where he served until his death in 1967. In public, he was modest and unassuming, but behind the scenes his depth of knowledge, quiet demeanour, objectivity and pragmatism proved decisive. He is often ranked as one of the greatest British prime ministers, receiving particular praise for his government's welfare state reforms, creation of the NHS, continuation of the \"Special Relationship\" with the US, and involvement in NATO.\nEarly life.\nClement Richard Attlee was born on 3 January 1883 in Putney, Surrey (now part of London), into an upper middle class family, the seventh of eight children. His father was Henry Attlee, a solicitor, and his mother was Ellen Bravery Watson, daughter of Thomas Simons Watson, secretary for the Art Union of London. His parents were \"committed Anglicans\" who read prayers and psalms each morning at breakfast.\nAttlee grew up in a two-storey villa with a large garden and tennis court, staffed by three servants and a gardener. His father, a political Liberal, had inherited family interests in milling and brewing, and became a senior partner in the law firm of Druces, also serving a term as president of the Law Society of England and Wales. In 1898 he purchased a estate, Comarques in Thorpe-le-Soken, Essex. At the age of nine, Attlee was sent to board at Northaw Place, a boys' preparatory school in Hertfordshire. In 1896 he followed his brothers to Haileybury College, where he was a middling student. He was influenced by the Darwinist views of his housemaster Frederick Webb Headley, and in 1899 he published an attack on striking London cab-drivers in the school magazine, predicting they would soon have to \"beg for their fares\".\nIn 1901, Attlee went up to University College, Oxford, reading modern history. He and his brother Tom \"were given a generous stipend by their father and embraced the university lifestyle\u2014rowing, reading and socializing\". He was later described by a tutor as \"level-headed, industrious, dependable man with no brilliance of style\u00a0... but with excellent sound judgement\". At university he had little interest in politics or economics, later describing his views at this time as \"good old fashioned imperialist conservative\". He graduated Bachelor of Arts in 1904 with second-class honours.\nAttlee then trained as a barrister at the Inner Temple and was called to the bar in March 1906. He worked for a time at his father's law firm Druces and Attlee but did not enjoy the work, and had no particular ambition to succeed in the legal profession. He also played football for non-League club Fleet. Attlee's father died in 1908, leaving an estate valued for probate at \u00a375,394 (equivalent to \u00a3 in 2023).\nEarly career.\nIn 1906, Attlee became a volunteer at Haileybury House, a charitable club for working-class boys in Stepney in the East End of London run by his old school, and from 1907 to 1909 he served as the club's manager. Until then, his political views had been more conservative. However, after his shock at the poverty and deprivation he saw while working with the slum children, he came to the view that private charity would never be sufficient to alleviate poverty and that only direct action and income redistribution by the state would have any serious effect. This sparked a process that caused him to convert to socialism. He joined the Independent Labour Party (ILP) in 1908 and became active in local politics.\nFollowing his father's death in November 1908, Attlee gave up his legal career and devoted himself to politics and social work. His father left him an income of \u00a3400 a year (). In 1909, he stood unsuccessfully at his first election, as an ILP candidate for Stepney Borough Council. He got a job briefly working as a secretary for Beatrice Webb in 1909, before becoming a secretary for Toynbee Hall. He worked for Webb's campaign of popularisation of the Minority Report as he was very active in Fabian Society circles, in which he would go round visiting many political societies\u2014Liberal, Conservative and socialist\u2014to explain and popularise the ideas, as well as recruiting lecturers deemed suitable to work on the campaign. In 1911, he was employed by the Government as an \"official explainer\"\u2014touring the country to explain Chancellor of the Exchequer David Lloyd George's National Insurance Act. He spent the summer of that year touring Essex and Somerset on a bicycle, explaining the Act at public meetings. A year later, he became a lecturer at the London School of Economics, teaching social science and public administration.\nMilitary service.\nFollowing the outbreak of the First World War in August 1914, Attlee applied to join the British Army. Initially his application was turned down, as his age of 31 was seen as being too old; however, he was eventually commissioned as a temporary lieutenant in the 6th (Service) Battalion, South Lancashire Regiment, on 30 September 1914. On 9 February 1915 he was promoted to captain, and on 14 March was appointed battalion adjutant. The 6th South Lancashires were part of the 38th Brigade of the 13th (Western) Division, which served in the Gallipoli campaign in Turkey. Attlee's decision to fight caused a rift between him and his older brother Tom, who, as a conscientious objector, spent much of the war in prison.\nAfter a period spent fighting in Gallipoli, Attlee collapsed after falling ill with dysentery and was put on a ship bound for England to recover. When he woke up he wanted to get back to action as soon as possible, and asked to be let off the ship in Malta, where he stayed in hospital in order to recover. His hospitalisation coincided with the Battle of Sari Bair, which saw a large number of his comrades killed. Upon returning to action, he was informed that his company had been chosen to hold the final lines during the evacuation of Suvla. As such, he was the penultimate man to be evacuated from Suvla Bay, the last being General Stanley Maude.\nThe Gallipoli Campaign had been engineered by the First Lord of the Admiralty, Winston Churchill. Although it was unsuccessful, Attlee believed that it was a bold strategy which could have been successful if it had been better implemented on the ground. This led to an admiration for Churchill as a military strategist, something which would make their working relationship in later years productive.\nHe later served in the Mesopotamian campaign in what is now Iraq, where in April 1916 he was badly wounded, being hit in the leg by shrapnel from friendly fire while storming an enemy trench during the Battle of Hanna. The battle was an unsuccessful attempt to relieve the Siege of Kut, and many of Attlee's fellow soldiers were also wounded or killed. He was sent firstly to India, and then back to the UK to recover. On 18 December 1916 he was transferred to the Heavy Section of the Machine Gun Corps, and 1 March 1917 he was promoted to the temporary rank of major, leading him to be known as \"Major Attlee\" for much of the inter-war period. He would spend most of 1917 training soldiers at various locations in England. From 2 to 9 July 1917, he was the temporary commanding officer (CO) of the newly formed L (later 10th) Battalion, the Tank Corps at Bovington Camp, Dorset. From 9 July, he assumed command of the 30th Company of the same battalion; however, he did not deploy to France with it in December 1917, as he was transferred back to the South Lancashire Regiment on 28 November.\nAfter fully recovering from his injuries, he was sent to France in June 1918 to serve on the Western Front for the final months of the war. After being discharged from the Army in January 1919, he returned to Stepney, and returned to his old job lecturing part-time at the London School of Economics.\nEarly political career.\nLocal politics.\nAttlee returned to local politics in the immediate post-war period, becoming mayor of the Metropolitan Borough of Stepney, one of London's most deprived inner-city boroughs, in 1919. During his time as mayor, the council undertook action to tackle slum landlords who charged high rents but refused to spend money on keeping their property in habitable condition. The council served and enforced legal orders on homeowners to repair their property. It also appointed health visitors and sanitary inspectors, reducing the infant mortality rate, and took action to find work for returning unemployed ex-servicemen.\nIn 1920, while mayor, he wrote his first book, \"The Social Worker\", which set out many of the principles that informed his political philosophy and that were to underpin the actions of his government in later years. The book attacked the idea that looking after the poor could be left to voluntary action. He wrote that:In a civilised community, although it may be composed of self-reliant individuals, there will be some persons who will be unable at some period of their lives to look after themselves, and the question of what is to happen to them may be solved in three ways \u2013 they may be neglected, they may be cared for by the organised community as of right, or they may be left to the goodwill of individuals in the community. [...] Charity is only possible without loss of dignity between equals. A right established by law, such as that to an old age pension, is less galling than an allowance made by a rich man to a poor one, dependent on his view of the recipient's character, and terminable at his caprice. In 1921, George Lansbury, the Labour mayor of the neighbouring borough of Poplar, and future Labour Party leader, launched the Poplar Rates Rebellion; a campaign of disobedience seeking to equalise the poor relief burden across all the London boroughs. Attlee, who was a personal friend of Lansbury, strongly supported this. However, Herbert Morrison, the Labour mayor of nearby Hackney, and one of the main figures in the London Labour Party, strongly denounced Lansbury and the rebellion. During this period, Attlee developed a lifelong dislike of Morrison.\nMember of Parliament.\nAt the 1922 general election, Attlee became the Member of Parliament (MP) for the constituency of Limehouse in Stepney. At the time, he admired Ramsay MacDonald and helped him get elected as Labour Party leader at the 1922 leadership election. He served as MacDonald's Parliamentary Private Secretary for the brief 1922 parliament. His first taste of ministerial office came in 1924, when he served as Under-Secretary of State for War in the short-lived first Labour government, led by MacDonald.\nAttlee opposed the 1926 General Strike, believing that strike action should not be used as a political weapon. However, when it happened, he did not attempt to undermine it. At the time of the strike, he was chairman of the Stepney Borough Electricity Committee. He negotiated a deal with the Electrical Trade Union so that they would continue to supply power to hospitals, but would end supplies to factories. One firm, Scammell and Nephew Ltd, took a civil action against Attlee and the other Labour members of the committee (although not against the Conservative members who had also supported this). The court found against Attlee and his fellow councillors and they were ordered to pay \u00a3300 damages. The decision was later reversed on appeal, but the financial problems caused by the episode almost forced Attlee out of politics.\nIn 1927, he was appointed a member of the multi-party Simon Commission, a royal commission set up to examine the possibility of granting self-rule to India. Due to the time he needed to devote to the commission, and contrary to a promise MacDonald made to Attlee to induce him to serve on the commission, he was not initially offered a ministerial post in the second Labour government, which entered office after the 1929 general election. Attlee's service on the Commission equipped him with a thorough exposure to India and many of its political leaders. By 1933 he argued that British rule was alien to India and was unable to make the social and economic reforms necessary for India's progress. He became the British leader most sympathetic to Indian independence (as a dominion), preparing him for his role in deciding on independence in 1947.\nIn May 1930, Labour MP Oswald Mosley left the party after its rejection of his proposals for solving the unemployment problem, and Attlee was given Mosley's post of Chancellor of the Duchy of Lancaster. In March 1931, he became Postmaster General, a post he held for five months until August, when the Labour government fell, after failing to agree on how to tackle the financial crisis of the Great Depression. That month MacDonald and a few of his allies formed a National Government with the Conservatives and Liberals, leading them to be expelled from Labour. MacDonald offered Attlee a job in the National Government, but he turned down the offer and opted to stay loyal to the main Labour party.\nAfter Ramsay MacDonald formed the National Government, Labour was deeply divided. Attlee had long been close to MacDonald and now felt betrayed\u2014as did most Labour politicians. During the course of the second Labour government, Attlee had become increasingly disillusioned with MacDonald, whom he came to regard as vain and incompetent, and of whom he later wrote scathingly in his autobiography. He would write:\nIn the old days I had looked up to MacDonald as a great leader. He had a fine presence and great oratorical power. The unpopular line which he took during the First World War seemed to mark him as a man of character. Despite his mishandling of the Red Letter episode, I had not appreciated his defects until he took office a second time. I then realised his reluctance to take positive action and noted with dismay his increasing vanity and snobbery, while his habit of telling me, a junior Minister, the poor opinion he had of all his Cabinet colleagues made an unpleasant impression. I had not, however, expected that he would perpetrate the greatest betrayal in the political history of this country\u00a0... The shock to the Party was very great, especially to the loyal workers of the rank-and-file who had made great sacrifices for these men.\nDeputy Labour Leader.\nThe general election held in October 1931 proved disastrous for the Labour Party, which lost over 200 seats, returning only 52 MPs to Parliament. The vast majority of the party's senior figures, including the Leader Arthur Henderson, lost their seats. Attlee, however, narrowly retained his Limehouse seat, with his majority being slashed from 7,288 to just 551. He was one of only three Labour MPs who had experience of government to retain their seats, along with George Lansbury and Stafford Cripps. Accordingly, Lansbury was elected Leader unopposed, with Attlee as his deputy.\nMost of the remaining Labour MPs after 1931 were elderly trade-union officials who could not contribute much to debates; Lansbury was in his 70s, and Stafford Cripps \u2013 another main figure of the Labour front-bench who had entered Parliament in January 1931 \u2013 lacked parliamentary experience. As one of the most capable and experienced of the remaining Labour MPs, Attlee therefore shouldered a lot of the burden of providing an opposition to the National Government in the years 1931 to 1935; during this time he had to extend his knowledge of subjects which he had not studied in any depth before (such as finance and foreign affairs) in order to provide an effective opposition to the government.\nAttlee effectively served as Labour's acting-leader for nine months from December 1933, after Lansbury fractured his thigh in an accident; this raised Attlee's public profile considerably. It was during this period, however, that personal financial problems almost forced Attlee to quit politics altogether. His wife had become ill, and at that time there was no separate salary for the Leader of the Opposition. On the verge of resigning from Parliament, he was persuaded to stay by Stafford Cripps, a wealthy socialist, who agreed to make a donation to party funds to pay him an additional salary until Lansbury could take over again.\nDuring 1932\u201333 Attlee flirted with, and then drew back from radicalism \u2013 influenced by Stafford Cripps, who was then on the radical wing of the party. He was briefly a member of the Socialist League, which had been formed by former Independent Labour Party (ILP) members who opposed the ILP's disaffiliation from the main Labour Party in 1932. At one point he agreed with the proposition put forward by Cripps that gradual reform was inadequate and that a socialist government would have to pass an emergency powers act, allowing it to rule by decree to overcome any opposition by vested interests until it was safe to restore democracy. He admired Oliver Cromwell's strong-armed rule and use of major generals to control England. After looking more closely at Hitler, Mussolini, Stalin, and even his former colleague Oswald Mosley (leader of the new blackshirt fascist movement in Britain), Attlee retreated from radicalism, distanced himself from the League, and argued instead that the Labour Party must adhere to constitutional methods and stand forthright for democracy and against totalitarianism either of the left or of the right. He always supported the crown, and as prime minister was close to King George\u00a0VI.\nLeader of the Opposition.\nGeorge Lansbury, a committed pacifist, resigned as the Leader of the Labour Party at the 1935 Party Conference on 8 October, after delegates voted in favour of sanctions against Italy for its aggression against Abyssinia. Lansbury had strongly opposed the policy, and felt unable to continue leading the party. Taking advantage of the disarray in the Labour Party, the Prime Minister Stanley Baldwin announced on 19 October that a general election would be held on 14 November. With no time for a leadership contest, the party agreed that Attlee should serve as interim leader, on the understanding that a leadership election would be held after the general election. Attlee therefore led Labour through the 1935 election, which saw the party stage a partial comeback from its disastrous 1931 performance, winning 38 per cent of the vote, the highest share Labour had won up to that point, and gaining over one hundred seats.\nAttlee stood in the subsequent leadership election, held soon afterward, where he was opposed by Herbert Morrison, who had just re-entered parliament in the recent election, and Arthur Greenwood: Morrison was seen as the favourite, but was distrusted by many sections of the party, especially the left wing. Arthur Greenwood meanwhile was a popular figure in the party; however, his leadership bid was severely hampered by his alcohol problem. Attlee was able to come across as a competent and unifying figure, particularly having already led the party through a general election. He went on to come first in both the first and second ballots, formally being elected Leader of the Labour Party on 3 December 1935.\nThroughout the 1920s and most of the 1930s, the Labour Party's official policy had been to oppose rearmament, instead supporting internationalism and collective security under the League of Nations. At the 1934 Labour Party Conference, Attlee declared that, \"We have absolutely abandoned any idea of nationalist loyalty. We are deliberately putting a world order before our loyalty to our own country. We say we want to see put on the statute book something which will make our people citizens of the world before they are citizens of this country\". During a debate on defence in Commons a year later, Attlee said \"We are told (in the White Paper) that there is danger against which we have to guard ourselves. We do not think you can do it by national defence. We think you can only do it by moving forward to a new world. A world of law, the abolition of national armaments with a world force and a world economic system. I shall be told that that is quite impossible\". Shortly after those comments, Adolf Hitler proclaimed that German rearmament offered no threat to world peace. Attlee responded the next day noting that Hitler's speech, although containing unfavourable references to the Soviet Union, created \"A chance to call a halt in the armaments race\u00a0... We do not think that our answer to Herr Hitler should be just rearmament. We are in an age of rearmaments, but we on this side cannot accept that position\".\nAttlee played little part in the events that would lead up to the abdication of Edward\u00a0VIII, for despite Baldwin's threat to step down if Edward attempted to remain on the throne after marrying Wallis Simpson, Labour was widely accepted not to be a viable alternative government, owing to the National Government's overwhelming majority in the Commons. Attlee, along with Liberal leader Archibald Sinclair, was eventually consulted with by Baldwin on 24 November 1936, and Attlee agreed with both Baldwin and Sinclair that Edward could not remain on the throne, firmly eliminating any prospect of any alternative government forming were Baldwin to resign.\nIn April 1936, the Chancellor of the Exchequer, Neville Chamberlain, introduced a Budget which increased the amount spent on the armed forces. Attlee made a radio broadcast in opposition to it, saying:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;[The budget] was the natural expression of the character of the present Government. There was hardly any increase allowed for the services which went to build up the life of the people, education and health. Everything was devoted to piling up the instruments of death. The Chancellor expressed great regret that he should have to spend so much on armaments, but said that it was absolutely necessary and was due only to the actions of other nations. One would think to listen to him that the Government had no responsibility for the state of world affairs. [...] The Government has now resolved to enter upon an arms race, and the people will have to pay for their mistake in believing that it could be trusted to carry out a policy of peace. [...] This is a War Budget. We can look in the future for no advance in Social Legislation. All available resources are to be devoted to armaments.\nIn June 1936, the Conservative MP Duff Cooper called for an Anglo-French alliance against possible German aggression and called for all parties to support one. Attlee condemned this: \"We say that any suggestion of an alliance of this kind\u2014an alliance in which one country is bound to another, right or wrong, by some overwhelming necessity\u2014is contrary to the spirit of the League of Nations, is contrary to the Covenant, is contrary to Locarno is contrary to the obligations which this country has undertaken, and is contrary to the professed policy of this Government\". At the Labour Party conference at Edinburgh in October Attlee reiterated that \"There can be no question of our supporting the Government in its rearmament policy\".\nHowever, with the rising threat from Nazi Germany, and the ineffectiveness of the League of Nations, this policy eventually lost credibility. By 1937, Labour had jettisoned its pacifist position and came to support rearmament and oppose Neville Chamberlain's policy of appeasement. However Attlee and the Labour Party strongly opposed conscription when it was passed in April 1939.\nAt the end of 1937, Attlee and a party of three Labour MPs visited Spain and visited the British Battalion of the International Brigades fighting in the Spanish Civil War. One of the companies was named the \"Major Attlee Company\" in his honour. Attlee was supportive of the Republican government in Spain, and at the 1937 Labour conference moved the wider Labour Party towards opposing what he considered the \"farce\" of the Non-Intervention Committee organised by the British and French governments. In the House of Commons, Attlee stated, \"I cannot understand the delusion that if Franco wins with Italian and German aid, he will immediately become independent. I think it is a ridiculous proposition.\" Dalton, the Labour Party's spokesman on foreign policy, also thought that Franco would ally with Germany and Italy. However, Franco's subsequent behaviour proved it was not such a ridiculous proposition. As Dalton later acknowledged, Franco skilfully maintained Spanish neutrality, whereas Hitler would likely have occupied Spain if Franco had lost the Civil War.\nIn 1938, Attlee opposed the Munich Agreement, in which Chamberlain negotiated with Hitler to give Germany the German-speaking parts of Czechoslovakia, the Sudetenland: We all feel relief that war has not come this time... we cannot, however, feel that peace has been established, but that we have nothing but an armistice in a state of war. We have been unable to go in for care-free rejoicing. We have felt that we are in the midst of a tragedy... [and] humiliation. This has not been a victory for reason and humanity. It has been a victory for brute force. At every stage of the proceedings there have been time limits laid down... [the] terms laid down as ultimata. We have seen to-day a gallant, civilised and democratic people betrayed and handed over to a ruthless despotism... The events of these last few days constitute one of the greatest diplomatic defeats that this country and France have ever sustained. There can be no doubt that it is a tremendous victory for Herr Hitler. Without firing a shot, by the mere display of military force, he has achieved a dominating position in Europe which Germany failed to win after four years of war. He has overturned the balance of power in Europe... [and] destroyed the last fortress of democracy in Eastern Europe which stood in the way of his ambition. He has opened his way to the food, the oil and the resources which he requires in order to consolidate his military power, and he has successfully defeated and reduced to impotence the forces that might have stood against the rule of violence. [...] The cause [of the crisis which we have undergone] was not the existence of minorities in Czechoslovakia; it was not that the position of the Sudeten Germans had become intolerable. It was not the wonderful principle of self-determination. It was because Herr Hitler had decided that the time was ripe for another step forward in his design to dominate Europe... The minorities question is no new one. [...] [And] short of a drastic and entire reshuffling of these populations there is no possible solution to the problem of minorities in Europe except toleration.\nHowever, the new Czechoslovakian state did not provide equal rights to the Slovaks and Sudeten Germans, with the historian Arnold J. Toynbee already having noted that \"for the Germans, Magyars and Poles, who account between them for more than one quarter of the whole population, the present regime in Czechoslovakia is not essentially different from the regimes in the surrounding countries\". Anthony Eden in the Munich debate acknowledged that there had been \"discrimination, even severe discrimination\" against the Sudeten Germans.\nIn 1937, Attlee wrote a book entitled \"The Labour Party in Perspective\" that sold fairly well in which he set out some of his views. He argued that there was no point in Labour compromising on its socialist principles in the belief that this would achieve electoral success. He wrote: \"I find that the proposition often reduces itself to this \u2013 that if the Labour Party would drop its socialism and adopt a Liberal platform, many Liberals would be pleased to support it. I have heard it said more than once that if Labour would only drop its policy of nationalisation everyone would be pleased, and it would soon obtain a majority. I am convinced it would be fatal for the Labour Party.\" He also wrote that there was no point in \"watering down Labour's socialist creed in order to attract new adherents who cannot accept the full socialist faith. On the contrary, I believe that it is only a clear and bold policy that will attract this support\".\nIn the late 1930s, Attlee sponsored a Jewish mother and her two children, enabling them to leave Germany in 1939 and move to the UK. On arriving in Britain, Attlee invited one of the children into his home in Stanmore, north-west London, where he stayed for several months.\nDeputy Prime Minister.\nAttlee remained as Leader of the Opposition when the Second World War broke out in September 1939. The ensuing disastrous Norwegian campaign would result in a motion of no confidence in Neville Chamberlain. Although Chamberlain survived this, the reputation of his administration was so badly and publicly damaged that it became clear a coalition government would be necessary. Even if Attlee had personally been prepared to serve under Chamberlain in an emergency coalition government, he would never have been able to carry Labour with him. Consequently, Chamberlain tendered his resignation, and Labour and the Conservatives entered a coalition government led by Winston Churchill on 10 May 1940, with Attlee joining the Cabinet as Lord Privy Seal on 12 May.\nAttlee and Churchill quickly agreed that the War Cabinet would consist of three Conservatives (initially Churchill, Chamberlain and Lord Halifax) and two Labour members (initially himself and Arthur Greenwood) and that Labour should have slightly more than one third of the posts in the coalition government. Attlee and Greenwood played a vital role in supporting Churchill during a series of War Cabinet debates over whether or not to negotiate peace terms with Hitler following the Fall of France in May 1940; both supported Churchill and gave him the majority he needed in the War Cabinet to continue Britain's resistance.\nOnly Attlee and Churchill remained in the War Cabinet from the formation of the Government of National Unity in May 1940 through to the election in May 1945. Attlee was initially the Lord Privy Seal, before becoming Britain's first ever Deputy Prime Minister in 1942, as well as becoming the Dominions Secretary and Lord President of the Council on 28 September 1943.\nAttlee himself played a generally low key but vital role in the wartime government, working behind the scenes and in committees to ensure the smooth operation of government. Attlee was also pivotal in the British war effort on the home front. In the coalition government, three inter-connected committees effectively ran the country. Churchill chaired the first two, the War cabinet and the Defence Committee, with Attlee deputising for him in these, and answering for the government in Parliament when Churchill was absent. Attlee himself instituted, and later chaired the third body, the Lord President's Committee, which was responsible for overseeing domestic affairs. As Churchill was most concerned with overseeing the war effort, this arrangement suited both men. Attlee himself had largely been responsible for creating these arrangements with Churchill's backing, streamlining the machinery of government and abolishing many committees. He also acted as a conciliator in the government, smoothing over tensions which frequently arose between Labour and Conservative Ministers.\nMany Labour activists were baffled by the top leadership role for a man they regarded as having little charisma; Beatrice Webb wrote in her diary in early 1940:\nHe looked and spoke like an insignificant elderly clerk, without distinction in the voice, manner or substance of his discourse. To realise that this little nonentity is the Parliamentary Leader of the Labour Party\u00a0... and presumably the future P.M. [Prime Minister] is pitiable\".\n1945 election.\nFollowing the defeat of Nazi Germany and the end of the War in Europe in May 1945, Attlee and Churchill favoured the coalition government remaining in place until Japan had been defeated. However, Herbert Morrison made it clear that the Labour Party would not be willing to accept this, and Churchill was forced to tender his resignation as Prime Minister and call an immediate election.\nThe war had set in motion profound social changes within Britain and had ultimately led to a widespread popular desire for social reform. This mood was epitomised in the Beveridge Report of 1942, by the Liberal economist William Beveridge. The \"Report\" assumed that the maintenance of full employment would be the aim of post-war governments, and that this would provide the basis for the welfare state. Immediately upon its release, it sold hundreds of thousands of copies. All major parties committed themselves to fulfilling this aim, but most historians say that Attlee's Labour Party was seen by the electorate as the party most likely to follow it through.\nLabour campaigned on the theme of \"Let Us Face the Future\", positioning themselves as the party best placed to rebuild Britain following the war, and were widely viewed as having run a strong and positive campaign, while the Conservative campaign centred entirely on Churchill. Despite opinion polls indicating a strong Labour lead, opinion polls were then viewed as a novelty which had not proven their worth, and most commentators expected that Churchill's prestige and status as a \"war hero\" would ensure a comfortable Conservative victory. Before polling day, \"The Manchester Guardian\" surmised that \"the chances of Labour sweeping the country and obtaining a clear majority\u00a0... are pretty remote\". The \"News of the World\" predicted a working Conservative majority, while in Glasgow a pundit forecast the result as Conservatives 360, Labour 220, Others 60. Churchill, however, made some costly errors during the campaign. In particular, his suggestion during one radio broadcast that a future Labour Government would require \"some form of a gestapo\" to implement their policies was widely regarded as being in very bad taste and massively backfired.\nWhen the results of the election were announced on 26 July, they came as a surprise to most, including Attlee himself. Labour had won power by a huge landslide, winning 49.7 per cent of the vote to the Conservatives' 36.2 per cent. This gave them 393 seats in the House of Commons, a working majority of 146. This was the first time in history that the Labour Party had won a majority in Parliament. When Attlee went to see King George\u00a0VI at Buckingham Palace to be appointed prime minister, the notoriously laconic Attlee and the famously tongue-tied King stood in silence; Attlee finally volunteered the remark, \"I've won the election\". The King replied \"I know. I heard it on the Six O'Clock News\".\nPrime Minister.\nDomestic policy.\nFrancis (1995) argues there was consensus both in the Labour's national executive committee and at party conferences on a definition of socialism that stressed moral improvement as well as material improvement. The Attlee government was committed to rebuilding British society as an ethical commonwealth, using public ownership and controls to abolish extremes of wealth and poverty. Labour's ideology contrasted sharply with the contemporary Conservative Party's defence of individualism, inherited privileges, and income inequality. On 5 July 1948, Clement Attlee replied to a letter dated 22 June from James Murray and ten other MPs who raised concerns about West Indians who arrived on board the . As for the prime minister himself, he was not much focused on economic policy, letting others handle the issues.\nNationalisation.\nAttlee's government also carried out their manifesto commitment for nationalisation of basic industries and public utilities. The Bank of England and civil aviation were nationalised in 1946. Coal mining, the railways, road haulage, canals and Cable and Wireless were nationalised in 1947, and electricity and gas followed in 1948. The steel industry was nationalised in 1951. By 1951 about 20 per cent of the British economy had been taken into public ownership.\nNationalisation failed to provide workers with a greater say in the running of the industries in which they worked. It did, however, bring about significant material gains for workers in the form of higher wages, reduced working hours, and improvements in working conditions, especially in regards to safety. As historian Eric Shaw noted of the years following nationalisation, the electricity and gas supply companies became \"impressive models of public enterprise\" in terms of efficiency, and the National Coal Board was not only profitable, but working conditions for miners had significantly improved as well.\nWithin a few years of nationalisation, a number of progressive measures had been carried out which did much to improve conditions in the mines, including better pay, a five-day working week, a national safety scheme (with proper standards at all the collieries), a ban on boys under the age of 16 going underground, the introduction of training for newcomers before going down to the coalface, and the making of pithead baths into a standard facility.\nThe newly established National Coal Board offered sick pay and holiday pay to miners. As noted by Martin Francis:\nUnion leaders saw nationalisation as a means to pursue a more advantageous position within a framework of continued conflict, rather than as an opportunity to replace the old adversarial form of industrial relations. Moreover, most workers in nationalised industries exhibited an essentially instrumentalist attitude, favouring public ownership because it secured job security and improved wages rather than because it promised the creation of a new set of socialist relationships in the workplace.\nHealth.\nAttlee's Health Minister, Aneurin Bevan, fought hard against the general disapproval of the medical establishment, including the British Medical Association, by creating the National Health Service in 1948. This was a publicly funded healthcare system, which offered treatment for all, regardless of income, free of charge at the point of use. Reflecting pent-up demand that had long existed for medical services, the NHS treated some 8.5 million dental patients and dispensed more than 5 million pairs of spectacles during its first year of operation.\nConsultants benefited from the new system by being paid salaries that provided an acceptable standard of living without the need for them to resort to private practice. The NHS brought major improvements in the health of working-class people, with deaths from diphtheria, pneumonia, and tuberculosis significantly reduced. Although there were often disputes about its organisation and funding, British political parties continued to voice their general support for the NHS in order to remain electable.\nIn the field of health care, funds were allocated to modernisation and extension schemes aimed at improving administrative efficiency. Improvements were made in nursing accommodation in order to recruit more nurses and reduce labour shortages which were keeping 60,000 beds out of use, and efforts were made to reduce the imbalance \"between an excess of fever and tuberculosis (TB) beds and a shortage of maternity beds\".\nBCG vaccinations were introduced for the protection of medical students, midwives, nurses, and contacts of patients with tuberculosis, a pension scheme was set up for employees of the newly established NHS, The National Health Service (Superannuation) Regulations 1947 laid down a number of provisions for beneficiaries including an officer's pension and retiring allowance, an injury allowance, a short service gratuity, a death gratuity, a widow's pension, and supplementary payments in the case of special classes of officers. Provision was also made for the allocation of part of pension or injury allowance to spouse of dependent.\nThe Radioactive Substances Act 1948 set out general provisions to control radioactive substances. Numerous lesser reforms were also introduced, some of which were of great benefit to certain segments of British society, such as the mentally deficient and the blind. Between 1948 and 1951, Attlee's government increased spending on health from \u00a36 billion to \u00a311 billion: an increase of over 80%, and from 2.1% to 3.6% of GDP.\nWelfare.\nThe government set about implementing the Wartime plans of William Beveridge's plans for the creation of a 'cradle to grave' welfare state, and set in place an entirely new system of social security. Among the most important pieces of legislation was the National Insurance Act 1946, in which people in work paid a flat rate of national insurance. In return, they (and the wives of male contributors) were eligible for flat-rate pensions, sickness benefit, unemployment benefit, and funeral benefit. Various provisions were included in the National Insurance Act 1946 including unemployment and sickness benefit, maternity grant and attendance allowance, maternity allowance, widow's benefit, widow's pensions in special cases, guardian's allowance, retirement pension, and death grant.\nVarious other pieces of legislation provided for child benefit and support for people with no other source of income. In 1949, unemployment, sickness and maternity benefits were exempted from taxation.\nA block grant introduced in 1948 helped the social services provided by local authorities. Personal Social Services or welfare services were developed in 1948 for individual and families in general, particularly special groups such as the mentally disordered, deprived children, the elderly, and the handicapped.\nThe Attlee Government increased pensions and other benefits, with pensions raised to become more of a living income than they had ever been. War pensions and allowances (for both World Wars) were increased by the Pensions (Increase) Act 1947, which gave the wounded man with an allowance for his wife and children if he married after he had been wounded, thereby removing a grievance of more than twenty years standing. Other improvements were made in war pensions during Attlee's tenure as prime minister. A Constant Attendance Allowance was tripled, an Unemployability Allowance was tripled from 10s to 30s a week, and a special hardship allowance of up to \u00a31 a week was introduced. In addition, the 1951 Budget made further improvements in the supplementary allowances for many war pensioners. From 1945 onwards, three out of every four pension claims had been successful, whilst after the First World War only one pension claim in three was allowed. Under the Superannuation (Miscellaneous Provisions) Act 1948, employees of a body representative of local authorities or of the officers of local authorities could be admitted \"on suitable terms to the superannuation fund of a local authority\". In 1951, a comforts allowance was introduced that was automatically paid to war pensioners \"receiving unemployability supplement and constant attendance allowance\".\nThe Personal injuries (Civilians) Scheme of 1947 included various benefits such as an exceptional maximum rate of constant attendance allowance of 40s a week, and an allowance for wear and tear of clothing caused by the use of artificial limbs and appliances. In addition, allowances payable while a pensioner underwent inpatient treatment \"are normally no longer subject to a deduction in respect of decreased home expenditure.\" Various changes were also made in respect of gainfully employed persons who sustained war injuries and civil defence volunteers who war service injuries. These included the provision of allowances for the wife and children for injured persons receiving injury allowance or disablement pension, amendments to the provisions for an allowance to a pensioner deemed unemployable by reason of his pensioned disablement \"to secure that he receives in the aggregate by way of unemployability allowance and any social service benefits for which he is eligible at least 20s. a week in addition to his pension,\" increases in the allowance payable for a wife of a person receiving treatment allowance, unemployability allowance or injury allowance under certain conditions and \"if no allowance is payable for a wife, an allowance may be granted for a dependant adult,\" and a social hardship allowance for partially disabled men \"who, though not unemployable, is prevented by his pensioned disablement from resuming his former occupation or taking up one of equivalent standard.\" Also, \"Where a man dies as the direct result of a qualifying injury his widow may be awarded a pension (with allowances for his children) without regard to the date of marriage.\"\nA more extensive system of social welfare benefits had been established by the Attlee Government, which did much to reduce acute social deprivation. The cumulative impact of the Attlee's Government's health and welfare policies was such that all the indices of health (such as statistics of school medical or dental officers, or of medical officers of health) showed signs of improvement, with continual improvements in survival rates for infants and increased life expectancy for the elderly. The success of the Attlee Government's welfare legislation in reducing poverty was such that, in the general election of 1950, according to one study, \"Labour propaganda could make much of the claim that social security had eradicated the most abject destitution of the 1930s\".\nEducation.\nThe Attlee government ensured provisions of the Education Act 1944 were fully implemented, with free secondary education becoming a right for the first time. Fees in state grammar schools were eliminated, while new, modern secondary schools were constructed.\nThe school leaving age was raised to 15 in 1947, an accomplishment helped brought into fruition by initiatives such as the HORSA (\"Huts Operation for Raising the School-leaving Age\") scheme and the S.F.O.R.S.A. (furniture) scheme. University scholarships were introduced to ensure that no one who was qualified \"should be deprived of a university education for financial reasons\", while a large school building programme was organised. A rapid increase in the number of trained teachers took place, and the number of new school places was increased. Under the Education Act of 1946 and the Education (Miscellaneous Provisions) Act 1948, local authorities were empowered to provide clothing to pupils.\nIncreased Treasury funds were made available for education, particularly for upgrading school buildings suffering from years of neglect and war damage. Prefabricated classrooms were built, and 928 new primary schools were constructed between 1945 and 1950. The provision of free school meals was expanded, and opportunities for university entrants were increased. State scholarships to universities were increased, and the government adopted a policy of supplementing university scholarships awards to a level sufficient to cover fees plus maintenance.\nMany thousands of ex-servicemen were assisted to go through college who could never have contemplated it before the war. Free milk was also made available to all schoolchildren for the first time. In addition, spending on technical education rose, and the number of nursery schools was increased. Salaries for teachers were also improved, and funds were allocated towards improving existing schools.\nIn 1947 the Arts Council of Great Britain was set up to encourage the arts.\nThe Ministry of Education was established under the 1944 Act, and free County Colleges were set up for the compulsory part-time instruction of teenagers between the ages of 15 and 18 who were not in full-time education. An Emergency Training Scheme was also introduced which turned out an extra 25,000 teachers in 1945\u20131951. In 1947, Regional Advisory Councils were set up to bring together industry and education to find out the needs of young workers \"and advise on the provision required, and to secure reasonable economy of provision\". That same year, thirteen Area Training Organisations were set up in England and one in Wales to coordinate teacher training.\nAttlee's government, however, failed to introduce the comprehensive education for which many socialists had hoped. This reform was eventually carried out by Harold Wilson's government. During its time in office, the Attlee government increased spending on education by over 50 per cent, from \u00a36.5\u00a0billion to \u00a310\u00a0billion.\nEconomy.\nThe most significant problem facing Attlee and his ministers remained the economy, as the war effort had left Britain nearly bankrupt. Overseas investments had been used up to pay for the war. The transition to a peacetime economy, and the maintaining of strategic military commitments abroad led to continuous and severe problems with the balance of trade. This resulted in strict rationing of food and other essential goods continuing in the post war period to force a reduction in consumption in an effort to limit imports, boost exports, and stabilise the Pound Sterling so that Britain could trade its way out of its financial state.\nThe abrupt end of the American Lend-Lease programme in August 1945 almost caused a crisis. Some relief was provided by the Anglo-American loan, negotiated in December 1945. The conditions attached to the loan included making the pound fully convertible to the US dollar. When this was introduced in July 1947, it led to a currency crisis and convertibility had to be suspended after just five weeks. The UK benefited from the American Marshall Aid program in 1948, and the economic situation improved significantly. Another balance of payments crisis in 1949 forced Chancellor of the Exchequer, Stafford Cripps, into devaluation of the pound.\nDespite these problems, one of the main achievements of Attlee's government was the maintenance of near full employment. The government maintained most of the wartime controls over the economy, including control over the allocation of materials and manpower, and unemployment rarely rose above 500,000, or 3 per cent of the total workforce. Labour shortages proved a more frequent problem. The inflation rate was also kept low during his term. The rate of unemployment rarely rose above 2 per cent during Attlee's time in office, whilst there was no hard-core of long-term unemployed. Both production and productivity rose as a result of new equipment, while the average working week was shortened.\nThe government was less successful in housing, which was the responsibility of Aneurin Bevan. The government had a target to build 400,000 new houses a year to replace those which had been destroyed in the war, but shortages of materials and manpower meant that less than half this number were built. Nevertheless, millions of people were rehoused as a result of the Attlee government's housing policies. Between August 1945 and December 1951, 1,016,349 new homes were completed in England, Scotland, and Wales.\nWhen the Attlee government was voted out of office in 1951, the economy had been improved compared to 1945. The period from 1946 to 1951 saw continuous full employment and steadily rising living standards, which increased by about 10 per cent each year. During that same period, the economy grew by 3 per cent a year, and by 1951 the UK had \"the best economic performance in Europe, while output per person was increasing faster than in the United States\". Careful planning after 1945 also ensured that demobilisation was carried out without having a negative impact upon economic recovery, and that unemployment stayed at very low levels. In addition, the number of motor cars on the roads rose from 3\u00a0million to 5\u00a0million from 1945 to 1951, and seaside holidays were taken by far more people than ever before. A Monopolies and Restrictive Practices (Inquiry and Control) Act was passed in 1948, which allowed for investigations of restrictive practices and monopolies. However, some economic historians have argued that the UK failed to develop economically after the war, with failure to support industry leaving the economy not recovering as effectively as Germany.\nEnergy.\n1947 proved a particularly difficult year for the government; an exceptionally cold winter that year caused coal mines to freeze and cease production, creating widespread power cuts and food shortages. The Minister of Fuel and Power, Emanuel Shinwell was widely blamed for failing to ensure adequate coal stocks, and soon resigned from his post. The Conservatives capitalised on the crisis with the slogan 'Starve with Strachey and shiver with Shinwell' (referring to the Minister of Food John Strachey).\nThe crisis led to an unsuccessful plot by Hugh Dalton to replace Attlee as prime minister with Ernest Bevin. Later that year Stafford Cripps tried to persuade Attlee to stand aside for Bevin. These plots petered out after Bevin refused to cooperate. Later that year, Dalton resigned as Chancellor after inadvertently leaking details of the budget to a journalist. He was replaced by Cripps.\nForeign policy.\nIn foreign affairs, the Attlee government was concerned with four main issues: post-war Europe, the onset of the Cold War, the establishment of the United Nations, and decolonisation. The first two were closely related, and Attlee was assisted by Foreign Secretary Ernest Bevin. Attlee also attended the later stages of the Potsdam Conference, where he negotiated with President Harry S. Truman and Joseph Stalin.In the immediate aftermath of the war, the Government faced the challenge of managing relations with Britain's former war-time ally, Stalin and the Soviet Union. Ernest Bevin was a passionate anti-communist, based largely on his experience of fighting communist influence in the trade union movement. Bevin's initial approach to the USSR as foreign secretary was \"wary and suspicious, but not automatically hostile\". Attlee himself sought warm relations with Stalin. He put his trust in the United Nations, rejected notions that the Soviet Union was bent on world conquest, and warned that treating Moscow as an enemy would turn it into one. This put Attlee at sword's point with his foreign minister, the Foreign Office, and the military who all saw the Soviets as a growing threat to Britain's role in the Middle East. Suddenly in January 1947, Attlee reversed his position and agreed with Bevin on a hardline anti-Soviet policy.\nIn an early \"good-will\" gesture that was later heavily criticised, the Attlee government allowed the Soviets to purchase, under the terms of a 1946 UK-USSR Trade agreement, a total of 25 Rolls-Royce Nene jet engines in September 1947 and March 1948. The agreement included an agreement not to use them for military purposes. The price was fixed under a commercial contract; a total of 55 jet engines were sold to the USSR in 1947. However, the Cold War intensified during this period and the Soviets, who at the time were well behind the West in jet technology, reverse-engineered the Nene and installed their own version in the MiG-15 interceptor. This was used to good effect against US-UK forces in the subsequent Korean War, as well as in several later MiG models.\nAfter Stalin took political control of most of Eastern Europe, and began to subvert other governments in the Balkans, Attlee's and Bevin's worst fears of Soviet intentions were realised. The Attlee government then became instrumental in the creation of the successful NATO defence alliance to protect Western Europe against any Soviet expansion. In a crucial contribution to the economic stability of post-war Europe, Attlee's Cabinet was instrumental in promoting the American Marshall Plan for the economic recovery of Europe. He called it one of the \"most bold, enlightened and good-natured acts in the history of nations\".\nA group of Labour MPs, organised under the banner of \"Keep Left\", urged the government to steer a middle way between the two emerging superpowers, and advocated the creation of a \"third force\" of European powers to stand between the US and USSR. However, deteriorating relations between Britain and the USSR, as well as Britain's economic reliance on America following the Marshall Plan, steered policy towards supporting the US. In January 1947, fear of both Soviet and American nuclear intentions led to a secret meeting of the Cabinet, where the decision was made to press ahead with the development of Britain's independent nuclear deterrent, an issue which later caused a split in the Labour Party. Britain's first successful nuclear test, however, did not occur until 1952, one year after Attlee had left office.\nThe London dock strike of July 1949, led by Communists, was suppressed when the Attlee government sent in 13,000 Army troops and passed special legislation to promptly end the strike. His response reveals Attlee's growing concern that Soviet expansionism, supported by the Communist Party of Britain, was a genuine threat to national security, and that the docks were highly vulnerable to sabotage ordered by Moscow. He noted that the strike was caused not by local grievances, but to help communist unions who were on strike in Canada. Attlee agreed with MI5 that he faced \"a very present menace\".\nDecolonisation.\nDecolonisation was never a major election issue, but Attlee gave the matter a great deal of attention and was the chief leader in beginning the process of decolonisation of the British Empire.\nEast Asia.\nIn August 1948, the Chinese Communists' victories caused Attlee to begin preparing for a Communist takeover of China. It kept open consulates in Communist-controlled areas and rejected the Chinese Nationalists' requests that British citizens assist in the defence of Shanghai. By December, the government concluded that although British property in China would likely be nationalised, British traders would benefit in the long run from a stable, industrialising Communist China. Retaining Hong Kong was especially important to him; although the Chinese Communists promised to not interfere with its rule, Britain reinforced the Hong Kong Garrison during 1949. When the victorious Chinese Communists government declared on 1 October 1949 that it would exchange diplomats with any country that ended relations with the Chinese Nationalists, Britain became the first western country to formally recognise the People's Republic of China in January 1950. In 1954, a Labour Party delegation including Attlee visited China at the invitation of then Foreign Minister Zhou Enlai. Attlee became the first high-ranking western politician to meet Mao Zedong.\nSouth Asia.\nAttlee orchestrated the granting of independence to India and Pakistan in 1947. Attlee in 1928\u20131934 had been a member of the Indian Statutory Commission (otherwise known as the Simon Commission). He became the Labour Party expert on India and by 1934 was committed to granting India the same independent dominion status that Canada, Australia, New Zealand and South Africa had recently been given. He faced strong resistance from the die-hard Conservative imperialists, led by Churchill, who opposed both independence and efforts led by Prime Minister Stanley Baldwin to set up a system of limited local control by Indians themselves. Attlee and the Labour leadership were sympathetic to both the Indian National Congress led by Jawaharlal Nehru and the Pakistan movement led by Muhammad Ali Jinnah. During the Second World War, Attlee was in charge of Indian affairs. He set up the Cripps Mission in 1942, which tried and failed to bring the factions together and unite behind the war effort. When Gandhi and Congress called for passive resistance in the Quit India movement of 1942\u20131945, the British government ordered the widespread arrest and internment for the duration of tens of thousands of Congress leaders as part of its efforts to crush the revolt.\nLabour's election Manifesto in 1945 called for \"the advancement of India to responsible self-government\". Attlee did not object. By contrast, the Muslim League, led by Muhammad Ali Jinnah, strongly supported the war effort. They greatly enlarged their membership and won favour from London for their decision. Attlee retained a fondness for Congress and until 1946, accepted their thesis that they were a non-religious party that accepted Hindus, Muslims, Sikhs, and everyone else. Nevertheless, this difference in opinion between the Congress and the Muslim League towards the British war effort encouraged Attlee and his government to consider further negotiations with the Muslim League.\nThe Muslim League insisted that it was the only true representative of all of the Muslims of India. With violence escalating in India after the war, but with British financial power at a low ebb, large-scale military involvement was impossible. Viceroy Archibald Wavell said he needed a further seven army divisions to prevent communal violence if independence negotiations failed. No divisions were available; independence was the only option. Given the increasing demands of the Muslim League, independence implied a partition that set off heavily Muslim Pakistan from the main portion of India. After becoming prime minister in 1945 Attlee originally planned to give India dominion status in 1948.\nAttlee suggested in his memoirs that \"traditional\" colonial rule in Asia was no longer viable. He said that he expected it to meet renewed opposition after the war both by local national movements as well as by the United States. The prime minister's biographer John Bew says that Attlee hoped for a transition to a multilateral world order and a Commonwealth, and that the old British Empire \"should not be supported beyond its natural lifespan\" and instead be ended \"on the right note.\" His exchequer Hugh Dalton meanwhile feared that post-war Britain could no longer afford to garrison its empire.\nUltimately the Labour government gave full independence to India and Pakistan in 1947 through the Indian Independence Act. This involved creating a demarcation between the two regions which was known as the Radcliffe Line. The boundary between the newly created states of Pakistan and India involved the widespread resettlement of millions of Hindus, Sikhs and Muslims. Almost immediately, extreme anti-Hindu and anti-Sikh violence ensued in Lahore, Multan and Dacca when the Punjab province and the Bengal province were split in the Partition of India. This was followed by a rapid increase in widespread anti-Muslim violence in several areas including Amritsar, Rajkot, Jaipur, Calcutta and Delhi. Historian Yasmin Khan estimates that over a million people were killed of which several were women and children. Gandhi himself was assassinated in January 1948. Attlee remarked Gandhi as the \"greatest citizen\" of India and added, \"this one man has been the major factor in every consideration of the Indian problem. He had become the expression of the aspirations of the Indian people for independence\".\nHistorian Andrew Roberts says the independence of India was a \"national humiliation\" but it was necessitated by urgent financial, administrative, strategic and political needs. Churchill in 1940\u20131945 had tightened the hold on India and imprisoned the Congress leadership, with Attlee's approval. Labour had looked forward to making it a fully independent dominion like Canada or Australia. Many of the Congress leaders in the India had studied in England, and were highly regarded as fellow idealistic socialists by Labour leaders. Attlee was the Labour expert on India and took special charge of decolonisation. Attlee found that Churchill's viceroy, Field Marshal Wavell, was too imperialistic, too keen on military solutions, and too neglectful of Indian political alignments. The eventual appointee for new viceroy, Lord Mountbatten, the dashing war hero and a cousin of the King, was put forward by V. K. Krishna Menon as a candidate acceptable to all, in a series of clandestine meetings with Sir Stafford Scripps, and with Attlee.\nAttlee also sponsored the peaceful transition to independence in 1948 of Burma (Myanmar) and Ceylon (Sri Lanka).\nPalestine.\nOne of the most urgent problems facing Attlee concerned the future of the British mandate in Palestine, which had become too troublesome and expensive to handle. British policies in Palestine were perceived by the Zionist movement and the Truman administration to be pro-Arab and anti-Jewish, and Britain soon found itself unable to maintain public order in the face of a Jewish insurgency and a civil war.\nDuring this period, 70,000 Holocaust survivors attempted to reach Palestine as part of the Aliyah Bet refugee movement. Attlee's government tried several tactics to prevent the migration. Five ships were bombed by the Secret Intelligence Service (though with no casualties) with a fake Palestinian group created to take responsibility. The navy apprehended over 50,000 refugees en route, interning them in detention camps in Cyprus. Conditions in the camps were harsh and faced global criticism. Later, the refugee ship Exodus 1947 would be sent back to mainland Europe, instead of being taken to Cyprus.\nIn response to the increasingly unpopular mandate, Attlee ordered the evacuation of all British military personnel and handed over the issue to the United Nations, a decision which was widely supported by the general public in Britain. With the establishment of the state of Israel in 1948, the camps in Cyprus were eventually closed, with their former occupants completing their journey to the new country.\nAttlee remained hostile to Israel years after its establishment. In 1958, describing the Israelis as extremely aggressive against the neighbouring Arab states and describing the Balfour Declaration as a mistake.\nAfrica.\nThe government's policies with regard to the other colonies, particularly those in Africa, focused on keeping them as strategic Cold War assets while modernising their economies. The Labour Party had long attracted aspiring leaders from Africa and had developed elaborate plans before the war. Implementing them overnight with an empty treasury proved too challenging. A major military base was built in Kenya, and the African colonies came under an unprecedented degree of direct control from London. Development schemes were implemented to help solve Britain's post-war balance of payments crisis and raise African living standards. This \"new colonialism\" worked slowly, and had failures such as the Tanganyika groundnut scheme.\nElections.\nThe 1950 election gave Labour a massively reduced majority of five seats compared to the triple-digit majority of 1945. Although re-elected, the result was seen by Attlee as very disappointing, and was widely attributed to the effects of post-war austerity denting Labour's appeal to middle-class voters. With such a small majority leaving him dependent on a small number of MPs to govern, Attlee's second term was much tamer than his first. Some major reforms were nevertheless passed, particularly regarding industry in urban areas and regulations to limit air and water pollution.\nBy 1951, the Attlee government was exhausted, with several of its most senior ministers ailing or ageing, and with a lack of new ideas. Attlee's record for settling internal differences in the Labour Party fell in April 1951, when there was a damaging split over an austerity Budget brought in by the Chancellor, Hugh Gaitskell, to pay for the cost of Britain's participation in the Korean War. Aneurin Bevan resigned to protest against the new charges for \"teeth and spectacles\" in the National Health Service introduced by that Budget, and was joined in this action by several senior ministers, including the future prime minister Harold Wilson, then the president of the Board of Trade. Thus escalated a battle between the left and right wings of the Party that continues today. Finding it increasingly impossible to govern, Attlee's only chance was to call a snap election in October 1951, in the hope of achieving a more workable majority and to regain authority. The gamble failed: Labour narrowly lost to the Conservative Party, despite winning considerably more votes (achieving the largest Labour vote in electoral history). Attlee tendered his resignation as prime minister the following day, after six years and three months in office.\nReturn to opposition.\nFollowing the defeat in 1951, Attlee continued to lead the party as Leader of the Opposition. His last four years as leader were, however, widely seen as one of the Labour Party's weaker periods.\nThe period was dominated by infighting between the Labour Party's right wing, led by Hugh Gaitskell, and its left, led by Aneurin Bevan. Many Labour MPs felt that Attlee should have retired following the 1951 election and allowed a younger man to lead the party. Bevan openly called for him to stand down in the summer of 1954. One of his main reasons for staying on as leader was to frustrate the leadership ambitions of Herbert Morrison, whom Attlee disliked for both political and personal reasons. At one time, Attlee had favoured Aneurin Bevan to succeed him as leader, but this became problematic after Bevan almost irrevocably split the party.\nAttlee, now aged 72, contested the 1955 general election against Anthony Eden, which saw Labour lose 18 seats, and the Conservatives increase their majority.\nIn an interview with the \"News Chronicle\" columnist Percy Cudlipp in mid-September 1955, Attlee made clear his own thinking together with his preference for the leadership succession, stating:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Labour has nothing to gain by dwelling in the past. Nor do I think we can impress the nation by adopting a futile left-wingism. I regard myself as Left of Centre which is where a Party Leader ought to be. It is no use asking, 'What would Keir Hardie have done?' We must have at the top men brought up in the present age, not, as I was, in the Victorian Age.\nHe retired as Leader of the Labour Party on 7 December 1955, having led the party for twenty years, and on 14 December Hugh Gaitskell was elected as his successor.\nGlobal policy.\nHe was one of the signatories of the agreement to convene a convention for drafting a world constitution. As a result, for the first time in human history, a World Constituent Assembly convened to draft and adopt a Constitution for the Federation of Earth.\nAttlee was nominated for the Nobel Peace Prize in 1954 for his support of the League of Nations and the United Nations, and received further nominations in 1955 and 1964, but was unsuccessful on each occasion.\nRetirement.\nHe subsequently retired from the House of Commons and was elevated to the peerage as Earl Attlee and Viscount Prestwood on 16 December 1955, taking his seat in the House of Lords on 25 January. He believed Eden had been forced into taking a strong stand on the Suez Crisis by his backbenchers. In 1958, Attlee, along with numerous notables, established the Homosexual Law Reform Society: this campaigned for the decriminalisation of homosexual acts in private by consenting adults, a reform that was voted through Parliament nine years later. In May 1961, he travelled to Washington, D.C., to meet with President Kennedy.\nIn 1962, he spoke twice in the House of Lords against the British government's application for the UK to join the European Communities (\"Common Market\"). In his second speech delivered in November, Attlee claimed that Britain had a separate parliamentary tradition from the Continental European countries that comprised the EC. He also claimed that if Britain became a member, EC rules would prevent the British government from planning the economy and that Britain's traditional policy had been outward-looking rather than Continental.\nHe attended Winston Churchill's funeral in January 1965. He was frail by that time, and had to remain seated in the freezing cold as the coffin was carried, having tired himself out by standing at the rehearsal the previous day. He lived to see the Labour Party return to power under Harold Wilson in 1964, and also to see his old constituency of Walthamstow West fall to the Conservatives in a by-election in September 1967.\nDeath.\nAttlee died peacefully in his sleep of pneumonia, at the age of 84 at Westminster Hospital on 8 October 1967. Two thousand people attended his funeral in November, including the then-Prime Minister Harold Wilson and the Duke of Kent, representing the Queen. He was cremated and his ashes were buried at Westminster Abbey.\nUpon his death, the title passed to his son Martin Richard Attlee, 2nd Earl Attlee (1927\u20131991), who defected from Labour to the SDP in 1981. It is now held by Clement Attlee's grandson John Richard Attlee, 3rd Earl Attlee. The third earl (a member of the Conservative Party) retained his seat in the Lords as one of the hereditary peers to remain under an amendment to Labour's House of Lords Act 1999.\nAttlee's estate was sworn for probate purposes at a value of \u00a37,295, (equivalent to \u00a3 in 2023) a relatively modest sum for so prominent a figure, and only a fraction of the \u00a375,394 in his father's estate when he died in 1908.\nLegacy.\nThe quotation about Attlee, \"A modest man, but then he has so much to be modest about\", is commonly ascribed to Churchill\u2014though Churchill denied saying it, and respected Attlee's service in the War cabinet. Attlee's modesty and quiet manner hid a great deal that has only come to light with historical reappraisal. Attlee himself is said to have responded to critics with a limerick: \"There were few who thought him a starter, Many who thought themselves smarter. But he ended PM, CH and OM, an Earl and a Knight of the Garter\".\nHis leadership style of consensual government, acting as a chairman rather than a president, won him much praise from historians and politicians alike. Christopher Soames, the British Ambassador to France during the Conservative government of Edward Heath and cabinet minister under Margaret Thatcher, remarked that \"Mrs Thatcher was not really running a team. Every time you have a Prime Minister who wants to make all the decisions, it mainly leads to bad results. Attlee didn't. That's why he was so damn good\". The journalist and broadcaster Anthony Howard called him \"the greatest Prime Minister of the 20th century\".\nThatcher herself wrote in her 1995 memoirs, which charted her life from her beginnings in Grantham to her victory at the 1979 general election, that she admired Attlee, writing: \"Of Clement Attlee, however, I was an admirer. He was a serious man and a patriot. Quite contrary to the general tendency of politicians in the 1990s, he was all substance and no show\".\nAttlee's government presided over the successful transition from a wartime economy to peacetime, tackling problems of demobilisation, shortages of foreign currency, and adverse deficits in trade balances and government expenditure. Further domestic policies that he brought about included the creation of the National Health Service and the post-war welfare state, which became key to the reconstruction of post-war Britain. Attlee and his ministers did much to transform the UK into a more prosperous and egalitarian society during their time in office with reductions in poverty and a rise in the general economic security of the population.\nIn foreign affairs, he did much to assist with the post-war economic recovery of Europe. He proved a loyal ally of the US at the onset of the Cold War. Due to his style of leadership, it was not he, but Ernest Bevin who masterminded foreign policy. It was Attlee's government that decided Britain should have an independent nuclear weapons programme, and work on it began in 1947.\nBevin, Attlee's foreign secretary, famously stated that \"We've got to have it [nuclear weapons] and it's got to have a bloody Union Jack on it\". The first operational British nuclear bomb detonated in October 1952, about one year after Attlee had left office. Independent British atomic research was prompted partly by the 1946 US McMahon Act, which nullified wartime expectations of postwar US\u2013UK collaboration in nuclear research, and prohibited Americans from communicating nuclear technology even to allied countries who had participated in the wartime development of the atomic bomb. British atomic bomb research was kept secret even from some members of Attlee's own cabinet, whose loyalty or discretion seemed uncertain.\nAlthough a socialist, Attlee still believed in the British Empire of his youth. He thought of it as an institution that was a power for good in the world. Nevertheless, he saw that a large part of it needed to be self-governing. Using the Dominions of Canada, Australia, and New Zealand as a model, he continued the transformation of the empire into the modern-day British Commonwealth.\nHis greatest achievement, surpassing many of these, was perhaps the establishment of a political and economic consensus about the governance of Britain that all three major parties subscribed to for three decades, fixing the arena of political discourse until the late-1970s. In 2004, he was voted the most successful British prime minister of the 20th century by a poll of 139 academics organised by Ipsos MORI.\nA blue plaque unveiled in 1979 commemorates Attlee at 17 Monkhams Avenue, in Woodford Green in the London Borough of Redbridge.\nAttlee was elected a Fellow of the Royal Society in 1947. Attlee was awarded an Honorary Fellowship of Queen Mary College on 15 December 1948.\nIn the 1960s a new suburb near Curepipe in British Mauritius was given the name \"Cit\u00e9 Atlee\" [\"sic\"] in his honour.\nStatues.\nOn 30 November 1988, a bronze statue of Clement Attlee was unveiled by Harold Wilson (the next Labour Prime Minister after Attlee) outside Limehouse Library in Attlee's former constituency. By then Wilson was the last surviving member of Attlee's cabinet, and the unveiling of the statue would be one of the last public appearances by Wilson, who was by that point in the early stages of Alzheimer's disease; he died at the age of 79 in May 1995.\nLimehouse Library was closed in 2003, after which the statue was vandalised. The council surrounded it with protective hoarding for four years, before eventually removing it for repair and recasting in 2009. The restored statue was unveiled by Peter Mandelson in April 2011, in its new position less than a mile away at the Queen Mary University of London's Mile End campus.\nThere is also a statue of Clement Attlee in the Houses of Parliament that was erected, instead of a bust, by parliamentary vote in 1979. The sculptor was Ivor Roberts-Jones.\nPersonal life.\nAttlee met Violet Millar while on a long trip with friends to Italy in 1921. They fell in love and were soon engaged, marrying at Christ Church, Hampstead, on 10 January 1922. It was a devoted marriage, with Attlee providing protection and Violet providing a home that was an escape for Attlee from political turmoil. She died in 1964. They had four children:\nReligious views.\nAlthough his parents were devout Anglicans, with one of his brothers becoming a clergyman and one of his sisters a missionary, Attlee himself is usually regarded as an agnostic. In an interview he described himself as \"incapable of religious feeling\", saying that he believed in \"the ethics of Christianity\" but not \"the mumbo-jumbo\". When asked whether he was an agnostic, Attlee replied \"I don't know\".\nReferences.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nBibliography.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nFurther reading.\nBiographical\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nBiographies of his cabinet and associates\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nScholarly studies\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nWorks.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "5768", "revid": "635492", "url": "https://en.wikipedia.org/wiki?curid=5768", "title": "Catullus", "text": "Latin poet of the late Roman Republic (c. 84 \u2013 c. 54 BC)\nGaius Valerius Catullus (; c.\u200984\u00a0\u2013 c.\u200954 BC), known as Catullus (), was a Latin neoteric poet of the late Roman Republic. His surviving works remain widely read due to their popularity as teaching tools and because of their personal or sexual themes.\nLife.\nG\u0101ius Valerius Catullus was born to a leading equestrian family of Verona, in Cisalpine Gaul. The social prominence of his family allowed his father to entertain Julius Caesar when he was the Promagistrate (proconsul) of both Gallic provinces. In a poem, Catullus describes his happy homecoming to the family villa at Sirmio, on Lake Garda, near Verona; he also owned a villa near the resort of Tibur (modern Tivoli).\nCatullus appears to have spent most of his young adult years in Rome. His friends there included the poets Licinius Calvus and Helvius Cinna, Quintus Hortensius (son of the orator and rival of Cicero), and the biographer Cornelius Nepos, to whom Catullus dedicated a \"libellus\" of poems, the relation of which to the extant collection remains a matter of debate. He appears to have been acquainted with the poet Marcus Furius Bibaculus. A number of prominent contemporaries appear in his poetry, including Cicero, Caesar and Pompey. According to an anecdote preserved by Suetonius, Caesar did not deny that Catullus's lampoons left an indelible stain on his reputation, but when Catullus apologized, he invited the poet for dinner the very same day.\nThe \"Lesbia\" of his poems is usually identified with Clodia Metelli, a sophisticated woman from the aristocratic house of patrician family Claudii Pulchri, sister of the infamous Publius Clodius Pulcher, and wife to Quintus Caecilius Metellus Celer (consul of 60 BC). In his poems Catullus describes several stages of their relationship: initial euphoria, doubts, separation, and his wrenching feelings of loss. Clodia had several other partners; \"From the poems one can adduce no fewer than five lovers in addition to Catullus: Egnatius (poem 37), Gellius (poem 91), Quintius (poem 82), Rufus (poem 77), and Lesbius (poem 79).\" There is also some question surrounding her husband's mysterious death in 59\u00a0BC: in his speech \"Pro Caelio\" Cicero hints that he may have been poisoned. However, a sensitive and passionate Catullus could not relinquish his flame for Clodia, regardless of her obvious indifference to his desire for a deep and permanent relationship. In his poems, Catullus wavers between devout, sweltering love and bitter, scornful insults that he directs at her blatant infidelity (as demonstrated in poems 11 and 58). His passion for her is unrelenting\u2014yet it is unclear when exactly the couple split up for good. Catullus's poems about the relationship display striking depth and psychological insight.\nHe spent the year from summer 57 to summer 56\u00a0BC in Bithynia on the staff of the commander Gaius Memmius. While in the East, he traveled to the Troad to perform rites at his brother's tomb, an event recorded in a moving poem (101).\nNo ancient biography of Catullus has survived. His life has to be pieced together from scattered references to him in other ancient authors and from his poems. Thus it is uncertain when he was born and when he died. Jerome stated that he was born in 87 BC and died in Rome in his 30th year. However, Catullus's poems include references to events of 55 BC. Since the Roman consular fasti make it somewhat easy to confuse 87\u201357 BC with 84\u201354 BC, many scholars accept the dates 84\u201354 BC, supposing that his latest poems and the publication of his \"libellus\" coincided with the year of his death. Other authors suggest 52 or 51\u00a0BC as the year of the poet's death. Though upon his elder brother's death Catullus lamented that their \"whole house was buried along\" with the deceased, the existence (and prominence) of \"Valerii Catulli\" is attested in the following centuries. T. P. Wiseman argues that after the brother's death Catullus could have married, and that, in this case, the later \"Valerii Catulli\" may have been his descendants.\nPoetry.\nSources and organization.\nCatullus's poems have been preserved in an anthology of 116 \"carmina\" (the actual number of poems may slightly vary in various editions), which can be divided into three parts according to their form: approximately sixty short poems in varying meters, called \"polymetra\", nine longer poems, and forty-eight epigrams in elegiac couplets. Each of these three parts \u2013 approximately 860 (or more), 1136, and 330 lines respectively \u2013 would fit onto a single scroll.\nThere is no scholarly consensus on whether Catullus himself arranged the order of the poems. The longer poems differ from the \"polymetra\" and the epigrams not only in length but also in their subjects: several of them are based on the theme of marriage. The longest (64) of 408 lines, contains two myths (the abandonment of Ariadne and the marriage of Peleus and Thetis), one story included inside the other.\nThe \"polymetra\" and the epigrams can be divided into four major thematic groups (ignoring a rather large number of poems that elude such categorization):\nAbove all other qualities, Catullus seems to have valued , or charm, in his acquaintances, a theme which he explores in a number of his poems.\nIntellectual influences.\nCatullus's poetry was influenced by the innovative poetry of the Hellenistic Age, and especially by Callimachus and the Alexandrian school, which had propagated a new style of poetry that deliberately turned away from the classical epic poetry in the tradition of Homer. Cicero called these local innovators \"neoteroi\" () or \"moderns\" (in Latin \"poetae novi\" or 'new poets'), in that they cast off the heroic model handed down from Ennius in order to strike new ground and ring a contemporary note. Catullus and Callimachus did not describe the feats of ancient heroes and gods (except perhaps in re-evaluating and predominantly artistic circumstances, e.g. poem 64), focusing instead on small-scale personal themes. Although these poems sometimes seem quite superficial and their subjects often are mere everyday concerns, they are accomplished works of art. Catullus described his work as \"expolitum\", or polished, to show that the language he used was very carefully and artistically composed.\nCatullus was also an admirer of Sappho, a female poet of the seventh century BC. Catullus 51 partly translates, partly imitates, and transforms Sappho 31. Some hypothesize that 61 and 62 were perhaps inspired by lost works of Sappho but this is purely speculative. Both of the latter are \"epithalamia\", a form of laudatory or erotic wedding-poetry that Sappho was famous for. Catullus twice used a meter that Sappho was known for, called the Sapphic stanza, in poems 11 and 51, perhaps prompting his successor Horace's interest in the form.\nCatullus, as was common to his era, was greatly influenced by stories from Greek and Roman myth. His longer poems\u2014such as 63, 64, 65, 66, and 68\u2014allude to mythology in various ways. Some stories he refers to are the wedding of Peleus and Thetis, the departure of the Argonauts, Theseus and the Minotaur, Ariadne's abandonment, Tereus and Procne, as well as Protesilaus and Laodamia.\nStyle.\nCatullus wrote in many different meters including hendecasyllabic verse and elegiac couplets (common in love poetry). A great part of his poetry shows strong and occasionally wild emotions, especially in regard to Lesbia (e.g., poems 5 and 7). His love poems are very emotional and ardent, and are relatable to this day. Catullus describes his Lesbia as having multiple suitors and often showing little affection towards him. He also demonstrates a great sense of humour such as in Catullus 13.\nMusical settings.\nThe Hungarian-born British composer M\u00e1ty\u00e1s Seiber set Catullus 31 (\"Sirmio\") for unaccompanied mixed chorus (1956). The American composer Ned Rorem\u2019s song \u201cCatullus: On the Burial of His Brother\u201d sets poem 101 for voice and piano.\nPulitzer winning American composer Dominick Argento set verses of Catullus for mixed chorus and percussion in 1981. \"I Hate and I Love\" presents about 50 lines of text over eight movements using the composer's own translation into English. The Dale Warland Singers, who commissioned the work, recorded it, as did Robert Shaw with his Festival Chorus.\n\"Catullus Dreams\" (2011) is a song cycle by David Glaser set to texts of Catullus, scored for soprano and eight instruments; it premiered at Symphony Space in New York by soprano Linda Larson and Sequitur Ensemble. is a song cycle arranged from 17 of Catullus's poems by American composer Michael Linton. The cycle was recorded in December 2013 and premiered at Carnegie Hall's Weill Recital Hall in March 2014 by French baritone Edwin Crossley-Mercer and pianist Jason Paul Peterson.\nThomas Campion also wrote a lute-song entitled \"My Sweetest Lesbia\" dating from 1601 using his own translation of the first six lines of Catullus 5 followed by two verses of his own; the translation by Richard Crashaw was set to music in a four-part glee by Samuel Webbe Jr. It was also set to music, in a three-part glee by John Stafford Smith.\nCatullus 5, the love poem , in the translation by Ben Jonson, was set to music in 1606, (lute accompanied song) by Alfonso Ferrabosco the younger. Dutch composer Bertha Tideman-Wijers used Catullus's text for her composition \"Variations on Valerius's \"Where that one already turns or turns\"\" (1929). The Icelandic composer J\u00f3hann J\u00f3hannsson set Catullus 85 to music; entitled , the song is found on J\u00f3hannsson's album \"Englab\u00f6rn\", and is sung through a vocoder, and the music is played by a string quartet and piano. \"Catulli Carmina\" is a cantata by Carl Orff dating from 1943 that sets texts from Catullus to music. Finnish jazz singer Reine Rim\u00f3n has recorded poems of Catullus set to standard jazz tunes.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "5769", "revid": "38455317", "url": "https://en.wikipedia.org/wiki?curid=5769", "title": "C. S. Forester", "text": "British novelist (1899\u20131966)\nCecil Louis Troughton Smith (27 August 1899 \u2013 2 April 1966), best known by his pen name C.S. \"(Cecil Scott)\" Forester, was an English novelist known for writing tales of naval warfare, such as the 12-book Horatio Hornblower series depicting a Royal Navy officer during the Napoleonic Wars. \nThe Hornblower novels \"A Ship of the Line\" and \"Flying Colours\" were jointly awarded the 1938 James Tait Black Memorial Prize for fiction. Other works include \"The African Queen\" and \"The Good Shepherd\", both of which were later adapted as movies. \nDuring World War II, he moved to the United States where he worked for the British Ministry of Information, writing propaganda for the Allied cause. He eventually settled in Fullerton, California, where he died in 1966 of complications arising from a stroke.\nEarly years.\nForester was born in Cairo on 27 August 1899, fifth and youngest child of George Foster Smith and his wife Sarah Troughton. His father was an English teacher in a local school set up to give upper-class Egyptian boys an English education. His parents separated when he was young, and his mother took him to London, where he was educated at Alleyn's School and Dulwich College. He began to study medicine at Guy's Hospital, but left without completing his degree. He was somewhat athletic, wore glasses, and had a slender physique. He failed his Army physical and was told that there was no chance that he would be accepted. He began writing seriously, using his pen name, in around 1921.\nSecond World War.\nDuring the Second World War, Forester moved to Berkeley, California, where he worked for the British Ministry of Information and wrote propaganda to encourage the U.S. to join the Allies.\nIn 1942, he met the young British diplomat Roald Dahl in Washington, D.C., and encouraged him to write about his experiences in the Royal Air Force. According to Dahl's autobiography, \"Lucky Break\", Forester asked him about his experiences as a fighter pilot, and this prompted Dahl to write his first story, \"A Piece of Cake\".\nLiterary career.\nForester wrote many novels, but he is best known for the 12-book Horatio Hornblower series about an officer in the Royal Navy during the Napoleonic Wars. He began the series with Hornblower a captain in the first novel, \"The Happy Return\", which was published in 1937, but demand for more stories led him to fill in Hornblower's life story, and he wrote novels detailing his rise from the rank of midshipman. The last completed novel was published in 1962. Hornblower's fictional adventures were based on real events, but Forester wrote the body of the works carefully to avoid entanglements with real world history, so that Hornblower is always off on another mission when a great naval battle occurs during the Napoleonic Wars.\nForester's other novels include \"The African Queen\" (1935) and \"The General\" (1936); two novels about the Peninsular War, \"Death to the French\" in 1932 later on (published in the United States as \"Rifleman Dodd\") and \"The Gun\" (filmed as \"The Pride and the Passion\" in 1957); and seafaring stories that do not involve Hornblower, such as \"Brown on Resolution\" (1929), \"The Captain from Connecticut\" (1941), \"The Ship\" (1943), and \"Hunting the Bismarck\" (1959), which was used as the basis of the screenplay for the film \"Sink the Bismarck!\" (1960). Several of his novels have been filmed, including \"The African Queen\" (1951), directed by John Huston. Forester is also credited as story writer on several films not based on his published novels, including \"Commandos Strike at Dawn\" (1942).\nForester also wrote several volumes of short stories set during the Second World War. Those in \"The Nightmare\" (1954) were based on events in Nazi Germany, ending at the Nuremberg trials. The linked stories in \"The Man in the Yellow Raft\" (1969) follow the career of the destroyer USS \"Boon\", while many of the stories in \"Gold from Crete\" (1971) follow the destroyer HMS \"Apache\". The last of the stories in \"Gold from Crete\" is \"If Hitler Had Invaded England\", which offers an imagined sequence of events starting with Hitler's attempt to implement Operation Sea Lion and culminating in the early military defeat of Nazi Germany in the summer of 1941.\nHis non-fiction works about seafaring include \"The Age of Fighting Sail\" (1956), an account of the sea battles between Great Britain and the United States in the War of 1812.\nForester also published the crime novels \"Payment Deferred\" (1926) and \"Plain Murder\" (1930), as well as two children's books. \"Poo-Poo and the Dragons\" (1942) was created as a series of stories told to his son George to encourage him to finish his meals. George had mild food allergies and needed encouragement to eat. \"The Barbary Pirates\" (1953) is a children's history of early 19th-century pirates.\nForester appeared as a contestant on the television quiz programme \"You Bet Your Life\", hosted by Groucho Marx, in an episode broadcast on 1 November 1956.\nA previously unknown novel of Forester's, \"The Pursued\", was discovered in 2003 and published by Penguin Classics on 3 November 2011.\nPersonal life.\nForester married Kathleen Belcher in 1926. They had two sons, John, born in 1929, and George, born in 1933. Forrester moved to Berkeley, CA in 1940 to further his career in Hollywood, commuting back and forth from Los Angeles. He had previously commuted back and forth from London since the production of \"Payment Deferred\" in 1932, but felt exhausted from the culture in LA and felt he needed even the little distance Berkely provided. He was striken with arteriosclerosis while at sea on a research trip aboard the USS \"Tennessee\" (BB-43) in 1943 which would leave him crippled. Belcher and Forester divorced in 1945.\nKathleen Belcher's great\u2011uncle was Capt. Edward Belcher, RN, who achieved renown as a hydrographer and explorer. After his retirement, Belcher devoted much of his time to writing. After penning biographical material, he turned his hand to naval fiction, inventing a character called \"Horatio Howard Brenton\", and attributing great feats and adventures to him. It is possible that Forester found some inspiration in these stories for his own \"Horatio Hornblower\".\nIn 1947 Forester married another childhood friend, Dorothy Foster, as Forester's fortunes prospered from the successful releases of \"The African Queen\" and \"Captain Horatio Hornblower\", the later which then Princess Elizabeth and Princess Margaret visited the set of, and Princess Margaret attended the London premiere. Queen Elizabeth offered to honor Forester with a Commander of the British Empire in her 1953 Coronation Honours, however he turned it down in the hope of a knighthood.\nForester moved into his son John Forester's Fullerton, California home in 1959, suffered a stroke in 1964 which affected his ability to continue writing, and died on 2 April 1966.\nJohn Forester wrote a two-volume biography of his father, including many elements of Forester's life which became clear to his son only after his father's death.\nFilm adaptations.\nIn addition to providing the source material for numerous adaptations (not all of which are listed below), Forester was also credited as \"adapted for the screen by\" for \"Captain Horatio Hornblower\".\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "5770", "revid": "37298639", "url": "https://en.wikipedia.org/wiki?curid=5770", "title": "List of telephone country codes", "text": "Telephone country codes are telephone number prefixes for reaching subscribers in foreign countries or areas by international direct dialing (IDD). Country codes are defined by the International Telecommunication Union (ITU) in ITU-T standards E.123 and E.164 and constitute the international telephone numbering plan of the public switched telephone network (PSTN) and other networks.\nOverview.\nThis table lists in its first column the initial digits of the country code shared by each country in each row, which is arranged in columns for the last digit (x). When three-digit codes share a common leading pair, the shared prefix is marked by an arrow, ( \u2199 ) pointing down and left to the three-digit codes. Unassigned codes are denoted by a dash (\u2014). Countries are identified by ISO 3166-1 alpha-2 country codes; codes for non-geographic services are denoted by two asterisks (**).\nList by world numbering zones.\nZone 1: North American Numbering Plan (NANP).\nNorth American Numbering Plan members are assigned three-digit numbering plan area (NPA) codes under the common country code \"1\", shown in the format \"1\u00a0(NPA)\". Within an NPA, all telephone numbers have seven digits.\nZones 3 and 4: Mostly Europe.\nThe larger countries were assigned two-digit codes starting in 1960. Subsequently, beginning in 1964, smaller countries were assigned three-digit codes, which also has been the practice since the 1980s.\nZone 7: Russia and neighboring regions.\nFormerly assigned to the Soviet Union until its dissolution in 1991.\nZone 9: West, Central, and South Asia.\n Gilgit Baltistan\nAlphabetical order.\n&lt;templatestyles src=\"template:sticky header/styles.css\"/&gt;\nLocations without country code.\nAntarctica.\nIn Antarctica, telecommunication services are generally provided by the parent country of each base, though some bases have service (and numbering) through more than one country:\n&lt;templatestyles src=\"template:sticky header/styles.css\"/&gt;&lt;templatestyles src=\"Template:Table alignment/tables.css\" /&gt;\nOther places with no country codes in use, although a code may be reserved:\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "5771", "revid": "7320285", "url": "https://en.wikipedia.org/wiki?curid=5771", "title": "Christopher Marlowe", "text": "16th-century English dramatist, poet, and translator\nChristopher Marlowe ( ; baptised 26 February 1564\u00a0\u2013 30 May 1593), also known as Kit Marlowe, was an English playwright, poet, and translator of the Elizabethan era. Marlowe is among the most famous of the Elizabethan playwrights. Based upon the \"many imitations\" of his play \"Tamburlaine\", modern scholars consider him to have been the foremost dramatist in London in the years just before his mysterious early death. Some scholars also believe that he greatly influenced William Shakespeare, who was baptised in the same year as Marlowe and later succeeded him as the preeminent Elizabethan playwright. Marlowe was the first to achieve critical reputation for his use of blank verse, which became the standard for the era. His plays are distinguished by their overreaching protagonists. Themes found within Marlowe's literary works have been noted as humanistic with realistic emotions, which some scholars find difficult to reconcile with Marlowe's \"anti-intellectualism\" and his catering to the prurient tastes of his Elizabethan audiences for generous displays of extreme physical violence, cruelty, and bloodshed.\nEvents in Marlowe's life were sometimes as extreme as those found in his plays. Differing sensational reports of Marlowe's death in 1593 abounded after the event and are contested by scholars today owing to a lack of good documentation. There have been many conjectures as to the nature and reason for his death, including a vicious bar-room fight, blasphemous libel against the church, homosexual intrigue, betrayal by another playwright, and espionage from the highest level: the Privy Council of Elizabeth I. An official coroner's account of Marlowe's death was discovered only in 1925, and it did little to persuade all scholars that it told the whole story, nor did it eliminate the uncertainties present in his biography.\nEarly life.\nChristopher Marlowe, the second of nine children, and oldest child after the death of his sister Mary in 1568, was born to Canterbury shoemaker John Marlowe and his wife Katherine, daughter of William Arthur of Dover. He was baptised at St George's Church, Canterbury, on 26 February 1564 (1563 in the old style dates in use at the time, which placed the new year on 25 March). Marlowe's birth was likely to have been a few days before, making him about two months older than William Shakespeare, who was baptised on 26 April 1564 in Stratford-upon-Avon.\nBy age 14, Marlowe was a pupil at The King's School, Canterbury on a scholarship and two years later a student at Corpus Christi College, Cambridge, where he also studied through a scholarship with expectation that he would become an Anglican clergyman. Instead, he received his Bachelor of Arts degree in 1584. Marlowe mastered Latin during his schooling, reading and translating the works of Ovid. In 1587, the university hesitated to award his Master of Arts degree because of a rumour that he intended to go to the English seminary at Rheims in northern France, presumably to prepare for ordination as a Roman Catholic priest. If true, such an action on his part would have been a direct violation of royal edict issued by Queen Elizabeth I in 1585 criminalising any attempt by an English citizen to be ordained in the Roman Catholic Church.\nLarge-scale violence between Protestants and Catholics on the European continent has been cited by scholars as the impetus for the Protestant English Queen's defensive anti-Catholic laws issued from 1581 until her death in 1603. Despite the dire implications for Marlowe, his degree was awarded on schedule when the Privy Council intervened on his behalf, commending him for his \"faithful dealing\" and \"good service\" to the Queen. The nature of Marlowe's service was not specified by the council, but its letter to the Cambridge authorities has provoked much speculation by modern scholars, notably the theory that Marlowe was operating as a secret agent for Privy Council member Sir Francis Walsingham. The only surviving evidence of the Privy Council's correspondence is found in their minutes, the letter being lost. There is no mention of espionage in the minutes, but its summation of the lost Privy Council letter is vague in meaning, stating that \"it was not Her Majesties pleasure\" that persons employed as Marlowe had been \"in matters touching the benefit of his country should be defamed by those who are ignorant in th'affaires he went about.\" Scholars agree the vague wording was typically used to protect government agents, but they continue to debate what the \"matters touching the benefit of his country\" actually were in Marlowe's case and how they affected the 23-year-old writer as he began his literary career in 1587.\nAdult life and legend.\nLittle is known about Marlowe's adult life. All available evidence, other than what can be deduced from his literary works, is found in legal records and other official documents. Writers of fiction and non-fiction have speculated about his professional activities, private life, and character. Marlowe has been described as a spy, a brawler, and a heretic, as well as a \"magician\", \"duellist\", \"tobacco-user\", \"counterfeiter\" and \"rakehell\". While J. A. Downie and Constance Kuriyama have argued against the more lurid speculations, J. B. Steane remarked, \"it seems absurd to dismiss all of these Elizabethan rumours and accusations as 'the Marlowe myth'\". Much has been written on his brief adult life, including speculation of: his involvement in royally sanctioned espionage; his vocal declaration of atheism; his (possibly same-sex) sexual interests; and the puzzling circumstances surrounding his death.\nSpying.\nMarlowe is alleged to have been a government spy. Park Honan and Charles Nicholl speculate that this was the case and suggest that Marlowe's recruitment took place when he was at Cambridge. In 1587, when the Privy Council ordered the University of Cambridge to award Marlowe his degree as Master of Arts, it denied rumours that he intended to go to the English Catholic college in Rheims, saying instead that he had been engaged in unspecified \"affaires\" on \"matters touching the benefit of his country\". Surviving college records from the period also indicate that, in the academic year 1584\u20131585, Marlowe had a series of unusually lengthy absences from the university which violated university regulations. Surviving college buttery accounts, which record student purchases for personal provisions, show that Marlowe began spending lavishly on food and drink during the periods he was in attendance; the amount was more than he could have afforded on his known scholarship income.\nIt has been speculated that Marlowe was the \"Morley\" who was tutor to Arbella Stuart in 1589. This possibility was first raised in a \"Times Literary Supplement\" letter by E. St John Brooks in 1937; in a letter to \"Notes and Queries\", John Baker has added that only Marlowe could have been Arbella's tutor owing to the absence of any other known \"Morley\" from the period with an MA and not otherwise occupied. If Marlowe was Arbella's tutor, it might indicate that he was there as a spy, since Arbella, niece of Mary, Queen of Scots, and cousin of James VI of Scotland, later James I of England, was at the time a strong candidate for the succession to Elizabeth's throne. Frederick S. Boas dismisses the possibility of this identification, based on surviving legal records which document Marlowe's \"residence in London between September and December 1589\". Marlowe had been party to a fatal quarrel involving his neighbours and the poet Thomas Watson in Norton Folgate and was held in Newgate Prison for a fortnight. In fact, the quarrel and his arrest occurred on 18 September, he was released on bail on 1 October and he had to attend court, where he was acquitted on 3 December, but there is no record of where he was for the intervening two months.\nIn 1592 Marlowe was arrested in the English garrison town of Flushing (Vlissingen) in the Netherlands, for alleged involvement in the counterfeiting of coins, presumably related to the activities of seditious Catholics. He was sent to the Lord Treasurer (Burghley), but no charge or imprisonment resulted. This arrest may have disrupted another of Marlowe's spying missions, perhaps by giving the resulting coinage to the Catholic cause. He was to infiltrate the followers of the active Catholic plotter William Stanley and report back to Burghley.\nPhilosophy.\nMarlowe was reputed to be an atheist, which held the dangerous implication of being an enemy of God and, by association, the state. With the rise of public fears concerning The School of Night, or \"School of Atheism\" in the late 16th century, accusations of atheism were closely associated with disloyalty to the Protestant monarchy of England.\nSome modern historians consider that Marlowe's professed atheism, as with his supposed Catholicism, may have been no more than a sham to further his work as a government spy. Contemporary evidence comes from Marlowe's accuser in Flushing, an informer called Richard Baines. The governor of Flushing had reported that each of the men had \"of malice\" accused the other of instigating the counterfeiting and of intending to go over to the Catholic \"enemy\"; such an action was considered atheistic by the Church of England. Following Marlowe's arrest in 1593, Baines submitted to the authorities a \"note containing the opinion of one Christopher Marly concerning his damnable judgment of religion, and scorn of God's word\". Baines attributes to Marlowe a total of eighteen items which \"scoff at the pretensions of the Old and New Testament\" such as, \"Christ was a bastard and his mother dishonest [unchaste]\", \"the woman of Samaria and her sister were whores and that Christ knew them dishonestly\", \"St John the Evangelist was bedfellow to Christ and leaned always in his bosom\" (cf. John 13:23\u201325) and \"that he used him as the sinners of Sodom\". He also implied that Marlowe had Catholic sympathies. Other passages are merely sceptical in tone: \"he persuades men to atheism, willing them not to be afraid of bugbears and hobgoblins\". The final paragraph of Baines's document reads:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nSimilar examples of Marlowe's statements were given by Thomas Kyd after his imprisonment and possible torture (see above); Kyd and Baines connect Marlowe with mathematician Thomas Harriot's and Sir Walter Raleigh's circle. Another document claimed about that time that \"one Marlowe is able to show more sound reasons for Atheism than any divine in England is able to give to prove divinity, and that ... he hath read the Atheist lecture to Sir Walter Raleigh and others\".\nSome critics believe that Marlowe sought to disseminate these views in his work and that he identified with his rebellious and iconoclastic protagonists. Plays had to be approved by the Master of the Revels before they could be performed and the censorship of publications was under the control of the Archbishop of Canterbury. Presumably these authorities did not consider any of Marlowe's works to be unacceptable other than the \"Amores\".\nSexuality.\nIt has been claimed that Marlowe was homosexual. Some scholars argue that the identification of an Elizabethan as such in the modern sense is \"anachronistic,\" saying that for the Elizabethans the terms were more likely to have been applied to homoerotic affections or sexual acts rather than to what we currently understand as a settled sexual orientation or personal role identity. Other scholars argue that the evidence is inconclusive and that the reports of Marlowe's homosexuality may be rumours produced after his death. Richard Baines reported Marlowe as saying: \"all they that love not Tobacco &amp; Boies were fools\". David Bevington and Eric C. Rasmussen describe Baines's evidence as \"unreliable testimony\" and \"[t]hese and other testimonials need to be discounted for their exaggeration and for their having been produced under legal circumstances we would now regard as a witch-hunt\".\nLiterary scholar J. B. Steane considered there to be \"no evidence for Marlowe's homosexuality at all\". Other scholars point to the frequency with which Marlowe explores homosexual themes in his writing: in \"Hero and Leander\", Marlowe writes of the male youth Leander: \"in his looks were all that men desire...\" \"Edward the Second\" contains the following passage enumerating homosexual relationships:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;&lt;poem&gt;\nThe mightiest kings have had their minions;\nGreat Alexander loved Hephaestion,\nThe conquering Hercules for Hylas wept;\nAnd for Patroclus, stern Achilles drooped.\nAnd not kings only, but the wisest men:\nThe Roman Tully loved Octavius,\nGrave Socrates, wild Alcibiades.\n&lt;/poem&gt;\nMarlowe wrote the only play about the life of Edward II up to his time, taking the humanist literary discussion of male sexuality much further than his contemporaries. The play was extremely bold, dealing with a star-crossed love story between Edward II and Piers Gaveston. Though it was a common practice at the time to reveal characters as homosexual to give audiences reason to suspect them as culprits in a crime, Christopher Marlowe's Edward II is portrayed as a sympathetic character. The decision to start the play \"Dido, Queen of Carthage\" with a homoerotic scene between Jupiter and Ganymede that bears no connection to the subsequent plot has long puzzled scholars.\nArrest and death.\nIn early May 1593, several bills were posted about London threatening the Protestant refugees from France and the Netherlands who had settled in the city. One of these, the \"Dutch church libel\", written in rhymed iambic pentameter, contained allusions to several of Marlowe's plays and was signed, \"Tamburlaine\". On 11 May 1593 the Privy Council ordered the arrest of those responsible for the libels. The next day, Marlowe's colleague Thomas Kyd was arrested and when his lodgings were searched, a three-page fragment of a heretical tract was found. On being charged with atheism and tortured, Kyd declared the document to be Marlowe's, and to have been shuffled together with his own papers when they were writing together in the same chamber two years previously. In a second letter, Kyd said they had both been working for an aristocratic patron (probably Ferdinando Stanley), and he described Marlowe as blasphemous, disorderly, holding treasonous opinions, being an irreligious reprobate and \"intemperate &amp; of a cruel hart\". \nA warrant for Marlowe's arrest was issued on 18 May 1593, when the Privy Council apparently knew that he might be found staying with Thomas Walsingham, whose father was a first cousin of the late Sir Francis Walsingham, Elizabeth's principal secretary in the 1580s and a man more deeply involved in state espionage than any other member of the Privy Council. Marlowe duly presented himself on 20 May 1593 but there apparently being no Privy Council meeting on that day, was instructed to \"give his daily attendance on their Lordships, until he shall be licensed to the contrary\". On Wednesday, 30 May 1593, Marlowe was killed.\nVarious accounts of Marlowe's death were current over the next few years. In his \"Palladis Tamia\", published in 1598, Francis Meres says Marlowe was \"stabbed to death by a bawdy serving-man, a rival of his in his lewd love\" as punishment for his \"epicurism and atheism\". In 1917, in the \"Dictionary of National Biography\", Sir Sidney Lee wrote, on slender evidence, that Marlowe was killed in a drunken fight. His claim was not much at variance with the official account, which came to light only in 1925, when the scholar Leslie Hotson discovered the coroner's report of the inquest on Marlowe's death, held two days later on Friday 1 June 1593, by the Coroner of the Queen's Household, William Danby. Marlowe had spent all day in a house in Deptford, owned by the widow Eleanor Bull, with three men: Ingram Frizer, Nicholas Skeres and Robert Poley. All three had been employed by one or other of the Walsinghams. Skeres and Poley had helped snare the conspirators in the Babington plot, and Frizer was a servant to Thomas Walsingham, probably acting as a financial or business agent, as he was for Walsingham's wife Audrey a few years later. These witnesses testified that Frizer and Marlowe had argued over payment of the bill (now famously known as the \"Reckoning\"), exchanging \"divers malicious words\", while Frizer was sitting at a table between the other two and Marlowe was lying behind him on a couch. Marlowe snatched Frizer's dagger and wounded him on the head. According to the coroner's report, in the ensuing struggle Marlowe was stabbed above the right eye, killing him instantly. The jury concluded that Frizer acted in self-defence and within a month he was pardoned. Marlowe was buried in an unmarked grave in the churchyard of St. Nicholas, Deptford, immediately after the inquest, on 1 June 1593.\nThe complete text of the inquest report was published by Leslie Hotson in his book, \"The Death of Christopher Marlowe\", in the introduction to which Professor George Lyman Kittredge wrote: \"The mystery of Marlowe's death, heretofore involved in a cloud of contradictory gossip and irresponsible guess-work, is now cleared up for good and all on the authority of public records of complete authenticity and gratifying fullness\". However, this confidence proved to be fairly short-lived. Hotson had considered the possibility that the witnesses had \"concocted a lying account of Marlowe's behaviour, to which they swore at the inquest, and with which they deceived the jury\", but decided against that scenario. Others began to suspect that this theory was indeed the case. Writing to the \"Times Literary Supplement\" shortly after the book's publication, Eug\u00e9nie de Kalb disputed that the struggle and outcome as described were even possible, and Samuel A. Tannenbaum insisted the following year that such a wound could not have possibly resulted in instant death, as had been claimed. Even Marlowe's biographer John Bakeless acknowledged that \"some scholars have been inclined to question the truthfulness of the coroner's report. There is something queer about the whole episode\", and said that Hotson's discovery \"raises almost as many questions as it answers\". It has also been discovered more recently that the apparent absence of a local county coroner to accompany the Coroner of the Queen's Household would, if noticed, have made the inquest null and void.\nOne of the main reasons for doubting the truth of the inquest concerns the reliability of Marlowe's companions as witnesses. As an \"agent provocateur\" for the late Sir Francis Walsingham, Robert Poley was a consummate liar, the \"very genius of the Elizabethan underworld\", and was on record as saying \"I will swear and forswear myself, rather than I will accuse myself to do me any harm\". The other witness, Nicholas Skeres, had for many years acted as a confidence trickster, drawing young men into the clutches of people involved in the money-lending racket, including Marlowe's apparent killer, Ingram Frizer, with whom he was engaged in such a swindle. Despite their being referred to as \"generosi\" (gentlemen) in the inquest report, the witnesses were professional liars. Some biographers, such as Kuriyama and Downie, take the inquest to be a true account of what occurred, but in trying to explain what really happened if the account was not true, others have come up with a variety of murder theories:\nSince there are only written documents on which to base any conclusions, and since it is probable that the most crucial information about his death was never committed to paper, it is unlikely that the full circumstances of Marlowe's death will ever be known.\nReputation among contemporary writers.\n Ben Jonson, leading satirist of the Elizabethan and Jacobean eras, was one of the first to acknowledge Marlowe for the power of his dramatic verse.\nFor his contemporaries in the literary world, Marlowe was above all an admired and influential artist. Within weeks of his death, George Peele remembered him as \"Marley, the Muses' darling\"; Michael Drayton noted that he \"Had in him those brave translunary things / That the first poets had\" and Ben Jonson even wrote of \"Marlowe's mighty line\". Thomas Nashe wrote warmly of his friend, \"poor deceased Kit Marlowe,\" as did the publisher Edward Blount in his dedication of \"Hero and Leander\" to Sir Thomas Walsingham. Among the few contemporary dramatists to say anything negative about Marlowe was the anonymous author of the Cambridge University play \"The Return from Parnassus\" (1598) who wrote, \"Pity it is that wit so ill should dwell, / Wit lent from heaven, but vices sent from hell\".\nThe most famous tribute to Marlowe was paid by Shakespeare in \"As You Like It\", where he not only quotes a line from \"Hero and Leander\" (\"Dead Shepherd, now I find thy saw of might, 'Who ever lov'd that lov'd not at first sight?'\") but also gives to the clown Touchstone the words \"When a man's verses cannot be understood, nor a man's good wit seconded with the forward child, understanding, it strikes a man more dead than a great reckoning in a little room.\" This appears to be a reference to Marlowe's murder which involved a fight over the \"reckoning,\" the bill, as well as to a line in Marlowe's \"Jew of Malta\", \"Infinite riches in a little room.\"\n The influence of Marlowe upon William Shakespeare is evidenced by the Marlovian themes and other allusions to Marlowe found in Shakespeare's plays and sonnets.\nShakespeare was much influenced by Marlowe in his work, as can be seen in the use of Marlovian themes in \"Antony and Cleopatra\", \"The Merchant of Venice\", \"Richard II\" and \"Macbeth\" (\"Dido\", \"Jew of Malta\", \"Edward II\" and \"Doctor Faustus\", respectively). In \"Hamlet\", after meeting with the travelling actors, Hamlet requests the Player perform a speech about the Trojan War, which at 2.2.429\u2013432 has an echo of Marlowe's \"Dido, Queen of Carthage\". In \"Love's Labour's Lost\" Shakespeare brings on a character \"Marcade\" (three syllables) in conscious acknowledgement of Marlowe's character \"Mercury\", also attending the King of Navarre, in \"Massacre at Paris\". The significance, to those of Shakespeare's audience who were familiar with \"Hero and Leander\", was Marlowe's identification of himself with the god Mercury.\nShakespeare authorship theory.\nAn fringe theory has arisen about the notion that Marlowe faked his death and then continued to write under the assumed name of William Shakespeare. Academic consensus rejects alternative candidates for authorship of Shakespeare's plays and sonnets, including Marlowe.\nLiterary career.\n Edward Alleyn, lead actor of Lord Strange's Men was possibly the first to play the title characters in \"Doctor Faustus\", \"Tamburlaine\", and \"The Jew of Malta\".\nPlays.\nSix dramas have been attributed to the authorship of Christopher Marlowe either alone or in collaboration with other writers, with varying degrees of evidence. The writing sequence or chronology of these plays is mostly unknown and is offered here with any dates and evidence known. Among the little available information, \"Dido\" is believed to be the first Marlowe play performed, while \"Tamburlaine\" was first to be performed on a regular commercial stage in London in 1587. Believed by many scholars to be Marlowe's greatest success, \"Tamburlaine\" was the first English play written in blank verse and, with Thomas Kyd's \"The Spanish Tragedy\", is generally considered the beginning of the mature phase of the Elizabethan theatre.\nThe play \"Lust's Dominion\" was attributed to Marlowe upon its initial publication in 1657, though scholars and critics have almost unanimously rejected the attribution. He may also have written or co-written \"Arden of Faversham\".\n Ferdinando Stanley, 5th Earl of Derby, aka \"Ferdinando, Lord Straunge,\" was patron of some of Marlowe's early plays as performed by Lord Strange's Men.\nPoetry and translations.\nPublication and responses to the poetry and translations credited to Marlowe primarily occurred posthumously, including:\nCollaborations.\nModern scholars still look for evidence of collaborations between Marlowe and other writers. In 2016, one publisher was the first to endorse the scholarly claim of a collaboration between Marlowe and the playwright William Shakespeare:\nContemporary reception.\nMarlowe's plays were enormously successful, possibly because of the imposing stage presence of his lead actor, Edward Alleyn. Alleyn was unusually tall for the time and the haughty roles of Tamburlaine, Faustus and Barabas were probably written for him. Marlowe's plays were the foundation of the repertoire of Alleyn's company, the Admiral's Men, throughout the 1590s. One of Marlowe's poetry translations did not fare as well. In 1599, Marlowe's translation of Ovid was banned and copies were publicly burned as part of Archbishop Whitgift's crackdown on offensive material.\nChronology of dramatic works.\n\"Dido, Queen of Carthage\" (c.\u20091585\u20131587).\nFirst official record 1594\nFirst published 1594; posthumously\nFirst recorded performance between 1587 and 1593 by the Children of the Chapel, a company of boy actors in London.\nSignificance This play is believed by many scholars to be the first play by Christopher Marlowe to be performed.\nAttribution The title page attributes the play to Marlowe and Thomas Nashe, yet some scholars question how much of a contribution Nashe made to the play.\nEvidence No manuscripts by Marlowe exist for this play.\n\"Tamburlaine, Part I\" (c.\u20091587); \"Part II\" (c.\u20091587\u20131588).\nFirst official record 1587, Part I\nFirst published 1590, Parts I and II in one octavo, London. No author named.\nFirst recorded performance 1587, Part I, by the Admiral's Men, London.\nSignificance \"Tamburlaine\" is the first example of blank verse used in the dramatic literature of the Early Modern English theatre.\nAttribution Author name is missing from first printing in 1590. Attribution of this work by scholars to Marlowe is based upon comparison to his other verified works. Passages and character development in \"Tamburlane\" are similar to many other Marlowe works.\nEvidence No manuscripts by Marlowe exist for this play. Parts I and II were entered into the Stationers' Register on 14 August 1590. The two parts were published together by the London printer, Richard Jones, in 1590; a second edition in 1592, and a third in 1597. The 1597 edition of the two parts were published separately in quarto by Edward White; part I in 1605, and part II in 1606.\n\"The Jew of Malta\" (c.\u20091589\u20131590).\nFirst official record 1592\nFirst published 1592; earliest extant edition, 1633\nFirst recorded performance 26 February 1592, by Lord Strange's acting company.\nSignificance The performances of the play were a success and it remained popular for the next fifty years. This play helps to establish the strong theme of \"anti-authoritarianism\" that is found throughout Marlowe's works.\nEvidence No manuscripts by Marlowe exist for this play. The play was entered in the Stationers' Register on 17 May 1594 but the earliest surviving printed edition is from 1633.\n\"Doctor Faustus\" (c.\u20091588\u20131592).\nFirst official record 1594\u20131597\nFirst published 1601, no extant copy; first extant copy, 1604 (A text) quarto; 1616 (B text) quarto.\nFirst recorded performance 1594\u20131597; 24 revival performances occurred between these years by the Lord Admiral's Company, Rose Theatre, London; earlier performances probably occurred around 1589 by the same company.\nSignificance This is the first dramatised version of the Faust legend of a scholar's dealing with the devil. Marlowe deviates from earlier versions of \"The Devil's Pact\" significantly: Marlowe's protagonist is unable to \"burn his books\" or repent to a merciful God to have his contract annulled at the end of the play; he is carried off by demons; and, in the 1616 quarto, his mangled corpse is found by the scholar characters.\nAttribution The 'B text' was highly edited and censored, owing in part to the shifting theatre laws regarding religious words onstage during the seventeenth-century. Because it contains several additional scenes believed to be the additions of other playwrights, particularly Samuel Rowley and William Bird (\"alias\" Borne), a recent edition attributes the authorship of both versions to \"Christopher Marlowe and his collaborator and revisers.\" This recent edition has tried to establish that the 'A text' was assembled from Marlowe's work and another writer, with the 'B text' as a later revision.\nEvidence No manuscripts by Marlowe exist for this play. The two earliest-printed extant versions of the play, A and B, form a textual problem for scholars. Both were published after Marlowe's death and scholars disagree which text is more representative of Marlowe's original. Some editions are based on a combination of the two texts. Late-twentieth-century scholarly consensus identifies 'A text' as more representative because it contains irregular character names and idiosyncratic spelling, which are believed to reflect the author's handwritten manuscript or \"foul papers\". In comparison, 'B text' is highly edited with several additional scenes possibly written by other playwrights.\n\"Edward the Second\" (c.\u20091592).\nFirst official record 1593\nFirst published 1590; earliest extant edition 1594 octavo\nFirst recorded performance 1592, performed by the Earl of Pembroke's Men.\nSignificance Considered by recent scholars as Marlowe's \"most modern play\" because of its probing treatment of the private life of a king and unflattering depiction of the power politics of the time. The 1594 editions of \"Edward II\" and of \"Dido\" are the first published plays with Marlowe's name appearing as the author.\nAttribution Earliest extant edition of 1594.\nEvidence The play was entered into the Stationers' Register on 6 July 1593, five weeks after Marlowe's death.\n\"The Massacre at Paris\" (c.\u20091589\u20131593).\nFirst official record c.\u20091593, alleged foul sheet by Marlowe of \"Scene 19\"; although authorship by Marlowe is contested by recent scholars, the manuscript is believed written while the play was first performed and with an unknown purpose.\nFirst published undated, c.\u20091594 or later, octavo, London; while this is the most complete surviving text, it is near half the length of Marlowe's other works and possibly a reconstruction. The printer and publisher credit, \"E.A. for Edward White,\" also appears on the 1605/06 printing of Marlowe's \"Tamburlaine\".\nFirst recorded performance 26 January 1593, by Lord Strange's Men, at Henslowe's Rose Theatre, London, under the title \"The Tragedy of the Guise\"; 1594, in the repertory of the Admiral's Men.\nSignificance \"The Massacre at Paris\" is considered Marlowe's most dangerous play, as agitators in London seized on its theme to advocate the murders of refugees from the low countries of the Spanish Netherlands, and it warns Elizabeth I of this possibility in its last scene. It features the silent \"English Agent\", whom tradition has identified with Marlowe and his connexions to the secret service. Highest grossing play for Lord Strange's Men in 1593.\nAttribution A 1593 loose manuscript sheet of the play, called a foul sheet, is alleged to be by Marlowe and has been claimed by some scholars as the only extant play manuscript by the author. It could also provide an approximate date of composition for the play. When compared with the extant printed text and his other work, other scholars reject the attribution to Marlowe. The only surviving printed text of this play is possibly a reconstruction from memory of Marlowe's original performance text. Current scholarship notes that there are only 1147 lines in the play, half the amount of a typical play of the 1590s. Other evidence that the extant published text is not Marlowe's original is the uneven style throughout, with two-dimensional characterisations, deteriorating verbal quality and repetitions of content.\nEvidence Never appeared in the Stationer's Register.\nMemorials.\n \"The Muse of Poetry\", part of the Marlowe Memorial in Canterbury\n\"The Muse of Poetry\", a bronze sculpture by Edward Onslow Ford references Marlowe and his work. It was erected on Buttermarket, Canterbury in 1891, and now stands outside the Marlowe Theatre in the city.\nIn July 2002, a memorial window to Marlowe was unveiled by the Marlowe Society at Poets' Corner in Westminster Abbey. Controversially, a question mark was added to his generally accepted date of death. On 25 October 2011 a letter from Paul Edmondson and Stanley Wells was published by \"The Times\" newspaper, in which they called on the Dean and Chapter to remove the question mark on the grounds that it \"flew in the face of a mass of unimpugnable evidence\". In 2012, they renewed this call in their e-book \"Shakespeare Bites Back\", adding that it \"denies history\" and again the following year in their book \"Shakespeare Beyond Doubt\".\nThe Marlowe Theatre in Canterbury, Kent, UK, was named for Marlowe in 1949.\nMarlowe in fiction.\nMarlowe has been used as a character in books, theatre, film, television, games and radio.\nModern compendia.\nModern scholarly collected works of Marlowe include:\nWorks of Marlowe in performance.\nRoyal Shakespeare Company.\nRoyal Shakespeare Company\nRoyal National Theatre.\nRoyal National Theatre\nShakespeare's Globe.\nShakespeare's Globe\nMalthouse Theatre.\nThe Marlowe Sessions\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nSources\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "5772", "revid": "1317671806", "url": "https://en.wikipedia.org/wiki?curid=5772", "title": "Cricket (disambiguation)", "text": "Cricket is a bat-and-ball sport contested by two teams.\nCricket also commonly refers to:\nCricket(s) or The Cricket(s) may also refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "5773", "revid": "1416331", "url": "https://en.wikipedia.org/wiki?curid=5773", "title": "Carroll OConnor", "text": ""}
{"id": "5776", "revid": "7611264", "url": "https://en.wikipedia.org/wiki?curid=5776", "title": "Caving", "text": "Recreational pastime of exploring cave systems\nCaving, also known as spelunking (United States and Canada) and potholing (United Kingdom and Ireland), is the recreational pastime of exploring wild cave systems (as distinguished from show caves). In contrast, speleology is the scientific study of caves and the cave environment.\nThe challenges involved in caving vary according to the cave being visited; in addition to the total absence of light beyond the entrance, negotiating pitches, squeezes, and water hazards can be difficult. Cave diving is a distinct, and more hazardous, sub-speciality undertaken by a small minority of technically proficient cavers. In an area of overlap between recreational pursuit and scientific study, the most devoted and serious-minded cavers become accomplished at the surveying and mapping of caves and the formal publication of their efforts. These are usually published freely and publicly, especially in the UK and other European countries, although in the US they are generally more private. \nAlthough caving is sometimes categorized as an \"extreme sport,\" cavers do not commonly use this terminology and typically dislike the term being used in reference to caving, as it implies a disregard for safety. Though caving is a fairly safe sport compared to other activities that are sometimes classified as \"extreme sports\", incidents do occur. These tend to be related to flooding, hypothermia, rock falls, caver falls, SRT accidents, or some combination of these.\nMany caving skills overlap with those involved in canyoning and mine and urban exploration.\nMotivation.\nCaving is often undertaken for the enjoyment of the outdoor activity or for physical exercise, as well as original exploration, similar to mountaineering or diving. Physical or biological science is also an important goal for some cavers, while others are engaged in cave photography. Virgin cave systems comprise some of the last unexplored regions on Earth and much effort is put into trying to locate, enter and survey them. In well-explored regions (such as most developed nations), the most accessible caves have already been explored, and gaining access to new caves often requires cave digging or cave diving.\nCaving, in certain areas, has also been utilized as a form of eco and adventure tourism, for example in New Zealand. Tour companies have established an industry leading and guiding tours into and through caves. Depending on the type of cave and the type of tour, the experience could be adventure-based or ecological-based. There are tours led through lava tubes by a guiding service (e.g. Lava River Cave, the oceanic islands of Tenerife, http:// and https://).\nCaving has also been described as an \"individualist's team sport\" by some, as cavers can often make a trip without direct physical assistance from others but will generally go in a group for companionship or to provide emergency help if needed. Some however consider the assistance cavers give each other as a typical team sport activity.\nEtymology.\nThe term \"potholing\" refers to the act of exploring \"potholes\", a word originating in the north of England for predominantly vertical caves.\nClay Perry, an American caver of the 1940s, wrote about a group of men and boys who explored and studied caves throughout New England. This group referred to themselves as \"spelunkers\", a term derived from the Latin \"\" (\"cave, cavern, den\"). This is regarded as the first use of the word in the Americas. Throughout the 1950s, \"spelunking\" was the general term used for exploring caves in US English. It was used freely, without any positive or negative connotations, although only rarely outside the US.\nIn the 1960s, the terms \"spelunking\" and \"spelunker\" began to be considered d\u00e9class\u00e9 among experienced enthusiasts. In 1985, Steve Knutson\u00a0\u2013 editor of the National Speleological Society (NSS) publication \"American Caving Accidents\"\u00a0\u2013 made the following distinction:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\u2026Note that (in this case) the term 'spelunker' denotes someone untrained and unknowledgeable in current exploration techniques, and 'caver' is for those who are.\nThis sentiment is exemplified by bumper stickers and T-shirts displayed by some cavers: \"Cavers rescue spelunkers\". Nevertheless, outside the caving community, \"spelunking\" and \"spelunkers\" predominately remain neutral terms referring to the practice and practitioners, without any respect to skill level.\nHistory.\nIn the mid-19th century, John Birkbeck explored potholes in England, notably Gaping Gill in 1842 and Alum Pot in 1847\u20138, returning there in the 1870s. In the mid-1880s, Herbert E. Balch began exploring Wookey Hole Caves and in the 1890s, Balch was introduced to the caves of the Mendip Hills. One of the oldest established caving clubs, Yorkshire Ramblers' Club, was founded in 1892.\nCaving as a specialized pursuit was pioneered by \u00c9douard-Alfred Martel (1859\u20131938), who first achieved the descent and exploration of the Gouffre de Padirac, in France, as early as 1889 and the first complete descent of a wet vertical shaft at Gaping Gill in 1895. He developed his own techniques based on ropes and metallic ladders. Martel visited Kentucky and notably Mammoth Cave National Park in October 1912. In the 1920s famous US caver Floyd Collins made important explorations in the area and in the 1930s, as caving became increasingly popular, small exploration teams both in the Alps and in the karstic high plateaus of southwest France (Causses and Pyrenees) transformed cave exploration into both a scientific and recreational activity. Robert de Joly, Guy de Lavaur and Norbert Casteret were prominent figures of that time, surveying mostly caves in Southwest France.\nDuring World War II, an alpine team composed of Pierre Chevalier, Fernand Petzl, Charles Petit-Didier and others explored the Dent de Crolles cave system near Grenoble, France which became the deepest explored system in the world at that time at a depth of . The lack of available equipment during the war forced Pierre Chevalier and the rest of the team to develop their own equipment, leading to technical innovation. The scaling-pole (1940), nylon ropes (1942), use of explosives in caves (1947) and mechanical rope-ascenders (Henri Brenot's \"monkeys\", first used by Chevalier and Brenot in a cave in 1934) can be directly associated to the exploration of the Dent de Crolles cave system.\nIn 1941, American cavers organized themselves into the National Speleological Society (NSS) to advance the exploration, conservation, study and understanding of caves in the United States. American caver Bill Cuddington, known as \"Vertical Bill\", further developed the single-rope technique (SRT) in the late 1950s. In 1958, two Swiss alpinists, Juesi and Marti teamed together, creating the first rope ascender known as the Jumar. In 1968 Bruno Dressler asked Fernand Petzl, who worked as a metals machinist, to build a rope-ascending tool, today known as the Petzl Croll, that he had developed by adapting the Jumar to vertical caving. Pursuing these developments, Petzl started in the 1970s a caving equipment manufacturing company named Petzl. The development of the rappel rack and the evolution of mechanical ascension systems extended the practice and safety of vertical exploration to a wider range of cavers.\nPractice and equipment.\nHard hats are worn to protect the head from bumps and falling rocks. The caver's primary light source is usually mounted on the helmet in order to keep the hands free. Electric LED lights are most common. Many cavers carry two or more sources of light \u2013 one as primary and the others as backup in case the first fails. More often than not, a second light will be mounted to the helmet for quick transition if the primary fails. Carbide lamp systems are an older form of illumination, inspired by miner's equipment, and are still used by some cavers, particularly on remote expeditions where electric charging facilities are not available.\nThe type of clothes worn underground varies according to the environment of the cave being explored, and the local culture. In cold caves, the caver may wear a warm base layer that retains its insulating properties when wet, such as a fleece (\"furry\") suit or polypropylene underwear, and an oversuit of hard-wearing (e.g., cordura) or waterproof (e.g., PVC) material. Lighter clothing may be worn in warm caves, particularly if the cave is dry, and in tropical caves thin polypropylene clothing is used, to provide some abrasion protection while remaining as cool as possible. Wetsuits may be worn if the cave is particularly wet or involves stream passages. On the feet boots are worn\u00a0\u2013 hiking-style boots in drier caves, or rubber boots (such as wellies) often with neoprene socks (\"wetsocks\") in wetter caves. Knee-pads (and sometimes elbow-pads) are popular for protecting joints during crawls. Depending on the nature of the cave, gloves are sometimes worn to protect the hands against abrasion or cold. In pristine areas and for restoration, clean oversuits and powder-free, non-latex surgical gloves are used to protect the cave itself from contaminants.\nRopes are used for descending or ascending pitches (single rope technique or SRT) or for protection. Knots commonly used in caving are the figure-of-eight- (or figure-of-nine-) loop, bowline, alpine butterfly, and Italian hitch. Ropes are usually rigged using bolts, slings, and carabiners. In some cases cavers may choose to bring and use a flexible metal ladder.\nIn addition to the equipment already described, cavers frequently carry packs containing first-aid kits, emergency equipment, and food. Containers for securely transporting urine are also commonly carried. On longer trips, containers for securely transporting feces out of the cave are carried.\nDuring very long trips, it may be necessary to camp in the cave\u00a0\u2013 some cavers have stayed underground for many days, or in particularly extreme cases, for weeks at a time. This is particularly the case when exploring or mapping extensive cave systems, where it would be impractical to retrace the route back to the surface regularly. Such long trips necessitate the cavers carrying provisions, sleeping, and cooking equipment.\nSafety.\nCaves can be dangerous places; hypothermia, falling, flooding, falling rocks and physical exhaustion are the main risks. Rescuing people from underground is difficult and time-consuming, and requires special skills, training, and equipment. Full-scale cave rescues often involve the efforts of dozens of rescue workers (often other long-time cavers who have participated in specialized courses, as normal rescue staff are not sufficiently experienced in cave environments), who may themselves be put in jeopardy in effecting the rescue. This said, caving is not necessarily a high-risk sport (especially if it does not involve difficult climbs or diving). As in all physical sports, knowing one's limitations is key.\nCaving in warmer climates carries the risk of contracting histoplasmosis, a fungal infection that is contracted from bird or bat droppings. It can cause pneumonia and can disseminate in the body to cause continued infections.\nIn many parts of the world, leptospirosis, a type of bacterial infection spread by animals including rats, is a distinct threat. The presence of rat urine in rainwater or precipitation that enters the cave's water system is the primary vector of infection. Complications are uncommon, but can be serious.\nThese safety risks while caving can be minimized by using a number of techniques:\nCave conservation.\nMany cave environments are very fragile. Many speleothems can be damaged by even the slightest touch and some by impacts as slight as a breath. Research suggests that increased carbon dioxide levels can lead to \"a higher equilibrium concentration of calcium within the drip waters feeding the speleothems, and hence causes dissolution of existing features.\" In 2008, researchers found evidence that respiration from cave visitors may generate elevated carbon dioxide concentrations in caves, leading to increased temperatures of up to 3\u00a0\u00b0C and a dissolution of existing features.\nPollution is also of concern. Since water that flows through a cave eventually comes out in streams and rivers, any pollution may ultimately end up in someone's drinking water, and can even seriously affect the surface environment, as well. Even minor pollution such as dropping organic material can have a dramatic effect on the cave biota.\nCave-dwelling species are also very fragile. Often, a particular species found in a cave may live within that cave alone, and be found nowhere else in the world; an example is the Alabama cave shrimp. Cave-dwelling species are accustomed to a near-constant climate of temperature and humidity, and any disturbance can be disruptive to the species' life cycles. Though cave wildlife may not always be immediately visible, it is typically nonetheless present in most caves.\nBats are one such fragile species of cave-dwelling animal. Bats which hibernate are most vulnerable during the winter season, when no food supply exists on the surface to replenish the bat's store of energy should it be awakened from hibernation. Bats which migrate are most sensitive during the summer months when they are raising their young. For these reasons, visiting caves inhabited by hibernating bats is discouraged during cold months; and visiting caves inhabited by migratory bats is discouraged during the warmer months when they are most sensitive and vulnerable. Due to an affliction affecting bats in the northeastern US known as white nose syndrome (WNS), the US Fish &amp; Wildlife Service has called for a moratorium effective March 26, 2009, on caving activity in states known to have hibernacula (MD, NY, VT, NH, MA, CT, NJ, PA, VA, and WV) affected by WNS, as well as adjoining states.\nSome cave passages may be marked with flagging tape or other indicators to show biologically, aesthetically, or archaeologically sensitive areas. Marked paths may show ways around notably fragile areas such as a pristine floor of sand or silt which may be thousands of years old, dating from the last time water flowed through the cave. Such deposits may easily be spoiled forever by a single misplaced step. Active formations such as flowstone can be similarly marred with a muddy footprint or handprint, and ancient human artifacts, such as fiber products, may even crumble to dust under all but the most gentle touch.\nIn 1988, concerned that cave resources were becoming increasingly damaged through unregulated use, Congress enacted the Federal Cave Resources Protection Act, giving land management agencies in the United States expanded authority to manage cave conservation on public land.\nCaving organizations.\nCavers in many countries have created organizations for the administration and oversight of caving activities within their nations. The oldest of these is the French Federation of Speleology (originally Soci\u00e9t\u00e9 de sp\u00e9l\u00e9ologie) founded by \u00c9douard-Alfred Martel in 1895, which produced the first periodical journal in speleology, \"Spelunca\". The first University-based speleological institute in the world was founded in 1920 in Cluj-Napoca, Romania, by Emil Racovita, a Romanian biologist, zoologist, speleologist and explorer of Antarctica.\nThe British Speleological Association was established in 1935. In the United States, the National Speleological Society in the US was founded in 1941; however, it was originally formed as the Speleological Society of the District of Columbia on May 6, 1939.\nAn international speleological congress was proposed at a meeting in Valence-sur-Rhone, France in 1949 and first held in 1953 in Paris. The International Union of Speleology (UIS) was founded in 1965.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "5778", "revid": "10044298", "url": "https://en.wikipedia.org/wiki?curid=5778", "title": "Cave", "text": "Natural void under a planetary surface\nCaves or caverns are natural voids under the surface of the Earth and have been observed in other rocky worlds also (\"viz.\" on Mars). Caves often form by the weathering of rock and can extend deep underground. Exogene caves are smaller openings that extend a relatively short distance underground (such as rock shelters). Caves which extend farther underground than the opening is wide are called endogene caves.\nSpeleology is the science of exploration and study of all aspects of caves and the cave environment. Visiting or exploring caves for recreation may be called \"caving\", \"potholing\", or \"spelunking\".\nFormation types.\nThe formation and development of caves is known as \"speleogenesis\"; it can occur over the course of millions of years. Caves can range widely in size, and are formed by various geological processes. These may involve a combination of chemical processes, erosion by water, tectonic forces, microorganisms, pressure, and atmospheric influences. Isotopic dating techniques can be applied to cave sediments, to determine the timescale of the geological events which formed and shaped present-day caves.\nIt is estimated that a cave cannot be more than vertically beneath the surface due to the pressure of overlying rocks. This does not, however, impose a maximum depth for a cave which is measured from its highest entrance to its lowest point, as the amount of rock above the lowest point is dependent on the topography of the landscape above it. For karst caves the maximum depth is determined on the basis of the lower limit of karst forming processes, coinciding with the base of the soluble carbonate rocks. Most caves are formed in limestone by dissolution.\nCaves can be classified in various other ways as well, including a contrast between active and relict: active caves have water flowing through them; relict caves do not, though water may be retained in them. Types of active caves include inflow caves (\"into which a stream sinks\"), outflow caves (\"from which a stream emerges\"), and through caves (\"traversed by a stream\").\nSolutional.\nSolutional caves or karst caves are the most frequently occurring caves. Such caves form in rock that is soluble; most occur in limestone, but they can also form in other rocks including chalk, dolomite, marble, salt, and gypsum. Except for salt caves, solutional caves result when rock is dissolved by natural acid in groundwater that seeps through bedding planes, faults, joints, and comparable features. Over time cracks enlarge to become caves and cave systems.\nThe largest and most abundant solutional caves are located in limestone. Limestone dissolves under the action of rainwater and groundwater charged with H2CO3 (carbonic acid) and naturally occurring organic acids. The dissolution process produces a distinctive landform known as \"karst\", characterized by sinkholes and underground drainage. Limestone caves are often adorned with calcium carbonate formations produced through slow precipitation. These include flowstones, stalactites, stalagmites, helictites, soda straws and columns. These secondary mineral deposits in caves are called \"speleothems\".\nThe portions of a solutional cave that are below the water table or the local level of the groundwater will be flooded.\nLechuguilla Cave in New Mexico and nearby Carlsbad Cavern are now believed to be examples of another type of solutional cave. They were formed by H2S (hydrogen sulfide) gas rising from below, where reservoirs of oil give off sulfurous fumes. This gas mixes with groundwater and forms H2SO4 (sulfuric acid). The acid then dissolves the limestone from below, rather than from above, by acidic water percolating from the surface.\nPrimary.\nCaves formed at the same time as the surrounding rock are called primary caves.\nLava tubes are formed through volcanic activity and are the most common primary caves. As lava flows downhill, its surface cools and solidifies. Hot liquid lava continues to flow under that crust, and if most of it flows out, a hollow tube remains. Such caves can be found in the Canary Islands, Jeju-do, the basaltic plains of Eastern Idaho, and in other places. Kazumura Cave near Hilo, Hawaii is a remarkably long and deep lava tube; it is .\nLava caves include but are not limited to lava tubes. Other caves formed through volcanic activity include rifts, lava molds, open vertical conduits, inflationary, blisters, among others.\nSea or littoral.\nSea caves are found along coasts around the world. A special case is littoral caves, which are formed by wave action in zones of weakness in sea cliffs. Often these weaknesses are faults, but they may also be dykes or bedding-plane contacts. Some wave-cut caves are now above sea level because of later uplift. Elsewhere, in places such as Thailand's Phang Nga Bay, solutional caves have been flooded by the sea and are now subject to littoral erosion. Sea caves are generally around in length, but may exceed .\nErosional.\nErosional caves are those that form entirely by erosion by flowing streams carrying rocks and other sediments. These can form in any type of rock, including hard rocks such as granite. Generally there must be some zone of weakness to guide the water, such as a fault or joint. A subtype of the erosional cave is the wind or aeolian cave, carved by wind-born sediments. Many caves formed initially by solutional processes often undergo a subsequent phase of erosional or vadose enlargement where active streams or rivers pass through them.\nGlacier.\nGlacier caves are formed by melting ice and flowing water within and under glaciers. The cavities are influenced by the very slow flow of the ice, which tends to collapse the caves again. Glacier caves are sometimes misidentified as \"ice caves\", though this latter term is properly reserved for bedrock caves that contain year-round ice formations.\nFracture.\nFracture caves are formed when layers of more soluble minerals, such as gypsum, dissolve out from between layers of less soluble rock. These rocks fracture and collapse in blocks of stone.\nTalus.\nTalus caves are formed by the openings among large boulders that have fallen down into a random heap, often at the bases of cliffs. These unstable deposits are called talus or scree, and may be subject to frequent rockfalls and landslides.\nAnchialine.\nAnchialine caves are caves, usually coastal, containing a mixture of freshwater and saline water (usually sea water). They occur in many parts of the world, and often contain highly specialized and endemic fauna.\nGeographic distribution.\nCaves are found throughout the world, although the distribution of documented cave system is heavily skewed towards those countries where caving has been popular for many years (such as France, Italy, Australia, the UK, the United States, etc.). As a result, explored caves are found widely in Europe, Asia, North America and Oceania, but are sparse in South America, Africa, and Antarctica.\nThis is a rough generalization, as large expanses of North America and Asia contain no documented caves, whereas areas such as the Madagascar dry deciduous forests and parts of Brazil contain many documented caves. As the world's expanses of soluble bedrock are researched by cavers, the distribution of documented caves is likely to shift. For example, China, despite containing around half the world's exposed limestone\u2014more than \u2014has relatively few documented caves.\nEcology.\nCave-inhabiting animals are often categorized as troglobites (cave-limited species), troglophiles (species that can live their entire lives in caves, but also occur in other environments), trogloxenes (species that use caves, but cannot complete their life cycle fully in caves) and accidentals (animals not in one of the previous categories). Some authors use separate terminology for aquatic forms (for example, stygobites, stygophiles, and stygoxenes).\nOf these animals, the troglobites are perhaps the most unusual organisms. Troglobitic species often show a number of characteristics, termed troglomorphic, associated with their adaptation to subterranean life. These characteristics may include a loss of pigment (often resulting in a pale or white coloration), a loss of eyes (or at least of optical functionality), an elongation of appendages, and an enhancement of other senses (such as the ability to sense vibrations in water). Aquatic troglobites (or stygobites), such as the endangered Alabama cave shrimp, live in bodies of water found in caves and get nutrients from detritus washed into their caves and from the feces of bats and other cave inhabitants. Other aquatic troglobites include cave fish, and cave salamanders such as the olm and the Texas blind salamander.\nCave insects such as \"Oligaphorura\" (formerly \"Archaphorura\") \"schoetti\" are troglophiles, reaching in length. They have extensive distribution and have been studied fairly widely. Most specimens are female, but a male specimen was collected from St Cuthberts Swallet in 1969.\nBats, such as the gray bat and Mexican free-tailed bat, are trogloxenes and are often found in caves; they forage outside of the caves. Some species of cave crickets are classified as trogloxenes, because they roost in caves by day and forage above ground at night.\nBecause of the fragility of cave ecosystems, and the fact that cave regions tend to be isolated from one another, caves harbor a number of endangered species, such as the Tooth cave spider, liphistius trapdoor spider, and the gray bat.\nCaves are visited by many surface-living animals, including humans. These are usually relatively short-lived incursions, due to the lack of light and sustenance.\nCave entrances often have typical florae. For instance, in the eastern temperate United States, cave entrances are most frequently (and often densely) populated by the bulblet fern, \"Cystopteris bulbifera\".\nArchaeological and cultural importance.\nPeople have made use of caves throughout history. The earliest human fossils found in caves come from a series of caves near Krugersdorp and Mokopane in South Africa. The cave sites of Sterkfontein, Swartkrans, Kromdraai B, Drimolen, Malapa, Cooper's D, Gladysvale, Gondolin and Makapansgat have yielded a range of early human species dating back to between three and one million years ago, including \"Australopithecus africanus\", \"Australopithecus sediba\" and \"Paranthropus robustus\". However, it is not generally thought that these early humans were living in the caves, but that they were brought into the caves by carnivores that had killed them.\nThe first early hominid ever found in Africa, the Taung Child in 1924, was also thought for many years to come from a cave, where it had been deposited after being predated on by an eagle. However, this is now debated (Hopley et al., 2013; Am. J. Phys. Anthrop.). Caves do form in the dolomite of the Ghaap Plateau, including the Early, Middle and Later Stone Age site of Wonderwerk Cave; however, the caves that form along the escarpment's edge, like that hypothesised for the Taung Child, are formed within a secondary limestone deposit called tufa. There is numerous evidence for other early human species inhabiting caves from at least one million years ago in different parts of the world, including \"Homo erectus\" in China at Zhoukoudian, \"Homo rhodesiensis\" in South Africa at the Cave of Hearths (Makapansgat), \"Homo neanderthalensis\" and \"Homo heidelbergensis\" in Europe at Archaeological Site of Atapuerca, \"Homo floresiensis\" in Indonesia, and the Denisovans in southern Siberia.\nIn southern Africa, early modern humans regularly used sea caves as shelter starting about 180,000 years ago when they learned to exploit the sea for the first time. The oldest known site is PP13B at Pinnacle Point. This may have allowed rapid expansion of humans out of Africa and colonization of areas of the world such as Australia by 60\u201350,000 years ago. Throughout southern Africa, Australia, and Europe, early modern humans used caves and rock shelters as sites for rock art, such as those at Giant's Castle. Among the known sacred caves are China's Cave of a Thousand Buddhas and the sacred caves of Crete.\nPaleolithic cave paintings have been found throughout the world dating from 64,800 years old for non-figurative art and 43,900 years old for figurative art.\nCaves and acoustics.\nThe importance of sound in caves predates a modern understanding of acoustics. Archaeologists have uncovered relationships between paintings of dots and lines, in specific areas of resonance, within the caves of Spain and France, as well as instruments depicting paleolithic motifs, indicators of musical events and rituals. Clusters of paintings were often found in areas with notable acoustics, sometimes even replicating the sounds of the animals depicted on the walls. The human voice was also theorized to be used as an echolocation device to navigate darker areas of the caves where torches were less useful. Dots of red ochre are often found in spaces with the highest resonance, where the production of paintings was too difficult.\nCaves continue to provide usage for modern-day explorers of acoustics. Today Cumberland Caverns provides one of the best examples for modern musical usages of caves. The caves are utilized not only for reverberation, but for the dampening qualities of their abnormal faces as well. The irregularities in the walls of the Cumberland Caverns diffuse sounds bouncing off the walls and give the space an almost recording studio-like quality. During the 20th century musicians began to explore the possibility of using caves as locations as clubs and concert halls, including the likes of Dinah Shore, Roy Acuff, and Benny Goodman. Unlike today, these early performances were typically held in the mouths of the caves, as the lack of technology made depths of the interior inaccessible with musical equipment. In Luray Caverns, Virginia, a functioning organ has been developed that generates sound by mallets striking stalactites, each with a different pitch.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "5780", "revid": "4938", "url": "https://en.wikipedia.org/wiki?curid=5780", "title": "Chaco Canyon", "text": ""}
{"id": "5781", "revid": "46271501", "url": "https://en.wikipedia.org/wiki?curid=5781", "title": "Chinese numerals", "text": "Characters used to denote numbers in Chinese\nChinese numerals are words and characters used to denote numbers in written Chinese.\nSpeakers of Chinese languages use three written numeral systems: the international system of Arabic numerals, and two indigenous systems. The more familiar indigenous system is based on Chinese characters that correspond to numerals in the spoken language. These may be shared with other languages of the Chinese cultural sphere such as Korean, Japanese, and Vietnamese. Most people and institutions in China primarily use the Arabic or mixed Arabic-Chinese systems for convenience, with traditional Chinese numerals used in finance, mainly for writing amounts on cheques, banknotes, some ceremonial occasions, some boxes, and on commercials.\nThe other indigenous system consists of the Suzhou numerals, or \"huama\", a positional system, the only surviving form of the rod numerals. These were once used by Chinese mathematicians, and later by merchants in Chinese markets, such as those in Hong Kong until the 1990s, but were gradually supplanted by Arabic numerals.\nBasic counting in Chinese.\nThe Chinese character numeral system consists of the Chinese characters used by the Chinese written language to write spoken numerals. Similar to spelling-out numbers in English (e.g., \"one thousand nine hundred forty-five\"), it is not an independent system \"per se\". Since it reflects spoken language, it does not use the positional system as in Arabic numerals, in the same way that spelling out numbers in English does not.\nOrdinary numerals.\nThere are characters representing the numbers zero through nine, and other characters representing larger numbers such as tens, hundreds, thousands, ten thousands and hundred millions. There are two sets of characters for Chinese numerals: one for everyday writing, known as (), and one for use in commercial, accounting or financial contexts, known as ( or 'capital numbers'). The latter were developed by Wu Zetian (fl.\u2009690\u2013705) and were further refined by the Hongwu Emperor (fl.\u20091328\u20131398). They arose because the characters used for writing numerals are geometrically simple, so simply using those numerals cannot prevent forgeries in the same way spelling numbers out in English would. A forger could easily change the characters (30) to (5000) by adding a few strokes. That would not be possible when writing using the financial characters (30) and (5000). They are also referred to as \"banker's numerals\" or \"anti-fraud numerals\". For the same reason, rod numerals were never used in commercial records.\n1. &lt;templatestyles src=\"Citation/styles.css\"/&gt;^ Wugniu is a pan-Wu romanization scheme, but the exact romanization depends on the variety. The romanization listed here is specifically for Shanghainese.\nPowers of 10.\nLarge numbers.\nFor numbers larger than 10,000, similarly to the long and short scales in the West, there have been four systems in ancient and modern usage. The original one, with unique names for all powers of ten up to the 14th, is ascribed to the Yellow Emperor in the 6th century book by Zhen Luan, . In modern Chinese, only the second system is used, in which the same ancient names are used, but each represents a myriad, times the previous:\nIn practice, this situation does not lead to ambiguity, with the exception of , which means 1012 according to the system in common usage throughout Chinese communities as well as in Japan and Korea, but has also been used for 106 in recent years (especially in mainland China for megabyte). To avoid ambiguity, the PRC government never uses this character in official documents, but uses or instead. Partly due to this, combinations of and are often used instead of the larger units of the traditional system as well, for example instead of . The ROC government in Taiwan uses to mean 1012 in official documents.\nLarge numbers from Buddhism.\nNumerals beyond z\u01cei come from Buddhist texts in Sanskrit, but are mostly found in ancient texts. Some of the following words are still being used today, but may have transferred meanings.\nSmall numbers.\nThe following are characters used to denote small order of magnitude in Chinese historically. With the introduction of SI units, some of them have been incorporated as SI prefixes, while the rest have fallen into disuse.\nSI prefixes.\nIn the People's Republic of China, the early translation for the SI prefixes in 1981 was different from those used today. The larger (, , , , ) and smaller Chinese numerals (, , , , ) were defined as translation for the SI prefixes as \"mega\", \"giga\", \"tera\", \"peta\", \"exa\", \"micro\", \"nano\", \"pico\", \"femto\", \"atto\", resulting in the creation of yet more values for each numeral.\nThe Republic of China (Taiwan) defined as the translation for \"mega\" and as the translation for \"tera\". This translation is widely used in official documents, academic communities, informational industries, etc. However, the civil broadcasting industries sometimes use to represent \"megahertz\".\nToday, the governments of both China and Taiwan use phonetic transliterations for the SI prefixes. However, the governments have chosen different Chinese characters for certain prefixes. The following table lists the two different standards together with the early translation.\nReading and transcribing numbers.\nWhole numbers.\nMultiple-digit numbers are constructed using a multiplicative principle; first the digit itself (from 1 to 9), then the place (such as 10 or 100); then the next digit.\nIn Mandarin, (\"li\u01ceng\") rather than is often used for all numbers 200 and greater to represent the \"2\" numeral (although as noted earlier this varies from dialect to dialect and person to person). Use of both or are acceptable for the number 200. When writing in the Cantonese dialect, is used to represent the \"2\" numeral for all numbers. In the southern Min dialect of Chaozhou (Teochew), (\"no6\") is used to represent the \"2\" numeral in all numbers from 200 onwards. Thus:\nFor the numbers 11 through 19, the leading 'one' () is usually omitted. In some dialects, like Shanghainese, when there are only two significant digits in the number, the leading 'one' and the trailing zeroes are omitted. Sometimes, the one before \"ten\" in the middle of a number, such as 213, is omitted. Thus:\nIn certain older texts like the Protestant Bible, or in poetic usage, numbers such as 114 may be \"written\" as [100] [10] [4] ().\nOutside of Taiwan, digits are sometimes grouped by myriads instead of thousands. Hence it is more convenient to think of numbers here as in groups of four, thus 1,234,567,890 is regrouped here as 12,3456,7890. Larger than a myriad, each number is therefore four zeroes longer than the one before it, thus 10000 \u00d7 = . If one of the numbers is between 10 and 19, the leading 'one' is omitted as per the above point. Hence (numbers in parentheses indicate that the number has been written as one number rather than expanded):\nIn Taiwan, pure Arabic numerals are officially always and only grouped by thousands. Unofficially, they are often not grouped, particularly for numbers below 100,000. Mixed Arabic-Chinese numerals are often used in order to denote myriads. This is used both officially and unofficially, and come in a variety of styles:\nInterior zeroes before the unit position (as in 1002) must be spelt explicitly. The reason for this is that trailing zeroes (as in 1200) are often omitted as shorthand, so ambiguity occurs. One zero is sufficient to resolve the ambiguity. Where the zero is before a digit other than the units digit, the explicit zero is not ambiguous and is therefore optional, but preferred. Thus:\nFractional values.\nTo construct a fraction, the denominator is written first, followed by , then the literary possessive particle , and lastly the numerator. Each half of the fraction is written the same as a whole number. For example, to express \"two thirds\", the structure \"three parts of-this two\" is used. Mixed numbers are written with the whole-number part first, followed by , then the fractional part.\nPercentages are constructed similarly, using as the denominator. (The number 100 is typically expressed as , like the English 'one hundred'. However, for percentages, is used on its own.)\nBecause percentages and other fractions are formulated the same, Chinese are more likely than not to express 10%, 20% etc. as 'parts of 10' (or &lt;templatestyles src=\"Fraction/styles.css\" /&gt;1\u204410, &lt;templatestyles src=\"Fraction/styles.css\" /&gt;2\u204410, etc. i.e. ; , ; , etc.) rather than \"parts of 100\" (or &lt;templatestyles src=\"Fraction/styles.css\" /&gt;10\u2044100, &lt;templatestyles src=\"Fraction/styles.css\" /&gt;20\u2044100, etc. i.e. ; , ; , etc.)\nIn Taiwan, the most common formation of percentages in the spoken language is the number per hundred followed by the word , a contraction of the Japanese ; , itself taken from 'percent'. Thus 25% is ; .\nDecimal numbers are constructed by first writing the whole number part, then inserting a point (), and finally the fractional part. The fractional part is expressed using only the numbers for 0 to 9, similarly to English.\n functions as a number and therefore requires a measure word. For example: .\nOrdinal numbers.\nOrdinal numbers are formed by adding before the number.\nThe Heavenly Stems are a traditional Chinese ordinal system.\nNegative numbers.\nNegative numbers are formed by adding before the number.\nUsage.\nChinese grammar requires the use of classifiers (measure words) when a numeral is used together with a noun to express a quantity. For example, \"three people\" is expressed as , \"three ( particle) person\", where / \"\" is a classifier. There exist many different classifiers, for use with different sets of nouns, although / is the most common, and may be used informally in place of other classifiers.\nChinese uses cardinal numbers in certain situations in which English would use ordinals. For example, (literally \"three story/storey\") means \"third floor\" (\"second floor\" in British ). Likewise, (literally \"twenty-one century\") is used for \"21st century\".\nNumbers of years are commonly spoken as a sequence of digits, as in (\"two zero zero one\") for the year 2001. Names of months and days (in the Western system) are also expressed using numbers: (\"one month\") for January, etc.; and (\"week one\") for Monday, etc. There is only one exception: Sunday is , or informally , both literally \"week day\". When meaning \"week\", \" and \" are interchangeable. \" or \" means \"day of worship\". Chinese Catholics call Sunday \" \", \"Lord's day\".\nFull dates are usually written in the format 2001\u5e741\u670820\u65e5 for January 20, 2001 (using \"year\", \"month\", and \"day\") \u2013 all the numbers are read as cardinals, not ordinals, with no leading zeroes, and the year is read as a sequence of digits. For brevity the , and may be dropped to give a date composed of just numbers. For example \"6-4\" in Chinese is \"six-four\", short for \"month six, day four\" i.e. June Fourth, a common Chinese shorthand for the 1989 Tiananmen Square protests and massacre (because of the violence that occurred on June 4). For another example 67, in Chinese is sixty seven, short for year nineteen sixty seven, a common Chinese shorthand for the 1967 Hong Kong riots.\nCounting rod and Suzhou numerals.\nIn the same way that Roman numerals were standard in ancient and medieval Europe for mathematics and commerce, the Chinese formerly used the rod numerals, which is a positional system. The Suzhou numerals () system is a variation of the Southern Song rod numerals. Nowadays, the \"hu\u0101m\u01ce\" system is only used for displaying prices in Chinese markets or on traditional handwritten invoices.\nHand gestures.\nThere is a common method of using of one hand to signify the numbers one to ten. While the five digits on one hand can easily express the numbers one to five, six to ten have special signs that can be used in commerce or day-to-day communication.\nHistorical use of numerals in China.\nMost Chinese numerals of later periods were descendants of the Shang dynasty oracle numerals of the 14th century BC. The oracle bone script numerals were found on tortoise shell and animal bones. In early civilizations, the Shang were able to express any numbers, however large, with only nine symbols and a counting board though it was still not positional.\nSome of the bronze script numerals such as 1, 2, 3, 4, 10, 11, 12, and 13 became part of the system of rod numerals.\nIn this system, horizontal rod numbers are used for the tens, thousands, hundred thousands etc. It is written in \"Sunzi Suanjing\" that \"one is vertical, ten is horizontal\".\nThe counting rod numerals system has place value and decimal numerals for computation, and was used widely by Chinese merchants, mathematicians and astronomers from the Han dynasty to the 16th century.\nAlexander Wylie, Christian missionary to China, in 1853 already refuted the notion that \"the Chinese numbers were written in words at length\", and stated that in ancient China, calculation was carried out by means of counting rods, and \"the written character is evidently a rude presentation of these\". After being introduced to the rod numerals, he said \"Having thus obtained a simple but effective system of figures, we find the Chinese in actual use of a method of notation depending on the theory of local value [i.e. place-value], several centuries before such theory was understood in Europe, and while yet the science of numbers had scarcely dawned among the Arabs.\"\nDuring the Ming and Qing dynasties (after Arabic numerals were introduced into China), some Chinese mathematicians used Chinese numeral characters as positional system digits. After the Qing period, both the Chinese numeral characters and the Suzhou numerals were replaced by Arabic numerals in mathematical writings.\nCultural influences.\nTraditional Chinese numeric characters are also used in Japan and Korea and were used in Vietnam before the 20th century. In vertical text, using characters for numbers is the norm, while in horizontal text, Arabic numerals are most common. Chinese numeric characters are also used in much the same formal or decorative fashion that Roman numerals are in Western cultures. Chinese numerals may appear together with Arabic numbers on the same sign or document.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "5783", "revid": "6036800", "url": "https://en.wikipedia.org/wiki?curid=5783", "title": "Computer program", "text": "Instructions a computer can execute\nA computer program is a sequence or set of instructions in a programming language for a computer to execute. It is one component of software, which also includes documentation and other intangible components.\nA \"computer program\" in its human-readable form is called source code. Source code needs another computer program to execute because computers can only execute their native machine instructions. Therefore, source code may be translated to machine instructions using a compiler written for the language. (Assembly language programs are translated using an assembler.) The resulting file is called an executable. Alternatively, source code may execute within an interpreter written for the language.\nIf the executable is requested for execution, then the operating system loads it into memory and starts a process. The central processing unit will soon switch to this process so it can fetch, decode, and then execute each machine instruction.\nIf the source code is requested for execution, then the operating system loads the corresponding interpreter into memory and starts a process. The interpreter then loads the source code into memory to translate and execute each statement. Running the source code is slower than running an executable. Moreover, the interpreter must be installed on the computer.\nExample computer program.\nThe \"Hello, World!\" program is used to illustrate a language's basic syntax. The syntax of the language BASIC (1964) was intentionally limited to make the language easy to learn. For example, variables are not declared before being used. Also, variables are automatically initialized to zero. Here is an example computer program, in Basic, to average a list of numbers:\n10 INPUT \"How many numbers to average?\", A\n20 FOR I = 1 TO A\n30 INPUT \"Enter number:\", B\n40 LET C = C + B\n50 NEXT I\n60 LET D = C/A\n70 PRINT \"The average is\", D\n80 END\nOnce the mechanics of basic computer programming are learned, more sophisticated and powerful languages are available to build large computer systems.\nHistory.\nImprovements in software development are the result of improvements in computer hardware. At each stage in hardware's history, the task of computer programming changed dramatically.\nAnalytical Engine.\nIn 1837, Jacquard's loom inspired Charles Babbage to attempt to build the Analytical Engine.\nThe names of the components of the calculating device were borrowed from the textile industry. In the textile industry, yarn was brought from the store to be milled. The device had a \"store\" which consisted of memory to hold 1,000 numbers of 50 decimal digits each. Numbers from the \"store\" were transferred to the \"mill\" for processing. The engine was programmed using two sets of perforated cards. One set directed the operation and the other set inputted the variables. However, the thousands of cogged wheels and gears never fully worked together.\nAda Lovelace worked for Charles Babbage to create a description of the Analytical Engine (1843). The description contained Note G which completely detailed a method for calculating Bernoulli numbers using the Analytical Engine. This note is recognized by some historians as the world's first \"computer program\".\nUniversal Turing machine.\nIn 1936, Alan Turing introduced the Universal Turing machine, a theoretical device that can model every computation.\nIt is a finite-state machine that has an infinitely long read/write tape. The machine can move the tape back and forth, changing its contents as it performs an algorithm. The machine starts in the initial state, goes through a sequence of steps, and halts when it encounters the halt state. All present-day computers are Turing complete.\nENIAC.\nThe Electronic Numerical Integrator And Computer (ENIAC) was built between July 1943 and Fall 1945. It was a Turing complete, general-purpose computer that used 17,468 vacuum tubes to create the circuits. At its core, it was a series of Pascalines wired together. Its 40 units weighed 30 tons, occupied , and consumed $650 per hour (in 1940s currency) in electricity when idle. It had 20 base-10 accumulators. Programming the ENIAC took up to two months. Three function tables were on wheels and needed to be rolled to fixed function panels. Function tables were connected to function panels by plugging heavy black cables into plugboards. Each function table had 728 rotating knobs. Programming the ENIAC also involved setting some of the 3,000 switches. Debugging a program took a week. It ran from 1947 until 1955 at Aberdeen Proving Ground, calculating hydrogen bomb parameters, predicting weather patterns, and producing firing tables to aim artillery guns.\nStored-program computers.\nInstead of plugging in cords and turning switches, a stored-program computer loads its instructions into memory just like it loads its data into memory. As a result, the computer could be programmed quickly and perform calculations at very fast speeds. Presper Eckert and John Mauchly built the ENIAC. The two engineers introduced the \"stored-program concept\" in a three-page memo dated February 1944. Later, in September 1944, John von Neumann began working on the ENIAC project. On June 30, 1945, von Neumann published the \"First Draft of a Report on the EDVAC\", which equated the structures of the computer with the structures of the human brain. The design became known as the von Neumann architecture. The architecture was simultaneously deployed in the constructions of the EDVAC and EDSAC computers in 1949.\nThe IBM System/360 (1964) was a family of computers, each having the same instruction set architecture. The Model 20 was the smallest and least expensive. Customers could upgrade and retain the same application software. The Model 195 was the most premium. Each System/360 model featured multiprogramming\u2014having multiple processes in memory at once. When one process was waiting for input/output, another could compute.\nIBM planned for each model to be programmed using PL/I. A committee was formed that included COBOL, FORTRAN and ALGOL programmers. The purpose was to develop a language that was comprehensive, easy to use, extendible, and would replace COBOL and FORTRAN. The result was a large and complex language that took a long time to compile.\nComputers manufactured until the 1970s had front-panel switches for manual programming. The computer program was written on paper for reference. An instruction was represented by a configuration of on/off settings. After setting the configuration, an execute button was pressed. This process was then repeated. Computer programs also were automatically inputted via paper tape, punched cards or magnetic-tape. After the medium was loaded, the starting address was set via switches, and the execute button was pressed.\nVery Large Scale Integration.\nA major milestone in software development was the invention of the Very Large Scale Integration (VLSI) circuit (1964).\nRobert Noyce, co-founder of Fairchild Semiconductor (1957) and Intel (1968), achieved a technological improvement to refine the production of field-effect transistors (1963). The goal is to alter the electrical resistivity and conductivity of a semiconductor junction. First, naturally occurring silicate minerals are converted into polysilicon rods using the Siemens process. The Czochralski process then converts the rods into a monocrystalline silicon, boule crystal. The crystal is then thinly sliced to form a wafer substrate. The planar process of photolithography then \"integrates\" unipolar transistors, capacitors, diodes, and resistors onto the wafer to build a matrix of metal\u2013oxide\u2013semiconductor (MOS) transistors. The MOS transistor is the primary component in \"integrated circuit chips\".\nOriginally, integrated circuit chips had their function set during manufacturing. During the 1960s, controlling the electrical flow migrated to programming a matrix of read-only memory (ROM). The matrix resembled a two-dimensional array of fuses. The process to embed instructions onto the matrix was to burn out the unneeded connections. There were so many connections, firmware programmers wrote a \"computer program\" on another chip to oversee the burning. The technology became known as Programmable ROM. In 1971, Intel installed the computer program onto the chip and named it the Intel 4004 microprocessor.\nThe terms \"microprocessor\" and central processing unit (CPU) are now used interchangeably. However, CPUs predate microprocessors. For example, the IBM System/360 (1964) had a CPU made from circuit boards containing discrete components on ceramic substrates.\nx86 series.\nIn 1978, the modern software development environment began when Intel upgraded the Intel 8080 to the Intel 8086. Intel simplified the Intel 8086 to manufacture the cheaper Intel 8088. IBM embraced the Intel 8088 when they entered the personal computer market (1981). As consumer demand for personal computers increased, so did Intel's microprocessor development. The succession of development is known as the x86 series. The x86 assembly language is a family of backward-compatible machine instructions. Machine instructions created in earlier microprocessors were retained throughout microprocessor upgrades. This enabled consumers to purchase new computers without having to purchase new application software. The major categories of instructions are:\nChanging programming environment.\nVLSI circuits enabled the programming environment to advance from a computer terminal (until the 1990s) to a graphical user interface (GUI) computer. Computer terminals limited programmers to a single shell running in a command-line environment. During the 1970s, full-screen source code editing became possible through a text-based user interface. Regardless of the technology available, the goal is to program in a programming language.\nProgramming paradigms and languages.\nProgramming language features exist to provide building blocks to be combined to express programming ideals. Ideally, a programming language should:\nThe programming style of a programming language to provide these building blocks may be categorized into programming paradigms. For example, different paradigms may differentiate:\nEach of these programming styles has contributed to the synthesis of different \"programming languages\".\nA \"programming language\" is a set of keywords, symbols, identifiers, and rules by which programmers can communicate instructions to the computer. They follow a set of rules called a syntax.\n\"Programming languages\" get their basis from formal languages. The purpose of defining a solution in terms of its \"formal language\" is to generate an algorithm to solve the underlining problem. An \"algorithm\" is a sequence of simple instructions that solve a problem.\nGenerations of programming language.\nThe evolution of programming languages began when the EDSAC (1949) used the first stored computer program in its von Neumann architecture. Programming the EDSAC was in the first generation of programming language.\n* The basic structure of an assembly language statement is a label, operation, operand, and comment.\n* \"Labels\" allow the programmer to work with variable names. The assembler will later translate labels into physical memory addresses.\n* \"Operations\" allow the programmer to work with mnemonics. The assembler will later translate mnemonics into instruction numbers.\n* \"Operands\" tell the assembler which data the operation will process.\n* \"Comments\" allow the programmer to articulate a narrative because the instructions alone are vague.\n The key characteristic of an assembly language program is it forms a one-to-one mapping to its corresponding machine language target.\nImperative languages.\n\"Imperative languages\" specify a sequential algorithm using declarations, expressions, and statements:\nFortran.\nFORTRAN (1958) was unveiled as \"The IBM Mathematical FORmula TRANslating system\". It was designed for scientific calculations, without string handling facilities. Along with declarations, expressions, and statements, it supported:\nIt succeeded because:\nHowever, non-IBM vendors also wrote Fortran compilers, but with a syntax that would likely fail IBM's compiler. The American National Standards Institute (ANSI) developed the first Fortran standard in 1966. In 1978, Fortran 77 became the standard until 1991. Fortran 90 supports:\nCOBOL.\nCOBOL (1959) stands for \"COmmon Business Oriented Language\". Fortran manipulated symbols. It was soon realized that symbols did not need to be numbers, so strings were introduced. The US Department of Defense influenced COBOL's development, with Grace Hopper being a major contributor. The statements were English-like and verbose. The goal was to design a language so managers could read the programs. However, the lack of structured statements hindered this goal.\nCOBOL's development was tightly controlled, so dialects did not emerge to require ANSI standards. As a consequence, it was not changed for 15 years until 1974. The 1990s version did make consequential changes, like object-oriented programming.\nAlgol.\nALGOL (1960) stands for \"ALGOrithmic Language\". It had a profound influence on programming language design. Emerging from a committee of European and American programming language experts, it used standard mathematical notation and had a readable, structured design. Algol was first to define its syntax using the Backus\u2013Naur form. This led to syntax-directed compilers. It added features like:\nAlgol's direct descendants include Pascal, Modula-2, Ada, Delphi and Oberon on one branch. On another branch the descendants include C, C++ and Java.\nBasic.\nBASIC (1964) stands for \"Beginner's All-Purpose Symbolic Instruction Code\". It was developed at Dartmouth College for all of their students to learn. If a student did not go on to a more powerful language, the student would still remember Basic. A Basic interpreter was installed in the microcomputers manufactured in the late 1970s. As the microcomputer industry grew, so did the language.\nBasic pioneered the interactive session. It offered operating system commands within its environment:\nHowever, the Basic syntax was too simple for large programs. Recent dialects added structure and object-oriented extensions. Microsoft's Visual Basic is still widely used and produces a graphical user interface.\nC.\nC programming language (1973) got its name because the language BCPL was replaced with B, and AT&amp;T Bell Labs called the next version \"C\". Its purpose was to write the UNIX operating system. C is a relatively small language, making it easy to write compilers. Its growth mirrored the hardware growth in the 1980s. Its growth also was because it has the facilities of assembly language, but it uses a high-level syntax. It added advanced features like:\n\"C\" allows the programmer to control which region of memory data is to be stored. Global variables and static variables require the fewest clock cycles to store. The stack is automatically used for the standard variable declarations. Heap memory is returned to a pointer variable from the codice_4 function.\n* The global and static data region is technically two regions. One region is called the \"initialized data segment\", where variables declared with default values are stored. The other region is called the \"block started by segment\", where variables declared without default values are stored.\n* Variables stored in the \"global and static data\" region have their addresses set at compile time. They retain their values throughout the life of the process.\n* The global and static region stores the \"global variables\" that are declared on top of (outside) the codice_5 function. Global variables are visible to codice_5 and every other function in the source code.\n On the other hand, variable declarations inside of codice_5, other functions, or within codice_8 codice_9 block delimiters are \"local variables\". Local variables also include \"formal parameter variables\". Parameter variables are enclosed within the parenthesis of a function definition. Parameters provide an interface to the function.\n* \"Local variables\" declared using the codice_10 prefix are also stored in the \"global and static data\" region. Unlike global variables, static variables are only visible within the function or block. Static variables always retain their value. An example usage would be the function codice_11\n* \"Local variables\" declared without the codice_10 prefix, including formal parameter variables, are called \"automatic variables\" and are stored in the stack. They are visible inside the function or block and lose their scope upon exiting the function or block.\n* \"C\" provides the codice_4 library function to allocate heap memory. Populating the heap with data is an additional copy function. Variables stored in the heap are economically passed to functions using pointers. Without pointers, the entire block of data would have to be passed to the function via the stack.\nC++.\nIn the 1970s, software engineers needed language support to break large projects down into modules. One obvious feature was to decompose large projects \"physically\" into separate files. A less obvious feature was to decompose large projects \"logically\" into abstract data types. At the time, languages supported concrete (scalar) datatypes like integer numbers, floating-point numbers, and strings of characters. Abstract datatypes are structures of concrete datatypes, with a new name assigned. For example, a list of integers could be called codice_14.\nIn object-oriented jargon, abstract datatypes are called classes. However, a \"class\" is only a definition; no memory is allocated. When memory is allocated to a class and bound to an identifier, it is called an object.\nObject-oriented imperative languages developed by combining the need for classes and the need for safe functional programming. A function, in an object-oriented language, is assigned to a class. An assigned function is then referred to as a method, member function, or operation. \"Object-oriented programming\" is executing \"operations\" on \"objects\".\n\"Object-oriented languages\" support a syntax to model subset/superset relationships. In set theory, an element of a subset inherits all the attributes contained in the superset. For example, a student is a person. Therefore, the set of students is a subset of the set of persons. As a result, students inherit all the attributes common to all persons. Additionally, students have unique attributes that other people do not have. \"Object-oriented languages\" model \"subset/superset\" relationships using inheritance. \"Object-oriented programming\" became the dominant language paradigm by the late 1990s.\nC++ (1985) was originally called \"C with Classes\". It was designed to expand C's capabilities by adding the object-oriented facilities of the language Simula.\nAn object-oriented module is composed of two files. The definitions file is called the header file. Here is a C++ \"header file\" for the \"GRADE class\" in a simple school application:\n// grade.h\n// Used to allow multiple source files to include\n// this header file without duplication errors.\nclass GRADE {\npublic:\n // This is the constructor operation.\n GRADE ( const char letter );\n // This is a class variable.\n char letter;\n // This is a member operation.\n int grade_numeric( const char letter );\n // This is a class variable.\n int numeric;\nA constructor operation is a function with the same name as the class name. It is executed when the calling operation executes the codice_15 statement.\nA module's other file is the source file. Here is a C++ source file for the \"GRADE class\" in a simple school application:\n// grade.cpp\nGRADE::GRADE( const char letter )\n // Reference the object using the keyword 'this'.\n this-&gt;letter = letter;\n // This is Temporal Cohesion\n this-&gt;numeric = grade_numeric( letter );\nint GRADE::grade_numeric( const char letter )\n if ( ( letter == 'A' || letter == 'a' ) )\n return 4;\n else\n if ( ( letter == 'B' || letter == 'b' ) )\n return 3;\n else\n if ( ( letter == 'C' || letter == 'c' ) )\n return 2;\n else\n if ( ( letter == 'D' || letter == 'd' ) )\n return 1;\n else\n if ( ( letter == 'F' || letter == 'f' ) )\n return 0;\n else\n return -1;\nHere is a C++ \"header file\" for the \"PERSON class\" in a simple school application:\n// person.h\nclass PERSON {\npublic:\n PERSON ( const char *name );\n const char *name;\nHere is a C++ \"source file\" for the \"PERSON class\" in a simple school application:\n// person.cpp\nPERSON::PERSON ( const char *name )\n this-&gt;name = name;\nHere is a C++ \"header file\" for the \"STUDENT class\" in a simple school application:\n// student.h\n// A STUDENT is a subset of PERSON.\nclass STUDENT : public PERSON{\npublic:\n STUDENT ( const char *name );\n GRADE *grade;\nHere is a C++ \"source file\" for the \"STUDENT class\" in a simple school application:\n// student.cpp\nSTUDENT::STUDENT ( const char *name ):\n // Execute the constructor of the PERSON superclass.\n PERSON( name )\n // Nothing else to do.\nHere is a driver program for demonstration:\n// student_dvr.cpp\nint main( void )\n STUDENT *student = new STUDENT( \"The Student\" );\n student-&gt;grade = new GRADE( 'a' );\n std::cout\n // Notice student inherits PERSON's name\n \u00ab student-&gt;name\n \u00ab \": Numeric grade = \"\n \u00ab student-&gt;grade-&gt;numeric\n \u00ab \"\\n\";\n return 0;\nHere is a makefile to compile everything:\nall: student_dvr\nclean:\n rm student_dvr *.o\nstudent_dvr: student_dvr.cpp grade.o student.o person.o\n c++ student_dvr.cpp grade.o student.o person.o -o student_dvr\ngrade.o: grade.cpp grade.h\n c++ -c grade.cpp\nstudent.o: student.cpp student.h\n c++ -c student.cpp\nperson.o: person.cpp person.h\n c++ -c person.cpp\nDeclarative languages.\n\"Imperative languages\" have one major criticism: assigning an expression to a \"non-local\" variable may produce an unintended side effect. Declarative languages generally omit the assignment statement and the control flow. They describe \"what\" computation should be performed and not \"how\" to compute it. Two broad categories of declarative languages are functional languages and logical languages.\nThe principle behind a \"functional language\" is to use lambda calculus as a guide for a well defined semantic. In mathematics, a function is a rule that maps elements from an \"expression\" to a range of \"values\". Consider the function:\ncodice_16\nThe \"expression\" codice_17 is mapped by the function codice_18 to a range of \"values\". One \"value\" happens to be 20. This occurs when x is 2. So, the application of the function is mathematically written as:\ncodice_19\nA \"functional language\" compiler will not store this value in a variable. Instead, it will \"push\" the value onto the computer's stack before setting the program counter back to the calling function. The calling function will then \"pop\" the value from the stack.\n\"Imperative languages\" do support functions. Therefore, \"functional programming\" can be achieved in an imperative language, if the programmer uses discipline. However, a \"functional language\" will force this discipline onto the programmer through its syntax. Functional languages have a syntax tailored to emphasize the \"what\".\nA functional program is developed with a set of primitive functions followed by a single driver function. Consider the snippet:\ncodice_20\ncodice_21\ncodice_22\ncodice_23\ncodice_9\nThe primitives are codice_25 and codice_26. The driver function is codice_27. Executing:\ncodice_28 will output 6.\n\"Functional languages\" are used in computer science research to explore new language features. Moreover, their lack of side-effects have made them popular in parallel programming and concurrent programming. However, application developers prefer the object-oriented features of \"imperative languages\".\nLisp.\nLisp (1958) stands for \"LISt Processor\". It is tailored to process lists. A full structure of the data is formed by building lists of lists. In memory, a tree data structure is built. Internally, the tree structure lends nicely for recursive functions. The syntax to build a tree is to enclose the space-separated elements within parenthesis. The following is a list of three elements. The first two elements are themselves lists of two elements:\ncodice_29\nLisp has functions to extract and reconstruct elements. The function codice_30 returns a list containing the first element in the list. The function codice_31 returns a list containing everything but the first element. The function codice_32 returns a list that is the concatenation of other lists. Therefore, the following expression will return the list codice_33:\ncodice_34\nOne drawback of Lisp is when many functions are nested, the parentheses may look confusing. Modern Lisp environments help ensure parenthesis match. As an aside, Lisp does support the \"imperative language\" operations of the assignment statement and goto loops. Also, \"Lisp\" is not concerned with the datatype of the elements at compile time. Instead, it assigns (and may reassign) the datatypes at runtime. Assigning the datatype at runtime is called dynamic binding. Whereas dynamic binding increases the language's flexibility, programming errors may linger until late in the software development process.\nWriting large, reliable, and readable Lisp programs requires forethought. If properly planned, the program may be much shorter than an equivalent \"imperative language\" program. \"Lisp\" is widely used in artificial intelligence. However, its usage has been accepted only because it has \"imperative language\" operations, making unintended side-effects possible.\nML.\nML (1973) stands for \"Meta Language\". ML checks to make sure only data of the same type are compared with one another. For example, this function has one input parameter (an integer) and returns an integer:\n\"ML\" is not parenthesis-eccentric like \"Lisp\". The following is an application of codice_18:\n times_10 2\nIt returns \"20 : int\". (Both the results and the datatype are returned.)\nLike \"Lisp\", \"ML\" is tailored to process lists. Unlike \"Lisp\", each element is the same datatype. Moreover, \"ML\" assigns the datatype of an element at compile time. Assigning the datatype at compile time is called static binding. Static binding increases reliability because the compiler checks the context of variables before they are used.\nProlog.\nProlog (1972) stands for \"PROgramming in LOGic\". It is a logic programming language, based on formal logic. The language was developed by Alain Colmerauer and Philippe Roussel in Marseille, France. It is an implementation of Selective Linear Definite clause resolution, pioneered by Robert Kowalski and others at the University of Edinburgh.\nThe building blocks of a Prolog program are \"facts\" and \"rules\". Here is a simple example:\ncat(tom). % tom is a cat\nmouse(jerry). % jerry is a mouse\nanimal(X) :- cat(X). % each cat is an animal\nanimal(X) :- mouse(X). % each mouse is an animal\nbig(X) :- cat(X). % each cat is big\nsmall(X) :- mouse(X). % each mouse is small\neat(X,Y) :- mouse(X), cheese(Y). % each mouse eats each cheese\neat(X,Y) :- big(X), small(Y). % each big animal eats each small animal\nAfter all the facts and rules are entered, then a question can be asked:\n Will Tom eat Jerry?\n?- eat(tom,jerry).\ntrue\nThe following example shows how Prolog will convert a letter grade to its numeric value:\nnumeric_grade('A', 4).\nnumeric_grade('B', 3).\nnumeric_grade('C', 2).\nnumeric_grade('D', 1).\nnumeric_grade('F', 0).\nnumeric_grade(X, -1) :- not X = 'A', not X = 'B', not X = 'C', not X = 'D', not X = 'F'.\ngrade('The Student', 'A').\n?- grade('The Student', X), numeric_grade(X, Y).\nX = 'A',\nY = 4\nHere is a comprehensive example:\n1) All dragons billow fire, or equivalently, a thing billows fire if the thing is a dragon:\nbillows_fire(X) :-\n is_a_dragon(X).\n2) A creature billows fire if one of its parents billows fire:\nbillows_fire(X) :-\n is_a_creature(X),\n is_a_parent_of(Y,X),\n billows_fire(Y).\n3) A thing X is a parent of a thing Y if X is the mother of Y or X is the father of Y:\nis_a_parent_of(X, Y):- is_the_mother_of(X, Y).\nis_a_parent_of(X, Y):- is_the_father_of(X, Y).\n4) A thing is a creature if the thing is a dragon:\nis_a_creature(X) :-\n is_a_dragon(X).\n5) Norberta is a dragon, and Puff is a creature. Norberta is the mother of Puff.\nis_a_dragon(norberta).\nis_a_creature(puff).\nis_the_mother_of(norberta, puff).\nRule (2) is a recursive (inductive) definition. It can be understood declaratively, without the need to understand how it is executed.\nRule (3) shows how functions are represented by using relations. Here, the mother and father functions ensure that every individual has only one mother and only one father.\nProlog is an untyped language. Nonetheless, inheritance can be represented by using predicates. Rule (4) asserts that a creature is a superclass of a dragon.\nQuestions are answered using backward reasoning. Given the question:\n ?- billows_fire(X).\nProlog generates two answers :\nX = norberta\nX = puff\nPractical applications for Prolog are knowledge representation and problem solving in artificial intelligence.\nObject-oriented programming.\nObject-oriented programming is a programming method to execute operations (functions) on objects. The basic idea is to group the characteristics of a phenomenon into an object container and give the container a name. The \"operations\" on the phenomenon are also grouped into the container. \"Object-oriented programming\" developed by combining the need for containers and the need for safe functional programming. This programming method need not be confined to an \"object-oriented language\". In an object-oriented language, an object container is called a class. In a non-object-oriented language, a data structure (which is also known as a record) may become an object container. To turn a data structure into an object container, operations need to be written specifically for the structure. The resulting structure is called an abstract datatype. However, inheritance will be missing. Nonetheless, this shortcoming can be overcome.\nHere is a C programming language \"header file\" for the \"GRADE abstract datatype\" in a simple school application:\n/* grade.h */\n/* Used to allow multiple source files to include */\n/* this header file without duplication errors. */\ntypedef struct\n char letter;\n} GRADE;\n/* Constructor */\nGRADE *grade_new( char letter );\nint grade_numeric( char letter );\nThe codice_36 function performs the same algorithm as the C++ constructor operation.\nHere is a C programming language \"source file\" for the \"GRADE abstract datatype\" in a simple school application:\n/* grade.c */\nGRADE *grade_new( char letter )\n GRADE *grade;\n /* Allocate heap memory */\n if ( ! ( grade = calloc( 1, sizeof ( GRADE ) ) ) )\n fprintf(stderr,\n \"ERROR in %s/%s/%d: calloc() returned empty.\\n\",\n __FILE__,\n __FUNCTION__,\n __LINE__ );\n exit( 1 );\n grade-&gt;letter = letter;\n return grade;\nint grade_numeric( char letter )\n if ( ( letter == 'A' || letter == 'a' ) )\n return 4;\n else\n if ( ( letter == 'B' || letter == 'b' ) )\n return 3;\n else\n if ( ( letter == 'C' || letter == 'c' ) )\n return 2;\n else\n if ( ( letter == 'D' || letter == 'd' ) )\n return 1;\n else\n if ( ( letter == 'F' || letter == 'f' ) )\n return 0;\n else\n return -1;\nIn the constructor, the function codice_37 is used instead of codice_4 because each memory cell will be set to zero.\nHere is a C programming language \"header file\" for the \"PERSON abstract datatype\" in a simple school application:\n/* person.h */\ntypedef struct\n char *name;\n} PERSON;\n/* Constructor */\nPERSON *person_new( char *name );\nHere is a C programming language \"source file\" for the \"PERSON abstract datatype\" in a simple school application:\n/* person.c */\nPERSON *person_new( char *name )\n PERSON *person;\n if ( ! ( person = calloc( 1, sizeof ( PERSON ) ) ) )\n fprintf(stderr,\n \"ERROR in %s/%s/%d: calloc() returned empty.\\n\",\n __FILE__,\n __FUNCTION__,\n __LINE__ );\n exit( 1 );\n person-&gt;name = name;\n return person;\nHere is a C programming language \"header file\" for the \"STUDENT abstract datatype\" in a simple school application:\n/* student.h */\ntypedef struct\n /* A STUDENT is a subset of PERSON. */\n PERSON *person;\n GRADE *grade;\n} STUDENT;\n/* Constructor */\nSTUDENT *student_new( char *name );\nHere is a C programming language \"source file\" for the \"STUDENT abstract datatype\" in a simple school application:\n/* student.c */\nSTUDENT *student_new( char *name )\n STUDENT *student;\n if ( ! ( student = calloc( 1, sizeof ( STUDENT ) ) ) )\n fprintf(stderr,\n \"ERROR in %s/%s/%d: calloc() returned empty.\\n\",\n __FILE__,\n __FUNCTION__,\n __LINE__ );\n exit( 1 );\n /* Execute the constructor of the PERSON superclass. */\n student-&gt;person = person_new( name );\n return student;\nHere is a driver program for demonstration:\n/* student_dvr.c */\nint main( void )\n STUDENT *student = student_new( \"The Student\" );\n student-&gt;grade = grade_new( 'a' );\n printf( \"%s: Numeric grade = %d\\n\",\n /* Whereas a subset exists, inheritance does not. */\n student-&gt;person-&gt;name,\n /* Functional programming is executing functions just-in-time (JIT) */\n grade_numeric( student-&gt;grade-&gt;letter ) );\n return 0;\nHere is a makefile to compile everything:\nall: student_dvr\nclean:\n rm student_dvr *.o\nstudent_dvr: student_dvr.c grade.o student.o person.o\n gcc student_dvr.c grade.o student.o person.o -o student_dvr\ngrade.o: grade.c grade.h\n gcc -c grade.c\nstudent.o: student.c student.h\n gcc -c student.c\nperson.o: person.c person.h\n gcc -c person.c\nThe formal strategy to build object-oriented objects is to:\nFor example:\nSyntax and semantics.\nThe syntax of a \"computer program\" is a list of production rules which form its grammar. A programming language's grammar correctly places its declarations, expressions, and statements. Complementing the \"syntax\" of a language are its semantics. The \"semantics\" describe the meanings attached to various syntactic constructs. A syntactic construct may need a semantic description because a production rule may have an invalid interpretation. Also, different languages might have the same syntax; however, their behaviors may be different.\nThe syntax of a language is formally described by listing the production rules. Whereas the syntax of a natural language is extremely complicated, a subset of the English language can have this production rule listing:\nThe words in bold-face are known as \"non-terminals\". The words in 'single quotes' are known as \"terminals\".\nFrom this production rule listing, complete sentences may be formed using a series of replacements. The process is to replace \"non-terminals\" with either a valid \"non-terminal\" or a valid \"terminal\". The replacement process repeats until only \"terminals\" remain. One valid sentence is:\nHowever, another combination results in an invalid sentence:\nTherefore, a \"semantic\" is necessary to correctly describe the meaning of an \"eat\" activity.\nOne \"production rule\" listing method is called the Backus\u2013Naur form (BNF). BNF describes the syntax of a language and itself has a \"syntax\". This recursive definition is an example of a metalanguage. The \"syntax\" of BNF includes:\nUsing BNF, a subset of the English language can have this \"production rule\" listing:\n&lt;sentence&gt; ::= &lt;noun-phrase&gt;&lt;verb-phrase&gt;\n&lt;noun-phrase&gt; ::= &lt;article&gt;&lt;adjective&gt;&lt;noun&gt;\n&lt;verb-phrase&gt; ::= &lt;verb&gt;&lt;noun-phrase&gt;\n&lt;article&gt; ::= the\n&lt;adjective&gt; ::= big | small\n&lt;noun&gt; ::= cat | mouse\n&lt;verb&gt; ::= eats\nUsing BNF, a signed-integer has the \"production rule\" listing:\n&lt;signed-integer&gt; ::= &lt;sign&gt;&lt;integer&gt;\n&lt;sign&gt; ::= + | -\n&lt;integer&gt; ::= &lt;digit&gt; | &lt;digit&gt;&lt;integer&gt;\n&lt;digit&gt; ::= 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9\nNotice the recursive production rule:\n&lt;integer&gt; ::= &lt;digit&gt; | &lt;digit&gt;&lt;integer&gt;\nThis allows for an infinite number of possibilities. Therefore, a \"semantic\" is necessary to describe a limitation of the number of digits.\nNotice the leading zero possibility in the production rules:\n&lt;integer&gt; ::= &lt;digit&gt; | &lt;digit&gt;&lt;integer&gt;\n&lt;digit&gt; ::= 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9\nTherefore, a \"semantic\" is necessary to describe that leading zeros need to be ignored.\nTwo formal methods are available to describe \"semantics\". They are denotational semantics and axiomatic semantics.\nSoftware engineering and computer programming.\nSoftware engineering is a variety of techniques to produce quality \"computer programs\". Computer programming is the process of writing or editing source code. In a formal environment, a systems analyst will gather information from managers about all the organization's processes to automate. This professional then prepares a detailed plan for the new or modified system. The plan is analogous to an architect's blueprint.\nPerformance objectives.\nThe systems analyst has the objective to deliver the right information to the right person at the right time. The critical factors to achieve this objective are:\nCost objectives.\nAchieving performance objectives should be balanced with all of the costs, including:\nApplying a systems development process will mitigate the axiom: the later in the process an error is detected, the more expensive it is to correct.\nWaterfall model.\nThe waterfall model is an implementation of a \"systems development process\". As the \"waterfall\" label implies, the basic phases overlap each other:\nComputer programmer.\nA computer programmer is a specialist responsible for writing or modifying the source code to implement the detailed plan. A programming team is likely to be needed because most systems are too large to be completed by a single programmer. However, adding programmers to a project may not shorten the completion time. Instead, it may lower the quality of the system. To be effective, program modules need to be defined and distributed to team members. Also, team members must interact with one another in a meaningful and effective way.\nComputer programmers may be programming in the small: programming within a single module. Chances are a module will execute modules located in other source code files. Therefore, computer programmers may be programming in the large: programming modules so they will effectively couple with each other. Programming-in-the-large includes contributing to the application programming interface (API).\nProgram modules.\nModular programming is a technique to refine \"imperative language\" programs. Refined programs may reduce the software size, separate responsibilities, and thereby mitigate software aging. A \"program module\" is a sequence of statements that are bounded within a block and together identified by a name. Modules have a \"function\", \"context\", and \"logic\":\nThe module's name should be derived first by its \"function\", then by its \"context\". Its \"logic\" should not be part of the name. For example, codice_43 or codice_44 are appropriate module names. However, codice_45 is not.\nThe degree of interaction \"within\" a module is its level of cohesion. \"Cohesion\" is a judgment of the relationship between a module's name and its \"function\". The degree of interaction \"between\" modules is the level of coupling. \"Coupling\" is a judgement of the relationship between a module's \"context\" and the elements being performed upon.\nCohesion.\nThe levels of cohesion from worst to best are:\nCoupling.\nThe levels of coupling from worst to best are:\nData flow analysis.\n\"Data flow analysis\" is a design method used to achieve modules of \"functional cohesion\" and \"data coupling\". The input to the method is a data-flow diagram. A data-flow diagram is a set of ovals representing modules. Each module's name is displayed inside its oval. Modules may be at the executable level or the function level.\nThe diagram also has arrows connecting modules to each other. Arrows pointing into modules represent a set of inputs. Each module should have only one arrow pointing out from it to represent its single output object. (Optionally, an additional exception arrow points out.) A daisy chain of ovals will convey an entire algorithm. The input modules should start the diagram. The input modules should connect to the transform modules. The transform modules should connect to the output modules.\nFunctional categories.\n\"Computer programs\" may be categorized along functional lines. The main functional categories are application software and system software. System software includes the operating system, which couples computer hardware with application software. The purpose of the operating system is to provide an environment where application software executes in a convenient and efficient manner. Both application software and system software execute utility programs. At the hardware level, a microcode program controls the circuits throughout the central processing unit.\nApplication software.\nApplication software is the key to unlocking the potential of the computer system. Enterprise application software bundles accounting, personnel, customer, and vendor applications. Examples include enterprise resource planning, customer relationship management, and supply chain management software.\nEnterprise applications may be developed in-house as a one-of-a-kind proprietary software. Alternatively, they may be purchased as off-the-shelf software. Purchased software may be modified to provide custom software. If the application is customized, then either the company's resources are used or the resources are outsourced. Outsourced software development may be from the original software vendor or a third-party developer.\nThe potential advantages of in-house software are features and reports may be developed exactly to specification. Management may also be involved in the development process and offer a level of control. Management may decide to counteract a competitor's new initiative or implement a customer or vendor requirement. A merger or acquisition may necessitate enterprise software changes. The potential disadvantages of in-house software are time and resource costs may be extensive. Furthermore, risks concerning features and performance may be looming.\nThe potential advantages of off-the-shelf software are upfront costs are identifiable, the basic needs should be fulfilled, and its performance and reliability have a track record. The potential disadvantages of off-the-shelf software are it may have unnecessary features that confuse end users, it may lack features the enterprise needs, and the data flow may not match the enterprise's work processes.\nApplication service provider.\nOne approach to economically obtaining a customized enterprise application is through an application service provider. Specialty companies provide hardware, custom software, and end-user support. They may speed the development of new applications because they possess skilled information system staff. The biggest advantage is it frees in-house resources from staffing and managing complex computer projects. Many application service providers target small, fast-growing companies with limited information system resources. On the other hand, larger companies with major systems will likely have their technical infrastructure in place. One risk is having to trust an external organization with sensitive information. Another risk is having to trust the provider's infrastructure reliability.\nOperating system.\nAn operating system is the low-level software that supports a computer's basic functions, such as scheduling processes and controlling peripherals.\nIn the 1950s, the programmer, who was also the operator, would write a program and run it. After the program finished executing, the output may have been printed, or it may have been punched onto paper tape or cards for later processing. More often than not the program did not work. The programmer then looked at the console lights and fiddled with the console switches. If less fortunate, a memory printout was made for further study. In the 1960s, programmers reduced the amount of wasted time by automating the operator's job. A program called an \"operating system\" was kept in the computer at all times.\nThe term \"operating system\" may refer to two levels of software. The operating system may refer to the kernel program that manages the processes, memory, and devices. More broadly, the operating system may refer to the entire package of the central software. The package includes a kernel program, command-line interpreter, graphical user interface, utility programs, and editor.\nKernel Program.\nThe kernel's main purpose is to manage the limited resources of a computer:\n* When the kernel initially loads an executable into memory, it divides the address space logically into regions. The kernel maintains a master-region table and many per-process-region (pregion) tables\u2014one for each running process. These tables constitute the virtual address space. The master-region table is used to determine where its contents are located in physical memory. The pregion tables allow each process to have its own program (text) pregion, data pregion, and stack pregion.\n*The program pregion stores machine instructions. Since machine instructions do not change, the program pregion may be shared by many processes of the same executable.\n* To save time and memory, the kernel may load only blocks of execution instructions from the disk drive, not the entire execution file completely.\n*The kernel is responsible for translating virtual addresses into physical addresses. The kernel may request data from the memory controller and, instead, receive a page fault. If so, the kernel accesses the memory management unit to populate the physical data region and translate the address.\n* The kernel allocates memory from the \"heap\" upon request by a process. When the process is finished with the memory, the process may request for it to be freed. If the process exits without requesting all allocated memory to be freed, then the kernel performs garbage collection to free the memory.\n* The kernel also ensures that a process only accesses its own memory, and not that of the kernel or other processes.\nOriginally, operating systems were programmed in assembly; however, modern operating systems are typically written in higher-level languages like C, Objective-C, and Swift.\nUtility program.\nA utility is a program that aids system administration and software execution. An operating system typically provides utilities to check hardware such as storage, memory, speakers, and printers. A utility may optimize the performance of a storage device. System utilities monitor hardware and network performance and may trigger an alert when a metric is outside the nominal range. A utility may compress files to reduce storage space and network transmission time. A utility may sort and merge data sets or detect computer viruses.\nMicrocode program.\nA microcode program is the bottom-level interpreter that controls the datapath of software-driven computers.\n(Advances in hardware have migrated these operations to hardware execution circuits.) Microcode instructions allow the programmer to more easily implement the digital logic level\u2014the computer's real hardware. The digital logic level is the boundary between computer science and computer engineering.\nA logic gate is a tiny transistor that can return one of two signals: on or off.\nThese five gates form the building blocks of binary algebra\u2014the digital logic functions of the computer.\nMicrocode instructions are mnemonics programmers may use to execute digital logic functions instead of forming them in binary algebra. They are stored in a central processing unit's (CPU) control store.\nThese hardware-level instructions move data throughout the data path.\nThe micro-instruction cycle begins when the microsequencer uses its microprogram counter to \"fetch\" the next machine instruction from random-access memory. The next step is to \"decode\" the machine instruction by selecting the proper output line to the hardware module.\nThe final step is to \"execute\" the instruction using the hardware module's set of gates.\nInstructions to perform arithmetic are passed through an arithmetic logic unit (ALU). The ALU has circuits to perform elementary operations to add, shift, and compare integers. By combining and looping the elementary operations through the ALU, the CPU performs its complex arithmetic.\nMicrocode instructions move data between the CPU and the memory controller. Memory controller microcode instructions manipulate two registers. The memory address register is used to access each memory cell's address. The memory data register is used to set and read each cell's contents.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "5785", "revid": "199747", "url": "https://en.wikipedia.org/wiki?curid=5785", "title": "Crime", "text": "Unlawful act punishable by an authority\nIn ordinary language, a crime is an unlawful act punishable by a state or other authority. The term \"crime\" does not, in modern criminal law, have any simple and universally accepted definition, though statutory definitions have been provided for certain purposes. The most popular view is that crime is a category created by law; in other words, something is a crime if declared as such by the relevant and applicable law. One proposed definition is that a crime or offence (or criminal offence) is an act harmful not only to some individual but also to a community, society, or the state (\"a public wrong\"). Such acts are forbidden and punishable by law.\nThe notion that acts such as murder, rape, and theft are to be prohibited exists worldwide. What precisely is a criminal offence is defined by the criminal law of each relevant jurisdiction. While many have a catalogue of crimes called the criminal code, in some common law nations no such comprehensive statute exists.\nThe state (government) has the power to severely restrict one's liberty for committing certain crimes. In most modern societies, there are procedures to which investigations and trials must adhere. If found guilty, an offender may be sentenced to a form of reparation such as a community sentence, or, depending on the nature of their offence, to undergo imprisonment, life imprisonment or, in some jurisdictions, death.\nUsually, to be classified as a crime, the \"act of doing something criminal\" (\"actus reus\") must\u00a0\u2013 with certain exceptions\u00a0\u2013 be accompanied by the \"intention to do something criminal\" (\"mens rea\").\nWhile every crime violates the law, not every violation of the law counts as a crime. Breaches of private law (torts and breaches of contract) are not automatically punished by the state, but can be enforced through civil procedure.\nDefinition.\nThe exact definition of crime is a philosophical issue without an agreed upon answer. Fields such as law, politics, sociology, and psychology define crime in different ways. Crimes may be variously considered as wrongs against individuals, against the community, or against the state. The criminality of an action is dependent on its context; acts of violence will be seen as crimes in many circumstances but as permissible or desirable in others. Crime was historically seen as a manifestation of evil, but this has been superseded by modern criminal theories.\nLegalism.\nLegal and political definitions of crime consider actions that are banned by authorities or punishable by law. Crime is defined by the criminal law of a given jurisdiction, including all actions that are subject to criminal procedure. There is no limit to what can be considered a crime in a legal system, so there may not be a unifying principle used to determine whether an action should be designated as a crime. From a legal perspective, crimes are generally wrong actions that are severe enough to warrant punishment that infringes on the perpetrator's liberties. \nEnglish criminal law and the related common law of Commonwealth countries can define offences that the courts alone have developed over the years, without any actual legislation: common law offences. The courts used the concept of \"malum in se\" to develop various common law offences.\nSociology.\nAs a sociological concept, crime is associated with actions that cause harm and violate social norms. Under this definition, crime is a type of social construct, and societal attitudes determine what is considered criminal. \nIn legal systems based on legal moralism, the predominant moral beliefs of society determine the legal definition as well as the social definition of crime. This system is less prominent in liberal democratic societies that prioritize individualism and multiculturalism over other moral beliefs.\nPaternalism defines crime not only as harm to others or to society, but also as harm to the self.\nPsychology.\nPsychological definitions consider the state of mind of perpetrators and their relationship with their environment. \nCriminal law.\nVirtually all countries in the 21st century have criminal law grounded in civil law, common law, Islamic law, or socialist law. Historically, criminal codes have often divided criminals by class or caste, prescribing different penalties depending on status. In some tribal societies, an entire clan is recognized as liable for a crime. In many cases, disputes over a crime in this system lead to a feud that lasts over several generations.\nCriminalization.\nThe state determines what actions are considered criminal in the scope of the law. Criminalization has significant human rights considerations, as it can infringe on rights of autonomy and subject individuals to unjust punishment.\nCriminal procedure.\nWhen the perpetrator of a crime is found guilty of the crime, the state delivers a sentence to determine the penalty for the crime.\nLiability.\nIf a crime is committed, the individual responsible is considered to be liable for the crime. For liability to exist, the individual must be capable of understanding the criminal process and the relevant authority must have legitimate power to establish what constitutes a crime.\nInternational criminal law.\nInternational criminal law typically addresses serious offenses, such as genocide, crimes against humanity, and war crimes. As with all international law, these laws are created through treaties and international custom, and they are defined through the consensus of the involved states. International crimes are not prosecuted through a standard legal system, though international organizations may establish tribunals to investigate and rule on egregious offenses such as genocide.\nTypes.\nWhite-collar crime.\nWhite-collar crime refers to financially motivated, nonviolent or non-directly violent crime committed by individuals, businesses and government professionals. The crimes are believed to be committed by middle- or upper-class individuals for financial gains. Typical white-collar crimes could include wage theft, fraud, bribery, Ponzi schemes, insider trading, labor racketeering, embezzlement, cybercrime, copyright infringement, money laundering, identity theft, and forgery.\nBlue-collar crime.\nBlue-collar crime is any crime committed by an individual from a lower social class as opposed to white-collar crime which is associated with crime committed by someone of a higher-level social class. These crimes are primarily small scale, for immediate beneficial gain to the individual or group involved in them. Examples of blue-collar crime include Narcotic production or distribution, sexual assault, theft, burglary, assault or murder.\nViolent crime.\nViolent crime is crime that involves an act of violent aggression against another person. Common examples of violent crime include homicide, assault, sexual assault, and robbery. Some violent crimes, such as assault, may be committed with the intention of causing harm. Other violent crimes, such as robbery, may use violence to further another goal. Violent crime is distinct from noncriminal types of violence, such as self-defense, use of force, and acts of war. Acts of violence are most often perceived as deviant when they are committed as an overreaction or a disproportionate response to provocation.\nProperty crime.\nCommon examples of property crime include burglary, theft, and vandalism.\nExamples of financial crimes include counterfeiting, smuggling, tax evasion, and bribery. The scope of financial crimes has expanded significantly since the beginning of modern economics in the 17th century. In occupational crime, the complexity and anonymity of computer systems may help criminal employees camouflage their operations. The victims of the most costly scams include banks, brokerage houses, insurance companies, and other large financial institutions.\nPublic order crime.\nPublic order crime is crime that violates a society's norms about what constitutes socially acceptable behavior. Examples of public order crimes include gambling, drug-related crime, public intoxication, prostitution, loitering, breach of the peace, panhandling, vagrancy, street harassment, excessive noise, and littering. Public order crime is associated with the broken windows theory, which posits that public order crimes increase the likelihood of other types of crime. Some public order crimes are considered victimless crimes in which no specific victim can be identified. Most nations in the Western world have moved toward decriminalization of victimless crimes in the modern era.\nAdultery, fornication, blasphemy, apostasy, and invoking the name of God are commonly recognized as crimes in theocratic societies or those heavily influenced by religion.\nPolitical crime.\nPolitical crime is crime that directly challenges or threatens the state. Examples of political crimes include subversion, rebellion, treason, mutiny, espionage, sedition, terrorism, riot, and unlawful assembly. Political crimes are associated with the political agenda of a given state, and they are necessarily applied against political dissidents. Due to their unique relation to the state, political crimes are often encouraged by one nation against another, and it is political alignment rather than the act itself that determines criminality. State crime that is carried out by the state to repress law-abiding citizens may also be considered political crime.\nInchoate crime.\nInchoate crime is crime that is carried out in anticipation of other illegal actions but does not cause direct harm. Examples of inchoate crimes include attempt and conspiracy. Inchoate crimes are defined by substantial action to facilitate a crime with the intention of the crime's occurrence. This is distinct from simple preparation for or consideration of criminal activity. They are unique in that renunciation of criminal intention is generally enough to absolve the perpetrator of criminal liability, as their actions are no longer facilitating a potential future crime.\nParticipants.\nCriminal.\nA criminal is an individual who commits a crime. What constitutes a criminal can vary depending on the context and the law, and it often carries a pejorative connotation. Criminals are often seen as embodying certain stereotypes or traits and are seen as a distinct type of person from law-abiding citizens. Despite this, no mental or physical trend is identifiable that differentiates criminals from non-criminals. Public response to criminals may be indignant or sympathetic. Indignant responses involve resentment and a desire for vengeance, wishing to see criminals removed from society or made to suffer for harm that they cause. Sympathetic responses involve compassion and understanding, seeking to rehabilitate or forgive criminals and absolve them of blame.\nIn the modern era, a criminal is a human being. Historically, from ancient times until the 19th century, many societies believed that non-human animals were capable of committing crimes, and prosecuted and punished them accordingly. Prosecutions of animals gradually dwindled during the 19th century, although a few were recorded as late as the 1910s and 1920s.\nVictim.\nA victim is an individual who has been treated unjustly or made to suffer. In the context of crime, the victim is the individual that is harmed by a violation of criminal law. Victimization is associated with post-traumatic stress and a long-term decrease in quality of life. Victimology is the study of victims, including their role in crime and how they are affected.\nSeveral factors affect an individual's likelihood of becoming a victim. Some factors may cause victims of crime to experience short-term or long-term \"repeat victimization\". Common long-term victims are those that have close relationships with the criminal, manifesting in crimes such as domestic violence, embezzlement, child abuse, and bullying. Repeat victimization may also occur when a potential victim appears to be a viable target, such as when indicating wealth in a less affluent region. Many of the traits that indicate criminality also indicate victimality; victims of crime are more likely to engage in unlawful behavior and respond to provocation. Overall demographic trends of victims and criminals are often similar, and victims are more likely to have engaged in criminal activities themselves.\nThe victims may only want compensation for the injuries suffered, while remaining indifferent to a possible desire for deterrence. Victims, on their own, may lack the economies of scale that could allow them to administer a penal system, let alone to collect any fines levied by a court.\nCrime statistics.\nInformation and statistics about crime in a given jurisdiction are collected as crime estimates, typically produced by national or international agencies. Methods to collect crime statistics may vary, even between jurisdictions within the same nation. Under-reporting of crime is common, particularly in developing nations, resulting in the dark figure of crime. Victim studies may be used to determine the frequency of crime in a given population. The gap to official statistics is generally smaller with higher severity of the crime. Clearance rate measures the fraction of crimes where a criminal charge has been laid or the responsible person convicted. Fear of crime can be distinct from crime probability.\nPublic perception.\nCrime is often a high priority political issue in developed countries, regardless of the country's crime rates. People that are not regularly exposed to crime most often experience it through media, including news reporting and crime fiction. Exposure of crime through news stories is associated with alarmism and inaccurate perceptions of crime trends. Selection bias in new stories about criminals significantly over-represent the prevalence of violent crime, and news reporting will often overemphasize a specific type of crime for a period of time, creating a \"crime wave\" effect. \nAs public opinion of morality changes over time, actions that were once condemned as crimes may be considered justifiable. \nCauses and correlates.\nCriminal behavior determinants include cost\u2013benefit analysis, opportunity or crime of passion. A person that commits a criminal act typically believes that its benefits will outweigh the risk of being caught and punished. Negative economic factors, such as unemployment and income inequality, can increase the incentive to commit crime, while severe punishments can deter crime in some cases.\nSocial factors similarly affect the likelihood of criminal activity. Crime corresponds heavily with social integration; groups that are less integrated with society or that are forcibly integrated with society are more likely to engage in crime. Involvement in the community, such as through a church, decreases the likelihood of crime, while associating with criminals increases the likelihood of becoming a criminal as well.\nThere is no known genetic cause of crime. Some genes have been found to affect traits that may incline individuals toward criminal activity, but no biological or physiological trait has been found to directly cause or compel criminal actions. One biological factor is the disparity between men and women, as men are significantly more likely to commit crimes than women in virtually all cultures. Crimes committed by men also tend to be more severe than those committed by women.\nCrime distribution shows a long tail with a small fraction of individuals re-offending many times due to high recidivism, while onset of crime at younger age predicts a longer criminal career.\nCriminal justice.\nNatural-law theory.\nJustifying the state's use of force to coerce compliance with its laws has proven a consistent theoretical problem. One of the earliest justifications involved the theory of natural law. This posits that the nature of the world or of human beings underlies the standards of morality or constructs them. Thomas Aquinas wrote in the 13th century: \"the rule and measure of human acts is the reason, which is the first principle of human acts\". He regarded people as by nature rational beings, concluding that it becomes morally appropriate that they should behave in a way that conforms to their rational nature. Thus, to be valid, any law must conform to natural law and coercing people to conform to that law is morally acceptable. In the 1760s, William Blackstone described the thesis:\n \"This law of nature, being co-eval with mankind and dictated by God himself, is of course superior in obligation to any other. It is binding over all the globe, in all countries, and at all times: no human laws are of any validity, if contrary to this; and such of them as are valid derive all their force, and all their authority, mediately or immediately, from this original.\"\nBut John Austin (1790\u20131859), an early positivist, applied utilitarianism in accepting the calculating nature of human beings and the existence of an objective morality. He denied that the legal validity of a norm depends on whether its content conforms to morality. Thus, in Austinian terms, a moral code can objectively determine what people ought to do, the law can embody whatever norms the legislature decrees to achieve social utility, but every individual remains free to choose what to do. Similarly, H.L.A. Hart saw the law as an aspect of sovereignty, with lawmakers able to adopt any law as a means to a moral end.\nThus the necessary and sufficient conditions for the truth of a proposition of law involved internal logic and consistency, and that the state's agents used state power with responsibility. Ronald Dworkin rejects Hart's theory and proposes that all individuals should expect the equal respect and concern of those who govern them as a fundamental political right. He offers a theory of compliance overlaid by a theory of deference (the citizen's duty to obey the law) and a theory of enforcement, which identifies the legitimate goals of enforcement and punishment. Legislation must conform to a theory of legitimacy, which describes the circumstances under which a particular person or group is entitled to make law, and a theory of legislative justice, which describes the law they are entitled or obliged to make.\nThere are natural-law theorists who have accepted the idea of enforcing the prevailing morality as a primary function of the law. This view entails the problem that it makes any moral criticism of the law impossible: if conformity with natural law forms a necessary condition for legal validity, all valid law must, by definition, count as morally just. Thus, on this line of reasoning, the legal validity of a norm necessarily entails its moral justice.\nCorrections and punishment.\nAuthorities may respond to crime through corrections, carrying out punishment as a means to censure the criminal act. Punishment is generally reserved for serious offenses. Individuals regularly engage in activity that could be scrutinized under criminal law but are deemed inconsequential. Retributive justice seeks to create a system of accountability and punish criminals in a way that knowingly causes suffering. This may arise out of a feeling that criminals deserve to suffer and that punishment should exist for its own sake. The existence of punishment also creates an effect of deterrence that discourages criminal action for fear of punishment. \nDeveloped nations are less likely to use physical punishments. Instead, they will impose financial penalties or imprisonment. In places with widespread corruption or limited rule of law, crime may be punished extralegally through mob rule and lynching.\nWhether a crime can be resolved through financial compensation varies depending on the culture and the specific context of the crime. Historically, many societies have absolved acts of homicide through compensation to the victim's relatives.\nCrime prevention.\nLaw enforcement.\nThe enforcement of criminal law seeks to prevent crime and sanction crimes that do occur. This enforcement is carried out by the state through law enforcement agencies, such as police, which are empowered to arrest suspected perpetrators of crimes. Law enforcement may focus on policing individual crimes, or it may focus on bringing down overall crime rates. One common variant, community policing, seeks to prevent crime by integrating police into the community and public life.\nIncreased policing was found to decrease crime through deterrence, with an estimated elasticity -0.67 for murder and -0.56 for robbery according to a 2013 study.\nRehabilitation.\nRehabilitation seeks to understand and mitigate the causes of a criminal's unlawful action to prevent recidivism. Different criminological theories propose different methods of rehabilitation, including strengthening social networks, reducing poverty, influencing values, and providing therapy for physical and mental ailments. Rehabilitative programs may include counseling or vocational education.\nCriminology.\nThe study of crime is called \"criminology\". Criminology addresses issues of social norms, social order, deviance, and violence. It includes the motivations and consequences of crime and its perpetrators, as well as preventative measures, either studying criminal acts on an individual level or the relationship of crime and the community. Due to the wide range of concepts associated with crime and the disagreement on a precise definition, the focus of criminology can vary considerably. Various theories within criminology provide different descriptions and explanations for crime, including social control theory, subcultural theory, strain theory, differential association, and labeling theory.\nSubfields of criminology and related fields of study include crime prevention, criminal law, crime statistics, anthropological criminology, criminal psychology, criminal sociology, criminal psychiatry, victimology, penology, and forensic science. Besides sociology, criminology is often associated with law and psychology.\nHistory.\nEarly history.\nRestrictions on behavior existed in all prehistoric societies. Crime in early human society was seen as a personal transgression and was addressed by the community as a whole rather than through a formal legal system, often through the use of custom, religion, or the rule of a tribal leader. Some of the oldest extant writings are ancient criminal codes. The earliest known criminal code was the Code of Ur-Nammu (c.\u20092100\u00a0\u2013 c.\u20092050 BC), and the first known criminal code that incorporated retaliatory justice was the Code of Hammurabi. The latter influenced the conception of crime across several civilizations over the following millennia.\nThe Romans systematized law and applied their system across the Roman Empire. The initial rules of Roman law regarded assaults as a matter of private compensation. The most significant Roman law concept involved \"dominion\". Most acts recognized as crimes in ancient societies, such as violence and theft, have persisted to the modern era. The criminal justice system of Imperial China existed unbroken for over 2,000 years.\nMany of the earliest conceptions of crime are associated with sin and corresponded to acts that were believed to invoke the anger of a deity. This idea was further popularized with the development of the Abrahamic religions. The understanding of crime and sin were closely associated with one another for much of history, and conceptions of crime took on many of the ideas associated with sin. Islamic law developed its own system of criminal justice as Islam spread in the seventh and eighth centuries.\nPost-classical era.\nIn post-classical Europe and East Asia, central government was limited and crime was defined locally. Towns established their own criminal justice systems, while crime in the countryside was defined by the social hierarchies of feudalism. In some places, such as the Russian Empire and the Kingdom of Italy, feudal justice survived into the 19th century.\nCommon law first developed in England under the rule of Henry II in the 12th century. He established a system of traveling judges that tried accused criminals in each region of England by applying precedent from previous rulings. Legal developments in 12th century England also resulted in the earliest known recording of official crime data.\nModern era.\nIn the modern era, crime came to be seen as an issue affecting society rather than conflicts between individuals. Writers such as Thomas Hobbes saw crime as a societal issue as early as the 17th century. Imprisonment developed as a long-term penalty for crime in the 18th century. Increasing urbanization and industrialization in the 19th century caused crime to become an immediate issue that affected society, prompting government intervention in crime and the establishment of criminology as its own field.\nAnthropological criminology was popularized by Cesare Lombroso in the late-19th century. This was a biological determinist school of thought based in social darwinism, arguing that certain people are naturally born as criminals. The eugenics movement of the early-20th century similarly held that crime was caused primarily by genetic factors.\nThe concept of crime underwent a period of change as modernism was widely accepted in the years following World War II. Crime increasingly came to be seen as a societal issue, and criminal law was seen as a means to protect the public from antisocial behavior. This idea was associated with a larger trend in the western world toward social democracy and centre-left politics.\nThrough most of history, reporting of crime was generally local. The advent of mass media through radio and television in the mid-20th century allowed for the sensationalism of crime. This created well-known stories of criminals such as Jeffrey Dahmer, and it allowed for dramatization that perpetuates misconceptions about crime. Forensic science was popularized in the 1980s, establishing DNA profiling as a new method to prevent and analyze crime.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "5786", "revid": "48643156", "url": "https://en.wikipedia.org/wiki?curid=5786", "title": "California Institute of Technology", "text": "Private university in Pasadena, California\nThe California Institute of Technology (branded as Caltech) is a private research university in Pasadena, California, United States. The university is responsible for many modern scientific advancements and is among a small group of institutes of technology in the United States that are devoted to the instruction of pure and applied sciences.\nThe institution was founded as a preparatory and vocational school by Amos G. Throop in 1891 and began attracting influential scientists such as George Ellery Hale, Arthur Amos Noyes, and Robert Andrews Millikan in the early 20th century. The vocational and preparatory schools were disbanded and spun off in 1910, and the college assumed its present name in 1920. In 1934, Caltech was elected to the Association of American Universities, and the antecedents of NASA's Jet Propulsion Laboratory, which Caltech continues to manage and operate, were established between 1936 and 1943 under Theodore von K\u00e1rm\u00e1n.\nCaltech has six academic divisions with strong emphasis on science and engineering, managing $332 million in research grants as of 2010. Its primary campus is located approximately northeast of downtown Los Angeles, in Pasadena. First-year students are required to live on campus, and 95% of undergraduates remain in the on-campus housing system at Caltech. Students agree to abide by an honor code which allows faculty to assign take-home examinations. The Caltech Beavers compete in 13 intercollegiate sports in the NCAA Division III's Southern California Intercollegiate Athletic Conference (SCIAC).\nScientists and engineers at or from the university have played an essential role in many modern scientific breakthroughs and innovations, including advances in space research, sustainability science, quantum physics, and seismology. As of October\u00a02024[ [update]], there are 80 Nobel laureates who have been affiliated with Caltech, making it the institution with the highest number of Nobelists per capita in America. This includes 48 alumni and faculty members (49 prizes, with chemist Linus Pauling being the only individual in history to win two unshared prizes). In addition, 68 National Medal of Science Recipients, 43 MacArthur Fellows, 15 National Medal of Technology and Innovation recipients, 11 astronauts, 5 Science Advisors to the President, 4 Fields Medalists, and 6 Turing Award winners have been affiliated with Caltech.\nHistory.\nThroop College.\nCaltech started as a vocational school founded in present-day Old Pasadena on Fair Oaks Avenue and Chestnut Street on September 23, 1891, by local businessman and politician Amos G. Throop. The school was known successively as Throop University, Throop Polytechnic Institute (and Manual Training School) and Throop College of Technology before acquiring its current name in 1920. The vocational school was disbanded and the preparatory program was split off to form the independent Polytechnic School in 1907.\nAt a time when scientific research in the United States was still in its infancy, George Ellery Hale, a solar astronomer from the University of Chicago, founded the Mount Wilson Observatory in 1904. He joined Throop's board of trustees in 1907, and soon began developing the university, and the whole of Pasadena, into a major scientific and cultural destination. He engineered the appointment of James A. B. Scherer, a literary scholar untutored in science but very capable in administration and fund-raising, to Throop's presidency in 1908. Scherer persuaded retired businessman and trustee Charles W. Gates to donate $25,000 in seed money () to build Gates Laboratory, the first science building on campus.\nWorld Wars.\nIn 1910, Throop moved to its current site. Arthur Fleming donated the land for the permanent campus site. Theodore Roosevelt delivered an address at Throop Institute on March 21, 1911, and he declared:\nI want to see institutions like Throop turn out perhaps ninety-nine of every hundred students as men who are to do given pieces of industrial work better than any one else can do them; I want to see those men do the kind of work that is now being done on the Panama Canal and on the great irrigation projects in the interior of this country\u2014and the one-hundredth man I want to see with the kind of cultural scientific training that will make him and his fellows the matrix out of which you can occasionally develop a man like your great astronomer, George Ellery Hale.\nAlso in 1911, a bill was introduced in the California Legislature calling for the establishment of a publicly funded \"California Institute of Technology,\" with an initial budget of a million dollars, ten times the budget of Throop at the time. The board of trustees offered to turn Throop over to the state, but the presidents of Stanford University and the University of California, Berkeley successfully lobbied to defeat the bill, which allowed Throop to develop as the only scientific research-oriented educational institute in southern California, public or private, until the onset of World War II necessitated the broader development of research-based science education. The promise of Throop attracted physical chemist Arthur Amos Noyes from MIT to develop the institution and assist in establishing it as a center for science and technology.\nWith the onset of World War I, Hale organized the National Research Council to coordinate and support scientific work on military problems. While he supported the idea of federal appropriations for science, he took exception to a federal bill that would have funded engineering research at land-grant colleges, and instead sought to raise a $1\u00a0million national research fund entirely from private sources. To that end, as Hale wrote in \"The New York Times\":\nThroop College of Technology, in Pasadena California has recently afforded a striking illustration of one way in which the Research Council can secure co-operation and advance scientific investigation. This institution, with its able investigators and excellent research laboratories, could be of great service in any broad scheme of cooperation. President Scherer, hearing of the formation of the council, immediately offered to take part in its work, and with this object, he secured within three days an additional research endowment of one hundred thousand dollars.\nThrough the National Research Council, Hale simultaneously lobbied for science to play a larger role in national affairs, and for Throop to play a national role in science. The new funds were designated for physics research, and ultimately led to the establishment of the Norman Bridge Laboratory, which attracted experimental physicist Robert Andrews Millikan from the University of Chicago in 1917. During the course of the war, Hale, Noyes and Millikan worked together in Washington on the NRC. Subsequently, they continued their partnership in developing Caltech.\nUnder the leadership of Hale, Noyes, and Millikan (aided by the booming economy of Southern California), Caltech grew to national prominence in the 1920s and concentrated on the development of Roosevelt's \"Hundredth Man\". On November 29, 1921, the trustees declared it to be the express policy of the institute to pursue scientific research of the greatest importance and at the same time \"to continue to conduct thorough courses in engineering and pure science, basing the work of these courses on exceptionally strong instruction in the fundamental sciences of mathematics, physics, and chemistry; broadening and enriching the curriculum by a liberal amount of instruction in such subjects as English, history, and economics; and vitalizing all the work of the Institute by the infusion in generous measure of the spirit of research\". In 1923, Millikan was awarded the Nobel Prize in Physics. In 1925, the school established a department of geology and hired William Bennett Munro, then chairman of the division of History, Government, and Economics at Harvard University, to create a division of humanities and social sciences at Caltech. In 1928, a division of biology was established under the leadership of Thomas Hunt Morgan, the most distinguished biologist in the United States at the time, and discoverer of the role of genes and the chromosome in heredity. In 1930, Kerckhoff Marine Laboratory was established in Corona del Mar under the care of Professor George MacGinitie. In 1926, a graduate school of aeronautics was created, which eventually attracted Theodore von K\u00e1rm\u00e1n. K\u00e1rm\u00e1n later helped create the Jet Propulsion Laboratory, and played an integral part in establishing Caltech as one of the world's centers for rocket science. In 1928, construction of the Palomar Observatory began.\nMillikan served as \"Chairman of the Executive Council\" (effectively Caltech's president) from 1921 to 1945, and his influence was such that the institute was occasionally referred to as \"Millikan's School\". Millikan initiated a visiting-scholars program soon after joining Caltech. Notable scientists who accepted his invitation include Paul Dirac, Erwin Schr\u00f6dinger, Werner Heisenberg, Hendrik Lorentz and Niels Bohr. Albert Einstein arrived on the Caltech campus for the first time in 1931 to polish up his Theory of General Relativity, and he returned to Caltech subsequently as a visiting professor in 1932 and 1933.\nDuring World War II, Caltech was one of 131 colleges and universities nationally that took part in the V-12 Navy College Training Program which offered students a path to a Navy commission. The United States Navy also maintained a naval training school for aeronautical engineering, resident inspectors of ordinance and naval material, and a liaison officer to the National Defense Research Committee on campus. During the war, some scientists from Caltech, including J. Robert Oppenheimer, Richard Tolman, and Robert Bacher, were instrumental in the Manhattan Project and contributed to critical aspects of the atomic bomb's development.\nCaltech was also directly involved in other bomb-related research with a group led by Charles Lauritsen which assisted in the development of the high-explosive lenses used in the Fat Man implosion bomb, crucial to the Trinity Test and the subsequent bombing of Nagasaki. Lauritsen's team at Caltech developed detonators that would later be used in atomic bombs. In November 1943, Caltech and the U.S. Navy established the Naval Ordnance Test Station (NOTS) in Inyokern, California, near the Mojave Desert to work on aircraft ordnance and rocket development. One of the most successful innovations was the development of the 5-inch High-Velocity Aircraft Rocket, commonly known as the \"Holy Moses,\" which was used in combat against enemy fortifications and ships.\nThe partnership between the Navy and Caltech continued to deepen throughout the war, leading to the creation of several military technologies, and by 1945, the focus of Caltech's war contributions expanded further with Project Camel, a collaboration between the Naval Ordnance Test Station and the Manhattan Project. Caltech scientists worked on a variety of assignments, including B-29 airdrop tests of model atomic bombs and the manufacturing of explosives for use in the atomic bomb's implosion mechanism. Additionally, the Salt Wells Pilot Plant at Inyokern was developed with Caltech scientists in response to concerns about the safety of explosive production at Los Alamos and began producing high explosives just days before the Trinity Test in July 1945. Early in the war, Caltech scientists, including Lauritsen's son, Thomas Lauritsen, worked on various rocket designs at the Kellogg Radiation Laboratory. These rockets, including the \"Tiny Tim\" and the \"Mighty Mouse,\" were used in critical military operations, from naval engagements to land assaults. By the end of the war, Caltech had essentially become an extension of the U.S. Navy's Bureau of Ordnance, with its rocket research providing important technology to U.S. combat capabilities.\nProject Vista.\nFrom April to December 1951, Caltech was the host of a federal classified study, Project Vista. The selection of Caltech as host for the project was based on the university's expertise in rocketry and nuclear physics. In response to the war in Korea and the pressure from the Soviet Union, the project was Caltech's way of assisting the federal government in its effort to increase national security. The project was created to study new ways of improving the relationship between tactical air support and ground troops. The Army, Air Force, and Navy sponsored the project; however, it was under contract with the Army. The study was named after the hotel, Vista del Arroyo Hotel, which housed the study. The study operated under a committee with the supervision of President Lee A. DuBridge. William A. Fowler, a professor at Caltech, was selected as research director. More than a fourth of Caltech's faculty and a group of outside scientists staffed the project. Moreover, the number increases if one takes into account visiting scientists, military liaisons, secretarial, and security staff. In compensation for its participation, the university received about $750,000.\nPost-war growth.\nFrom the 1950s to 1980s, Caltech was the home of Murray Gell-Mann and Richard Feynman, whose work was central to the establishment of the Standard Model of particle physics. Feynman was also widely known outside the physics community as an exceptional teacher and a colorful, unconventional character.\nDuring Lee A. DuBridge's tenure as Caltech's president (1946\u20131969), Caltech's faculty doubled and the campus tripled in size. DuBridge, unlike his predecessors, welcomed federal funding of science. New research fields flourished, including chemical biology, planetary science, nuclear astrophysics, and geochemistry. A 200-inch telescope was dedicated on nearby Palomar Mountain in 1948 and remained the world's most powerful optical telescope for over forty years.\nCaltech opened its doors to female undergraduates during the presidency of Harold Brown in 1970, and they made up 14% of the entering class. The portion of female undergraduates has been increasing since then.\nProtests by Caltech students are rare. The earliest was a 1968 protest outside the NBC Burbank studios, in response to rumors that NBC was to cancel \"\". In 1973, the students from Dabney House protested a presidential visit with a sign on the library bearing the simple phrase \"Impeach Nixon\". The following week, Ross McCollum, president of the National Oil Company, wrote an open letter to Dabney House stating that in light of their actions he had decided not to donate one million dollars to Caltech. The Dabney family, being Republicans, disowned Dabney House after hearing of the protest.\n21st century.\nSince 2000, the Einstein Papers Project has been located at Caltech. The project was established in 1986 to assemble, preserve, translate, and publish papers selected from the literary estate of Albert Einstein and from other collections.\nIn fall 2008, the freshman class was 42% female, a record for Caltech's undergraduate enrollment. In the same year, the Institute concluded a six-year-long fund-raising campaign. The campaign raised more than $1.4\u00a0billion from about 16,000 donors. Nearly half of the funds went into the support of Caltech programs and projects.\nIn 2010, Caltech, in partnership with Lawrence Berkeley National Laboratory and headed by Professor Nathan Lewis, established a DOE Energy Innovation Hub aimed at developing revolutionary methods to generate fuels directly from sunlight. This hub, the Joint Center for Artificial Photosynthesis, will receive up to $122\u00a0million in federal funding over five years.\nSince 2012, Caltech began to offer classes through massive open online courses (MOOCs) under Coursera, from 2013, edX. Since 2020, Caltech\u2019s Center for Technology and Management Education (CTME) has provided professional certificate programs and bootcamps targeted at working professionals. Beginning in 2022, CTME faced a class-action lawsuit alleging that its cybersecurity bootcamp was misleadingly marketed as a Caltech program, despite being fully designed and taught by the third-party company Simplilearn without Caltech faculty involvement. The lawsuit asserted that students were misled by the use of Caltech branding. In response, Caltech announced it would end its partnership with Simplilearn and restructure CTME programs under internal oversight.\nJean-Lou Chameau, the eighth president, announced on February 19, 2013, that he would be stepping down to accept the presidency at King Abdullah University of Science and Technology. Thomas F. Rosenbaum was announced to be the ninth president of Caltech on October 24, 2013, and his term began on July 1, 2014.\nThe Laser Interferometer Gravitational\u2011Wave Observatory (LIGO) was designed and constructed by a team of scientists from the California Institute of Technology, MIT, and industrial partners, funded by the National Science Foundation. It was intended to launch gravitational\u2011wave astronomy by detecting the ripples in spacetime predicted by Einstein\u2019s general relativity. Gravitational waves were directly detected for the first time on September\u202f14, 2015, by the LIGO detectors. For their pivotal roles in building the LIGO observatory and making the discovery, Caltech physicists Kip\u202fThorne and Barry\u202fBarish, together with MIT physicist Rainer\u202fWeiss, were awarded the 2017 Nobel Prize in Physics. Thorne, who is a Caltech graduate, provided the theoretical foundation that guided LIGO's design.\nIn 2019, Caltech received a gift of $750\u00a0million for sustainability research from the Resnick family of The Wonderful Company. The gift is the largest ever for environmental sustainability research and the second-largest private donation to a US academic institution (after Bloomberg's gift of $1.8\u00a0billion to Johns Hopkins University in 2018).\nIn January 2021, the Caltech Board of Trustees authorized the removal the names of six historical figures\u2014including inaugural president Robert Millikan, Harry Chandler, Albert Ruddock\u2014from campus buildings due to their affiliations with the Human Betterment Foundation, an American eugenics organization. As a result, Millikan Library was renamed Caltech Hall, Chandler Dining Hall became Lee F. Browne Dining Hall, Ruddock House was renamed Grant D. Venerable House (after Caltech\u2019s first Black graduate).\nCampus.\nCaltech's primary campus is located in Pasadena, California, approximately northeast of downtown Los Angeles. It is within walking distance of Old Town Pasadena and the Pasadena Playhouse District and therefore the two locations are frequent getaways for Caltech students.\nIn 1917 Hale hired architect Bertram Goodhue to produce a master plan for the campus. Goodhue conceived the overall layout of the campus and designed the physics building, Dabney Hall, and several other structures, in which he sought to be consistent with the local climate, the character of the school, and Hale's educational philosophy. Goodhue's designs for Caltech were also influenced by the traditional Spanish mission architecture of Southern California.\nDuring the 1960s, Caltech underwent considerable expansion, in part due to the philanthropy of alumnus and professor Arnold O. Beckman. In 1953, Beckman was asked to join the Caltech Board of Trustees. In 1964, he became its chairman. Over the next few years, as Caltech's president emeritus David Baltimore described it, Arnold Beckman and his wife Mabel \"shaped the destiny of Caltech.\"\nIn 1971 a magnitude-6.6 earthquake in San Fernando caused some damage to the Caltech campus. Engineers who evaluated the damage found that two historic buildings dating from the early days of the Institute\u2014Throop Hall and the Goodhue-designed Culbertson Auditorium\u2014had cracked.\nNew additions to the campus include the Cahill Center for Astronomy and Astrophysics and the Walter and Leonore Annenberg Center for Information Science and Technology, which opened in 2009, and the Warren and Katherine Schlinger Laboratory for Chemistry and Chemical Engineering followed in March 2010. The institute also concluded an upgrading of the South Houses in 2006. In late 2010, Caltech completed a 1.3 MW solar array projected to produce approximately 1.6 GWh in 2011.\nOrganization and administration.\nCaltech is incorporated as a non-profit corporation and is governed by a privately appointed 46-member board of trustees who serve five-year terms of office and retire at the age of 72. The trustees elect a president to serve as the chief executive officer of the institute and administer the affairs on the institute on behalf of the board, a provost who serves as the chief academic officer of the institute below the president, and ten other vice presidential and other senior positions. Thomas F. Rosenbaum became the ninth president of Caltech in 2014. Caltech's endowment is governed by a permanent trustee committee and administered by an investment office.\nThe institute is organized into six primary academic divisions: Biology and Biological Engineering (founded 1927), Chemistry and Chemical Engineering (founded 1926), Engineering and Applied Science (founded 1926), Geological and Planetary Sciences (founded 1927), Humanities and Social Sciences (founded 1926), Physics, Mathematics, and Astronomy (founded 1926). Given Caltech's historical prestige and the small size of its faculty in many major fields, the institution is exceptionally careful in selecting candidates. This rigorous process can result in some positions remaining unfilled for several years until the right candidate is found. Caltech dedicates significant resources to attract top-tier faculty and provides them with substantial financial support to foster their research and academic endeavors. The voting faculty of Caltech include all professors, instructors, research associates and fellows, and the University Librarian. Faculty are responsible for establishing admission requirements, academic standards, and curricula. The Faculty Board is the faculty's representative body and consists of 18 elected faculty representatives as well as other senior administration officials. Full-time professors are expected to teach classes, conduct research, advise students, and perform administrative work such as serving on committees.\nFounded in 1930s, the Jet Propulsion Laboratory (JPL) is a federally funded research and development center (FFRDC) owned by NASA and operated as a division of Caltech through a contract between NASA and Caltech. In 2008, JPL spent over $1.6\u00a0billion on research and development and employed over 5,000 project-related and support employees. The JPL Director also serves as a Caltech Vice President and is responsible to the President of the Institute for the management of the laboratory.\nIn December 2023, graduate students and postdoctoral researchers filed to be recognized for collective bargaining as https://, in affiliation with the United Auto Workers (C/GPU-UAW). On January 31 and February 1, 2024, a vote was held by the National Labor Relations Board (NLRB). In February 2024, the NLRB certified that 1335 of 1997 eligible workers voted, with 78% voting in favor of unionization. In May 2024, contract negotiations began. In December 2024, C/GPU-UAW members held a strike authorization vote, 1441 participating in the vote, and 86% voting in favor of authorizing the C/GPU bargaining team to call a strike, if necessary.\nAcademics.\nCaltech is a small four-year, highly residential research university with slightly more students in graduate programs than undergraduate. The institute has been accredited by the Western Association of Schools and Colleges since 1949. Caltech is on the quarter system: the fall term starts in late September and ends before Christmas, the second term starts after New Year's Day and ends in mid-March, and the third term starts in late March or early April and ends in early June.\nUndergraduate admissions.\nAdmission to Caltech is extremely rigorous. Prior to going test blind, Caltech students had the highest test scores in the nation. In admissions for the Class of 2028 (entering 2024), Caltech was ranked the hardest college in America to gain acceptance to by admit rate, at an all-time low of 2.7%. For the freshmen who enrolled in 2019 (Class of 2023) the middle 50% range of SAT were 740\u2013780 for evidence-based reading and writing and 790\u2013800 for math, and 1530\u20131570 total. The middle 50% range ACT Composite score was 35\u201336. The SAT Math Level 2 middle 50% range was 800\u2013800. The middle 50% range for the SAT Physics Subject Test was 760\u2013800; SAT Chemistry Subject Test was 760\u2013800; \nSAT Biology Subject Tests was 760\u2013800. In June 2020, Caltech announced a test-blind policy where they would not require nor consider test scores for the next two years. The moratorium was extended twice, starting July 2021, but was subsequently cancelled starting with the Class of 2029. The institute is need-blind for domestic applicants.\nFor the Class of 2027 (enrolled Fall 2023), Caltech received 13,136 applications and accepted 412 applicants for a 3.14% admit rate; 270 enrolled. The subsequent year, for the Class of 2028, Caltech reduced the number of seats by almost one hundred, accepting 315 applicants out of approximately 13,000 total applications. For the Class of 2025, 32% were of underrepresented ancestry (which includes students who self-identify as American Indian/Alaska Native, Hispanic/Latino, Black/African American, and/or Native Hawaiian/Pacific Islander), and 6% were foreign students.\nTuition and financial aid.\nUndergraduate tuition for the 2021\u20132022 school year was $56,394 and total annual costs were estimated to be $79,947 excluding the Caltech Student Health Insurance Plan. In 2012\u20132013, Caltech awarded $17.1\u00a0million in need-based aid, $438k in non-need-based aid, and $2.51\u00a0million in self-help support to enrolled undergraduate students. The average financial aid package of all students eligible for aid was $38,756 and students graduated with an average debt of $15,090.\nUndergraduate program.\nThe full-time, four-year undergraduate program emphasizes instruction in the arts and sciences and has high graduate coexistence. Caltech offers 28 majors (called \"options\") and 17 minors across all six academic divisions. Caltech also offers interdisciplinary programs in Applied Physics, Biochemistry, Bioengineering, Computation and Neural Systems, Control and Dynamical Systems, Environmental Science and Engineering, Geobiology and Astrobiology, Geochemistry, and Planetary Astronomy. The most popular options are Chemical Engineering, Computer Science, Electrical Engineering, Mechanical Engineering and Physics. The most popular majors of the class of 2023 were Computer Science, Mechanical Engineering, Physics, and Electrical Engineering.\nAll undergraduates are required to complete the core curriculum, which consists of 108 units typically completed in the first two years, providing a rigorous foundation in science, mathematics, humanities, and physical education to develop analytical and interdisciplinary skills. It includes 3 terms of mathematics, 3 terms of physics, 2 terms of chemistry, 1 term of biology, a 1 term \u201cmenu\u201d course, 1 term of computer science, a scientific writing requirement, 1 term of physical education, and 11 terms of humanities and social science, with placement exams allowing advanced students to substitute introductory courses and a pass/no-record grading system in the freshman fall term to ease academic pressure. Prior to the entering class of 2013, Caltech required students to take a core curriculum of five terms of mathematics, five terms of physics, two terms of chemistry, one term of biology, two terms of lab courses, one term of scientific communication, three terms of physical education, and 12 terms of humanities and social science. Since 2013, only three terms each of mathematics and physics have been required by the institute, with the remaining two terms each required by certain options.\nA typical class is worth 9 academic units and given the extensive core curriculum requirements in addition to individual options' degree requirements, students need to take an average of 40.5 units per term (more than four classes) to graduate in four years. 36 units is the minimum full-time load, 48 units is considered a heavy load, and registrations above 51 units require an overload petition. Approximately 20 percent of students double-major. This is achievable since the humanities and social sciences majors have been designed to be done in conjunction with a science major. Although choosing two options in the same division is discouraged, it is still possible.\nFirst-year students are enrolled in first-term classes based upon results of placement exams in math, physics, chemistry, and writing and take all classes in their first two terms on a Pass/Fail basis. There is little competition; collaboration on homework is encouraged and the honor system encourages take-home tests and flexible homework schedules. Caltech offers co-operative programs with other schools, such as the Pasadena Art Center College of Design and Occidental College.\nAccording to a 2018[ [update]] PayScale study, Caltech graduates earn a median early career salary of $83,400 and $143,100 mid-career, placing them in the top 5 among graduates of US colleges and universities. The average net return on investment over a period of 20 years is $887,000, the tenth-highest among US colleges.\nCaltech offers Army and Air Force ROTC in cooperation with the University of Southern California.\nGraduate program.\nAdmission to Caltech's graduate study is highly competitive, with faculty evaluating factors such as academic preparation, research experience, scientific interests, and recommendations from teachers or mentors. A key aspect of the admission process is the matching of faculty and an applicant's research interests. Historically, many programs required applicants to submit GRE scores. However, in recent years, many departments have made the GRE optional or no longer require it at all.\nThe graduate instructional programs emphasize doctoral studies and are dominated by science, technology, engineering, and mathematics fields. The institute offers graduate degree programs for the Master of Science, Engineer's Degree, Doctor of Philosophy, BS/MS and MD/PhD, with the majority of students in the PhD program. The most popular options are Chemistry, Physics, Biology, Electrical Engineering, and Chemical Engineering.\nInitially, most new graduate students are assigned a temporary advisor, allowing time to select a permanent advisor. To aid in this, some graduate options include rotations in research labs, facilitating a better match with faculty research groups that align with the students' scientific interests. Up to three rotations in the first year are allowed in some options.\nCaltech provides on-campus housing options for incoming graduate students. All new graduate students are guaranteed housing in their first year, with a variety of living experiences available to suit different needs. Approximately half of Caltech's graduate student population resides in campus housing. Post-first year, students participate in a housing lottery, with the results announced two months prior to the contract end date, aiding in planning for those who need to seek off-campus housing.\nThe research facilities at Caltech are available to graduate students, but there are opportunities for students to work in facilities of other universities, research centers (such as NASA's Jet Propulsion Laboratory), and private industries. The graduate student to faculty ratio is 4:1. Joint programs also exist between Caltech and the Keck School of Medicine of the University of Southern California, the UCLA David Geffen School of Medicine, and the Kaiser Permanente Bernard J. Tyson School of Medicine, which grants MD/PhD degrees. Students in this program do their preclinical and clinical work at USC, UCLA, or KPSOM, and their PhD work with any member of the Caltech faculty, including the Biology, Chemistry, and Engineering and Applied Sciences Divisions. The MD degree would be from the student's respective medical school and the PhD would be awarded from Caltech.\nApproximately 99 percent of doctoral students have full financial support. Financial support for graduate students comes in the form of fellowships, research assistantships, teaching assistantships or a combination of fellowship and assistantship support.\nGraduate students are bound by the same honor code as the undergraduates, allowing for take-home examinations. The Graduate Honor Council oversees any violations of the code.\nRankings.\n&lt;templatestyles src=\"Col-begin/styles.css\"/&gt;\nCaltech was ranked within the top ten universities in the world by the Times Higher Education World University Rankings, QS World University Rankings, and Academic Ranking of World Universities\".\" For 2022, U.S. News &amp; World Report ranked Caltech as tied for 9th in the United States among national universities overall, 11th for most innovative, and 15th for best value. \"U.S. News &amp; World Report\" also ranked the graduate programs in chemistry and earth sciences first among national universities.\nResearch.\nCaltech is classified among \"R1: Doctoral Universities \u2013 Very High Research Activity\". Caltech was elected to the Association of American Universities in 1934 and remains a research university with \"very high\" research activity, primarily in STEM fields. Caltech manages research expenditures of $270\u00a0million annually, 66th among all universities in the U.S. and 17th among private institutions without medical schools for 2008. The largest federal agencies contributing to research are NASA, National Science Foundation, Department of Health and Human Services, Department of Defense, and Department of Energy. Caltech received $144\u00a0million in federal funding for the physical sciences, $40.8\u00a0million for the life sciences, $33.5\u00a0million for engineering, $14.4\u00a0million for environmental sciences, $7.16\u00a0million for computer sciences, and $1.97\u00a0million for mathematical sciences in 2008.\nThe institute was awarded an all-time high funding of $357\u00a0million in 2009. Active funding from the National Science Foundation Directorate of Mathematical and Physical Science (MPS) for Caltech stands at $343\u00a0million as of 2011[ [update]], the highest for any educational institution in the nation, and higher than the total funds allocated to any state except California and New York.\nIn 2005, Caltech had dedicated to research: to physical sciences, to engineering, and to biological sciences.\nIn addition to managing JPL, Caltech also operates the Palomar Observatory in San Diego County, the Owens Valley Radio Observatory in Bishop, California, the Submillimeter Observatory and W. M. Keck Observatory at the Mauna Kea Observatory, the Laser Interferometer Gravitational-Wave Observatory at Livingston, Louisiana and Richland, Washington, and Kerckhoff Marine Laboratory in Corona del Mar, California. The Institute launched the Kavli Nanoscience Institute at Caltech in 2006, the Keck Institute for Space Studies in 2008, and is also the current home for the Einstein Papers Project. The Spitzer Science Center (SSC), part of the Infrared Processing and Analysis Center located on the Caltech campus, is the data analysis and community support center for NASA's Spitzer Space Telescope.\nCaltech partnered with UCLA to establish a Joint Center for Translational Medicine (UCLA-Caltech JCTM), which conducts experimental research into clinical applications, including the diagnosis and treatment of diseases such as cancer. In 1997, Caltech partnered with UCLA to train physician-scientists.\nCaltech operates several TCCON stations as part of an international collaborative effort of measuring greenhouse gases globally. One station is on campus.\nUndergraduates at Caltech are also encouraged to participate in research. About 80% of the class of 2010 did research through the annual Summer Undergraduate Research Fellowships (SURF) program at least once during their stay, and many continued during the school year. Students write and submit SURF proposals for research projects in collaboration with professors, and about 70 percent of applicants are awarded SURFs. The program is open to both Caltech and non-Caltech undergraduate students. It serves as preparation for graduate school and helps to explain why Caltech has the highest percentage of alumni who go on to receive a PhD of all the major universities.\nThe licensing and transferring of technology to the commercial sector is managed by the Office of Technology Transfer (OTT). OTT protects and manages the intellectual property developed by faculty members, students, other researchers, and JPL technologists. Caltech receives more invention disclosures per faculty member than any other university in the nation. As of 2008[ [update]], 1891 patents were granted to Caltech researchers since 1969.\nStudents.\nCaltech enrolled 987 undergraduate students and 1,443 graduate students for the 2024\u20132025 school year. Women made up 45% of the undergraduate and 36% of the graduate student body. The racial demographics of the school substantially differ from those of the nation as a whole.\nThe four-year graduation rate is 79% and the six-year rate is 92%, which is low compared to most leading U.S. universities, but substantially higher than it was in the 1960s and 1970s. Students majoring in STEM fields traditionally have graduation rates below 70%.\nTable notes:\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nStudent life.\nHouse system.\nDuring the early 20th century, a Caltech committee visited several universities and decided to transform the undergraduate housing system from fraternities to a house system. Four South Houses (or \"Hovses\", as styled in the stone engravings) were built: Blacker House, Dabney House, Fleming House and Ricketts House. In the 1960s, three North Houses were built: Lloyd House, Page House, and Ruddock House, and during the 1990s, Avery House. The four South Houses closed for renovation in 2005 and reopened in 2006. The latest addition to residential life at Caltech is Bechtel Residence, which opened in 2018. It is not affiliated with the house system. All first- and second-year students live on campus in the house system or in the Bechtel Residence.\nOn account of Albert B. Ruddock's affiliation with the Human Betterment Foundation, in January 2021, the Caltech Board of Trustees authorized the removal of Ruddock's name from campus buildings. Ruddock House was renamed as the Grant D. Venerable House.\nAthletics.\nCaltech has athletic teams in baseball, men's and women's basketball, cross country, men's and women's soccer, swimming and diving, men's and women's tennis, track and field, women's volleyball, and men's and women's water polo. Caltech's mascot is the Beaver, a homage to nature's engineer. Its teams are members of the NCAA Division III and compete in the Southern California Intercollegiate Athletic Conference (SCIAC), which Caltech co-founded in 1915.\nOn January 6, 2007, the Beavers' men's basketball team snapped a 207-game losing streak to Division III schools, beating Bard College 81\u201352. It was their first Division III victory since 1996.\nUntil their win over Occidental College on February 22, 2011 the team had not won a game in SCIAC play since 1985. Ryan Elmquist's free throw with 3.3 seconds in regulation gave the Beavers the victory. The documentary film \"Quantum Hoops\" concerns the events of the Beavers' 2005\u201306 season.\nOn January 13, 2007, the Caltech women's basketball team snapped a 50-game losing streak, defeating the Pomona-Pitzer Sagehens 55\u201353. The women's program, which entered the SCIAC in 2002, garnered their first conference win. On the bench as honorary coach for the evening was Robert Grubbs, 2005 Nobel laureate in Chemistry. The team went on to beat Whittier College on February 10, for its second SCIAC win, and placed its first member on the All Conference team.\nIn 2007, 2008, and 2009, the women's table tennis team (a club team) competed in nationals. The women's Ultimate club team, known as \"Snatch\", has also been very successful in recent years, ranking 44 of over 200 college teams in the Ultimate Player's Association.\nOn February 2, 2013, the Caltech baseball team ended a 228-game losing streak, the team's first win in nearly 10 years.\nThe track and field team's home venue is at the South Athletic Field in Tournament Park, the site of the first eight Rose Bowl games.\nThe school also sponsored an intercollegiate football team from 1973 through 1977, and played part of its home schedule at the Rose Bowl.\nPerforming and visual arts.\nThe Caltech/Occidental College Orchestra is a full seventy-piece orchestra composed of students, faculty, and staff at Caltech and nearby Occidental College. The orchestra gives three pairs of concerts annually, at both Caltech and Occidental College. There are also two Caltech Jazz Bands and a Concert Band, as well as an active chamber music program. For vocal music, Caltech has a mixed-voice Glee Club and the smaller Chamber Singers. The theater program at Caltech is known as TACIT, or Theater Arts at the California Institute of Technology. There are two to three plays organized by TACIT per year, and they were involved in the production of the , released in 2011.\nStudent life traditions.\nAnnual events.\nEvery Halloween, Dabney House conducts the infamous \"Millikan pumpkin-drop experiment\" from the top of Millikan Library, the highest point on campus. According to tradition, a claim was once made that the shattering of a pumpkin frozen in liquid nitrogen and dropped from a sufficient height would produce a triboluminescent spark. This yearly event involves a crowd of observers, who try to spot the elusive spark. The title of the event is an oblique reference to the famous Millikan oil-drop experiment which measured \"e\", the elemental unit of electrical charge.\nOn Ditch Day, the seniors ditch school, leaving behind elaborately designed tasks and traps at the doors of their rooms to prevent underclassmen from entering. Over the years this has evolved to the point where many seniors spend months designing mechanical, electrical, and software obstacles to confound the underclassmen. Each group of seniors designs a \"stack\" to be solved by a handful of underclassmen. The faculty have been drawn into the event as well, and cancel all classes on Ditch Day so the underclassmen can participate in what has become a highlight of the academic year.\nAnother long-standing tradition is the playing of Wagner's \"Ride of the Valkyries\" at 7:00 each morning during finals week with the largest, loudest speakers available. The playing of that piece is not allowed at any other time (except if one happens to be listening to the entire 14 hours and 5 minutes of \"The Ring Cycle\"), and any offender is dragged into the showers to be drenched in cold water fully dressed. \nPranks.\nCaltech students have been known for their many pranks (also known as \"RFs\").\nThe two most famous in recent history are the changing of the Hollywood Sign to read \"Caltech\", by judiciously covering up certain parts of the letters, and the changing of the scoreboard to read Caltech 38, MIT 9 during the 1984 Rose Bowl Game. But the most famous of all occurred during the 1961 Rose Bowl Game, where Caltech students altered the flip-cards that were raised by the stadium attendees to display \"Caltech\", and several other \"unintended\" messages. This event is now referred to as the Great Rose Bowl Hoax.\nIn recent years, pranking has been officially encouraged by Tom Mannion, Caltech's Assistant VP for Student Affairs and Campus Life. \"The grand old days of pranking have gone away at Caltech, and that's what we are trying to bring back,\" reported the \"Boston Globe\".\nIn December 2011, Caltech students went to New York and pulled a prank in Manhattan's Greenwich Village. The prank involved making The Cube sculpture look like the Aperture Science Weighted Companion Cube from the video game \"Portal\".\nCaltech pranks have been documented in three Legends of Caltech books, the most recent of which was edited by alumni Autumn Looijen '99 and Mason Porter '98 and published in May 2007.\nRivalry with MIT.\nIn 2005, a group of Caltech students pulled a string of pranks during MIT's Campus Preview Weekend for admitted students. These include covering up the word Massachusetts in the \"Massachusetts Institute of Technology\" engraving on the main building fa\u00e7ade with a banner so that it read \"That Other Institute of Technology\". A group of MIT hackers responded by altering the banner so that the inscription read \"The Only Institute of Technology.\" Caltech students also passed out T-shirts to MIT's incoming freshman class that had MIT written on the front and \"...because not everyone can go to Caltech\" along with an image of a palm tree on the back.\nMIT retaliated in April 2006, when students posing as the Howe &amp; Ser (Howitzer) Moving Company stole the 130-year-old, 1.7-ton Fleming House cannon and moved it over 3,000 miles to their campus in Cambridge, Massachusetts for their 2006 Campus Preview Weekend, repeating a similar prank performed by nearby Harvey Mudd College in 1986. Thirty members of Fleming House traveled to MIT and reclaimed their cannon on April 10, 2006.\nOn April 13, 2007 (Friday the 13th), a group of students from \"The California Tech\", Caltech's campus newspaper, arrived and distributed fake copies of \"The Tech\", MIT's campus newspaper, while prospective students were visiting for their Campus Preview Weekend. Articles included \"MIT Invents the Interweb\", \"Architects Deem Campus 'Unfortunate'\", and \"Infinite Corridor Not Actually Infinite\".\nIn December 2009, some Caltech students declared that MIT had been sold and had become the Caltech East campus. A \"sold\" banner was hung on front of the MIT dome building and a \"Welcome to Caltech East: School of the Humanities\" banner over the Massachusetts Avenue Entrance. Newspapers and T-shirts were distributed, and door labels and fliers in the infinite corridor were put up in accordance with the \"curriculum change.\"\nIn September 2010, MIT students attempted to put a TARDIS, the time machine from the BBC's \"Doctor Who\", onto a roof. Caught in mid-act, the prank was aborted. In January 2011, Caltech students in conjunction with MIT students helped put the TARDIS on top of Baxter. Caltech students then moved the TARDIS to UC Berkeley and Stanford.\nIn April 2014, during MIT's Campus Preview Weekend, a group of Caltech students handed out mugs emblazoned with the MIT logo on the front and the words \"The Institute of Technology\" on the back. When heated, the mugs turn orange, display a palm tree, and read \"Caltech The Hotter Institute of Technology.\" Identical mugs continue to be sold at the Caltech campus store.\nHonor code.\nLife in the Caltech community is governed by the honor code, which simply states: \"No member of the Caltech community shall take unfair advantage of any other member of the Caltech community.\" This is enforced by a Board of Control, which consists of undergraduate students, and by a similar body at the graduate level, called the Graduate Honor Council.\nThe honor code aims at promoting an atmosphere of respect and trust that allows Caltech students to enjoy privileges that make for a more relaxed atmosphere. For example, the honor code allows professors to make the majority of exams as take-home, allowing students to take them on their own schedule and in their preferred environment.\nThrough the late 1990s, the only exception to the honor code, implemented earlier in the decade in response to changes in federal regulations, concerned the sexual harassment policy. Today, there are myriad exceptions to the honor code in the form of new Institute policies such as the fire policy and alcohol policy. Although both policies are presented in the Honor System Handbook given to new members of the Caltech community, some undergraduates regard them as a slight against the honor code and the implicit trust and respect it represents within the community. In recent years, the Student Affairs Office has also taken up pursuing investigations independently of the Board of Control and Conduct Review Committee, an implicit violation of both the honor code and written disciplinary policy that has contributed to further erosion of trust between some parts of the undergraduate community and the administration.\nNotable people.\nAs of October 2025, Caltech has 48 Nobel laureates to its name awarded to 26 alumni, 5 postdocs, and 17 non-alumni professors. The 26 alumni include five Caltech professors (Carl D. Anderson, Linus Pauling, William A. Fowler, Edward B. Lewis, and Kip Thorne). Among the 17 non-alumni professors, 14 were in residence at Caltech at the time of the award; David Baltimore, who shared the Prize in Physiology or Medicine in 1975, became Caltech President in 1997; Renato Dulbecco, who shared the Prize in Physiology or Medicine in 1975, credited his Prize to the time he had spent at Caltech; John Hopfield, who won the Prize in Physics in 2024, is the Dickinson Professor Emeritus at Caltech. The total number of Nobel Prizes is 49 because Pauling received prizes in both Chemistry and Peace. Eight faculty and alumni have received a Crafoord Prize from the Royal Swedish Academy of Sciences, while 58 have been awarded the U.S. National Medal of Science, and 11 have received the National Medal of Technology. One alumnus, Stanislav Smirnov, won the Fields Medal in 2010. Other distinguished researchers have been affiliated with Caltech as postdoctoral scholars (for example, Barbara McClintock, James D. Watson, Sheldon Glashow and John Gurdon) or visiting professors (for example, Albert Einstein, Stephen Hawking and Edward Witten).\nAlumni.\nThere are 22,930 total living alumni in the U.S. and around the world. As of October 2022, 30 alumni and 16 non-alumni faculty have won the Nobel Prize. The Turing Award, the \"Nobel Prize of Computer Science\", has been awarded to six alumni, and one has won the Fields Medal.\nMany alumni have participated in scientific research. Some have concentrated their studies on the very small universe of atoms and molecules. Nobel laureate Carl D. Anderson (BS 1927, PhD 1930) proved the existence of positrons and muons, Nobel laureate Edwin McMillan (BS 1928, MS 1929) synthesized the first transuranium element, Nobel laureate Leo James Rainwater (BS 1939) investigated the non-spherical shapes of atomic nuclei, and Nobel laureate Douglas D. Osheroff (BS 1967) studied the superfluid nature of helium-3. Donald Knuth (PhD 1963), the \"father\" of the analysis of algorithms, wrote \"The Art of Computer Programming\" and created the TeX computer typesetting system, which is commonly used in the scientific community. Bruce Reznick (BS 1973) is a mathematician noted for his contributions to number theory and the combinatorial-algebraic-analytic investigations of\u00a0polynomials. Narendra Karmarkar (MS 1979) is known for the interior point method, a polynomial algorithm for linear programming known as Karmarkar's algorithm.\nOther alumni have turned their gaze to the universe. C. Gordon Fullerton (BS 1957, MS 1958) piloted the third Space Shuttle mission. Astronaut (and later, United States Senator) Harrison Schmitt (BS 1957) was the only geologist to have walked on the surface of the Moon. Astronomer Eugene Merle Shoemaker (BS 1947, MS 1948) co-discovered Comet Shoemaker-Levy 9 (a comet which crashed into the planet Jupiter) and was the first person buried on the Moon (by having his ashes crashed into the Moon). Astronomer George O. Abell (BS 1951, MS 1952, PhD 1957) while a grad student at Caltech participated in the National Geographic Society-Palomar Sky Survey. This ultimately resulted in the publication of the \"Abell Catalogue of Clusters of Galaxies,\" the definitive work in the field.\nUndergraduate alumni founded, or co-founded, companies such as LCD manufacturer Varitronix, Hotmail, Compaq, MathWorks (which created Matlab), and database provider Imply, while graduate students founded, or co-founded, companies such as Intel, TRW, and the non-profit educational organization, the Exploratorium.\nArnold Beckman (PhD 1928) invented the pH meter and commercialized it with the founding of Beckman Instruments. His success with that company enabled him to provide seed funding for William Shockley (BS 1932), who had co-invented semiconductor transistors and wanted to commercialize them. Shockley became the founding Director of the Shockley Semiconductor Laboratory division of Beckman Instruments. Shockley had previously worked at Bell Labs, whose first president was another alumnus, Frank Jewett (BS 1898). Because his aging mother lived in Palo Alto, California, Shockley established his laboratory near her in Mountain View, California. Shockley was a co-recipient of the Nobel Prize in Physics in 1956, but his aggressive management style and odd personality at the Shockley Lab became unbearable. In late 1957, eight of his researchers resigned and with support from Sherman Fairchild formed Fairchild Semiconductor. Among the \"traitorous eight\" was Gordon E. Moore (PhD 1954), who later left Fairchild to co-found Intel. Other offspring companies of Fairchild Semiconductor include National Semiconductor and Advanced Micro Devices, which in turn spawned more technology companies in the area. Shockley's decision to use silicon instead of germanium as the semiconductor material, coupled with the abundance of silicon semiconductor related companies in the area, gave rise to the term \"Silicon Valley\" to describe that geographic region surrounding Palo Alto.\nCaltech alumni also held public offices, with Mustafa A. G. Abushagur (PhD 1984) the Deputy Prime Minister of Libya and Prime Minister-Elect of Libya, James Fletcher (PhD 1948) the 4th and 7th Administrator of NASA, Steven Koonin (PhD 1972) the Undersecretary of Energy for Science, and Regina Dugan (PhD 1993) the 19th director of DARPA. The 20th director for DARPA, Arati Prabhakar, is also a Caltech alumna (PhD 1984) as well as Charles Elachi (Phd 1971), former director of the Jet Propulsion Lab. Arvind Virmani is a former Chief Economic Adviser to the Government of India. In 2013, President Barack Obama announced the nomination of France Cordova (PhD 1979) as the director of the National Science Foundation and Ellen Williams (PhD 1982) as the director for ARPA-E.\nFaculty and staff.\nRichard Feynman was among the most well-known physicists associated with Caltech, having published the \"Feynman Lectures on Physics\", an undergraduate physics text, and popular science texts such as \"Six Easy Pieces\" for the general audience. The promotion of physics made him a public figure of science, although his Nobel-winning work in quantum electrodynamics was already very established in the scientific community. Murray Gell-Mann, a Nobel-winning physicist, introduced a classification of hadrons and went on to postulate the existence of quarks, which is currently accepted as part of the Standard Model. Long-time Caltech President Robert Andrews Millikan was the first to calculate the charge of the electron with his well-known oil-drop experiment, while Richard Chace Tolman is remembered for his contributions to cosmology and statistical mechanics. 2004 Nobel Prize in Physics winner H. David Politzer is a current professor at Caltech, as is astrophysicist and author Kip Thorne and eminent mathematician Barry Simon. Linus Pauling pioneered quantum chemistry and molecular biology, and went on to discover the nature of the chemical bond in 1939. Seismologist Charles Richter, also an alumnus, developed the magnitude scale that bears his name, the Richter magnitude scale for measuring the power of earthquakes. One of the founders of the geochemistry department, Clair Patterson was the first to accurately determine the age of the Earth via lead:uranium ratio in meteorites. In engineering, Theodore von K\u00e1rm\u00e1n made many key advances in aerodynamics, notably his work on supersonic and hypersonic airflow characterization. A repeating pattern of swirling vortices is named after him, the von K\u00e1rm\u00e1n vortex street. Participants in von K\u00e1rm\u00e1n's GALCIT project included Frank Malina, who helped develop the WAC Corporal, which was the first U.S. rocket to reach the edge of space, Jack Parsons, a pioneer in the development of liquid and solid rocket fuels who designed the first castable composite-based rocket motor, and Qian Xuesen, who was dubbed the \"Father of Chinese Rocketry\". More recently, Michael Brown, a professor of planetary astronomy, discovered many trans-Neptunian objects, most notably the dwarf planet Eris, which prompted the International Astronomical Union to redefine the term \"planet\".\nDavid Baltimore, the Robert A. Millikan Professor of Biology, and Alice Huang, Senior Faculty Associate in Biology, served as the presidents of AAAS from 2007 to 2008 and 2010 to 2011, respectively.\n33% of the faculty are members of the National Academy of Sciences or Engineering and/or fellows of the American Academy of Arts and Sciences. This is the highest percentage of any faculty in the country with the exception of the graduate institution Rockefeller University.\nThe average salary for assistant professors at Caltech is $111,300, associate professors $121,300, and full professors $172,800. Caltech faculty are active in applied physics, astronomy and astrophysics, biology, biochemistry, biological engineering, chemical engineering, computer science, geology, mechanical engineering, and physics.\nPresidents.\nThe following persons have led Caltech since 1921:\nTable notes:\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nCaltech startups.\nOver the years Caltech has actively promoted the commercialization of technologies developed within its walls. Through its Office of Technology Transfer &amp; Corporate Partnerships, scientific breakthroughs have led to the transfer of numerous technologies in a wide variety of scientific-related fields such as photovoltaic, radio-frequency identification (RFID), semiconductors, hyperspectral imaging, electronic devices, protein design, solid state amplifiers and many more. Companies such as Quora, Contour Energy Systems, Impinj, Fulcrum Microsystems, Nanosys, Inc., Photon etc., Xencor, and Wavestream Wireless have emerged from Caltech.\nIn media and popular culture.\nCaltech has appeared in many works of popular culture, both as itself and in disguised form. On television, it played a prominent role and was the workplace of all four male lead characters and one female lead character in the sitcom \"The Big Bang Theory\". Caltech is also the inspiration, and frequent film location, for the California Institute of Science in \"Numb3rs\". On film, the Pacific Tech of \"The War of the Worlds\" and \"Real Genius\" is based on Caltech.\nIn nonfiction, two 2007 documentaries examine aspects of Caltech: \"Curious\", its researchers, and \"Quantum Hoops\", its men's basketball team.\nCaltech is also prominently featured in many comics and television series by Marvel Entertainment. In Marvel Comics, the university serves as the alma mater of Hulk, Mister Fantastic, Bill Foster (Black Goliath), and Madman. In the Marvel Cinematic Universe, Bruno Carrelli (Kamala Khan's best friend and love interest) attends Caltech in the miniseries \"Ms. Marvel\".\nGiven its Los Angeles-area location, the grounds of the Institute are often host to short scenes in movies and television. The Athenaeum dining club appears in the \"Beverly Hills Cop\" series, \"The X-Files\", \"True Romance\", and \"The West Wing\".\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "5788", "revid": "194203", "url": "https://en.wikipedia.org/wiki?curid=5788", "title": "Cretaceous-Tertiary Extinction Event", "text": ""}
{"id": "5790", "revid": "35936988", "url": "https://en.wikipedia.org/wiki?curid=5790", "title": "Carlo Goldoni", "text": "Italian playwright (1707\u20131793)\nCarlo Osvaldo Goldoni (, , ; 25 February 1707 \u2013 6 February 1793) was an Italian playwright and librettist from the Republic of Venice. His works include some of Italy's most famous and best-loved plays. Audiences have admired the plays of Goldoni for their ingenious mix of wit and honesty. His plays offered his contemporaries images of themselves, often dramatizing the lives, values, and conflicts of the emerging middle classes. Though he wrote in French and Italian, his plays make rich use of the Venetian language, regional vernacular, and colloquialisms. Goldoni also wrote under the pen name and title \"Polisseno Fegeio, Pastor Arcade\", which he claimed in his memoirs the \"Arcadians of Rome\" bestowed on him.\nBiography.\nMemoirs.\nThere is an abundance of autobiographical information on Goldoni, most of which comes from the introductions to his plays and from his \"Memoirs\". However, these memoirs are known to contain many errors of fact, especially about his earlier years.\nIn these memoirs, he paints himself as a born comedian, careless, light-hearted and with a happy temperament, proof against all strokes of fate, yet thoroughly respectable and honourable.\nEarly life and studies.\nGoldoni was born in Venice in 1707, the son of Margherita Salvioni (or Saioni) and Giulio Goldoni. In his memoirs, Goldoni describes his father as a physician, and claims that he was introduced to theatre by his grandfather Carlo Alessandro Goldoni. In reality, it seems that Giulio was an apothecary; as for the grandfather, he had died four years before Carlo's birth. In any case, Goldoni was deeply interested in theatre from his earliest years, and all attempts to direct his activity into other channels were of no avail; his toys were puppets, and his books were plays.\nHis father placed him under the care of the philosopher Caldini at Rimini but the youth soon ran away with a company of strolling players and returned to Venice. In 1723 his father matriculated him into the stern Collegio Ghislieri in Pavia, which imposed the tonsure and monastic habits on its students. However, he relates in his \"Memoirs\" that a considerable part of his time was spent reading Greek and Latin comedies. He had already begun writing at this time and, in his third year, he composed a libellous poem (\"Il colosso\") in which he ridiculed the daughters of certain Pavian families. As a result of that incident (and/or of a visit with some schoolmates to a local brothel), he was expelled from the school and had to leave the city (1725). He studied law at Udine, and eventually took his degree at University of Modena. He was employed as a law clerk at Chioggia and Feltre, after which he returned to his native city and began practising.\nEducated as a lawyer, and holding lucrative positions as secretary and counsellor, he seemed, indeed, at one time to have settled down to the practice of law, but following an unexpected summons to Venice, after an absence of several years, he changed his career, and thenceforth he devoted himself to writing plays and managing theatres. His father died in 1731. In 1732, to avoid an unwanted marriage, he left the town for Milan and then for Verona where the theatre manager Giuseppe Imer helped him on his way to becoming a comical poet as well as introducing him to his future wife, Nicoletta Conio. Goldoni returned with her to Venice, where he stayed until 1743.\nTheatrical career.\nGoldoni entered the Italian theatre scene with a tragedy, \"Amalasunta\", produced in Milan. The play was a critical and financial failure.\nSubmitting it to Count Prata, director of the opera, he was told that his piece \"was composed with due regard for the rules of Aristotle and Horace, but not according to those laid down for the Italian drama.\" \"In France\", continued the count, \"you can try to please the public, but here in Italy it is the actors and actresses whom you must consult, as well as the composer of the music and the stage decorators. Everything must be done according to a certain form which I will explain to you.\"\nGoldoni thanked his critic, went back to his inn and ordered a fire, into which he threw the manuscript of his \"Amalasunta\".\nHis next play, \"Belisario\", written in 1734, was more successful, though of its success he afterwards professed himself ashamed.\nDuring this period he also wrote librettos for opera seria and served for a time as literary director of the San Giovanni Grisostomo, Venice's most distinguished opera house.\nHe wrote other tragedies for a time, but he was not long in discovering that his bent was for comedy. He had come to realize that the Italian stage needed reforming; adopting Moli\u00e8re as his model, he went to work in earnest and in 1738 produced his first real comedy, \"L'uomo di mondo\" (\"The Man of the World\"). During his many wanderings and adventures in Italy, he was constantly at work and when, at Livorno, he became acquainted with the manager Medebac, he determined to pursue the profession of playwriting in order to make a living. He was employed by Medebac to write plays for his theatre in Venice. He worked for other managers and produced during his stay in that city some of his most characteristic works. He also wrote \"Momolo Cortesan\" in 1738. By 1743, he had perfected his hybrid style of playwriting (combining the model of Moli\u00e8re with the strengths of \"Commedia dell'arte\" and his own wit and sincerity). This style was typified in \"La Donna di garbo\", the first Italian comedy of its kind.\nAfter 1748, Goldoni collaborated with the composer Baldassare Galuppi, making significant contributions to the new form of 'opera buffa'. Galuppi composed the score for more than twenty of Goldoni's librettos. As with his comedies, Goldoni's \"opera buffa\" integrates elements of the Commedia dell'arte with recognisable local and middle-class realities. His operatic works include two of the most successful musical comedies of the eighteenth century, \"Il filosofo di campagna\" (\"The Country Philosopher\"), set by Galuppi (1752) and \"La buona figliuola\" (\"The Good Girl\"), set by Niccol\u00f2 Piccinni (1760).\nIn 1753, following his return from Bologna, he defected to the Teatro San Luca of the Vendramin family, where he performed most of his plays to 1762.\nMove to France and death.\nIn 1757, he engaged in a bitter dispute with playwright Carlo Gozzi, which left him utterly disgusted with the tastes of his countrymen; so much so that in 1761 he moved to Paris, where he received a position at court and was put in charge of the Th\u00e9\u00e2tre-Italien. He spent the rest of his life in France, composing most of his plays in French and writing his memoirs in that language.\nAmong the plays which he wrote in French, the most successful was \"Le bourru bienfaisant\", dedicated to Marie Ad\u00e9la\u00efde, a daughter of Louis XV and aunt to the dauphin, the future Louis XVI of France. It premiered on 4 February 1771, almost nine months after the dauphin's marriage to Marie Antoinette. Goldoni enjoyed considerable popularity in France; in 1769, when he retired to Versailles, the King gave him a pension. He lost this pension after the French Revolution. The Convention eventually voted to restore his pension the day after his death. It was restored to his widow, at the pleading of the poet Andr\u00e9 Ch\u00e9nier; \"She is old\", he urged, \"she is seventy-six, and her husband has left her no heritage save his illustrious name, his virtues and his poverty.\"\nGoldoni's impact on Italian theatre.\nIn his \"Memoirs\" Goldoni amply discusses the state of Italian comedy when he began writing. At that time, Italian comedy revolved around the conventionality of the Commedia dell'arte, or improvised comedy. Goldoni took to himself the task of superseding the comedy of masks and the comedy of intrigue with representations of actual life and manners through the characters and their behaviours. He maintained that Italian life and manners were susceptible of artistic treatment such as had not been given them before.\nHis works are a lasting monument to the changes that he initiated: a dramatic revolution that had been attempted but not achieved before. Goldoni's importance lies in providing good examples rather than precepts. Goldoni says that he took for his models the plays of Moli\u00e8re and that whenever a piece of his own succeeded he whispered to himself: \"Good, but not yet Moli\u00e8re\". Goldoni's plays are gentler and more optimistic in tone than Moli\u00e8re's.\nIt was this very success that was the object of harsh critiques by Carlo Gozzi, who accused Goldoni of having deprived the Italian theatre of the charms of poetry and imagination. The great success of Gozzi's fairy dramas so irritated Goldoni that it led to his self-exile to France.\nGoldoni gave to his country a classical form, which, though it has since been cultivated, has yet to be cultivated by a master.\nThemes.\nGoldoni's plays that were written while he was still in Italy ignore religious and ecclesiastical subjects. This may be surprising, considering his staunch Catholic upbringing. No thoughts are expressed about death or repentance in his memoirs or in his comedies. After his move to France, his position became clearer, as his plays took on a clear anti-clerical tone and often satirized the hypocrisy of monks and of the Church.\nGoldoni was inspired by his love of humanity and the admiration he had for his fellow men. He wrote, and was obsessed with, the relationships that humans establish with one another, their cities and homes, and the study of philosophy. The moral and civil values that Goldoni promotes in his plays are those of rationality, civility, humanism, the importance of the rising middle class, a progressive stance on state affairs, honour and honesty. Goldoni had a dislike for arrogance, intolerance and the abuse of power.\nGoldoni's main characters are no abstract examples of human virtue, nor monstrous examples of human vice. They occupy the middle ground of human temperament. Goldoni maintains an acute sensibility for the differences in social classes between his characters as well as environmental and generational changes. Goldoni pokes fun at the arrogant nobility and the pauper who lacks dignity.\nVenetian and Tuscan.\nAs in other theatrical works of the time and place, the characters in Goldoni's Italian comedies spoke originally either the literary Tuscan variety (which became modern Italian) or the Venetian dialect, depending on their station in life. However, in some printed editions of his plays, he often turned the Venetian texts into Tuscan, too.\nGoldoni in popular culture.\nOne of his best-known works is the comic play \"Servant of Two Masters\", which has been translated and adapted internationally numerous times. In 1966 it was adapted into an opera buffa by the American composer Vittorio Giannini. In 2011, Richard Bean adapted the play for the National Theatre of Great Britain as \"One Man, Two Guvnors\". Its popularity led to a transfer to the West End and in 2012 to Broadway.\nThe film \"Carlo Goldoni \u2013 Venice, Grand Theatre of the World\", directed by Alessandro Bettero, was released in 2007 and is available in English, Italian, French, and Japanese.\nSelected works.\nThe following is a small sampling of Goldoni's enormous output.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "5792", "revid": "30395827", "url": "https://en.wikipedia.org/wiki?curid=5792", "title": "Continuous probability distribution", "text": ""}
{"id": "5793", "revid": "194203", "url": "https://en.wikipedia.org/wiki?curid=5793", "title": "Cumulative distribution function", "text": "Probability that random variable X is less than or equal to x\nIn probability theory and statistics, the cumulative distribution function (CDF) of a real-valued random variable formula_1, or just distribution function of formula_1, evaluated at formula_3, is the probability that formula_1 will take a value less than or equal to formula_3.\nEvery probability distribution supported on the real numbers, discrete or \"mixed\" as well as continuous, is uniquely identified by a right-continuous monotone increasing function (a c\u00e0dl\u00e0g function) formula_6 satisfying formula_7 and formula_8.\nIn the case of a scalar continuous distribution, it gives the area under the probability density function from negative infinity to formula_3. Cumulative distribution functions are also used to specify the distribution of multivariate random variables.\nDefinition.\nThe cumulative distribution function of a real-valued random variable formula_1 is the function given by77\nformula_11\u00a0\u00a0\u00a0(Eq.1)\nwhere the right-hand side represents the probability that the random variable formula_1 takes on a value less than or equal to formula_3.\nThe probability that formula_1 lies in the semi-closed interval formula_15, where formula_16, is therefore84\nformula_17\u00a0\u00a0\u00a0(Eq.2)\nIn the definition above, the \"less than or equal to\" sign, \"\u2264\", is a convention, not a universally used one (e.g. Hungarian literature uses \"&lt;\"), but the distinction is important for discrete distributions. The proper use of tables of the binomial and Poisson distributions depends upon this convention. Moreover, important formulas like Paul L\u00e9vy's inversion formula for the characteristic function also rely on the \"less than or equal\" formulation.\nIf treating several random variables formula_18 etc. the corresponding letters are used as subscripts while, if treating only one, the subscript is usually omitted. It is conventional to use a capital formula_19 for a cumulative distribution function, in contrast to the lower-case formula_20 used for probability density functions and probability mass functions. This applies when discussing general distributions: some specific distributions have their own conventional notation, for example the normal distribution uses formula_21 and formula_22 instead of formula_19 and formula_20, respectively.\nThe probability density function of a continuous random variable can be determined from the cumulative distribution function by differentiating using the Fundamental Theorem of Calculus; i.e. given formula_25,\nformula_26\nas long as the derivative exists.\nThe CDF of a continuous random variable formula_1 can be expressed as the integral of its probability density function formula_28 as follows:86\nformula_29\nIn the case of a random variable formula_1 which has distribution having a discrete component at a value formula_31,\nformula_32\nIf formula_33 is continuous at formula_31, this equals zero and there is no discrete component at formula_31.\nProperties.\nEvery cumulative distribution function formula_33 is non-decreasing78 and right-continuous,79 which makes it a c\u00e0dl\u00e0g function. Furthermore,\nformula_37\nEvery function with these three properties is a CDF, i.e., for every such function, a random variable can be defined such that the function is the cumulative distribution function of that random variable.\nIf formula_1 is a purely discrete random variable, then it attains values formula_39 with probability formula_40, and the CDF of formula_1 will be discontinuous at the points formula_42:\nformula_43\nIf the CDF formula_33 of a real valued random variable formula_1 is continuous, then formula_1 is a continuous random variable; if furthermore formula_33 is absolutely continuous, then there exists a Lebesgue-integrable function formula_48 such that\nformula_49\nfor all real numbers formula_50 and formula_31. The function formula_28 is equal to the derivative of formula_33 almost everywhere, and it is called the probability density function of the distribution of formula_1.\nIf formula_1 has finite L1-norm, that is, the expectation of formula_56 is finite, then the expectation is given by the Riemann\u2013Stieltjes integral \nformula_57\nand for any formula_58,\nformula_59\nas well as\nformula_60\nas shown in the diagram (consider the areas of the two red rectangles and their extensions to the right or left up to the graph of formula_33). In particular, we have \nformula_62\nIn addition, the (finite) expected value of the real-valued random variable formula_1 can be defined on the graph of its cumulative distribution function as illustrated by the drawing in the definition of expected value for arbitrary real-valued random variables.\nExamples.\nAs an example, suppose formula_1 is uniformly distributed on the unit interval formula_65.\nThen the CDF of formula_1 is given by\nformula_67\nSuppose instead that formula_1 takes only the discrete values 0 and 1, with equal probability.\nThen the CDF of formula_1 is given by\nformula_70\nSuppose formula_1 is exponential distributed. Then the CDF of formula_1 is given by\nformula_73\nHere \"\u03bb\" &gt; 0 is the parameter of the distribution, often called the rate parameter.\nSuppose formula_1 is normal distributed. Then the CDF of formula_1 is given by\nformula_76\nHere the parameter formula_77 is the mean or expectation of the distribution; and formula_78 is its standard deviation.\nA table of the CDF of the standard normal distribution is often used in statistical applications, where it is named the standard normal table, the unit normal table, or the Z table.\nSuppose formula_1 is binomial distributed. Then the CDF of formula_1 is given by\nformula_81\nHere formula_82 is the probability of success and the function denotes the discrete probability distribution of the number of successes in a sequence of formula_83 independent experiments, and formula_84 is the \"floor\" under formula_85, i.e. the greatest integer less than or equal to formula_85.\nDerived functions.\nComplementary cumulative distribution function (tail distribution).\nSometimes, it is useful to study the opposite question and ask how often the random variable is \"above\" a particular level. This is called the &lt;templatestyles src=\"Template:Visible anchor/styles.css\" /&gt;complementary cumulative distribution function (&lt;templatestyles src=\"Template:Visible anchor/styles.css\" /&gt;ccdf) or simply the &lt;templatestyles src=\"Template:Visible anchor/styles.css\" /&gt;tail distribution or &lt;templatestyles src=\"Template:Visible anchor/styles.css\" /&gt;exceedance, and is defined as\nformula_87\nThis has applications in statistical hypothesis testing, for example, because the one-sided p-value is the probability of observing a test statistic \"at least\" as extreme as the one observed. Thus, provided that the test statistic, \"T\", has a continuous distribution, the one-sided p-value is simply given by the ccdf: for an observed value formula_88 of the test statistic\nformula_89\nIn survival analysis, formula_90 is called the survival function and denoted formula_91, while the term \"reliability function\" is common in engineering.\nFolded cumulative distribution.\nWhile the plot of a cumulative distribution formula_19 often has an S-like shape, an alternative illustration is the folded cumulative distribution or mountain plot, which folds the top half of the graph over, that is\nformula_105\nwhere formula_106 denotes the indicator function and the second summand is the survivor function, thus using two scales, one for the upslope and another for the downslope. This form of illustration emphasises the median, dispersion (specifically, the mean absolute deviation from the median) and skewness of the distribution or of the empirical results.\nInverse distribution function (quantile function).\nIf the CDF \"F\" is strictly increasing and continuous then formula_107 is the unique real number formula_108 such that formula_109. This defines the inverse distribution function or quantile function.\nSome distributions do not have a unique inverse (for example if formula_110 for all &lt;math&gt;a&lt;x, causing formula_33 to be constant). In this case, one may use the generalized inverse distribution function, which is defined as\nformula_112\nSome useful properties of the inverse cdf (which are also preserved in the definition of the generalized inverse distribution function) are:\nThe inverse of the cdf can be used to translate results obtained for the uniform distribution to other distributions.\nEmpirical distribution function.\nThe empirical distribution function is an estimate of the cumulative distribution function that generated the points in the sample. It converges with probability 1 to that underlying distribution. A number of results exist to quantify the rate of convergence of the empirical distribution function to the underlying cumulative distribution function.\nMultivariate case.\nDefinition for two random variables.\nWhen dealing simultaneously with more than one random variable the joint cumulative distribution function can also be defined. For example, for a pair of random variables formula_132, the joint CDF formula_133 is given by89\nformula_134\u00a0\u00a0\u00a0(Eq.3)\nwhere the right-hand side represents the probability that the random variable formula_1 takes on a value less than or equal to formula_3 and that formula_121 takes on a value less than or equal to formula_138.\nExample of joint cumulative distribution function:\nFor two continuous variables \"X\" and \"Y\": formula_139\nFor two discrete random variables, it is beneficial to generate a table of probabilities and address the cumulative probability for each potential range of \"X\" and \"Y\", and here is the example:\ngiven the joint probability mass function in tabular form, determine the joint cumulative distribution function.\nSolution: using the given table of probabilities for each potential range of \"X\" and \"Y\", the joint cumulative distribution function may be constructed in tabular form:\nDefinition for more than two random variables.\nFor formula_140 random variables formula_141, the joint CDF formula_142 is given by\nformula_143\u00a0\u00a0\u00a0(Eq.4)\nInterpreting the formula_140 random variables as a random vector formula_145 yields a shorter notation:\nformula_146\nProperties.\nEvery multivariate CDF is:\nNot every function satisfying the above four properties is a multivariate CDF, unlike in the single dimension case. For example, let formula_150 for formula_151 or formula_152 or formula_153 and let formula_154 otherwise. It is easy to see that the above conditions are met, and yet formula_19 is not a CDF since if it was, then formula_156 as explained below.\nThe probability that a point belongs to a hyperrectangle is analogous to the 1-dimensional case:\nformula_157\nComplex case.\nComplex random variable.\nThe generalization of the cumulative distribution function from real to complex random variables is not obvious because expressions of the form formula_158 make no sense. However expressions of the form formula_159 make sense. Therefore, we define the cumulative distribution of a complex random variables via the joint distribution of their real and imaginary parts:\nformula_160\nComplex random vector.\nGeneralization of Eq.4 yields\nformula_161\nas definition for the CDS of a complex random vector formula_162.\nUse in statistical analysis.\nThe concept of the cumulative distribution function makes an explicit appearance in statistical analysis in two (similar) ways. Cumulative frequency analysis is the analysis of the frequency of occurrence of values of a phenomenon less than a reference value. The empirical distribution function is a formal direct estimate of the cumulative distribution function for which simple statistical properties can be derived and which can form the basis of various statistical hypothesis tests. Such tests can assess whether there is evidence against a sample of data having arisen from a given distribution, or evidence against two samples of data having arisen from the same (unknown) population distribution.\nKolmogorov\u2013Smirnov and Kuiper's tests.\nThe Kolmogorov\u2013Smirnov test is based on cumulative distribution functions and can be used to test to see whether two empirical distributions are different or whether an empirical distribution is different from an ideal distribution. The closely related Kuiper's test is useful if the domain of the distribution is cyclic as in day of the week. For instance Kuiper's test might be used to see if the number of tornadoes varies during the year or if sales of a product vary by day of the week or day of the month.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "5794", "revid": "15130", "url": "https://en.wikipedia.org/wiki?curid=5794", "title": "Central tendency", "text": "Statistical value representing the center or average of a distribution\nIn statistics, a central tendency (or measure of central tendency) is a central or typical value for a probability distribution.\nColloquially, measures of central tendency are often called \"averages.\" The term \"central tendency\" dates from the late 1920s.\nThe most common measures of central tendency are the arithmetic mean, the median, and the mode. A middle tendency can be calculated for either a finite set of values or for a theoretical distribution, such as the normal distribution. Occasionally authors use central tendency to denote \"the tendency of quantitative data to cluster around some central value.\"\nThe central tendency of a distribution is typically contrasted with its \"dispersion\" or \"variability\"; dispersion and central tendency are the often characterized properties of distributions. Analysis may judge whether data has a strong or a weak central tendency based on its dispersion.\nMeasures.\nThe following may be applied to one-dimensional data. Depending on the circumstances, it may be appropriate to transform the data before calculating a central tendency. Examples are squaring the values or taking logarithms. Whether a transformation is appropriate and what it should be, depend heavily on the data being analyzed.\nAny of the above may be applied to each dimension of multi-dimensional data, but the results may not be invariant to rotations of the multi-dimensional space.\nSolutions to variational problems.\nSeveral measures of central tendency can be characterized as solving a variational problem, in the sense of the calculus of variations, namely minimizing variation from the center. That is, given a measure of statistical dispersion, one asks for a measure of central tendency that minimizes variation: such that variation from the center is minimal among all choices of center. In a quip, \"dispersion precedes location\". These measures are initially defined in one dimension, but can be generalized to multiple dimensions. This center may or may not be unique. In the sense of spaces, the correspondence is:\nThe associated functions are called -norms: respectively 0-\"norm\", 1-norm, 2-norm, and \u221e-norm. The function corresponding to the L0 space is not a norm, and is thus often referred to in quotes: 0-\"norm\".\nIn equations, for a given (finite) data set X, thought of as a vector , the dispersion about a point c is the \"distance\" from x to the constant vector in the p-norm (normalized by the number of points n):\nformula_1\nFor and these functions are defined by taking limits, respectively as and . For the limiting values are 00 \n 0 and for , so the difference becomes simply equality, so the 0-norm counts the number of \"unequal\" points. For the largest number dominates, and thus the \u221e-norm is the maximum difference.\nUniqueness.\nThe mean (\"L\"2 center) and midrange (\"L\"\u221e center) are unique (when they exist), while the median (\"L\"1 center) and mode (\"L\"0 center) are not in general unique. This can be understood in terms of convexity of the associated functions (coercive functions).\nThe 2-norm and \u221e-norm are strictly convex, and thus (by convex optimization) the minimizer is unique (if it exists), and exists for bounded distributions. Thus standard deviation about the mean is lower than standard deviation about any other point, and the maximum deviation about the midrange is lower than the maximum deviation about any other point.\nThe 1-norm is not \"strictly\" convex, whereas strict convexity is needed to ensure uniqueness of the minimizer. Correspondingly, the median (in this sense of minimizing) is not in general unique, and in fact any point between the two central points of a discrete distribution minimizes average absolute deviation.\nThe 0-\"norm\" is not convex (hence not a norm). Correspondingly, the mode is not unique \u2013 for example, in a uniform distribution \"any\" point is the mode.\nClustering.\nInstead of a single central point, one can ask for multiple points such that the variation from these points is minimized. This leads to cluster analysis, where each point in the data set is clustered with the nearest \"center\". Most commonly, using the 2-norm generalizes the mean to \"k\"-means clustering, while using the 1-norm generalizes the (geometric) median to \"k\"-medians clustering. Using the 0-norm simply generalizes the mode (most common value) to using the \"k\" most common values as centers.\nUnlike the single-center statistics, this multi-center clustering cannot in general be computed in a closed-form expression, and instead must be computed or approximated by an iterative method; one general approach is expectation\u2013maximization algorithms.\nInformation geometry.\nThe notion of a \"center\" as minimizing variation can be generalized in information geometry as a distribution that minimizes divergence (a generalized distance) from a data set. The most common case is maximum likelihood estimation, where the maximum likelihood estimate (MLE) maximizes likelihood (minimizes expected surprisal), which can be interpreted geometrically by using entropy to measure variation: the MLE minimizes cross-entropy (equivalently, relative entropy, Kullback\u2013Leibler divergence).\nA simple example of this is for the center of nominal data: instead of using the mode (the only single-valued \"center\"), one often uses the empirical measure (the frequency distribution divided by the sample size) as a \"center\". For example, given binary data, say heads or tails, if a data set consists of 2 heads and 1 tails, then the mode is \"heads\", but the empirical measure is 2/3 heads, 1/3 tails, which minimizes the cross-entropy (total surprisal) from the data set. This perspective is also used in regression analysis, where least squares finds the solution that minimizes the distances from it, and analogously in logistic regression, a maximum likelihood estimate minimizes the surprisal (information distance).\nRelationships between the mean, median and mode.\nFor unimodal distributions the following bounds are known and are sharp:\n formula_2\n formula_3\n formula_2\nwhere \"\u03bc\" is the mean, \"\u03bd\" is the median, \"\u03b8\" is the mode, and \"\u03c3\" is the standard deviation.\nFor every distribution,\n formula_5\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "5796", "revid": "14498400", "url": "https://en.wikipedia.org/wiki?curid=5796", "title": "Celebrity", "text": "Fame in mass media\nCelebrity is a condition of fame and broad public recognition of a person or group due to the attention given to them by mass media. The word is also used to refer to famous individuals. A person may attain celebrity status by having great wealth, participation in sports or the entertainment industry, their position as a political figure, or even their connection to another celebrity. 'Celebrity' usually implies a favorable public image, as opposed to the neutrals 'famous' or 'notable', or the negatives 'infamous' and 'notorious'.\nHistory.\nIn his 2020 book \"Dead Famous: An Unexpected History Of Celebrity\", British historian Greg Jenner uses the definition:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nAlthough his book is subtitled \"from Bronze Age to Silver Screen\", and despite the fact that \"Until very recently, sociologists argued that \"celebrity\" was invented just over 100 years ago, in the flickering glimmer of early Hollywood\" and the suggestion that some medieval saints might qualify, Jenner asserts that the earliest celebrities lived in the early 1700s, his first example being Henry Sacheverell. Over time, the invention of more types of mass media has broadened the ways in which people have become famous.\nAthletes in Ancient Greece were welcomed home as heroes, had songs and poems written in their honor, and received free food and gifts from those seeking celebrity endorsement. Ancient Rome similarly lauded actors and notorious gladiators, and Julius Caesar appeared on a coin in his own lifetime (a departure from the usual depiction of battles and divine lineage).\nIn the early 12th century, Thomas Becket became famous following his murder, the first possible case of posthumous popularity. The Christian Church promoted him as a martyr, and images of him and scenes from his life became widespread in just a few years. In a pattern often repeated, what started as an explosion of popularity (often referred to with the suffix 'mania') turned into long-lasting fame: pilgrimages to Canterbury Cathedral, where he was killed, became instantly fashionable, and the fascination with his life and death inspired plays and films.\nThe cult of personality (particularly in the west) can be traced back to the Romantics in the 18th century, whose livelihood as artists and poets depended on the currency of their reputation. Lord Byron became a celebrity in 1812 after the publication of the first two cantos of \"Childe Harold's Pilgrimage\". \"I awoke one morning and found myself famous,\" he said. According to McGann: \"He rapidly became the most brilliant star in the dazzling world of Regency London.\"\nEstablishing cultural hot spots became important in generating fame, such as in London and Paris in the 18th and 19th centuries. Newspapers started including \"gossip\" columns, and certain clubs and events became places to be seen to receive publicity. Madame Tussauds, a museum that displays waxworks of famous figures, was first established in Baker Street, London in 1835, with \"Punch\" in 1849 stating: \"In these days, no one can be considered positively popular, unless he is admitted into the company of Madame Tussaud's celebrities in Baker Street\". David Lodge called Charles Dickens the \"first writer to feel the intense pressure of being simultaneously an artist and an object of unrelenting public interest and adulation\", and Juliet John backed up the claim for Dickens \"to be called the first self-made global media star of the age of mass culture.\"\nTheatrical actors were often considered celebrities. Restaurants near theaters, where actors would congregate, began putting up caricatures or photographs of actors on celebrity walls in the late 19th century. The subject of widespread public and media interest, Lillie Langtry, made her West End theatre debut in 1881 causing a sensation in London by becoming the first socialite to appear on stage. The following year she became the poster-girl for Pears Soap, becoming the first celebrity to endorse a commercial product. In 1895, poet and playwright Oscar Wilde became the subject of \"one of the first celebrity trials\".\nAnother example of celebrities in the entertainment industry was in music, beginning in the mid-19th century. Never seen before in music, many people engaged in an immense fan frenzy called Lisztomania that began in 1841. This created the basis for the behavior fans have around their favorite musicians in modern society.\nThe movie industry spread around the globe in the first half of the 20th century, creating the first film celebrities. The term celebrity was not always tied to actors in films however, especially when cinema was starting as a medium. As Paul McDonald states in \"The Star System: Hollywood's Production of Popular Identities\", \"In the first decade of the twentieth century, American film production companies withheld the names of film performers, despite requests from audiences, fearing that public recognition would drive performers to demand higher salaries.\" Public fascination went well beyond the on-screen exploits of movie stars, and their private lives became headline news: for example, in Hollywood the marriages of Elizabeth Taylor and in Bollywood the affairs of Raj Kapoor in the 1950s. Like theatrical actors before them, movie actors were the subjects of celebrity walls in restaurants they frequented, near movie studios, most notably at Sardi's in Hollywood.\nThe second half of the century saw television and popular music bring new forms of celebrity, such as the rock star and the pop group, epitomised by Elvis Presley and the Beatles, respectively. John Lennon's highly controversial 1966 quote: \"We're more popular than Jesus now\", which he later insisted was not a boast, and that he was not in any way comparing himself with Christ, gives an insight into both the adulation and notoriety that fame can bring. Unlike movies, television created celebrities who were not primarily actors; for example, presenters, talk show hosts, and newsreaders. However, most of these are only famous within the regions reached by their particular broadcaster, and only a few such as Oprah Winfrey, Jerry Springer, or David Frost could be said to have broken through into wider stardom. Television also gave exposure to sportspeople, notably Pel\u00e9 after his emergence at the 1958 FIFA World Cup, with Barney Ronay in \"The Guardian\" stating, \"What is certain is that Pel\u00e9 invented this game, the idea of individual global sporting superstardom, and in a way that is unrepeatable now.\"\nIn the '60s and early '70s, the book publishing industry began to persuade major celebrities to put their names on autobiographies and other titles in a genre called celebrity publishing. In most cases, the book was not written by the celebrity but by a ghostwriter, but the celebrity would then be available for a book tour and appearances on talk shows.\nWealth.\n\"Forbes\" celebrity lists.\n\"Forbes\" magazine releases an annual list of the highest-paid celebrities in the world, \"Forbes\" Top 40 between 1987-1999, later reacreated as \"Forbes\" Celebrity 100. The total earnings for all top celebrity 100 earners totaled $4.5 billion in 2010 alone.\nFor instance, \"Forbes\" ranked media mogul and talk show host, Oprah Winfrey as the top earner \"Forbes magazine's annual ranking of the most powerful celebrities\", with earnings of $290 million in the past year. Forbes cites that Lady Gaga reportedly earned over $90 million in 2010. In 2011, golfer Tiger Woods was one of highest-earning celebrity athletes, with an income of $74 million and is consistently ranked one of the highest-paid athletes in the world. In 2013, Madonna was ranked as the fifth most powerful and the highest-earning celebrity of the year with earnings of $125 million. She has consistently been among the most powerful and highest-earning celebrities in the world, occupying the third place in Forbes Celebrity 100 2009 with $110 million of earnings, and getting the tenth place in the 2011 edition of the list with annual earnings equal to $58 million. Beyonc\u00e9 has also appeared in the top ten in 2008, 2009, 2010, 2013, 2017, and topped the list in 2014 with earnings of $115 million. Cristiano Ronaldo followed by Lionel Messi in 2020 became the first two athletes in a team sport to surpass $1\u00a0billion in earnings during their careers.\n\"Forbes\" also lists the top-earning deceased celebrities, with singer Michael Jackson, fantasy author J. R. R. Tolkien and children's author Roald Dahl each topping the annual list with earnings of $500 million over the course of a year.\nEntrepreneurship and endorsements.\nCelebrity endorsements have proven very successful around the world where, due to increasing consumerism, a person owns a \"status symbol\" by purchasing a celebrity-endorsed product. Although it has become commonplace for celebrities to place their name with endorsements onto products just for quick money, some celebrities have gone beyond merely using their names and have put their entrepreneurial spirit to work by becoming entrepreneurs by attaching themselves in the business aspects of entertainment and building their own business brand beyond their traditional salaried activities. Along with investing their salaried wages into growing business endeavors, several celebrities have become innovative business leaders in their respective industries.\nNumerous celebrities have ventured into becoming business moguls and established themselves as entrepreneurs, idolizing many well known business leaders such as Bill Gates, Richard Branson and Warren Buffett. For instance, former basketball player Michael Jordan became an entrepreneur involved with many sports-related ventures including investing a minority stake in the Charlotte Bobcats, Paul Newman started his own salad dressing business after leaving behind a distinguished acting career, and rap musician Birdman started his own record label, clothing line, and an oil business while maintaining a career as a rap artist. In 2014, David Beckham became co-owner of new Major League Soccer team Inter Miami, which began playing in 2020. Former Brazil striker and World Cup winner Ronaldo became the majority owner of La Liga club Real Valladolid in 2018. Other celebrities such as Tyler Perry, George Lucas, and Steven Spielberg have become successful entrepreneurs through starting their own film production companies and running their own movie studios beyond their traditional activities.\nTabloid magazines and talk TV shows bestow a great deal of attention to celebrities. To stay in the public eye and build wealth in addition to their salaried labor, numerous celebrities have begun participating and branching into various business ventures and endorsements, which include: animation, publishing, fashion designing, cosmetics, consumer electronics, household items and appliances, cigarettes, soft drinks and alcoholic beverages, hair care, hairdressing, jewelry design, fast food, credit cards, video games, writing, and toys.\nIn addition to these, some celebrities have been involved with some business and investment-related ventures also include: sports team ownership, fashion retailing, establishments such as restaurants, cafes, hotels, and casinos, movie theaters, advertising and event planning, management-related ventures such as sports management, financial services, model management, and talent management, record labels, film production, television production, publishing books and music, massage therapy, salons, health and fitness, and real estate.\nAlthough some celebrities have achieved additional financial success from various business ventures, the vast majority of celebrities are not successful businesspeople and still rely on salaried labored wages to earn a living. Not all celebrities eventually succeed with their businesses and other related side ventures. Some celebrities either went broke or filed for bankruptcy as a result of dabbling with such side businesses or endorsements.\nFamous for being famous.\n\"Famous for being famous\", in popular culture terminology, refers to someone who attains celebrity status for no particular identifiable reason, or who achieves fame through association with a celebrity. The term is a pejorative, suggesting the target has no particular talents or abilities. British journalist Malcolm Muggeridge made the first known usage of the phrase in the introduction to his book \"Muggeridge Through The Microphone: BBC Radio and Television\" (1967) in which he wrote:In the past if someone was famous or notorious, it was for something\u2014as a writer or an actor or a criminal; for some talent or distinction or abomination. Today one is famous for being famous. People who come up to one in the street or in public places to claim recognition nearly always say: \"I've seen you on the telly!\"\nThe coinages \"famesque\" and \"celebutante\" are of similar pejorative gist.\nThis shift has sparked criticism for promoting superficial recognition over substantive achievements and reflects broader changes in how fame and success are perceived in modern culture.\nMass media phenomena.\nMass media has dramatically reshaped the concept of celebrity by amplifying visibility and extending fame globally. With the rise of television, social media, and reality TV, individuals can achieve stardom not just through traditional talents but also through their personal lives and online presence. This heightened visibility brings intense public scrutiny, where every detail of a celebrity's life is subject to constant media coverage. Celebrities often become brands themselves, influencing trends and consumer behavior while navigating the pressures of privacy erosion and mental health challenges.\nCelebrities may be resented for their accolades, and the public may have a love/hate relationship with celebrities. Due to the high visibility of celebrities' private lives, their successes and shortcomings are often made very public. Celebrities are alternately portrayed as glowing examples of perfection, when they garner awards, or as decadent or immoral if they become associated with a scandal. When seen in a positive light, celebrities are frequently portrayed as possessing skills and abilities beyond average people; for example, celebrity actors are routinely celebrated for acquiring new skills necessary for filming a role within a very brief time, and to a level that amazes the professionals who train them. Similarly, some celebrities with very little formal education can sometimes be portrayed as experts on complicated issues. Some celebrities have been very vocal about their political views. For example, Matt Damon expressed his displeasure with 2008 US vice presidential nominee Sarah Palin, as well as with the 2011 United States debt-ceiling crisis.\nInternet.\nAlso known as being \"internet famous\".\nSocial networking and video hosting.\nMost high-profile celebrities participate in social networking services and photo or video hosting platforms such as YouTube, Twitter, Facebook, Instagram, and Snapchat. Social networking services allow celebrities to communicate directly with their fans, removing the \"traditional\" media. Through social media, many people outside of the entertainment and sports sphere become a celebrity in their own sphere. Social media humanizes celebrities in a way that arouses public fascination as evident by the success of magazines such as \"Us Weekly\" and \"People Weekly\". Celebrity blogging has also spawned stars such as Perez Hilton who is known for not only blogging but also outing celebrities.\nSocial media and the rise of the smartphone has changed how celebrities are treated and how people gain the platform of fame. Websites like Twitter, Facebook, Instagram, and YouTube allow people to become a celebrity in a different manner. For example, Justin Bieber got his start on YouTube by posting videos of him singing. His fans were able to directly contact him through his content and were able to interact with him on several social media platforms. The internet, as said before, also allows fans to connect with their favorite celebrity without ever meeting them in person.\nSocial media sites have also contributed to the fame of certain celebrities, such as Tila Tequila who became known through MySpace.\nAsia.\nA report by the BBC highlighted a longtime trend of Asian internet celebrities called Wanghong in Chinese. According to the BBC, there are two kinds of online celebrities in China\u2014those who create original content, such as Papi Jiang, who is regularly censored by Chinese authorities for cursing in her videos, and Wanghongs fall under the second category, as they have clothing and cosmetics businesses on Taobao, China's equivalent of Amazon.\nAccess restriction.\nAccess to celebrities is strictly controlled by the celebrities entourage of staff which includes managers, publicists, agents, personal assistants, and bodyguards. Journalists may even have difficulty accessing celebrities for interviews. Writer and actor Michael Musto said, \"You have to go through many hoops just to talk to a major celebrity. You have to get past three different sets of publicists: the publicist for the event, the publicist for the movie, and then the celebrity's personal publicist. They all have to approve you.\"\nCelebrities also typically have security staff at their home or properties, to protect them and their belongs from similar threats.\n\"Fifteen minutes of fame\".\n\"15 minutes of fame\" is a phrase often used as slang to short-lived publicity. Certain \"15 minutes of fame\" celebrities can be average people seen with an A-list celebrity, who are sometimes noticed on entertainment news channels such as E! News. These are ordinary people becoming celebrities, often based on the ridiculous things they do.\n\"In fact, many reality show contestants fall into this category: the only thing that qualifies them to be on TV is that they're real.\"\nHealth implications.\nCommon threats such as stalking have spawned celebrity worship syndrome where a person becomes overly involved with the details of a celebrity's personal life. Psychologists have indicated that though many people obsess over glamorous film, television, sport and music stars, the disparity in salaries in society seems to value professional athletes and entertainment industry-based professionals. One study found that singers, musicians, actors and athletes die younger on average than writers, composers, academics, politicians and businesspeople, with a greater incidence of cancer and especially lung cancer. However, it was remarked that the reasons for this remained unclear, with theories including innate tendencies towards risk-taking as well as the pressure or opportunities of particular types of fame.\nFame might have negative psychological effects. An academic study on the subject said that fame has an addictive quality to it. When a celebrity's fame recedes over time, the celebrity may find it difficult to adjust psychologically.\nRecently, there has been more attention toward the impact celebrities have on health decisions of the population at large. It is believed that the public will follow celebrities' health advice to some extent. This can have positive impacts when the celebrities give solid, evidence-informed health advice, however, it can also have detrimental effects if the health advice is not accurate enough.\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "5797", "revid": "194203", "url": "https://en.wikipedia.org/wiki?curid=5797", "title": "Cluster sampling", "text": "Sampling methodology in statistics\nIn statistics, cluster sampling is a sampling plan used when mutually homogeneous yet internally heterogeneous groupings are evident in a statistical population. It is often used in marketing research. \nIn this sampling plan, the total population is divided into these groups (known as clusters) and a simple random sample of the groups is selected. The elements in each cluster are then sampled. If all elements in each sampled cluster are sampled, then this is referred to as a \"one-stage\" cluster sampling plan. If a simple random subsample of elements is selected within each of these groups, this is referred to as a \"two-stage\" cluster sampling plan. A common motivation for cluster sampling is to reduce the total number of interviews and costs given the desired accuracy. For a fixed sample size, the expected random error is smaller when most of the variation in the population is present internally within the groups, and not between the groups.\nCluster elemental.\nThe population within a cluster should ideally be as heterogeneous as possible, but there should be homogeneity between clusters. Each cluster should be a small-scale representation of the total population. The clusters should be mutually exclusive and collectively exhaustive. A random sampling technique is then used on any relevant clusters to choose which clusters to include in the study. In single-stage cluster sampling, all the elements from each of the selected clusters are sampled. In two-stage cluster sampling, a random sampling technique is applied to the elements from each of the selected clusters.\nThe main difference between cluster sampling and stratified sampling is that in cluster sampling the cluster is treated as the sampling unit so sampling is done on a population of clusters (at least in the first stage). In stratified sampling, the sampling is done on elements within each stratum. In stratified sampling, a random sample is drawn from each of the strata, whereas in cluster sampling only the selected clusters are sampled. A common motivation for cluster sampling is to reduce costs by increasing sampling efficiency. This contrasts with stratified sampling where the motivation is to increase precision.\nThere is also multistage cluster sampling, where at least two stages are taken in selecting elements from clusters.\nWhen clusters are of different sizes.\nWithout modifying the estimated parameter, cluster sampling is unbiased when the clusters are approximately the same size. In this case, the parameter is computed by combining all the selected clusters. When the clusters are of different sizes there are several options:\nOne method is to sample clusters and then survey all elements in that cluster. Another method is a two-stage method of sampling a fixed proportion of units (be it 5% or 50%, or another number, depending on cost considerations) from within each of the selected clusters. Relying on the sample drawn from these options will yield an unbiased estimator. However, the sample size is no longer fixed upfront. This leads to a more complicated formula for the standard error of the estimator, as well as issues with the optics of the study plan (since the power analysis and the cost estimations often relate to a specific sample size).\nA third possible solution is to use probability proportionate to size sampling. In this sampling plan, the probability of selecting a cluster is proportional to its size, so a large cluster has a greater probability of selection than a small cluster. The advantage here is that when clusters are selected with probability proportionate to size, the same number of interviews should be carried out in each sampled cluster so that each unit sampled has the same probability of selection.\nApplications of cluster sampling.\nAn example of cluster sampling is area sampling or geographical cluster sampling. Each cluster is a geographical area in an area sampling frame. Because a geographically dispersed population can be expensive to survey, greater economy than simple random sampling can be achieved by grouping several respondents within a local area into a cluster. It is usually necessary to increase the total sample size to achieve equivalent precision in the estimators, but cost savings may make such an increase in sample size feasible.\nFor the organization of a population census, the first step is usually dividing the overall geographic area into enumeration areas or census tracts for the field work organization. Enumeration areas may be also useful as first-stage units for cluster sampling in many types of surveys. When a population census is outdated, the list of individuals should not be directly used as sampling frame for a socio-economic survey. Updating the whole census is economically unfeasible. A good alternative may be keeping the old enumeration areas, with some update in highly dynamic areas, such as urban suburbs, selecting a sample of enumeration areas and updating the list of individuals or households only in the selected enumeration areas. \nCluster sampling is used to estimate low mortalities in cases such as wars, famines and natural disasters.\nFisheries science.\nIt is almost impossible to take a simple random sample of fish from a population, which would require that individuals are captured individually and at random. This is because fishing gears capture fish in groups (or clusters). \nIn commercial fisheries sampling, the costs of operating at sea are often too large to select hauls individually and at random. Therefore, observations are further clustered by either vessel or fishing trip.\nEconomics.\nThe World Bank has applied adaptive cluster sampling to study informal businesses in developing countries in a cost efficient manner, as the informal sector is not captured by official records and too expensive to be studied through simple random sampling. The approach follows a two-stage sampling whereby adaptive cluster sampling is used to generate an estimate of the universe of informal businesses in operations, while the second stage to obtain a random sample about the characteristics of those businesses.\nAdvantages.\nMajor use: when the sampling frame of all elements is not available we can resort only to cluster sampling.\nMore on cluster sampling.\nTwo-stage cluster sampling.\nTwo-stage cluster sampling, a simple case of multistage sampling, is obtained by selecting cluster samples in the first stage and then selecting a sample of elements from every sampled cluster. Consider a population of \"N\" clusters in total. In the first stage, \"n\" clusters are selected using the ordinary cluster sampling method. In the second stage, simple random sampling is usually used. It is used separately in every cluster and the numbers of elements selected from different clusters are not necessarily equal. The total number of clusters \"N\", the number of clusters selected \"n\", and the numbers of elements from selected clusters need to be pre-determined by the survey designer. Two-stage cluster sampling aims at minimizing survey costs and at the same time controlling the uncertainty related to estimates of interest. This method can be used in health and social sciences. For instance, researchers used two-stage cluster sampling to generate a representative sample of the Iraqi population to conduct mortality surveys. Sampling in this method can be quicker and more reliable than other methods, which is why this method is now used frequently.\nInference when the number of clusters is small.\nCluster sampling methods can lead to significant bias when working with a small number of clusters. For instance, it can be necessary to cluster at the state or city-level, units that may be small and fixed in number. Microeconometrics methods for panel data often use short panels, which is analogous to having few observations per clusters and many clusters. The small cluster problem can be viewed as an incidental parameter problem. While the point estimates can be reasonably precisely estimated, if the number of observations per cluster is sufficiently high, we need the number of clusters formula_1 for the asymptotics to kick in. If the number of clusters is low the estimated covariance matrix can be downward biased.\nSmall numbers of clusters are a risk when there is serial correlation or when there is intraclass correlation as in the Moulton context. When having few clusters, we tend to underestimate serial correlation across observations when a random shock occurs, or the intraclass correlation in a Moulton setting. Several studies have highlighted the consequences of serial correlation and highlighted the small-cluster problem.\nIn the framework of the Moulton factor, an intuitive explanation of the small cluster problem can be derived from the formula for the Moulton factor. Assume for simplicity that the number of observations per cluster is fixed at \"n\". Below, formula_2 stands for the covariance matrix adjusted for clustering, formula_3 stands for the covariance matrix not adjusted for clustering, and \u03c1 stands for the intraclass correlation:\n formula_4\nThe ratio on the left-hand side indicates how much the unadjusted scenario overestimates the precision. Therefore, a high number means a strong downward bias of the estimated covariance matrix. A small cluster problem can be interpreted as a large n: when the data is fixed and the number of clusters is low, the number of data within a cluster can be high. It follows that inference, when the number of clusters is small, will not have the correct coverage.\nSeveral solutions for the small cluster problem have been proposed. One can use a bias-corrected cluster-robust variance matrix, make T-distribution adjustments, or use bootstrap methods with asymptotic refinements, such as the percentile-t or wild bootstrap, that can lead to improved finite sample inference. Cameron, Gelbach and Miller (2008) provide microsimulations for different methods and find that the wild bootstrap performs well in the face of a small number of clusters.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "5798", "revid": "6781", "url": "https://en.wikipedia.org/wiki?curid=5798", "title": "Closeted person", "text": ""}
{"id": "5799", "revid": "35126782", "url": "https://en.wikipedia.org/wiki?curid=5799", "title": "Coming out of the closet", "text": ""}
{"id": "5801", "revid": "36767729", "url": "https://en.wikipedia.org/wiki?curid=5801", "title": "Catholicism/Councils", "text": ""}
{"id": "5802", "revid": "36767729", "url": "https://en.wikipedia.org/wiki?curid=5802", "title": "Catholicism/Council of Trent", "text": ""}
{"id": "5803", "revid": "36767729", "url": "https://en.wikipedia.org/wiki?curid=5803", "title": "Catholicism/Second Vatican Council", "text": ""}
{"id": "5804", "revid": "44248157", "url": "https://en.wikipedia.org/wiki?curid=5804", "title": "Charles Baudelaire", "text": "French poet and critic (1821\u20131867)\nCharles Pierre Baudelaire (; ; ; 9 April 1821 \u2013 31 August 1867) was a French poet, essayist, translator and art critic. His poems are described as exhibiting mastery of rhythm and rhyme, containing an exoticism inherited from the Romantics, and are based on observations of real life.\nHis most famous work, a book of lyric poetry titled \"Les Fleurs du mal\" (\"The Flowers of Evil\"), expresses the changing nature of beauty in the rapidly industrialising Paris caused by Haussmann's renovation of Paris during the mid-19th century. Baudelaire's original style of prose-poetry influenced a generation of poets including Paul Verlaine, Arthur Rimbaud and St\u00e9phane Mallarm\u00e9. He coined the term modernity (\"modernit\u00e9\") to designate the fleeting experience of life in an urban metropolis, and the responsibility of artistic expression to capture that experience. Marshall Berman has credited Baudelaire as being the first Modernist.\nEarly life.\nBaudelaire was born in Paris, France, on 9 April 1821, and baptized two months later at Saint-Sulpice Catholic church. His father, Joseph-Fran\u00e7ois Baudelaire, was a senior civil servant and amateur artist, who at 60, was 34 years older than Baudelaire's 26-year-old mother, Caroline (n\u00e9e Dufa\u00ffs); she was his second wife.\nJoseph-Fran\u00e7ois died during Baudelaire's childhood, at rue Hautefeuille, Paris, on 10 February 1827. The following year, Caroline married Lieutenant Colonel Jacques Aupick, who later became a French ambassador to various noble courts.\nBaudelaire's biographers have often seen this as a crucial moment, considering that finding himself no longer the sole focus of his mother's affection left him with a trauma, which goes some way to explaining the excesses later apparent in his life. He stated in a letter to her that, \"There was in my childhood a period of passionate love for you.\" Baudelaire regularly begged his mother for money throughout his career, often promising that a lucrative publishing contract or journalistic commission was just around the corner.\nBaudelaire was educated in Lyon, where he boarded. At 14, he was described by a classmate as \"much more refined and distinguished than any of our fellow pupils ... we are bound to one another ... by shared tastes and sympathies, the precocious love of fine works of literature.\"\nBaudelaire was erratic in his studies, at times diligent, at other times prone to \"idleness\". Later, he attended the Lyc\u00e9e Louis-le-Grand in Paris, studying law, a popular course for those not yet decided on any particular career. He began to frequent prostitutes and may have contracted gonorrhea and syphilis during this period. He also began to run up debts, mostly for clothes.\nUpon gaining his degree in 1839, he told his brother \"I don't feel I have a vocation for anything.\" His stepfather had in mind a career in law or diplomacy, but instead Baudelaire decided to embark upon a literary career. His mother later recalled: \"Oh, what grief! If Charles had let himself be guided by his stepfather, his career would have been very different ... He would not have left a name in literature, it is true, but we should have been happier, all three of us.\"\nHis stepfather sent him on a voyage to Calcutta, India in 1841 in the hope of ending his dissolute habits. The trip provided strong impressions of the sea, sailing, and exotic ports, that he later employed in his poetry. Baudelaire later exaggerated his aborted trip to create a legend about his youthful travels and experiences, including \"riding on elephants\".\nOn returning to the taverns of Paris, he began to compose some of the poems of \"Les Fleurs du Mal\". At 21, he received a sizable inheritance but squandered much of it within a few years. His family obtained a decree to place his property in trust, which he resented bitterly, at one point arguing that allowing him to fail financially would have been the one sure way of teaching him to keep his finances in order.\nBaudelaire became known in artistic circles as a dandy and free-spender, going through much of his inheritance and allowance in a short period of time. During this time, Jeanne Duval, a French-born actress, became his mistress. She was rejected by his family. His mother thought Duval a \"Black Venus\" who \"tortured him in every way\" and drained him of money at every opportunity. Baudelaire made a suicide attempt during this period.\nHe took part in the Revolutions of 1848 and wrote for a revolutionary newspaper. However, his interest in politics was passing, as he was later to note in his journals.\nIn the early 1850s, Baudelaire struggled with poor health, pressing debts, and irregular literary output. He often moved from one lodging to another to escape creditors. He undertook many projects that he was unable to complete, though he did finish translations of stories by Edgar Allan Poe.\nUpon the death of his stepfather in 1857, Baudelaire received no mention in the will but he was heartened nonetheless that the division with his mother might now be mended. At 36, he wrote to her: \"believe that I belong to you absolutely, and that I belong only to you.\" His mother died on 16 August 1871, outliving her son by almost four years.\nPublishing career.\nHis first published work, under the pseudonym Baudelaire Dufa\u00ffs, was his art review \"Salon of 1845\", which attracted immediate attention for its boldness. Many of his critical opinions were novel in their time, including his championing of Delacroix, and some of his views seem remarkably in tune with the future theories of the Impressionist painters.\nIn 1846, Baudelaire wrote his second Salon review, gaining additional credibility as an advocate and critic of Romanticism. His continued support of Delacroix as the foremost Romantic artist gained widespread notice. The following year Baudelaire's novella \"La Fanfarlo\" was published.\n\"The Flowers of Evil\".\nBaudelaire was a slow and very attentive worker. However, he often was sidetracked by indolence, emotional distress and illness, and it was not until 1857 that he published \"Les Fleurs du mal\" (\"The Flowers of Evil\"), his first and most famous volume of poems. Some of these poems had already appeared in the \"Revue des deux mondes\" (\"Review of Two Worlds\") in 1855, when they were published by Baudelaire's friend Auguste Poulet-Malassis. Some of the poems had appeared as \"fugitive verse\" in various French magazines during the previous decade.\nThe poems found a small, yet appreciative audience. However, greater public attention was given to their subject matter. The effect on fellow artists was, as Th\u00e9odore de Banville stated, \"immense, prodigious, unexpected, mingled with admiration and with some indefinable anxious fear\". Gustave Flaubert, recently attacked in a similar fashion for \"Madame Bovary\" (and acquitted), was impressed and wrote to Baudelaire: \"You have found a way to rejuvenate Romanticism...You are as unyielding as marble, and as penetrating as an English mist.\"\nThe principal themes of sex and death were considered scandalous for the period. He also touched on lesbianism, sacred and profane love, metamorphosis, melancholy, the corruption of the city, lost innocence, the oppressiveness of living, and wine. Notable in some poems is Baudelaire's use of imagery of the sense of smell and of fragrances, which is used to evoke feelings of nostalgia and past intimacy.\nThe book, however, quickly became a byword for unwholesomeness among mainstream critics of the day. Some critics called a few of the poems \"masterpieces of passion, art and poetry,\" but other poems were deemed to merit no less than legal action to suppress them. J. Habas led the charge against Baudelaire, writing in : \"Everything in it which is not hideous is incomprehensible, everything one understands is putrid.\" Baudelaire responded to the outcry in a prophetic letter to his mother:\n\"You know that I have always considered that literature and the arts pursue an aim independent of morality. Beauty of conception and style is enough for me. But this book, whose title (\"Fleurs du mal\") says everything, is clad, as you will see, in a cold and sinister beauty. It was created with rage and patience. Besides, the proof of its positive worth is in all the ill that they speak of it. The book enrages people. Moreover, since I was terrified myself of the horror that I should inspire, I cut out a third from the proofs. They deny me everything, the spirit of invention and even the knowledge of the French language. I don't care a rap about all these imbeciles, and I know that this book, with its virtues and its faults, will make its way in the memory of the lettered public, beside the best poems of V. Hugo, Th. Gautier and even Byron.\"\nBaudelaire, his publisher and the printer were successfully prosecuted for creating an offense against public morals. They were fined, but Baudelaire was not imprisoned. Six of the poems were suppressed, but printed later as \"Les \u00c9paves\" (\"The Wrecks\") (Brussels, 1866). Another edition of \"Les Fleurs du mal\", without these poems, but with considerable additions, appeared in 1861. Many notables rallied behind Baudelaire and condemned the sentence. Victor Hugo wrote to him: \"Your \"fleurs du mal\" shine and dazzle like stars...I applaud your vigorous spirit with all my might.\" Baudelaire did not appeal the judgment, but his fine was reduced. Nearly 100 years later, on 11 May 1949, Baudelaire was vindicated, the judgment officially reversed, and the six banned poems reinstated in France.\nIn the poem \"Au lecteur\" (\"To the Reader\") that prefaces \"Les Fleurs du mal\", Baudelaire accuses his readers of hypocrisy and of being as guilty of sins and lies as the poet:\n... If rape or arson, poison or the knife\nHas wove no pleasing patterns in the stuff\nOf this drab canvas we accept as life\u2014\nIt is because we are not bold enough!\n(Roy Campbell's translation)\nFinal years.\nBaudelaire next worked on a translation and adaptation of Thomas De Quincey's \"Confessions of an English Opium-Eater\". Other works in the years that followed included \"Petits Po\u00e8mes en prose\" (\"Small Prose poems\"); a series of art reviews published in the \"Pays, Exposition universelle\" (\"Country, World Fair\"); studies on Gustave Flaubert (in \"L'Artiste\", 18 October 1857); on Th\u00e9ophile Gautier (\"Revue contemporaine\", September 1858); various articles contributed to Eug\u00e8ne Cr\u00e9pet's \"Po\u00e8tes fran\u00e7ais\"; \"Les Paradis artificiels: opium et haschisch\" (\"French poets; Artificial Paradises: opium and hashish\") (1860); and \"Un Dernier Chapitre de l'histoire des oeuvres de Balzac\" (\"A Final Chapter of the history of works of Balzac\") (1880), originally an article \"Comment on paye ses dettes quand on a du g\u00e9nie\" (\"How one pays one's debts when one has genius\"), in which his criticism turns against his friends Honor\u00e9 de Balzac, Th\u00e9ophile Gautier, and G\u00e9rard de Nerval.\nBy 1859, his illnesses, his long-term use of laudanum, his life of stress, and his poverty had taken a toll and Baudelaire had aged noticeably. But at last, his mother relented and agreed to let him live with her for a while at Honfleur. Baudelaire was productive and at peace in the seaside town, his poem \"Le Voyage\" being one example of his efforts during that time. In 1860, he became an ardent supporter of Richard Wagner.\nHis financial difficulties increased again, however, particularly after his publisher Poulet Malassis went bankrupt in 1861. In 1864, he left Paris for Belgium, partly in the hope of selling the rights to his works and to give lectures. His long-standing relationship with Jeanne Duval continued on-and-off, and he helped her to the end of his life. Baudelaire's relationships with actress Marie Daubrun and with courtesan Apollonie Sabatier, though the source of much inspiration, never produced any lasting satisfaction. He smoked opium, and in Brussels he began to drink to excess. Baudelaire suffered a massive stroke in 1866 and paralysis followed. After more than a year of aphasia, he received the last rites of the Catholic Church. The last year of his life was spent in a semi-paralyzed state in various \"maisons de sant\u00e9\" in Brussels and in Paris, where he died on 31 August 1867. His funeral was held at the Saint-Honor\u00e9 d'Eylau church, with a few dozen persons in attendance. Baudelaire is buried in the Cimeti\u00e8re du Montparnasse, Paris.\nMany of Baudelaire's works were published posthumously. After his death, his mother paid off his substantial debts, and she found some comfort in Baudelaire's emerging fame. \"I see that my son, for all his faults, has his place in literature.\" She lived another four years.\nPoetry.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Who among us has not dreamt, in moments of ambition, of the miracle of a poetic prose, musical without rhythm and rhyme, supple and staccato enough to adapt to the lyrical stirrings of the soul, the undulations of dreams, and sudden leaps of consciousness. This obsessive idea is above all a child of giant cities, of the intersecting of their myriad relations.\u2014\u200a\nBaudelaire is one of the major innovators in French literature. His poetry is influenced by the French romantic poets of the earlier 19th century, although its attention to the formal features of verse connects it more closely to the work of the contemporary \"Parnassians\". As for theme and tone, his works exhibit the rejection of the belief in the supremacy of nature and the fundamental goodness of man as typically espoused by the romantics and expressed by them in rhetorical, effusive and public voice in favor of a new urban sensibility, an awareness of individual moral complexity, an interest in vice (linked with decadence) and refined sensual and aesthetic pleasures, and the use of urban subject matter, such as the city, the crowd, individual passers-by, all expressed in highly ordered verse, sometimes through a cynical and ironic voice. Formally, the use of sound to create atmosphere, and of \"symbols\" (images that take on an expanded function within the poem), betray a move towards considering the poem as a self-referential object, an idea further developed by the Symbolists Verlaine and Mallarm\u00e9, who acknowledge Baudelaire as a pioneer in this regard.\nBeyond his innovations in versification and the theories of symbolism and \"correspondences\", an awareness of which is essential to any appreciation of the literary value of his work, aspects of his work that regularly receive much critical discussion include the role of women, the theological direction of his work and his alleged advocacy of \"satanism\", his experience of drug-induced states of mind, the figure of the dandy, his stance regarding democracy and its implications for the individual, his response to the spiritual uncertainties of the time, his criticisms of the bourgeois, and his advocacy of modern music and painting (e.g., Wagner, Delacroix). He made Paris the subject of modern poetry. He brought the city's details to life in the eyes and hearts of his readers.\nCritiques.\nBaudelaire was an active participant in the artistic life of his times. As critic and essayist, he wrote extensively and perceptively about the luminaries and themes of French culture. He was frank with friends and enemies, rarely took the diplomatic approach and sometimes responded violently verbally, which often undermined his cause. His associations were numerous, including Gustave Courbet, Honor\u00e9 Daumier, F\u00e9licien Rops, Franz Liszt, Champfleury, Victor Hugo, Gustave Flaubert, and Balzac.\nEdgar Allan Poe.\nIn 1847, Baudelaire became acquainted with the works of Poe, in which he found tales and poems that had, he claimed, long existed in his own brain but never taken shape. Baudelaire saw in Poe a precursor and tried to be his French contemporary counterpart. From this time until 1865, he was largely occupied with translating Poe's works; his translations were widely praised. Baudelaire was not the first French translator of Poe, but his \"scrupulous translations\" were considered among the best. These were published as \"Histoires extraordinaires\" (\"Extraordinary stories\") (1856), \"Nouvelles histoires extraordinaires\" (\"New extraordinary stories\") (1857), \"Aventures d'Arthur Gordon Pym\", \"\", and \"Histoires grotesques et s\u00e9rieuses\" (\"Grotesque and serious stories\") (1865). Two essays on Poe are to be found in his \"\u0152uvres compl\u00e8tes\" (\"Complete works\") (vols. v. and vi.).\nEug\u00e8ne Delacroix.\nA strong supporter of the Romantic painter Delacroix, calling him \"a poet in painting\", Baudelaire also absorbed much of Delacroix's aesthetic ideas as expressed in his journals. As Baudelaire elaborated in his \"Salon of 1846\", \"As one contemplates his series of pictures, one seems to be attending the celebration of some grievous mystery...This grave and lofty melancholy shines with a dull light.. plaintive and profound like a melody by Weber.\" Delacroix, though appreciative, kept his distance from Baudelaire, particularly after the scandal of \"Les Fleurs du mal\". In private correspondence, Delacroix stated that Baudelaire \"really gets on my nerves\" and he expressed his unhappiness with Baudelaire's persistent comments about \"melancholy\" and \"feverishness\".\nRichard Wagner.\nBaudelaire had no formal musical training, and knew little of composers beyond Beethoven and Weber. Weber was in some ways Wagner's precursor, using the leitmotif and conceiving the idea of the \"total art work\" (\"Gesamtkunstwerk\"), both of which gained Baudelaire's admiration. Before even hearing Wagner's music, Baudelaire studied reviews and essays about him, and formulated his impressions. Later, Baudelaire put them into his non-technical analysis of Wagner, which was highly regarded, particularly his essay \"Richard Wagner et Tannh\u00e4user \u00e0 Paris\". Baudelaire's reaction to music was passionate and psychological. \"Music engulfs (possesses) me like the sea.\" After attending three Wagner concerts in Paris in 1860, Baudelaire wrote to the composer: \"I had a feeling of pride and joy in understanding, in being possessed, in being overwhelmed, a truly sensual pleasure like that of rising in the air.\" Baudelaire's writings contributed to the elevation of Wagner and to the cult of Wagnerism that swept Europe in the following decades.\nTh\u00e9ophile Gautier.\nGautier, writer and poet, earned Baudelaire's respect for his perfection of form and his mastery of language, though Baudelaire thought he lacked deeper emotion and spirituality. Both strove to express the artist's inner vision, which Heinrich Heine earlier stated: \"In artistic matters, I am a supernaturalist. I believe that the artist can not find all his forms in nature, but that the most remarkable are revealed to him in his soul.\" Gautier's frequent meditations on death and the horror of life are themes which influenced Baudelaire's writings. In gratitude for their friendship and commonality of vision, Baudelaire dedicated \"Les Fleurs du mal\" to Gautier.\n\u00c9douard Manet.\nManet and Baudelaire became constant companions from around 1855. In the early 1860s, Baudelaire accompanied Manet on daily sketching trips and often met him socially. Manet also lent Baudelaire money and looked after his affairs, particularly when Baudelaire went to Belgium. Baudelaire encouraged Manet to strike out on his own path and not succumb to criticism. \"Manet has great talent, a talent which will stand the test of time. But he has a weak character. He seems to me crushed and stunned by shock.\" In his painting \"Music in the Tuileries\", Manet includes portraits of his friends Th\u00e9ophile Gautier, Jacques Offenbach, and Baudelaire. While it's difficult to differentiate who influenced whom, both Manet and Baudelaire discussed and expressed some common themes through their respective arts. Baudelaire praised the modernity of Manet's subject matter: \"almost all our originality comes from the stamp that 'time' imprints upon our feelings.\" When Manet's famous \"Olympia\" (1865), a portrait of a nude prostitute, provoked a scandal for its blatant realism mixed with an imitation of Renaissance motifs, Baudelaire worked privately to support his friend, though he offered no public defense (he was ill at the time). When Baudelaire returned from Belgium after his stroke, Manet and his wife were frequent visitors at the nursing home and she played passages from Wagner for Baudelaire on the piano.\nNadar.\nNadar (F\u00e9lix Tournachon) was a noted caricaturist, scientist and important early photographer. Baudelaire admired Nadar, one of his close friends, and wrote: \"Nadar is the most amazing manifestation of vitality.\" They moved in similar circles and Baudelaire made many social connections through him. Nadar's ex-mistress Jeanne Duval became Baudelaire's mistress around 1842. Baudelaire became interested in photography in the 1850s, and denouncing it as an art form, advocated its return to \"its real purpose, which is that of being the servant to the sciences and arts\". Photography should not, according to Baudelaire, encroach upon \"the domain of the impalpable and the imaginary\". Nadar remained a stalwart friend right to Baudelaire's last days and wrote his obituary notice in .\nPhilosophy.\nMany of Baudelaire's philosophical proclamations were considered scandalous and intentionally provocative in his time. He wrote on a wide range of subjects, drawing criticism and outrage from many quarters. Along with Poe, Baudelaire named the arch-reactionary Joseph de Maistre as his \"ma\u00eetre \u00e0 penser\" and adopted increasingly aristocratic views. In his journals, he wrote:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;There is no form of rational and assured government save an aristocracy. [...] There are but three beings worthy of respect: the priest, the warrior and the poet. To know, to kill and to create. The rest of mankind may be taxed and drudged, they are born for the stable, that is to say, to practise what they call professions.\nInfluence and legacy.\nBaudelaire's influence on the direction of modern French (and English) language literature was considerable. The most significant French writers to come after him were generous with tributes; four years after his death, Arthur Rimbaud praised him in a letter as \"the king of poets, a true God\". In 1895, St\u00e9phane Mallarm\u00e9 published \"Le Tombeau de Charles Baudelaire\", a sonnet in Baudelaire's memory. Marcel Proust, in an essay published in 1922, stated that, along with Alfred de Vigny, Baudelaire was \"the greatest poet of the nineteenth century\".\nIn the English-speaking world, Edmund Wilson credited Baudelaire as providing an initial impetus for the Symbolist movement by virtue of his translations of Poe. In 1930, T. S. Eliot, while asserting that Baudelaire had not yet received a \"just appreciation\" even in France, claimed that the poet had \"great genius\" and asserted that his \"technical mastery which can hardly be overpraised ... has made his verse an inexhaustible study for later poets, not only in his own language\". In a lecture delivered in French on \"Edgar Allan Poe and France\" (Edgar Poe et la France) in Aix-en-Provence in April 1948, Eliot stated that \"I am an English poet of American origin who learnt his art under the aegis of Baudelaire and the Baudelairian lineage of poets.\" Eliot also alluded to Baudelaire's poetry directly in his own poetry. For example, he quoted the last line of Baudelaire's \"Au Lecteur\" in the last line of Section I of \"The Waste Land\".\nAt the same time that Eliot was affirming Baudelaire's importance from a broadly conservative and explicitly Christian viewpoint, left-wing critics such as Wilson and Walter Benjamin were able to do so from a dramatically different perspective. Benjamin translated Baudelaire's \"Tableaux Parisiens\" into German and published a major essay on translation as the foreword.\nIn the late 1930s, Benjamin used Baudelaire as a starting point and focus for \"Das Passagenwerk\", his monumental attempt at a materialist assessment of 19th-century culture. For Benjamin, Baudelaire's importance lay in his anatomies of the crowd, of the city and of modernity. He says that, in \"Les Fleurs du mal\", \"the specific devaluation of the world of things, as manifested in the commodity, is the foundation of Baudelaire's allegorical intention.\"\nFran\u00e7ois Porch\u00e9 published a poetry collection called \"Charles Baudelaire: Poetry Collection\" in memory of Baudelaire.\nThe novel \"A Singular Conspiracy\" (1974) by Barry Perowne is a fictional treatment of the unaccounted period in Edgar Allan Poe's life from January to May 1844, in which (among other things) Poe becomes involved with a young Baudelaire in a plot to expose Baudelaires' stepfather to blackmail, to free up Baudelaires' patrimony.\nVanderbilt University has \"assembled one of the world's most comprehensive research collections on ... Baudelaire\".\nReferences.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "5808", "revid": "44641411", "url": "https://en.wikipedia.org/wiki?curid=5808", "title": "Casey at the Bat", "text": "1888 baseball poem by Ernest Thayer\n\"Casey at the Bat: A Ballad of the Republic, Sung in the Year 1888\" is a mock-heroic poem written in 1888 by Ernest Thayer. It was first published in \"The San Francisco Examiner\" (then called \"The Daily Examiner\") on June 3, 1888, under the pen name \"Phin\", based on Thayer's college nickname, \"Phinney\". Featuring a dramatic narrative about a baseball game, the poem was later popularized by DeWolf Hopper in many vaudeville performances. It has become one of the best-known poems in American literature.\nSynopsis.\nA baseball team from the fictional town of \"Mudville\" (the home team) is losing by two runs in its last inning. Both the team and its fans, a crowd of 5,000, believe that they can win if Casey, Mudville's star player, gets to bat. However, Casey is scheduled to be the fifth batter of the inning, and the first two batters (Cooney and Barrows) fail to get on base. The next two batters (Flynn and Jimmy Blake) are perceived to be weak hitters with little chance of reaching base to allow Casey a chance to bat.\nSurprisingly, Flynn hits a single, and Blake follows with a double that allows Flynn to reach third base. Both runners are now in scoring position and Casey represents the potential winning run. Casey is so sure of his abilities that he does not swing at the first two pitches, both called strikes. On the last pitch, the overconfident Casey strikes out swinging, ending the game and sending the crowd home unhappy.\nText.\nThe text is filled with references to baseball as it was in 1888, which in many ways is not far removed from today's version. As a work, the poem encapsulates much of the appeal of baseball, including the involvement of the crowd. It also has a fair amount of baseball jargon that can pose challenges for the uninitiated.\nThis is the complete poem as it originally appeared in \"The Daily Examiner\". After publication, various versions with minor changes were produced.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nInspiration.\nThayer said he chose the name \"Casey\" after a non-player of Irish ancestry he once knew named Daniel H. Casey; it is open to debate whom, if anyone, he modeled the character after. It has been reported that Thayer's best friend Samuel Winslow, who played baseball at Harvard, was the inspiration for Casey.\nAnother classmate of Thayer at Harvard\u2014Edward Terry Sanford\u2014also has been put forward as a possible model for Casey, in part on the ground that Thayer and Sanford were both members of a student group at Harvard (the OK Society) that played some baseball in the mid-1880s. Sanford would go on to a distinguished career in the law, culminating in his appointment to the Supreme Court of the United States in 1923.\nAnother candidate is National League player Mike \"King\" Kelly, who became famous when Boston paid Chicago a record $10,000 for him. He had a personality that fans liked to cheer or jeer. After the 1887 season, Kelly went on a playing tour to San Francisco. Thayer, who wrote \"Casey\" in 1888, covered the San Francisco leg for the \"San Francisco Examiner\".\nThayer, in a letter he wrote in 1905, mentions Kelly as showing \"impudence\" in claiming to have written the poem. The author of the 2004 definitive biography of Kelly\u2014which included a close tracking of his vaudeville career\u2014did not find Kelly claiming to have been the author.\nComposition and publication history.\n\"Casey at the Bat\" was first published in \"The Daily Examiner\" on June 3, 1888.\nA month after the poem was published, it was reprinted as \"Kelly at the Bat\" in the \"New York Sporting Times\".\nAside from omitting the first five verses, the only changes from the original are substitutions of Kelly for Casey, and Boston for Mudville. King Kelly, then of the Boston Beaneaters, was one of baseball's two biggest stars at the time (along with Cap Anson).9\nIn 1897, the magazine \"Current Literature\" noted the two versions and said, \"The locality, as originally given, is Mudville, not Boston; the latter was substituted to give the poem local color.\"\nLive performances.\nDeWolf Hopper gave the poem's first stage recitation on August 14, 1888, at New York's Wallack Theatre as part of the comic opera \"Prinz Methusalem\" in the presence of the Chicago White Stockings and New York Giants baseball teams; August 14, 1888 was also Thayer's 25th birthday. Hopper became known as an orator of the poem, and recited it more than 10,000 times (by his count\u2014some tabulations are as much as four times higher) before his death.\nOn stage in the early 1890s, baseball star Kelly recited the original \"Casey\" a few dozen times and not the parody. For example, in a review in 1893 of a variety show he was in, the \"Indianapolis News\" said, \"Many who attended the performance had heard of Kelly's singing and his reciting, and many had heard De Wolf Hopper recite 'Casey at the Bat' in his inimitable way. Kelly recited this in a sing-song, school-boy fashion.\" Upon Kelly's death, a writer would say he gained \"considerable notoriety by his ludicrous rendition of 'Casey at the Bat,' with which he concluded his 'turn' [act] at each performance.\"229\nDuring the 1980s, the magic/comedy team Penn &amp; Teller performed a version of \"Casey at the Bat\" with Teller (the \"silent\" partner) struggling to escape a straitjacket while suspended upside-down over a platform of sharp steel spikes. The set-up was that Penn Jillette would leap off his chair upon finishing the poem, releasing the rope which supported Teller, and send Teller to a gruesome death if Teller had failed to free himself by that time. Jillette enhanced the drama of the performance by drastically accelerating the pace of his recital after the first few stanzas, greatly reducing the time that Teller had left to work free from his bonds.\nRecordings.\nThe first recorded version of \"Casey at the Bat\" was made by Russell Hunting, speaking in a broad Irish accent, in 1893; an http:// can be accessed from the Cylinder Preservation and Digitization Project at the University of California, Santa Barbara Library.\nDeWolf Hopper's more famous recorded recitation was released in October 1906.\nIn 1946, Walt Disney released a recording of the narration of the poem by Jerry Colonna, which accompanied the studio's animated cartoon adaptation of the poem (see below).\nIn 1973, the Cincinnati Symphony Orchestra commissioned its former Composer-in-Residence, Frank Proto, to create a work to feature Baseball Hall-of-Famer Johnny Bench with the orchestra. The result \"Casey At The Bat \u2013 an American Folk Tale for Narrator and Orchestra\" was an immediate hit and recorded by Bench and the orchestra. It has since been performed more than 800 times by nearly every major and Metropolitan orchestra in the U.S. and Canada.\nIn 1980, baseball pitcher Tug McGraw recorded \"Casey at The Bat\u2014an American Folk Tale for Narrator and Orchestra\" by Frank Proto with Peter Nero and the Philly Pops.\nIn 1996, actor James Earl Jones recorded the poem with arranger/composer Steven Reineke and the Cincinnati Pops Orchestra.\nOn a 1997 CD set with memorable moments and stories from the game of baseball titled \"Take Me Out to the Ball Game\" produced by Jerry Hoffman and Douglas Duer, a Vincent Price oration of the poem is a slightly altered version of the original.\nIn 1998, actor Sir Derek Jacobi recorded the poem with composer/arranger Randol Alan Bass and the National Symphony of London, with the composer conducting. This work, titled \"Casey at the Bat\", has been recorded by the Boston Pops Orchestra, Keith Lockhart conducting.\nIn 2013, Dave Jageler and Charlie Slowes, both radio announcers for the Washington Nationals, each made recordings of the poem for the Library of Congress to mark the 125th anniversary of its first publication.\nMudville.\nA rivalry of sorts has developed between two cities claiming to be the Mudville described in the poem.\nResidents of Holliston, Massachusetts, where there is a neighborhood called Mudville, claim it as the Mudville described in the poem. Thayer grew up in nearby Worcester, Massachusetts, where he wrote the poem in 1888; his family owned a wool mill less than from Mudville's baseball field.\nHowever, residents of Stockton, California\u2014which was known for a time as Mudville prior to incorporation in 1850\u2014also lay claim to being the inspiration for the poem. In 1887, Thayer covered baseball for \"The Daily Examiner\"\u2014owned by his Harvard classmate William Randolph Hearst\u2014and is said to have covered the local California League team, the Stockton Ports. For the 1902 season, after the poem became popular, Stockton's team was renamed the Mudville Nine. The team reverted to the Mudville Nine moniker for the 2000 and 2001 seasons. The Visalia Rawhide, another California League team, currently keeps Mudville alive playing in Mudville jerseys on June\u00a03 each year.\nDespite the towns' rival claims, Thayer himself told the \"Syracuse Post-Standard\" that \"the poem has no basis in fact.\"\nAdaptations.\nThe poem has been adapted to diverse types of media:\nDerivations.\nFor a relatively short poem apparently dashed off quickly (and denied by its author for years), \"Casey at the Bat\" had a profound effect on American popular culture. It has been recited, re-enacted, adapted, dissected, parodied, and subjected to just about every other treatment one could imagine.\nParodies.\nOf the many parodies made of the poem, some of the notable ones include:\nTranslations.\nThere are three known translations of the poem into a foreign language, one in French, written in 2007 by French Canadian linguist Paul Laurendeau, with the title \"Casey au b\u00e2ton\", and two in Hebrew. One by the sports journalist Menachem Less titled \"\u05d4\u05ea\u05d5\u05e8 \u05e9\u05dc \u05e7\u05d9\u05d9\u05e1\u05d9 \u05dc\u05d7\u05d1\u05d5\u05d8\" [Hator Shel Casey Lachbot], and the other more recent and more true to the original cadence and style by Jason H. Elbaum called \u05e7\u05b5\u05d9\u05e1\u05b4\u05d9 \u05d1\u05b7\u05bc\u05de\u05b7\u05bc\u05d7\u05b0\u05d1\u05b5\u05bc\u05d8 [Casey BaMachbayt].\nNames.\nCasey Stengel describes in his autobiography how his original nickname \"K.C.\" (for his hometown, Kansas City, Missouri) evolved into \"Casey\". It was influenced not just by the name of the poem, which was widely popular in the 1910s, but also because he tended to strike out frequently in his early career so fans and writers started calling him \"strikeout Casey\".\nContemporary culture.\nPostage stamp.\nOn July 11, 1996, the United States Postal Service issued a commemorative stamp depicting \"Mighty Casey.\" The stamp was part of a set commemorating American folk heroes. Other stamps in the set depicted Paul Bunyan, John Henry, and Pecos Bill.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "5810", "revid": "50159594", "url": "https://en.wikipedia.org/wiki?curid=5810", "title": "Classical guitar", "text": "String instrument\nThe classical guitar, also known as a Spanish guitar, is a member of the guitar family used in classical music and other styles. As an acoustic wooden string instrument with strings made of gut or nylon, it is a precursor of the modern steel-string acoustic and electric guitars, both of which use metal strings. Classical guitars derive from instruments such as the lute, the vihuela, the gittern (the name being a derivative of the Greek \"kithara\"), which evolved into the Renaissance guitar and into the 17th and 18th-century baroque guitar. Today's \"modern classical guitar\" was established by the late designs of the 19th-century Spanish luthier, Antonio Torres Jurado.\nFor a right-handed player, the traditional classical guitar has 12 frets clear of the body and is properly held up by the left leg, so that the hand that plucks or strums the strings does so near the back of the sound hole. This is called the classical, or sul ponticello, position. However, the right-hand may move closer to the fretboard to achieve different tonal qualities, known as the sul tasto position. The player typically holds the left leg higher by the use of a foot rest. The modern steel string guitar, on the other hand, usually has at least 14 frets clear of the body (see Dreadnought) and is commonly held with a strap around the neck and shoulder.\nThe phrase \"classical guitar\" may refer to either of two concepts other than the instrument itself:\nThe term \"modern classical guitar\" sometimes distinguishes the classical guitar from older forms of guitar, which are in their broadest sense also called \"classical\", or more specifically, \"early guitars\". Examples of early guitars include the six-string early romantic guitar (c.\u20091790 \u2013 1880), and the earlier baroque guitars with five courses.\nThe materials and the methods of classical guitar construction may vary, but the typical shape is either \"modern classical guitar\" or that \"historic classical guitar\" similar to the early romantic guitars of Spain, France and Italy. Classical guitar strings once made of gut are now made of materials such as nylon or fluoropolymers (especially PVDF), typically with silver-plated copper fine wire wound about the 3 lower-pitched strings, which are D, A and low E in standard tuning.\nA guitar family tree may be identified. The flamenco guitar derives from the modern classical, but has differences in material, construction and sound.\nContexts.\nThe classical guitar has a long history and one is able to distinguish various:\nBoth instrument and repertoire can be viewed from a combination of various perspectives:\nHistorical (chronological period of time)\nGeographical\nCultural\nHistorical perspective.\nEarly guitars.\nWhile \"classical guitar\" is today mainly associated with the modern classical guitar design, there is an increasing interest in early guitars; and understanding the link between historical repertoire and the particular period guitar that was originally used to perform this repertoire. The musicologist and author Graham Wade writes:\nNowadays it is customary to play this repertoire on reproductions of instruments authentically modelled on concepts of musicological research with appropriate adjustments to techniques and overall interpretation. Thus over recent decades we have become accustomed to specialist artists with expertise in the art of vihuela (a 16th-century type of guitar popular in Spain), lute, Baroque guitar, 19th-century guitar, etc.\nDifferent types of guitars have different sound aesthetics, e.g. different colour-spectrum characteristics (the way the sound energy is spread in the fundamental frequency and the overtones), different response, etc. These differences are due to differences in construction; for example, modern classical guitars usually use a different bracing (fan-bracing) from that used in earlier guitars (they had ladder-bracing); and a different voicing was used by the luthier.\nThere is a historical parallel between musical styles (baroque, classical, romantic, flamenco, jazz) and the style of \"sound aesthetic\" of the musical instruments used, for example: Robert de Vis\u00e9e played a baroque guitar with a very different sound aesthetic from the guitars used by Mauro Giuliani and Luigi Legnani \u2013 they used 19th-century guitars. These guitars in turn sound different from the Torres models used by Segovia that are suited for interpretations of romantic-modern works such as Moreno Torroba.\nWhen considering the guitar from a historical perspective, the musical instrument used is as important as the musical language and style of the particular period. As an example: It is impossible to play a historically informed de Visee or Corbetta (baroque guitarist-composers) on a modern classical guitar. The reason is that the baroque guitar used courses, which are two strings close together (in unison), that are plucked together. This gives baroque guitars an unmistakable sound characteristic and tonal texture that is an integral part of an interpretation. Additionally, the sound aesthetic of the baroque guitar (with its strong overtone presence) is very different from modern classical type guitars, as is shown below.\nToday's use of Torres and post-Torres type guitars for repertoire of all periods is sometimes critically viewed: Torres and post-Torres style modern guitars (with their fan-bracing and design) have a thick and strong tone, very suitable for modern-era repertoire. However, they are considered to emphasize the fundamental too heavily (at the expense of overtone partials) for earlier repertoire (Classical/Romantic: Carulli, Sor, Giuliani, Mertz,\u00a0...; Baroque: de Visee,\u00a0...; etc.). \"Andr\u00e9s Segovia presented the Spanish guitar as a versatile model for all playing styles\" to the extent, that still today, \"many guitarists have tunnel-vision of the world of the guitar, coming from the modern Segovia tradition\".\nWhile fan-braced modern classical Torres and post-Torres style instruments coexisted with traditional ladder-braced guitars at the beginning of the 20th century, the older forms eventually fell away. Some attribute this to the popularity of Segovia, considering him \"the catalyst for change toward the Spanish design and the so-called 'modern' school in the 1920s and beyond.\" The styles of music performed on ladder-braced guitars were becoming unfashionable\u2014and, e.g., in Germany, more musicians were turning towards folk music (Schrammel-music and the Contraguitar). This was localized in Germany and Austria and became unfashionable again. On the other hand, Segovia was playing concerts around the world, popularizing modern classical guitar\u2014and, in the 1920s, Spanish romantic-modern style with guitar works by Moreno Torroba, de Falla, etc.\nThe 19th-century classical guitarist Francisco T\u00e1rrega first popularized the Torres design as a classical solo instrument. However, some maintain that Segovia's influence led to its domination over other designs. Factories around the world began producing them in large numbers.\nStyle periods.\nRenaissance.\nComposers of the Renaissance period who wrote for four-course guitar include Alonso Mudarra, Miguel de Fuenllana, Adrian Le Roy, Gr\u00e9goire Brayssing, Guillaume de Morlaye, and Simon Gorlier.\nFour-course guitar\nBaroque.\nSome well known composers of the Baroque guitar were Gaspar Sanz, Robert de Vis\u00e9e, Francesco Corbetta and Santiago de Murcia.\nClassical and romantic.\nFrom approximately 1780 to 1850, the guitar had numerous composers and performers including:\nHector Berlioz studied the guitar as a teenager; Franz Schubert owned at least two and wrote for the instrument; and Ludwig van Beethoven, after hearing Giuliani play, commented the instrument was \"a miniature orchestra in itself\". Niccol\u00f2 Paganini was also a guitar virtuoso and composer. He once wrote: \"I love the guitar for its harmony; it is my constant companion in all my travels\". He also said, on another occasion: \"I do not like this instrument, but regard it simply as a way of helping me to think.\"\nFrancisco T\u00e1rrega.\nThe guitarist and composer Francisco T\u00e1rrega (November 21, 1852 \u2013 December 15, 1909) was one of the great guitar virtuosos and teachers and is considered the father of modern classical guitar playing. As a professor of guitar at the conservatories of Madrid and Barcelona, he defined many elements of the modern classical technique and elevated the importance of the guitar in the classical music tradition.\nModern period.\nAt the beginning of the 1920s, Andr\u00e9s Segovia popularized the guitar with tours and early phonograph recordings. Segovia collaborated with the composers Federico Moreno Torroba and Joaqu\u00edn Turina with the aim of extending the guitar repertoire with new music. Segovia's tour of South America revitalized public interest in the guitar and helped the guitar music of Manuel Ponce and Heitor Villa-Lobos reach a wider audience. The composers Alexandre Tansman and Mario Castelnuovo-Tedesco were commissioned by Segovia to write new pieces for the guitar. Luiz Bonf\u00e1 popularized Brazilian musical styles such as the newly created Bossa Nova, which was well received by audiences in the USA.\n\"New music\" \u2013 avant-garde.\nThe classical guitar repertoire also includes modern contemporary works \u2013 sometimes termed \"New Music\" \u2013 such as Elliott Carter's \"Changes\", Crist\u00f3bal Halffter's \"Codex I\", Luciano Berio's \"Sequenza XI\", Maurizio Pisati's \"Sette Studi\", Maurice Ohana's \"Si Le Jour Para\u00eet\", Sylvano Bussotti's \"Rara (eco sierologico)\", Ernst Krenek's \"Suite f\u00fcr Guitarre allein, Op. 164\", Franco Donatoni's \"Algo: Due pezzi per chitarra\", Paolo Coggiola's \"Variazioni Notturne\", etc.\nPerformers who are known for including modern repertoire include J\u00fcrgen Ruck, Elena C\u00e0soli, Leo Brouwer (when he was still performing), John Schneider, Reinbert Evers, Maria K\u00e4mmerling, Siegfried Behrend, David Starobin, Mats Scheidegger, Magnus Andersson, etc.\nThis type of repertoire is usually performed by guitarists who have particularly chosen to focus on the avant-garde in their performances.\nWithin the contemporary music scene itself, there are also works which are generally regarded as extreme. These include works such as Brian Ferneyhough's \"Kurze Schatten II\", Sven-David Sandstr\u00f6m's \"away from\" and Rolf Riehm's \"Toccata Orpheus\" etc. which are notorious for their extreme difficulty.\nThere are also a variety of databases documenting modern guitar works such as http:// and others.\nBackground.\nThe evolution of the classical guitar and its repertoire spans more than four centuries. It has a history that was shaped by contributions from earlier instruments, such as the lute, the vihuela, and the baroque guitar.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The last guitarist to follow in Segovia's footsteps was Julian Bream and Julian Bream will be 73 years old on July 15th 2006. Miguel Llobet, Andr\u00e9s Segovia and Julian Bream are the three performer personalities of the 20th century. Do not understand me wrong, we have many guitarists today that are very excellent performers, but none with such a distinct personality in their tone and style as Llobet, Segovia and Bream. In all instrumental areas, not just the guitar, there is a lack of individualism with a strong tendency to conformity. This I find very unfortunate since art (music, theatre or the pictorial arts) is a very individual and personal matter.\u2014\u200a\nHistory.\nOverview of the classical guitar's history.\nThe origins of the modern guitar are not known with certainty. Some believe it is indigenous to Europe, while others think it is an imported instrument. Guitar-like instruments appear in ancient carvings and statues recovered from Egyptian, Sumerian, and Babylonian civilizations. This means that contemporary Iranian instruments such as the tanbur and setar are distantly related to the European guitar, as they all derive ultimately from the same ancient origins, but by very different historical routes and influences. Gitterns called \"guitars\" were already in use since the 13th century, but their construction and tuning were different from modern guitars. The time where the most changes were made to the guitar was in the 1500s to the 1800s.\nRenaissance guitar.\nAlonso de Mudarra's book \"Tres Libros de M\u00fasica\", published in Spain in 1546, contains the earliest known written pieces for a four-course guitarra. This four-course \"guitar\" was popular in France, Spain, and Italy. In France this instrument gained popularity among aristocrats. A considerable volume of music was published in Paris from the 1550s to the 1570s: Simon Gorlier's Le Troysi\u00e8me Livre... mis en tablature de Guiterne was published in 1551. In 1551 Adrian Le Roy also published his Premier Livre de Tablature de Guiterne, and in the same year he also published Briefve et facile instruction pour apprendre la tablature a bien accorder, conduire, et disposer la main sur la Guiterne. Robert Ballard, Gr\u00e9goire Brayssing from Augsburg, and Guillaume Morlaye (c.\u20091510 \u2013 c.\u20091558) significantly contributed to its repertoire. Morlaye's Le Premier Livre de Chansons, Gaillardes, Pavannes, Bransles, Almandes, Fantasies \u2013 which has a four-course instrument illustrated on its title page \u2013 was published in partnership with Michel Fedenzat, and among other music, they published six books of tablature by lutenist Albert de Rippe (who was very likely Guillaume's teacher).\nVihuela.\nThe written history of the classical guitar can be traced back to the early 16th century with the development of the \"vihuela\" in Spain. While the lute was then becoming popular in other parts of Europe, the Spaniards did not take to it well because of its association with the Moors. Instead, the lute-like vihuela appeared with two more strings that gave it more range and complexity. In its most developed form, the vihuela was a guitar-like instrument with six double strings made of gut, tuned like a modern classical guitar with the exception of the third string, which was tuned half a step lower. It has a high sound and is rather large to hold. Few have survived and most of what is known today come from diagrams and paintings.\n\"Early romantic guitar\" or \"Guitar during the Classical music era\".\nThe earliest extant six-string guitar is believed to have been built in 1779 by Gaetano Vinaccia (1759 \u2013 after 1831) in Naples, Italy; however, the date on the label is a little ambiguous. The Vinaccia family of luthiers is known for developing the mandolin. This guitar has been examined and does not show tell-tale signs of modifications from a double-course guitar.\nThe authenticity of guitars allegedly produced before the 1790s is often in question. This also corresponds to when Moretti's 6-string method appeared, in 1792.\nModern classical guitar.\nThe modern classical guitar was developed in the 19th century by Antonio de Torres Jurado, Ignacio Fleta, Hermann Hauser Sr., and Robert Bouchet. The Spanish luthier and player Antonio de Torres gave the modern classical guitar its definitive form, with a broadened body, increased waist curve, thinned belly, and improved internal bracing. The modern classical guitar replaced an older form for the accompaniment of song and dance called flamenco, and a modified version, known as the flamenco guitar, was created.\nAmerican Classical Guitar Music.\nAmerican classical guitar music represents a distinctive evolution within the classical guitar tradition in the United States. It blends European classical techniques with elements from American folk, blues, and other local musical styles. Pioneering figures such as Justin Holland and William Foden laid the groundwork, while later innovators like Aaron Shearer, Christopher Parkening, and Jason Vieaux have significantly influenced performance practices, pedagogy, and repertoire in America. For more detailed information on this American evolution, please see the article on American Classical Guitar Music.\nTechnique.\nThe fingerstyle is used fervently on the modern classical guitar. The thumb traditionally plucks the bass \u2013 or root note \u2013 whereas the fingers ring the melody and its accompanying parts. Often classical guitar technique involves the use of the nails of the right hand to pluck the notes. Noted players were: Francisco T\u00e1rrega, Emilio Pujol, Andr\u00e9s Segovia, Julian Bream, Agust\u00edn Barrios, and John Williams (guitarist).\nPerformance.\nThe modern classical guitar is usually played in a seated position, with the instrument resting on the left lap \u2013 and the left foot placed on a footstool. Alternatively \u2013 if a footstool is not used \u2013 a \"guitar support\" can be placed between the guitar and the left lap (the support usually attaches to the instrument's side with suction cups). (There are of course exceptions, with some performers choosing to hold the instrument another way.)\nRight-handed players use the fingers of the right hand to pluck the strings, with the thumb plucking from the top of a string downwards (downstroke) and the other fingers plucking from the bottom of the string upwards (upstroke). The little finger in classical technique as it evolved in the 20th century is used only to ride along with the ring finger without striking the strings and to thus physiologically facilitate the ring finger's motion.\nIn contrast, Flamenco technique, and classical compositions evoking Flamenco, employ the little finger semi-independently in the Flamenco four-finger rasgueado, that rapid strumming of the string by the fingers in reverse order employing the back of the fingernail\u2014a familiar characteristic of Flamenco.\nFlamenco technique, in the performance of the rasgueado also uses the upstroke of the four fingers and the downstroke of the thumb: the string is hit not only with the inner, fleshy side of the fingertip but also with the outer, fingernail side. This was also used in a technique of the vihuela called dedillo which has recently begun to be introduced on the classical guitar.\nSome modern guitarists, such as \u0160t\u011bp\u00e1n Rak and Kazuhito Yamashita, use the little finger independently, compensating for the little finger's shortness by maintaining an extremely long fingernail. Rak and Yamashita have also generalized the use of the upstroke of the four fingers and the downstroke of the thumb (the same technique as in the rasgueado of the Flamenco: as explained above the string is hit not only with the inner, fleshy side of the fingertip but also with the outer, fingernail side) both as a free stroke and as a rest stroke.\nDirect contact with strings.\nAs with other plucked instruments (such as the lute), the musician directly touches the strings (usually plucking) to produce the sound. This has important consequences: Different tone/timbre (of a single note) can be produced by plucking the string in different manners (apoyando or tirando) and in different positions (such as closer and further away from the guitar bridge). For example, plucking an open string will sound brighter than playing the same note(s) on a fretted position (which would have a warmer tone).\nThe instrument's versatility means it can create a variety of tones, but this finger-picking style also makes the instrument harder to learn than a standard acoustic guitar's strumming technique.\nFingering notation.\nIn guitar \"scores\" the five fingers of the right-hand (which pluck the strings) are designated by the first letter of their Spanish names namely p = thumb (\"pulgar\"), i = index finger (\"\u00edndice\"), m = middle finger (\"mayor\"), a = ring finger (\"anular\"), c = little finger or pinky (\"me\u00f1ique/chiquito\")\nThe four fingers of the left hand (which fret the strings) are designated 1 = index, 2 = major, 3 = ring finger, 4 = little finger. 0 designates an open string\u2014a string not stopped by a finger and whose full length thus vibrates when plucked. It is rare to use the left hand thumb in performance, the neck of a classical guitar being too wide for comfort, and normal technique keeps the thumb behind the neck. However Johann Kaspar Mertz, for example, is notable for specifying the thumb to fret bass notes on the sixth string, notated with an up arrowhead (\u2303).\nScores (contrary to \"tablatures\") do not systematically indicate the string to pluck (though the choice is usually obvious). When indicating the string is useful, the score uses the numbers 1 to 6 inside circles (highest-pitch sting to lowest).\nScores do not systematically indicate fretboard positions (where to put the first finger of the fretting hand), but when helpful (mostly with barr\u00e9s chords) the score indicates positions with Roman numerals from the first position I (index finger on the 1st fret: F-B flat-E flat-A flat-C-F) to the twelfth position XII (index finger on the 12th fret: E-A-D-G-B-E. The 12th fret is where the body begins) or even higher up to position XIX (the classical guitar most often having 19 frets, with the 19th fret being most often split and not being usable to fret the 3rd and 4th strings).\nAlternation.\nTo achieve tremolo effects and rapid, fluent scale passages, the player must practice alternation, that is, never plucking a string with the same finger twice in a row. \nUsing p to indicate the thumb, i the index finger, m the middle finger and a the ring finger, common alternation patterns include:\nRepertoire.\nMusic written specifically for the classical guitar dates from the addition of the sixth string (the baroque guitar normally had five pairs of strings) in the late 18th century.\nA guitar recital may include a variety of works, e.g., works written originally for the lute or vihuela by composers such as John Dowland (b. England 1563) and Luis de Narv\u00e1ez (b. Spain c.\u20091500), and also music written for the harpsichord by Domenico Scarlatti (b. Italy 1685), for the baroque lute by Sylvius Leopold Weiss (b. Germany 1687), for the baroque guitar by Robert de Vis\u00e9e (b. France c.\u20091650) or even Spanish-flavored music written for the piano by Isaac Alb\u00e9niz (b. Spain 1860) and Enrique Granados (b. Spain 1867). The most important composer who did not write for the guitar but whose music is often played on it is Johann Sebastian Bach (b. Germany 1685), whose baroque lute, violin, and cello works have proved highly adaptable to the instrument.\nOf music written originally for guitar, the earliest important composers are from the classical period and include Fernando Sor (b. Spain 1778) and Mauro Giuliani (b. Italy 1781), both of whom wrote in a style strongly influenced by Viennese classicism. In the 19th-century guitar composers such as Johann Kaspar Mertz (b. Slovakia, Austria 1806) were strongly influenced by the dominance of the piano. Not until the end of the nineteenth century did the guitar begin to establish its own unique identity. Francisco T\u00e1rrega (b. Spain 1852) was central to this, sometimes incorporating stylized aspects of flamenco's Moorish influences into his romantic miniatures. This was part of late 19th century mainstream European musical nationalism. Alb\u00e9niz and Granados were central to this movement; their evocation of the guitar was so successful that their compositions have been absorbed into the standard guitar repertoire.\nThe steel-string and electric guitars characteristic to the rise of rock and roll in the post-WWII era became more widely played in North America and the English-speaking world. Agust\u00edn Barrios Mangor\u00e9 of Paraguay composed many works and brought into the mainstream the characteristics of Latin American music, as did the Brazilian composer Heitor Villa-Lobos. Andr\u00e9s Segovia commissioned works from Spanish composers such as Federico Moreno Torroba and Joaqu\u00edn Rodrigo, Italians such as Mario Castelnuovo-Tedesco and Latin American composers such as Manuel Ponce of Mexico. Other prominent Latin American composers are Leo Brouwer of Cuba, Antonio Lauro of Venezuela and Enrique Solares of Guatemala. Julian Bream of Britain managed to get nearly every British composer from William Walton and Benjamin Britten to Peter Maxwell Davies to write significant works for guitar. Bream's collaborations with tenor Peter Pears also resulted in song cycles by Britten, Lennox Berkeley and others. There are significant works by composers such as Hans Werner Henze of Germany, Gilbert Biberian of England and Roland Chadwick of Australia.\nThe classical guitar also became widely used in popular music and rock &amp; roll in the 1960s after guitarist Mason Williams popularized the instrument in his instrumental hit Classical Gas. Guitarist Christopher Parkening is quoted in the book \"Classical Gas: The Music of Mason Williams\" as saying that it is the most requested guitar piece besides Malague\u00f1a and perhaps the best-known instrumental guitar piece today.\nIn the field of New Flamenco, the works and performances of Spanish composer and player Paco de Luc\u00eda are known worldwide.\nNot many classical guitar concertos were written through history. Nevertheless, some guitar concertos are nowadays widely known and popular, especially Joaqu\u00edn Rodrigo's \"Concierto de Aranjuez\" (with the famous theme from 2nd movement) and \"Fantas\u00eda para un gentilhombre\". Composers, who also wrote famous guitar concertos are: Antonio Vivaldi (originally for mandolin or lute), Mauro Giuliani, Heitor Villa-Lobos, Mario Castelnuovo-Tedesco, Manuel Ponce, Leo Brouwer, Lennox Berkeley and Malcolm Arnold. \nNowadays, more and more contemporary composers decide to write a guitar concerto, among them \"Bosco Sacro\" by Federico Biscione, for guitar and string orchestra, is one of the most inspired.\nPhysical characteristics.\nThe classical guitar is distinguished by a number of characteristics:\nParts.\nParts of typical classical guitars include:\nFretboard.\nThe fretboard (also called the fingerboard) is a piece of wood embedded with metal frets that constitutes the top of the neck. It is flat or slightly curved. The curvature of the fretboard is measured by the fretboard radius, which is the radius of a hypothetical circle of which the fretboard's surface constitutes a segment. The smaller the fretboard radius, the more noticeably curved the fretboard is. Fretboards are most commonly made of ebony, but may also be made of rosewood, some other hardwood, or of phenolic composite (\"micarta\").\nFrets.\nFrets are the metal strips (usually nickel alloy or stainless steel) embedded along the fingerboard and placed at points that divide the length of string mathematically. The strings' vibrating length is determined when the strings are pressed down behind the frets. Each fret produces a different pitch and each pitch spaced a half-step apart on the 12 tone scale. The ratio of the widths of two consecutive frets is the twelfth root of two (formula_1), whose numeric value is about 1.059463. The twelfth fret divides the string into two exact halves and the 24th fret (if present) divides the string in half yet again. Every twelve frets represents one octave. This arrangement of frets results in equal tempered tuning.\nNeck.\nA classical guitar's frets, fretboard, tuners, headstock, all attached to a long wooden extension, collectively constitute its neck. The wood for the fretboard usually differs from the wood in the rest of the neck. The bending stress on the neck is considerable, particularly when heavier gauge strings are used. The most common scale length for classical guitar is 650mm (calculated by measuring the distance between the end of the nut and the center of the 12th fret, then doubling that measurement). However, scale lengths may vary from 635-664mm or more.\nNeck joint or 'heel'.\nThis is the point where the neck meets the body. In the traditional Spanish neck joint, the neck and block are one piece with the sides inserted into slots cut in the block. Other necks are built separately and joined to the body either with a dovetail joint, mortise or flush joint. These joints are usually glued and can be reinforced with mechanical fasteners. Recently many manufacturers use bolt-on fasteners. Bolt-on neck joints were once associated only with less expensive instruments but now some top manufacturers and hand builders are using variations of this method. Some people believed that the Spanish-style one piece neck/block and glued dovetail necks have better sustain, but testing has failed to confirm this.\nWhile most traditional Spanish style builders use the one-piece neck/heel block, Fleta, a prominent Spanish builder, used a dovetail joint due to the influence of his early training in violin making.\nOne reason for the introduction of mechanical joints was to make it easier to repair necks. This is more of a problem with steel string guitars than with nylon strings, which have about half the string tension. This is why nylon string guitars often do not include a truss rod either.\nBody.\nThe body of the instrument is a major determinant of the overall sound variety for acoustic guitars. The guitar top, or soundboard, is a finely crafted and engineered element often made of spruce or red cedar. Considered the most prominent factor in determining the sound quality of a guitar, this thin (often 2 or 3\u00a0mm thick) piece of wood has a uniform thickness and is strengthened by different types of internal bracing. The back is made in rosewood and Brazilian rosewood is especially coveted, but mahogany or other decorative woods are sometimes used.\nThe majority of the sound is caused by the vibration of the guitar top as the energy of the vibrating strings is transferred to it. Different patterns of wood bracing have been used through the years by luthiers (Torres, Hauser, Ram\u00edrez, Fleta, and C.F. Martin being among the most influential designers of their times); to not only strengthen the top against collapsing under the tremendous stress exerted by the tensioned strings, but also to affect the resonance of the top. Some contemporary guitar makers have introduced new construction concepts such as \"double-top\" consisting of two extra-thin wooden plates separated by Nomex, or carbon-fiber reinforced lattice \u2013 pattern bracing. The back and sides are made out of a variety of woods such as mahogany, maple, cypress Indian rosewood and highly regarded Brazilian rosewood (\"Dalbergia nigra\"). Each one is chosen for its aesthetic effect and structural strength, and such choice can also play a role in determining the instrument's timbre. These are also strengthened with internal bracing, and decorated with inlays and purfling.\nAntonio de Torres Jurado proved that it was the top, and not the back and sides of the guitar that gave the instrument its sound, in 1862 he built a guitar with back and sides of papier-m\u00e2ch\u00e9. (This guitar resides in the Museu de la Musica in Barcelona, and before the year 2000 it was restored to playable condition by the brothers Yag\u00fce, Barcelona). \nThe body of a classical guitar is a resonating chamber that projects the vibrations of the body through a \"sound hole\", allowing the acoustic guitar to be heard without amplification. The sound hole is normally a single round hole in the top of the guitar (under the strings), though some have different placement, shapes, or numbers of holes. How much air an instrument can move determines its maximum volume.\nBinding, purfling and kerfing.\nThe top, back and sides of a classical guitar body are very thin, so a flexible piece of wood called \"kerfing\" (because it is often scored, or \"kerfed\" so it bends with the shape of the rim) is glued into the corners where the rim meets the top and back. This interior reinforcement provides 5 to 20\u00a0mm of solid gluing area for these corner joints.\nDuring final construction, a small section of the outside corners is carved or routed out and filled with binding material on the outside corners and decorative strips of material next to the binding, which are called \"purfling\". This binding serves to seal off the endgrain of the top and back. Binding and purfling materials are generally made of either wood or high-quality plastic materials.\nBridge.\nThe main purpose of the bridge on a classical guitar is to transfer the vibration from the strings to the soundboard, which vibrates the air inside of the guitar, thereby amplifying the sound produced by the strings. The bridge holds the strings in place on the body. Also, the position of the saddle, usually a strip of bone or plastic that supports the strings off the bridge, determines the distance to the nut (at the top of the fingerboard).\nSizes.\nThe modern full-size classical guitar has a scale length of around , with an overall instrument length of . The scale length has remained quite consistent since it was chosen by the originator of the instrument, Antonio de Torres. This length may have been chosen because it's twice the length of a violin string. As the guitar is tuned to one octave below that of the violin, the same size gut could be used for the first strings of both instruments.\nSmaller-scale instruments are produced to assist children in learning the instrument as the smaller scale leads to the frets being closer together, making it easier for smaller hands. The scale-size for the smaller guitars is usually in the range , with an instrument length of . Full-size instruments are sometimes referred to as 4/4, while the smaller sizes are 3/4, 1/2, 1/4, and even as small as 1/8 for very small children. However, there is not a standardized set of dimensions for fractional guitars, and their size difference is not linear from a full size guitar.\nTuning.\nA variety of different tunings are used. The most common by far, which one could call the \"standard tuning\" is:\nThe above order is the tuning from the \"1st string\" (highest-pitched string e'\u2014spatially the bottom string in playing position) to the \"6th string\" \u2013 lowest-pitched string E\u2014spatially the upper string in playing position, and hence comfortable to pluck with the thumb.\nThe explanation for this \"asymmetrical\" tuning (in the sense that the maj 3rd is not between the two middle strings, as in the tuning of the viola da gamba) is probably that the guitar originated as a 4-string instrument (actually an instrument with 4 double courses of strings, see above) with a maj 3rd between the 2nd and 3rd strings, and it only became a 6-string instrument by gradual addition of a 5th string and then a 6th string tuned a 4th apart:\n\"The development of the modern tuning can be traced in stages. One of the tunings from the 16th century is C-F-A-D. This is equivalent to the top four strings of the modern guitar tuned a tone lower. However, the absolute pitch for these notes is not equivalent to modern \"concert pitch\". The tuning of the four-course guitar was moved up by a tone and toward the end of the 16th century, five-course instruments were in use with an added lower string tuned to A. This produced A-D-G-B-E, one of a wide number of variant tunings of the period. The low E string was added during the 18th century.\"\nThis tuning is such that neighboring strings are at most 5 semitones apart.\nThere are also a variety of commonly used alternate tunings. The most common is known as Drop D tuning which has the 6th string tuned down from an E to a D.\nSee also.\n&lt;templatestyles src=\"Col-begin/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "5813", "revid": "3382231", "url": "https://en.wikipedia.org/wiki?curid=5813", "title": "C. S. Lewis", "text": "British writer, lay theologian, and scholar\nClive Staples Lewis (29 November 1898\u00a0\u2013 22 November 1963) was a British writer, literary scholar and Anglican lay theologian. He held academic positions in English literature at both Magdalen College, Oxford (1925\u20131954), and Magdalene College, Cambridge (1954\u20131963). He is best known as the author of \"The Chronicles of Narnia\", but he is also noted for his other works of fiction, such as \"The Screwtape Letters\" and \"The Space Trilogy\", and for his non-fiction Christian apologetics, including \"Mere Christianity\", \"Miracles\" and \"The Problem of Pain.\"\nLewis was a close friend of J.\u00a0R.\u00a0R. Tolkien, the author of \"The Lord of the Rings\". Both men served on the English faculty at the University of Oxford and were active in the informal Oxford literary group known as the Inklings. According to Lewis's 1955 memoir \"Surprised by Joy\", he was baptized in the Church of Ireland but fell away from his faith during adolescence. Lewis returned to Anglicanism at the age of 32, owing to the influence of Tolkien and other friends, and he became an \"ordinary layman of the Church of England\". Lewis's faith profoundly affected his work, and his wartime radio broadcasts on the subject of Christianity brought him wide acclaim.\nLewis wrote more than 30 books which have been translated into over 30 languages and have sold millions of copies. The seven books that make up \"The Chronicles of Narnia\" have sold the most and have been popularized on stage, television, radio and cinema. His philosophical writings are widely cited by Christian scholars from many denominations.\nIn 1956 Lewis married the American writer Joy Davidman; she died of cancer four years later at the age of 45. Lewis died on 22 November 1963 of kidney failure, at age 64. In 2013, on the 50th anniversary of his death, Lewis was honoured with a memorial in Poets' Corner in Westminster Abbey.\nLife.\nChildhood.\nClive Staples Lewis was born in Belfast in Ulster, Ireland (before partition), on 29 November 1898. His father was Albert James Lewis (1863\u20131929), a solicitor whose father Richard Lewis had come to Ireland from Wales during the mid-19th century. Lewis's mother was Florence Augusta Lewis n\u00e9e Hamilton (1862\u20131908), known as Flora, the daughter of Thomas Hamilton, a Church of Ireland priest, and the great-granddaughter of both Bishop Hugh Hamilton and John Staples. She was the first female mathematics graduate to study at Queen's College Belfast. Lewis had an elder brother, Warren Hamilton Lewis (known as \"Warnie\"). He was baptized on 29 January 1899 by his maternal grandfather in St Mark's Church, Dundela.\nWhen his dog Jacksie was fatally struck by a horse-drawn carriage, the four-year-old Lewis adopted the name Jacksie. At first, he would answer to no other name, but later accepted Jack, the name by which he was known to friends and family for the rest of his life. When he was seven, his family moved into \"Little Lea\", the family home of his childhood, in the Strandtown area of East Belfast.\nAs a boy, Lewis was fascinated with anthropomorphic animals; he fell in love with Beatrix Potter's stories and often wrote and illustrated his own animal tales. Along with his brother Warnie, he created the world of Boxen, a fantasy land inhabited and run by animals. Lewis loved to read from an early age. His father's house was filled with books; he later wrote that finding something to read was as easy as walking into a field and \"finding a new blade of grass\".\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\n&lt;poem&gt;\nThe New House is almost a major character in my story.\nI am the product of long corridors, empty sunlit rooms,\nupstair indoor silences, attics explored in solitude,\ndistant noises of gurgling cisterns and pipes,\nand the noise of wind under the tiles. Also, of endless books.&lt;/poem&gt;\n\u2014\"Surprised by Joy\"\nLewis was schooled by private tutors until age nine, when his mother died in 1908 from cancer. His father then sent him to England to live and study at Wynyard School in Watford, Hertfordshire. Lewis's brother had enrolled there three years previously. Not long after, the school was closed due to a lack of pupils. Lewis then attended Campbell College in the east of Belfast about a mile from his home, but left after a few months due to respiratory problems.\nHe was then sent back to England to the health-resort town of Malvern, Worcestershire, where he attended the preparatory school Cherbourg House, which Lewis referred to as \"Chartres\" in his autobiography. It was during this time that he abandoned the Christianity he was taught as a child and became an atheist. During this time he also developed a fascination with European mythology and the occult.\nIn September 1913 Lewis enrolled at Malvern College, where he remained until the following June. He found the school socially competitive, and some of the fellow pupils of his house, such as Donald Hardman, had mixed feelings about him. Hardman later recalled: \nHe was a bit of a rebel; he had a wonderful sense of humour and was a past master of mimicry. I think he took his work seriously, but nothing else; never took any interest in games and never played any so for as I can remember unless he had to. ... I met him in Oxford after the war and noticed he had changed, but was staggered to find him the author of \"The Screwtape Letters\". When I knew him I can only describe him as a riotously amusing atheist. He really was pretty foul mouthed about it. \nAfter leaving Malvern he studied privately with William T. Kirkpatrick, his father's old tutor and former headmaster of Lurgan College.\nAs a teenager Lewis was wonderstruck by the songs and legends of what he called \"Northernness\", the ancient literature of Scandinavia preserved in the Icelandic sagas. These legends intensified an inner longing that he would later call \"joy\". He also grew to love nature; its beauty reminded him of the stories of the North, and the stories of the North reminded him of the beauties of nature. His teenage writings moved away from the tales of Boxen, and he began experimenting with different art forms such as epic poetry and opera to try to capture his new-found interest in Norse mythology and the natural world.\nStudying with Kirkpatrick (\"The Great Knock\", as Lewis afterward called him) instilled in him a love of Greek literature and mythology and sharpened his debate and reasoning skills. In 1916, Lewis was awarded a scholarship at University College, Oxford.\n\"My Irish life\".\nLewis experienced a certain cultural shock on first arriving in England: \"No Englishman will be able to understand my first impressions of England,\" Lewis wrote in \"Surprised by Joy\". \"The strange English accents with which I was surrounded seemed like the voices of demons. But what was worst was the English landscape\u00a0... I have made up the quarrel since; but at that moment I conceived a hatred for England which took many years to heal.\"\nFrom boyhood, Lewis had immersed himself in Norse and Greek mythology, and later in Irish mythology and literature. He also expressed an interest in the Irish language, though there is not much evidence that he laboured to learn it. He developed a particular fondness for W. B. Yeats, in part because of Yeats's use of Ireland's Celtic heritage in poetry. In a letter to a friend, Lewis wrote, \"I have here discovered an author exactly after my own heart, whom I am sure you would delight in, W. B. Yeats. He writes plays and poems of rare spirit and beauty about our old Irish mythology.\"\nIn 1921 Lewis met Yeats twice, since Yeats had moved to Oxford. Lewis was surprised to find his English peers indifferent to Yeats and the Celtic Revival movement, and wrote: \"I am often surprised to find how utterly ignored Yeats is among the men I have met: perhaps his appeal is purely Irish\u00a0\u2013 if so, then thank the gods that I am Irish.\" Early in his career, Lewis considered sending his work to the major Dublin publishers, writing: \"If I do ever send my stuff to a publisher, I think I shall try Maunsel, those Dublin people, and so tack myself definitely onto the Irish school.\"\nAfter his conversion to Christianity his interests gravitated towards Christian theology and away from pagan Celtic mysticism (as opposed to Celtic Christian mysticism).\nLewis occasionally expressed a somewhat tongue-in-cheek chauvinism towards the English. Describing an encounter with a fellow Irishman, he wrote: \"Like all Irish people who meet in England, we ended by criticisms on the invincible flippancy and dullness of the Anglo-Saxon race. After all, there is no doubt, \"ami\", that the Irish are the only people: with all their faults, I would not gladly live or die among another folk.\" Throughout his life he sought out the company of other Irish people living in England and visited Northern Ireland regularly. In 1958 he spent his honeymoon there at the Old Inn, Crawfordsburn, which he called \"my Irish life\".\nVarious critics have suggested that it was Lewis's dismay over the sectarian conflict in his native Belfast which led him to eventually adopt such an ecumenical brand of Christianity. As one critic has said, Lewis \"repeatedly extolled the virtues of all branches of the Christian faith, emphasising a need for unity among Christians around what the Catholic writer G. K. Chesterton called 'Mere Christianity', the core doctrinal beliefs that all denominations share\".\nPaul Stevens of the University of Toronto opined that \"Lewis' mere Christianity masked many of the political prejudices of an old-fashioned Ulster Protestant, a native of middle-class Belfast for whom British withdrawal from Northern Ireland even in the 1950s and 1960s was unthinkable.\"\nFirst World War and Oxford University.\nLewis entered Oxford in the 1917 summer term, studying at University College, and shortly after, he joined the Officers' Training Corps at the university as his \"most promising route into the army\". From there he was drafted into a Cadet Battalion for training. After his training he was commissioned into the 3rd Battalion of the Somerset Light Infantry of the British Army as a Second Lieutenant, and was later transferred to the 1st Battalion of the regiment, then serving in France (he would not remain with the 3rd Battalion as it moved to Northern Ireland). Within months of entering Oxford, he was shipped by the British Army to France to fight in the First World War.\nOn his 19th birthday (29 November 1917) Lewis arrived at the front line in the Somme Valley in France, where he experienced trench warfare for the first time. On 15 April 1918, as 1st Battalion, Somerset Light Infantry assaulted the village of Riez du Vinage in the midst of the German spring offensive, Lewis was wounded and two of his colleagues were killed by a British shell falling short of its target. He was depressed and homesick during his convalescence and, upon his recovery in October, he was assigned to duty in Andover, England. He was demobilized in December 1918 and soon restarted his studies. In a later letter, Lewis stated that his experience of the horrors of war, along with the loss of his mother and unhappiness in school, were the basis of his pessimism and atheism.\nAfter Lewis returned to Oxford, he received a First in Honour Moderations (Greek and Latin literature) in 1920, a First in Greats (Philosophy and Ancient History) in 1922 and a First in English in 1923. In 1924 he became a philosophy tutor at University College and, in 1925, was elected a Fellow and Tutor in English Literature at Magdalen College, where he served for 29 years until 1954.\nJanie Moore.\nDuring his army training, Lewis shared a room with another cadet, Edward Courtnay Francis \"Paddy\" Moore (1898\u20131918). Maureen Moore, Paddy's sister, said that the two made a mutual pact that if either died during the war, the survivor would take care of both of their families. Paddy was killed in action in 1918 and Lewis kept his promise. Paddy had earlier introduced Lewis to his mother, Janie King Moore, and a friendship quickly sprang up between Lewis, who was 18 when they met, and Janie, who was 45. The friendship with Moore was particularly important to Lewis while he was recovering from his wounds in hospital, as his father did not visit him.\nLewis lived with and cared for Moore until she was hospitalized in the late 1940s. He routinely introduced her as his mother, referred to her as such in letters, and developed a deeply affectionate friendship with her. Lewis's own mother had died when he was a child, while his father was distant, demanding, and eccentric.\nSpeculation regarding their relationship resurfaced with the 1990 publication of A. N. Wilson's biography of Lewis. Wilson (who never met Lewis) attempted to make a case for their having been lovers for a time. Wilson's biography was not the first to address the question of Lewis's relationship with Moore. George Sayer knew Lewis for 29 years, and he had sought to shed light on the relationship during the period of 14 years before Lewis's conversion to Christianity. In his biography \"Jack: A Life of C. S. Lewis\", he wrote:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Were they lovers? Owen Barfield, who knew Jack well in the 1920s, once said that he thought the likelihood was \"fifty-fifty\". Although she was twenty-six years older than Jack, she was still a handsome woman, and he was certainly infatuated with her. But it seems very odd, if they were lovers, that he would call her \"mother\". We know, too, that they did not share the same bedroom. It seems most likely that he was bound to her by the promise he had given to Paddy and that his promise was reinforced by his love for her as his second mother.\nLater Sayer changed his mind. In the introduction to the 1997 edition of his biography of Lewis he wrote:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;I have had to alter my opinion of Lewis's relationship with Mrs. Moore. In chapter eight of this book I wrote that I was uncertain about whether they were lovers. Now after conversations with Mrs. Moore's daughter, Maureen, and a consideration of the way in which their bedrooms were arranged at The Kilns, I am quite certain that they were.\nHowever, the romantic nature of the relationship is doubted by other writers; for example, Philip Zaleski and Carol Zaleski write in \"The Fellowship\" that\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;When\u2014or whether\u2014Lewis commenced an affair with Mrs. Moore remains unclear.\nLewis spoke well of Mrs. Moore throughout his life, saying to his friend George Sayer, \"She was generous and taught me to be generous, too.\" In December 1917, Lewis wrote in a letter to his childhood friend Arthur Greeves that Janie and Greeves were \"the two people who matter most to me in the world\".\nIn 1930 Lewis moved into The Kilns with his brother Warnie, Mrs. Moore, and her daughter Maureen. The Kilns was a house in the district of Headington Quarry on the outskirts of Oxford, now part of the suburb of Risinghurst. They all contributed financially to the purchase of the house, which eventually passed to Maureen, who by then was Dame Maureen Dunbar, when Warren died in 1973. Moore had dementia in her later years and was eventually moved into a nursing home, where she died in 1951. Lewis visited her every day in this home until her death.\nReturn to Christianity.\nLewis was raised in a religious family that attended the Church of Ireland. He became an atheist at age 15, though he later described his young self as being paradoxically \"very angry with God for not existing\" and \"equally angry with him for creating a world\". His early separation from Christianity began when he started to view his religion as a chore and a duty; around this time, he also gained an interest in the occult, as his studies expanded to include such topics. Lewis quoted Lucretius (\"De rerum natura\", 5.198\u20139) as having one of the strongest arguments for atheism:\n&lt;poem&gt;\n&lt;/poem&gt;\nwhich he translated poetically as follows:\n&lt;poem&gt;Had God designed the world, it would not be\nA world so frail and faulty as we see.&lt;/poem&gt;\nLewis's interest in the works of the Scottish writer George MacDonald was part of what turned him from atheism. This can be seen particularly well through this passage in Lewis's \"The Great Divorce\", chapter nine, when the semi-autobiographical protagonist meets MacDonald in Heaven:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;...\u00a0I tried, trembling, to tell this man all that his writings had done for me. I tried to tell how a certain frosty afternoon at Leatherhead Station when I had first bought a copy of \"Phantastes\" (being then about sixteen years old) had been to me what the first sight of Beatrice had been to Dante: \"Here begins the new life\". I started to confess how long that Life had delayed in the region of imagination merely: how slowly and reluctantly I had come to admit that his Christendom had more than an accidental connexion with it, how hard I had tried not to see the true name of the quality which first met me in his books is Holiness.\nHe eventually returned to Christianity, having been influenced by arguments with his Oxford colleague and friend J. R. R. Tolkien, whom he seems to have met for the first time on 11 May 1926, as well as the book \"The Everlasting Man\" by G. K. Chesterton. Lewis vigorously resisted conversion, noting that he was brought into Christianity like a prodigal, \"kicking, struggling, resentful, and darting his eyes in every direction for a chance to escape\". He described his last struggle in \"Surprised by Joy\":\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;You must picture me alone in that room in Magdalen [College, Oxford], night after night, feeling, whenever my mind lifted even for a second from my work, the steady, unrelenting approach of Him whom I so earnestly desired not to meet. That which I greatly feared had at last come upon me. In the Trinity Term of 1929 I gave in, and admitted that God was God, and knelt and prayed: perhaps, that night, the most dejected and reluctant convert in all England.\nAfter his conversion to theism in 1929, Lewis converted to Christianity in 1931, following a long discussion during a late-night walk along Addison's Walk with his close friends Tolkien and Hugo Dyson. He records making a specific commitment to Christian belief while on his way to the zoo with his brother. He became a member of the Church of England\u00a0\u2013 somewhat to the disappointment of Tolkien, who had hoped that he would join the Catholic Church.\nLewis was a committed Anglican who upheld a largely orthodox Anglican theology, though in his apologetic writings, he made an effort to avoid espousing any one denomination. In his later writings, some believe that he proposed ideas such as purification of venial sins after death in purgatory (\"The Great Divorce\" and \"Letters to Malcolm\") and mortal sin (\"The Screwtape Letters\"), which are generally considered to be Roman Catholic teachings, although they are also widely held in Anglicanism (particularly in high church Anglo-Catholic circles). Regardless, Lewis considered himself an entirely orthodox Anglican to the end of his life, reflecting that he had initially attended church only to receive communion and had been repelled by the hymns and the poor quality of the sermons. He later came to consider himself honoured by worshipping with men of faith who came in shabby clothes and work boots and who sang all the verses to all the hymns.\nSecond World War.\nAfter the outbreak of the Second World War in 1939, the Lewises took child evacuees from London and other cities into The Kilns. Lewis was only 40 when the war began, and he tried to re-enter military service, offering to instruct cadets; however, his offer was not accepted. He rejected the recruiting office's suggestion of writing columns for the Ministry of Information in the press, as he did not want to \"write lies\" to deceive the enemy. He later served in the local Home Guard in Oxford.\nFrom 1941 to 1943 Lewis spoke on religious programmes broadcast by the BBC from London while the city was under periodic air raids. These broadcasts were appreciated by civilians and servicemen at that stage. For example, Air Chief Marshal Sir Donald Hardman wrote:\n\"The war, the whole of life, everything tended to seem pointless. We needed, many of us, a key to the meaning of the universe. Lewis provided just that.\"\nThe youthful Alistair Cooke was less impressed, and in 1944 described \"the alarming vogue of Mr. C.S. Lewis\" as an example of how wartime tends to \"spawn so many quack religions and Messiahs\". The broadcasts were anthologized in \"Mere Christianity\". From 1941 Lewis was occupied at his summer holiday weekends visiting Royal Air Force stations to speak on his faith, invited by Chaplain-in-Chief Maurice Edwards.\nIt was also during the same wartime period that Lewis was invited to become first President of the Oxford Socratic Club in January 1942, a position he enthusiastically held until he resigned on appointment to the University of Cambridge in 1954.\nHonour declined.\nLewis was named on the last list of honours by George VI in December 1951 as a Commander of the Order of the British Empire (CBE) but declined so as to avoid association with any political issues.\nChair at Cambridge University.\nIn 1954 Lewis accepted the newly founded chair in Mediaeval and Renaissance Literature at Magdalene College, Cambridge, where he finished his career. He maintained a strong attachment to the city of Oxford, keeping a home there and returning on weekends until his death in 1963.\nJoy Davidman.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\nShe was my daughter and my mother, my pupil and my teacher, my subject and my sovereign; and always, holding all these in solution, my trusty comrade, friend, shipmate, fellow-soldier. My mistress; but at the same time all that any man friend (and I have good ones) has ever been to me. Perhaps more.\nC. S. Lewis\nIn his later life Lewis corresponded with Joy Davidman Gresham, an American writer of Jewish background, a former member of the Communist Party USA and a convert from atheism to Christianity. She was separated from her alcoholic and abusive husband, the novelist William L. Gresham, and came to England with her two sons, David and Douglas. Lewis at first regarded her as an agreeable intellectual companion and personal friend, and it was on this level that he agreed to enter into a civil marriage contract with her so that she could continue to live in Britain. They were married at the register office, 42 St Giles', Oxford, on 23 April 1956. Lewis's brother Warren wrote: \"For Jack the attraction was at first undoubtedly intellectual. Joy was the only woman whom he had met\u00a0... who had a brain which matched his own in suppleness, in width of interest, and in analytical grasp, and above all in humour and a sense of fun.\" After complaining of a painful hip, she was diagnosed with terminal bone cancer, and the relationship developed to the point that they sought a Christian marriage. Since she was divorced, this was not straightforward in the Church of England at the time, but a friend, the Rev. Peter Bide, performed the ceremony at her bed in the Churchill Hospital on 21 March 1957.\nGresham's cancer soon went into remission, and the couple lived together as a family with Warren Lewis until 1960, when her cancer recurred. She died on 13 July 1960. Earlier that year, the couple took a brief holiday in Greece and the Aegean; Lewis was fond of walking but not of travel, and this marked his only crossing of the English Channel after 1918. Lewis's book \"A Grief Observed\" describes his experience of bereavement in such a raw and personal fashion that he originally released it under the pseudonym N. W. Clerk to keep readers from associating the book with him. Ironically, many friends recommended the book to Lewis as a method for dealing with his own grief. After Lewis's death, his authorship was made public by Faber, with the permission of the executors.\nLewis had adopted Gresham's two sons and continued to raise them after her death. Douglas Gresham is a Christian like Lewis and his mother, while David Gresham turned to his mother's ancestral faith, becoming Orthodox Jewish in his beliefs. His mother's writings had featured the Jews in an unsympathetic manner, particularly on \"shechita\" (ritual slaughter). David informed Lewis that he was going to become a \"shohet\", a ritual slaughterer, to present this type of Jewish religious functionary to the world in a more favourable light. In a 2005 interview Douglas Gresham acknowledged that he and his brother were not close, although they had corresponded via email. \nDavid died on 25 December 2014. In 2020 Douglas revealed that his brother had died at a Swiss mental hospital, and that when David was a young man he had been diagnosed with paranoid schizophrenia.\nIllness and death.\nIn early June 1961 Lewis became infected with recurrent nephritis which progressed to chronic low-grade sepsis. His illness caused him to miss the autumn term at Cambridge, though his health gradually began improving in 1962 and he returned that April. His health continued to improve and, according to his friend George Sayer, Lewis was fully himself by early 1963.\nOn 15 July that year Lewis fell ill and was admitted to the hospital; he had a heart attack at 5:00\u00a0pm the next day and lapsed into a coma, but unexpectedly woke the following day at 2:00\u00a0pm. After he was discharged from the hospital, Lewis returned to the Kilns, though he was too ill to return to work. As a result, he resigned from his post at Cambridge in August 1963.\nLewis's condition continued to decline, and he was diagnosed with end-stage kidney failure in mid-November. He collapsed in his bedroom at 5:30\u00a0pm on 22 November, at age 64, and died a few minutes later. He is buried in the churchyard of Holy Trinity Church, Headington, Oxford. His brother Warren died on 9 April 1973 and was buried in the same grave.\nMedia coverage of Lewis's death was largely overshadowed by news of the assassination of John F. Kennedy, which occurred on the same day (approximately 55 minutes following Lewis's collapse), as did the death of the English writer Aldous Huxley, the author of \"Brave New World\". This coincidence was the inspiration for Peter Kreeft's book \"Between Heaven and Hell: A Dialog Somewhere Beyond Death with John F. Kennedy, C. S. Lewis, &amp; Aldous Huxley\". Lewis is commemorated on 22 November in the church calendar of the Episcopal Church.\nCareer.\nScholar.\nLewis began his academic career as an undergraduate student at Oxford, where he won a triple first, the highest honours in three areas of study. He was then elected a Fellow of Magdalen College, Oxford, where he worked for nearly thirty years, from 1925 to 1954. In 1954 he was awarded the newly founded chair of Mediaeval and Renaissance Literature at Cambridge University, and was elected a fellow of Magdalene College. Concerning his appointed academic field, he argued that there was no such thing as an English Renaissance. Much of his scholarly work concentrated on the later Middle Ages, especially its use of allegory. His \"The Allegory of Love\" (1936) helped reinvigorate the serious study of late medieval narratives such as the \"Roman de la Rose\".\nLewis was commissioned to write the volume \"English Literature in the Sixteenth Century (Excluding Drama)\" for the Oxford History of English Literature. His book \"A Preface to Paradise Lost\" is still cited as a criticism of that work. His last academic work, \"The Discarded Image: An Introduction to Medieval and Renaissance Literature\" (1964), is a summary of the medieval world view, a reference to the \"discarded image\" of the cosmos.\nLewis was a prolific writer, and his circle of literary friends became an informal discussion society known as the \"Inklings\", including J. R. R. Tolkien, Nevill Coghill, Lord David Cecil, Charles Williams, Owen Barfield and his brother Warren Lewis. Glyer points to December 1929 as the Inklings' beginning date. Lewis's friendship with Coghill and Tolkien grew during their time as members of the Kolb\u00edtar, an Old Norse reading group that Tolkien founded and which ended around the time of the inception of the Inklings. At Oxford, he was the tutor of the poet John Betjeman, the theatre-critic Kenneth Tynan, the Catholic priest Bede Griffiths, the writer Roger Lancelyn Green and the Sufi scholar Martin Lings, among many other undergraduates. The religious and conservative Betjeman detested Lewis, whereas the anti-establishment Tynan retained a lifelong admiration for him.\nOf Tolkien, Lewis writes in \"Surprised by Joy\":\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;When I began teaching for the English Faculty, I made two other friends, both Christians (these queer people seemed now to pop up on every side) who were later to give me much help in getting over the last stile. They were HVV Dyson\u00a0... and JRR Tolkien. Friendship with the latter marked the breakdown of two old prejudices. At my first coming into the world I had been (implicitly) warned never to trust a Papist, and at my first coming into the English Faculty (explicitly) never to trust a philologist. Tolkien was both.\nNovelist.\nIn addition to his scholarly work, Lewis wrote several popular novels, including the science fiction \"Space Trilogy\" for adults and the Narnia fantasies for children. Most deal implicitly with Christian themes such as sin, humanity's fall from grace, and redemption.\nHis first novel after becoming a Christian was \"The Pilgrim's Regress\" (1933), which depicted his journey to Christianity in the allegorical style of John Bunyan's \"The Pilgrim's Progress\". The book was poorly received by critics at the time, although David Martyn Lloyd-Jones, one of Lewis's contemporaries at Oxford, gave him much-valued encouragement. Asked by Lloyd-Jones when he would write another book, Lewis replied, \"When I understand the meaning of prayer.\"\nThe \"Space Trilogy\" (also called the \"Cosmic Trilogy\" or \"Ransom Trilogy\") dealt with what Lewis saw as the dehumanizing trends in contemporary science fiction. The first book, \"Out of the Silent Planet\", was apparently written following a conversation with his friend Tolkien about these trends. Lewis agreed to write a \"space travel\" story and Tolkien a \"time travel\" one, but Tolkien never completed \"The Lost Road\", linking his Middle-earth to the modern world. Lewis's main character Elwin Ransom is based in part on Tolkien, a fact to which Tolkien alludes in his letters.\nThe second novel, \"Perelandra\", depicts a new Garden of Eden on the planet Venus, a new Adam and Eve, and a new \"serpent figure\" to tempt Eve. The story can be seen as an account of what might have happened if the terrestrial Adam had defeated the serpent and avoided the Fall of Man, with Ransom intervening in the novel to \"ransom\" the new Adam and Eve from the deceptions of the enemy. The third novel, \"That Hideous Strength\", develops the theme of nihilistic science threatening traditional human values, embodied in Arthurian legend.\nMany ideas in the trilogy, particularly opposition to dehumanization as portrayed in the third book, are presented more formally in \"The Abolition of Man\", based on a series of lectures by Lewis at Durham University in 1943. Lewis stayed in Durham, where he says he was overwhelmed by the magnificence of the cathedral. \"That Hideous Strength\" is in fact set in the environs of \"Edgestow\" university, a small English university like Durham, though Lewis disclaims any other resemblance between the two.\nWalter Hooper, Lewis's literary executor, discovered a fragment of another science-fiction novel apparently written by Lewis called \"The Dark Tower\". Ransom appears in the story but it is not clear whether the book was intended as part of the same series of novels. The manuscript was eventually published in 1977, though Lewis scholar Kathryn Lindskoog doubts its authenticity.\n\"The Chronicles of Narnia\", considered a classic of children's literature, is a series of seven fantasy novels. Written between 1949 and 1954 and illustrated by Pauline Baynes, the series is Lewis's most popular work, having sold over 100 million copies in 41 languages . It has been adapted several times, complete or in part, for radio, television, stage and cinema. In 1956, the final novel in the series, \"The Last Battle\", won the Carnegie Medal.\nThe books contain Christian ideas intended to be easily accessible to young readers. In addition to Christian themes, Lewis also borrows characters from Greek and Roman mythology, as well as traditional British and Irish fairy tales.\nLewis's last novel, \"Till We Have Faces\", a retelling of the myth of Cupid and Psyche, was published in 1956. Although Lewis called it \"far and away my best book\", it was not as well-reviewed as his previous work.\nOther works.\nLewis wrote several works on Heaven and Hell. One of these, \"The Great Divorce\", is a short novella in which a few residents of Hell take a bus ride to Heaven, where they are met by people who dwell there. The proposition is that they can stay if they choose, in which case they can call the place where they had come from \"Purgatory\", instead of \"Hell\", but many find it not to their taste. The title is a reference to William Blake's \"The Marriage of Heaven and Hell\", a concept that Lewis found a \"disastrous error\". This work deliberately echoes two other more famous works with a similar theme: the \"Divine Comedy\" of Dante Alighieri, and Bunyan's \"The Pilgrim's Progress\".\nAnother short work, \"The Screwtape Letters\", which he dedicated to Tolkien, consists of letters of advice from the senior demon Screwtape to his nephew Wormwood on the best ways to tempt a particular human and secure his damnation. Lewis's last novel was \"Till We Have Faces\", which he thought of as his most mature and masterly work of fiction but which was never a popular success. It is a retelling of the myth of Cupid and Psyche from the unusual perspective of Psyche's sister. It is deeply concerned with religious ideas, but the setting is entirely pagan, and the connections with specific Christian beliefs are left implicit.\nBefore Lewis's conversion to Christianity, he published two books: \"Spirits in Bondage\", a collection of poems, and \"Dymer\", a single narrative poem. Both were published under the pen name Clive Hamilton. Other narrative poems have since been published posthumously, including \"Launcelot\", \"The Nameless Isle\", and \"The Queen of Drum\".\nHe also wrote \"The Four Loves\", which rhetorically explains four categories of love: friendship, eros, affection, and charity.\nIn 2009 a partial draft was discovered of \"Language and Human Nature\", which Lewis had begun co-writing with J. R. R. Tolkien, but which was never completed.\nIn 2024 an original poem was discovered in a collection of documents in Special Collections at the University of Leeds. Its Old English title, \"M\u00f3d \u00der\u00fd\u00fee Ne W\u00e6g\", is not easily translated into modern English and references the epic poem \"Beowulf\". The poem was addressed to the professor of English Eric Valentine Gordon and his wife Dr Ida Gordon. It was written under the pen name Nat Whilk, meaning \"someone\" in Old English.\nChristian apologist.\nLewis is also regarded by many as one of the most influential Christian apologists of his time, in addition to his career as an English professor and an author of fiction. \"Mere Christianity\" was voted best book of the 20th century by \"Christianity Today\" in 2000. He has been called \"The Apostle to the Skeptics\" due to his approach to religious belief as a sceptic, and his following conversion.\nLewis was very interested in presenting an argument from reason against metaphysical naturalism and for the existence of God. \"Mere Christianity\", \"The Problem of Pain\", and \"Miracles\" were all concerned, to one degree or another, with refuting popular objections to Christianity, such as the question, \"How could a good God allow pain to exist in the world?\" He also became a popular lecturer and broadcaster, and some of his writing originated as scripts for radio talks or lectures (including much of \"Mere Christianity\").\nAccording to George Sayer, losing a 1948 debate with Elizabeth Anscombe, also a Christian, led Lewis to re-evaluate his role as an apologist, and his future works concentrated on devotional literature and children's books. Anscombe had a completely different recollection of the debate's outcome and its emotional effect on Lewis. Victor Reppert also disputes Sayer, listing some of Lewis's post-1948 apologetic publications, including the second and revised edition of his \"Miracles\" in 1960, in which Lewis addressed Anscombe's criticism.&lt;ref name=\"Reppert 2005 https://books.google.com/books?id=hn1gaNlri1cC&amp;pg=PA266 266\"&gt;&lt;/ref&gt; Noteworthy too is Roger Teichman's suggestion in \"The Philosophy of Elizabeth Anscombe\" that the intellectual impact of Anscombe's paper on Lewis's philosophical self-confidence should not be over-rated: \"...\u00a0it seems unlikely that he felt as irretrievably crushed as some of his acquaintances have made out; the episode is probably an inflated legend, in the same category as the affair of Wittgenstein's Poker. Certainly, Anscombe herself believed that Lewis's argument, though flawed, was getting at something very important; she thought that this came out more in the improved version of it that Lewis presented in a subsequent edition of \"Miracles\"\u00a0\u2013 though that version also had 'much to criticize in it'.\"\nLewis wrote an autobiography titled \"Surprised by Joy\", which places special emphasis on his own conversion. He also wrote many essays and public speeches on Christian belief, many of which were collected in \"God in the Dock\" and \"The Weight of Glory and Other Addresses\".\nHis most famous works, the \"Chronicles of Narnia\", contain many strong Christian messages and are often considered allegory. Lewis, an expert on the subject of allegory, maintained that the books were not allegory, and preferred to call the Christian aspects of them \"suppositional\". As Lewis wrote in a letter to a Mrs. Hook in December 1958:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;If Aslan represented the immaterial Deity in the same way in which Giant Despair [a character in \"The Pilgrim's Progress\"] represents despair, he would be an allegorical figure. In reality, he is an invention giving an imaginary answer to the question, \"What might Christ become like, if there really were a world like Narnia and He chose to be incarnate and die and rise again in that world as He actually has done in ours?\" This is not allegory at all.\nPrior to his conversion, Lewis used the word \"Moslem\" to refer to Muslims, adherents of Islam; following his conversion, however, he started using \"Mohammedans\" and described Islam as a Christian heresy rather than an independent religion.\n\"Trilemma\".\nIn a much-cited passage from \"Mere Christianity\", Lewis challenged the view that Jesus was a great moral teacher but not God. He argued that Jesus made several implicit claims to divinity, which would logically exclude that claim:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;I am trying here to prevent anyone saying the really foolish thing that people often say about Him: 'I'm ready to accept Jesus as a great moral teacher, but I don't accept his claim to be God.' That is the one thing we must not say. A man who was merely a man and said the sort of things Jesus said would not be a great moral teacher. He would either be a lunatic\u00a0\u2013 on the level with the man who says he is a poached egg\u00a0\u2013 or else he would be the Devil of Hell. You must make your choice. Either this man was, and is, the Son of God, or else a madman or something worse. You can shut him up for a fool, you can spit at him and kill him as a demon or you can fall at his feet and call him Lord and God, but let us not come with any patronising nonsense about his being a great human teacher. He has not left that open to us. He did not intend to.\nAlthough this argument is sometimes called \"Lewis's trilemma\", Lewis did not invent it but rather developed and popularized it. It has also been used by the Christian apologist Josh McDowell in his book \"More Than a Carpenter\". It has been widely repeated in Christian apologetic literature but largely ignored by professional theologians and biblical scholars.\nLewis's Christian apologetics, and this argument in particular, have been criticized. Philosopher John Beversluis described Lewis's arguments as \"textually careless and theologically unreliable\", and this particular argument as logically unsound and an example of a false dilemma. The Anglican New Testament scholar N. T. Wright criticizes Lewis for failing to recognize the significance of Jesus's Jewish identity and setting\u00a0\u2013 an oversight which \"at best, drastically short-circuits the argument\" and which lays Lewis open to criticism that his argument \"doesn't work as history, and it backfires dangerously when historical critics question his reading of the gospels\", although he argues that this \"doesn't undermine the eventual claim\".\nLewis used a similar argument in \"The Lion, the Witch and the Wardrobe\", when the old Professor advises his young guests that their sister's claims of a magical world must logically be taken as either lies, madness, or truth.\nUniversal morality.\nOne of the main theses in Lewis's apologia is that there is a common morality known throughout humanity, which he calls \"natural law\". In the first five chapters of \"Mere Christianity\", Lewis discusses the idea that people have a standard of behaviour to which they expect people to adhere. Lewis claims that people all over the earth know what this law is and when they break it. He goes on to claim that there must be someone or something behind such a universal set of principles.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;These then are the two points that I wanted to make. First, that human beings, all over the earth, have this curious idea that they ought to behave in a certain way, and cannot really get rid of it. Secondly, that they do not in fact behave in that way. They know the Law of Nature; they break it. These two facts are the foundation of all clear thinking about ourselves and the universe we live in.\nLewis also portrays Universal Morality in his works of fiction. In \"The Chronicles of Narnia\" he describes Universal Morality as the \"deep magic\" which everyone knew.\nIn the second chapter of \"Mere Christianity\" Lewis recognizes that \"many people find it difficult to understand what this Law of Human Nature\u00a0... is.\" And he responds first to the idea \"that the Moral Law is simply our herd instinct\" and second to the idea \"that the Moral Law is simply a social convention\". In responding to the second idea Lewis notes that people often complain that one set of moral ideas is better than another, but that this actually argues for there existing some \"Real Morality\" to which they are comparing other moralities. Finally, he notes that sometimes differences in moral codes are exaggerated by people who confuse differences in beliefs about morality with differences in beliefs about facts:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;I have met people who exaggerate the differences, because they have not distinguished between differences of morality and differences of belief about facts. For example, one man said to me, \"Three hundred years ago people in England were putting witches to death. Was that what you call the Rule of Human Nature or Right Conduct?\" But surely the reason we do not execute witches is that we do not believe there are such things. If we did\u00a0\u2013 if we really thought that there were people going about who had sold themselves to the devil and received supernatural powers from him in return and were using these powers to kill their neighbours or drive them mad or bring bad weather, surely we would all agree that if anyone deserved the death penalty, then these filthy quislings did. There is no difference of moral principle here: the difference is simply about matter of fact. It may be a great advance in knowledge not to believe in witches: there is no moral advance in not executing them when you do not think they are there. You would not call a man humane for ceasing to set mousetraps if he did so because he believed there were no mice in the house.\nLewis also had fairly progressive views on the topic of \"animal morality\", in particular the suffering of animals, as is evidenced by several of his essays: most notably, \"On Vivisection\" and \"On the Pains of Animals\".\nPolitical views.\nLewis eschewed political involvement and partisan politics, took little interest in transitory political issues, and held many politicians in disdain. He refused a knighthood for fear that his detractors might then use it to accuse him of holding a political viewpoint, and he saw his role as a Christian apologist. His worldview was Christian, but he also did not believe in establishment of Christian parties. He avoided the political sphere, although he was not ignorant of it.238 He did not see himself as a political philosopher, but his work, \"The Abolition of Man\" (1943) defends objective value and the concept of natural law. Lewis referred to this work as almost his own favourite, although he felt it had been largely ignored. \"The Abolition of Man\" was not presented as something new. Instead, he paid attention to ideas, with the intent of recovering them. In \"The Abolition of Man\", \"Lewis offered the postmodern world a vision of reality that could make sense of our lived moral experiences, and he put forth a powerful defense of natural law as a necessary basis for \"the very idea of a rule which is not tyranny or an obedience which is not slavery\".4876\nLegacy.\nLewis continues to attract a wide readership. In 2008 \"The Times\" ranked him eleventh on their list of \"the 50 greatest British writers since 1945\". Readers of his fiction are often unaware of what Lewis considered the Christian themes of his works. His Christian apologetics are read and quoted by members of many Christian denominations. In 2013, on the 50th anniversary of his death, Lewis joined some of Britain's greatest writers recognized at Poets' Corner, Westminster Abbey. The dedication service, at noon on 22 November 2013, included a reading from \"The Last Battle\" by Douglas Gresham, younger stepson of Lewis. Flowers were laid by Walter Hooper, trustee and literary advisor to the Lewis Estate. An address was delivered by the former Archbishop of Canterbury Rowan Williams. The floor stone inscription is a quotation from an address by Lewis:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nLewis has been the subject of several biographies, a few of which were written by close friends, such as Roger Lancelyn Green and George Sayer. In 1985 the screenplay \"Shadowlands\" by William Nicholson dramatized Lewis's life and relationship with Joy Davidman Gresham. It was aired on British television starring Joss Ackland and Claire Bloom. This was also staged as a theatre play starring Nigel Hawthorne in 1989 and made into the 1993 feature film \"Shadowlands\" starring Anthony Hopkins and Debra Winger.\nMany books have been inspired by Lewis, including \"A Severe Mercy\" by his correspondent and friend Sheldon Vanauken. \"The Chronicles of Narnia\" has been particularly influential. Modern children's literature has been more or less influenced by Lewis's series, such as Daniel Handler's \"A Series of Unfortunate Events\", Eoin Colfer's \"Artemis Fowl\", Philip Pullman's \"His Dark Materials\" and J. K. Rowling's \"Harry Potter\". Pullman is an atheist and is known to be sharply critical of Lewis's work, accusing Lewis of featuring religious propaganda, misogyny, racism, and emotional sadism in his books. However, he has also modestly praised \"The Chronicles of Narnia\" for being a \"more serious\" work of literature in comparison with Tolkien's \"trivial\" \"The Lord of the Rings\". Authors of adult fantasy literature such as Tim Powers have also testified to being influenced by Lewis's work.\nMost of Lewis's posthumous work has been edited by his literary executor Walter Hooper. Kathryn Lindskoog, an independent Lewis scholar, argued that Hooper's scholarship is not reliable and that he has made false statements and attributed forged works to Lewis. Lewis's stepson, Douglas Gresham, denies the forgery claims, saying that \"[t]he whole controversy thing was engineered for very personal reasons\u00a0... Her fanciful theories have been pretty thoroughly discredited.\"\nA bronze statue of Lewis's character Digory from \"The Magician's Nephew\" stands in Belfast's Holywood Arches in front of the Holywood Road Library.\nSeveral C. S. Lewis Societies exist around the world, including one which was founded in Oxford in 1982. The C.S. Lewis Society at the University of Oxford meets at Pusey House during term time to discuss papers on the life and works of Lewis and the other Inklings, and generally appreciate all things Lewisian.\nLive-action film adaptations have been made of three of \"The Chronicles of Narnia: \" (2005), ' (2008) and ' (2010).\nLewis is featured as a main character in \"The Chronicles of the Imaginarium Geographica\" series by James A. Owen. He is one of two characters in Mark St. Germain's 2009 play \"Freud's Last Session\", which imagines a meeting between Lewis, aged 40, and Sigmund Freud, aged 83, at Freud's house in Hampstead, London, in 1939, as the Second World War is about to break out. In 2023 \"Freud's Last Session\" was released as a film starring Anthony Hopkins as Freud and Matthew Goode as Lewis. It had additional characters as well, including Anna Freud, played by Liv Lisa Fries.\nIn 2021 \"The Most Reluctant Convert\", a biographical drama about Lewis's life and conversion, was released.\nThe CS Lewis Nature Reserve, on ground owned by Lewis, lies behind his house, The Kilns. There is public access.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "5814", "revid": "61262", "url": "https://en.wikipedia.org/wiki?curid=5814", "title": "Chinese dominoes", "text": "Type of dominoes\nChinese dominoes are used in several tile-based games, namely, tien gow, pai gow, tiu u and kap tai shap. In Cantonese they are called (), which literally means \"bone tiles\"; it is also the name of a northern Chinese game, where the rules are quite different from the southern Chinese version of tien gow.\nHistory.\nMing author Xie Zhaozhe (1567\u20131624) records the legend of dominoes having been presented to Song Emperor Huizong in 1112. However the contemporary Li Qingzhao (1084 \u2013 c.\u20091155) made no mention of dominoes in her compendium of games.\nIn China, early \"domino\" tiles were functionally identical to playing cards. An identifiable version of Chinese dominoes developed in the 12th or 13th century.\nThe oldest confirmed written mention of dominoes in China comes from the \"Former Events in Wulin\" (i.e. the capital Hangzhou) written by the Yuan Dynasty (1271\u20131368) author Zhou Mi (1232\u20131298), who listed \"pupai\" (gambling plaques or dominoes) as well as dice as items sold by peddlers during the reign of Song Emperor Xiaozong (r.\u20091162\u00a0\u2013\u00a01189). Andrew Lo asserts that Zhou Mi meant dominoes when referring to \"pupai\", since the Ming author Lu Rong (1436\u20131494) explicitly defined \"pupai\" as dominoes (in regards to a story of a suitor who won a maiden's hand by drawing out four winning \"pupai\" from a set). Tiles dating from the 12th to 14th centuries have survived. Unlike most modern tiles they are white with black and red pips.\nThe earliest known manual written about dominoes is the \"Manual of the Xuanhe Period\" () written by Qu You (1341\u20131427), but some Chinese scholars believe this manual is a forgery from a later time. In the \"Encyclopedia of a Myriad of Treasures\", Zhang Pu (1602\u20131641) described the game of laying out dominoes as \"pupai\", although the character for \"pu\" had changed, yet retained a similar pronunciation.\nDuring the Qing dynasty (1644-1912), the suits known as \"Chinese\" and \"barbarian\" were renamed to \"civil\" and \"military\" respectively to avoid offending the ruling Manchus. Tiles with blank ends, like those found in Western \"double-six\" dominoes, once existed during the 17th century. These games employed two sets of \"double-six\" tiles. It is possible that these were the types of dominoes that made it to Europe the following century. However, the 32-piece Chinese domino set, made to represent each possible face of two thrown dice and thus have no blank faces, differs from the 28-piece domino set found in the West during the mid 18th century. Chinese dominoes with blank faces were known during the 17th century.\nEach domino originally represented one of the 21 results of throwing two six-sided dice (2d6). One half of each domino is set with the pips from one die and the other half contains the pips from the second die. Chinese sets also introduce duplicates of some throws and divide the tiles into two suits: military and civil. Chinese dominoes are also longer than typical European ones.\nTraditional Chinese domino games include \"Tien Gow, Pai Gow, Che Deng\", and others.\nDeck composition and ranking.\nEach tile pattern in the Chinese domino set is equivalent to a single outcome when two six-sided dice are thrown. Each combination is only used once, so there are 21 unique possible patterns. Eleven of these 21 unique patterns are repeated to make a total of 32 tiles in a Chinese dominoes set. The 32-tile set is divided into two \"suits\" or groups called \"military\" and \"civil\". There are no markings on the tiles to distinguish these suits; a player must simply remember which tiles belong to which group. There are two each of the eleven civil suit tiles (6-6, 1-1, 4-4, 1-3, 5-5, 3-3, 2-2, 5-6, 4-6, 1-6, 1-5) and one each of the ten military suit tiles (3-6, 4-5; 2-6, 3-5; 2-5, 3-4; 2-4; 1-4, 2-3; 1-2).\nCivil suit.\nEach civil tile also has a Chinese name. Here are the Cantonese names and rough English translations:\nThe civil tiles are ranked according to the Chinese cultural significance of the tile names, and must be memorized. The hendiatris of heaven, earth, and man () dates back for over two thousand years while the harmony () of the three have been in dice and domino games since at least the Ming dynasty. Remembering the suits and rankings of the tiles is easier if one understands the Chinese names of the tiles and the symbolism behind them.\nMilitary suit.\nThe military tiles are named and ranked according to the total pips or points on the tiles. For example, the \"nines\" (3-6 and 4-5) rank higher than the \"eights\" (2-6 and 3-5). The rankings of the individual tiles are similar in most games. However, the ranking of combinations of tiles is slightly different in Pai Gow and Tien Gow.\nSince there is only one of each military tile, these are usually grouped in four mixed \"pairs\" of equivalent total points: nines, eights, sevens, and fives; for example, the 3-6 and 4-5 tiles \"match\" because they have same total points (nine) and both are in the military suit. Among the military tiles, individual tiles of the same pair rank equally, such as 1-4 and 2-3, each totaling five.\nThe 2-4 (six) and 1-2 (three) military tiles also are paired together in many games despite the nominal difference in total points. They are the only tiles in the entire set that have no corresponding tile in the military suit, considering sums. In Pai Gow both of these tiles may be scored as three or six, depending on which is more advantageous. This pair when played together is considered a suit on its own, called the \"gi jun\" ( supreme). It is the highest ranking pair in the game of Pai Gow, though the tiles rank low individually (in their normal order). When either tile of this pair is played individually in the game of Tien Gow, each takes its regular ranking according to the total points among the other military suit tiles.\nPhysical characteristics.\nStewart Culin stated that traditional dominoes are made of Chinese ebony with measurements of long, wide, and thick.\nValues are marked with white and red pips. Using the same coloring scheme as traditional Chinese dice, every half-domino with 1 or 4 pips has those pips colored red; for example, the 4-5 domino has four red pips and five white pips. The only exception is the pair of 6-6 tiles. Half of the pips on the 6-6 domino are colored red to make them stand out as the top ranking tiles.\nTypically, one of the short edges is marked with a single red pip, and the backs may be marked with three pips, arrayed diagonally white-red-white.\nVariants.\nThere are also sets with where the tiles have Xiangqi characters next to the pips. As Xiangqi also has 32 pieces, these dual use sets can be used to play Giog.\nVariant sets include the Digging Flowers () game, which use the same 21 patterns generated by the 2d6 combination; some tiles have flowers or frames printed on them while others have their values duplicated. In addition, a Digging Flowers set may include several bonus tiles from mahjong, including flower, season, and blank tiles.\nDominoes from Korea also come in a set of 32 and bear markings schematically identical to Chinese dominoes, based on the throw of two dice, although the tiles are closer in size and shape to those used in mahjong, measuring , and the pip size may vary, especially for the 1- and 4-pip halves. The pairings for the \"military\" suit also differ: 1-2 and 4-5; 1-4 and 2-3, 2-4 and 3-4, 2-5 and 3-5, and 2-6 and 3-6.\nChinese Dominoes may also appear in a card format (). 15 Lake Cards () have the 21 patterns (from the 2d6 combinations) quadruplicated to form an 84-card deck. Si Chuan Cards () may have the 21 patterns plus two additional cards (the \"listen - use\" and the \"god of wealth\") duplicated up to 5 times to form a 115-card deck.\nBone tiles game.\nThe eponymous game of Bone Tiles (\"g\u01d4p\u00e1i\" in Mandarin) is played in northern and central China and as far south as Hunan. The name suggests that it is or became the default game played with dominoes in those regions. It is a trick-taking game similar to Tien Gow but has been simplified. In single-tile tricks, the civil and military suits have been merged into a single suit. In double-tile tricks, there is a new ranking order similar to Pai Gow. Triple-tile and quadruple-tile tricks are not allowed as in older versions of Tien Gow. Scoring has been simplified to number of stacks won.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "5816", "revid": "44248157", "url": "https://en.wikipedia.org/wiki?curid=5816", "title": "Cenozoic", "text": "Third era of the Phanerozoic Eon\nThe Cenozoic Era (also known as Caenozoic, Kainozoic, or Neozoic Era; ; ; lit.\u2009'new life') is Earth's current geological era, representing the last 66million years of Earth's history. It is characterized by the dominance of mammals, insects, birds and angiosperms (flowering plants). It is the latest of three geological eras of the Phanerozoic Eon, preceded by the Mesozoic and Paleozoic. The Cenozoic started with the Cretaceous\u2013Paleogene extinction event, when many species, including the non-avian dinosaurs, became extinct in an event attributed by most experts to the impact of a large asteroid or other celestial body, the Chicxulub impactor.\nThe Cenozoic is also known as the Age of Mammals because the terrestrial animals that dominated both hemispheres were mammals\u00a0\u2013\u00a0the eutherians (placentals) in the Northern Hemisphere and the metatherians (marsupials, now mainly restricted to Australia and to some extent South America) in the Southern Hemisphere. The extinction of many groups allowed mammals and birds to greatly diversify so that large mammals and birds dominated life on Earth. The continents also moved into their current positions during this era.\nThe climate during the early Cenozoic was warmer than today, particularly during the Paleocene\u2013Eocene Thermal Maximum. However, the Eocene to Oligocene transition and the Quaternary glaciation dried and cooled Earth.\nNomenclature.\n\"Cenozoic\" derives from the Ancient Greek words (, 'new') and (, 'life'). The name was proposed in 1840 by the British geologist John Phillips (1800\u20131874), who originally spelled it \"Kainozoic\". The era is also known as the \"C\u00e6nozoic\", \"Caenozoic\", or \"Cainozoic\" ().\nIn name, the Cenozoic (lit.\u2009'new life') is comparable to the preceding Mesozoic ('middle life') and Paleozoic ('old life') Eras, as well as to the Proterozoic ('earlier life') Eon.\nDivisions.\nThe Cenozoic is divided into three periods: the Paleogene, Neogene, and Quaternary; and seven epochs: the Paleocene, Eocene, Oligocene, Miocene, Pliocene, Pleistocene, and Holocene. The Quaternary Period was officially recognised by the International Commission on Stratigraphy in June 2009. In 2004, the Tertiary Period was officially replaced by the Paleogene and Neogene Periods. The common use of epochs during the Cenozoic helps palaeontologists better organise and group the many significant events that occurred during this comparatively short interval of time. Knowledge of this era is more detailed than any other era because of the relatively young, well-preserved rocks associated with it.\nPaleogene.\nThe Paleogene spans from the extinction of non-avian dinosaurs, 66 million years ago, to the dawn of the Neogene, 23.03\u00a0million years ago. It features three epochs: the Paleocene, Eocene and Oligocene. \nThe Paleocene Epoch lasted from 66 million to 56\u00a0million years ago. Modern placental mammals originated during this time. The devastation of the K\u2013Pg extinction event included the extinction of large herbivores, which permitted the spread of dense but usually species-poor forests. The Early Paleocene saw the recovery of Earth. The continents began to take their modern shape, but all the continents and the subcontinent of India were separated from each other. Afro-Eurasia was separated by the Tethys Sea, and the Americas were separated by the strait of Panama, as the isthmus had not yet formed. This epoch featured a general warming trend, with jungles eventually reaching the poles. The oceans were dominated by sharks as the large reptiles that had once predominated were extinct. Archaic mammals filled the world such as creodonts (extinct carnivores, unrelated to existing Carnivora).\nThe Eocene Epoch ranged from 56 million years to 33.9\u00a0million years ago. In the Early-Eocene, species living in dense forest were unable to evolve into larger forms, as in the Paleocene. Among them were early primates, whales and horses along with many other early forms of mammals. At the top of the food chains were huge birds, such as Paracrax. Carbon dioxide levels were approximately 1,400 ppm. The temperature was 30 degrees Celsius with little temperature gradient from pole to pole. In the Mid-Eocene, the Antarctic Circumpolar Current between Australia and Antarctica formed. This disrupted ocean currents worldwide and as a result caused a global cooling effect, shrinking the jungles. This allowed mammals to grow to mammoth proportions, such as whales which, by that time, had become almost fully aquatic. Mammals like \"Andrewsarchus\" were at the top of the food-chain. The Late Eocene saw the rebirth of seasons, which caused the expansion of savanna-like areas, along with the evolution of grasses. The end of the Eocene was marked by the Eocene\u2013Oligocene extinction event, the European face of which is known as the Grande Coupure.\nThe Oligocene spans from 33.9\u00a0million to 23.03\u00a0million years ago. The Oligocene featured the expansion of grasslands which had led to many new species to evolve, including the first elephants, cats, dogs, marsupials and many other species still prevalent today. Many other species of plants evolved in this period too. A cooling period featuring seasonal rains was still in effect. Mammals still continued to grow larger and larger.\nNeogene.\nThe Neogene spans from 23.03\u00a0million to 2.58\u00a0million years ago. It features two epochs: the Miocene, and the Pliocene.\nThe Miocene Epoch spans from 23.03 to 5.333\u00a0million years ago and is a period in which grasses spread further, dominating a large portion of the world, at the expense of forests. Kelp forests evolved, encouraging the evolution of new species, such as sea otters. During this time, Perissodactyla thrived, and evolved into many different varieties. Apes evolved into 30 species. The Tethys Sea finally closed with the creation of the Arabian Peninsula, leaving only remnants as the Black, Red, Mediterranean and Caspian Seas. This increased aridity. Many new plants evolved: 95% of modern seed plants families were present by the end of the Miocene.\nThe Pliocene Epoch lasted from 5.333 to 2.58\u00a0million years ago. The Pliocene featured dramatic climatic changes, which ultimately led to modern species of flora and fauna. The Mediterranean Sea dried up for several million years (because the ice ages reduced sea levels, disconnecting the Atlantic from the Mediterranean, and evaporation rates exceeded inflow from rivers). \"Australopithecus\" evolved in Africa, beginning the human branch. The Isthmus of Panama formed, and animals migrated between North and South America during the great American interchange, wreaking havoc on local ecologies. Climatic changes brought: savannas that are still continuing to spread across the world; Indian monsoons; deserts in central Asia; and the beginnings of the Sahara desert. The world map has not changed much since, save for changes brought about by the glaciations of the Quaternary, such as the Great Lakes, Hudson Bay, and the Baltic Sea.\nQuaternary.\nThe Quaternary spans from 2.58\u00a0million years ago to present day, and is the shortest geological period in the Phanerozoic Eon. It features modern animals, and dramatic changes in the climate. It is divided into two epochs: the Pleistocene and the Holocene.\nThe Pleistocene lasted from 2.58\u00a0million to 11,700 years ago. This epoch was marked by ice ages as a result of the cooling trend that started in the Mid-Eocene. There were at least four separate glaciation periods marked by the advance of ice caps as far south as 40\u00b0 N in mountainous areas. Meanwhile, Africa experienced a trend of desiccation which resulted in the creation of the Sahara, Namib, and Kalahari deserts. Many animals evolved including mammoths, giant ground sloths, dire wolves, sabre-toothed cats, and \"Homo sapiens\". 100,000 years ago marked the end of one of the worst droughts in Africa, and led to the expansion of primitive humans. As the Pleistocene drew to a close, a major extinction wiped out much of the world's megafauna, including some of the hominid species, such as Neanderthals. All the continents were affected, but Africa to a lesser extent. It still retains many large animals, such as hippos.\nThe Holocene began 11,700 years ago and lasts to the present day. All recorded history and \"the Human history\" lies within the boundaries of the Holocene Epoch. Human activity is blamed for a mass extinction that began roughly 10,000 years ago, though the species becoming extinct have only been recorded since the Industrial Revolution. This is sometimes referred to as the \"Sixth Extinction\". It is often cited that over 322 recorded species have become extinct due to human activity since the Industrial Revolution, but the rate may be as high as 500 vertebrate species alone, the majority of which have occurred after 1900.\nTectonics.\nGeologically, the Cenozoic is the era when the continents moved into their current positions. Australia-New Guinea, having split from Pangea during the early Cretaceous, drifted north and, eventually, collided with Southeast Asia; Antarctica moved into its current position over the South Pole; the Atlantic Ocean widened and, later in the era (2.8\u00a0million years ago), South America became attached to North America with the isthmus of Panama.\nIndia collided with Asia https:// 45 creating the Himalayas; Arabia collided with Eurasia, closing the Tethys Ocean and creating the Zagros Mountains, around https://\u00a0million years ago.\nThe break-up of Gondwana in Late Cretaceous and Cenozoic times led to a shift in the river courses of various large African rivers including the Congo, Niger, Nile, Orange, Limpopo and Zambezi.\nClimate.\nIn the Cretaceous, the climate was hot and humid with lush forests at the poles, there was no permanent ice and sea levels were around 300 metres higher than today. This continued for the first 10\u00a0million years of the Paleocene, culminating in the Paleocene\u2013Eocene Thermal Maximum about https://\u00a0million years ago. Around https://\u00a0million years ago, Earth entered a period of long term cooling. This was mainly due to the collision of India with Eurasia, which caused the rise of the Himalayas: the upraised rocks eroded and reacted with CO2 in the air, causing a long-term reduction in the proportion of this greenhouse gas in the atmosphere. Around https://\u00a0million years ago, permanent ice began to build up on Antarctica. The cooling trend continued in the Miocene, with relatively short warmer periods. When South America became attached to North America creating the Isthmus of Panama around https://\u00a0million years ago, the Arctic region cooled due to the strengthening of the Humboldt and Gulf Stream currents, eventually leading to the glaciations of the Quaternary ice age, the current interglacial of which is the Holocene Epoch.\nRecent analysis of the geomagnetic reversal frequency, oxygen isotope record, and tectonic plate subduction rate, which are indicators of the changes in the heat flux at the core mantle boundary, climate and plate tectonic activity, shows that all these changes indicate similar rhythms on million years' timescale in the Cenozoic Era occurring with the common fundamental periodicity of ~13 Myr during most of the time. The levels of carbonate ions in the ocean fell over the course of the Cenozoic.\nLife.\nEarly in the Cenozoic, following the K-Pg event, the planet was dominated by relatively small fauna, including small mammals, birds, reptiles, and amphibians. From a geological perspective, it did not take long for mammals to greatly diversify in the absence of the dinosaurs that had dominated during the Mesozoic. Birds also diversified rapidly; some flightless birds grew larger than humans. These species are sometimes referred to as \"terror birds\", and were formidable predators. Mammals came to occupy almost every available niche (both marine and terrestrial), and some also grew very large, attaining sizes not seen in most of today's terrestrial mammals. The ranges of many Cenozoic bird clades were governed by latitude and temperature and have contracted over the course of this era as the world cooled.\nDuring the Cenozoic, mammals proliferated from a few small, simple, generalised forms into a diverse collection of terrestrial, marine, and flying animals, giving this period its other name, the Age of Mammals. The Cenozoic is just as much the age of savannas, the age of co-dependent flowering plants and insects, and the age of birds. Grasses also played a very important role in this era, shaping the evolution of the birds and mammals that fed on them. One group that diversified significantly in the Cenozoic as well were the snakes. Evolving in the Cenozoic, the variety of snakes increased tremendously, resulting in many colubrids, following the evolution of their current primary prey source, the rodents.\nIn the earlier part of the Cenozoic, the world was dominated by the gastornithid birds, terrestrial crocodylians like \"Pristichampsus\", large sharks such as Otodus, and a handful of primitive large mammal groups like uintatheres, mesonychians, and pantodonts. But as the forests began to recede and the climate began to cool, other mammals took over.\nThe Cenozoic is full of mammals both strange and familiar, including chalicotheres, creodonts, whales, primates, entelodonts, sabre-toothed cats, mastodons and mammoths, three-toed horses, giant rhinoceros like \"Paraceratherium\", the rhinoceros-like brontotheres, various bizarre groups of mammals from South America, such as the vaguely elephant-like pyrotheres and the dog-like marsupial relatives called borhyaenids and the monotremes and marsupials of Australia. Mammal evolution in the Cenozoic was predominantly shaped by climatic and geological processes.\nCenozoic calcareous nannoplankton experienced rapid rates of speciation and reduced species longevity, while suffering prolonged declines in diversity during the Eocene and Neogene. Diatoms, in contrast, experienced major diversification over the Eocene, especially at high latitudes, as the world's oceans cooled. Diatom diversification was particularly concentrated at the Eocene-Oligocene boundary. A second major pulse of diatom diversification occurred over the course of the Middle and Late Miocene.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "5820", "revid": "37005538", "url": "https://en.wikipedia.org/wiki?curid=5820", "title": "Confucianism", "text": "Chinese ethical and philosophical system\nConfucianism, also known as Ruism or Ru classicism, is a system of thought and behavior originating in ancient China, and is variously described as a tradition, philosophy, religion, theory of government, or way of life. Founded by Confucius in the Hundred Schools of Thought era (c. 500 BCE), Confucianism integrates philosophy, ethics, and social governance, with a core focus on virtue, social harmony, and familial responsibility.\nConfucianism emphasizes virtue through self-cultivation and communal effort. Key virtues include \"ren\" (, \"benevolence\"), \"yi\" (; \"righteousness\"), \"li\" (; \"propriety\"), \"zhi\" (; \"wisdom\"), and \"xin\" (; \"sincerity\"). These values, deeply tied to the notion of \"tian\" (; \"Heaven\"), present a worldview where human relationships and social order are manifestations of sacred moral principles. While Confucianism does not emphasize an omnipotent deity, it upholds \"tian\" as a transcendent moral order.\nConfucius regarded himself as a transmitter of cultural values from the preceding Xia, Shang, and Western Zhou dynasties. Suppressed during the Legalist Qin dynasty (c. 200 BCE), Confucianism flourished under the Han dynasty (c. 130 BCE), displacing the proto-Taoist Huang\u2013Lao tradition to become the dominant ideological framework, while blending with the pragmatic teachings of Legalism. The Tang dynasty (c. 600 CE) witnessed a response to the rising influence of Buddhism and Taoism in the development of Neo-Confucianism, a reformulated philosophical system that became central to the imperial examination system and the scholar-official class of the Song dynasty (c. 1000 CE).\nThe abolition of the imperial examination system in 1905 marked the decline of state-endorsed Confucianism. In the early 20th century, Chinese reformers came to associate Confucianism with China's \"Century of Humiliation\", and instead embraced alternative ideologies such as Sun Yat-sen's \"Three Principles of the People\" and later Maoism. Nevertheless, Confucianism endured as a cultural force, influencing East Asian economic and social structures into the modern era. Confucian work ethic was credited with the rise of the East Asian economy in the late twentieth century.\nConfucianism remains influential in China, Korea, Japan, Vietnam, and regions with significant Chinese diaspora. A modern Confucian revival has gained momentum in academic and cultural circles, culminating in the establishment of a national Confucian Church in China in 2015, reflecting renewed interest in Confucian ideals as a foundation for social and moral values.\nAmerican philosopher Herbert Fingarette describes Confucianism as a philosophical system which regards \"the secular as sacred\".\nTerminology.\nThere is no term in Chinese which directly corresponds to \"Confucianism\". The closest catch-all term for Confucianism is the word . Its literal meanings in modern Chinese include 'scholar', 'learned', or 'refined man'. In Old Chinese the word had a distinct set of meanings, including 'to tame', 'to mould', 'to educate', and 'to refine'. Several different terms, some of which with modern origin, are used in different situations to express different facets of Confucianism, including:\nThe terms that use do not use the name \"Confucius\" at all, but instead focus on the ideal of the Confucian man. The use of the term \"Confucianism\" has been avoided by some modern scholars, who favor \"Ruism\" and \"Ruists\" instead. Robert Eno argues that the term has been \"burdened... with the ambiguities and irrelevant traditional associations\". Ruism, as he states, is more faithful to the original Chinese name for the school.\nThe term \"Traditionalist\" has been suggested by David Schaberg to emphasize the connection to the past, its standards, and inherited forms, in which Confucius himself placed so much importance. This translation of the word is followed by e.g. Yuri Pines.\nAccording to Zhou Youguang, originally referred to shamanic methods of holding rites and existed before Confucius's times, but with Confucius it came to mean devotion to propagating such teachings to bring civilisation to the people.\nIn the Western world, the character for water is often used as a symbol for Confucianism, which is not the case in modern China.\nFive Classics and the Confucian vision.\nTraditionally, Confucius was thought to be the author or editor of the Five Classics which were the basic texts of Confucianism, all edited into their received versions around 500 years later by Imperial Librarian Liu Xin. The scholar Yao Xinzhong allows that there are good reasons to believe that Confucian classics took shape in the hands of Confucius, but that \"nothing can be taken for granted in the matter of the early versions of the classics\". The sixth classic similar to the Classic of Poetry was the Classic of Music. It was lost during the Han dynasty. Music carried an invaluable tool to induce focus in performing rituals. These were the internal (music) and external (rites) keys to harmonizing society. Yao suggests that most modern scholars hold the \"pragmatic\" view that Confucius and his followers did not intend to create a system of classics, but nonetheless \"contributed to their formation\".\nThe scholar Tu Weiming explains these classics as embodying \"five visions\" which underlie the development of Confucianism:\nDoctrines.\nTheory and theology.\nConfucianism revolves around the pursuit of the unity of the individual self and (\"heaven\"), or the relationship between humanity and heaven. The principle or way of Heaven ( or ) is the order of the world and the source of divine authority. or is monistic, meaning that it is singular and indivisible. Individuals may realise their humanity and become one with Heaven through the contemplation of such order. This transformation of the self is extended to family and society to create a harmonious community. Jo\u00ebl Thoraval studied Confucianism as a diffused civil religion in contemporary China, finding that it expresses itself in the widespread worship of five cosmological entities: Heaven and Earth (), the sovereign or the government (), ancestors (), and masters ().\nAccording to the scholar Stephan Feuchtwang, in Chinese cosmology, which is not merely Confucian but shared by many Chinese religions, \"the universe creates itself out of a primary chaos of material energy\" ( and ), and is organized through the polarity of yin and yang that characterises any thing and life. Creation is therefore a continuous ordering; it is not creation \"Yin and yang are the invisible and visible, the receptive and the active, the unshaped and the shaped; they characterise the yearly cycle (winter and summer), the landscape (shady and bright), the sexes (female and male), and even sociopolitical history (disorder and order). Confucianism is concerned with finding \"middle ways\" between yin and yang at every new configuration of the world.\"\nConfucianism conciliates both the inner and outer polarities of spiritual cultivation\u2014that is to say self-cultivation and world redemption\u2014in the ideal of \"sageliness within and kingliness without\". , translated as \"humaneness\" or the essence proper of a human being, is the character of compassionate mind; it is the virtue endowed by Heaven and at the same time the means by which a person may achieve oneness with Heaven by comprehending their origin in Heaven, and therefore divine essence. In his work \"The Book of Great Unity\" (), late Qing dynasty reformer Kang Youwei considered as the means \"to form one body with all things\" and one can find \"when the self and others are not separated... and when compassion is aroused\".\n\"Lord Heaven\" and \"Jade Emperor\" were terms for a Confucianist supreme deity who was an anthropomorphized , and some conceptions of it thought of the two names as synonymous.\n\"Tian\" and the gods.\n, a key concept in Chinese thought, refers to the God of Heaven, the northern culmen of the skies and its spinning stars, earthly nature and its laws which come from Heaven, to 'Heaven and Earth' (that is, \"all things\"), and to the awe-inspiring forces beyond human control. There are so many uses in Chinese thought that it is impossible to give a single English translation.\nConfucius used the term in a mystical way. He wrote in the \"Analects\" (7.23) that gave him life, and that watched and judged (6.28; 9.12). In 9.5 Confucius says that a person may know the movements of , and this provides with the sense of having a special place in the universe. In 17.19 Confucius says that spoke to him, though not in words. The scholar Ronnie Littlejohn warns that was not to be interpreted as a personal god comparable to that of the Abrahamic faiths, in the sense of an otherworldly or transcendent creator. Rather it is similar to what Taoists meant by : \"the way things are\" or \"the regularities of the world\", which Stephan Feuchtwang equates with the ancient Greek concept of \"physis\", \"nature\" as the generation and regenerations of things and of the moral order. may also be compared to the \"Brahman\" of Hindu and Vedic traditions. The scholar Promise Hsu, in the wake of Robert B. Louden, explained 17:19 (\"What does ever say? Yet there are four seasons going round and there are the hundred things coming into being. What does say?\") as implying that even though is not a \"speaking person\", it constantly \"does\" through the rhythms of nature, and communicates \"how human beings ought to live and act\", at least to those who have learnt to carefully listen to it.\nDuanmu Ci, a disciple of Confucius, said that had set the master on the path to become a wise man (9.6). In 7.23 Confucius says that he has no doubt left that gave him life, and from it he had developed right virtue (). In 8.19, he says that the lives of the sages are interwoven with .\nRegarding personal gods (, energies who emanate from and reproduce ) enliving nature, in the \"Analects\" Confucius says that it is appropriate () for people to worship () them, although only through proper rites (), implying respect of positions and discretion. Confucius himself was a ritual and sacrificial master.\nAnswering to a disciple who asked whether it is better to sacrifice to the god of the stove or to the god of the family (a popular saying), in 3.13 Confucius says that in order to appropriately pray to gods, one should first know and respect Heaven. In 3.12, he explains that religious rituals produce meaningful experiences, and one has to offer sacrifices in person, acting in presence, otherwise \"it is the same as not having sacrificed at all\". Rites and sacrifices to the gods have an ethical importance: they generate good life, because taking part in them leads to the overcoming of the self. Analects 10.11 tells that Confucius always took a small part of his food and placed it on the sacrificial bowls as an offering to his ancestors.\nSome Confucian movements worship Confucius, although not as a supreme being or anything else approaching the power of or the , and/or gods from Chinese folk religion. These movements are not a part of mainstream Confucianism, although the boundary between Chinese folk religion and Confucianism can be blurred.\nOther movements, such as Mohism which was later absorbed by Taoism, developed a more theistic idea of Heaven. Feuchtwang explains that the difference between Confucianism and Taoism primarily lies in the fact that the former focuses on the realisation of the starry order of Heaven in human society, while the latter on the contemplation of the Dao which spontaneously arises in nature. However, Confucianism does venerate many aspects of nature and also respects various , as well as what Confucius saw as the main , the \"[Way] of Heaven.\"\nThe Way of Heaven involves \"lifelong and sincere devotion to traditional cultural forms\" and , \"a state of spontaneous harmony between individual inclinations and the sacred Way\".\nKelly James Clark argued that Confucius himself saw as an anthropomorphic god that Clark hypothetically refers to as \"Heavenly Supreme Emperor\", although most other scholars on Confucianism disagree with this view.\nSocial morality and ethics.\nAs explained by Stephan Feuchtwang, the order coming from Heaven preserves the world, and has to be followed by humanity finding a \"middle way\" between yin and yang forces in each new configuration of reality. Social harmony or morality is identified as patriarchy, which is expressed in the worship of ancestors and deified progenitors in the male line, at ancestral shrines.\nConfucian ethical codes are described as humanistic. They may be practiced by all the members of a society. Confucian ethics is characterised by the promotion of virtues, encompassed by the Five Constants, elaborated by Confucian scholars out of the inherited tradition during the Han dynasty. The Five Constants are:\nThese are accompanied by the classical four virtues (), one of which (\"Yi\") is also included among the Five Constants:\nThere are many other traditionally Confucian values, such as , , , , a , , , , , and ).\nRen.\n\"Ren (\u4ec1 )\" is the highest Confucian virtue meaning the good quality of a virtuous human when reaching for higher ideals or when being altruistic. According to Confucius, \"Ren\" encompasses benevolence, trustworthiness, courage, compassion, empathy, and reciprocity. It is considered the essence of the human being endowed by Heaven, and the means by which someone may act according to the principle of Heaven and become one with it.\n\"Ren\" is expressed through interpersonal relationships and can be cultivated through the observance of proper \"Li\". \"Li\", or ritual, guides people's behaviors in nurturing and expressing \"Ren. Li\" regulates the fundamental human relationships between parents and kids, spouses, siblings, friends, and set the foundation to a harmonious society. Yan Hui, Confucius's most outstanding student, once asked his master to describe the criteria of R\"en\". Confucius replied, \"If contrary to ritual, do not look; if contrary to ritual, do not listen; if contrary to ritual, do not speak; if contrary to ritual, do not act.\" \n\"Ren\" is also a central principle in Confucian political theory: a ruler with the Mandate of Heaven is one of great virtue, who leads by moral example and prioritizes the well-being of the people.\nRite and centring.\n\"Li\" () is a word which finds its most extensive use in Confucian and post-Confucian Chinese philosophy. \"Li\" can be translated as 'rite' or ritual, when referring to its realization in the context of human social behavior it has also been translated as 'customs', 'measures' and 'rules', among other terms. \"Li\" also means religious rites which establish relations between humanity and the gods.\nAccording to Stephan Feuchtwang, rites are conceived as \"what makes the invisible visible\", making possible for humans to cultivate the underlying order of nature. Correctly performed rituals move society in alignment with earthly and heavenly (astral) forces, establishing the harmony of the three realms\u2014Heaven, Earth and humanity. This practice is defined as \"centering\" ( or ). Among all things of creation, humans themselves are \"central\" because they have the ability to cultivate and centre natural forces.\n\"Li\" embodies the entire web of interaction between humanity, human objects, and nature. Confucius includes in his discussions of \"li\" such diverse topics as learning, tea drinking, titles, mourning, and governance. Xunzi cites \"songs and laughter, weeping and lamentation... rice and millet, fish and meat... the wearing of ceremonial caps, embroidered robes, and patterned silks, or of fasting clothes and mourning clothes... spacious rooms and secluded halls, soft mats, couches and benches\" as vital parts of the fabric of \"li\".\nConfucius envisioned proper government being guided by the principles of \"li\". Some Confucians proposed that all human beings may pursue perfection by learning and practising \"li\". Overall, Confucians believe that governments should place more emphasis on \"li\" and rely much less on penal punishment when they govern.\nLoyalty.\nLoyalty () is particularly relevant for the social class to which most of Confucius's students belonged, because the most important way for an ambitious young scholar to become a prominent official was to enter a ruler's civil service.\nConfucius himself did not propose that \"might makes right\", but rather that a superior should be obeyed because of his moral rectitude. In addition, loyalty does not mean subservience to authority. This is because reciprocity is demanded from the superior as well. As Confucius stated \"a prince should employ his minister according to the rules of propriety; ministers should serve their prince with faithfulness (loyalty).\"\nSimilarly, Mencius also said that \"when the prince regards his ministers as his hands and feet, his ministers regard their prince as their belly and heart; when he regards them as his dogs and horses, they regard him as another man; when he regards them as the ground or as grass, they regard him as a robber and an enemy.\" Moreover, Mencius indicated that if the ruler is incompetent, he should be replaced. If the ruler is evil, then the people have the right to overthrow him. A good Confucian is also expected to remonstrate with his superiors when necessary. At the same time, a proper Confucian ruler should also accept his ministers' advice, as this will help him govern the realm better.\nIn later ages, however, emphasis was often placed more on the obligations of the ruled to the ruler, and less on the ruler's obligations to the ruled. Like filial piety, loyalty was often subverted by the autocratic regimes in China. Nonetheless, throughout the ages, many Confucians continued to fight against unrighteous superiors and rulers. Many of these Confucians suffered and sometimes died because of their conviction and action. During the Ming-Qing era, prominent Confucians such as Wang Yangming promoted individuality and independent thinking as a counterweight to subservience to authority. The famous thinker Huang Zongxi also strongly criticised the autocratic nature of the imperial system and wanted to keep imperial power in check.\nMany Confucians also realised that loyalty and filial piety have the potential of coming into conflict with one another. This may be true especially in times of social chaos, such as during the period of the Ming-Qing transition.\nFilial piety.\nIn Confucian philosophy, is a virtue of respect for one's parents and ancestors, and of the hierarchies within society: father\u2013son, elder\u2013junior and male\u2013female. The Confucian classic \"Xiaojing\" (\"Book of Piety\"), thought to be written during the Qin or Han dynasties, has historically been the authoritative source on the Confucian tenet of \"xiao\". The book, a conversation between Confucius and his disciple Zeng Shen, is about how to set up a good society using the principle of \"xiao\".\nIn more general terms, filial piety means to be good to one's parents; to take care of one's parents; to engage in good conduct not just towards parents but also outside the home so as to bring a good name to one's parents and ancestors; to perform the duties of one's job well so as to obtain the material means to support parents as well as carry out sacrifices to the ancestors; not be rebellious; show love, respect and support; the wife in filial piety must obey her husband absolutely and take care of the whole family wholeheartedly. display courtesy; ensure male heirs, uphold fraternity among brothers; wisely advise one's parents, including dissuading them from moral unrighteousness, for blindly following the parents' wishes is not considered to be \"xiao\"; display sorrow for their sickness and death; and carry out sacrifices after their death.\nFilial piety is considered a key virtue in Chinese culture, and it is the main concern of a large number of stories. One of the most famous collections of such stories is \"The Twenty-four Filial Exemplars\". These stories depict how children exercised their filial piety in the past. While China has always had a diversity of religious beliefs, filial piety has been common to almost all of them; historian Hugh D.R. Baker calls respect for the family the only element common to almost all Chinese believers.\nRelationships.\nSocial harmony results in part from every individual knowing his or her place in the natural order, and playing his or her part well. Reciprocity or responsibility (\"renqing\") extends beyond filial piety and involves the entire network of social relations, even the respect for rulers. This is shown in the story where Duke Jing of Qi asks Confucius about government, by which he meant proper administration so as to bring social harmony:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\u2014\u200a\nParticular duties arise from one's particular situation in relation to others. The individual stands simultaneously in several different relationships with different people: as a junior in relation to parents and elders, and as a senior in relation to younger siblings, students, and others. While juniors are considered in Confucianism to owe their seniors reverence, seniors also have duties of benevolence and concern toward juniors. The same is true with the husband and wife relationship where the husband needs to show benevolence towards his wife and the wife needs to respect the husband in return. This theme of mutuality still exists in East Asian cultures even to this day.\nThe Five Bonds are: ruler to ruled, father to son, husband to wife, elder brother to younger brother, friend to friend. Specific duties were prescribed to each of the participants in these sets of relationships. Such duties are also extended to the dead, where the living stand as sons to their deceased family. The only relationship where respect for elders is not stressed was the friend to friend relationship, where mutual equal respect is emphasised instead. All these duties take the practical form of prescribed rituals, for instance wedding and death rituals.\n\"Junzi\".\nThe \"junzi\" is a Chinese philosophical term often translated as \"gentleman\" or \"superior person.\" \"Junzi\", which literally means \"son of a lord\", was redefined by Confucius in the \"Analects\" to describe a person of noble character and ethical virtue.\nIn Confucianism, the sage or wise is the ideal personality; however, it is very hard to become one of them. Confucius created the model of \"junzi\", which may be achieved by any individual through the discipline of one's minds and actions. Song dynasty Confucian philosopher Zhu Xi defined \"junzi\" as second only to the sage. There are many characteristics of the \"junzi\": he may live in poverty, he does more and speaks less, he is loyal, obedient and knowledgeable. The \"junzi\" disciplines himself. \"Ren\" is fundamental to become a \"junzi\".\nAs the potential leader of a nation, a son of the ruler is raised to have a superior ethical and moral position while gaining inner peace through his virtue. The \"junzi\" enforces his rule over his subjects by acting virtuously himself. It is thought that his pure virtue would lead others to follow his example. The ultimate goal is that the government behaves much like a family, the \"junzi\" being a beacon of filial piety. To Confucius, the \"junzi\" sustained the functions of government and social stratification through his ethical values. Despite its literal meaning, any righteous man willing to improve himself may become a \"junzi\".\nIn contrast to the \"junzi\", the \"xiaoren\" ( ), small-minded or morally inferior people, do not grasp the value of virtues and seeks only immediate gains. The petty person is egotistic and does not consider the consequences of his action in the overall scheme of things. Should the ruler be surrounded by \"xiaoren\" as opposed to \"junzi\", his governance and his people will suffer due to their small-mindness. Examples of such \"xiaoren\" individuals may range from those who continually indulge in sensual and emotional pleasures all day to the politician who is interested merely in power and fame; neither sincerely aims for the long-term benefit of others.\nRectification of names.\nConfucius believed that social disorder often stemmed from failure to perceive, understand, and deal with reality. Fundamentally, then, social disorder may stem from the failure to call things by their proper names, and his solution to this was the . He gave an explanation of this concept to one of his disciples:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Zi-lu said, \"The vassal of Wei has been waiting for you, in order with you to administer the government. What will you consider the first thing to be done?\"\nThe Master replied, \"What is necessary to rectify names.\"\n\"So! indeed!\" said Zi-lu. \"You are wide off the mark! Why must there be such rectification?\"\nThe Master said, \"How uncultivated you are, Yu! The superior man [Junzi] cannot care about the everything, just as he cannot go to check all himself!\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0If names be not correct, language is not in accordance with the truth of things.\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0If language be not in accordance with the truth of things, affairs cannot be carried on to success.\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0When affairs cannot be carried on to success, proprieties and music do not flourish.\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0When proprieties and music do not flourish, punishments will not be properly awarded.\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0When punishments are not properly awarded, the people do not know how to move hand or foot.\nTherefore a superior man considers it necessary that the names he uses may be spoken appropriately, and also that what he speaks may be carried out appropriately. What the superior man requires is just that in his words there may be nothing incorrect.\"\n\"Xunzi\" chapter (22) \"On the Rectification of Names\" claims the ancient sage-kings chose names () that directly corresponded with actualities (), but later generations confused terminology, coined new nomenclature, and thus could no longer distinguish right from wrong. Since social harmony is of utmost importance, without the proper rectification of names, society would essentially crumble and \"undertakings [would] not [be] completed.\"\nHistory.\nMetaphysical antecedents.\nAccording to He Guanghu, Confucianism may be identified as a continuation of the Shang-Zhou (c.\u20091600\u2013256 BC) official religion, or the Chinese aboriginal religion which has lasted uninterrupted for three thousand years. Both the dynasties worshipped a supreme \"godhead\", called \"Shangdi\" ('Highest Deity') or \"Di\" by the Shang and \"Tian\" ('Heaven') by the Zhou. \"Shangdi\" was conceived as the first ancestor of the Shang royal house, an alternate name for him being the \"Supreme Progenitor\" (). Shang theology viewed the multiplicity of gods of nature and ancestors as parts of \"Di\". \"Di\" manifests as the \"Wufang Shangdi\" with the winds () as its cosmic will. With the Zhou dynasty, which overthrew the Shang, the name for the supreme godhead became \"tian\". While the Shang identified \"Shangdi\" as their ancestor-god to assert their claim to power by divine right, the Zhou transformed this claim into a legitimacy based on moral power, the Mandate of Heaven. In Zhou theology, \"Tian\" had no singular earthly progeny, but bestowed divine favour on virtuous rulers. Zhou kings declared that their victory over the Shang was because they were virtuous and loved their people, while the Shang were tyrants and thus were deprived of power by \"Tian\".\nJohn C. Didier and David Pankenier relate the shapes of both the ancient Chinese characters for \"Di\" and \"Tian\" to the patterns of stars in the northern skies, either drawn, in Didier's theory by connecting the constellations bracketing the north celestial pole as a square, or in Pankenier's theory by connecting some of the stars which form the constellations of the Big Dipper and broader Ursa Major, and Ursa Minor (Little Dipper). Cultures in other parts of the world have also conceived these stars or constellations as symbols of the origin of things, the supreme godhead, divinity and royal power. The supreme godhead was also identified with the dragon, symbol of unlimited power (\"qi\"), of the protean primordial power which embodies both yin and yang in unity, associated to the constellation Draco which winds around the north ecliptic pole, and slithers between the Little and Big Dipper.\nZhou traditions wane.\nBy the 6th century BC, the power of \"Tian\" and the symbols that represented it on earth (architecture of cities, temples, altars and ritual vessels, and the Zhou system of rites) became \"diffuse\" and claimed by different potentates in the Zhou states to legitimise economic, political, and military ambitions. Communication with the divine no longer was an exclusive privilege of the Zhou royal house, but might be bought by anyone able to afford the elaborate ceremonies and the old and new rites required to access the authority of \"Tian\".\nBesides the waning Zhou ritual system, what may be defined as traditions, or traditions outside of the official system, developed as attempts to access the will of \"Tian\". As central political authority crumbled in the wake of the collapse of the Western Zhou, the population lost faith in the official tradition, which was no longer perceived as an effective way to communicate with Heaven. The traditions of the and of the \"Yijing\" flourished. Chinese thinkers, faced with this challenge to legitimacy, diverged in a \"Hundred Schools of Thought\", each positing its own philosophical lens for understanding the processes of the world.\nConfucius (551\u2013479 BC) appeared in this period of political reconfiguration and spiritual questioning. He was educated in Shang\u2013Zhou traditions, which he contributed to transmit and reformulate giving centrality to self-cultivation and agency of humans, and the educational power of the self-established individual in assisting others to establish themselves (the ). As the Zhou reign collapsed, traditional values were abandoned resulting in a period of perceived moral decline. Confucius saw an opportunity to reinforce values of compassion and tradition into society, with the intended goal of reconstructing what he believed to be a lost perfect moral order of high antiquity. Disillusioned with the culture, opposing scholars, and religious authorities of the time, he began to advance an ethical interpretation of traditional Zhou religion. In his view, the power of \"Tian\" is pervasive, and responds positively to the sincere heart driven by humaneness and rightness, decency and altruism. Confucius conceived these qualities as the foundation needed to restore socio-political harmony. Like many contemporaries, Confucius saw ritual practices as efficacious ways to access \"Tian\", but he thought that the crucial knot was the reverent inner state that participants enter prior to engaging in the ritual acts. Confucius is said to have amended and recodified the classical books inherited from the Xia-Shang-Zhou dynasties, and to have composed the \"Spring and Autumn Annals\".\nConfucianism rises.\nPhilosophers in the Warring States period, both focused on state-endorsed ritual and non-aligned to state ritual built upon Confucius's legacy, compiled in the \"Analects\", and formulated the classical metaphysics that became the lash of Confucianism. In accordance with Confucius, they identified mental tranquility as the state of \"Tian\", or , which in each individual is the Heaven-bestowed divine power to rule one's own life and the world. They also extended the theory, proposing the oneness of production and reabsorption into the cosmic source, and the possibility to understand and therefore reattain it through correct state of mind. This line of thought would have influenced all Chinese individual and collective-political mystical theories and practices thereafter.\nIn the Han dynasty, Confucians beginning with Dong Zhongshu synthesised Warring States Confucianism with ideas of yin and yang, and \"wuxing\", as well as folk superstition and the prior schools that led up to the School of Naturalists.\nIn the 460s, Confucianism competed with Chinese Buddhism and \"traditional Confucianism\" was \"a broad cosmology that was as much about personal ethics as about spiritual beliefs\" and had roots that went back to Confucianist philosophers from over a thousand years before.\nDecline.\nThe Confucian examination system was abolished in Korea in 1894, in China in 1905, and in Vietnam in 1919. This meant that conformity to Confucian ideology was no longer a prerequisite for a career in the civil service or politics, allowing persons of other ideologies (notably Nationalism and Socialism) to attain leading positions in society.\nOrganisation and liturgy.\nSince the 2000s, there has been a growing identification of the Chinese intellectual class with Confucianism. In 2003, the Confucian intellectual Kang Xiaoguang published a manifesto in which he made four suggestions: Confucian education should enter official education at any level, from elementary to high school; the state should establish Confucianism as the state religion by law; Confucian religion should enter the daily life of ordinary people through standardisation and development of doctrines, rituals, organisations, churches and activity sites; the Confucian religion should be spread through non-governmental organisations. Another modern proponent of the institutionalisation of Confucianism in a state church is Jiang Qing.\nIn 2005, the Center for the Study of Confucian Religion was established, and \"guoxue\" started to be implemented in public schools on all levels. Being well received by the population, even Confucian preachers have appeared on television since 2006. The most enthusiastic New Confucians proclaim the uniqueness and superiority of Confucian Chinese culture, and have generated some popular sentiment against Western cultural influences in China.\nThe idea of a \"Confucian church\" as the state religion of China has roots in the thought of Kang Youwei, an exponent of the early New Confucian search for a regeneration of the social relevance of Confucianism, at a time when it was de-institutionalised with the collapse of the Qing dynasty and the Chinese empire. Kang modeled his ideal \"Confucian Church\" after European national Christian churches, as a hierarchic and centralised institution, closely bound to the state, with local church branches, devoted to the worship and the spread of the teachings of Confucius.\nIn contemporary China, the Confucian revival has developed into various interwoven directions: the proliferation of Confucian schools or academies, the resurgence of Confucian rites, and the birth of new forms of Confucian activity on the popular level, such as the Confucian communities (). Some scholars also consider the reconstruction of lineage churches and their ancestral temples, as well as cults and temples of natural and national gods within broader Chinese traditional religion, as part of the renewal of Confucianism.\nOther forms of revival are salvationist folk religious movements groups with a specifically Confucian focus, or Confucian churches, for example the of Beijing, the of Shanghai, Confucian Shenism (also known as the \"phoenix churches\"), the Confucian Fellowship () in northern Fujian which has spread rapidly over the years after its foundation, and ancestral temples of the Kong kin (the lineage of the descendants of Confucius himself) operating as Confucian-teaching churches.\nAlso, the Hong Kong Confucian Academy, one of the direct heirs of Kang Youwei's Confucian Church, has expanded its activities to the mainland, with the construction of statues of Confucius, Confucian hospitals, restoration of temples and other activities. In 2009, Zhou Beichen founded another institution which inherits the idea of Kang Youwei's Confucian Church, the Holy Hall of Confucius () in Shenzhen, affiliated with the Federation of Confucian Culture of Qufu City. It was the first of a nationwide movement of congregations and civil organisations that was unified in 2015 in the Holy Confucian Church. The first spiritual leader of the church is the scholar Jiang Qing, the founder and manager of the Yangming Confucian Abode (), a Confucian academy in Guiyang, Guizhou.\nChinese folk religious temples and kinship ancestral shrines may, on peculiar occasions, choose Confucian liturgy (called or led by Confucian ritual masters () to worship the gods, instead of Taoist or popular ritual. \"Confucian businessmen\" (, also \"refined businessman\") is a recently \"rediscovered\" concept defining people of the economic-entrepreneurial elite who recognise their social responsibility and therefore apply Confucian culture to their business.\nConfucianists historically tried to proselytize to others, although this is rarely done in modern times. Given Confucianism's place of importance in historical Chinese governments, the argument has been made that Imperial China's wars were Confucianism's wars, but the connection between Confucianism and war is not so direct or simple. Modern Confucianism is the descendant of movements that greatly changed how they practiced the teachings of Confucius and his disciples from previous orthodox teachings.\nGovernance.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\u2014\u200a\nA key Confucian concept is that in order to govern others one must first cultivate inner virtue to be a moral elite. When actual, the king's personal virtue (\"de\") spreads beneficent influence throughout the kingdom. The authority of the ruler and the submission of its people are grounded on a spiritual-ethical foundation, rather than on coercive power. Confucius' ideal of good government, is one led by a superior man (\"junzi\"), takes effective use of \"culture and tradition\", and relies less on law and punishment.\nWhen Confucius praised the sage-king Shun for his \"non-action\", the undertone is different from the Taoist \"wu wei\" that emphasizes a spontaneous reaction to allow the natural course of things. The Confucian non-action is conditioned by a solid moral base and compassion for the welfare of the people. The virtuous ruler's non-action is further supported by the officials he appoints\u2014individuals of upright character and benevolence toward the common people.\nMencius provided more concrete and specific measures in the making of a \"good ruler\". He advised that a good ruler must prioritize the people's welfare by ensuring adequate food and shelter, implementing light taxation, and avoiding unnecessary warfare, as moral instructions can only follow after people's basic needs are satisfied. He argued that rulers should govern by moral example\u2014exhibiting sincerity, benevolence, and righteousness\u2014so that subjects emulate virtuous conduct. \nThe emperors of China were considered agents of Heaven, endowed with the Mandate of Heaven, one of the most vital concepts in imperial-era political theory. According to the Confucian classics, the Mandate is not fated or absolute, it reacts to the wishes and interests of the people. While virtuous rulers keep the Mandate, wicked ruler would be abandoned by the Mandate.\nConfucianism, despite supporting the importance of obeying national authority, places this obedience under absolute moral principles that curbed the willful exercise of power, rather than being unconditional. Submission to authority was only taken within the context of the moral obligations that rulers had toward their subjects, in particular \"ren\". Confucians\u2014including the most pro-authoritarian scholars such as Xunzi\u2014have always recognised the right of revolution against tyranny.\nMeritocracy.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\u2014\u200a\nAlthough Confucius claimed that he never invented anything but was only transmitting ancient knowledge (), he did produce a number of new ideas. Many European and American admirers such as Voltaire and Herrlee G. Creel point to the revolutionary idea of replacing nobility of blood with nobility of virtue. \"Junzi\" ('lord's son'), which originally signified the younger, non-inheriting, offspring of a noble, became, in Confucius's work, an epithet having much the same meaning and evolution as the English \"gentleman\".\nA virtuous commoner who cultivates his qualities may be a \"gentleman\", while a shameless son of the king is only a \"petty person\". That Confucius admitted students of different classes as disciples is a clear demonstration that he fought against the feudal structures that defined pre-imperial Chinese society.\nAnother new idea, that of meritocracy, led to the introduction of the imperial examination system in China. This system allowed anyone who passed an examination to become a government officer, a position which would bring wealth and honour to the whole family. The Chinese imperial examination system started in the Sui dynasty. Over the following centuries the system grew until finally almost anyone who wished to become an official had to prove his worth by passing a set of written government examinations.\nConfucian political meritocracy is not merely a historical phenomenon. The practice of meritocracy still exists across China and East Asia today, and a wide range of contemporary intellectuals\u2014from Daniel Bell to Tongdong Bai, Joseph Chan, and Jiang Qing\u2014defend political meritocracy as a viable alternative to liberal democracy.\nIn \"Just Hierarchy\", Daniel Bell and Wang Pei argue that hierarchies are inevitable. Faced with ever-increasing complexity at scale, modern societies must build hierarchies to coordinate collective action and tackle long-term problems such as climate change. In this context, people need not\u2014and should not\u2014want to flatten hierarchies as much as possible. They ought to ask what makes political hierarchies just and use these criteria to decide the institutions that deserve preservation, those that require reform, and those that need radical transformation. They call this approach \"progressive conservatism\", a term that reflects the ambiguous place of the Confucian tradition within the Left-Right dichotomy.\nBell and Wang propose two justifications for political hierarchies that do not depend on a \"one person, one vote\" system. First is raw efficiency, which may require centralized rule in the hands of the competent few. Second, and most important, is serving the interests of the people (and the common good more broadly). In \"Against Political Equality\", Tongdong Bai complements this account by using a proto-Rawlsian \"political difference principle\". Just as Rawls claims that economic inequality is justified so long as it benefits those at the bottom of the socioeconomic ladder, so Bai argues that political inequality is justified so long as it benefits those materially worse off.\nBell, Wang, and Bai all criticize liberal democracy to argue that government by the people may not be government for the people in any meaningful sense of the term. They argue that voters tend to act in irrational, tribal, short-termist ways; they are vulnerable to populism and struggle to account for the interests of future generations. In other words, at a minimum, democracy needs Confucian meritocratic checks.\nIn \"The China Model\", Bell argues that Confucian political meritocracy provides\u2014and has provided\u2014a blueprint for China's development. For Bell, the ideal according to which China should reform itself (and has reformed itself) follows a simple structure: Aspiring rulers first pass hyper-selective examinations, then have to rule well at the local level to be promoted to positions as the provincial level, then have to excel at the provincial level to access positions at the national level, and so on. This system aligns with what Harvard historian James Hankins calls \"virtue politics\", or the idea that institutions should be built to select the most competent and virtuous rulers\u2014as opposed to institutions concerned first and foremost with limiting the power of rulers.\nWhile contemporary defenders of Confucian political meritocracy all accept this broad frame, they disagree with each other on three main questions: institutional design, the means by which meritocrats are promoted, and the compatibility of Confucian political meritocracy with liberalism.\nInstitutional design.\nBell and Wang favour a system in which officials at the local level are democratically elected and higher-level officials are promoted by peers. As Bell puts it, he defends \"democracy at the bottom, experimentation in the middle, and meritocracy at the top.\" Bell and Wang argue that this combination conserves the main advantages of democracy\u2014involving the people in public affairs at the local level, strengthening the legitimacy of the system, forcing some degree of direct accountability, etc.\u2014while preserving the broader meritocratic character of the regime.\nJiang Qing, by contrast, imagines a tricameral government with one chamber selected by the people (the ), one chamber composed of Confucian meritocrats selected via examination and gradual promotion (the ), and one body made up of descendants of Confucius himself (the ). Jiang's aim is to construct a legitimacy that will go beyond what he sees as the atomistic, individualist, and utilitarian ethos of modern democracies and ground authority in something sacred and traditional. While Jiang's model is closer to an ideal theory than Bell's proposals, it represents a more traditionalist alternative.\nTongdong Bai presents an in-between solution by proposing a two-tiered bicameral system. At the local level, as with Bell, Bai advocates Deweyan participatory democracy. At the national level, Bai proposes two chambers: one of meritocrats (selected by examination, by examination and promotion, from leaders in certain professional fields, etc.), and one of representatives elected by the people. While the lower house does not have any legislative power per se, it acts as a popular accountability mechanism by championing the people and putting pressure on the upper house. More generally, Bai argues that his model marries the best of meritocracy and democracy. Following Dewey's account of democracy as a way of life, he points to the participatory features of his local model: citizens still get to have a democratic lifestyle, participate in political affairs, and be educated as \"democratic men\". Similarly, the lower house allows citizens to be represented, have a voice in public affairs (albeit a weak one), and ensure accountability. Meanwhile, the meritocratic house preserves competence, statesmanship, and Confucian virtues.\nPromotion system.\nDefenders of Confucian political meritocracy generally champion a system in which rulers are selected on the basis of intellect, social skills, and virtue. Bell proposes a model wherein aspiring meritocrats take hyper-selective exams and prove themselves at the local levels of government before reaching the higher levels of government, where they hold more centralized power. In his account, the exams select for intellect and other virtues\u2014for instance, the ability to argue three different viewpoints on a contentious issue may indicate a certain degree of openness. Tongdong Bai's approach incorporates different ways to select members of the meritocratic house, from exams to performance in various fields\u2014business, science, administration, and so on. In every case, Confucian meritocrats draw on China's extensive history of meritocratic administration to outline the pros and cons of competing methods of selection.\nFor those who, like Bell, defend a model in which performance at the local levels of government determines future promotion, an important question is how the system judges who \"performs best\". In other words, while examinations may ensure that early-career officials are competent and educated, how is it thereafter ensured that \"only\" those who rule well get promoted? The literature opposes those who prefer evaluation by peers to evaluation by superiors, with some thinkers including quasi-democratic selection mechanisms along the way. Bell and Wang favour a system in which officials at the local level are democratically elected and higher-level officials are promoted by peers. Because they believe that promotion should depend upon peer evaluations only, Bell and Wang argue against transparency\u2014i.e. the public should not know how officials are selected, since ordinary people are in no position to judge officials beyond the local level. Others, like Jiang Qing, defend a model in which superiors decide who gets promoted; this method is in line with more traditionalist strands of Confucian political thought, which place a greater emphasis on strict hierarchies and epistemic paternalism\u2014that is, the idea that older and more experienced people know more.\nCompatibility with liberalism and democracy, and critique of political meritocracy.\nAnother key question is whether Confucian political thought is compatible with liberalism. Tongdong Bai, for instance, argues that while Confucian political thought departs from the \"one person, one vote\" model, it can conserve many of the essential characteristics of liberalism, such as freedom of speech and individual rights. In fact, both Daniel Bell and Tongdong Bai hold that Confucian political meritocracy can tackle challenges that liberalism wants to tackle, but cannot by itself. At the cultural level, for instance, Confucianism, its institutions, and its rituals offer bulwarks against atomization and individualism. At the political level, the non-democratic side of political meritocracy is\u2014for Bell and Bai\u2014more efficient at addressing long-term questions such as climate change, in part because the meritocrats do not have to worry about the whims of public opinion.\nJoseph Chan defends the compatibility of Confucianism with both liberalism and democracy. In his book \"Confucian Perfectionism\", he argues that Confucians can embrace both democracy and liberalism on instrumental grounds; that is, while liberal democracy may not be valuable for its own sake, its institutions remain valuable\u2014particularly when combined with a broadly Confucian culture\u2014to serve Confucian ends and inculcate Confucian virtues.\nOther Confucians have criticized Confucian meritocrats like Bell for their rejection of democracy. For them, Confucianism does not have to be premised on the assumption that meritorious, virtuous political leadership is inherently incompatible with popular sovereignty, political equality and the right to political participation. These thinkers accuse the meritocrats of overestimating the flaws of democracy, mistaking temporary flaws for permanent and inherent features, and underestimating the challenges that the construction of a true political meritocracy poses in practice\u2014including those faced by contemporary China and Singapore. Franz Mang claims that, when decoupled from democracy, meritocracy tends to deteriorate into an oppressive regime under putatively \"meritorious\" but actually \"authoritarian\" rulers; Mang accuses Bell's China model of being self-defeating, as\u2014Mang claims\u2014the CCP's authoritarian modes of engagement with the dissenting voices illustrate. He Baogang and Mark Warren add that \"meritocracy\" should be understood as a concept describing a regime's character rather than its type, which is determined by distribution of political power\u2014on their view, democratic institutions can be built which are meritocratic insofar as they favour competence.\nRoy Tseng, drawing on the New Confucians of the twentieth century, argues that Confucianism and liberal democracy can enter into a dialectical process, in which liberal rights and voting rights are rethought into resolutely modern, but nonetheless Confucian ways of life. This synthesis, blending Confucians rituals and institutions with a broader liberal democratic frame, is distinct from both Western-style liberalism\u2014which, for Tseng, suffers from excessive individualism and a lack of moral vision\u2014and from traditional Confucianism\u2014which, for Tseng, has historically suffered from rigid hierarchies and sclerotic elites. Against defenders of political meritocracy, Tseng claims that the fusion of Confucian and democratic institutions can conserve the best of both worlds, producing a more communal democracy which draws on a rich ethical tradition, addresses abuses of power, and combines popular accountability with a clear attention to the cultivation of virtue in elites.\nInfluence.\nIn 17th-century Europe.\nThe works of Confucius were translated into European languages through the agency of Jesuit missionaries stationed in China. Matteo Ricci was among the very earliest to report on the thoughts of Confucius, and father Prospero Intorcetta wrote about the life and works of Confucius in Latin in 1687.\nTranslations of Confucian texts influenced European thinkers of the period, particularly among the Deists and other philosophical groups of the Enlightenment who were interested by the integration of the system of morality of Confucius into Western civilization.\nConfucianism influenced the German philosopher Gottfried Wilhelm Leibniz, who was attracted to the philosophy because of its perceived similarity to his own. It is postulated that certain elements of Leibniz's philosophy, such as \"simple substance\" and \"Pre-established harmony\", were borrowed from his interactions with Confucianism. \nThe French philosopher Voltaire, Leibniz's intellectual rival, was also influenced by Confucius, seeing the concept of Confucian rationalism as an alternative to Christian dogma. He praised Confucian ethics and politics, portraying the sociopolitical hierarchy of China as a model for Europe:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Confucius has no interest in falsehood; he did not pretend to be prophet; he claimed no inspiration; he taught no new religion; he used no delusions; flattered not the emperor under whom he lived...\u2014\u200a\nOn Islamic thought.\nFrom the late 17th century onwards a whole body of literature known as the Han Kitab developed amongst the Hui Muslims of China who infused Islamic thought with Confucianism. Especially the works of Liu Zhi such as \"Tianfang Dianli\" () sought to harmonise Islam with not only Confucianism but also with Taoism and is considered to be one of the crowning achievements of the Chinese Islamic culture.\nIn modern times.\nImportant military and political figures in modern Chinese history continued to be influenced by Confucianism, like the Muslim warlord Ma Fuxiang. The New Life Movement in the early 20th century was also influenced by Confucianism.\nReferred to variously as the Confucian hypothesis and as a debated component of the more all-encompassing Asian Development Model, there exists among political scientists and economists a theory that Confucianism plays a large latent role in the ostensibly non-Confucian cultures of modern-day East Asia, in the form of the rigorous work ethic it endowed those cultures with. These scholars have held that, if not for Confucianism's influence on these cultures, many of the people of the East Asia region would not have been able to modernise and industrialise as quickly as Singapore, Malaysia, Hong Kong, Taiwan, Japan, South Korea and even China have done.\nFor example, the impact of the Vietnam War on Vietnam was devastating, but over the last few decades Vietnam has been re-developing in a very fast pace. Most scholars attribute the origins of this idea to futurologist Herman Kahn's \"World Economic Development: 1979 and Beyond\".\nOther studies, for example Cristobal Kay's \"Why East Asia Overtook Latin America: Agrarian Reform, Industrialization, and Development\", have attributed the Asian growth to other factors, for example the character of agrarian reforms, \"state-craft\" (state capacity), and interaction between agriculture and industry.\nHistorical and current Confucianists were and are often environmentalists out of their respect for \"tian\" and the other aspects of nature and the \"Principle\" that comes from their unity and, more generally, harmony as a whole, which is \"the basis for a sincere mind\".\nOn Chinese martial arts.\nAfter Confucianism had become the official 'state religion' in China, its influence penetrated all walks of life and all streams of thought in Chinese society for the generations to come. This did not exclude martial arts culture. Though in his own day, Confucius had rejected the practice of Martial Arts (with the exception of Archery), he did serve under rulers who used military power extensively to achieve their goals. In later centuries, Confucianism heavily influenced many educated martial artists of great influence, such as Sun Lutang, especially from the 19th century onwards, when bare-handed martial arts in China became more widespread and had begun to more readily absorb philosophical influences from Confucianism, Buddhism and Daoism.\nCriticism.\nConfucius and Confucianism were opposed or criticised from the start, including Laozi's philosophy and Mozi's critique, and Legalists such as Han Fei ridiculed the idea that virtue would lead people to be orderly. In modern times, waves of opposition and vilification showed that Confucianism, instead of taking credit for the glories of Chinese civilisation, now had to take blame for its failures. The Taiping Rebellion described Confucianism sages as well as gods in Taoism and Buddhism as devils.\nContradiction with modernist values.\nIn the New Culture Movement, Lu Xun criticised Confucianism for shaping Chinese people into the condition they had reached by the late Qing dynasty: his criticisms are expressed metaphorically in the work \"Diary of a Madman\", in which traditional Chinese Confucian society is portrayed as feudalistic, hypocritical, socially cannibalistic, despotic, fostering a \"slave mentality\" favouring despotism, lack of critical thinking and blind obedience and worship of authority, fuelling a form of \"Confucian authoritarianism\" which persists into the present day. Leftists during the Cultural Revolution described Confucius as the representative of the slave-owning class.\nIn South Korea, there has long been criticism. Some South Koreans believe Confucianism has not contributed to the modernisation of South Korea. For example, South Korean writer Kim Kyong-il wrote a book in 1998 entitled \"Confucius Must Die For the Nation to Live\" (, ). Kim said that filial piety is one-sided and blind, and if it continues, social problems will continue as government keeps forcing Confucian filial obligations onto families.\nWomen in Confucian thought.\nConfucianism \"largely defined the mainstream discourse on gender in China from the Han dynasty onward.\" The gender roles prescribed in the Three Obediences and Four Virtues became a cornerstone of the family, and thus, societal stability. The Three Obediences and Four Virtues is one of the moral standards for feudal etiquette to bind women. Starting from the Han period, Confucians began to teach that a virtuous woman was supposed to follow the males in her family: the father before her marriage, the husband after she marries, and her sons in widowhood. In the later dynasties, more emphasis was placed on the virtue of chastity. The Song dynasty Confucian Cheng Yi stated that: \"To starve to death is a small matter, but to lose one's chastity is a great matter.\" It was during the Song dynasty that the value of chastity was so severe, Confucian scholars criminalized the remarriage of widows. Widows were revered and memorialised during the Ming and Qing periods. The principle of chaste widowhood was made an official institution during the Ming dynasty. This \"cult of chastity\" accordingly condemned many widows to poverty and loneliness by placing a social stigma on remarriage. Though the repercussions for widows at times went beyond poverty and loneliness, as for some the preservation of chastity resulted in suicide. The ideal of a chaste widow became an extremely high honor and esteem, especially for a woman who chose to end her life after her husband's death. Many instances of such acts were recorded in, Biographies of Virtuous Women, \"a collection of stories of women who distinguished themselves by committing suicide after their husband\u2019s deaths to guard their chastity and purity\". Though it can be contested whether all these instances can be deemed self-sacrificing for the virtue of chastity, as it became common practice for women to be forced to commit suicide after their husband's death. This resulted from the honor which chaste widowhood garnered, lending itself to the husband's family as well as his clan or village.\nFor years, many modern scholars have regarded Confucianism as a sexist, patriarchal ideology that was historically damaging to Chinese women. It has also been argued by some Chinese and Western writers that the rise of neo-Confucianism during the Song dynasty had led to a decline of status of women. Some critics have also accused the prominent Song neo-Confucian scholar Zhu Xi for believing in the inferiority of women and that men and women need to be kept strictly separate, while Sima Guang also believed that women should remain indoors and not deal with the matters of men in the outside world. Finally, scholars have discussed the attitudes toward women in Confucian texts such as Analects. In a much-discussed passage, women are grouped together with , meaning people of low status or low morals) and described as being difficult to cultivate or deal with. Many traditional commentators and modern scholars have debated over the precise meaning of the passage, and whether Confucius referred to all women or just certain groups of women.\nFurther analysis suggests, however, that women's place in Confucian society may be more complex. During the Han dynasty period, the influential Confucian text \"Lessons for Women\" was written by Ban Zhao (45\u2013114\u00a0CE) to instruct her daughters how to be proper Confucian wives and mothers, that is, to be silent, hard-working, and compliant. She stresses the complementarity and equal importance of the male and female roles according to yin-yang theory, but she clearly accepts the dominance of the male. However, she does present education and literary power as important for women. In later dynasties, a number of women took advantage of the Confucian acknowledgment of education to become independent in thought.\nJoseph A. Adler points out that \"Neo-Confucian writings do not necessarily reflect either the prevailing social practices or the scholars' own attitudes and practices in regard to actual women.\" Matthew Sommers has also indicated that the Qing dynasty government began to realise the utopian nature of enforcing the \"cult of chastity\" and began to allow practices such as widow remarrying to stand. Moreover, some Confucian texts like Dong Zhongshu's \"Luxuriant Dew of the Spring and Autumn Annals\" have passages that suggest a more equal relationship between a husband and his wife. More recently, some scholars have also begun to discuss the viability of constructing a \"Confucian feminism\".\nCatholic controversy over Chinese rites.\nEver since Europeans first encountered Confucianism, the issue of how Confucianism should be classified has been subject to debate. In the 16th and the 17th centuries, the earliest European arrivals in China, the Christian Jesuits, considered Confucianism to be an ethical system, not a religion, and one that was compatible with Christianity. The Jesuits, including Matteo Ricci, saw Chinese rituals as \"civil rituals\" that could co-exist alongside the spiritual rituals of Catholicism.\nBy the early 18th century, this initial portrayal was rejected by the Dominicans and Franciscans, creating a dispute among Catholics in East Asia that was known as the \"Rites Controversy\". The Dominicans and Franciscans argued that Chinese ancestral worship was a form of idolatry that was contradictory to the tenets of Christianity. This view was reinforced by Pope Benedict XIV, who ordered a ban on Chinese rituals, though this ban was re-assessed and repealed in 1939 by Pope Pius XII, provided that such traditions harmonize with the true and authentic spirit of the liturgy.\nSome critics view Confucianism as definitely pantheistic and nontheistic, in that it is not based on the belief in the supernatural or in a personal god existing separate from the temporal plane. Confucius' views about \"tian\" and about the divine providence ruling the world, can be found above (in this page) and in Analects 6:26, 7:22, and 9:12, for example. On spirituality, Confucius said to Chi Lu, one of his students: \"You are not yet able to serve men, how can you serve spirits?\" Attributes such as ancestor worship, ritual, and sacrifice were advocated by Confucius as necessary for social harmony; these attributes may be traced to the traditional Chinese folk religion.\nScholars recognise that classification ultimately depends on how one defines religion. Using stricter definitions of religion, Confucianism has been described as a moral science or philosophy. But using a broader definition, such as Frederick Streng's characterisation of religion as \"a means of ultimate transformation\", Confucianism could be described as a \"sociopolitical doctrine having religious qualities\". With the latter definition, Confucianism is religious, even if non-theistic, in the sense that it \"performs some of the basic psycho-social functions of full-fledged religions\".\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nBibliography.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nTranslations of the \"Analects\"\nExternal links.\nInstitutional"}
