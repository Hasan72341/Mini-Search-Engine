{"id": "849", "revid": "3000221", "url": "https://en.wikipedia.org/wiki?curid=849", "title": "Aircraft", "text": "Vehicle or machine that is able to fly by gaining support from the air\nAn aircraft is a vehicle that is able to fly by gaining support from the air. It counters the force of gravity by using either static lift or the dynamic lift of an airfoil, or, in a few cases, direct downward thrust from its engines. Common examples of aircraft include airplanes, drones, rotorcraft (including helicopters), airships (including blimps), gliders, paramotors, and hot air balloons. Part 1 (Definitions and Abbreviations) of Subchapter A of Chapter I of Title 14 of the U. S. Code of Federal Regulations states that aircraft \"means a device that is used or intended to be used for flight in the air.\"\nThe human activity that surrounds aircraft is called \"aviation\". The science of aviation, including designing and building aircraft, is called \"aeronautics.\" Crewed aircraft are flown by an onboard pilot, whereas unmanned aerial vehicles may be remotely controlled or self-controlled by onboard computers. Aircraft may be classified by different criteria, such as lift type, aircraft propulsion (if any), usage and others.\nHistory.\nThe history of aviation spans over two millennia, from the earliest innovations like kites and attempts at tower jumping to supersonic and hypersonic flight in powered, heavier-than-air jet aircraft. Kite flying in China, dating back several hundred years BC, is considered the earliest example of man-made flight. In the 15th century, Leonardo da Vinci created flying machine designs incorporating aeronautical concepts, but they were unworkable due to the limitations of contemporary knowledge.\nIn the late 18th century, the Montgolfier brothers invented the hot-air balloon which soon led to manned flights. At almost the same time, the discovery of hydrogen gas led to the invention of the hydrogen balloon. Various theories in mechanics by physicists during the same period, such as fluid dynamics and Newton's laws of motion, led to the development of modern aerodynamics; most notably by Sir George Cayley. Balloons, both free-flying and tethered, began to be used for military purposes from the end of the 18th century, with France establishing balloon companies during the French Revolution.\nIn the 19th century, especially the second half, experiments with gliders provided the basis for learning the dynamics of winged aircraft; most notably by Cayley, Otto Lilienthal, and Octave Chanute. By the early 20th century, advances in engine technology and aerodynamics made controlled, powered, manned heavier-than-air flight possible for the first time. In 1903, following their pioneering research and experiments with wing design and aircraft control, the Wright brothers successfully incorporated all of the required elements to create and fly the first airplane. In 1906 Charles Frederick Page was granted the first U.S. patent for an aircraft. The basic configuration with its characteristic cruciform tail was established by 1909, followed by rapid design and performance improvements aided by the development of more powerful engines.\nThe first vessels of the air were the rigid steerable balloons pioneered by Ferdinand von Zeppelin that became synonymous with airships and dominated long-distance flight until the 1930s, when large flying boats became popular for trans-oceanic routes. After World War II, the flying boats were in turn replaced by airplanes operating from land, made far more capable first by improved propeller engines, then by jet engines, which revolutionized both civilian air travel and military aviation.\nIn the latter half of the 20th century, the development of digital electronics led to major advances in flight instrumentation and \"fly-by-wire\" systems. The 21st century has seen the widespread use of pilotless drones for military, commercial, and recreational purposes. With computerized controls, inherently unstable aircraft designs, such as flying wings, have also become practical.\nMethods of lift.\nLighter-than-air.\nLighter-than-air aircraft or \"aerostats\" use buoyancy to float in the air in much the same way that ships float on the water. They are characterized by one or more large cells or canopies, filled with a lifting gas such as helium, hydrogen or hot air, which is less dense than the surrounding air. Other gases lighter than air also theoretically work, however, such gases also needs to be safe for human use (non-flammable, non-toxic).\nSmall hot-air balloons, called sky lanterns, were first invented in ancient China prior to the 3rd century BC and used primarily in cultural celebrations, although they also had military purposes. They, along with kites, were two forms of unmanned aircraft that originated from China. Kites were also used in the military, but unlike sky lanterns, their flight is caused by the differences of air pressure beneath and above the kite.\nA balloon was originally any aerostat, while the term airship was used for large, powered aircraft designs\u00a0\u2014 usually fixed-wing. In 1919, Frederick Handley Page was reported as referring to \"ships of the air,\" with smaller passenger types as \"Air yachts.\" In the 1930s, large intercontinental flying boats were also sometimes referred to as \"ships of the air\" or \"flying-ships\".\nLighter-than-air aircraft don't typically require a pilot's license in the United States. In most countries in Europe, standards for flying Lighter-than-air aircraft tend to be stricter compared to the United States.\nHeavier-than-air.\nHeavier-than-air aircraft or \"aerodynes\" are denser than air and thus must find some way to obtain enough lift that can overcome the aircraft's weight. There are two ways to produce dynamic upthrust \u2014 aerodynamic lift by having air flowing past an aerofoil (such dynamic interaction of aerofoils with air is the origin of the term \"aerodyne\"), or powered lift in the form of reactional lift from downward engine thrust.\nAerodynamic lift involving wings is the most common, and can be achieved via two methods. Fixed-wing aircraft (airplanes and gliders) achieve airflow past the wings by having the entire aircraft moving forward through the air, while rotorcraft (helicopters and autogyros) do so by having mobile, elongated wings spinning rapidly around a mast in an assembly known as the rotor.\nFixed-wing aircraft.\nGliders were one of the first forms of a fixed wing aircraft. They are a special type of aircraft that doesn't require an engine. The first person to successfully build a human-carrying glider was George Cayley, who also was the first to discover the four major aerodynamic forces. The first powered aircraft (Airplane) was invented by Wilbur and Orville Wright.\nRotorcraft.\nA \"rotary-wing aircraft\", \"rotorwing aircraft\" or \"rotorcraft\" is a heavier-than-air aircraft with rotary wings that spin around a vertical mast to generate lift. The assembly of several rotor blades mounted on a single mast is referred to as a rotor. The International Civil Aviation Organization (ICAO) defines a rotorcraft as \"supported in flight by the reactions of the air on one or more rotors\".\nRotorcraft generally include aircraft where one or more rotors provide lift throughout the entire flight, such as helicopters, gyroplanes, autogyros, and gyrodynes Compound rotorcraft augment the rotor with additional thrust engines, propellers, or static lifting surfaces. Some types, such as helicopters, are capable of vertical takeoff and landing. An aircraft which uses rotor lift for vertical flight but changes to solely fixed-wing lift in horizontal flight is not a rotorcraft but a convertiplane.\nSize and speed extremes.\nSize.\nThe largest aircraft by dimensions and volume (as of 2016) is the long British Airlander 10, a hybrid blimp, with helicopter and fixed-wing features, and reportedly capable of speeds up to , and an airborne endurance of two weeks with a payload of up to .\nThe largest aircraft by weight and largest regular fixed-wing aircraft ever built, as of 2016[ [update]], was the Antonov An-225 \"Mriya\". That Soviet-built (Ukrainian SSR) six-engine transport of the 1980s was long, with an wingspan. It holds the world payload record, after transporting of goods, and has flown loads commercially. With a maximum loaded weight of , it was also the heaviest aircraft built to date. It could cruise at . The aircraft was destroyed during the Russo-Ukrainian War.\nThe largest military airplanes are the Ukrainian Antonov An-124 \"Ruslan\" (world's second-largest airplane, also used as a civilian transport), and American Lockheed C-5 Galaxy transport, weighing, loaded, over . The 8-engine, piston/propeller Hughes H-4 \"Hercules\" \"Spruce Goose\"\u00a0\u2014 an American World War II wooden flying boat transport with a greater wingspan (94m/260\u00a0ft) than any current aircraft and a tail height equal to the tallest (Airbus A380-800 at 24.1m/78\u00a0ft)\u00a0\u2014 flew only one short hop in the late 1940s and never flew out of ground effect.\nThe largest civilian airplanes, apart from the above-noted An-225 and An-124, are the Airbus Beluga cargo transport derivative of the Airbus A300 jet airliner, the Boeing Dreamlifter cargo transport derivative of the Boeing 747 jet airliner/transport (the 747-200B was, at its creation in the 1960s, the heaviest aircraft ever built, with a maximum weight of over ), and the double-decker Airbus A380 \"super-jumbo\" jet airliner (the world's largest passenger airliner).\nSpeeds.\nThe fastest fixed-wing aircraft and fastest glider, is the Space Shuttle, which re-entered the atmosphere at nearly Mach 25 or \nThe fastest recorded powered aircraft flight and fastest recorded aircraft flight of an air-breathing powered aircraft was of the NASA X-43A \"Pegasus\", a scramjet-powered, hypersonic, lifting body experimental research aircraft, at Mach 9.68 or on 16 November 2004.\nPrior to the X-43A, the fastest recorded powered airplane flight, and still the record for the fastest manned powered airplane, was the North American X-15, rocket-powered airplane at Mach 6.7 or 7,274\u00a0km/h (4,520\u00a0mph) on 3 October 1967.\nThe fastest manned, air-breathing powered airplane is the Lockheed SR-71 Blackbird, a U.S. reconnaissance jet fixed-wing aircraft, having reached on 28 July 1976.\nPropulsion and steering.\nUnpowered aircraft.\nThe main feature of unpowered aircraft is the inability to directly provide thrust through its engines. This means that all unpowered aircraft rely on the environment for sustained flight. Gliders, for example, take advantage of their aerodynamic properties to enable them to travel long distances. Techniques such as thermal circling, where gliders fly into warm air which allows them to rise, prolongs flight time.\nDue to the lack of an engine, initial propulsion assistance is usually necessary to ensure flight. A common glider launching method is aerotowing, where another aircraft tows the glider to an altitude from which sustained flight is possible. Steering for a glider is also rudimentary, while more complex gliders like sailplanes usually have joysticks for steering, more basic aircraft like hang gliders rely on the pilot's physical coordination to change the centre of gravity.\nPowered aircraft.\nA powered aircraft is an aircraft with a source of mechanical power, used to produce thrust. Such sources are generally engines, as is the case with airplanes, but can be human-powered in more extreme cases.\nPropeller aircraft.\nPropeller aircraft, as their name suggests, rely on propellers to produce thrust for the airplane.\nJet aircraft.\nCompared to engines using propellers, jet engines can provide much higher thrust, higher speeds and, above about , greater efficiency.\nRotorcraft.\nAlthough some rotorcraft, such as rotor kites, can be unpowered, most rotorcraft are powered by either piston engines or turboprops. Some rotorcraft, including autogyros and gyrodynes, are propelled by a conventional propeller or jet engine, with the rotor unpowered, but most modern rotorcraft have a powered rotor, allowing them to hover in place. Autogyros and gyrodynes are steered using a rudder, similarly to propeller and jet aircraft, and rotorcraft with powered rotors, such as helicopters, turn by adjusting the pitch of the rotor cylically, so that the rotors on one side produce more lift than the other. Rotorcraft with powered rotors typically need a tail rotor to counter the rotational thrust produced by the rotor, which can cause the helicopter to spin.\nDesign and construction.\nThe key parts of an aircraft are generally divided into three categories:\nStructure.\nAerostats.\nAn \"aerostat\" or \"lighter-than-air aircraft\" relies on buoyancy to maintain flight. Aerostats include unpowered balloons (free-flying or tethered) and powered airships. The relative density of an aerostat as a whole is lower than that of the surrounding atmospheric air (hence the name \"lighter-than-air\"). Its main component is one or more gas capsules made of lightweight skins, containing a lifting gas (hot air, or any gas with lower density than air, typically hydrogen or helium) that displaces a large volume of air to generate enough buoyancy to overcome its own weight. Payload (passengers and cargo) can then be carried on attached components such as a basket, a gondola, a cabin or various hardpoints. With airships, which need to be able to fly against wind, the lifting gas capsules are often protected by a more rigid outer envelope or an airframe, with other gasbags such as ballonets to help modulate buoyancy.\nAerostats are so named because they use aerostatic buoyant force that does not require any forward movement through the surrounding air mass, resulting in the inherent ability to levitate and perform vertical takeoff and landing. This contrasts with the heavier-than-air aerodynes that primarily use aerodynamic lift, which must have consistent airflow over an aerofoil (wing) surface to stay airborne. The term has also been used in a narrower sense, to refer to the statically tethered balloon in contrast to the free-flying airship. This article uses the term in its broader sense.\nAerodynes.\nAn \"aerodyne\" is a heavier-than-air aircraft that relies on aerodynamic lift, or upthrust produced by the airflow, to fly. Aerodynes include rotorcraft, airplanes, gliders, and several other varieties of aircraft. Airplanes use wings, or airfoils, to direct the airflow to produce lift. Wings are usually constructed with a wooden or metal inner framework, and a skin stretched over it. Rotorcraft use a rotor which acts like a rotating wing, allowing them to hover in place. When aerodynes carry a payload, it is usually carried inside the aircraft's fuselage, or central structure, but aerodynes can also carry loads attached outside the aircraft or inside the wing. Unlike aerostats, which control their altitude by changing their weight, aerodynes use control surfaces to control their altitude, or raise or lower the lift on their wing by adjusting their speed. As they typically travel at higher speeds than aerostats, most aerodynes have a rigid structure consisting of a frame covered by a skin.\nPower.\nThe source of motive power for an aircraft is normally called the \"powerplant,\" and includes engine or motor, propeller or rotor, (if any), jet nozzles and thrust reversers (if any), and accessories essential to the functioning of the engine or motor (e.g.: starter, ignition system, intake system, exhaust system, fuel system, lubrication system, engine cooling system, and engine controls).\nPowered aircraft are typically powered by internal combustion engines (piston or turbine) burning fossil fuels\u2014typically gasoline (avgas) or jet fuel. A very few are powered by rocket power, ramjet propulsion, or by electric motors, or by internal combustion engines of other types, or using other fuels. A very few have been powered, for short flights, by human muscle energy (e.g.: Gossamer Condor).\nAvionics.\nThe avionics comprise any \"electronic\" aircraft flight control systems and related equipment, including electronic cockpit instrumentation, navigation, radar, monitoring, and communications systems.\nFlight characteristics.\nFlight envelope.\nThe flight envelope of an aircraft refers to its approved design capabilities in terms of airspeed, load factor and altitude.\nRange.\nThe maximal total \"range\" is the maximum distance an aircraft can fly between takeoff and landing. Powered aircraft range is limited by the aviation fuel energy storage capacity (chemical or electrical) considering both weight and volume limits. Unpowered aircraft range depends on factors such as cross-country speed and environmental conditions. The range can be seen as the cross-country ground speed multiplied by the maximum time in the air. The fuel time limit for powered aircraft is fixed by the available fuel (considering reserve fuel requirements) and rate of consumption. The Airbus A350-900ULR is among the longest range airliners.\nSome aircraft can gain energy while airborne through the environment (e.g. collecting solar energy or through rising air currents from mechanical or thermal lifting) or from in-flight refueling. These aircraft could theoretically have an infinite range.\n\"Ferry range\" means the maximum range that an aircraft engaged in ferry flying can achieve. This usually means maximum fuel load, optionally with extra fuel tanks and minimum equipment. It refers to the transport of aircraft without any passengers or cargo. \"Combat radius\" is a related measure based on the maximum distance a warplane can travel from its base of operations, accomplish some objective, and return to its original airfield with minimal reserves.\nFlight dynamics.\n\"Flight dynamics\" is the science of air vehicle orientation and control in three dimensions. The three critical flight dynamics parameters are the angles of rotation in three dimensions about the vehicle's center of gravity (cg), known as \"pitch\", \"roll\" and \"yaw\". These are collectively known as \"aircraft attitude\", often principally relative to the atmospheric frame in normal flight, but also relative to terrain during takeoff or landing, or when operating at low elevation. The concept of attitude is not specific to fixed-wing aircraft, but also extends to rotary aircraft such as helicopters, and dirigibles, where the flight dynamics involved in establishing and controlling attitude are entirely different.\nControl systems adjust the orientation of a vehicle about its cg. A control system includes control surfaces which, when deflected, generate a moment (or couple from ailerons) about the cg which rotates the aircraft in pitch, roll, and yaw. For example, a pitching moment comes from a force applied at a distance forward or aft of the cg, causing the aircraft to pitch up or down.\nA fixed-wing aircraft increases or decreases the lift generated by the wings when it pitches nose up or down by increasing or decreasing the angle of attack (AOA). The roll angle is also known as bank angle on a fixed-wing aircraft, which usually \"banks\" to change the horizontal direction of flight. An aircraft is streamlined from nose to tail to reduce drag making it advantageous to keep the sideslip angle near zero, though an aircraft may be deliberately \"sideslipped\" to increase drag and descent rate during landing, to keep aircraft heading same as runway heading during cross-wind landings and during flight with asymmetric power.\nStability.\nA fixed wing is typically unstable in pitch, roll, and yaw. Pitch and yaw stabilities of conventional fixed wing designs require horizontal and vertical stabilisers, which act similarly to the feathers on an arrow. These stabilizing surfaces allow equilibrium of aerodynamic forces and to stabilise the flight dynamics of pitch and yaw.\nControl.\nIn fixed-wing aircraft, multiple control surfaces are used to adjust the aircraft's roll, pitch, and yaw. Ailerons, hinged surfaces normally located on the rear edge of the wing, can raise or lower the lift produced by one side of the wing, causing the aircraft to bank to one side. Elevators, usually located in the horizontal stabilizer, are used to increase or decrease the lift produced by the tail, causing the aircraft to pitch upwards or downwards, which in turn affects the lift of the wing. However, when the ailerons are used to turn an aircraft to the left, the right aileron must be tilted downwards, producing more drag than the left aileron and causing the aircraft to yaw right. To counteract this force, most fixed-wing aircraft have a rudder mounted on the vertical stabilizer which can deflect the airflow to the tail left or right to control the aircraft's yaw. In rotorcraft, control is mainly accomplished through the cyclical tilting of the rotor's blades, increasing the angle of attack of the blades on one side and decreasing the angle of attack on the other. Similarly to the rudder on fixed-wing aircraft, rotorcraft with powered rotors have a tail rotor, which counters the rotational thrust produced by the rotor and allows the aircraft to turn in forward flight. Rotorcraft with unpowered rotors, such as autogyros, use a rudder for yaw.\nEnvironmental impact.\nAircraft engines produce gases, noise, and particulates from fossil fuel combustion, raising environmental concerns over their global effects and on local air quality.\nJet airliners contribute to climate change by emitting carbon dioxide (CO2), the best understood greenhouse gas, and, with less scientific understanding, nitrogen oxides, contrails and particulates. Their radiative forcing is estimated at 1.4 that of CO2 alone, excluding induced cirrus cloud with a very low level of scientific understanding.\nIn 2018, global commercial operations generated 2.4% of CO2 emissions. Jet airliners have become more fuel efficient and CO2 emissions per revenue ton-kilometer (RTK) in 2018 were 47% of those in 1990. In 2018, CO2 emissions averaged 88 grams of CO2 per revenue passenger per km. While the aviation industry is more fuel efficient, overall emissions have risen as the volume of air travel has increased. By 2020, aviation emissions were 70% higher than in 2005 and they could grow by 300% by 2050.\nAircraft noise pollution disrupts sleep, children's education and could increase cardiovascular risk. Airports can generate water pollution due to their extensive handling of jet fuel and deicing chemicals if not contained, contaminating nearby water bodies. Aviation activities emit ozone and ultrafine particles, both of which are health hazards. Piston engines used in general aviation burn Avgas, releasing toxic lead.\nAviation's environmental footprint can be reduced by better fuel economy in aircraft, or air traffic control and flight routes can be optimized to lower non-CO2 effects on climate from , particulates or contrails.\nAviation biofuel, emissions trading and carbon offsetting, part of the ICAO's CORSIA, can lower CO2 emissions. Aviation usage can be lowered by short-haul flight bans, train connections, personal choices and aviation taxation and subsidies. Fuel-powered aircraft may be replaced by hybrid electric aircraft and electric aircraft or by hydrogen-powered aircraft.\nSince 2021, the IATA members plan net-zero carbon emissions by 2050, followed by the ICAO in 2022.\nUses for aircraft.\nMilitary.\nA military aircraft is any aircraft that is operated by a legal or insurrectionary armed service of any type. Military aircraft can be either combat or non-combat:\nCivil.\n\"Civil aviation\" is one of two major categories of flying, representing all non-military and non-state aviation, which can be both private and commercial. Most countries in the world are members of the International Civil Aviation Organization and work together to establish common Standards and Recommended Practices for civil aviation through that agency.\nCivil aviation includes three major categories:\nAlthough scheduled air transport is the larger operation in terms of passenger numbers, GA is larger in the number of flights (and flight hours, in the U.S.) In the U.S., GA carries 166 million passengers each year, more than any individual airline, though less than all the airlines combined. Since 2004, the U.S. airlines combined have carried over 600 million passengers each year, and in 2014, they carried a combined 662,819,232 passengers.\nSome countries also make a regulatory distinction based on whether aircraft are flown for hire, like:\nAll scheduled air transport is commercial, but general aviation can be either commercial or private. Normally, the pilot, aircraft, and operator must all be authorized to perform commercial operations through separate commercial licensing, registration, and operation certificates.\nExperimental.\nAn \"experimental aircraft\" is an aircraft intended for testing new aerospace technologies and design concepts.\nThe term \"research aircraft\" or \"testbed aircraft\", by contrast, generally denotes aircraft modified to perform scientific studies, such as weather research or geophysical surveying, similar to a research vessel.\nThe term \"experimental aircraft\" also has specific legal meaning in Australia, the United States and some other countries; usually used to refer to aircraft flown with an experimental certificate. In the United States, this also includes most homebuilt aircraft, many of which are based on conventional designs and hence are experimental only in name because of certain restrictions in operation.\nModel.\nModel aircraft are typically small-scale replicas of flying aircraft, or new designs built smaller than most passenger aircraft. Static model aircraft, which cannot fly, are usually not considered to be aircraft, but they can be used to test aspects of a flying aircraft, such as its aerodynamics. Flying models are commonly propelled by electric motors, combustion engines, or are gliders, but there are many alternate methods of propulsion, such as wound rubber bands and small jet engines. Most flying model aircraft are either radio-controlled aircraft, fly freely, or are controlled by wires held by the pilot.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "851", "revid": "51004909", "url": "https://en.wikipedia.org/wiki?curid=851", "title": "Alfred Nobel", "text": "Swedish chemist and inventor (1833\u20131896)\nAlfred Bernhard Nobel ( ; ; 21 October 1833 \u2013 10 December 1896) was a Swedish chemist, inventor, engineer, and businessman. He is known for inventing dynamite, as well as having bequeathed his fortune to establish the Nobel Prizes. He also made several other important contributions to science, holding 355 patents during his life.\nBorn into the prominent Nobel family in Stockholm, Nobel displayed an early aptitude for science and learning, particularly in chemistry and languages; he became fluent in six languages and filed his first patent at the age of 24. He embarked on many business ventures with his family, most notably owning the company Bofors\u2014which was an iron and steel producer that he had developed into a major manufacturer of cannons and other armaments. Nobel's most famous invention, dynamite, was an explosive made using nitroglycerin, which was patented in 1867. He further invented gelignite in 1875 and ballistite in 1887.\nUpon his death, Nobel donated his fortune to a foundation to fund the Nobel Prizes, which annually recognize those who have \"conferred the greatest benefit to humankind\". The synthetic element nobelium was named after him, and his name and legacy also survive in companies such as Dynamit Nobel and AkzoNobel, which descend from mergers with companies he founded. Nobel was elected a member of the Royal Swedish Academy of Sciences, which, pursuant to his will, is responsible for choosing the Nobel laureates in Physics and in Chemistry.\nBiography.\nEarly life and education.\nAlfred Nobel was born in Stockholm, Sweden, on 21 October 1833. He was the third son of Immanuel Nobel (1801\u20131872), an inventor and engineer, and Andriette Nobel (n\u00e9e Ahlsell 1805\u20131889). The couple married in 1827 and had eight children. The family was impoverished, and only Alfred and his three brothers survived beyond their childhood. Through his father, Alfred Nobel was a descendant of the Swedish scientist Olaus Rudbeck (1630\u20131702). Nobel's father was an alumnus of the Royal Institute of Technology in Stockholm and was an engineer and inventor who built bridges and buildings and experimented with different ways of blasting rocks. He encouraged and taught Nobel from a young age.\nFollowing various business failures caused by the loss of some barges of building material, Immanuel Nobel was forced into bankruptcy. Nobel's father moved to Saint Petersburg, then part of the Russian Empire, and grew successful there as a manufacturer of machine tools and explosives. He invented the veneer lathe, which made possible the production of modern plywood, and started work on the naval mine. In 1842, the family joined him in the city. Now prosperous, his parents were able to send Nobel to private tutors, and the boy excelled in his studies, particularly in chemistry and languages, achieving fluency in English, French, German, and Russian. For 18 months, from 1841 to 1842, Nobel attended the Jacobs Apologistic School in Stockholm, his only schooling; he never attended university.\nNobel gained proficiency in Swedish, French, Russian, English, German, and Italian. He also developed sufficient literary skill to write poetry in English. His \"Nemesis\" is a prose tragedy in four acts about the Italian noblewoman Beatrice Cenci. It was printed while he was dying, but the entire stock was destroyed immediately after his death, except for three copies, being regarded as scandalous and blasphemous. It was published in Sweden in 2003 and has been translated into Slovenian, French, Italian, and Spanish.\nScientific career.\nAs a young man, Nobel studied with chemist Nikolai Zinin; then, in 1850, he went to Paris to further the work. There he met Ascanio Sobrero, who had synthesized nitroglycerin three years before. Sobrero strongly opposed the use of nitroglycerin because it was unpredictable, exploding when subjected to variable heat or pressure. But Nobel became interested in finding a way to control and use nitroglycerin as a commercially usable explosive; it had much more power than gunpowder. In 1851 at age 18, he went to the United States for one year to study, working for a short period under Swedish-American inventor John Ericsson, who designed the American Civil War ironclad, USS \"Monitor\". Nobel filed his first patent, an English patent for a gas meter, in 1857, while his first Swedish patent, which he received in 1863, was on \"ways to prepare gunpowder\". The family factory produced armaments for the Crimean War (1853\u20131856), but had difficulty switching back to regular domestic production when the fighting ended and they filed for bankruptcy. In 1859, Nobel's father left his factory in the care of the second son, Ludvig Nobel (1831\u20131888), who greatly improved the business. Nobel and his parents returned to Sweden from Russia, and Nobel devoted himself to the study of explosives, and especially to the safe manufacture and use of nitroglycerin. Nobel invented a detonator in 1863, and in 1865 designed the blasting cap. \nOn 3 September 1864, a shed used for preparation of nitroglycerin exploded at the factory in Heleneborg, Stockholm, Sweden, killing five people, including Nobel's younger brother Emil. He was then deprived of his license to produce explosives. Fazed by the accident, Nobel founded the company Nitroglycerin AB in Vinterviken so that he could continue to work in a more isolated area. Nobel invented dynamite in 1867, a substance easier and safer to handle than the more unstable nitroglycerin. Dynamite was patented in the US and the UK and was used extensively in mining and the building of transport networks internationally. In 1875, Nobel invented gelignite, more stable and powerful than dynamite, and in 1887, patented ballistite, a predecessor of cordite.\nNobel was elected a member of the Royal Swedish Academy of Sciences in 1884, the same institution that would later select laureates for two of the Nobel prizes, and he received an honorary doctorate from Uppsala University in 1893. Nobel's brothers Ludvig and Robert founded the oil company Branobel and became hugely rich in their own right. Nobel invested in these and amassed great wealth through the development of these new oil regions. It operated mainly in Baku, Azerbaijan, but also in Cheleken, Turkmenistan. During his life, Nobel was issued 355 patents internationally, and by his death, his business had established more than 90 explosives and armament factories, despite his apparently pacifist character.\nInventions.\nNobel found that when nitroglycerin was incorporated in an absorbent inert substance like \"kieselguhr\" (diatomaceous earth) it became safer and more convenient to handle, and this mixture he patented in 1867 as \"dynamite\". Nobel demonstrated his explosive for the first time that year, at a quarry in Redhill, Surrey, England. To help reestablish his name and improve the image of his business from the earlier controversies associated with dangerous explosives, Nobel had also considered naming the highly powerful substance \"Nobel's Safety Powder\", which is the text used in his patent, but settled with Dynamite instead, referring to the Greek word for \"power\" ().\nNobel later combined nitroglycerin with various nitrocellulose compounds, similar to collodion, but settled on a more efficient recipe combining another nitrate explosive, and obtained a transparent, jelly-like substance, which was a more powerful explosive than dynamite. Gelignite, or blasting gelatin, as it was named, was patented in 1876; and was followed by a host of similar combinations, modified by the addition of potassium nitrate and various other substances. Gelignite was more stable, powerful, transportable and conveniently formed to fit into bored holes, like those used in drilling and mining, than the previously used compounds. It was adopted as the standard technology for mining in the \"Age of Engineering\", bringing Nobel a great amount of financial success, though at a cost to his health. An offshoot of this research resulted in Nobel's invention of ballistite, the precursor of many modern smokeless powder explosives and still used as a rocket propellant.\nNobel Prize.\nThere is a well-known story about the origin of the Nobel Prize, although historians have been unable to verify it, and some dismiss the story as a myth. In 1888, the death of his brother Ludvig supposedly caused several newspapers to publish obituaries of Alfred in error. One French newspaper condemned him for his invention of military explosives\u2014in many versions of the story, dynamite is quoted, although this was mainly used for civilian applications\u2014and this is said to have brought about his decision to leave a better legacy after his death. The obituary stated, \"\" (\"The merchant of death is dead\"), and went on to say, \"Dr. Alfred Nobel, who became rich by finding ways to kill more people faster than ever before, died yesterday.\" Nobel read the obituary and was appalled at the idea that he would be remembered in this way. His decision to posthumously donate the majority of his wealth to found the Nobel Prize has been credited to him wanting to leave behind a better legacy. However, it has been questioned whether or not the obituary in question actually existed.\nOn 27 November 1895, at the Swedish-Norwegian Club in Paris, Nobel signed his last will and set aside the bulk of his estate to establish the Nobel Prizes, to be awarded annually without distinction of nationality. After taxes and bequests to individuals, Nobel's will allocated 94% of his total assets, 31,225,000 Swedish kronor, to establish the five Nobel Prizes. By 2022, the foundation had approximately 6 billion Swedish Kronor of invested capital.\nThe first three of these prizes are awarded for eminence in physical science, in chemistry and in medical science or physiology; the fourth is for literary work \"in an ideal direction\" and the fifth prize is to be given to the person or society that renders the greatest service to the cause of international fraternity, in the suppression or reduction of standing armies, or in the establishment or furtherance of peace congresses.\nThe formulation for the literary prize being given for a work \"in an ideal direction\" (' in Swedish) is cryptic and has caused much confusion. For many years, the Swedish Academy interpreted \"ideal\" as \"idealistic\" (') and used it as a reason not to give the prize to important but less romantic authors, such as Henrik Ibsen and Leo Tolstoy. This interpretation has since been revised, and the prize has been awarded to, for example, Dario Fo and Jos\u00e9 Saramago, who do not belong to the camp of literary idealism.\nThere was room for interpretation by the bodies he had named for deciding on the physical sciences and chemistry prizes, given that he had not consulted them before making the will. In his one-page testament, he stipulated that the money go to discoveries or inventions in the physical sciences and to discoveries or improvements in chemistry. He had opened the door to technological awards, but had not left instructions on how to deal with the distinction between science and technology. Since the deciding bodies he had chosen were more concerned with the former, the prizes went to scientists more often than engineers, technicians, or other inventors.\nSweden's central bank Sveriges Riksbank celebrated its 300th anniversary in 1968 by donating a large sum of money to the Nobel Foundation to be used to set up a sixth prize in the field of economics in honor of Alfred Nobel. In 2001, Alfred Nobel's great-great-nephew, Peter Nobel (born 1931), asked the Bank of Sweden to differentiate its award to economists given \"in Alfred Nobel's memory\" from the five other awards. This request added to the controversy over whether the Bank of Sweden Prize in Economic Sciences in Memory of Alfred Nobel is actually a legitimate \"Nobel Prize\".\nHealth issues and death.\nIn his letters to his mistress, Hess, Nobel described constant pain, debilitating migraines, and \"paralyzing\" fatigue, leading some to believe that he suffered from fibromyalgia. However, his concerns at the time were dismissed as hypochondria, leading to further depression.\nBy 1895, Nobel had developed angina pectoris.\nOn 27 November 1895, he finalized his will and testament, leaving most of his wealth in trust, unbeknownst to his family, to fund the Nobel Prize awards.\nOn 10 December 1896, he suffered a stroke/intracerebral hemorrhage and was first partially paralyzed and then died, aged 63. He is buried in Norra begravningsplatsen in Stockholm.\nBased on his experimentation with explosives, his strenuous work habits, and the decline in his health at the end of the 1870s, some hypothesize that nitroglycerine poisoning was a contributing factor to his death.\nPersonal life.\nReligion.\nNobel was Lutheran and, during his years living in Paris, he regularly attended the Church of Sweden Abroad led by pastor Nathan S\u00f6derblom, who received the Nobel Peace Prize in 1930. He was an agnostic in youth and became an atheist later in life, though he still donated generously to the Church.\nRomantic relationships and personality.\nNobel remained a solitary character, given to periods of depression. He never married, although his biographers note that he had at least three loves. His first love was in Russia with a girl named Alexandra, who rejected his marriage proposal.\nIn 1876, Austro-Bohemian Countess Bertha von Suttner became his secretary, but she left him after a brief stay to marry her previous lover, Baron Arthur Gundaccar von Suttner. Her contact with Nobel was brief, yet she corresponded with him until he died in 1896, and probably influenced his decision to include the Nobel Peace Prize in his will. She was awarded the 1905 Nobel Peace prize \"for her sincere peace activities\".\nNobel's longest-lasting romance was an 18-year relationship with Sofija Hess from Celje, whom he met in 1876 in Baden bei Wien, where she worked as an employee in a flower shop that catered to wealthy clientele. The extent of their relationship was revealed by a collection of 221 letters sent by Nobel to Hess over 15 years. At the time that they met, Nobel was 43 years old while Hess was 26. Their relationship, which was not merely platonic, ended when she became pregnant with another man, although Nobel continued to support her financially until Hess married her child's father to avoid being ostracized as a whore. Hess was a Jewish Christian, and the letters include remarks by Nobel characterized as antisemitism. Nobel also displayed characteristics of chauvinism in the letters writing to Hess: \"You neither work, nor write, nor read, nor think\" and guilted her, writing \"I have for years now sacrificed out of purely noble motives my time, my duties, my intellectual life, my reputation\".\nResidences.\nNobel traveled for much of his business life, maintaining companies in Europe and America. From 1865 to 1873, Nobel lived in Kr\u00fcmmel (now in the municipality of Geesthacht, near Hamburg). From 1873 to 1891, he lived in a house on the Avenue Malakoff in Paris.\nIn 1891, after being accused of high treason against France for selling Ballistite to Italy, he moved from Paris to Sanremo, Italy, acquiring Villa Nobel, overlooking the Mediterranean Sea, where he died in 1896.\nIn 1894, when he acquired Bofors-Gullsp\u00e5ng, the Bj\u00f6rkborn Manor was included, where he stayed during the summers. It is now a museum.\nMonument to Alfred Nobel.\nThe \"Monument to Alfred Nobel\" (, ) is in Saint Petersburg along the Bolshaya Nevka River on Petrogradskaya Embankment, the street where Nobel's family lived until 1859. It was dedicated in 1991 to mark the 90th anniversary of the first Nobel Prize presentation. Diplomat Thomas Bertelman and Professor Arkady Melua were initiators of the creation of the monument in 1989, and they provided funds for the establishment of the monument. The abstract metal sculpture was designed by local artists Sergey Alipov and Pavel Shevchenko, and appears to be an explosion or branches of a tree.\nCriticism.\nCriticism of Nobel focuses on his leading role in weapons manufacturing and sales. Some people question his motives in creating his prizes, suggesting they are intended to improve his reputation. For example, the 1984 public artwork \"Nobel Metamorphoses\" in Troisdorf, Germany \u2013 at the time the location of the Dynamit Nobel headquarters, the sculpture critically contrasts war death statistics to peace prize recipients since the latter's inauguration in 1901. \nAntisemitism.\nNobel has also been criticized for displays of antisemitism. In his letters to Hess, he wrote, \"In my experience, [Jews] never do anything out of goodwill. They act merely out of selfishness or a desire to show off ... among selfish and inconsiderate people, they are the most selfish and inconsiderate... all others exist to be fleeced.\"\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "852", "revid": "48523215", "url": "https://en.wikipedia.org/wiki?curid=852", "title": "Alexander Graham Bell", "text": "Inventor of the telephone (1847\u20131922)\nAlexander Graham Bell (; born Alexander Bell; March 3, 1847 \u2013 August 2, 1922) was a Scottish-born Canadian-American inventor, scientist, and engineer who is credited with patenting the first practical telephone. He also co-founded the American Telephone and Telegraph Company (AT&amp;T) in 1885.\nBell's father, grandfather, and brother had all been associated with work on elocution and speech, and both his mother and wife were deaf, profoundly influencing Bell's life's work. His research on hearing and speech further led him to experiment with hearing devices, which eventually culminated in his being awarded the first U.S. patent for the telephone, on March 7, 1876. Bell considered his invention an intrusion on his real work as a scientist and refused to have a telephone in his study.\nMany other inventions marked Bell's later life, including ground-breaking work in optical telecommunications, hydrofoils, and aeronautics. Bell also had a strong influence on the National Geographic Society and its magazine while serving as its second president from 1898 to 1903.\nBeyond his work in engineering, Bell had a deep interest in the emerging science of heredity. His work in this area has been called \"the soundest, and most useful study of human heredity proposed in nineteenth-century America ... Bell's most notable contribution to basic science, as distinct from invention.\"\nEarly life.\nBell was born in Edinburgh, Scotland, on March 3, 1847, to Alexander Melville Bell, a phonetician, and Eliza Grace Bell (n\u00e9e\u00a0Symonds). The family home was on South Charlotte Street in Edinburgh, where a stone inscription marks it as Bell's birthplace. He had two brothers: Melville James Bell (1845\u20131870) and Edward Charles Bell (1848\u20131867), who both died of tuberculosis. He was born as just \"Alexander Bell\". At age 10, however, he made a plea to his father to have a middle name like his two brothers. For his 11th birthday, his father acquiesced and allowed him to adopt the name \"Graham\", chosen out of respect for Alexander Graham, a Canadian being treated by his father who was also a family friend. To close relatives and friends he remained \"Aleck\". Bell and his siblings attended a Presbyterian Church in their youth.\nFirst invention.\nAs a child, Bell displayed a curiosity about his world; he gathered botanical specimens and ran experiments at an early age. His best friend was Ben Herdman, a neighbour whose family operated a flour mill. At the age of 12, Bell built a homemade device that combined rotating paddles with sets of nail brushes, creating a simple dehusking machine that was put into operation at the mill and used steadily for a number of years. In return, Ben's father John Herdman gave both boys the run of a small workshop in which to \"invent\".\nFrom his early years, Bell showed a sensitive nature and a talent for art, poetry, and music that his mother encouraged. With no formal training, he mastered the piano and became the family's pianist. Though normally quiet and introspective, he revelled in mimicry and \"voice tricks\" akin to ventriloquism that entertained family guests. Bell was also deeply affected by his mother's gradual deafness (she began to lose her hearing when he was 12), and learned a manual finger language so he could sit at her side and tap out silently the conversations swirling around the family parlour. He also developed a technique of speaking in clear, modulated tones directly into his mother's forehead, whereby she would hear him with reasonable clarity. Bell's preoccupation with his mother's deafness led him to study acoustics.\nHis family was long associated with the teaching of elocution: his grandfather, Alexander Bell, in London, his uncle in Dublin, and his father, in Edinburgh, were all elocutionists. His father published a variety of works on the subject, several of which are still well known, especially \"The Standard Elocutionist\" (1860), which appeared in Edinburgh in 1868. \"The Standard Elocutionist\" appeared in 168 British editions and sold over 250,000 copies in the United States alone. It explains methods to instruct deaf-mutes (as they were then known) to articulate words and read other people's lip movements to decipher meaning. Bell's father taught him and his brothers not only to write Visible Speech but to identify any symbol and its accompanying sound. Bell became so proficient that he became a part of his father's public demonstrations and astounded audiences with his abilities. He could decipher Visible Speech representing virtually every language, including Latin, Scottish Gaelic, and even Sanskrit, accurately reciting written tracts without any prior knowledge of their pronunciation.\nEducation.\nAs a young child, Bell, like his brothers, was schooled at home by his father. At an early age, he was enrolled at the Royal High School in Edinburgh. But he left at age 15, having completed only the first four forms. His school record was undistinguished, marked by absenteeism and lacklustre grades. His main interest remained in the sciences, especially biology, while he treated other school subjects with indifference, to his father's dismay. Upon leaving school, Bell travelled to London to live with his grandfather, Alexander Bell, on Harrington Square. During the year he spent with his grandfather, a love of learning was born, with long hours spent in serious discussion and study. The elder Bell took great efforts to have his young pupil learn to speak clearly and with conviction, attributes he would need to become a teacher himself. At age 16, Bell secured a position as a \"pupil-teacher\" of elocution and music at Weston House Academy in Elgin, Moray, Scotland. Although enrolled as a student in Latin and Greek, he instructed classes himself in return for board and \u00a310 per session. The next year, he attended the University of Edinburgh, joining his brother Melville, who had enrolled there the previous year. In 1868, Bell completed his matriculation exams and was accepted for admission to University College London, though he did not complete his studies, as his family emigrated to Canada in 1870 following the deaths of his brothers Edward and Melville from tuberculosis.\nFirst experiments with sound.\nBell's father encouraged his interest in speech and, in 1863, took his sons to see a unique automaton developed by Sir Charles Wheatstone based on the earlier work of Baron Wolfgang von Kempelen. The rudimentary \"mechanical man\" simulated a human voice. Bell was fascinated by the machine, and after he obtained a copy of von Kempelen's book, published in German, and had laboriously translated it, he and Melville built their own automaton head. Their father, highly interested in their project, offered to pay for any supplies and spurred the boys on with the enticement of a \"big prize\" if they were successful. While his brother constructed the throat and larynx, Bell tackled the more difficult task of recreating a realistic skull. His efforts resulted in a remarkably lifelike head that could \"speak\", albeit only a few words. The boys would carefully adjust the \"lips\" and when a bellows forced air through the windpipe, a very recognizable \"Mama\" ensued, to the delight of neighbours who came to see the invention.\nIntrigued by the results of the automaton, Bell continued to experiment with a live subject, the family's Skye Terrier, Trouve. After he taught it to growl continuously, Bell would reach into its mouth and manipulate the dog's lips and vocal cords to produce a crude-sounding \"Ow ah oo ga ma ma\". With little convincing, visitors believed his dog could articulate \"How are you, grandmama?\" Indicative of his playful nature, his experiments convinced onlookers that they saw a \"talking dog\". These initial forays into experimentation with sound led Bell to undertake his first serious work on the transmission of sound, using tuning forks to explore resonance.\nAt age 19, Bell wrote a report on his work and sent it to philologist Alexander Ellis, a colleague of his father. Ellis immediately wrote back indicating that the experiments were similar to existing work in Germany, and also lent Bell a copy of Hermann von Helmholtz's work, \"The Sensations of Tone as a Physiological Basis for the Theory of Music\".\nDismayed to find that groundbreaking work had already been undertaken by Helmholtz, who had conveyed vowel sounds by means of a similar tuning fork \"contraption\", Bell pored over the book. Working from his own erroneous mistranslation of a French edition, Bell fortuitously then made a deduction that would underpin all his future work on transmitting sound, reporting: \"Without knowing much about the subject, it seemed to me that if vowel sounds could be produced by electrical means, so could consonants, so could articulate speech.\" He also later remarked: \"I thought that Helmholtz had done it\u00a0... and that my failure was due only to my ignorance of electricity. It was a valuable blunder\u00a0... If I had been able to read German in those days, I might never have commenced my experiments!\"\nFamily tragedy.\nIn 1865, when the Bell family moved to London, Bell returned to Weston House as an assistant master and, in his spare hours, continued experiments on sound using a minimum of laboratory equipment. Bell concentrated on experimenting with electricity to convey sound and later installed a telegraph wire from his room in Somerset College to that of a friend. Throughout late 1867, his health faltered mainly through exhaustion. His brother Edward was similarly affected by tuberculosis. While Bell recovered (by then referring to himself in correspondence as \"A. G. Bell\") and served the next year as an instructor at Somerset College, Bath, England, his brother's condition deteriorated. Edward never recovered. Upon his brother's death, Bell returned home in 1867. Melville had married and moved out. With aspirations to obtain a degree at University College London, Bell considered his next years preparation for the degree examinations, devoting his spare time to studying.\nHelping his father in Visible Speech demonstrations and lectures brought Bell to Susanna E. Hull's private school for the deaf in South Kensington, London. His first two pupils were deaf-mute girls who made remarkable progress under his tutelage. While Melville seemed to achieve success on many fronts, including opening his own elocution school, applying for a patent on an invention, and starting a family, Bell continued as a teacher. In May 1870, Melville died from complications of tuberculosis, causing a family crisis. His father had also experienced a debilitating illness earlier in life and been restored to health by convalescence in Newfoundland. Bell's parents embarked upon a long-planned move when they realized that their remaining son was also sickly. Acting decisively, Alexander Melville Bell asked Bell to arrange for the sale of all the family property, conclude all his brother's affairs (Bell took on his last student, curing a pronounced lisp), and join his father and mother in setting out for Canada. Reluctantly, Bell also had to conclude a relationship with Marie Eccleston, who, as he had surmised, was not prepared to leave England with him.\nCanada.\nIn 1870, 23-year-old Bell travelled with his parents and his brother's widow, Caroline Margaret Ottaway, to Paris, Ontario, to stay with Thomas Henderson, a Baptist minister and family friend. The Bells soon purchased a farm of at Tutelo Heights (now called Tutela Heights), near Brantford, Ontario. The property consisted of an orchard, large farmhouse, stable, pigsty, hen-house, and a carriage house, which bordered the Grand River.\nAt the homestead, Bell set up a workshop in the converted carriage house near what he called his \"dreaming place\", a large hollow nestled in trees at the back of the property above the river. Despite his frail condition upon arriving in Canada, Bell found the climate and environs to his liking and rapidly improved. He continued his interest in the study of the human voice, and when he discovered the Six Nations Reserve across the river at Onondaga, learned the Mohawk language and translated its unwritten vocabulary into Visible Speech symbols. For his work, Bell was awarded the title of Honorary Chief and participated in a ceremony where he donned a Mohawk headdress and danced traditional dances.\nAfter setting up his workshop, Bell continued experiments based on Helmholtz's work with electricity and sound. He also modified a melodeon (a type of pump organ) to transmit its music electrically over a distance. Once the family was settled, Bell and his father made plans to establish a teaching practice and in 1871, he accompanied his father to Montreal, where Melville was offered a position to teach his System of Visible Speech.\nWork with deaf people.\nBell's father was invited by Sarah Fuller, principal of the Boston School for Deaf Mutes (later to become the public Horace Mann School for the Deaf) to introduce the Visible Speech System by providing training for Fuller's instructors, but he declined the post in favour of his son. Travelling to Boston in April 1871, Bell proved successful in training the school's instructors. He was asked to repeat the programme at the American Asylum for Deaf-mutes in Hartford, Connecticut, and the Clarke School for the Deaf in Northampton, Massachusetts.\nReturning home to Brantford after six months abroad, Bell continued his experiments with his \"harmonic telegraph\". The basic concept behind his device was that messages could be sent through a single wire if each was transmitted at a different pitch, but work on both the transmitter and receiver was needed.\nUnsure of his future, he contemplated returning to London to complete his studies, but decided to return to Boston as a teacher. His father helped him set up his private practice by contacting Gardiner Greene Hubbard, the president of the Clarke School for the Deaf for a recommendation. Teaching his father's system, in October 1872, Alexander Bell opened his \"School of Vocal Physiology and Mechanics of Speech\" in Boston, which attracted a large number of deaf pupils, with his first class numbering 30 students. While he was working as a private tutor, one of his pupils was Helen Keller, who came to him as a young child unable to see, hear, or speak. She later said that Bell dedicated his life to the penetration of that \"inhuman silence which separates and estranges\". In 1893, Keller performed the sod-breaking ceremony for the construction of Bell's new Volta Bureau, dedicated to \"the increase and diffusion of knowledge relating to the deaf\".\nThroughout his life, Bell sought to assimilate the deaf and hard of hearing with the hearing world. He encouraged speech therapy and lip-reading over sign language. He outlined this in an 1898 paper detailing his belief that, with resources and effort, the deaf could be taught to read lips and speak (known as oralism), enabling their integration with wider society. Members of the Deaf community have criticized Bell for supporting ideas that could cause the closure of dozens of deaf schools, and what some consider eugenicist ideas. In his memoir \"Memoir upon the Formation of a Deaf Variety of the Human Race\", Bell observed that if deaf people tended to marry other deaf people, this could result in the emergence of a \"deaf race\". Ultimately, in 1880, the Second International Congress on Education of the Deaf passed a resolution mandating the teaching of oral communication and banning signing in schools.\nContinuing experimentation.\nIn 1872, Bell became professor of Vocal Physiology and Elocution at the Boston University School of Oratory. During this period, he alternated between Boston and Brantford, spending summers in his Canadian home. At Boston University, Bell was \"swept up\" by the excitement engendered by the many scientists and inventors living in the city. He continued his research in sound and endeavoured to find a way to transmit musical notes and articulate speech, but although absorbed by his experiments, he found it difficult to devote enough time to experimentation. With days and evenings occupied by his teaching and private classes, Bell began to stay awake late into the night, running experiment after experiment in rented facilities at his boarding house. Keeping \"night owl\" hours, he worried that his work would be discovered and took great pains to lock up his notebooks and laboratory equipment. Bell had a specially made table where he could place his notes and equipment inside a locking cover. His health deteriorated as he had severe headaches. Returning to Boston in autumn 1873, Bell made a far-reaching decision to concentrate on his experiments in sound.\nGiving up his lucrative private Boston practice, Bell retained only two students, six-year-old \"Georgie\" Sanders, deaf from birth, and 15-year-old Mabel Hubbard. Each played an important role in the next developments. Georgie's father, Thomas Sanders, a wealthy businessman, offered Bell a place to stay in nearby Salem with Georgie's grandmother, complete with a room to \"experiment\". Although the offer was made by Georgie's mother and followed the year-long arrangement in 1872 where her son and his nurse had moved to quarters next to Bell's boarding house, it was clear that Mr. Sanders backed the proposal. The arrangement was for teacher and student to continue their work together, with free room and board thrown in. Mabel was a bright, attractive girl ten years Bell's junior who became the object of his affection. Having lost her hearing after a near-fatal bout of scarlet fever close to her fifth birthday, she had learned to read lips but her father, Gardiner Greene Hubbard, Bell's benefactor and personal friend, wanted her to work directly with her teacher.\nThe telephone.\nBy 1874, Bell's initial work on the harmonic telegraph had entered a formative stage, with progress made both at his new Boston \"laboratory\" (a rented facility) and at his family home in Canada a big success. While working that summer in Brantford, Bell experimented with a \"phonautograph\", a pen-like machine that could draw shapes of sound waves on smoked glass by tracing their vibrations. Bell thought it might be possible to generate undulating electrical currents that corresponded to sound waves. He also thought that multiple metal reeds tuned to different frequencies like a harp would be able to convert the undulating currents back into sound. But he had no working model to demonstrate the feasibility of these ideas.\nIn 1874, telegraph message traffic was rapidly expanding and, in the words of Western Union President William Orton, had become \"the nervous system of commerce\". Orton had contracted with inventors Thomas Edison and Elisha Gray to find a way to send multiple telegraph messages on each telegraph line to avoid the great cost of constructing new lines. When Bell mentioned to Gardiner Hubbard and Thomas Sanders that he was working on a method of sending multiple tones on a telegraph wire using a multi-reed device, the two began to financially support Bell's experiments. Patent matters were handled by Hubbard's patent attorney, Anthony Pollok.\nIn March 1875, Bell and Pollok visited the scientist Joseph Henry, then the director of the Smithsonian Institution, to ask his advice on the electrical multi-reed apparatus that Bell hoped would transmit the human voice by telegraph. Henry said Bell had \"the germ of a great invention\". When Bell said that he lacked the necessary knowledge, Henry replied, \"Get it!\" That declaration greatly encouraged Bell to keep trying, even though he had neither the equipment needed to continue his experiments nor the ability to create a working model of his ideas. But a chance meeting in 1874 between Bell and Thomas A. Watson, an experienced electrical designer and mechanic at the electrical machine shop of Charles Williams, changed that.\nWith financial support from Sanders and Hubbard, Bell hired Watson as his assistant, and the two experimented with acoustic telegraphy. On June 2, 1875, Watson accidentally plucked one of the reeds and Bell, at the receiving end of the wire, heard the reed's overtones that would be necessary for transmitting speech. That demonstrated to Bell that only one reed or armature was necessary, not multiple reeds. This led to the \"gallows\" sound-powered telephone, which could transmit indistinct, voice-like sounds, but not clear speech.\nThe race to the patent office.\nIn 1875, Bell developed an acoustic telegraph and drew up a patent application for it. Since he had agreed to share U.S. profits with his investors Gardiner Hubbard and Thomas Sanders, Bell requested that an associate in Ontario, George Brown, attempt to patent it in Britain, instructing his lawyers to apply for a patent in the U.S. only after they received word from Britain (Britain issued patents only for discoveries not previously patented elsewhere).\nMeanwhile, Elisha Gray was also experimenting with acoustic telegraphy and thought of a way to transmit speech using a water transmitter. On February 14, 1876, Gray filed a caveat with the U.S. Patent Office for a telephone design that used a water transmitter. That same morning, Bell's lawyer filed Bell's application with the patent office. There is considerable debate about who arrived first and Gray later challenged the primacy of Bell's patent. Bell was in Boston on February 14 and did not arrive in Washington until February 26.\nOn March 7, 1876, the U.S. Patent Office issued Bell patent 174,465. It covered \"the method of, and apparatus for, transmitting vocal or other sounds telegraphically ... by causing electrical undulations, similar in form to the vibrations of the air accompanying the said vocal or other sound\" Bell returned to Boston that day and the next day resumed work, drawing in his notebook a diagram similar to that in Gray's patent caveat.\nOn March 10, Bell succeeded in getting his telephone to work, using a liquid transmitter similar to Gray's design. Vibration of the diaphragm caused a needle to vibrate in the water, varying the electrical resistance in the circuit. When Bell spoke the sentence \"Mr. Watson\u2014Come here\u2014I want to see you\" into the liquid transmitter, Watson, listening at the receiving end in an adjoining room, heard the words clearly.\nAlthough Bell was, and still is, accused of stealing the telephone from Gray, Bell used Gray's water transmitter design only after Bell's patent had been granted, and only as a proof of concept scientific experiment, to prove to his own satisfaction that intelligible \"articulate speech\" (Bell's words) could be electrically transmitted. After March 1876, Bell focused on improving the electromagnetic telephone and never used Gray's liquid transmitter in public demonstrations or commercial use.\nThe examiner raised the question of priority for the variable resistance feature of the telephone before approving Bell's patent application. He told Bell that his claim for the variable resistance feature was also described in Gray's caveat. Bell pointed to a variable resistance device in his previous application in which he described a cup of mercury, not water. He had filed the mercury application at the patent office on February 25, 1875, long before Gray described the water device. In addition, Gray abandoned his caveat, and because he did not contest Bell's priority, the examiner approved Bell's patent on March 3, 1876. Gray had reinvented the variable resistance telephone, but Bell was the first to write down the idea and test it in a telephone.\nThe patent examiner, Zenas Fisk Wilber, later stated in an affidavit that he was an alcoholic who was much in debt to Bell's lawyer, Marcellus Bailey, with whom he had served in the Civil War. He said he had shown Bailey Gray's patent caveat. Wilber also said (after Bell arrived in Washington D.C. from Boston) that he showed Bell Gray's caveat and that Bell paid him $100 (). Bell said they discussed the patent only in general terms, although in a letter to Gray, Bell admitted that he learned some of the technical details. Bell denied in an affidavit that he ever gave Wilber any money.\nLater developments.\nOn March 10, 1876, Bell used \"the instrument\" in Boston to call Thomas Watson who was in another room but out of earshot. He said, \"Mr. Watson, come here \u2013 I want to see you\" and Watson soon appeared at his side.\nContinuing his experiments in Brantford, Bell brought home a working model of his telephone. On August 3, 1876, from the telegraph office in Brantford, Bell sent a telegram to the village of Mount Pleasant away, indicating that he was ready. He made a telephone call via telegraph wires and faint voices were heard replying. The following night, he amazed guests as well as his family with a call between the Bell Homestead and the office of the Dominion Telegraph Company in Brantford along an improvised wire strung up along telegraph lines and fences, and laid through a tunnel. This time, guests at the household distinctly heard people in Brantford reading and singing. The third test, on August 10, 1876, was made via the telegraph line between Brantford and Paris, Ontario, away. This test is said by many sources to be the \"world's first long-distance call\". It proved that the telephone could work over long distances, at least as a one-way call.\nThe first two-way (reciprocal) conversation over a line occurred between Cambridge and Boston (roughly 2.5 miles) on October 9, 1876. During that conversation, Bell was on Kilby Street in Boston and Watson was at the offices of the Walworth Manufacturing Company.\nBell and his partners, Hubbard and Sanders, offered to sell the patent outright to Western Union for $100,000, equal to $ today, but it did not work (according to an apocryphal story, the president of Western Union balked, countering that the telephone was nothing but a toy). Two years later, he told colleagues that if he could get the patent for $25 million (equal to $ today), he would consider it a bargain. By then, the Bell company no longer wanted to sell the patent. Bell's investors became millionaires while he fared well from residuals and at one point had assets of nearly $1 million.\nBell began a series of public demonstrations and lectures to introduce the new invention to the scientific community as well as the general public. A short time later, his demonstration of an early telephone prototype at the 1876 Centennial Exposition in Philadelphia brought the telephone to international attention. Influential visitors to the exhibition included Emperor Pedro II of Brazil. One of the judges at the Exhibition, Sir William Thomson (later Lord Kelvin), a renowned Scottish scientist, described the telephone as \"the greatest by far of all the marvels of the electric telegraph\".\nOn January 14, 1878, at Osborne House, on the Isle of Wight, Bell demonstrated the device to Queen Victoria, placing calls to Cowes, Southampton, and London. These were the first publicly witnessed long-distance telephone calls in the UK. The queen found the process \"quite extraordinary\" although the sound was \"rather faint\". She later asked to buy the equipment that was used, but Bell offered to make \"a set of telephones\" specifically for her.\nThe Bell Telephone Company was created in 1877, and by 1886, more than 150,000 people in the U.S. owned telephones. Bell Company engineers made numerous other improvements to the telephone, which emerged as one of the most successful products ever. In 1879, the company acquired Edison's patents for the carbon microphone from Western Union. This made the telephone practical for longer distances, and it was no longer necessary to shout to be heard at the receiving telephone.\nPedro II of Brazil was the first person to buy stock in the Bell Telephone Company. One of the first telephones in a private residence was installed in his palace in Petr\u00f3polis, his summer retreat from Rio de Janeiro.\nIn January 1915, Bell made the first ceremonial transcontinental telephone call. Calling from the AT&amp;T head office at 15 Dey Street in New York City, Bell was heard by Thomas Watson at 333 Grant Avenue in San Francisco. \"The New York Times\" reported:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;On October 9, 1876, Alexander Graham Bell and Thomas A. Watson talked by telephone to each other over a two-mile wire stretched between Cambridge and Boston. It was the first wire conversation ever held. Yesterday afternoon [on January 25, 1915], the same two men talked by telephone to each other over a 3,400-mile wire between New York and San Francisco. Dr. Bell, the veteran inventor of the telephone, was in New York, and Mr. Watson, his former associate, was on the other side of the continent.\nCompetitors.\nAs is sometimes common in scientific discoveries, simultaneous developments occurred, as evidenced by a number of inventors who were at work on the telephone. Over 18 years, the Bell Telephone Company faced 587 court challenges to its patents, including five that went to the U.S. Supreme Court, but none was successful in establishing priority over Bell's original patent, and the Bell Telephone Company never lost a case that had proceeded to a final trial stage. Bell's laboratory notes and family letters were the key to establishing a long lineage to his experiments. The Bell company lawyers successfully fought off myriad lawsuits generated initially around the challenges by Elisha Gray and Amos Dolbear. In personal correspondence to Bell, both Gray and Dolbear had acknowledged his prior work, which considerably weakened their later claims.\nOn January 13, 1887, the U.S. government moved to annul the patent issued to Bell on the grounds of fraud and misrepresentation. After a series of decisions and reversals, the Bell company won a decision in the Supreme Court, though a couple of the original claims from the lower court cases were left undecided. By the time the trial had wound its way through nine years of legal battles, the U.S. prosecuting attorney had died and the two Bell patents (No. 174,465, dated March 7, 1876, and No. 186,787, dated January 30, 1877) were no longer in effect, although the presiding judges agreed to continue the proceedings due to the case's importance as a precedent. With a change in administration and charges of conflict of interest (on both sides) arising from the original trial, the U.S. attorney general dropped the lawsuit on November 30, 1897, leaving several issues undecided on the merits.\nDuring a deposition filed for the 1887 trial, Italian inventor Antonio Meucci also claimed to have created the first working model of a telephone in Italy in 1834. In 1886, in the first of three cases in which he was involved, Meucci took the stand as a witness in hope of establishing his invention's priority. Meucci's testimony was disputed due to lack of material evidence for his inventions, as his working models were purportedly lost at the laboratory of American District Telegraph (ADT) of New York, which was incorporated as a subsidiary of Western Union in 1901. Meucci's work, like that of many other inventors of the period, was based on earlier acoustic principles and, despite evidence of earlier experiments, the final case involving Meucci was eventually dropped upon Meucci's death. But due to the efforts of Congressman Vito Fossella, on June 11, 2002, the U.S. House of Representatives stated that Meucci's \"work in the invention of the telephone should be acknowledged\". This did not put an end to the still contentious issue. Some modern scholars do not agree that Bell's work on the telephone was influenced by Meucci's inventions.\nThe value of Bell's patent was acknowledged throughout the world, and patent applications were made in most major countries. When Bell delayed the German patent application, the electrical firm Siemens &amp; Halske set up a rival manufacturer of Bell telephones under its own patent. Siemens produced near-identical copies of the Bell telephone without having to pay royalties. The establishment of the International Bell Telephone Company in Brussels, Belgium, in 1880, as well as a series of agreements in other countries eventually consolidated a global telephone operation. The strain put on Bell by his constant appearances in court, necessitated by the legal battles, eventually resulted in his resignation from the company.\nFamily life.\nOn July 11, 1877, a few days after the Bell Telephone Company was established, Bell married Mabel Hubbard (1857\u20131923) at the Hubbard estate in Cambridge, Massachusetts. His wedding present to his bride was to turn over 1,487 of his 1,497 shares in the newly formed Bell Telephone Company. Shortly thereafter, the newly-weds embarked on a year-long honeymoon in Europe. During that excursion, Bell took a handmade model of his telephone with him, making it a \"working holiday\". The courtship had begun years earlier; however, Bell waited until he was more financially secure before marrying. Although the telephone appeared to be an \"instant\" success, it was not initially a profitable venture and Bell's main sources of income were from lectures until after 1897. One unusual request exacted by his fianc\u00e9e was that he use \"Alec\" rather than the family's earlier familiar name of \"Aleck\". From 1876, he would sign his name \"Alec Bell\". They had four children:\nThe Bell family home was in Cambridge, Massachusetts, until 1880 when Bell's father-in-law bought a house in Washington, D.C.; in 1882 he bought a home in the same city for Bell's family, so they could be with him while he attended to the numerous court cases involving patent disputes.\nBell was a British subject throughout his early life in Scotland and later in Canada until 1882 when he became a naturalized citizen of the United States. In 1915, he characterized his status as: \"I am not one of those hyphenated Americans who claim allegiance to two countries.\" Despite this declaration, Bell has been proudly claimed as a \"native son\" by all three countries he resided in: the United States, Canada, and the United Kingdom.\nBy 1885, a new summer retreat was contemplated. That summer, the Bells had a vacation on Cape Breton Island in Nova Scotia, Canada, spending time at the small village of Baddeck. Returning in 1886, Bell started building an estate on a point across from Baddeck, overlooking Bras d'Or Lake. By 1889, a large house, christened \"The Lodge\" was completed and two years later, a larger complex of buildings, including a new laboratory, were begun that the Bells would name Beinn Bhreagh (Gaelic: \"Beautiful Mountain\") after Bell's ancestral Scottish highlands. Bell also built the Bell Boatyard on the estate, employing up to 40 people building experimental craft as well as wartime lifeboats and workboats for the Royal Canadian Navy and pleasure craft for the Bell family. He was an enthusiastic boater, and Bell and his family sailed or rowed a long series of vessels on Bras d'Or Lake, ordering additional vessels from the H.W. Embree and Sons boatyard in Port Hawkesbury, Nova Scotia. In his final, and some of his most productive years, Bell split his residency between Washington, D.C., where he and his family initially resided for most of the year, and Beinn Bhreagh, where they spent increasing amounts of time.\nUntil the end of his life, Bell and his family would alternate between the two homes, but \"Beinn Bhreagh\" would, over the next 30 years, become more than a summer home as Bell became so absorbed in his experiments that his annual stays lengthened. Both Mabel and Bell became immersed in the Baddeck community and were accepted by the villagers as \"their own\". The Bells were still in residence at \"Beinn Bhreagh\" when the Halifax Explosion occurred on December 6, 1917. Mabel and Bell mobilized the community to help victims in Halifax.\nLater inventions.\nAlthough Alexander Graham Bell is most often associated with the invention of the telephone, his interests were extremely varied. According to one of his biographers, Charlotte Gray, Bell's work ranged \"unfettered across the scientific landscape\" and he often went to bed voraciously reading the \"Encyclop\u00e6dia Britannica\", scouring it for new areas of interest. The range of Bell's inventive genius is represented only in part by the 18 patents granted in his name alone and the 12 he shared with his collaborators. These included 14 for the telephone and telegraph, four for the photophone, one for the phonograph, five for aerial vehicles, four for \"hydroairplanes\", and two for selenium cells. Bell's inventions spanned a wide range of interests and included a metal jacket to assist in breathing, the audiometer to detect minor hearing problems, a device to locate icebergs, investigations on how to separate salt from seawater, and work on finding alternative fuels.\nBell worked extensively in medical research and invented techniques for teaching speech to the deaf. During his Volta Laboratory period, Bell and his associates considered impressing a magnetic field on a record as a means of reproducing sound. Although the trio briefly experimented with the concept, they could not develop a workable prototype. They abandoned the idea, never realizing they had glimpsed a basic principle which would one day find its application in the tape recorder, the hard disc and floppy disc drive, and other magnetic media.\nBell's own home used a primitive form of air conditioning, in which fans blew currents of air across great blocks of ice. He also anticipated modern concerns with fuel shortages and industrial pollution. Methane gas, he reasoned, could be produced from the waste of farms and factories. At his Canadian estate in Nova Scotia, he experimented with composting toilets and devices to capture water from the atmosphere. In a magazine article published in 1917, he reflected on the possibility of using solar energy to heat houses.\nPhotophone.\nBell and his assistant Charles Sumner Tainter jointly invented a wireless telephone, named a photophone, which allowed for the transmission of both sounds and normal human conversations on a beam of light. Both men later became full associates in the Volta Laboratory Association.\nOn June 21, 1880, Bell's assistant transmitted a wireless voice telephone message a considerable distance, from the roof of the Franklin School in Washington, D.C., to Bell at the window of his laboratory, some away, 19 years before the first voice radio transmissions.\nBell believed the photophone's principles were his life's \"greatest achievement\", telling a reporter shortly before his death that the photophone was \"the greatest invention [I have] ever made, greater than the telephone\". The photophone was a precursor to the fiber-optic communication systems which achieved popular worldwide usage in the 1980s. Its master patent was issued in December 1880, many decades before the photophone's principles came into popular use.\nMetal detector.\nBell is also credited with developing one of the early versions of a metal detector through the use of an induction balance, after the shooting of U.S. President James A. Garfield in 1881. According to some accounts, the metal detector worked flawlessly in tests but did not find Guiteau's bullet, partly because the metal bed frame on which the President was lying disturbed the instrument, resulting in static. Garfield's surgeons, led by self-appointed chief physician Doctor Willard Bliss, were sceptical of the device, and ignored Bell's requests to move the President to a bed not fitted with metal springs. Alternatively, although Bell had detected a slight sound on his first test, the bullet may have been lodged too deeply to be detected by the crude apparatus.\nBell's own detailed account, presented to the American Association for the Advancement of Science in 1882, differs in several particulars from most of the many and varied versions now in circulation, by concluding that extraneous metal was not to blame for failure to locate the bullet. Perplexed by the peculiar results he had obtained during an examination of Garfield, Bell \"proceeded to the Executive Mansion the next morning\u00a0... to ascertain from the surgeons whether they were perfectly sure that all metal had been removed from the neighborhood of the bed. It was then recollected that underneath the horse-hair mattress on which the President lay was another mattress composed of steel wires. Upon obtaining a duplicate, the mattress was found to consist of a sort of net of woven steel wires, with large meshes. The extent of the [area that produced a response from the detector] having been so small, as compared with the area of the bed, it seemed reasonable to conclude that the steel mattress had produced no detrimental effect.\" In a footnote, Bell adds, \"The death of President Garfield and the subsequent \"post-mortem\" examination, however, proved that the bullet was at too great a distance from the surface to have affected our apparatus.\"\nHydrofoils.\nThe March 1906 \"Scientific American\" article by American pioneer William E. Meacham explained the basic principle of hydrofoils and hydroplanes. Bell considered the invention of the hydroplane as a very significant achievement. Based on information gained from that article, he began to sketch concepts of what is now called a hydrofoil boat. Bell and assistant Frederick W. \"Casey\" Baldwin began hydrofoil experimentation in the summer of 1908 as a possible aid to airplane takeoff from water. Baldwin studied the work of the Italian inventor Enrico Forlanini and began testing models. This led him and Bell to the development of practical hydrofoil watercraft.\nDuring his world tour of 1910\u201311, Bell and Baldwin met with Forlanini in France. They had rides in the Forlanini hydrofoil boat over Lake Maggiore. Baldwin described it as being as smooth as flying. On returning to Baddeck, a number of initial concepts were built as experimental models, including the \"Dhonnas Beag\" (Scottish Gaelic for 'little devil'), the first self-propelled Bell-Baldwin hydrofoil. The experimental boats were essentially proof-of-concept prototypes that culminated in the more substantial HD-4, powered by Renault engines. A top speed of was achieved, with the hydrofoil exhibiting rapid acceleration, good stability, and steering, along with the ability to take waves without difficulty.\nIn 1913, Dr. Bell hired Walter Pinaud, a Sydney yacht designer and builder as well as the proprietor of Pinaud's Yacht Yard in Westmount, Nova Scotia, to work on the pontoons of the HD-4. Pinaud soon took over the boatyard at Bell Laboratories on Beinn Bhreagh, Bell's estate near Baddeck, Nova Scotia. Pinaud's experience in boatbuilding enabled him to make useful design changes to the HD-4. After the First World War, work began again on the HD-4. Bell's report to the U.S. Navy permitted him to obtain two engines in July 1919. On September 9, 1919, the HD-4 set a world marine speed record of , a record which stood for ten years.\nAeronautics.\nIn 1891, Bell had begun experiments to develop motor-powered heavier-than-air aircraft. The AEA was first formed as Bell shared the vision to fly with his wife, who advised him to seek \"young\" help as Bell was at the age of 60.\nIn 1898, Bell experimented with tetrahedral box kites and wings constructed of multiple compound tetrahedral kites covered in maroon silk. The tetrahedral wings were named \"Cygnet\" I, II, and III, and were flown both unmanned and manned (\"Cygnet I\" crashed during a flight carrying Selfridge) in the period from 1907 to 1912. Some of Bell's kites are on display at the Alexander Graham Bell National Historic Site.\nBell was a supporter of aerospace engineering research through the Aerial Experiment Association (AEA), officially formed at Baddeck, Nova Scotia, in October 1907 at the suggestion of his wife Mabel and with her financial support after the sale of some of her real estate. The AEA was headed by Bell and the founding members were four young men: American Glenn H. Curtiss, a motorcycle manufacturer at the time and who held the title \"world's fastest man\", having ridden his self-constructed motor bicycle around in the shortest time, and who was later awarded the Scientific American Trophy for the first official one-kilometre flight in the Western hemisphere, and who later became a world-renowned airplane manufacturer; Lieutenant Thomas Selfridge, an official observer from the U.S. Federal government and one of the few people in the army who believed that aviation was the future; Frederick W. Baldwin, the first Canadian and first British subject to pilot a public flight in Hammondsport, New York; and J. A. D. McCurdy\u2013Baldwin and McCurdy being new engineering graduates from the University of Toronto.\nThe AEA's work progressed to heavier-than-air machines, applying their knowledge of kites to gliders. Moving to Hammondsport, the group then designed and built the \"Red Wing\", framed in bamboo and covered in red silk and powered by a small air-cooled engine. On March 12, 1908, over Keuka Lake, the biplane lifted off on the first public flight in North America. The innovations that were incorporated into this design included a cockpit enclosure and tail rudder (later variations on the original design would add ailerons as a means of control). One of the AEA's inventions, a practical wingtip form of the aileron, was to become a standard component on all aircraft. The \"White Wing\" and \"June Bug\" were to follow and by the end of 1908, over 150 flights without mishap had been accomplished. However, the AEA had depleted its initial reserves and only a $15,000 grant from Mrs. Bell allowed it to continue with experiments. Lt. Selfridge had also become the first person killed in a powered heavier-than-air flight in a crash of the Wright Flyer at Fort Myer, Virginia, on September 17, 1908.\nTheir final aircraft design, the \"Silver Dart\", embodied all of the advancements found in the earlier machines. On February 23, 1909, Bell was present as the \"Silver Dart\" flown by J. A. D. McCurdy from the frozen ice of Bras d'Or made the first aircraft flight in Canada. Bell had worried that the flight was too dangerous and had arranged for a doctor to be on hand. With the successful flight, the AEA disbanded and the \"Silver Dart\" would revert to Baldwin and McCurdy, who began the Canadian Aerodrome Company and would later demonstrate the aircraft to the Canadian Army.\nHeredity and genetics.\nBell, along with many members of the scientific community at the time, took an interest in the popular science of heredity which grew out of the publication of Charles Darwin's book \"On the Origin of Species\" in 1859. On his estate in Nova Scotia, Bell conducted meticulously recorded breeding experiments with rams and ewes. Over the course of more than 30 years, Bell sought to produce a breed of sheep with multiple nipples that would bear twins. He specifically wanted to see if selective breeding could produce sheep with four functional nipples with enough milk for twin lambs. This interest in animal breeding caught the attention of scientists focused on the study of heredity and genetics in humans.\nIn November 1883, Bell presented a paper at a meeting of the National Academy of Sciences titled \"Upon the Formation of a Deaf Variety of the Human Race\". The paper is a compilation of data on the hereditary aspects of deafness. Bell's research indicated that a hereditary tendency toward deafness, as indicated by the possession of deaf relatives, was an important element in determining the production of deaf offspring. He noted that the proportion of deaf children born to deaf parents was many times greater than the proportion of deaf children born to the general population. In the paper, Bell delved into social commentary and discussed hypothetical public policies to bring an end to deafness. He also criticized educational practices that segregated deaf children rather than integrating them fully into mainstream classrooms. The paper did not propose sterilization of deaf people or prohibition on intermarriage, noting that \"We cannot dictate to men and women whom they should marry and natural selection no longer influences mankind to any great extent.\"\nA review of Bell's \"Memoir upon the Formation of a Deaf Variety of the Human Race\" appearing in an 1885 issue of the \"American Annals of the Deaf and Dumb\" states that \"Dr. Bell does not advocate legislative interference with the marriages of the deaf for several reasons one of which is that the results of such marriages have not yet been sufficiently investigated.\" The article goes on to say that \"the editorial remarks based thereon did injustice to the author.\" The paper's author concludes by saying \"A wiser way to prevent the extension of hereditary deafness, it seems to us, would be to continue the investigations which Dr. Bell has so admirable begun until the laws of the transmission of the tendency to deafness are fully understood, and then by explaining those laws to the pupils of our schools to lead them to choose their partners in marriage in such a way that deaf-mute offspring will not be the result.\"\nHistorians have noted that Bell explicitly opposed laws regulating marriage, and never mentioned sterilization in any of his writings. Even after Bell agreed to engage with scientists conducting eugenic research, he consistently refused to support public policy that limited the rights or privileges of the deaf.\nBell's interest and research on heredity attracted the interest of Charles Davenport, a Harvard professor and head of the Cold Spring Harbor Laboratory. In 1906, Davenport, who was also the founder of the American Breeder's Association, approached Bell about joining a new committee on eugenics chaired by David Starr Jordan. In 1910, Davenport opened the Eugenics Records office at Cold Spring Harbor. To give the organization scientific credibility, Davenport set up a Board of Scientific Directors naming Bell as chairman. Other members of the board included Luther Burbank, Roswell H. Johnson, Vernon L. Kellogg, and William E. Castle.\nIn 1921, a Second International Congress of Eugenics was held in New York at the Museum of Natural History and chaired by Davenport. Although Bell did not present any research or speak as part of the proceedings, he was named as honorary president as a means to attract other scientists to attend the event. A summary of the event notes that Bell was a \"pioneering investigator in the field of human heredity\".\nDeath.\nBell died of complications arising from diabetes on August 2, 1922, at his private estate in Cape Breton, Nova Scotia, at age 75. Bell had also been affected by pernicious anemia. His last view of the land he had inhabited was by moonlight on his mountain estate at 2:00\u00a0a.m. While tending to him after his long illness, Mabel, his wife, whispered, \"Don't leave me.\" By way of reply, Bell signed \"no...\", lost consciousness, and died shortly after.\nOn learning of Bell's death, the Canadian Prime Minister, Mackenzie King, cabled Mrs. Bell, saying:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;My colleagues in the Government join with me in expressing to you our sense of the world's loss in the death of your distinguished husband. It will ever be a source of pride to our country that the great invention, with which his name is immortally associated, is a part of its history. On the behalf of the citizens of Canada, may I extend to you an expression of our combined gratitude and sympathy.\nBell's coffin was constructed of Beinn Bhreagh pine by his laboratory staff, lined with the same red silk fabric used in his tetrahedral kite experiments. To help celebrate his life, his wife asked guests not to wear black (the traditional funeral colour) while attending his service, during which soloist Jean MacDonald sang a verse of Robert Louis Stevenson's \"Requiem\":\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nUpon the conclusion of Bell's funeral, for one minute at 6:25\u00a0p.m. Eastern Time, \"every phone on the continent of North America was silenced in honor of the man who had given to mankind the means for direct communication at a distance\".\nAlexander Graham Bell was buried atop Beinn Bhreagh mountain, on his estate where he had resided increasingly for the last 35 years of his life, overlooking Bras d'Or Lake. He was survived by his wife Mabel, his two daughters, Elsie May and Marian, and nine of his grandchildren.\nLegacy and honours.\nHonours and tributes flowed to Bell in increasing numbers as his invention became ubiquitous and his personal fame grew. Bell received numerous honorary degrees from colleges and universities to the point that the requests almost became burdensome. During his life, he also received dozens of major awards, medals, and other tributes. These included statuary monuments to both him and the new form of communication his telephone created, including the Bell Telephone Memorial erected in his honour in \"Alexander Graham Bell Gardens\" in Brantford, Ontario, in 1917.\nA large number of Bell's writings, personal correspondence, notebooks, papers, and other documents reside in both the United States Library of Congress Manuscript Division (as the \"Alexander Graham Bell Family Papers\"), and at the Alexander Graham Bell Institute, Cape Breton University, Nova Scotia; major portions of which are available for online viewing.\nA number of historic sites and other marks commemorate Bell in North America and Europe, including the first telephone companies in the United States and Canada. Among the major sites are:\nIn 1880, Bell received the Volta Prize with a purse of 50,000 French francs (approximately US$ in today's currency) for the invention of the telephone from the French government. Among the luminaries who judged were Victor Hugo and Alexandre Dumas. The Volta Prize was conceived by Napoleon III in 1852, and named in honour of Alessandro Volta, with Bell becoming the second recipient of the grand prize in its history. Since Bell was becoming increasingly affluent, he used his prize money to create endowment funds (the 'Volta Fund') and institutions in and around Washington, D.C., the capital of the United States, including the Volta Laboratory Association (1880), also known as Volta Laboratory and as the Alexander Graham Bell Laboratory, which eventually led to the Volta Bureau (1887), a centre for studies on deafness, which remains in operation in the Georgetown neighborhood of Washington, D.C.\nThe Volta Laboratory became an experimental facility devoted to scientific discovery, and the very next year it improved Edison's phonograph by substituting wax for tinfoil as the recording medium and incising the recording rather than indenting it, key upgrades that Edison himself later adopted. The laboratory was also the site where he and his associate invented his \"proudest achievement\", \"the photophone\", the \"optical telephone\" which presaged fibre optical telecommunications while the Volta Bureau would later evolve into the Alexander Graham Bell Association for the Deaf and Hard of Hearing (the AG Bell), a centre for the research and pedagogy of deafness.\nIn partnership with Gardiner Greene Hubbard, Bell helped establish the publication \"Science\" during the early 1880s. In 1898, Bell was elected as the second president of the National Geographic Society, serving until 1903, and was primarily responsible for the extensive use of illustrations, including photography, in the magazine. He also served for many years as a Regent of the Smithsonian Institution (1898\u20131922). The French government conferred on him the decoration of the L\u00e9gion d'honneur (Legion of Honour); the Royal Society of Arts in London awarded him the Albert Medal in 1902; the University of W\u00fcrzburg, Bavaria, granted him a PhD, and he was awarded the Franklin Institute's Elliott Cresson Medal in 1912. He was one of the founders of the American Institute of Electrical Engineers in 1884 and served as its president from 1891 to 1892. Bell was later awarded the AIEE's Edison Medal in 1914 \"For meritorious achievement in the invention of the telephone\".\nThe \"bel\" (B) and the smaller \"decibel\" (dB) are units of measurement of sound pressure level (SPL) invented by Bell Labs and named after him. Since 1976, the IEEE's Alexander Graham Bell Medal has been awarded to honour outstanding contributions in the field of telecommunications.\nIn 1936, the US Patent Office declared Bell first on its list of the country's greatest inventors, leading to the US Post Office issuing a commemorative stamp honouring Bell in 1940 as part of its 'Famous Americans Series'. The First Day of Issue ceremony was held on October 28 in Boston, Massachusetts, the city where Bell spent considerable time on research and working with the deaf. The Bell stamp became very popular and sold out in little time. The stamp became, and remains to this day, the most valuable one of the series.\nThe 150th anniversary of Bell's birth in 1997 was marked by a special issue of commemorative \u00a31 banknotes from the Royal Bank of Scotland. The illustrations on the reverse of the note include Bell's face in profile, his signature, and objects from Bell's life and career: users of the telephone over the ages; an audio wave signal; a diagram of a telephone receiver; geometric shapes from engineering structures; representations of sign language and the phonetic alphabet; the geese which helped him to understand flight; and the sheep which he studied to understand genetics. Additionally, the Government of Canada honoured Bell in 1997 with a C$100 gold coin, in tribute also to the 150th anniversary of his birth, and with a silver dollar coin in 2009 in honour of the 100th anniversary of flight in Canada. That first flight was made by an airplane designed under Dr. Bell's tutelage, named the Silver Dart. Bell's image, and also those of his many inventions have graced paper money, coinage, and postal stamps in numerous countries worldwide for many dozens of years.\nAlexander Graham Bell was ranked 57th among the 100 Greatest Britons (2002) in an official BBC nationwide poll, and among the Top Ten Greatest Canadians (2004), and the 100 Greatest Americans (2005). In 2006, Bell was also named as one of the 10 greatest Scottish scientists in history after having been listed in the National Library of Scotland's 'Scottish Science Hall of Fame'. Bell's name is still widely known and used as part of the names of dozens of educational institutes, corporate namesakes, street and place names around the world.\nHonorary degrees.\nAlexander Graham Bell, who could not complete the university program of his youth, received at least a dozen honorary degrees from academic institutions, including eight honorary LL.D.s (Doctorate of Law), two Ph.D.s, a D.Sc., and an M.D.:\nBibliography.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "854", "revid": "10863197", "url": "https://en.wikipedia.org/wiki?curid=854", "title": "Anatolia", "text": "Peninsula of Turkey in Western Asia\nAnatolia (), also known as Asia Minor, is a peninsula in West Asia that makes up the majority of the land area of Turkey. It is the westernmost protrusion of Asia and is geographically bounded by the Mediterranean Sea to the south, the Aegean Sea to the west, the Turkish Straits to the northwest, and the Black Sea to the north. The eastern and southeastern limits have been expanded either to the entirety of Asiatic Turkey or to an imprecise line from the Black Sea to the Gulf of Alexandretta. Topographically, the Sea of Marmara connects the Black Sea with the Aegean Sea through the Bosporus and the Dardanelles, and separates Anatolia from Thrace in Southeast Europe.\nDuring the Neolithic, Anatolia was an early center for the development of farming after it originated in the adjacent Fertile Crescent. Beginning around 9,000 years ago, there was a major migration of Anatolian neolithic farmers into Europe, with their descendants coming to dominate the continent as far west as the Iberian Peninsula and the British Isles.\nThe earliest recorded inhabitants of Anatolia, such as the Hattians, who were neither Indo-European nor Semitic, were gradually absorbed by the incoming Indo-European Anatolian peoples, who spoke the now-extinct Anatolian languages. The major Anatolian languages included Hittite, Luwian, and Lydian; other local languages, albeit poorly attested, included Phrygian and Mysian. The Hurro-Urartian languages were spoken throughout Mitanni in the southeast, while Galatian, a Celtic language, was spoken throughout Galatia in the central peninsula. Among the other peoples who established a significant presence in ancient Anatolia were the Galatians, the Hurrians, the Assyrians, the Armenians, the Hattians, and the Cimmerians, as well as some of the ancient Greek tribes, including the Ionians, the Dorians, and the Aeolians. In the era of classical antiquity (see Classical Anatolia), the Anatolian languages were largely replaced by the Greek language, which came to dominate a large region during the Hellenistic period and the Roman period.\nThe Byzantine period saw the height and eventual decline of Greek influence throughout the peninsula as the Byzantine\u2013Seljuk wars enabled the incoming Seljuk Turks to establish a foothold in the region. Thus, the process of Anatolia's Turkification began under the Seljuk Empire in the late 11th century and continued under the Ottoman Empire until the early 20th century, when the Ottoman dynasty collapsed in the aftermath of World War I. Between 1894 and 1924, millions of non-Turkic peoples and Christians, especially Greeks (about two million) and Armenians (est. 1.2 million), were killed by the Ottoman Turkish authorities or expelled from the bulk of the area of modern-day Turkey. Nonetheless, a variety of non-Turkic languages continue to be spoken by ethnic minorities in Anatolia today, including Arabic, Kurdish, Neo-Aramaic, Armenian, the North Caucasian languages, Laz, Georgian, and Greek.\nGeography.\nTraditionally, Anatolia is considered to extend in the east to an indefinite line running from the Gulf of Alexandretta to the Black Sea, coterminous with the Anatolian Plateau. This traditional geographical definition is used, for example, in the latest edition of \"Merriam-Webster's Geographical Dictionary\". Under this definition, Anatolia is bounded to the east by the Armenian Highlands, and the Euphrates before that river bends to the southeast to enter Mesopotamia. To the southeast, it is bounded by the ranges that separate it from the Orontes valley in Syria and the Mesopotamian plain.\nFollowing the Armenian genocide, Western Armenia was renamed the Eastern Anatolia region by the newly established Turkish government. In 1941, with the First Geography Congress which divided Turkey into seven geographical regions based on differences in climate and landscape, the eastern provinces of Turkey were placed into the Eastern Anatolia region, which largely corresponds to the historical region of Western Armenia. Vazken Davidian terms the expanded use of \"Anatolia\" to apply to territory in eastern Turkey that was formerly referred to as \"Armenia\" (which had a sizeable Armenian population before the Armenian genocide) an \"ahistorical imposition\" and notes that a growing body of literature is uncomfortable with referring to the Ottoman East as \"Eastern Anatolia\".\nThe highest mountain in the Eastern Anatolia region (also the highest peak in the Armenian Highlands) is Mount Ararat (5123\u00a0m). The Euphrates, Aras, Karasu and Murat rivers connect the Armenian Highlands to the South Caucasus and the Upper Euphrates Valley. Along with the \u00c7oruh, these rivers are the longest in the Eastern Anatolia region.\nEtymology.\nThe English-language name \"Anatolia\" derives from the Greek () meaning \"the East\" and designating (from a Greek point of view) eastern regions in general. The Greek word refers to the direction where the sun rises, coming from \"anatello\" '(\u0399) rise up', comparable to terms in other languages such as \"levant\" from Latin 'to rise', \"orient\" from Latin 'to arise, to originate', Hebrew \"mizra\u1e25\" 'east' from \"zara\u1e25\" 'to rise, to shine', Aramaic \"midna\u1e25\" from \"dena\u1e25\" 'to rise, to shine'.\nThe use of Anatolian designations has varied over time, perhaps originally referring to the Aeolian, Ionian and Dorian colonies situated along the eastern coasts of the Aegean Sea, but also encompassing eastern regions in general. Such use of Anatolian designations was employed during the reign of Roman Emperor Diocletian (r.\u2009284\u00a0\u2013\u00a0305), who created the Diocese of the East, known in Greek as the Eastern Diocese, but completely unrelated to the regions of Asia Minor. In their widest territorial scope, Anatolian designations were employed during the reign of Roman Emperor Constantine\u00a0I (306\u2013337), who created the Praetorian prefecture of the East, known in Greek as the Eastern Prefecture, encompassing all eastern regions of the Late Roman Empire and spanning from Thrace to Egypt.\nOnly after the loss of other eastern regions during the 7th century and the reduction of Byzantine eastern domains to Asia Minor, that region became the only remaining part of the \"Byzantine East\", and thus commonly referred to (in Greek) as the Eastern part of the Empire. At the same time, the Anatolic Theme ( / \"the Eastern theme\") was created, as a province (\"theme\") covering the western and central parts of Turkey's present-day Central Anatolia Region, centered around Iconium, but ruled from the city of Amorium.\nThe Latinized form \"\", with its \"-ia\" ending, is probably a Medieval Latin innovation. The modern Turkish form derives directly from the Greek name (\"Anatol\u1e17\"). The Russian male name Anatoly, the French Anatole and plain Anatol, all stemming from saints Anatolius of Laodicea (d.\u00a0283) and Anatolius of Constantinople (d.\u00a0458; the first Patriarch of Constantinople), share the same linguistic origin.\nNames.\nThe oldest known name for any region within Anatolia is related to its central area, known as the \"Land of Hatti\" \u2013 a designation that was initially used for the land of ancient Hattians, but later became the most common name for the entire territory under the rule of ancient Hittites.\nThe first recorded name the Greeks used for the Anatolian peninsula, though not particularly popular at the time, was \u1f08\u03c3\u03af\u03b1 (\"As\u00eda\"), perhaps from an Akkadian expression for the \"sunrise\" or possibly echoing the name of the Assuwa league in western Anatolia. The Romans used it as the name of their province, comprising the west of the peninsula plus the nearby Aegean Islands. As the name \"Asia\" broadened its scope to apply to the vaster region east of the Mediterranean, some Greeks in Late Antiquity came to use the name Asia Minor (\u039c\u03b9\u03ba\u03c1\u1f70 \u1f08\u03c3\u03af\u03b1, \"Mikr\u00e0 As\u00eda\"), meaning \"Lesser Asia\" to refer to present-day Anatolia, whereas the administration of the Empire preferred the description \u1f08\u03bd\u03b1\u03c4\u03bf\u03bb\u03ae (\"Anatol\u1e17\"; lit.\u2009'the East').\nThe endonym \u1fec\u03c9\u03bc\u03b1\u03bd\u03af\u03b1 (\"R\u014dman\u00eda\" \"the land of the Romans, i.e. the Eastern Roman Empire\") was understood as another name for the province by the invading Seljuq Turks, who founded a Sultanate of R\u00fbm in 1077. Thus (land of the) R\u00fbm became another name for Anatolia. By the 12th century Europeans had started referring to Anatolia as \"Turchia\".\nDuring the era of the Ottoman Empire, many mapmakers referred to the mountainous plateau in eastern Anatolia as Armenia. Other contemporary sources called the same area Kurdistan. Geographers have used \"East Anatolian plateau\", \"Armenian plateau\" and the \"Iranian plateau\" to refer to the region; the former two largely overlap. While a standard definition of Anatolia refers to the entire Asian side of Turkey, according to archaeologist Lori Khatchadourian, this difference in terminology \"primarily result[s] from the shifting political fortunes and cultural trajectories of the region since the nineteenth century\".\nTurkey's First Geography Congress in 1941 created two geographical regions of Turkey to the east of the Gulf of Iskenderun-Black Sea line, the Eastern Anatolia region and the Southeastern Anatolia region, the former largely corresponding to the western part of the Armenian Highlands, the latter to the northern part of the Mesopotamian plain. According to Richard Hovannisian, this changing of toponyms was \"necessary to obscure all evidence\" of the Armenian presence as part of the policy of Armenian genocide denial embarked upon by the newly established Turkish government and what Hovannisian calls its \"foreign collaborators\".\nHistory.\nPrehistoric Anatolia.\nHuman habitation in Anatolia dates back to the Paleolithic. Neolithic settlements include \u00c7atalh\u00f6y\u00fck, \u00c7ay\u00f6n\u00fc, Nevali Cori, A\u015f\u0131kl\u0131 H\u00f6y\u00fck, Boncuklu H\u00f6y\u00fck, Hacilar, G\u00f6bekli Tepe, Nor\u015funtepe, K\u00f6\u015fk H\u00f6y\u00fck, and Yumuktepe. \u00c7atalh\u00f6y\u00fck (7,000 BCE) is considered the most advanced of these. Recent advances in archaeogenetics have confirmed that the spread of agriculture from the Middle East to Europe was strongly correlated with the migration of early farmers from Anatolia about 9,000 years ago, and was not just a cultural exchange. Anatolian Neolithic farmers derived most of their ancestry from local Anatolian hunter-gatherers, suggesting that agriculture was adopted in site by these hunter-gatherers and not spread by demic diffusion into the region. Anatolian-derived Neolithic Farmers would subsequently spread across Europe, as far west as the Iberian Peninsula and the British Isles, as well as to the Maghreb. Most modern Europeans derive a significant part of their ancestry from these Neolithic Anatolian farmers. Levantines also have significant Neolithic Anatolian farmer ancestry from post-Bronze Age migrations. About 6,500 years ago and thereafter, Anatolians became more genetically homogeneous due to eastern inflow. Earlier forms of Anatolian and non\u2013Indo-European languages such as Hattic and Hurrian were likely spoken by migrants and locals participating in this great mixture. Steppe ancestry is also absent in Anatolians until the Bronze Age.\nNeolithic Anatolia has been proposed as the homeland of the Indo-European language family, although linguists tend to favor a later origin in the steppes north of the Black Sea. However, it is clear that the Anatolian languages, the earliest attested branch of Indo-European, have been spoken in Anatolia since at least the 19th century BCE.\nAncient Anatolia.\nThe earliest historical data related to Anatolia appear during the Bronze Age and continue throughout the Iron Age. The most ancient period in the history of Anatolia spans from the emergence of ancient Hattians, up to the conquest of Anatolia by the Achaemenid Empire in the 6th century BCE.\nHattians and Hurrians.\nThe earliest historically attested populations of Anatolia were the Hattians in central Anatolia, and Hurrians further to the east. The Hattians were an indigenous people, whose main center was the city of Hattush. Affiliation of Hattian language remains unclear, while Hurrian language belongs to a distinctive family of Hurro-Urartian languages. All of those languages are extinct; relationships with indigenous languages of the Caucasus have been proposed, but are not generally accepted. The region became famous for exporting raw materials. Organized trade between Anatolia and Mesopotamia started to emerge during the period of the Akkadian Empire, and was continued and intensified during the period of the Old Assyrian Empire, between the 21st and the 18th centuries BCE. Assyrian traders were bringing tin and textiles in exchange for copper, silver or gold. Cuneiform records, dated c.\u200920th century BCE, found in Anatolia at the Assyrian colony of Kanesh, use an advanced system of trading computations and credit lines.\nHittite Anatolia (18th\u201312th centuries BCE).\nUnlike the Akkadians and Assyrians, whose Anatolian trading posts were peripheral to their core lands in Mesopotamia, the Hittites were centered at Hattusa (modern Bo\u011fazkale) in north-central Anatolia by the 17th century BCE. They were speakers of an Indo-European language, the Hittite language, or \"nesili\" (the language of Nesa) in Hittite. The Hittites originated from local ancient cultures that grew in Anatolia, in addition to the arrival of Indo-European languages. Attested for the first time in the Assyrian tablets of Nesa around 2,000 BCE, they conquered Hattusa in the 18th century BCE, imposing themselves over Hattian- and Hurrian-speaking populations. According to the widely accepted Kurgan theory on the Proto-Indo-European homeland, however, the Hittites (along with the other Indo-European ancient Anatolians) were themselves relatively recent immigrants to Anatolia from the north. However, they did not necessarily displace the population genetically; they assimilated into the former peoples' culture, preserving the Hittite language.\nThe Hittites adopted the Mesopotamian cuneiform script. In the Late Bronze Age, Hittite New Kingdom (c.\u20091650 BCE) was founded, becoming an empire in the 14th century BCE after the conquest of Kizzuwatna in the south-east and the defeat of the Assuwa league in western Anatolia. The empire reached its height in the 13th century BCE, controlling much of Asia Minor, northwestern Syria, and northwest upper Mesopotamia. However, the Hittite advance toward the Black Sea coast was halted by the semi-nomadic pastoralist and tribal Kaskians, a non-Indo-European people who had earlier displaced the Palaic-speaking Indo-Europeans. Much of the history of the Hittite Empire concerned war with the rival empires of Egypt, Assyria and the Mitanni.\nThe Ancient Egyptians eventually withdrew from the region after failing to gain the upper hand over the Hittites and becoming wary of the power of Assyria, which had destroyed the Mitanni Empire. The Assyrians and Hittites were then left to battle over control of eastern and southern Anatolia and colonial territories in Syria. The Assyrians had better success than the Egyptians, annexing much Hittite (and Hurrian) territory in these regions.\nPost-Hittite Anatolia (12th\u20136th centuries BCE).\nAfter 1180 BCE, during the Late Bronze Age collapse, the Hittite Empire disintegrated into several independent Syro-Hittite states, subsequent to losing much territory to the Middle Assyrian Empire and being finally overrun by the Phrygians, another Indo-European people who are believed to have migrated from the Balkans. The Phrygian expansion into southeast Anatolia was eventually halted by the Assyrians, who controlled that region.\nLuwians\nAnother Indo-European people, the Luwians, rose to prominence in central and western Anatolia c.\u20092,000 BCE. Their language belonged to the same linguistic branch as Hittite. The general consensus amongst scholars is that Luwian was spoken across a large area of western Anatolia, including (possibly) Wilusa (Troy), the Seha River Land (to be identified with the Hermos and/or Kaikos valley), and the kingdom of Mira-Kuwaliya with its core territory of the Maeander valley. From the 9th century BCE, Luwian regions coalesced into a number of states such as Lydia, Caria, and Lycia, all of which had Hellenic influence.\nArameans\nArameans encroached over the borders of south-central Anatolia in the century or so after the fall of the Hittite empire, and some of the Syro-Hittite states in this region became an amalgam of Hittites and Arameans. These became known as Syro-Hittite states.\nNeo-Assyrian Empire\nFrom the 10th to late 7th centuries BCE, much of Anatolia (particularly the southeastern regions) fell to the Neo-Assyrian Empire, including all of the Syro-Hittite states, Tabal, Commagene, the Cimmerians and Scythians, and swathes of Cappadocia.\nThe Neo-Assyrian empire collapsed due to a bitter series of civil wars followed by a combined attack by Medes, Persians, Scythians and their own Babylonian relations. The last Assyrian city to fall was Harran in southeast Anatolia. This city was the birthplace of the last king of Babylon, the Assyrian Nabonidus and his son and regent Belshazzar. Much of the region then fell to the short-lived Iran-based Median Empire, with the Babylonians and Scythians briefly appropriating some territory.\nCimmerian and Scythian invasions\nFrom the late 8th century BCE, a new wave of Indo-European-speaking raiders entered northern and northeast Anatolia: the Cimmerians and Scythians. The Cimmerians overran Phrygia and the Scythians threatened to do the same to Urartu and Lydia, before both were finally checked by the Assyrians.\nEarly Greek presence\nThe northwestern coast of Anatolia was inhabited by Greeks of the Achaean/Mycenaean culture from the 20th century BCE, related to the Greeks of southeastern Europe and the Aegean. Beginning with the Bronze Age collapse at the end of the 2nd millennium BCE, the west coast of Anatolia was settled by Ionian Greeks, usurping the area of the related but earlier Mycenaean Greeks. Over several centuries, numerous Ancient Greek city-states were established on the coasts of Anatolia. Greeks started Western philosophy on the western coast of Anatolia (Pre-Socratic philosophy).\nClassical Anatolia.\nIn Classical antiquity, Anatolia was described by the Ancient Greek historian Herodotus and later historians as divided into regions that were diverse in culture, language, and religious practices. The northern regions included Bithynia, Paphlagonia, and Pontus; to the west were Mysia, Lydia, and Caria; and Lycia, Pamphylia, and Cilicia belonged to the southern shore. There were also several inland regions: Phrygia, Cappadocia, Pisidia, and Galatia. Languages spoken included the late surviving Anatolic languages, Isaurian, and Pisidian, Greek in western and coastal regions, Phrygian spoken until the 7th century CE, local variants of Thracian in the northwest, the Galatian variant of Gaulish in Galatia until the 6th century CE, Cappadocian in the homonymous region, Armenian in the east, and Kartvelian languages in the northeast.\nAnatolia is known as the birthplace of minted coinage (as opposed to unminted coinage, which first appears in Mesopotamia at a much earlier date) as a medium of exchange, some time in the 7th century BCE in Lydia. The use of minted coins continued to flourish during the Greek and Roman eras.\nDuring the 6th century BCE, all of Anatolia was conquered by the Persian Achaemenid Empire, the Persians having usurped the Medes as the dominant dynasty of Persia. In 499 BCE, the Ionian city-states on the west coast of Anatolia rebelled against Persian rule. The Ionian Revolt, as it became known, though quelled, initiated the Greco-Persian Wars, which ended in a Greek victory in 449 BCE, and the Ionian cities regained their independence. By the Peace of Antalcidas (387 BCE), which ended the Corinthian War, Persia regained control over Ionia.\nIn 334 BCE, the Macedonian Greek king Alexander the Great conquered the Anatolian peninsula from the Achaemenid Persian Empire. Alexander's conquest opened up the interior of Asia Minor to Greek settlement and influence.\n Following the death of Alexander the Great and the subsequent breakup of the Macedonian Empire, Anatolia was ruled by a series of Hellenistic kingdoms, such as the Attalids of Pergamum and the Seleucids, the latter controlling most of Anatolia. A period of peaceful Hellenization followed, such that the local Anatolian languages had been supplanted by Greek by the 1st century BCE. In 133 BCE the last Attalid king bequeathed his kingdom to the Roman Republic; western and central Anatolia came under Roman control, but Hellenistic culture remained predominant.\nMithridates VI Eupator, ruler of the Kingdom of Pontus in northern Anatolia, waged war against the Roman Republic in the year 88 BCE in order to halt the advance of Roman hegemony in the Aegean Sea region. Mithridates VI sought to dominate Asia Minor and the Black Sea region, waging several hard-fought but ultimately unsuccessful wars (the Mithridatic Wars) to break Roman dominion over Asia and the Hellenic world. He has been called the greatest ruler of the Kingdom of Pontus. His ally and son-in-law, Tigranes the Great of Armenia (r.\u200995\u00a0\u2013\u00a055 BCE), briefly conquered significant portions of Anatolia, including Cilicia, Cappadocia, Sophene and perhaps Galatia. Further annexations by Rome, in particular of the Kingdom of Pontus by Pompey, brought all of Anatolia under Roman control, except for the southeastern frontier with the Parthian Empire, which remained unstable for centuries, causing a series of military conflicts that culminated in the Roman\u2013Parthian Wars (54 BCE \u2013 217 CE).\nEarly Christian period.\nAfter the first division of the Roman Empire, Anatolia became part of the Eastern Roman Empire, otherwise known as the Byzantine Empire or Byzantium. In the 1st century CE, Anatolia became one of the first places where Christianity spread, so that by the 4th century CE, western and central Anatolia were overwhelmingly Christian and Greek-speaking.\nByzantine Anatolia was one of the wealthiest and most densely populated places in the Later Roman Empire. Anatolia's wealth grew during the 4th and 5th centuries thanks, in part, to the Pilgrim's Road that ran through the peninsula. Literary evidence about the rural landscape stems from the Christian hagiographies of the 6th-century Nicholas of Sion and 7th-century Theodore of Sykeon. Large and prosperous urban centers of Byzantine Anatolia included Assos, Ephesus, Miletus, Nicaea, Pergamum, Priene, Sardis, and Aphrodisias.\nFrom the mid-5th century onwards, urbanism was affected negatively and began to decline, while the rural areas reached unprecedented levels of prosperity in the region. Historians and scholars continue to debate the cause of the urban decline in Byzantine Anatolia between the 6th and 7th centuries, variously attributing it to the Plague of Justinian (541), the Byzantine\u2013Sasanian War (602\u2013628), and the Arab invasion of the Levant (634\u2013638).\nMedieval period.\nIn the 10 years following the Battle of Manzikert in 1071, the Seljuk Turks from Central Asia migrated over large areas of Anatolia, with particular concentrations around the northwestern rim. The Turkish language and the Islamic religion were gradually introduced as a result of the Seljuk conquest, and this period marks the start of Anatolia's slow transition from predominantly Christian and Greek-speaking, to predominantly Muslim and Turkish-speaking (although ethnic groups such as Armenians, Greeks, and Assyrians remained numerous and retained Christianity and their native languages). In the following century, the Byzantines managed to reassert their control in western and northern Anatolia. Control of Anatolia was then split between the Byzantine Empire and the Seljuk Sultanate of R\u00fbm, with the Byzantine holdings gradually being reduced.\nIn 1255, the Mongols swept through eastern and central Anatolia, and would remain until 1335. The Ilkhanate garrison was stationed near Ankara. After the decline of the Ilkhanate from 1335 to 1353, the Mongol Empire's legacy in the region was the Uyghur Eretna Dynasty that was overthrown by Kadi Burhan al-Din in 1381.\nBy the end of the 14th century, most of Anatolia was controlled by various Anatolian beyliks. Smyrna fell in 1330, and the last Byzantine stronghold in Anatolia, Philadelphia, fell in 1390. The Turkmen Beyliks were under the control of the Mongols, at least nominally, through declining Seljuk Sultans. The Beyliks did not mint coins in the names of their own leaders while they remained under the suzerainty of the Mongol Ilkhanids. The Ottoman ruler Osman I was the first Turkish ruler who minted coins in his own name in 1320s; they bear the legend \"Minted by Osman son of Ertugrul\". Since the minting of coins was a prerogative accorded in Islamic practice only to a sovereign, it can be considered that the Ottoman Turks had become formally independent from the Mongol Khans.\nOttoman Empire.\nAmong the Turkish leaders, the Ottomans emerged as great power under Osman I and his son Orhan. The Anatolian beyliks were successively absorbed into the rising Ottoman Empire during the 15th century. It is not well understood how the Osmanl\u0131, or Ottoman Turks, came to dominate their neighbors, as the history of medieval Anatolia is still little known. The Ottomans completed the conquest of the peninsula in 1517 with the taking of Halicarnassus (modern Bodrum) from the Knights of Saint John.\nModern times.\nWith the acceleration of the decline of the Ottoman Empire in the early 19th century, and as a result of the expansionist policies of the Russian Empire in the Caucasus, many Muslim nations and groups in that region, mainly Circassians, Crimean Tatars, Azeris, Lezgis, Chechens, Muslim Georgians, Hamshenis and several Turkic groups left their homelands and settled in Anatolia. As the Ottoman Empire further shrank in the Balkan regions and then fragmented during the Balkan Wars, much of the non-Christian populations of its former possessions, mainly Balkan Muslims (Bosniaks, Albanians, Turks, Serb Muslims, Muslim Bulgarians and Greek Muslims such as the Vallahades from Greek Macedonia), were resettled in various parts of Anatolia, mostly in formerly Christian villages throughout Anatolia.\nA continuous reverse migration occurred since the early 19th century, when Greeks from Anatolia, Constantinople and Pontus area migrated toward the newly independent Kingdom of Greece, and also towards the United States, the southern part of the Russian Empire, Latin America, and the rest of Europe.\nFollowing the Russo-Persian Treaty of Turkmenchay (1828) and the incorporation of Eastern Armenia into the Russian Empire, another migration involved the large Armenian population of Anatolia, which recorded significant migration rates from Western Armenia (Eastern Anatolia) toward the Russian Empire, especially toward its newly established Armenian provinces.\nAnatolia remained multi-ethnic until the early 20th century (see the rise of nationalism under the Ottoman Empire). During World War I, the Armenian genocide, the Greek genocide (especially in Pontus), and the Assyrian genocide almost entirely removed the ancient indigenous communities of Armenian, Greek, and Assyrian populations in Anatolia and surrounding regions. Following the Greco-Turkish War of 1919\u20131922, most remaining ethnic Anatolian Greeks were forced out during the 1923 population exchange between Greece and Turkey. Of the remainder, most have left Turkey since then, leaving fewer than 5,000 Greeks in Anatolia today. According to Morris and Ze'evi, 4 million Christians were ethnically cleansed from Asia minor by the Turks from 1894 to 1924.\nGeology.\nAnatolia's terrain is structurally complex. A central massif composed of uplifted blocks and downfolded troughs, covered by recent deposits and giving the appearance of a plateau with rough terrain, is wedged between two folded mountain ranges that converge in the east. True lowland is confined to a few narrow coastal strips along the Aegean, Mediterranean, and the Black Sea coasts. Flat or gently sloping land is rare and largely confined to the deltas of the K\u0131z\u0131l River, the coastal plains of \u00c7ukurova and the valley floors of the Gediz River and the B\u00fcy\u00fck Menderes River as well as some interior high plains in Anatolia, mainly around Lake Tuz (Salt Lake) and the Konya Basin (\"Konya Ovasi\").\nThere are two mountain ranges in southern Anatolia: the Taurus and the Zagros Mountains.\nClimate.\nAnatolia has a varied range of climates. The central plateau is characterized by a continental climate, with hot summers and cold snowy winters. The south and west coasts enjoy a typical Mediterranean climate, with mild rainy winters, and warm dry summers. The Black Sea and Marmara coasts have a temperate oceanic climate, with warm, foggy summers and much rainfall throughout the year.\nEcoregions.\nThere is a diverse number of plant and animal communities.\nThe mountains and coastal plain of northern Anatolia experience a humid and mild climate. There are temperate broadleaf, mixed and coniferous forests. The central and eastern plateau, with its drier continental climate, has deciduous forests and forest steppes. Western and southern Anatolia, which have a Mediterranean climate, contain Mediterranean forests, woodlands, and scrub ecoregions.\nDemographics.\nThe largest provinces in Anatolia (aside from the Asian side of Istanbul) are Ankara, \u0130zmir, Bursa, Antalya, Konya, Adana, Kocaeli, Mersin, Manisa, Kayseri, Samsun, Bal\u0131kesir, Ayd\u0131n, Mara\u015f, Sakarya, Mu\u011fla, Denizli, Eski\u015fehir, Trabzon, Ordu, Afyon, Sivas, Tokat, Zonguldak, K\u00fctahya, \u00c7anakkale, Osmaniye and \u00c7orum. All have populations of more than 500,000.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nExplanatory notes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nSources.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "855", "revid": "279219", "url": "https://en.wikipedia.org/wiki?curid=855", "title": "Abiotic factors", "text": ""}
{"id": "856", "revid": "50849290", "url": "https://en.wikipedia.org/wiki?curid=856", "title": "Apple Inc.", "text": "American multinational technology company\nApple Inc. is an American multinational technology company headquartered in Cupertino, California, in Silicon Valley, best known for its consumer electronics, software and online services. Founded in 1976 as Apple Computer Company by Steve Jobs, Steve Wozniak and Ronald Wayne, the company was incorporated by Jobs and Wozniak as Apple Computer, Inc. the following year. It was renamed to its current name in 2007 as the company had expanded its focus from computers to consumer electronics. Apple has been described as a Big Tech company. \nThe company was founded to market Wozniak's Apple I personal computer. Its successor, the Apple II, became one of the first successful mass-produced microcomputers. Apple introduced the Lisa in 1983 and the Macintosh in 1984 as some of the first computers to use a graphical user interface and a mouse. By 1985, internal conflicts led to Jobs leaving the company to form NeXT and Wozniak withdrawing to other ventures; John Sculley served as CEO for over a decade. In the 1990s, Apple lost considerable market share in the personal computer industry to the lower-priced Wintel duopoly of Intel-powered PC clones running Microsoft Windows, and neared bankruptcy by 1997. To overhaul its market strategy, it acquired NeXT, bringing Jobs back to the company. Under his leadership, Apple returned to profitability by introducing the iMac, iPod, iPhone, and iPad devices; creating the iTunes Store; launching the \"Think different\" advertising campaign; and opening the Apple Store retail chain. Jobs resigned in 2011 for health reasons, and died two months later; he was succeeded as CEO by Tim Cook.\nApple's product lineup includes portable and home hardware like the iPhone, iPad, Apple Watch, Mac, and Apple TV; several in-house operating systems such as iOS, iPadOS, and macOS; and various software and services including Apple Pay and iCloud, as well as multimedia streaming services like Apple Music and Apple TV. Since 2011, Apple has for the most part been the world's largest company by market capitalization, and, as of 2024[ [update]], is the largest manufacturing company by revenue, the fourth-largest personal computer vendor, the largest vendor of tablet computers, and the largest vendor of mobile phones. Apple became the first publicly traded US company to be valued at over $1\u00a0trillion in 2018, and, as of \u00a02025[ [update]], is valued at just over $4 trillion.\nApple has received criticism regarding its contractors' labor conditions, its relationship with trade unions, its environmental practices, and its corporate ethics, including anti-competitive tactics, materials sourcing, and its acquisitions of smaller businesses. Nevertheless, the company has a large following and enjoys a high level of customer loyalty. It has consistently been ranked as one of the world's most valuable brands since the late 2000s.\nHistory.\n1976\u20131980: Founding and incorporation.\nApple Computer Company was founded on April 1, 1976, by Steve Jobs, Steve Wozniak, and Ronald Wayne as a partnership. The company's first product was the Apple I, a computer designed and hand-built entirely by Wozniak. To finance its creation, Jobs sold his Volkswagen Bus, and Wozniak sold his HP-65 calculator. Neither received the full selling price but in total earned $. Wozniak debuted the first prototype Apple I at the Homebrew Computer Club in July 1976. The Apple I was sold as a motherboard with CPU, RAM, and basic textual-video chips\u2014a base kit concept which was not yet marketed as a complete personal computer. It was priced soon after debut for $. Wozniak later said he was unaware of the coincidental mark of the beast in the number 666, and that he came up with the price because he liked \"repeating digits\".\nApple Computer, Inc. was incorporated in Cupertino, California, on January 3, 1977, without Wayne, who had left and sold his share of the company back to Jobs and Wozniak for $800 only twelve days after having co-founded it. Multimillionaire Mike Markkula provided essential business expertise and funding of $ to Jobs and Wozniak during the incorporation of Apple. During the first five years of operations, revenue grew exponentially, doubling about every four months. Between September 1977 and September 1980, yearly sales grew from $775,000 to US$\u00a0million, an average annual growth rate of 533%.\nThe Apple II, also designed by Wozniak, was introduced on April 16, 1977, at the first West Coast Computer Faire. It differs from its major rivals, the TRS-80 and Commodore PET, because of its character cell-based color graphics and open architecture. The Apple I and early Apple II models use ordinary audio cassette tapes as storage devices, which were superseded by the &lt;templatestyles src=\"Fraction/styles.css\" /&gt;5+1\u20444-inch floppy disk drive and interface called the Disk II in 1978.\nThe Apple II was chosen to be the desktop platform for the first killer application of the business world: VisiCalc, a spreadsheet program released in 1979. VisiCalc created a business market for the Apple II and gave home users an additional reason to buy an Apple II: compatibility with the office, but Apple II market share remained behind home computers made by competitors such as Atari, Commodore, and Tandy.\nOn December 12, 1980, Apple went public with an initial public offering (IPO) on the fully electronic Nasdaq stock market, selling 4.6 million shares at $22 per share ($.10 per share when adjusting for stock splits as of \u00a0, 2022[ [update]]), generating over $100\u00a0million, which was more capital than any IPO since Ford Motor Company in 1956. By the end of the day, around 300\u00a0millionaires were created, including Jobs and Wozniak, from a stock price of $29 per share and a market cap of $1.778\u00a0billion.\n1980\u20131990: Success with Macintosh.\nIn November and December 1979, Steve Jobs and Apple employees, including Jef Raskin, visited Xerox PARC, where they observed the Xerox Alto, featuring a graphical user interface (GUI) and a mouse. Jobs had negotiated with Xerox in advance to gain access to PARC's technology, in exchange for the right to purchase $1 million worth of Apple's pre-IPO shares. This visit influenced Jobs to implement a GUI in Apple's products, starting with the Apple Lisa. Despite being pioneering as a mass-marketed GUI computer, the Lisa suffered from high costs and limited software options, leading to commercial failure.\nJobs, infuriated by his removal from the Lisa team, joined the company's Macintosh division in January 1981. Raskin had envisioned the Macintosh as a low-cost, portable computer and Wozniak had helped its development until a plane crash in early 1981 forced him to step back from the project. Wozniak's absence allowed Jobs to quickly take over the project and he redefined the Macintosh as a graphical system that would be cheaper than the Lisa, undercutting his former division. Jobs was also hostile to the Apple II division, which at the time, generated most of the company's revenue.\nIn 1984, Apple launched the Macintosh, the first personal computer without a bundled programming language. Its debut was signified by \"1984\", a US$-million television advertisement directed by Ridley Scott that aired during the third quarter of Super Bowl XVIII on January 22, 1984. This was hailed as a watershed event for Apple's success and was called a \"masterpiece\" by CNN and one of the greatest TV advertisements of all time by \"TV Guide\".\nThe advertisement created great interest in the Macintosh, and sales were initially good, but began to taper off dramatically after the first three months as reviews started to come in. Jobs had required 128 kilobytes of RAM, which limited its speed and software in favor of aspiring for a projected price point of $. The Macintosh shipped for $, a price panned by critics due to its slow performance. In early 1985, this sales slump triggered a power struggle between Steve Jobs and CEO John Sculley, who had been hired away from Pepsi two years earlier by Jobs saying, \"Do you want to sell sugar water for the rest of your life or come with me and change the world?\" Sculley removed Jobs as the head of the Macintosh division, with unanimous support from the Apple board of directors.\nThe board of directors instructed Sculley to contain Jobs and his ability to launch expensive forays into untested products. Rather than submit to Sculley's direction, Jobs attempted to oust him from leadership. Jean-Louis Gass\u00e9e informed Sculley that Jobs had been attempting to organize a boardroom coup, and called an emergency meeting at which Apple's executive staff sided with Sculley, and stripped Jobs of all operational duties. Jobs resigned from Apple in September 1985 and took several Apple employees with him to found NeXT. Wozniak had also quit his active employment at Apple earlier in 1985 to pursue other ventures, expressing his frustration with Apple's treatment of the Apple II division and stating that the company had \"been going in the wrong direction for the last five years\". Wozniak remained employed by Apple as a representative, receiving a stipend estimated to be $120,000 per year. Jobs and Wozniak remained Apple shareholders following their departures.\nAfter the departures of Jobs and Wozniak in 1985, Sculley launched the Macintosh 512K that year with quadruple the RAM, and introduced the LaserWriter, the first reasonably priced PostScript-based laser printer. PageMaker, an early desktop publishing application taking advantage of the PostScript language, was also released by Aldus Corporation in July 1985. It has been suggested that the combination of Macintosh, LaserWriter, and PageMaker was responsible for the creation of the desktop publishing market.\nThis dominant position in the desktop publishing market allowed the company to focus on higher price points, the so-called \"high-right policy\" named for the position on a chart of price vs. profits. Newer models selling at higher price points offered higher profit margin, and appeared to have no effect on total sales as power users snapped up every increase in speed. Although some worried about pricing themselves out of the market, the high-right policy was in full force by the mid-1980s, due to Jean-Louis Gass\u00e9e's slogan of \"fifty-five or die\", referring to the 55% profit margins of the Macintosh II.\nThis policy began to backfire late in the decade as desktop publishing programs appeared on IBM PC compatibles with some of the same functionality of the Macintosh at far lower price points. The company lost its dominant position in the desktop publishing market and estranged many of its original consumer customer base who could no longer afford Apple products. The Christmas season of 1989 was the first in the company's history to have declining sales, which led to a 20% drop in Apple's stock price. During this period, the relationship between Sculley and Gass\u00e9e deteriorated, leading Sculley to effectively demote Gass\u00e9e in January 1990 by appointing Michael Spindler as the chief operating officer. Gass\u00e9e left the company later that year to set up a rival, Be Inc.\n1990\u20131997: Decline and restructuring.\nThe company pivoted strategy and, in October 1990, introduced three lower-cost models: the Macintosh Classic, the Macintosh LC, and the Macintosh IIsi, all of which generated significant sales due to pent-up demand. In 1991, Apple introduced the hugely successful PowerBook with a design that set the current shape for almost all modern laptops. The same year, Apple introduced System 7, a major upgrade to the Macintosh operating system, adding color to the interface and introducing new networking capabilities.\nThe success of the lower-cost Macs and the PowerBook brought increasing revenue. For some time, Apple was doing very well, introducing fresh new products at increasing profits. The magazine \"MacAddict\" named the period between 1989 and 1991 as the \"first golden age\" of the Macintosh.\nThe success of lower-cost consumer Macs, especially the LC, cannibalized higher-priced machines. To address this, management introduced several new brands, selling largely identical machines at different price points, for different markets: the high-end Quadra series, the mid-range Centris series, and the consumer-marketed Performa series. This led to significant consumer confusion between so many models.\nIn 1993, the Apple II series was discontinued. It was expensive to produce, and the company decided it was still absorbing sales from lower-cost Macintosh models. After the launch of the LC, Apple encouraged developers to create applications for Macintosh rather than Apple II, and authorized salespersons to redirect consumers from Apple II and toward Macintosh. The Apple IIe was discontinued in 1993.\nApple experimented with several other unsuccessful consumer targeted products during the 1990s, including QuickTake digital cameras, PowerCD portable CD audio players, speakers, the Pippin video game console, the eWorld online service, and Apple Interactive Television Box. Enormous resources were invested in the problematic Newton tablet division, based on John Sculley's unrealistic market forecasts.\nThroughout this period, Microsoft continued to gain market share with Windows by focusing on delivering software to inexpensive personal computers, while Apple was delivering a richly engineered but expensive experience. Apple relied on high profit margins and never developed a clear response; it sued Microsoft for making a GUI similar to the Lisa in \"Apple Computer, Inc. v. Microsoft Corp.\" The lawsuit dragged on for years and was finally dismissed. The major product flops and the rapid loss of market share to Windows sullied Apple's reputation, and in 1993 Sculley was replaced as CEO by Michael Spindler.\nUnder Spindler, Apple, IBM, and Motorola formed the AIM alliance in 1994 to create a new computing platform (the PowerPC Reference Platform or PReP), with IBM and Motorola hardware coupled with Apple software. The AIM alliance hoped that PReP's performance and Apple's software would leave the PC far behind and thus counter the dominance of Windows. That year, Apple introduced the Power Macintosh, the first of many computers with Motorola's PowerPC processor.\nIn the wake of the alliance, Apple opened up to the idea of allowing Motorola and other companies to build Macintosh clones. Over the next two years, 75 distinct Macintosh clone models were introduced. However, by 1996, Apple executives were worried that the clones were cannibalizing sales of its own high-end computers, where profit margins were highest.\nIn 1996, Spindler was replaced as CEO by Gil Amelio, who was hired for his reputation as a corporate rehabilitator. Amelio made deep changes, including extensive layoffs and cost-cutting.\nThis period was also marked by numerous failed attempts to modernize the Macintosh operating system (MacOS). The original Macintosh operating system (System 1) was not built for multitasking (running several applications at once). The company attempted to correct this by introducing cooperative multitasking in System 5, but still decided it needed a more modern approach. This led to the Pink project in 1988, A/UX that same year, Copland in 1994, and evaluated the purchase of BeOS in 1996. Talks with Be stalled when the CEO, former Apple executive Jean-Louis Gass\u00e9e, demanded $300\u00a0million in contrast to Apple's $125-million offer. Only weeks away from bankruptcy, Apple's board preferred NeXTSTEP and purchased NeXT in late 1996 for $400\u00a0million, retaining Steve Jobs.\n1997\u20132007: Return to profitability.\nThe NeXT acquisition was finalized on February 9, 1997, and the board brought Jobs back to Apple as an advisor. On July 9, 1997, Jobs staged a boardroom coup, which resulted in Amelio's resignation after overseeing a three-year record-low stock price and crippling financial losses. The board named Jobs as interim CEO and he immediately reviewed the product lineup. Jobs canceled 70% of models, ending 3,000 jobs and paring to the core of its computer offerings.\nThe next month, in August 1997, Steve Jobs convinced Microsoft to make a $150-million investment in Apple and a commitment to continue developing Mac software. This was seen as an \"antitrust insurance policy\" for Microsoft which had recently settled with the Department of Justice over anti-competitive practices in the \"United States v. Microsoft Corp.\" case. Around then, Jobs donated Apple's internal library and archives to Stanford University, to focus more on the present and the future rather than the past. He ended the Mac clone deals and in September 1997, purchased the largest clone maker, Power Computing. On November 10, 1997, the Apple Store website launched, which was tied to a new build-to-order manufacturing model similar to PC manufacturer Dell's success. The moves paid off for Jobs; at the end of his first year as CEO, the company had a $309-million profit.\nOn May 6, 1998, Apple introduced a new all-in-one computer reminiscent of the original Macintosh: the iMac. The iMac was a huge success, with 800,000 units sold in its first five months, and ushered in major shifts in the industry by abandoning legacy technologies like the &lt;templatestyles src=\"Fraction/styles.css\" /&gt;3+1\u20442-inch diskette, being an early adopter of the USB connector, and coming pre-installed with Internet connectivity (the \"i\" in iMac) via Ethernet and a dial-up modem. Its striking teardrop shape and translucent materials were designed by Jonathan Ive, who had been hired by Amelio, and who collaborated with Jobs for more than a decade to reshape Apple's product design.\nA little more than a year later on July 21, 1999, Apple introduced the iBook consumer laptop. It culminated Jobs's strategy to produce only four products: refined versions of the Power Macintosh G3 desktop and PowerBook G3 laptop for professionals, and the iMac desktop and iBook laptop for consumers. Jobs said the small product line allowed for a greater focus on quality and innovation.\nAround then, Apple also completed numerous acquisitions to create a portfolio of digital media production software for both professionals and consumers. Apple acquired Macromedia's Key Grip digital video editing software project, which was launched as Final Cut Pro in April 1999. Key Grip's development also led to Apple's release of the consumer video-editing product iMovie in October 1999. Apple acquired the German company Astarte in April 2000, which had developed the DVD authoring software DVDirector, which Apple repackaged as the professional-oriented DVD Studio Pro, and reused its technology to create iDVD for the consumer market. In 2000, Apple purchased the SoundJam MP audio player software from Casady &amp; Greene. Apple renamed the program iTunes, simplified the user interface and added CD burning.\nIn 2001, Apple changed course with three announcements. First, on March 24, 2001, Apple announced the release of a new modern operating system, Mac OS X. This was after numerous failed attempts in the early 1990s, and several years of development. Mac OS X is based on NeXTSTEP, OpenStep, and BSD Unix, to combine the stability, reliability, and security of Unix with the ease of use of an overhauled user interface. Second, in May 2001, the first two Apple Store retail locations opened in Virginia and California, offering an improved presentation of the company's products. At the time, many speculated that the stores would fail, but they became highly successful, and the first of more than 500 stores around the world. Third, on October 23, 2001, the iPod portable digital audio player debuted. The product was first sold on November 10, 2001, and was extremely successful, with over 100\u00a0million units sold within six years.\nIn 2003, the iTunes Store was introduced with music downloads for 99\u00a2 a song and iPod integration. It quickly became the market leader in online music services, with over 5\u00a0billion downloads by June 19, 2008. Two years later, the iTunes Store was the world's largest music retailer.\nIn 2002, Apple purchased Nothing Real for its advanced digital compositing application Shake, and Emagic for the music productivity application Logic. The purchase of Emagic made Apple the first computer manufacturer to own a music software company. The acquisition was followed by the development of Apple's consumer-level GarageBand application. The release of iPhoto that year completed the iLife suite.\nAt the Worldwide Developers Conference keynote address on June 6, 2005, Jobs announced that Apple would move away from PowerPC processors, and the Mac would transition to Intel processors in 2006. On January 10, 2006, the new MacBook Pro and iMac became the first Apple computers to use Intel's Core Duo CPU. By August 7, 2006, Apple made the transition to Intel chips for the entire Mac product line\u2014over one year sooner than announced. The Power Mac, iBook, and PowerBook brands were retired during the transition; the Mac Pro, MacBook, and MacBook Pro became their respective successors. Apple also introduced Boot Camp in 2006 to help users install Windows XP or Windows Vista on their Intel Macs alongside Mac OS X.\nApple's success during this period was evident in its stock price. Between early 2003 and 2006, the price of Apple's stock increased more than tenfold, from around $6 per share (split-adjusted) to over $80. When Apple surpassed Dell's market cap in January 2006, Jobs sent an email to Apple employees saying Dell's CEO Michael Dell should eat his words. Nine years prior, Dell had said that if he ran Apple he would \"shut it down and give the money back to the shareholders\".\n2007\u20132011: Success with mobile devices.\nDuring his keynote speech at the Macworld Expo on January 9, 2007, Jobs announced the renaming of Apple Computer, Inc. to Apple Inc., because the company had broadened its focus from computers to consumer electronics. This event also saw the announcement of the iPhone and the Apple TV. The company sold 270,000 first-generation iPhones during the first 30 hours of sales, and the device was called \"a game changer for the industry\".\nIn an article posted on Apple's website on February 6, 2007, Jobs wrote that Apple would be willing to sell music on the iTunes Store without digital rights management, thereby allowing tracks to be played on third-party players if record labels would agree to drop the technology. On April 2, 2007, Apple and EMI jointly announced the removal of DRM technology from EMI's catalog in the iTunes Store, effective in May 2007. Other record labels eventually followed suit and Apple published a press release in January 2009 to announce that all songs on the iTunes Store are available without their FairPlay DRM.\nIn July 2008, Apple launched the App Store to sell third-party applications for the iPhone and iPod Touch. Within a month, the store sold 60\u00a0million applications and registered an average daily revenue of $1\u00a0million, with Jobs speculating in August 2008 that the App Store could become a billion-dollar business for Apple. By October 2008, Apple was the third-largest mobile handset supplier in the world due to the popularity of the iPhone.\nOn January 14, 2009, Jobs announced in an internal memo that he would be taking a six-month medical leave of absence from Apple until the end of June 2009 and would spend the time focusing on his health. In the email, Jobs stated that \"the curiosity over my personal health continues to be a distraction not only for me and my family, but everyone else at Apple as well\", and explained that the break would allow the company \"to focus on delivering extraordinary products\". Though Jobs was absent, Apple recorded its best non-holiday quarter (Q1 FY 2009) during the recession, with revenue of $8.16\u00a0billion and profit of $1.21\u00a0billion.\nAfter years of speculation and multiple rumored \"leaks\", Apple unveiled a large screen, tablet-like media device known as the iPad on January 27, 2010. The iPad ran the same touch-based operating system as the iPhone, and all iPhone apps were compatible with the iPad. This gave the iPad a large app catalog on launch, though having very little development time before the release. Later that year on April 3, 2010, the iPad was launched in the US. It sold more than 300,000 units on its first day, and 500,000 by the end of the first week. In May 2010, Apple's market cap exceeded that of competitor Microsoft for the first time since 1989.\nIn June 2010, Apple released the iPhone 4, which introduced video calling using FaceTime, multitasking, and a new design with an exposed stainless steel frame as the phone's antenna system. Later that year, Apple again refreshed the iPod line by introducing a multi-touch iPod Nano, an iPod Touch with FaceTime, and an iPod Shuffle that brought back the clickwheel buttons of earlier generations. It also introduced the smaller, cheaper second-generation Apple TV which allowed the rental of movies and shows.\nOn January 17, 2011, Jobs announced in an internal Apple memo that he would take another medical leave of absence for an indefinite period to allow him to focus on his health. Chief operating officer Tim Cook assumed Jobs's day-to-day operations at Apple, although Jobs would still remain \"involved in major strategic decisions\". Apple became the most valuable consumer-facing brand in the world. In June 2011, Jobs surprisingly took the stage and unveiled iCloud, an online storage and syncing service for music, photos, files, and software which replaced MobileMe, Apple's previous attempt at content syncing. This would be the last product launch Jobs would attend before his death.\nOn August 24, 2011, Jobs resigned his position as CEO of Apple. He was replaced by Cook and Jobs became Apple's chairman. Apple did not have a chairman at the time and instead had two co-lead directors, Andrea Jung and Arthur D. Levinson, who continued with those titles until Levinson replaced Jobs as chairman of the board in November after Jobs's death.\n2011\u20132020: Post-Jobs era, new devices.\nOn October 5, 2011, Steve Jobs died, marking the end of an era for Apple. The next major product announcement by Apple was on January 19, 2012, when Apple's Phil Schiller introduced iBooks Textbooks for iOS and iBook Author for Mac OS X in New York City. Jobs stated in the biography \"Steve Jobs\" that he wanted to reinvent the textbook industry and education.\nFrom 2011 to 2012, Apple released the iPhone 4s and iPhone 5, which featured improved cameras, an intelligent software assistant named Siri, and cloud-synced data with iCloud; the third- and fourth-generation iPads, which featured Retina displays; and the iPad Mini, which featured a 7.9-inch screen in contrast to the iPad's 9.7-inch screen. These launches were successful, with the iPhone 5 (released September 21, 2012) becoming Apple's biggest iPhone launch with over two million pre-orders and sales of three million iPads in three days following the launch of the iPad Mini and fourth-generation iPad (released November 3, 2012). Apple also released a third-generation 13-inch MacBook Pro with a Retina display and new iMac and Mac Mini computers.\nOn August 20, 2012, Apple's rising stock price increased the company's market capitalization to a then-record $624\u00a0billion. This beat the non-inflation-adjusted record for market capitalization previously set by Microsoft in 1999. On August 24, 2012, a US jury ruled that Samsung should pay Apple $1.05\u00a0billion (\u00a3665m) in damages in an intellectual property lawsuit. Samsung appealed the damages award, which was reduced by $450\u00a0million and further granted Samsung's request for a new trial. On November 10, 2012, Apple confirmed a global settlement that dismissed all existing lawsuits between Apple and HTC up to that date, in favor of a ten-year license agreement for current and future patents between the two companies. It is predicted that Apple will make US$\u00a0million per year from this deal with HTC.\nIn May 2014, Apple confirmed its intent to acquire Dr. Dre and Jimmy Iovine's audio company Beats Electronics, producer of the \"Beats by Dr. Dre\" line of headphones and speaker products, and operator of the music streaming service Beats Music, for US$\u00a0billion, and to sell their products through Apple's retail outlets and resellers. Iovine believed that Beats had always \"belonged\" with Apple, as the company modeled itself after Apple's \"unmatched ability to marry culture and technology\". The acquisition was the largest purchase in Apple's history.\nDuring a press event on September 9, 2014, Apple introduced a smartwatch called the Apple Watch. Initially, Apple marketed the device as a fashion accessory and a complement to the iPhone, that would allow people to look at their smartphones less. Over time, the company has focused on developing health and fitness-oriented features on the watch, in an effort to compete with dedicated activity trackers. In January 2016, Apple announced that over one billion Apple devices were in active use worldwide.\nOn June 6, 2016, \"Fortune\" released Fortune 500, its list of companies ranked on revenue generation. In the trailing fiscal year of 2015, Apple was listed as the top tech company. It ranked third, overall, with US$\u00a0billion in revenue. This represents a movement upward of two spots from the previous year's list.\nIn June 2017, Apple announced the HomePod, its smart speaker aimed to compete against Sonos, Google Home, and Amazon Echo. Toward the end of the year, \"TechCrunch\" reported that Apple was acquiring Shazam, a company that introduced its products at WWDC and specializing in music, TV, film and advertising recognition. The acquisition was confirmed a few days later, reportedly costing Apple US$\u00a0million, with media reports that the purchase looked like a move to acquire data and tools bolstering the Apple Music streaming service. The purchase was approved by the European Union in September 2018.\nAlso in June 2017, Apple appointed Jamie Erlicht and Zack Van Amburg to head the newly formed worldwide video unit. In November 2017, Apple announced it was branching out into original scripted programming: a drama series starring Jennifer Aniston and Reese Witherspoon, and a reboot of the anthology series \"Amazing Stories\" with Steven Spielberg. In June 2018, Apple signed the Writers Guild of America's minimum basic agreement and Oprah Winfrey to a multi-year content partnership. Additional partnerships for original series include Sesame Workshop and DHX Media and its subsidiary Peanuts Worldwide, and a partnership with A24 to create original films.\nDuring the Apple Special Event in September 2017, the AirPower wireless charger was announced alongside the iPhone X, iPhone 8, and Watch Series 3. The AirPower was intended to wirelessly charge multiple devices, simultaneously. Though initially set to release in early 2018, the AirPower would be canceled in March 2019, marking the first cancellation of a device under Cook's leadership. On August 19, 2020, Apple's share price briefly topped $467.77, making it the first US company with a market capitalization of US$\u00a0trillion.\n2020\u20132024: Transition from Intel CPUs, legal compliance and settlements.\nDuring its annual WWDC keynote speech on June 22, 2020, Apple announced it would move away from Intel processors, and the Mac would transition to processors developed in-house. The announcement was expected by industry analysts, and it has been noted that Macs featuring Apple's processors would allow for big increases in performance over current Intel-based models. On November 10, 2020, the MacBook Air, MacBook Pro, and the Mac Mini became the first Macs powered by an Apple-designed processor, the Apple M1.\nIn April 2022, it was reported that Samsung Electro-Mechanics would be collaborating with Apple on its M2 chip instead of LG Innotek. Developer logs showed that at least nine Mac models with four different M2 chips were being tested.\n\"The Wall Street Journal\" reported that Apple's effort to develop its own chips left it better prepared to deal with the semiconductor shortage that emerged during the COVID-19 pandemic, which led to increased profitability, with sales of M1-based Mac computers rising sharply in 2020 and 2021. It also inspired other companies like Tesla, Amazon, and Meta Platforms to pursue a similar path.\nIn April 2022, Apple opened an online store that allowed anyone in the US to view repair manuals and order replacement parts for specific recent iPhones, although the difference in cost between this method and official repair is anticipated to be minimal.\nIn May 2022, a trademark was filed for RealityOS, an operating system reportedly intended for virtual and augmented reality headsets, first mentioned in 2017. According to Bloomberg, the headset may come out in 2023. Further insider reports state that the device uses iris scanning for payment confirmation and signing into accounts. In June 2023, Apple formally announced its first mixed reality headset, the Apple Vision Pro, which ran its new visionOS operating system. The headset was released in February of the following year.\nOn June 18, 2022, the Apple Store in Towson, Maryland, became the first to unionize in the US, with the employees voting to join the International Association of Machinists and Aerospace Workers.\nOn July 7, 2022, Apple added Lockdown Mode to macOS 13 and iOS 16, as a response to the earlier Pegasus revelations; the mode increases security protections for high-risk users against targeted zero-day malware.\nApple launched a buy now, pay later service called 'Apple Pay Later' for its Apple Wallet users in March 2023. The program allows its users to apply for loans between $50 and $1,000 to make online or in-app purchases and then repaying them through four installments spread over six weeks without any interest or fees.\nIn November 2023, Apple agreed to a $25-million settlement in a US Department of Justice case that alleged Apple was discriminating against US citizens in hiring. Apple created jobs that were not listed online and that required a paper submission application, while advertising these jobs to foreign workers as part of recruitment for PERM.\nIn January 2024, Apple announced compliance with the European Union's competition law, with major changes to the App Store and other services, effective on March 7. This enables iOS users in the 27-nation bloc to use alternative app stores, and alternative payment methods within apps. This adds a menu in Safari for downloading alternative browsers, such as Chrome or Firefox.\nIn June 2024, Apple introduced Apple Intelligence to incorporate on-device artificial intelligence (AI) capabilities.\nOn November 1, 2024, Apple announced its acquisition of Pixelmator, a company known for its image editing applications for iPhone and Mac. Apple had previously showcased Pixelmator's apps during its product launches, including naming Pixelmator Pro its Mac App of the Year in 2018 for its innovative use of machine learning and AI. In the announcement, Pixelmator stated that there would be no significant changes to its existing apps following the acquisition.\nOn December 31, 2024, a preliminary settlement was filed in the Oakland California federal court that accused Apple of unlawfully recording private conversations, through unintentional Siri activations, and of sharing them with third parties, including advertisers. Apple agreed to a $95-million cash settlement to resolve this lawsuit in which its Siri assistant violated user privacy. While denying any wrongdoing, Apple settled the case, allowing affected users to potentially claim up to $20 per device. Attorneys sought $28.5 million in fees from the settlement fund.\n2025\u2013present: Domestic investment, integrating AI capabilities into products and challenges.\nIn 2025, Apple undertook its largest investment initiative to date, announcing a commitment to spend over $500 billion in the United States over the following four years. This extensive strategy includes the opening of a new manufacturing facility in Houston to produce servers supporting Apple Intelligence, expansion of research and development in fields like silicon engineering and AI, and the establishment of a new advanced manufacturing academy in Detroit. The company also pledged to double its US Advanced Manufacturing Fund and increase collaboration with American suppliers, aiming to create tens of thousands of jobs related to R&amp;D, AI, and manufacturing technologies.\nThe software landscape at Apple underwent a transformation in 2025. At its Worldwide Developers Conference (WWDC), Apple introduced the new \"Liquid Glass\" design language, rolled out unified system design updates across iOS 26, iPadOS 26, macOS Tahoe 26, and other platforms, and significantly expanded the capabilities of \"Apple Intelligence\", the company's personal AI system. These updates aimed to address previous criticisms of fragmented interfaces, and use on-device and cloud-based AI to improve privacy and user experience.\nDespite continued growth in its services sector, including a new all-time high for services revenue in the March quarter and the launch of updated models such as the iPhone 16e and M4 MacBook Air, Apple faced significant challenges. The company contended with a 19% decline in stock value year-to-date, ongoing antitrust investigations by the US Department of Justice, and legal disputes involving the App Store. Competition in the AI space escalated, with rivals gaining ground. High-profile departures and political tensions, including calls for Apple to manufacture iPhones domestically or face tariffs, added to the pressure, making 2025 one of the most challenging years for CEO Tim Cook.\nProducts.\nSince the company's founding and into the early 2000s, Apple primarily sold computers, which are marketed as Macintosh since the mid-1980s. Since then, the company has expanded its product categories to include various portable devices, starting with the now discontinued iPod (2001), and later with the iPhone (2007) and iPad (2010). Apple also sells several other products that it categorizes as \"Wearables, Home and Accessories\", such as the Apple Watch, Apple TV, AirPods, HomePod, and Apple Vision Pro.\nApple devices have been praised for creating a cohesive ecosystem when used in conjunction with other Apple products, though have received criticism for not functioning as well or with as many features when used with competitive devices and instead often relying on Apple's proprietary features, software, and services to work as intended by Apple, an approach often described as \"walled garden\". As of 2023, there are over 2 billion Apple devices in active use worldwide.\nMac.\nMac, which is short for Macintosh, its official name until 1999, is Apple's line of personal computers that use the company's proprietary macOS operating system. Personal computers were Apple's original business line, but as of the end of 2024[ [update]] they account for only about eight percent of the company's revenue.\nThere are six Mac computer families in production:\nMacs use Apple silicon chips, run the macOS operating system, and include Apple software like the Safari web browser, iMovie for home movie editing, GarageBand for music creation, and the iWork productivity suite. Apple also sells pro apps: Final Cut Pro for video production, Logic Pro for musicians and producers, and Xcode for software developers. Apple also sells a variety of accessories for Macs, including the Pro Display XDR, Apple Studio Display, Magic Mouse, Magic Trackpad, and Magic Keyboard.\niPhone.\nThe iPhone is Apple's line of smartphones, which run the iOS operating system. The first iPhone was unveiled by Steve Jobs on January 9, 2007. Since then, new iPhone models have been released every year. When it was introduced, its multi-touch screen was described as \"revolutionary\" and a \"game-changer\" for the mobile phone industry. The device has been credited with creating the app economy.\niOS is one of the two major smartphone platforms in the world, alongside Android. The iPhone has generated large profits for the company, and is credited with helping to make Apple one of the world's most valuable publicly traded companies. As of the end of 2024[ [update]], the iPhone accounts for nearly half of the company's revenue.\niPad.\nThe iPad is Apple's line of tablets which run iPadOS. The first-generation iPad was announced on January 27, 2010. The iPad is mainly marketed for consuming multimedia, creating art, working on documents, videoconferencing, and playing games. The iPad lineup consists of several base iPad models, and the smaller iPad Mini, upgraded iPad Air, and high-end iPad Pro. Apple has consistently improved the iPad's performance, with the iPad Pro adopting the same M1 and M2 chips as the Mac; but the iPad still receives criticism for its limited OS.\nAs of September\u00a02020,[ [update]] Apple has sold more than 500\u00a0million iPads, though sales peaked in 2013. The iPad still remains the most popular tablet computer by sales as of the second quarter of 2020[ [update]], and accounted for seven percent of the company's revenue as of the end of 2024[ [update]]. Apple sells several iPad accessories, including the Apple Pencil, Smart Keyboard, Smart Keyboard Folio, Magic Keyboard, and several adapters.\nOther products.\nApple makes several other products that it categorizes as \"Wearables, Home and Accessories\". These products include the AirPods line of wireless headphones, Apple TV digital media players, Apple Watch smartwatches, Beats headphones, HomePod smart speakers, and the Vision Pro mixed reality headset. As of the end of 2024[ [update]], this broad line of products comprises about ten percent of the company's revenues.\nServices.\nApple offers a broad line of services, including advertising in the App Store and Apple News app, the AppleCare+ extended warranty plan, the iCloud+ cloud-based data storage service, payment services through the Apple Card credit card and the Apple Pay processing platform, digital content services including Apple Books, Apple Fitness+, Apple Music, Apple News+, Apple TV (formerly TV+), and the iTunes Store. Apple also provides Apple One, which is a bundle of these services. As of the end of 2024[ [update]], services comprise about 26% of the company's revenue. In 2019, Apple announced it would be making a concerted effort to expand its service revenues.\nMarketing.\nBranding.\nAccording to Steve Jobs, the company's name was inspired by his visit to an apple farm while on a fruitarian diet. Apple's first logo, designed by Ron Wayne, depicts Sir Isaac Newton sitting under an apple tree. It was almost immediately replaced by Rob Janoff's \"rainbow Apple\", the now-familiar rainbow-colored silhouette of an apple with a bite taken out of it. This logo has been erroneously referred to as a tribute to Alan Turing, with the bite mark a reference to his method of suicide. \nOn August 27, 1999, Apple officially dropped the rainbow scheme and began to use monochromatic logos nearly identical in shape to the previous rainbow incarnation. An Aqua-themed version of the monochrome logo was used from 1997 until 2003, and a glass-themed version was used from 2007 until 2013.\nApple evangelists were actively engaged by the company at one time, but this was after the phenomenon had already been firmly established. Apple evangelist Guy Kawasaki has called the brand fanaticism \"something that was stumbled upon\", while Jonathan Ive claimed in 2014 that \"people have an incredibly personal relationship\" with Apple's products.\n\"Fortune\" magazine named Apple the most admired company in the United States in 2008, and in the world from 2008 to 2012. On September 30, 2013, Apple surpassed Coca-Cola to become the world's most valuable brand in the Omnicom Group's \"Best Global Brands\" report. Boston Consulting Group has ranked Apple as the world's most innovative brand every year as of 2005[ [update]]. As of January\u00a02021,[ [update]] 1.65 billion Apple products were in active use. In February 2023, that number exceeded 2 billion devices. In 2023, the World Intellectual Property Organization's Madrid Yearly Review ranked Apple's number of trademark applications, filled under the Madrid System, as 10th in the world, with 74 trademark applications submitted during 2023.\nApple was ranked the No. 3 company in the world in the 2024 \"Fortune 500\" list.\nAdvertising.\nApple's first slogan, \"Byte into an Apple\", was coined in the late 1970s. From 1997 to 2002, the slogan \"Think different\" was used in advertising campaigns, and is still closely associated with Apple. Apple also has slogans for specific product lines\u2014for example, \"iThink, therefore iMac\" was used in 1998 to promote the iMac, and \"Say hello to iPhone\" has been used in iPhone advertisements. \"Hello\" was also used to introduce the original Macintosh, Newton, iMac (\"hello (again)\"), and iPod.\nFrom the introduction of the Macintosh in 1984, with the 1984 Super Bowl advertisement to the more modern Get a Mac adverts, Apple has been recognized for its efforts toward effective advertising and marketing for its products. However, claims made by later campaigns were criticized, particularly the 2005 Power Mac ads. Apple's product advertisements gained significant attention as a result of their eye-popping graphics and catchy tunes. Musicians who benefited from an improved profile as a result of their songs being included on Apple advertisements include Canadian singer Feist with the song \"1234\" and Yael Na\u00efm with the song \"New Soul\".\nStores.\nThe first Apple Stores were originally opened as two locations in May 2001 by then-CEO Steve Jobs, after years of attempting but failing store-within-a-store concepts. Seeing a need for improved retail presentation of the company's products, he began an effort in 1997 to revamp the retail program to get an improved relationship to consumers, and hired Ron Johnson in 2000. Jobs relaunched Apple's online store in 1997, and opened the first two physical stores in 2001. The media initially speculated that Apple would fail, but its stores were highly successful, exceeding the sales numbers of competing nearby stores, and within three years reached US$1 billion in annual sales, becoming the fastest retailer in history to do so.\nOver the years, Apple has expanded the number of retail locations and its geographical coverage, with 499 stores across 22 countries worldwide as of December\u00a02017[ [update]]. Strong product sales have placed Apple among the top-tier retail stores, with sales over $16 billion globally in 2011. Apple Stores underwent a period of significant redesign, beginning in May 2016. This redesign included physical changes to the Apple Stores, such as open spaces and re-branded rooms, and changes in function to facilitate interaction between consumers and professionals.\nMany Apple Stores are located inside shopping malls, but Apple has built several stand-alone \"flagship\" stores in high-profile locations. It has been granted design patents and received architectural awards for its stores' designs and construction, specifically for its use of glass staircases and cubes. The success of Apple Stores have had significant influence over other consumer electronics retailers, who have lost traffic, control and profits due to a perceived higher quality of service and products at Apple Stores. Due to the popularity of the brand, Apple receives a large number of job applications, many of which come from young workers. Although Apple Store employees receive above-average pay, are offered money toward education and health care, and receive product discounts, there are limited or no paths of career advancement.\nMarket power.\nOn March 16, 2020, France fined Apple \u20ac1.1 billion for colluding with two wholesalers to stifle competition and keep prices high by impeding independent resellers. The arrangement created aligned prices for Apple products such as iPads and personal computers for about half the French retail market. According to the French regulators, the abuses occurred between 2005 and 2017 but were first discovered after a complaint by an independent reseller, eBizcuss, in 2012.\nOn August 13, 2020, Epic Games, the maker of the popular game \"Fortnite\", sued both Apple and Google after \"Fortnite\" was removed from Apple's and Google's app stores. The lawsuits came after Apple and Google blocked the game after it introduced a direct payment system that bypassed the fees that Apple and Google had imposed. In September 2020, Epic Games founded the Coalition for App Fairness together with thirteen other companies, which aims for better conditions for the inclusion of apps in the app stores. Later, in December 2020, Facebook agreed to assist Epic in their legal game against Apple, planning to support the company by providing materials and documents to Epic. Facebook had, however, stated that the company would not participate directly with the lawsuit, although did commit to helping with the discovery of evidence relating to the trial of 2021. In the months prior to their agreement, Facebook had been dealing with feuds against Apple relating to the prices of paid apps and privacy rule changes. Head of ad products for Facebook Dan Levy commented, saying that \"this is not really about privacy for them, this is about an attack on personalized ads and the consequences it's going to have on small-business owners,\" commenting on the full-page ads placed by Facebook in various newspapers in December 2020.\nPrivacy.\nApple has publicly taken a pro-privacy stance, actively making privacy-conscious features and settings part of its conferences, promotional campaigns, and public image. With its iOS 8 mobile operating system in 2014, the company started encrypting all contents of iOS devices through users' passcodes, making it impossible at the time for the company to provide customer data to law enforcement requests seeking such information. With the popularity rise of cloud storage solutions, Apple began a technique in 2016 to do deep learning scans for facial data in photos on the user's local device and encrypting the content before uploading it to Apple's iCloud storage system. It also introduced \"differential privacy\", a way to collect crowdsourced data from many users, while keeping individual users anonymous, in a system that \"Wired\" described as \"trying to learn as much as possible about a group while learning as little as possible about any individual in it\". Users are explicitly asked if they want to participate, and can actively opt-in or opt-out.\nHowever, Apple has aided law enforcement in criminal investigations by providing iCloud backups of users' devices, and the company's commitment to privacy has been questioned by its efforts to promote biometric authentication technology in its newer iPhone models, which do not have the same level of constitutional privacy as a passcode in the United States.\nWith Apple's release of an update to iOS 14, Apple required all developers of iPhone, iPad, and iPod Touch applications to directly ask iPhone users permission to track them. The feature, called \"App Tracking Transparency\", received heavy criticism from Facebook, whose primary business model revolves around the tracking of users' data and sharing such data with advertisers so users can see more relevant ads, a technique commonly known as targeted advertising. After Facebook's measures, including purchasing full-page newspaper advertisements protesting App Tracking Transparency, Apple released the update in early 2021. A study by Verizon subsidiary Flurry Analytics reported only 4% of iOS users in the United States and 12% worldwide have opted into tracking.\nPrior to the release of iOS 15, Apple announced new efforts at combating child sexual abuse material on iOS and Mac platforms. Parents of minor iMessage users can now be alerted if their child sends or receives nude photographs. Additionally, on-device hashing would take place on media destined for upload to iCloud, and hashes would be compared to a list of known abusive images provided by law enforcement; if enough matches were found, Apple would be alerted and authorities informed. The new features received praise from law enforcement and victims rights advocates. However, privacy advocates, including the Electronic Frontier Foundation, condemned the new features as invasive and highly prone to abuse by authoritarian governments.\nIreland's Data Protection Commission launched a privacy investigation to examine whether Apple complied with the EU's GDPR law following an investigation into how the company processes personal data with targeted ads on its platform.\nIn December 2019, security researcher Brian Krebs discovered that the iPhone 11 Pro would still show the arrow indicator \u2013signifying location services are being used\u2013 at the top of the screen while the main location services toggle is enabled, despite all individual location services being disabled. Krebs was unable to replicate this behavior on older models and when asking Apple for comment, he was told by Apple that \"It is expected behavior that the Location Services icon appears in the status bar when Location Services is enabled. The icon appears for system services that do not have a switch in Settings.\"\nApple later further clarified that this behavior was to ensure compliance with ultra-wideband regulations in specific countries, a technology Apple started implementing in iPhones starting with iPhone 11 Pro, and emphasized that \"the management of ultra wideband compliance and its use of location data is done entirely on the device and Apple is not collecting user location data.\" Will Strafach, an executive at security firm Guardian Firewall, confirmed the lack of evidence that location data was sent off to a remote server. Apple promised to add a new toggle for this feature and in later iOS revisions Apple provided users with the option to tap on the location services indicator in Control Center to see which specific service is using the device's location.\nAccording to published reports by Bloomberg News on March 30, 2022, Apple turned over data such as phone numbers, physical addresses, and IP addresses to hackers posing as law enforcement officials using forged documents. The law enforcement requests sometimes included forged signatures of real or fictional officials. When asked about the allegations, an Apple representative referred the reporter to a section of the company policy for law enforcement guidelines, which stated, \"We review every data request for legal sufficiency and use advanced systems and processes to validate law enforcement requests and detect abuse.\"\nCorporate affairs.\nBusiness trends.\nThe key trends for Apple are, as of each financial year ending September 24:\nLeadership.\nSenior management.\nAs of \u00a03, 2025[ [update]], the management of Apple includes:\nBoard of directors.\nAs of \u00a03, 2025[ [update]], the board of directors of Apple includes:\nOwnership.\nAs of \u00a030, 2024[ [update]], the largest shareholders of Apple were:\nCorporate culture.\nApple is one of several highly successful companies founded in the 1970s that bucked the traditional notions of corporate culture. Jobs often walked around the office barefoot even after Apple became a Fortune 500 company. By the time of the \"1984\" television advertisement, Apple's informal culture had become a key trait that differentiated it from its competitors. According to a 2011 report in \"Fortune\", this has resulted in a corporate culture more akin to a startup rather than a multinational corporation. In a 2017 interview, Wozniak credited watching \"Star Trek\" and attending \"Star Trek\" conventions in his youth as inspiration for co-founding Apple.\nAs the company has grown and been led by a series of differently opinionated chief executives, some media have suggested that it has lost some of its original character. Nonetheless, it has maintained a reputation for fostering individuality and excellence that reliably attracts talented workers, particularly after Jobs returned. Numerous Apple employees have stated that projects without Jobs's involvement often took longer than others.\nThe Apple Fellows program awards employees for extraordinary technical or leadership contributions to personal computing. Recipients include Bill Atkinson, Steve Capps, Rod Holt, Alan Kay, Guy Kawasaki, Al Alcorn, Don Norman, Rich Page, Steve Wozniak, and Phil Schiller.\nJobs intended that employees were to be specialists who are not exposed to functions outside their area of expertise. For instance, Ron Johnson\u2014Senior Vice President of Retail Operations until November 1, 2011\u2014was responsible for site selection, in-store service, and store layout, yet had no control of the inventory in his stores. This was done by Tim Cook, who had a background in supply-chain management. Apple is known for strictly enforcing accountability. Each project has a \"directly responsible individual\" or \"DRI\" in Apple jargon. Unlike other major US companies, Apple provides a relatively simple compensation policy for executives that does not include perks enjoyed by other CEOs like country club fees or private use of company aircraft. The company typically grants stock options to executives every other year.\nIn 2015, Apple had 110,000\u00a0full-time employees. This increased to 116,000\u00a0full-time employees the next year, a notable hiring decrease, largely due to its first revenue decline. Apple does not specify how many of its employees work in retail, though its 2014 SEC filing put the number at approximately half of its employee base. In September 2017, Apple announced that it had over 123,000 full-time employees.\nApple has a strong culture of corporate secrecy, and has an anti-leak Global Security team that recruits from the National Security Agency, the Federal Bureau of Investigation, and the United States Secret Service. In December 2017, Glassdoor said Apple was the 48th best place to work, having originally entered at rank 19 in 2009, peaking at rank 10 in 2012, and falling down the ranks in subsequent years. In 2023, \"Bloomberg\"'s Mark Gurman revealed the existence of Apple's Exploratory Design Group (XDG), which was working to add glucose monitoring to the Apple Watch. Gurman compared XDG to Alphabet's X \"moonshot factory\".\nOffices.\nApple's world corporate headquarters are located in Cupertino, in the middle of California's Silicon Valley, at Apple Park, a massive circular groundscraper building with a circumference of . The building opened in April 2017 and houses more than 12,000 employees. Apple co-founder Steve Jobs wanted Apple Park to look less like a business park and more like a nature refuge, and personally appeared before the Cupertino City Council in June 2011 to make the proposal, in his final public appearance before his death.\nApple also operates from the Apple Campus (also known by its address, 1 Infinite Loop), a grouping of six buildings in Cupertino that total located about to the west of Apple Park. The Apple Campus was the company's headquarters from its opening in 1993, until the opening of Apple Park in 2017. The buildings, located at 1\u20136 Infinite Loop, are arranged in a circular pattern around a central green space, in a design that has been compared to that of a university.\nIn addition to Apple Park and the Apple Campus, Apple occupies an additional thirty office buildings scattered throughout the city of Cupertino, including three buildings as prior headquarters: Stephens Creek Three from 1977 to 1978, Bandley One from 1978 to 1982, and Mariani One from 1982 to 1993. In total, Apple occupies almost 40% of the available office space in the city.\nApple's headquarters for Europe, the Middle East and Africa (EMEA) are located in Cork in the south of Ireland, called the Hollyhill campus. The facility, which opened in 1980, houses 5,500 people and was Apple's first location outside of the United States. Apple's international sales and distribution arms operate out of the campus in Cork.\nApple has two campuses near Austin, Texas: a campus opened in 2014 houses 500 engineers who work on Apple silicon and a campus opened in 2021 where 6,000 people work in technical support, supply chain management, online store curation, and Apple Maps data management. The company also has several other locations in Boulder, Colorado; Culver City, California; Herzliya (Israel), London, New York, Pittsburgh, San Diego, and Seattle that each employ hundreds of people.\nLitigation.\nApple has been a participant in various legal proceedings and claims since it began operation. In particular, Apple is known for and promotes itself as actively and aggressively enforcing its intellectual property interests. Some litigation examples include \"Apple v. Samsung\", \"Apple v. Microsoft\", \"Motorola Mobility v. Apple Inc.\", and \"Apple Corps v. Apple Computer\". Apple has also had to defend itself against charges on numerous occasions of violating intellectual property rights. Most have been dismissed in the courts as shell companies known as patent trolls, with no evidence of actual use of patents in question. On December 21, 2016, Nokia announced that in the US and Germany, it has filed a suit against Apple, claiming that the latter's products infringe on Nokia's patents.\nMost recently, in November 2017, the United States International Trade Commission announced an investigation into allegations of patent infringement in regards to Apple's remote desktop technology; Aqua Connect, a company that builds remote desktop software, has claimed that Apple infringed on two of its patents.\nEpic Games filed lawsuit against Apple in August 2020 in the United States District Court for the Northern District of California, related to Apple's practices in the iOS App Store.\nIn January 2022, Ericsson sued Apple over payment of royalty of 5G technology. On June 24, 2024, the European Commission accused Apple of violating the Digital Markets Act by preventing \"app developers from freely steering consumers to alternative channels for offers and content\". In April 2025, Apple was found guilty and fined \u20ac500 million ($570 million) for violating the Digital Markets Act.\nLobbying.\nIn 2025, Apple was one of the donors who funded the White House's East Wing demolition, and planned building of a ballroom.\nFinances.\nAs of 2024, Apple was the world's fourth-largest personal computer vendor, the largest vendor of tablet computers, and the largest vendor of mobile phones.\nIn its fiscal year ending in September 2011, Apple reported a total of $108\u00a0billion in annual revenues\u2014a significant increase from its 2010 revenues of $65\u00a0billion\u2014and nearly $82\u00a0billion in cash reserves. On March 19, 2012, Apple announced plans for a $2.65-per-share dividend beginning in fourth quarter of 2012, per approval by their board of directors.\nThe company's worldwide annual revenue in 2013 totaled $170\u00a0billion. In May 2013, Apple entered the top ten of the \"Fortune\" 500 list of companies for the first time, rising 11 places above its 2012 ranking to take the sixth position. As of 2016[ [update]], Apple has around US$234\u00a0billion of cash and marketable securities, of which 90% is located outside the United States for tax purposes.\nApple amassed 65% of all profits made by the eight largest worldwide smartphone manufacturers in quarter one of 2014, according to a report by Canaccord Genuity. In the first quarter of 2015, the company garnered 92% of all earnings.\nOn April 30, 2017, \"The Wall Street Journal\" reported that Apple had cash reserves of $250\u00a0billion, officially confirmed by Apple as specifically $256.8\u00a0billion a few days later.\nAs of August\u00a03, 2018[ [update]], Apple was the largest publicly traded corporation in the world by market capitalization. On August 2, 2018, Apple became the first publicly traded US company to reach a $1\u00a0trillion market value, and, as of \u00a02024[ [update]], is valued at just over $4 trillion. Apple was ranked No. 4 on the 2018 \"Fortune\" 500 rankings of the largest United States corporations by revenue.\nIn July 2022, Apple reported an 11% decline in Q3 profits compared to 2021. Its revenue in the same period rose 2% year-on-year to $83 billion, though this figure was also lower than in 2021, where the increase was at 36%. The general downturn is reportedly caused by the slowing global economy and supply chain disruptions in China. That year, Apple was one of the largest corporate spenders on research and development worldwide, with R&amp;D expenditure amounting to over $27 billion.\nIn May 2023, Apple reported a decline in its sales for the first quarter of 2023. Compared to that of 2022, revenue for 2023 fell by 3%. This is Apple's second consecutive quarter of sales decline. This fall is attributed to the slowing economy and consumers putting off purchases of iPads and computers due to increased pricing. However, iPhone sales held up with a year-on-year increase of 1.5%. According to Apple, demands for such devices were strong, particularly in Latin America and South Asia.\nTaxes.\nApple has created subsidiaries in low-tax places such as Ireland, the Netherlands, Luxembourg, and the British Virgin Islands to cut the taxes it pays around the world. According to \"The New York Times\", in the 1980s Apple was among the first tech companies to designate overseas salespeople in high-tax countries in a manner that allowed the company to sell on behalf of low-tax subsidiaries on other continents, sidestepping income taxes. In the late 1980s, Apple was a pioneer of an accounting technique known as the \"Double Irish with a Dutch sandwich\", which reduces taxes by routing profits through Irish subsidiaries and the Netherlands and then to the Caribbean.\nBritish Conservative Party Member of Parliament Charlie Elphicke published research on October 30, 2012, which showed that some multinational companies, including Apple, were making billions of pounds of profit in the UK, but were paying an effective tax rate to the UK Treasury of only 3 percent, well below standard corporate tax rates. He followed this research by calling on the Chancellor of the Exchequer George Osborne to force these multinationals, which also included Google and The Coca-Cola Company, to state the effective rate of tax they pay on their UK revenues. Elphicke also said that government contracts should be withheld from multinationals who do not pay their fair share of UK tax.\nAccording to a US Senate report on the company's offshore tax structure concluded in May 2013, Apple has held billions of dollars in profits in Irish subsidiaries to pay little or no taxes to any government by using an unusual global tax structure. The main subsidiary, a holding company that includes Apple's retail stores throughout Europe, has not paid any corporate income tax in the last five years. \"Apple has exploited a difference between Irish and U.S. tax residency rules\", the report said. On May 21, 2013, Apple CEO Tim Cook defended his company's tax tactics at a Senate hearing.\nApple says that it is the single largest taxpayer in the US, with an effective tax rate of approximately of 26% as of Q2 FY2016. In an interview with the German newspaper \"FAZ\" in October 2017, Tim Cook stated that Apple was the biggest taxpayer worldwide.\nIn 2016, after a two-year investigation, the European Commission claimed that Apple's use of a hybrid Double Irish tax arrangement constituted \"illegal state aid\" from Ireland, and ordered Apple to pay \u20ac13 billion ($14.5 billion) in unpaid taxes, the largest corporate tax fine in history. This was later annulled, after the European General Court ruled that the commission had provided insufficient evidence. In 2018, Apple repatriated $285 billion to the United States, resulting in a $38-billion tax payment spread over the following eight years.\nCharity.\nApple is a partner of Product Red, a fundraising campaign for AIDS charity. In November 2014, Apple arranged for all App Store revenue in a two-week period to go to the fundraiser, generating more than US$20\u00a0million, and in March 2017, it released an iPhone 7 with a red color finish. As of 2021, Apple has donated over $250 million to Product Red.\nApple contributes financially to fundraisers in times of natural disasters. In November 2012, it donated $2.5\u00a0million to the American Red Cross to aid relief efforts after Hurricane Sandy, and in 2017 it donated $5\u00a0million to relief efforts for both Hurricane Irma and Hurricane Harvey, and for the 2017 Central Mexico earthquake. The company has used its iTunes platform to encourage donations in the wake of environmental disasters and humanitarian crises, such as the 2010 Haiti earthquake, the 2011 Japan earthquake, Typhoon Haiyan in the Philippines in November 2013, and the 2015 European migrant crisis. Apple emphasizes that it does not incur any processing or other fees for iTunes donations, sending 100% of the payments directly to relief efforts, though it also acknowledges that the Red Cross does not receive any personal information on the users donating and that the payments may not be tax deductible.\nOn April 14, 2016, Apple and the World Wide Fund for Nature (WWF) announced that they have engaged in a partnership to, \"help protect life on our planet\". Apple released a special page in the iTunes App Store, Apps for Earth. In the arrangement, Apple has committed that through April 24, WWF will receive 100% of the proceeds from the applications participating in the App Store via both the purchases of any paid apps and the In-App Purchases. Apple and WWF's Apps for Earth campaign raised more than $8\u00a0million in total proceeds to support WWF's conservation work. WWF announced the results at WWDC 2016 in San Francisco.\nDuring the COVID-19 pandemic, Apple's CEO Cook announced that the company will be donating \"millions\" of masks to health workers in the United States and Europe. On January 13, 2021, Apple announced a $100-million Racial Equity and Justice Initiative to help combat institutional racism worldwide after the 2020 murder of George Floyd. In June 2023, Apple announced doubling this and then distributed more than $200 million to support organizations focused on education, economic growth, and criminal justice. Half is philanthropic grants and half is centered on equity.\nEnvironment.\nApple Energy.\nApple Energy, LLC is a wholly owned subsidiary of Apple that sells solar energy. As of June\u00a06, 2016[ [update]], Apple's solar farms in California and Nevada have been declared to provide 217.9 megawatts of solar generation capacity. Apple has received regulatory approval to construct a landfill gas energy plant in North Carolina to use the methane emissions to generate electricity. Apple's North Carolina data center is already powered entirely by renewable sources.\nEnergy and resources.\nIn 2010, Climate Counts, a nonprofit organization dedicated to directing consumers toward the greenest companies, gave Apple a score of 52 points out of a possible 100, which puts Apple in their top category \"Striding\". This was an increase from May 2008, when Climate Counts only gave Apple 11 points out of 100, which placed the company last among electronics companies, at which time Climate Counts also labeled Apple with a \"stuck icon\", adding that Apple at the time was \"a choice to avoid for the climate-conscious consumer\".\nFollowing a Greenpeace protest, Apple released a statement on April 17, 2012, committing to ending its use of coal and shifting to 100% renewable clean energy. By 2013, Apple was using 100% renewable energy to power their data centers. Overall, 75% of the company's power came from clean renewable sources.\nIn May 2015, Greenpeace evaluated the state of the Green Internet and commended Apple on their environmental practices saying, \"Apple's commitment to renewable energy has helped set a new bar for the industry, illustrating in very concrete terms that a 100% renewable Internet is within its reach, and providing several models of intervention for other companies that want to build a sustainable Internet.\"\nAs of 2016[ [update]], Apple states that 100% of its US operations run on renewable energy, 100% of Apple's data centers run on renewable energy and 93% of Apple's global operations run on renewable energy. However, the facilities are connected to the local grid which usually contains a mix of fossil and renewable sources, so Apple carbon offsets its electricity use. The Electronic Product Environmental Assessment Tool (EPEAT) allows consumers to see the effect a product has on the environment. Each product receives a Gold, Silver, or Bronze rank depending on its efficiency and sustainability. Every Apple tablet, notebook, desktop computer, and display that EPEAT ranks achieves a Gold rating, the highest possible. Although Apple's data centers recycle water 35 times, the increased activity in retail, corporate and data centers also increase the amount of water use to in 2015.\nDuring an event on March 21, 2016, Apple provided a status update on its environmental initiative to be 100% renewable in all of its worldwide operations. Lisa P. Jackson, Apple's vice president of Environment, Policy and Social Initiatives who reports directly to CEO, Tim Cook, announced that as of March\u00a02016[ [update]], 93% of Apple's worldwide operations are powered with renewable energy. Also featured was the company's efforts to use sustainable paper in their product packaging; 99% of all paper used by Apple in the product packaging comes from post-consumer recycled paper or sustainably managed forests, as the company continues its move to all paper packaging for all of its products.\nApple announced on August 16, 2016, that Lens Technology, one of its major suppliers in China, has committed to power all its glass production for Apple with 100 percent renewable energy by 2018. The commitment is a large step in Apple's efforts to help manufacturers lower their carbon footprint in China. Apple also announced that all 14 of its final assembly sites in China are now compliant with UL's Zero Waste to Landfill validation. The standard, which started in January 2015, certifies that all manufacturing waste is reused, recycled, composted, or converted into energy (when necessary). Since the program began, nearly 140,000 metric tons of waste have been diverted from landfills.\nOn July 21, 2020, Apple announced its plan to become carbon neutral across its entire business, manufacturing supply chain, and product life cycle by 2030. In the next 10 years, Apple will try to lower emissions with a series of innovative actions, including: low carbon product design, expanding energy efficiency, renewable energy, process and material innovations, and carbon removal.\nIn June 2024, the United States Environmental Protection Agency (EPA) published a report about an electronic computer manufacturing facility leased by Apple in 2015 in Santa Clara, California, code named Aria. The EPA report stated that Apple was potentially in violation of federal regulations under the Resource Conservation and Recovery Act (RCRA). According to a report from \"Bloomberg\" in 2018, the facility is used to develop microLED screens under the code name T159. The inspection found that Apple was potentially mistreating waste as only subject to California regulations and that they had potentially miscalculated the effectiveness of Apple's activated carbon filters, which filter volatile organic compounds (VOCs) from the air. The EPA inspected the facility in August 2023 due to a tip from a former Apple employee who posted the report on X.\nToxins.\nFollowing further campaigns by Greenpeace, in 2008, Apple became the first electronics manufacturer to eliminate all polyvinyl chloride (PVC) and brominated flame retardants (BFRs) in its complete product line. In June 2007, Apple began replacing the cold cathode fluorescent lamp (CCFL) backlit LCD displays in its computers with mercury-free LED-backlit LCD displays and arsenic-free glass, starting with the upgraded MacBook Pro. Apple offers comprehensive and transparent information about the CO2e, emissions, materials, and electrical usage concerning every product they currently produce or have sold in the past (and which they have enough data needed to produce the report), in their portfolio on their homepage. Allowing consumers to make informed purchasing decisions on the products they offer for sale. In June 2009, Apple's iPhone 3GS was free of PVC, arsenic, and BFRs. Since 2009, all Apple products have mercury-free LED-backlit LCD displays, arsenic-free glass, and non-PVC cables. All Apple products have EPEAT Gold status and beat the latest Energy Star guidelines in each product's respective regulatory category.\nIn November 2011, Apple was featured in Greenpeace's Guide to Greener Electronics, which ranks electronics manufacturers on sustainability, climate and energy policy, and how \"green\" their products are. The company ranked fourth of fifteen electronics companies (moving up five places from the previous year) with a score of 4.6/10. Greenpeace praised Apple's sustainability, noting that the company exceeded its 70% global recycling goal in 2010. Apple continues to score well on product ratings, with all of their products now being free of PVC plastic and BFRs. However, the guide criticized Apple on the Energy criteria for not seeking external verification of its greenhouse gas emissions data, and for not setting any targets to reduce emissions. In January 2012, Apple requested that its cable maker, Volex, begin producing halogen-free USB and power cables.\nGreen bonds.\nIn February 2016, Apple issued a US$-billion green bond (climate bond), the first ever of its kind by a US tech company. The green bond proceeds are dedicated to the financing of environmental projects.\nSupply chain.\nApple products were made in the United States in Apple-owned factories until the late 1990s; however, as a result of outsourcing initiatives in the 2000s, almost all of its manufacturing is now handled abroad. According to a report by \"The New York Times\", Apple insiders \"believe the vast scale of overseas factories, as well as the flexibility, diligence and industrial skills of foreign workers, have so outpaced their American counterparts that 'Made in the U.S.A.' is no longer a viable option for most Apple products\".\nThe company's manufacturing, procurement, and logistics enable it to execute massive product launches without having to maintain large, profit-sapping inventories. In 2011, Apple's profit margins were 40 percent, compared with between 10 and 20 percent for most other hardware companies. Cook's catchphrase to describe his focus on the company's operational arm is: \"Nobody wants to buy sour milk.\"\nIn May 2017, the company announced a $1-billion funding project for \"advanced manufacturing\" in the United States, and subsequently invested $200\u00a0million in Corning Inc., a manufacturer of toughened Gorilla Glass technology used in Apple's iPhones. The following December, Apple's chief operating officer, Jeff Williams, told \"CNBC\" that the \"$1 billion\" amount was \"absolutely not\" the final limit on its spending, elaborating that \"We're not thinking in terms of a fund limit... We're thinking about, where are the opportunities across the U.S. to help nurture companies that are making the advanced technology \u2014 and the advanced manufacturing that goes with that \u2014 that quite frankly is essential to our innovation.\"\nDuring the Mac's early history, Apple generally refused to adopt prevailing industry standards for hardware, instead creating their own. This trend was largely reversed in the late 1990s, beginning with Apple's adoption of the PCI bus in the 7500/8500/9500 Power Macs. Apple has since joined the industry standards groups to influence the future direction of technology standards such as USB, AGP, HyperTransport, Wi-Fi, NVMe, PCIe and others in its products. FireWire is an Apple-originated standard that was widely adopted across the industry after it was standardized as IEEE 1394 and is a legally mandated port in all cable TV boxes in the United States.\nApple has gradually expanded its efforts in getting its products into the Indian market. In July 2012, during a conference call with investors, CEO Tim Cook said that he \"[loves] India\", but that Apple saw larger opportunities outside the region. India's requirement that 30% of products sold be manufactured in the country was described as \"really adds cost to getting product to market\". In May 2016, Apple opened an iOS app development center in Bangalore and a maps development office for 4,000 staff in Hyderabad. In March, \"The Wall Street Journal\" reported that Apple would begin manufacturing iPhone models in India \"over the next two months\", and in May, the \"Journal\" wrote that an Apple manufacturer had begun production of the iPhone SE in the country, while Apple told \"CNBC\" that the manufacturing was for a \"small number\" of units. In April 2019, Apple initiated manufacturing of the iPhone 7 at its Bengaluru facility, keeping in mind demand from local customers even as they seek more incentives from the government of India. At the beginning of 2020, Tim Cook announced that Apple schedules the opening of its first physical outlet in India for 2021, while an online store is to be launched by the end of the year. The opening of the Apple Store was postponed, and finally took place in April 2023, while the online store was launched in September 2020.\nWorker organizations.\nApple directly employs 147,000 workers including 25,000 corporate employees in Apple Park and across Silicon Valley. The vast majority of its employees work at the over 500 retail Apple Stores globally. Apple relies on a larger, outsourced workforce for manufacturing, particularly in China where Apple directly employs 10,000 workers across its retail and corporate divisions. In addition, one further million workers are contracted by Apple's suppliers to assemble Apple products, including Foxconn and Pegatron. Zhengzhou Technology Park alone employs 350,000 Chinese workers in Zhengzhou to exclusively work on the iPhone. As of 2021[ [update]], Apple uses hardware components from 43 different countries. The majority of assembling is done by Taiwanese original design manufacturer firms Foxconn, Pegatron, Wistron and Compal Electronics in factories primarily located inside China, and, to a lesser extent, Foxconn plants in Brazil, and India.\nApple workers around the globe have been involved in organizing since the 1990s. Apple unions are made up of retail, corporate, and outsourced workers. Apple employees have joined trade unions or formed works councils in Australia, France, Germany, Italy, Japan, the United Kingdom and the United States. In 2021, Apple Together, a solidarity union, sought to bring together the company's global worker organizations. The majority of industrial labor disputes (including union recognition) involving Apple occur indirectly through its suppliers and contractors, notably Foxconn plants in China and, to a lesser extent, in Brazil and India.\nDemocratic Republic of the Congo.\nIn 2019, Apple was named as a defendant in a forced labour and child slavery lawsuit by Congolese families of children injured and killed in cobalt mines owned by Glencore and Zhejiang Huayou Cobalt, which supply battery materials to Apple and other companies.\nIn April 2024, lawyers representing the Democratic Republic of the Congo notified Apple of evidence that Apple may be sourcing minerals from conflict areas of eastern Congo. Apple policies and documentation describe mitigation efforts against conflict minerals, however the lawyers identify discrepancies in supplier reporting as well as a Global Witness report describing a lack of \"meaningful mitigation\" on Apple's part. In December 2024, DRC filed a lawsuit against Apple's European subsidiaries, accusing them of using conflict minerals. In response, Apple said it \"strongly disputes\" these allegations and insisted it is \"deeply committed to responsible sourcing\" of the minerals it uses.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nBibliography.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "857", "revid": "45925219", "url": "https://en.wikipedia.org/wiki?curid=857", "title": "Aberdeenshire", "text": "Council area of Scotland\nAberdeenshire (; ) is one of the 32 council areas of Scotland.\nIt takes its name from the historic county of Aberdeenshire, which had substantially different boundaries. The Aberdeenshire Council area includes all of the areas of the historic counties of Aberdeenshire and Kincardineshire except the area making up Aberdeen City Council area, as well as part of Banffshire. The historic county boundaries are still officially used for a few purposes, namely land registration and lieutenancy.\nAberdeenshire Council is headquartered at Woodhill House in Aberdeen, making it the only Scottish council whose headquarters are located outside its jurisdiction. Aberdeen itself forms a different council area (Aberdeen City). Aberdeenshire borders onto Angus and Perth and Kinross to the south, Highland and Moray to the west and Aberdeen City to the east.\nTraditionally, it has depended economically on the primary sector (agriculture, fishing, and forestry) and related processing industries. Over the last 40 years, the development of the oil and gas industry and associated service sector has broadened Aberdeenshire's economic base, and contributed to a rapid population growth of some 50% since 1975. Its land represents 8% of Scotland's overall territory. It covers an area of .\nHistory.\nAberdeenshire has a rich prehistoric and historical heritage. It is the locus of a large number of Neolithic and Bronze Age archaeological sites, including Longman Hill, Kempstone Hill, Catto Long Barrow and Cairn Lee. The area was settled in the Bronze Age by the Beaker culture, who arrived from the south around 2000\u20131800 BC. Stone circles and cairns were constructed predominantly in this era. In the Iron Age, hill forts were built. \nAround the 1st century AD, the Taexali people, who left little history, were believed to have resided along the coast. The Picts were the next documented inhabitants of the area and were no later than 800\u2013900 AD. The Romans also were in the area during this period, as they left signs at Kintore. Christianity influenced the inhabitants early on, and there were Celtic monasteries at Old Deer and Monymusk.\nSince medieval times, there have been many traditional paths that crossed the Mounth (a spur of mountainous land that extends from the higher inland range to the North Sea slightly north of Stonehaven) through present-day Aberdeenshire from the Scottish Lowlands to the Highlands. Some of the most well known and historically important trackways are the Causey Mounth and Elsick Mounth.\nAberdeenshire played an important role in the fighting between the Scottish dynasties. Macbeth fell at Lumphanan in 1057. During the Anglo-Norman penetration, other families arrive, such as House of Balliol, Clan Bruce, and Clan Cumming (Comyn). During the Scottish Wars of Independence, the King of England Edward I travelled across the area twice with his invading army, in 1296 and 1303. In 1307, Robert the Bruce was victorious near Inverurie.\nThese new families set the stage for the upcoming rivalries during the 14th and 15th centuries. This rivalry grew worse during and after the Protestant Reformation when religion was another reason for conflict between the clans. The Gordon family adhered to Catholicism and the Forbeses to Protestantism. Aberdeenshire was the historic seat of the clan Dempster. Three universities were founded in the area prior to the 17th century, King's College in Old Aberdeen (1494), Marischal College in Aberdeen (1593), and the University of Fraserburgh (1592).\nDuring the 17th century, Aberdeenshire was the location of more fighting, centred on the Marquess of Montrose and the Wars of the Three Kingdoms. This period also saw increased wealth due to the increase in trade with Germany, Poland, and the Low Countries.\nAfter the end of the Revolution of 1688, an extended peaceful period was interrupted only by fleeting events such as the Rising of 1715 and the Rising of 1745. The latter resulted in the end of the ascendancy of Episcopalianism and the feudal power of landowners. An era began of increased agricultural and industrial progress.\nThe present council area is named after the historic county of Aberdeenshire, which has different boundaries and ceased to be used for local government purposes in 1975 under the Local Government (Scotland) Act 1973. The pre-1975 territory of Aberdeenshire was then split between four of the five new districts in the Grampian region: Banff and Buchan (which also included eastern parts of Banffshire, including its county town of Banff), Gordon, Kincardine and Deeside (which also included most of Kincardineshire), and Aberdeen City. Local government functions were shared between the two levels.\nThe modern council area was created in 1996 under the Local Government etc. (Scotland) Act 1994. It covers the combined area of the Banff and Buchan, Gordon, and Kincardine and Deeside districts that had been created in 1975. The present Aberdeenshire Council area therefore consists of all of the historic counties of Aberdeenshire and Kincardineshire (except the area of those two counties making up Aberdeen City), as well as the north-east portions of Banffshire.\nDemographics.\nThe population of the council area has risen over 50% since 1971 to approximately 265,080 in 2024, representing 4.7% of Scotland's total. Aberdeenshire's population has increased by 9.1% since 2001, while Scotland's total population grew by 3.8%.\nThe census lists a relatively high proportion of under 16s and slightly fewer working-age people compared with the Scottish average.\nAberdeenshire is one of the most homogeneous/indigenous regions of the UK. In 2011, 82.2% of residents identified as 'White Scottish', followed by 12.3% who are 'White British', whilst ethnic minorities constitute only 0.9% of the population. The largest ethnic minority group is Asian Scottish/British at 0.8%. In addition to the English language, 48.8% of residents reported being able to speak and understand the Scots language.\nLanguages.\nThe 2022 Scottish Census reported that out of 256,382 residents aged three and over, 121,797 (47.5%) considered themselves able to speak or read the Scots language. This is the greatest proportion of Scots speakers of any Scottish council area.\nThe 2022 Scottish Census reported that out of 256,377 residents aged three and over, 3,579 (1.4%) considered themselves able to speak or read Gaelic. \nSettlements.\nThe largest settlements in Aberdeenshire are:\nEconomy.\nAberdeenshire's Gross Domestic Product (GDP) is estimated at \u00a33,496M (2011), representing 5.2% of the Scottish total. Aberdeenshire's economy is closely linked to Aberdeen City's (GDP \u00a37,906M), and in 2011, the region as a whole was calculated to contribute 16.8% of Scotland's GDP. Between 2012 and 2014, the combined Aberdeenshire and Aberdeen City economic forecast GDP growth rate is 8.6%, the highest growth rate of any local council area in the UK and above the Scottish rate of 4.8%.\nA significant proportion of Aberdeenshire's working residents commute to Aberdeen City for work, varying from 11.5% from Fraserburgh to 65% from Westhill.\nAverage Gross Weekly Earnings (for full-time employees employed in workplaces in Aberdeenshire in 2011) are \u00a3572.60. This is lower than the Scottish average by \u00a32.10 and a fall of 2.6% on the 2010 figure. The average gross weekly pay of people resident in Aberdeenshire is much higher, at \u00a3741.90, as many people commute out\nof Aberdeenshire, principally into Aberdeen City.\nTotal employment (excluding farm data) in Aberdeenshire is estimated at 93,700 employees (Business Register and\nEmployment Survey 2009). The majority of employees work within the service sector, predominantly in public administration, education and health. Almost 19% of employment is within the public sector. Aberdeenshire's economy remains closely linked to Aberdeen City's and the North Sea oil industry, with many employees in oil-related jobs.\nThe average monthly unemployment (claimant count) rate for Aberdeenshire in 2011 was 1.5%. This is lower than the average rate of Aberdeen City (2.3%), Scotland (4.2%) and the UK (3.8%).\nNotable features.\nThe following significant structures or places are within Aberdeenshire:\nHydrology and climate.\nThere are numerous rivers and burns in Aberdeenshire, including Cowie Water, Carron Water, Burn of Muchalls, River Dee, River Don, River Ury, River Ythan, Water of Feugh, Burn of Myrehouse, Laeca Burn and Luther Water. Numerous bays and estuaries are found along the seacoast of Aberdeenshire, including Banff Bay, Ythan Estuary, Stonehaven Bay and Thornyhive Bay. Aberdeenshire has a marine west coast climate on the K\u00f6ppen climate classification. \nAberdeenshire is in the rain shadow of the Grampians, therefore it has a generally dry climate for a maritime region, with portions of the coast receiving of moisture annually. Summers are mild, and winters are typically cold in Aberdeenshire; Coastal temperatures are moderated by the North Sea such that coastal areas are typically cooler in the summer and warmer in the winter than inland locations. Coastal areas are also subject to haar, or coastal fog.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "858", "revid": "40192293", "url": "https://en.wikipedia.org/wiki?curid=858", "title": "AU", "text": ""}
{"id": "859", "revid": "35936988", "url": "https://en.wikipedia.org/wiki?curid=859", "title": "Aztlan Underground", "text": "American rapper\nAztlan Underground is a band from Los Angeles, California that combines Hip-Hop, Punk Rock, Jazz, and electronic music with Chicano and Native American themes, and indigenous instrumentation. They are often cited as progenitors of Chicano rap.\nBackground.\nThe band traces its roots to the late-1980s hardcore scene in the Eastside of Los Angeles. They have played rapcore, with elements of punk, hip hop, rock, funk, jazz, indigenous music, and spoken word. Indigenous drums, flutes, and rattles are also commonly used in their music. Their lyrics often address the family and economic issues faced by the Chicano community, and they have been noted as activists for that community.\nAs an example of the politically active and culturally important artists in Los Angeles in the 1990s, Aztlan Underground appeared on \"Culture Clash\" on Fox in 1993; and was part of \"Breaking Out\", a concert on pay per view in 1998, The band was featured in the independent films \"Algun Dia\" and \"Frontierland\" in the 1990s, and on the upcoming \"Studio 49\". The band has been mentioned or featured in various newspapers and magazines: \"the Vancouver Sun\", \"New Times\", \"BLU Magazine\" (an underground hip hop magazine), \"BAM Magazine\", \"La Banda Elastica Magazine\", and the \"Los Angeles Times\" calendar section. The band is also the subject of a chapter in the book \"It's Not About a Salary\", by Brian Cross.\nAztlan Underground remains active in the community, lending their voice to annual events such as The Farce of July, and the recent movement to recognize Indigenous People's Day in Los Angeles and beyond.\nIn addition to forming their own label, Xicano Records and Film, Aztlan Underground were signed to the Basque record label Esan Ozenki in 1999 which enabled them to tour Spain extensively and perform in France and Portugal. Aztlan Underground have also performed in Canada, Australia, and Venezuela. The band has been recognized for their music with nominations in the \"New Times\" 1998 \"Best Latin Influenced\" category, the \"BAM Magazine\" 1999 \"Best Rock en Espa\u00f1ol\" category, and the \"LA Weekly\" 1999 \"Best Hip Hop\" category. The release of their eponymous third album on August 29, 2009, was met with positive reviews and earned the band four Native American Music Award (NAMMY) nominations in 2010.\nDiscography.\n\"Decolonize\".\nYear:1995\n\"Sub-Verses\".\nYear:1998\n\"Aztlan Underground\".\nYear: 2009\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "860", "revid": "40192293", "url": "https://en.wikipedia.org/wiki?curid=860", "title": "Aland", "text": ""}
{"id": "863", "revid": "32589484", "url": "https://en.wikipedia.org/wiki?curid=863", "title": "American Civil War", "text": "1861\u20131865 conflict in the United States\nThe American Civil War (April 12, 1861\u00a0\u2013 May 26, 1865; also known by other names) was a civil war in the United States between the Union (\"the North\") and the Confederacy (\"the South\"), which was formed in 1861 by states that had seceded from the Union to preserve African American slavery, which they saw as threatened because of the election of Abraham Lincoln and the growing abolitionist movement in the North.\nDecades of controversy over slavery came to a head when Abraham Lincoln, a Republican who opposed slavery's expansion, won the 1860 presidential election. Seven Southern slave states responded to Lincoln's victory by seceding from the United States and forming the Confederacy. The Confederacy seized US forts and other federal assets within its borders. The war began on April 12, 1861, when the Confederacy bombarded Fort Sumter in South Carolina. A wave of enthusiasm for war swept over the North and South, as military recruitment soared. Four more Southern states seceded after the war began and, led by its president, Jefferson Davis, the Confederacy asserted control over a third of the US population in eleven states. Four years of intense combat, mostly in the South, ensued.\nDuring 1861\u20131862 in the western theater, the Union made permanent gains\u2014though in the eastern theater the conflict was inconclusive. The abolition of slavery became a Union war goal on January 1, 1863, when Lincoln issued the Emancipation Proclamation, which declared all slaves in rebel states to be free, applying to more than 3.5\u00a0million of the 4\u00a0million enslaved people in the country. To the west, the Union first destroyed the Confederacy's river navy by the summer of 1862, then much of its western armies, and seized New Orleans. The successful 1863 Union siege of Vicksburg split the Confederacy in two at the Mississippi River, while Confederate general Robert E. Lee's incursion north failed at the Battle of Gettysburg. General Ulysses S. Grant's western successes led to Lincoln's giving him command of all Union armies in 1864.\nInflicting an ever-tightening naval blockade of Confederate ports, the Union marshaled resources and manpower to attack the Confederacy from all directions. This led to the fall of Atlanta in 1864 to Union general William Tecumseh Sherman, followed by his March to the Sea, which culminated in his taking Savannah. The last significant battles raged around the ten-month Siege of Petersburg, gateway to the Confederate capital of Richmond. The Confederates abandoned Richmond, and on April 9, 1865, Lee surrendered to Grant following the Battle of Appomattox Court House, setting in motion the end of the war. Lincoln lived to see this victory but was shot by an assassin on April 14, dying the next day.\nBy the end of the war, much of the South's infrastructure had been destroyed. The Confederacy collapsed, slavery was abolished, and four million enslaved black people were freed. The war-torn nation then entered the Reconstruction era in an attempt to rebuild the country, bring the former Confederate states back into the United States, and grant civil rights to freed slaves. The war is one of the most extensively studied and written about episodes in the history of the United States. It remains the subject of cultural and historiographical debate. Of continuing interest is the myth of the Lost Cause of the Confederacy. The war was among the first to use industrial warfare. Railroads, the electrical telegraph, steamships, the ironclad warship, and mass-produced weapons were widely used. The war left an estimated 700,000 soldiers dead, along with an undetermined number of civilian casualties, making it the deadliest in American history. The technology and brutality of the Civil War foreshadowed the coming world wars.\nOrigins.\nThe origins of the war were rooted in the desire of the Southern states to preserve the institution of slavery. Historians in the 21st century overwhelmingly agree on the centrality of slavery in the conflict\u2014at least for the Southern states. They disagree on the North's reasons for refusing to allow the Southern states to secede. The pseudo-historical Lost Cause ideology denies that slavery was the principal cause of the secession, a view disproven by historical evidence, notably some of the seceding states' own secession documents. After leaving the Union, Mississippi issued a declaration stating, \"Our position is thoroughly identified with the institution of slavery\u2014the greatest material interest of the world.\"\nThe principal political battle leading to Southern secession was over whether slavery would expand into the Western territories destined to become states. Initially Congress had admitted new states into the Union in pairs, one slave and one free. This had kept a sectional balance in the Senate but not in the House of Representatives, as free states outstripped slave states in numbers of eligible voters. Thus, at mid-19th century, the free-versus-slave status of the new territories was a critical issue, both for the North, where anti-slavery sentiment had grown, and for the South, where the fear of slavery's abolition had grown. Another factor leading to secession and the formation of the Confederacy was the development of white Southern nationalism in the preceding decades. The primary reason for the North to reject secession was to preserve the Union, a cause based on American nationalism.\nBackground factors in the run up to the Civil War were partisan politics, abolitionism, nullification versus secession, Southern and Northern nationalism, expansionism, economics, and modernization in the antebellum period. As a panel of historians emphasized in 2011, \"while slavery and its various and multifaceted discontents were the primary cause of disunion, it was disunion itself that sparked the war.\"\nLincoln's election.\nAbraham Lincoln won the 1860 presidential election. Southern leaders feared Lincoln would stop slavery's expansion and put it on a course toward extinction. His victory triggered declarations of secession by seven slave states of the Deep South, all of whose riverfront or coastal economies were based on cotton that was cultivated by slave labor.\nLincoln was not inaugurated until March 4, 1861, four months after his 1860 election, which afforded the South time to prepare for war. Nationalists in the North and \"Unionists\" in the South refused to accept the declarations of secession, and no foreign government ever recognized the Confederacy. The US government, under President James Buchanan, refused to relinquish the nation's forts, which the Confederacy claimed were located in their territory.\nAccording to Lincoln, the American people had demonstrated, beginning with their victory in the American Revolution and Revolutionary War and subsequent establishment of a sovereign nation, that they could successfully establish and administer a republic. Yet, Lincoln believed, a question remained unanswered: Could the nation be maintained as a republic, where its government was selected based on the people's vote, given ongoing internal attempts to destroy or separate from such a system.\nOutbreak of the war.\nSecession crisis.\nLincoln's election provoked South Carolina's legislature to call a state convention to consider secession. South Carolina had done more than any other state to advance the notion that a state had the right to nullify federal laws and even secede. On December 20, 1860, the convention unanimously voted to secede and adopted a secession declaration. It argued for states' rights for slave owners but complained about states' rights in the North in the form of resistance to the federal Fugitive Slave Act, claiming that Northern states were not fulfilling their obligations to assist in the return of fugitive slaves. The \"cotton states\" of Mississippi, Florida, Alabama, Georgia, Louisiana, and Texas followed suit, seceding in January and February 1861.\nAmong the ordinances of secession, those of Texas, Alabama, and Virginia mentioned the plight of the \"slaveholding states\" at the hands of Northern abolitionists. The rest made no mention of slavery but were brief announcements by the legislatures of the dissolution of ties to the Union. However, at least four\u2014South Carolina, Mississippi, Georgia, and Texas\u2014provided detailed reasons for their secession, all blaming the movement to abolish slavery and its influence over the North. Southern states believed that the Fugitive Slave Clause made slaveholding a constitutional right. These states agreed to form a new federal government, the Confederate States of America, on February 4, 1861. They took control of federal forts and other properties within their boundaries, with little resistance from outgoing president James Buchanan, whose term ended on March 4. Buchanan said the Dred Scott decision was proof the Southern states had no reason to secede and that the Union \"was intended to be perpetual\". He added, however, that \"The power by force of arms to compel a State to remain in the Union\" was not among the \"enumerated powers granted to Congress\". A quarter of the US army\u2014the Texas garrison\u2014was surrendered in February to state forces by its general, David E. Twiggs, who joined the Confederacy.\nAs Southerners resigned their Senate and House seats, Republicans could pass projects that had been blocked. These included the Morrill Tariff, land grant colleges, a Homestead Act, a transcontinental railroad, the National Bank Act, authorization of United States Notes by the Legal Tender Act of 1862, the end of slavery in the District of Columbia, and a ban on slavery in the territories. The Revenue Act of 1861 introduced an income tax to help finance the war.\nIn December 1860, the Crittenden Compromise was proposed to re-establish the Missouri Compromise line, by constitutionally banning slavery in territories to the north of it, while permitting it to the south. The Compromise would likely have prevented secession, but Lincoln and the Republicans rejected it. Lincoln stated that any compromise that would extend slavery would bring down the Union. A February peace conference met in Washington, proposing a solution similar to the Compromise; it was rejected by Congress. The Republicans proposed the Corwin Amendment, an alternative, not to interfere with slavery where it existed, but the South regarded it as insufficient. The remaining eight slave states rejected pleas to join the Confederacy, following a no-vote in Virginia's First Secessionist Convention on April 4.\nOn March 4, Lincoln was sworn in as president. In his first inaugural address, he argued that the Constitution was a \"more perfect union\" than the earlier Articles of Confederation and Perpetual Union, was a binding contract, and that secession was \"legally void\". He did not intend to invade Southern states, nor to end slavery where it existed, but he said he would use force to maintain possession of federal property, including forts, arsenals, mints, and customhouses that had been seized. \"The mails, unless repelled, will continue to be furnished in all parts of the Union.\" Where conditions did not allow peaceful enforcement of federal law, US marshals and judges would be withdrawn. No mention was made of bullion lost from mints. He stated that it would be US policy \"to collect the duties and imposts\"; \"there will be no invasion, no using of force against or among the people anywhere\" that would justify an armed revolution. His speech closed with a plea for restoration of the bonds of union, famously calling on \"the mystic chords of memory\" binding the two regions.\nThe Davis government of the new Confederacy sent delegates to Washington to negotiate a peace treaty. Lincoln rejected negotiations, because he claimed that the Confederacy was not a legitimate government and to make a treaty with it would recognize it as such. Lincoln instead attempted to negotiate directly with the governors of seceded states, whose administrations he continued to recognize.\nComplicating Lincoln's attempts to defuse the crisis was Secretary of State William H. Seward, who had been Lincoln's rival for the Republican nomination. Embittered by his defeat, Seward agreed to support Lincoln's candidacy only after he was guaranteed the executive office then considered the second most powerful. In the early stages of Lincoln's presidency Seward held little regard for him, due to his perceived inexperience. Seward viewed himself as the de facto head of government, the \"prime minister\" behind the throne. Seward attempted to engage in unauthorized and indirect negotiations that failed. Lincoln was determined to hold all remaining Union-occupied forts in the seceded states: Fort Pickens, Fort Jefferson, and Fort Taylor in Florida, and Fort Sumter in South Carolina.\nBattle of Fort Sumter.\nThe American Civil War began on April 12, 1861, when Confederate forces opened fire on the Union-held Fort Sumter. Fort Sumter is located in the harbor of Charleston, South Carolina. Its status had been contentious for months. Outgoing president Buchanan had dithered in reinforcing its garrison, commanded by Major Robert Anderson. Anderson took matters into his own hands and on December 26, 1860, under the cover of darkness, sailed the garrison from the poorly placed Fort Moultrie to the stalwart island Fort Sumter. Anderson's actions catapulted him to hero status in the North. An attempt to resupply the fort on January 9, 1861, failed and nearly started the war then, but an informal truce held. On March 5, Lincoln was informed the fort was low on supplies.\nFort Sumter proved a key challenge to Lincoln's administration. Back-channel dealing by Seward with the Confederates undermined Lincoln's decision-making; Seward wanted to pull out. But a firm hand by Lincoln tamed Seward, who was a staunch Lincoln ally. Lincoln decided holding the fort, which would require reinforcing it, was the only workable option. On April 6, Lincoln informed the Governor of South Carolina that a ship with food but no ammunition would attempt to supply the fort. Richard N. Current wrote: &lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;In short, it appears that Lincoln, when he decided to send the Sumter expedition, considered hostilities to be \"probable\". It also appears, however, that he believed an unopposed and peaceable provisioning to be at least barely \"possible\"... He thought hostilities would be the likely result, and he was determined that, if they should be, they must clearly be initiated by the Confederates. \"To say that Lincoln meant that the first shot would be fired by the other side \"if a first shot was fired\", ... is not to say that he maneuvered to have the first shot fired.\"\nJames McPherson describes this win-win approach as \"the first sign of the mastery that would mark Lincoln's presidency\"; the Union would win if it could resupply and hold the fort, and the South would be the aggressor if it opened fire on an unarmed ship supplying starving men. An April 9 Confederate cabinet meeting resulted in Davis ordering General P. G. T. Beauregard to take the fort before supplies reached it.\nAt 4:30\u00a0a.m. on April 12, Confederate forces fired the first of 4,000 shells at the fort; it fell the next day. The loss of Fort Sumter lit a patriotic fire under the North. On April 15, Lincoln called on the states to field 75,000 militiamen for 90\u00a0days; impassioned Union states met the quotas quickly. On May 3, 1861, Lincoln called for an additional 42,000 volunteers for three years. Shortly after this, Virginia, Tennessee, Arkansas, and North Carolina seceded and joined the Confederacy. To reward Virginia, the Confederate capital was moved to Richmond.\nAttitude of the border states.\nMaryland, Delaware, Missouri, and Kentucky, known as the border states, were slave states that had not seceded and whose people had divided loyalties to the North and South, with some men enlisting in the Union Army and others in the Confederate Army. West Virginia may be compared to the border states because it had slavery after it separated from Virginia and was admitted to the Union on June 20, 1863, but it was admitted under a plan of gradual emancipation known as the Willey Amendment.\nMaryland's territory surrounded Washington, D.C., and could cut it off from the North. It had anti-Lincoln officials who tolerated anti-army rioting in Baltimore and the burning of bridges, both aimed at hindering the passage of troops to Washington, D.C., and the South. Maryland's legislature voted overwhelmingly to stay in the Union, but rejected hostilities with its southern neighbors, voting to close Maryland's rail lines to prevent their use for war. Lincoln responded by establishing martial law and unilaterally suspending habeas corpus in Maryland, along with sending in militia units. Lincoln took control of Maryland and the District of Columbia by seizing prominent figures, including arresting one-third of the members of the Maryland General Assembly, who were pro-Confederate, on September 17, 1861, the day it intended to reconvene. All were held without trial at Fort McHenry in Baltimore.\nIn September 1861, federal troops imprisoned a Baltimore newspaper editor, Frank Key Howard, after he criticized Lincoln in an editorial for ignoring Taney's ruling. Howard wrote a book about his prison experiences, which was published early in 1863. It \"stressed the crowded conditions and spartan hardships of prison life ... [and] likened the conditions in Fort Lafayette to those on 'a slave-ship, on the middle passage'\".\nIn Missouri, an elected convention on secession voted to remain in the Union. When pro-Confederate Governor Claiborne Fox Jackson called out the state militia, it was attacked by federal forces under General Nathaniel Lyon, who chased the governor and rest of the State Guard to the southwestern corner of Missouri (see Missouri secession). Early in the war the Confederacy controlled southern Missouri through the Confederate government of Missouri but was driven out after 1862. In the resulting vacuum, the convention on secession reconvened and took power as the Unionist provisional government of Missouri.\nKentucky did not secede, it declared itself neutral. When Confederate forces entered in September 1861, neutrality ended and the state reaffirmed its Union status while maintaining slavery. During an invasion by Confederate forces in 1861, Confederate sympathizers and delegates from 68 Kentucky counties organized the secession Russellville Convention, formed the shadow Confederate Government of Kentucky, inaugurated a governor, and Kentucky was admitted into the Confederacy on December 10, 1861. Its jurisdiction extended only as far as Confederate battle lines in the Commonwealth, which at its greatest extent was over half the state, and it went into exile after October 1862.\nAfter Virginia's secession, a Unionist government in Wheeling asked 48 counties to vote on an ordinance to create a new state in October 1861. A voter turnout of 34 percent approved the statehood bill (96 percent approving). Twenty-four secessionist counties were included in the new state, and the ensuing guerrilla war engaged about 40,000 federal troops for much of the war. Congress admitted West Virginia to the Union on June 20, 1863. West Virginians provided about 20,000 soldiers to each side in the war. A Unionist secession attempt occurred in East Tennessee, but was suppressed by the Confederacy, which arrested over 3,000 men suspected of loyalty to the Union; they were held without trial.\nWar.\nThe Civil War was marked by intense and frequent battles. Over four years, 237 named battles were fought, along with many smaller actions, often characterized by their bitter intensity and high casualties. Historian John Keegan described it as \"one of the most ferocious wars ever fought\", where in many cases the only target was the enemy's soldiers.\nMobilization.\nAs the Confederate states organized, the US Army numbered 16,000, while Northern governors began mobilizing their militias. The Confederate Congress authorized up to 100,000 troops in February. By May, Jefferson Davis was pushing for another 100,000 soldiers for one year or the duration, and the US Congress responded in kind.\nIn the first year of the war, both sides had more volunteers than they could effectively train and equip. After the initial enthusiasm faded, relying on young men who came of age each year was not enough. Both sides enacted draft laws (conscription) to encourage or force volunteering, though relatively few were drafted. The Confederacy passed a draft law in April 1862 for men aged 18 to 35, with exemptions for overseers, government officials, and clergymen. The US Congress followed in July, authorizing a militia draft within states that could not meet their quota with volunteers. European immigrants joined the Union Army in large numbers, including 177,000 born in Germany and 144,000 in Ireland. About 50,000 Canadians served, around 2,500 of whom were black.\nWhen the Emancipation Proclamation went into effect in January 1863, ex-slaves were energetically recruited to meet state quotas. States and local communities offered higher cash bonuses for white volunteers. Congress tightened the draft law in March 1863. Men selected in the draft could provide substitutes or, until mid-1864, pay commutation money. Many eligibles pooled their money to cover the cost of anyone drafted. Families used the substitute provision to select which man should go into the army and which should stay home. There was much evasion and resistance to the draft, especially in Catholic areas. The New York City draft riots in July 1863 involved Irish immigrants who had been signed up as citizens to swell the vote of the city's Democratic political machine, not realizing it made them liable for the draft. Of the 168,649 men procured for the Union through the draft, 117,986 were substitutes, leaving only 50,663 who were conscripted.\nIn the North and South, draft laws were highly unpopular. In the North, some 120,000 men evaded conscription, many fleeing to Canada, and another 280,000 soldiers deserted during the war. At least 100,000 Southerners deserted, about 10 percent of the total. Southern desertion was high because many soldiers were more concerned about the fate of their local area than the Southern cause. In the North, \"bounty jumpers\" enlisted to collect the generous bonus, deserted, then re-enlisted under a different name for a second bonus; 141 were caught and executed.\nFrom a tiny frontier force in 1860, the Union and Confederate armies grew into the \"largest and most efficient armies in the world\" within a few years. Some European observers at the time dismissed them as amateur and unprofessional, but historian John Keegan concluded that each outmatched the French, Prussian, and Russian armies, and without the Atlantic, could have threatened any of them with defeat.\nSouthern Unionists.\nUnionism was strong in certain areas within the Confederacy. As many as 100,000 men living in states under Confederate control served in the Union Army or pro-Union guerrilla groups. Although they came from all classes, most Southern Unionists differed socially, culturally, and economically from their region's dominant prewar, slave-owning planter class.\nPrisoners.\nAt the beginning of the Civil War, a parole system operated, under which captives agreed not to fight until exchanged. They were held in camps run by their army, paid, but not allowed to perform any military duties.\nThe system of exchanges collapsed in 1863 when the Confederacy refused to exchange black prisoners. After that, approximately 56,000 of the 409,000 POWs died in prisons, accounting for 10 percent of the conflict's fatalities.\nWomen.\nHistorian Elizabeth D. Leonard writes that between 500 and 1,000 women enlisted as soldiers on both sides, disguised as men. Women also served as spies, resistance activists, nurses, and hospital personnel. Women served on the Union hospital ship \"Red Rover\" and nursed Union and Confederate troops at field hospitals. Mary Edwards Walker, the only woman ever to receive the Medal of Honor, served in the Union Army and was given the medal for treating the wounded during the war. One woman, Jennie Hodgers, fought for the Union under the name Albert D. J. Cashier. After she returned to civilian life, she continued to live as a man until she died in 1915 at the age of 71.\nUnion.\nDuring the war, women in the North advocated for social reforms and created ladies' aid societies, also called soldiers' aid societies, which provided supplies to soldiers on the battlefield and cared for sick and wounded soldiers. Women in the North also held military rallies, village parades, and charity bazaars.\nWomen like Susan B. Anthony saw that supporting the war effort was a way to pave the future for women's suffrage movements. In her appeal to Northern women's loyalty, Anthony challenged the inconsistencies of the nation's founding ideal and its actual practices concerning equality among women.\nNorthern women during the Civil War also made great strides in the workforce, as they helped contribute to the war effort by stepping into roles that were traditionally held by men. While women rarely worked in factories before the war, many filled men's places as they felt they could erase some of the boundaries that separated them from male preserves of power. Women were important in the workforce as they prepared and packed provisions, sewed uniforms and havelocks, and knitted socks and mittens. By entering these new environments, women made significant progress in the fight for women's equality in the workforce.\nNorthern women were also essential in the wartime support, as they were active participants in the war narrative. While women were not allowed to fight on the battlefield in the Civil War, they exhibited a patriotism that gave them the strength to maintain courage for themselves as well as their households. While their men were off at war, Northern women created a landscape that emphasized love, sacrifice, and the nurturing of men's courage. This is demonstrated in feminized war literature that encouraged, expressed, and valorized men's patriotism. Women's unwavering encouragement and affection towards fighting men became a cornerstone of the war effort as it helped sustain the spirits of the men on the frontlines.\nConfederate.\nConfederate women during the Civil War focused on preserving the central economic institution of the Old South: the plantation. With so many men away at war, women were left with the land and the slaves. While some women hired male overseers to assist them in directing and maintaining newly female-headed plantations, other women decided to stay at the plantations and run the plantations themselves. Southern women became focused on keeping the economic structure of the South as they dealt with increasingly rebellious slaves.\nThe South relied on enslaved labor because it was an agrarian economy. A good number of enslaved men labored for the Confederate army during the war, which meant that enslaved women and children were increasingly at the center of the work force on the plantations.\nWhite Southern women struggled to maintain morale on the home front as they dealt with problems without men. Although Southern women were devoted to the Confederacy, many requested that their sons and husbands be discharged from the military to help them at home. Many women like Eliza Adams wrote to the Confederate government to appeal for exemption for her sons' military service as she sent five sons and other sons-in-laws to fight for the Confederacy. Southern women were torn between their patriotic ideals and their daily realities of life on the home front.\nUnion Navy.\nThe Union Navy in 1861 was relatively small but, by 1865, expanded rapidly to 6,000 officers, 45,000 sailors, and 671 vessels totaling 510,396 tons. Its mission was to blockade Confederate ports, control the river system, defend against Confederate raiders on the high seas, and be ready for a possible war with the British Royal Navy. The main riverine war was fought in the West, where major rivers gave access to the Confederate heartland. The US Navy eventually controlled the Red, Tennessee, Cumberland, Mississippi, and Ohio rivers. In the East, the Navy shelled Confederate forts and supported coastal army operations.\nThe Civil War occurred during the early stages of the industrial revolution, leading to naval innovations, including the ironclad warship. The Confederacy, recognizing the need to counter the Union's naval superiority, built or converted over 130 vessels, including 26 ironclads. Despite these efforts, Confederate ships were largely unsuccessful against Union ironclads. The Union Navy used timberclads, tinclads, and armored gunboats. Shipyards in Cairo, Illinois, and St. Louis built or modified steamboats.\nThe Confederacy experimented with the submarine , which proved unsuccessful, and with the ironclad , rebuilt from the sunken Union ship . On March 8, 1862, \"Virginia\" inflicted significant damage on the Union's wooden fleet, but the next day, the first Union ironclad, , arrived to challenge it in the Chesapeake Bay. The resulting three-hour Battle of Hampton Roads was a draw, proving ironclads were effective warships. The Confederacy scuttled the \"Virginia\" to prevent its capture, while the Union built many copies of the \"Monitor\". The Confederacy's efforts to obtain warships from Great Britain failed, as Britain had no interest in selling warships to a nation at war with a stronger enemy and feared souring relations with the US.\nUnion blockade.\nBy early 1861, General Winfield Scott had devised the Anaconda Plan to win the war with minimal bloodshed, calling for a blockade of the Confederacy to suffocate the South into surrender. Lincoln adopted parts of the plan but opted for a more active war strategy. In April 1861, Lincoln announced a blockade of all Southern ports; commercial ships could not get insurance, ending regular traffic. The South blundered by embargoing cotton exports before the blockade was fully effective; by the time they reversed this decision, it was too late. \"King Cotton\" was dead, as the South could export less than 10% of its cotton. The blockade shut down the ten Confederate seaports with railheads that moved almost all the cotton. By June 1861, warships were stationed off the principal Southern ports, and a year later nearly 300 ships were in service.\nBlockade runners.\nThe Confederates began the war short on military supplies, which the agrarian South could not produce. Northern arms manufacturers were restricted by an embargo, ending existing and future contracts with the South. The Confederacy turned to foreign sources, connecting with financiers and companies like S. Isaac, Campbell &amp; Company and the London Armoury Company in Britain, becoming the Confederacy's main source of arms.\nTo transport arms safely to the Confederacy, British investors built small, fast, steam-driven blockade runners that traded arms and supplies from Britain, through Bermuda, Cuba, and the Bahamas in exchange for high-priced cotton. Many were lightweight and designed for speed, only carrying small amounts of cotton back to England. When the Union Navy seized a blockade runner, the ship and cargo were condemned as a prize of war and sold, with proceeds given to the Navy sailors; the captured crewmen, mostly British, were released.\nEconomic impact.\nThe Southern economy nearly collapsed during the war due to multiple factors, the most notable being severe food shortages, failing railroads, loss of control over key rivers, foraging by Northern armies, and the seizure of animals and crops by Confederate forces. Historians agree the blockade was a major factor in ruining the Confederate economy; however, Wise argues blockade runners provided enough of a lifeline to allow Robert E. Lee, a Confederate general, to continue fighting for additional months, as a result of supplies that included 400,000 rifles, lead, blankets, and boots that Confederate economy could no longer supply.\nThe Confederate cotton crop became nearly useless, which cut off the Confederacy's primary income source. Critical imports were scarce, and coastal trade also largely ended. The blockade's success was not measured by the few ships, which slipped through, but by the thousands that never tried. European merchant ships could not obtain insurance for their ships and transport, and were too slow to evade the blockade, leading them to cease docking in Confederate ports.\nTo fight an offensive war, the Confederacy purchased arms in Britain and converted British-built ships into commerce raiders, which targeted United States Merchant Marine ships in the Atlantic and Pacific oceans. The Confederacy smuggled 600,000 arms, enabling it to continue fighting for two more years. As insurance rates soared, American-flagged ships largely ceased traveling in international waters, though some were reflagged with European flags, which allowed them to continue operating. After the conclusion of the Civil War, the US government demanded Britain reimburse it for the damage caused by blockade runners and raiders outfitted in British ports. Britain paid the US$15\u00a0million in 1871, which covered costs associated with commerce raiding but nothing more.\nDiplomacy.\nAlthough the Confederacy hoped Britain and France would join them against the Union, this was never likely, so they sought to bring them in as mediators. The Union worked to block this and threatened war against any country that recognized the Confederacy. In 1861, Southerners voluntarily embargoed cotton shipments, hoping to start an economic depression in Europe that would force Britain to enter the war, but this failed. Worse, Europe turned to Egypt and India for cotton, which they found superior, hindering the South's postwar recovery.\nCotton diplomacy proved a failure, because Europe had a surplus of cotton, while the 1860\u201362 crop failures in Europe made the North's grain exports critically important. It also helped turn European opinion against the Confederacy. It was said that \"King Corn was more powerful than King Cotton\", as US grain increased from a quarter to almost half of British imports. Meanwhile, the war created jobs for arms makers, ironworkers, and ships to transport weapons.\nLincoln's administration initially struggled to appeal to European public opinion. At first, diplomats explained that the US was not committed to ending slavery and emphasized legal arguments about the unconstitutionality of secession. Confederate representatives, however, focused on their struggle for liberty, commitment to free trade, and the essential role of cotton in the European economy. The European aristocracy was \"absolutely gleeful in pronouncing the American debacle as proof that the entire experiment in popular government had failed. European government leaders welcomed the fragmentation of the ascendant American Republic.\" However, a European public with liberal sensibilities remained, which the US sought to appeal to by building connections with the international press. By 1861, Union diplomats like Carl Schurz realized emphasizing the war against slavery was the Union's most effective moral asset in swaying European public opinion. Seward was concerned an overly radical case for reunification would distress European merchants with cotton interests; even so, he supported a widespread campaign of public diplomacy.\nUS minister to Britain Charles Francis Adams proved adept and convinced Britain not to challenge the Union blockade. The Confederacy purchased warships from commercial shipbuilders in Britain, with the most famous being the , which caused considerable damage and led to serious postwar disputes. However, public opinion against slavery in Britain created a political liability for politicians, where the anti-slavery movement was powerful.\nWar loomed in late 1861 between the US and Britain over the \"Trent\" Affair, which began when US Navy personnel boarded the British ship and seized two Confederate diplomats. However, London and Washington smoothed this over after Lincoln released the two men. Prince Albert left his deathbed to issue diplomatic instructions to Lord Lyons during the \"Trent\" Affair. His request was honored, and, as a result, the British response to the US was toned down, helping avert war. In 1862, the British government considered mediating between the Union and Confederacy, though such an offer would have risked war with the US. British prime minister Lord Palmerston reportedly read \"Uncle Tom's Cabin\" three times when deciding what his decision would be.\nThe Union victory at the Battle of Antietam caused the British to delay this decision. The Emancipation Proclamation increased the political liability of supporting the Confederacy. Realizing that Washington could not intervene in Mexico as long as the Confederacy controlled Texas, France invaded Mexico in 1861 and installed the Habsburg Austrian archduke Maximilian I as emperor. Washington repeatedly protested France's violation of the Monroe Doctrine. Despite sympathy for the Confederacy, France's seizure of Mexico deterred it from war with the Union. Confederate offers late in the war to end slavery in return for diplomatic recognition were not seriously considered by London or Paris. After 1863, the Polish revolt against Russia further distracted the European powers and ensured they remained neutral.\nRussia supported the Union, largely because it believed the US counterbalanced its geopolitical rival, the UK. In 1863, the Imperial Russian Navy's Baltic and Pacific fleets wintered in the American ports of New York and San Francisco, respectively.\nEastern theater.\nThe Eastern theater refers to the military operations east of the Appalachian Mountains, including Virginia, West Virginia, Maryland, and Pennsylvania, the District of Columbia, and the coastal fortifications and seaports of North Carolina.\nBackground.\nArmy of the Potomac.\nMaj. Gen. George B. McClellan took command of the Union Army of the Potomac on July 26, 1861, and the war began in earnest in 1862. The 1862 Union strategy called for simultaneous advances along four axes:\nArmy of Northern Virginia.\nThe primary Confederate force in the Eastern theater was the Army of Northern Virginia. The Army originated as the (Confederate) Army of the Potomac, which was organized on June 20, 1861, from all operational forces in Northern Virginia. On July 20 and 21, the Army of the Shenandoah and forces from the District of Harpers Ferry were added. Units from the Army of the Northwest were merged into the Army of the Potomac between March 14 and May 17, 1862. The Army of the Potomac was renamed \"Army of Northern Virginia\" on March 14. The Army of the Peninsula was merged into it on April 12, 1862.\nWhen Virginia declared its secession in April 1861, Robert E. Lee chose to follow his home state, despite his desire for the country to remain intact and an offer of a senior Union command. In his four-volume biography of Lee published in 1934 and 1935, historian Douglas S. Freeman wrote that the army received its final name from Lee when he issued orders assuming command on June 1, 1862. However, Freeman wrote, Lee corresponded with Brigadier General Joseph E. Johnston, his predecessor in army command, before that date and referred to Johnston's command as the Army of Northern Virginia. Part of the confusion results from the fact that Johnston commanded the Department of Northern Virginia as of October 22, 1861, and the name Army of Northern Virginia was seen as an informal consequence of its parent department's name. Jefferson Davis and Johnston did not adopt the name, but the organization of units as of March 14 was clearly the same organization that Lee received on June 1, and is generally referred to as the Army of Northern Virginia, even if that is correct only in retrospect.\nOn July 4 at Harper's Ferry, Colonel Thomas J. Jackson assigned Jeb Stuart command of all cavalry companies of the Army of the Shenandoah, and Jackson eventually commanded the Army of Northern Virginia's cavalry.\nBattles.\nCalled the \"Philippi Races\" because of its brevity, Philippi, VA (now Philippi, WV) was the scene of the first organized land action of the American Civil War, on June 3, 1861. In July 1861, in the first in a series of prominent battles in the war, Union Army troops commanded by Maj. Gen. Irvin McDowell attacked Confederate forces, which were under the command of Beauregard near the national capital in Washington. The Confederacy successfully repelled the attack in the First Battle of Bull Run. In the beginning of the battle, the Union appeared to hold the upper hand. The Union Army routed Confederate forces, then holding defensive positions, but Confederate reinforcements under Joseph E. Johnston arrived from the Shenandoah Valley by railroad, and the battle's course quickly changed. A brigade of Virginians, commanded by Thomas J. Jackson, then a relatively unknown brigadier general from Virginia Military Institute, stood its ground, leading to Jackson earning the nickname \"Stonewall\". Lincoln urged the Union Army to commence offensive operations against Confederate forces, which led General George B. McClellan, in the spring of 1862, to attack Virginia by way of the peninsula between the York River and James River southeast of Richmond. McClellan's army reached the gates of Richmond in the Peninsula campaign.\nAlso in the spring of 1862, in Shenandoah Valley, Jackson led his Valley Campaign, during which he employed rapid and unpredictable movements on interior lines. Jackson's 17,000 troops marched 646 miles (1,040\u00a0km) in 48 days, during which they won minor battles as they successfully engaged three Union armies, comprising 52,000 men, including those of Nathaniel P. Banks and John C. Fr\u00e9mont, preventing them from reinforcing the Union offensive against Richmond. The swiftness of Jackson's troops earned them the nickname foot cavalry. Johnston halted McClellan's advance at the Battle of Seven Pines, but he was wounded in the battle, and Robert E. Lee assumed his position of command. Lee and his senior subordinates, James Longstreet and Stonewall Jackson, defeated McClellan in the Seven Days Battles, forcing McClellan's retreat.\nDuring the Northern Virginia Campaign, which included the Second Battle of Bull Run, Confederate forces registered another important military victory. McClellan resisted General-in-Chief Halleck's orders to send reinforcements to John Pope's Union Army of Virginia, which enabled Lee's Confederate forces to defeat twice the number of combined enemy troops.\nEmboldened by Second Bull Run, Confederate forces launched their first invasion of the North in the Maryland Campaign during which Lee led 45,000 Army of Northern Virginia troops across the Potomac River into Maryland on September 5. Lincoln then restored Pope's troops to McClellan, and McClellan and Lee clashed in the Battle of Antietam near Sharpsburg, Maryland, on September 17, 1862, which proved the bloodiest single day in both the Civil War and US military history. Lee's army retreated to Virginia before McClellan could destroy it, leading the Battle of Antietam to be widely viewed as a Union victory since it halted Lee's invasion of the North and provided an opportunity for Lincoln to issue the Emancipation Proclamation, which he issued as an executive order on January 1, 1863.\nMcClellan failed to respond in any measurable way to Lee's attempt to invade the North at Antietam led to his replacement by Maj. Gen. Ambrose Burnside. Burnside led Union Army troops in the Battle of Fredericksburg, where they were defeated on December 13, 1862. Over 12,000 Union soldiers were killed or wounded during futile attempts by Union troops to launch frontal assaults against Marye's Heights. After the battle, Burnside was replaced by Maj. Gen. Joseph Hooker.\nHooker, too, proved unable to defeat Lee's army; despite having more than twice as many troops as Lee, Hooker's Chancellorsville Campaign proved ineffective, and he was soundly defeated in the Battle of Chancellorsville, which was fought between April 30 and May 6, 1863. Chancellorsville is known as Lee's \"perfect battle\" because his risky decision to divide his army paid off. During the Battle of Chancellorsville, Stonewall Jackson was shot in his left arm and right hand by friendly fire, leading to the amputation of his arm, and he died of pneumonia. Lee famously said: \"He has lost his left arm, but I have lost my right arm.\"\nThe fiercest fighting of the battle\u2014and the second bloodiest day of the Civil War\u2014occurred on May 3 as Lee launched multiple attacks against the Union position at Chancellorsville. That same day, John Sedgwick advanced across the Rappahannock River, defeated the small Confederate force at Marye's Heights in the Second Battle of Fredericksburg, and then moved westward, but Confederate forces succeeded in delaying Union forces in the Battle of Salem Church.\nHooker was replaced by Maj. Gen. George Meade during Lee's second invasion of the North, in June. In the Battle of Gettysburg, which proved the war's bloodiest and one of its most strategically significant, Meade defeated Lee in a three-day battle between July 1 and 3, 1863. The Battle of Gettysburg caused over 50,000 Union and Confederate casualties, but also proved the war's turning point, altering the course of the war in the Union's favor. Pickett's Charge, launched July 3, on the final day of the Battle of Gettysburg, is considered the high-water mark of the Confederacy, representing the collapse of any credible prospect that the Confederacy could prevail in the war. At Gettysburg, Lee's Army of Northern Virginia suffered 28,000 casualties versus Meade's 23,000, and Lee was repelled in a failed attempt to invade and occupy Union territory.\nWestern theater.\nThe Western theater refers to military operations between the Appalachian Mountains and the Mississippi River, including Alabama, Georgia, Florida, Mississippi, North Carolina, Kentucky, South Carolina, Tennessee, and parts of Louisiana.\nBackground.\nArmy of the Cumberland and Army of the Tennessee.\nThe primary Union forces in this theater were the Army of the Tennessee and Army of the Cumberland, named for the two rivers, Tennessee River and Cumberland River. After Meade's inconclusive fall campaign, Lincoln turned to the Western theater for new leadership. At the same time, the Confederate stronghold of Vicksburg surrendered, giving the Union control of the Mississippi River, permanently isolating the western Confederacy, and producing the new leader Lincoln needed, Ulysses S. Grant.\nThe Army of Tennessee, which served as the primary Confederate force in the Western theater, was formed on November 20, 1862, when General Braxton Bragg renamed the former Army of Mississippi. While Confederate forces had successes in the Eastern theater, they were defeated many times in the West.\nBattles.\nThe Union's key strategist and tactician in the West was Ulysses S. Grant, who led the Union to victories in battles at Fort Henry (February 6, 1862) and Fort Donelson (February 11 to 16, 1862), earning him the nickname of \"Unconditional Surrender\" Grant. With these victories, the Union gained control of the Tennessee and Cumberland Rivers. Nathan Bedford Forrest rallied nearly 4,000 Confederate troops and led them to escape across the Cumberland River. Nashville and central Tennessee fell to the Union, leading to attrition of local food supplies and livestock and a breakdown in social organization.\nConfederate general Leonidas Polk subsequently invaded Columbus, Kentucky, which ended Kentucky's policy of neutrality and turned it against the Confederacy. Grant used river transport and Andrew Hull Foote's gunboats of the Western Flotilla, threatening the Confederacy's \"Gibraltar of the West\" in Columbus, Kentucky. Although rebuffed at Belmont, Grant cut off Columbus. Confederate forces, lacking their gunboats, were forced to retreat and the Union took control of west Kentucky and opened Tennessee in March 1862.\nAt the Battle of Shiloh, in Shiloh, Tennessee, in April 1862, Confederate forces launched a surprise attack on Union forces, pushing them back to the Tennessee River as night fell. Over that night, however, the Navy landed reinforcements, and Grant counterattacked. Grant and the Union ultimately won a decisive victory in the first battle with a high number of casualties in what proved to be the first in a series of such battles. Confederate forces lost Albert Sidney Johnston, considered their finest general, before Lee emerged to assume command.\nOne of the early Union objectives was to capture the Mississippi River, which would permit it to cut the Confederacy in half. The Mississippi was opened to Union traffic to the southern border of Tennessee after it took Island No. 10, New Madrid, Missouri, and then Memphis, Tennessee.\nIn April 1862, the Union Navy captured New Orleans. \"The key to the river was New Orleans, the South's largest port [and] greatest industrial center.\" US naval forces under Farragut ran past Confederate defenses south of New Orleans. Confederate forces abandoned the city, giving the Union a critical anchor in the deep South, which allowed Union forces to move up the Mississippi. Memphis fell to Union forces on June 6, 1862, allowing it to serve as a key base for further Union advances south along the Mississippi. On the Mississippi River, the Union took every fortress city with the exception of Vicksburg, Mississippi. But Confederate control of Vicksburg was sufficient in preventing the Union from controlling the entire river.\nBragg's second invasion of Kentucky in the Confederate Heartland Offensive included initial successes, including Kirby Smith's triumph in the Battle of Richmond and the capture of the Kentucky capital of Frankfort, Kentucky, on September 3, 1862. The campaign ended with a meaningless victory over Maj. Gen. Don Carlos Buell at the Battle of Perryville, and Bragg was forced to end his attempt to invade and control Kentucky. Lacking logistical support and infantry recruits, Bragg was instead forced to retreat, and ended up being narrowly defeated by Maj. Gen. William Rosecrans in the Battle of Stones River in Tennessee in what proved to be the culmination of the Stones River Campaign.\nUS naval forces assisted Grant in the long, complex Vicksburg Campaign, which resulted in Confederate forces surrendering in the Battle of Vicksburg in July 1863, which cemented Union control of the Mississippi River in one of the war's turning points. The one clear Confederate victory in the West was the Battle of Chickamauga. After Rosecrans' successful Tullahoma Campaign, Bragg, reinforced by Lt. Gen. James Longstreet's Corps, defeated Rosecrans, despite the defensive stand of Maj. Gen. George Henry Thomas. Rosecrans retreated to Chattanooga, Tennessee, where Bragg was then besieged in the Chattanooga campaign. Grant marched to the relief of Rosecrans, where he led the defeat of Bragg in the Third Battle of Chattanooga, eventually causing Longstreet to abandon his Knoxville Campaign and driving Confederate forces out of Tennessee and opening a route to Atlanta and the heart of the Confederacy.\nTrans-Mississippi theater.\nBackground.\nThe Trans-Mississippi theater refers to military operations west of the Mississippi, encompassing most of Missouri, Arkansas, most of Louisiana, and the Indian Territory in present-day Oklahoma. The Trans-Mississippi District was formed by the Confederate States Army to better coordinate Ben McCulloch's command of troops in Arkansas and Louisiana, Sterling Price's Missouri State Guard, as well as the portion of Earl Van Dorn's command that included the Indian Territory and excluded the Army of the West. The Union's command was the Trans-Mississippi Division, or the Military Division of West Mississippi.\nBattles.\nThe first major battle of the Trans-Mississippi theater was the Battle of Wilson's Creek (August 1861). The Confederates were driven from Missouri early in the war as a result of the Battle of Pea Ridge.\nExtensive guerrilla warfare characterized the trans-Mississippi region, as the Confederacy lacked the troops and logistics to support regular armies that could challenge Union control. Roving Confederate bands such as Quantrill's Raiders terrorized the countryside, striking military installations and civilian settlements. The \"Sons of Liberty\" and \"Order of the American Knights\" attacked pro-Union people, elected officeholders, and unarmed uniformed soldiers. These partisans could not be driven out of Missouri, until an entire regular Union infantry division was engaged. By 1864, these violent activities harmed the nationwide antiwar movement organizing against the re-election of Lincoln. Missouri not only stayed in the Union, but Lincoln took 70 percent of the vote to win re-election.\nSmall-scale military actions south and west of Missouri sought to control Indian Territory and New Mexico Territory for the Union. The Battle of Glorieta Pass was the decisive battle of the New Mexico Campaign. The Union repulsed Confederate incursions into New Mexico in 1862, and the exiled Arizona government withdrew into Texas. In the Indian Territory, civil war broke out within tribes. About 12,000 Indian warriors fought for the Confederacy but fewer for the Union. The most prominent Cherokee was Brigadier General Stand Watie, the last Confederate general to surrender.\nAfter the fall of Vicksburg in July 1863, Jefferson Davis informed General Kirby Smith in Texas that he could expect no further help from east of the Mississippi. Although he lacked resources to beat Union armies, he built up a formidable arsenal at Tyler, along with his own Kirby Smithdom economy, a virtual \"independent fiefdom\" in Texas, including railroad construction and international smuggling. The Union, in turn, did not directly engage him. The Union's 1864 Red River Campaign to take Shreveport, Louisiana, failed and Texas remained in Confederate hands throughout the war.\nLower seaboard theater.\nBackground.\nThe lower seaboard theater refers to military and naval operations that occurred near the coastal areas of the Southeast as well as the southern part of the Mississippi. Union naval activities were dictated by the Anaconda Plan.\nBattles.\nOne of the earliest battles was fought in November 1861 at Port Royal Sound, south of Charleston. Much of the war along the South Carolina coast concentrated on capturing Charleston. In attempting to capture Charleston, the Union military tried two approaches: by land over James or Morris Islands or through the harbor. However, the Confederates were able to drive back each attack. A famous land attack was the Second Battle of Fort Wagner, in which the 54th Massachusetts Infantry took part. The Union suffered a serious defeat, losing 1,515 soldiers while the Confederates lost only 174. However, the 54th was hailed for its valor, which encouraged the general acceptance of the recruitment of African American soldiers into the Union Army, which reinforced the Union's numerical advantage.\nFort Pulaski on the Georgia coast was an early target for the Union navy. Following the capture of Port Royal, an expedition was organized with engineer troops under the command of Captain Quincy Adams Gillmore, forcing a Confederate surrender. The Union army occupied the fort for the rest of the war after repairing it.\nIn April 1862, a Union naval task force commanded by Commander David Dixon Porter attacked Forts Jackson and St. Philip, which guarded the river approach to New Orleans from the south. While part of the fleet bombarded the forts, other vessels forced a break in the obstructions in the river and enabled the rest of the fleet to steam upriver to the city. A Union army force commanded by Maj. Gen. Benjamin Butler landed near the forts and forced their surrender. Butler's controversial command of New Orleans earned him the nickname \"Beast\".\nThe following year, the Union Army of the Gulf commanded by Maj. Gen. Nathaniel P. Banks laid siege to Port Hudson for nearly eight weeks, the longest siege in US military history. The Confederates attempted to defend with the Bayou Teche Campaign but surrendered after Vicksburg. These surrenders gave the Union control over the Mississippi.\nSeveral skirmishes but no major battles were fought in Florida. The biggest was the Battle of Olustee in early 1864.\nPacific coast theater.\nThe Pacific coast theater refers to military operations on the Pacific Ocean and in the states and territories west of the Continental Divide.\nConquest of Virginia.\nAt the beginning of 1864, Lincoln made Grant commander of all Union armies. Grant made his headquarters with the Army of the Potomac and put Maj. Gen. William Tecumseh Sherman in command of most of the western armies. Grant understood the concept of total war and believed, along with Lincoln and Sherman, that only the utter defeat of Confederate forces and their economic base would end the war. This was total war not in killing civilians, but in injuring the Confederacy's capacity to produce and transport the supplies needed to continue the war. Sherman, at Grant's direction, seized provisions and destroyed homes, farms, and railroads, which Grant said \"would otherwise have gone to the support of secession and rebellion. This policy I believe exercised a material influence in hastening the end.\"\nGrant devised a coordinated strategy that would strike at the entire Confederacy from multiple directions. Generals Meade and Benjamin Butler were ordered to move against Lee near Richmond, General Franz Sigel was to attack the Shenandoah Valley, General Sherman was to capture Atlanta and march to the Atlantic Ocean, Generals George Crook and William W. Averell were to operate against railroad supply lines in West Virginia, and Maj. Gen. Nathaniel P. Banks was to capture Mobile, Alabama.\nGrant's Overland Campaign.\nGrant's army set out on the Overland Campaign intending to draw Lee into a defense of Richmond, where they would attempt to pin down and destroy the Confederate army. The Union army first attempted to maneuver past Lee and fought several battles, notably at the Wilderness, Spotsylvania, and Cold Harbor. These resulted in heavy losses on both sides and forced Lee's Confederates to fall back repeatedly. At the Battle of Yellow Tavern, the Confederates lost Jeb Stuart.\nAn attempt to outflank Lee from the south failed under Butler, who was trapped inside the Bermuda Hundred river bend. Each battle resulted in setbacks for the Union that mirrored those they had suffered under prior generals, though unlike them, Grant chose to fight on rather than retreat. Grant was tenacious and kept pressing Lee's Army of Northern Virginia back to Richmond. While Lee was preparing for an attack on Richmond, Grant unexpectedly turned south to cross the James River and began the protracted Siege of Petersburg, where the two armies engaged in trench warfare for over nine months.\nSheridan's Valley Campaign.\nTo deny the Confederacy continued use of the Shenandoah Valley as a base from which to launch invasions of Maryland and the Washington area, and to threaten Lee's supply lines for his forces, Grant launched the Valley campaigns in the spring of 1864. Initial efforts led by Gen. Sigel were repelled at the Battle of New Market by Confederate Gen. John C. Breckinridge. The Battle of New Market was the Confederacy's last major victory, and included a charge by teenage VMI cadets. After relieving Sigel, and following mixed performances by his successor, Grant finally found a commander, General Philip Sheridan, aggressive enough to prevail against the army of Maj. Gen. Jubal A. Early. After a cautious start, Sheridan defeated Early in a series of battles in September and October 1864, including a decisive defeat at the Battle of Cedar Creek. Sheridan then proceeded through that winter to destroy the agricultural base of the Shenandoah Valley, a strategy similar to the tactics Sherman later employed in Georgia.\nSherman's March to the Sea.\nMeanwhile, Sherman maneuvered from Chattanooga to Atlanta, defeating Confederate Generals Joseph E. Johnston and John Bell Hood. The fall of Atlanta on September 2, 1864, guaranteed the reelection of Lincoln. Hood left the Atlanta area to swing around and menace Sherman's supply lines and invade Tennessee in the Franklin\u2013Nashville Campaign. Union Maj. Gen. John Schofield defeated Hood at the Battle of Franklin, and George H. Thomas dealt Hood a massive defeat at the Battle of Nashville, effectively destroying Hood's army.\nLeaving Atlanta, and his base of supplies, Sherman's army marched, with no destination set, laying waste to about 20 percent of the farms in Georgia on his March to the Sea. He reached the Atlantic at Savannah, Georgia, in December 1864. Sherman's army was followed by thousands of freed slaves; there were no major battles along the march. Sherman turned north through South Carolina and North Carolina, to approach the Confederate Virginia lines from the south, increasing the pressure on Lee's army.\nThe Waterloo of the Confederacy.\nLee's army, thinned by desertion and casualties, was now much smaller than Grant's. One last Confederate attempt to break the Union hold on Petersburg failed at the decisive Battle of Five Forks on April 1. The Union now controlled the entire perimeter surrounding Richmond\u2013Petersburg, completely cutting it off from the Confederacy. Realizing the capital was now lost, Lee's army and the Confederate government were forced to evacuate. The Confederate capital fell on April 2\u20133, to the Union XXV Corps, composed of black troops. The remaining Confederate units fled west after a defeat at Sayler's Creek on April 6.\nEnd of the war.\nLee did not intend to surrender, but planned to regroup at Appomattox Station, where supplies were to be waiting, and then continue the war. Grant chased Lee and got in front of him, so that when Lee's army reached the village of Appomattox Court House, they were surrounded. After an initial battle, Lee decided the fight was hopeless, and surrendered his Army of Northern Virginia to Grant on April 9, 1865, during a conference at the McLean House. In an untraditional gesture and as a sign of Grant's respect and anticipation of peacefully restoring Confederate states to the Union, Lee was permitted to keep his sword and horse, Traveller. His men were paroled, and a chain of Confederate surrenders began.\nOn April 14, 1865, Lincoln was shot by John Wilkes Booth, a Confederate sympathizer. Lincoln died early the next morning. Lincoln's vice president, Andrew Johnson, was unharmed, because his would-be assassin, George Atzerodt, lost his nerve, so Johnson was immediately sworn in as president.\nMeanwhile, Confederate forces across the South surrendered, as news of Lee's surrender reached them. On April 26, the same day Sergeant Boston Corbett killed Booth at a tobacco barn, Johnston surrendered nearly 90,000 troops of the Army of Tennessee to Sherman at Bennett Place, near present-day Durham, North Carolina. It proved to be the largest surrender of Confederate forces. On May 4, all remaining Confederate forces in Alabama, Mississippi, and Louisiana east of the Mississippi, under the command of Lt. General Richard Taylor, surrendered. Confederate president Davis was captured in retreat at Irwinville, Georgia on May 10.\nThe final land battle was fought on May 13, 1865, at the Battle of Palmito Ranch in Texas. On May 26, 1865, Confederate Lt. Gen. Simon B. Buckner, acting for Edmund Smith, signed a military convention surrendering Confederate forces in the Trans-Mississippi Department. This date is often cited by contemporaries and historians as the effective end date of the war. On June 2, with most of his troops having already gone home, a reluctant Kirby Smith had little choice but to sign the official surrender document. On June 23, Cherokee leader and Brig. General Stand Watie became the last Confederate general to surrender his forces.\nOn June 19, 1865, Union Maj. Gen. Gordon Granger announced General Order No. 3, bringing the Emancipation Proclamation into effect in Texas and freeing the last slaves of the Confederacy. The anniversary of this date is now celebrated as Juneteenth.\nThe naval part of the war ended more slowly. On April 11, two days after Lee's surrender, when Lincoln proclaimed that foreign nations had no further \"claim or pretense\" to deny equality of maritime rights and hospitalities to US warships and, in effect, that rights extended to Confederate ships to use neutral ports as safe havens from US warships should end. Having no response to Lincoln's proclamation, President Johnson issued a similar proclamation dated May 10, more directly stating that the war was almost at an end and insurgent cruisers still at sea, and prepared to attack US ships, should not have rights to do so through use of safe foreign ports or waters. Britain finally responded on June 6, by transmitting a letter from Foreign Secretary John Russell, 1st Earl Russell, to the Lords of the Admiralty withdrawing rights to Confederate warships to enter British ports and waters. US Secretary of State Seward welcomed the withdrawal of concessions to the Confederates. Finally, on October 18, Russell advised the Admiralty that the time specified in his June message had elapsed and \"all measures of a restrictive nature on vessels of war of the United States in British ports, harbors, and waters, are now to be considered as at an end\". Nonetheless, the final Confederate surrender was in Liverpool, England where James Iredell Waddell, the captain of CSS \"Shenandoah\", surrendered the cruiser to British authorities on November 6.\nLegally, the war did not end until August 20, 1866, when President Johnson issued a proclamation that declared \"that the said insurrection is at an end and that peace, order, tranquillity, and civil authority now exist in and throughout the whole of the United States of America\".\nUnion victory.\nThe causes of the war, reasons for its outcome, and even its name are subjects of lingering contention. The North and West grew wealthy while the once-rich South became poor for a century. The national political power of the slaveowners and rich Southerners ended. Historians are less sure about the results of postwar Reconstruction, especially regarding the second-class citizenship of the freedmen and their poverty.\nHistorians have debated whether the Confederacy could have won the war. Most scholars, including James M. McPherson, argue Confederate victory was possible. McPherson argues that the North's advantage in population and resources made Northern victory likely, but not guaranteed. He argues that if the Confederacy had fought using unconventional tactics, it would have more easily been able to hold out long enough to exhaust the Union. Confederates did not need to invade and hold enemy territory to win, but only to fight a defensive war to convince the North the cost of winning was too high. The North needed to conquer and hold vast stretches of enemy territory and defeat Confederate armies to win. Lincoln was not a military dictator and could fight only as long as the American public supported the war. The Confederacy sought to win independence by outlasting Lincoln; however, after Atlanta fell and Lincoln defeated McClellan in the election of 1864, hope for a political victory for the South ended. Lincoln had secured the support of the Republicans, War Democrats, border states, emancipated slaves, and the neutrality of Britain and France. By defeating the Democrats and McClellan, he defeated the Copperheads, who had wanted a negotiated peace with the Confederacy.\nSome scholars argue the Union held an insurmountable long-term advantage over the Confederacy in industrial strength and population. Confederate actions, they argue, only delayed defeat. Historian Shelby Foote expressed this view succinctly: &lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;I think that the North fought that war with one hand behind its back... If there had been more Southern victories, and a lot more, the North simply would have brought that other hand out from behind its back. I don't think the South ever had a chance to win that War.\nA minority view among historians is that the Confederacy lost because, as E. Merton Coulter put it, \"people did not will hard enough and long enough to win\". However, most historians reject the argument. McPherson, after reading thousands of letters written by Confederate soldiers, found strong patriotism that continued to the end; they truly believed they were fighting for freedom and liberty. Even as the Confederacy was visibly collapsing in 1864\u201365, most Confederate soldiers were fighting hard. Historian Gary Gallagher cites General Sherman, who in early 1864 commented, \"The devils seem to have a determination that cannot but be admired.\" Despite their loss of slaves and wealth, with starvation looming, Sherman continued, \"yet I see no sign of let-up\u2014some few deserters\u2014plenty tired of war, but the masses determined to fight it out\".\nAlso important were Lincoln's eloquence in articulating the national purpose and his skill in keeping the border states committed to the Union cause. The Emancipation Proclamation was an effective use of the president's war powers. The Confederate government failed to get Europe involved militarily. Southern leaders needed to get European powers to help break the blockade the Union had created around Southern ports. Lincoln's naval blockade was 95 percent effective at stopping trade goods; as a result, imports and exports to the South declined significantly. The abundance of European cotton and Britain's hostility to slavery, along with Lincoln's naval blockades, severely decreased any chance that Britain or France would enter the war.\nHistorian Don H. Doyle has argued that the Union victory had a major impact on world history. The Union victory energized popular democratic forces. A Confederate victory, on the other hand, would have meant a new birth of slavery, not of freedom. Historian Fergus Bordewich, following Doyle, argues:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The North's victory decisively proved the durability of democratic government. Confederate independence, on the other hand, would have established an American model for reactionary politics and race-based repression that would likely have cast an international shadow into the 20th century and perhaps beyond. Scholars have debated what the effects of the war were on political and economic power in the South. The prevailing view is that the southern planter elite retained its powerful position in the South. However, a 2017 study challenges this, noting that while some Southern elites retained their economic status, the turmoil of the 1860s created greater opportunities for economic mobility in the South, than in the North.\nCasualties.\nExact casualty figures were collected for the Union, but Confederate records were poorly kept, or lost in the chaos of defeat. Thus, the casualty figures are imprecise and based on statistical extrapolation. Neither side kept a tally of civilian deaths due to the war. In the 19th century, the death toll had been estimated at a lower 620,000. In 2011, the death toll was recalculated based on a 1% sample of census data, yielding approximately 750,000 soldier deaths, 20 percent higher than traditionally estimated, and possibly as high as 850,000. The figure was recalculated to 698,000 soldier deaths in 2024 after examining newly available full census records. Mortality rates among men were as high as 19 percent in Louisiana, and 16.6\u201316.7 percent in Georgia and South Carolina respectively.\nThe war resulted in at least 1,030,000 casualties (3 percent of the population), including an estimated 698,000 soldier deaths\u2014two-thirds by disease. Based on 1860 census figures, 8 percent of all white men aged 13\u201343 died in the war, including 6 percent in the North and 18 percent in the South. About 56,000 soldiers died in prison camps during the War. An estimated 60,000 soldiers lost limbs. As McPherson notes, the war's \"cost in American lives was as great as in all of the nation's other wars combined through Vietnam\".\nOf the 359,528 Union Army dead, amounting to 15 percent of the over two million who served:\nIn addition, there were 4,523 deaths in the Navy (2,112 in battle) and 460 in the Marines (148 in battle).\nAfter the Emancipation Proclamation authorized freed slaves to \"be received into the armed service of the United States\", former slaves who escaped from plantations or were liberated by the Union Army were recruited into the United States Colored Troops regiments of the Union Army, as were black men who had not been slaves. The US Colored Troops made up 10 percent of the Union death toll\u201415 percent of Union deaths from disease and less than 3 percent of those killed in battle. Losses among African Americans were high. In the last year and a half and from all reported casualties, approximately 20 percent of all African Americans enrolled in the military died during the war. Their mortality rate was significantly higher than white soldiers. While 15 percent of US Volunteers and just 9 percent of white Regular Army troops died, 21 percent of US Colored Troops died.\nWhile the figures of 360,000 army deaths for the Union and 260,000 for the Confederacy remained commonly cited, they are incomplete. In addition to many Confederate records being missing, partly as a result of Confederate widows not reporting deaths due to being ineligible for benefits, both armies only counted troops who died during their service and not the tens of thousands who died of wounds or diseases after being discharged. This often happened only days or weeks later. Francis Amasa Walker, superintendent of the 1870 census, used census and surgeon general data to estimate a minimum of 500,000 Union military deaths and 350,000 Confederate military deaths, a total of 850,000 soldiers. While Walker's estimates were originally dismissed because of the 1870 census's undercounting, it was later found that the census was only off by 6.5 percent and that the data Walker used would be roughly accurate.\nLosses were far higher than during the war with Mexico, which saw roughly 13,000 American deaths, including fewer than two thousand killed in battle, between 1846 and 1848. One reason for the high number of battle deaths in the civil war was the continued use of tactics similar to those of the Napoleonic Wars, such as charging. With the advent of more accurate rifled barrels, Mini\u00e9 balls, and (near the end of the war for the Union) repeating firearms such as the Spencer repeating rifle and the Henry repeating rifle, soldiers were mowed down when standing in lines in the open. This led to the adoption of trench warfare, a style of fighting that defined much of World War I.\nDeaths among former slaves has proven hard to estimate, due to the lack of reliable census data, though they were known to be considerable, as former slaves were set free or escaped in massive numbers in areas where the Union army did not have sufficient shelter, doctors, or food for them. Professor Jim Downs states that tens of thousands to hundreds of thousands of slaves died during the war from disease, starvation, or exposure, and that if these deaths are counted in the war's total, the death toll would exceed 1\u00a0million.\nIt is estimated that during the war, of the equines killed, including horses, mules, donkeys and even confiscated children's ponies, over 32,600 of them belonged to the Union and 45,800 the Confederacy. However, other estimates place the total at 1,000,000.\nIt is estimated that 544 Confederate flags were captured during the war by the Union. The flags were sent to the War Department in Washington. The Union flags captured by the Confederates were sent to Richmond.\nEmancipation.\nAbolishing slavery was not a Union war goal from the outset but quickly became one. Lincoln initially claimed that preserving the Union was the central goal. In contrast, the South fought to preserve slavery. While not all Southerners saw themselves as fighting for slavery, most officers and over a third of the rank and file in Lee's army had close family ties to slavery. To Northerners, the motivation was primarily to preserve the Union, not to abolish slavery. However, as the war dragged on, and it became clear that slavery was central to the conflict, and that emancipation was (to quote the Emancipation Proclamation) \"a fit and necessary war measure for suppressing [the] rebellion\", Lincoln and his cabinet made ending slavery a war goal, culminating in the Emancipation Proclamation. Lincoln's decision to issue the Proclamation angered Peace Democrats (\"Copperheads\") and War Democrats, but energized most Republicans. By warning that free blacks would flood the North, Democrats made gains in the 1862 elections, but they did not gain control of Congress. The Republicans' counterargument that slavery was the mainstay of the enemy steadily gained support, with the Democrats losing decisively in the 1863 elections in the Northern state of Ohio, when they tried to resurrect anti-black sentiment.\nEmancipation Proclamation.\nThe Emancipation Proclamation legally freed the slaves in states \"in rebellion\", but, as a practical matter, slavery for the 3.5\u00a0million black people in the South effectively ended in each area when Union armies arrived. The last Confederate slaves were freed on June 19, 1865, celebrated as the modern holiday of Juneteenth. Slaves in the border states and those in some former Confederate territory occupied before the Emancipation Proclamation were freed by state action or (on December 6, 1865) by the Thirteenth Amendment. The Emancipation Proclamation enabled African Americans, both free blacks and escaped slaves, to join the Union Army. About 190,000 volunteered, further enhancing the numerical advantage the Union armies enjoyed over the Confederates, who did not dare emulate the equivalent manpower source for fear of undermining the legitimacy of slavery.\nDuring the war, sentiment concerning slaves, enslavement, and emancipation in the United States was divided. Lincoln's fears of making slavery a war issue were based on a harsh reality: abolition did not enjoy wide support in the west, the territories, and the border states. In 1861, Lincoln worried that premature attempts at emancipation would mean the loss of the border states, and that \"to lose Kentucky is nearly the same as to lose the whole game\". Copperheads and some War Democrats opposed emancipation, although the latter eventually accepted it as part of the total war needed to save the Union.\nLincoln reversed attempts at emancipation by Secretary of War Simon Cameron and Generals John C. Fr\u00e9mont and David Hunter, in an effort to retain the loyalty of the border states and the War Democrats. Lincoln warned the border states that a more radical type of emancipation would happen if they rejected his plan of gradual compensated emancipation and voluntary colonization. But compensated emancipation occurred only in the District of Columbia, where Congress had the power to enact it. When Lincoln told his cabinet about his proposed emancipation proclamation, which would apply to the states still in rebellion on January 1, 1863, Seward advised Lincoln to wait for a Union military victory before issuing it, because to do otherwise would seem like \"our last shriek on the retreat\". Walter Stahr, however, writes, \"There are contemporary sources, however, that suggest others were involved in the decision to delay\", and Stahr quotes them.\nLincoln laid the groundwork for public support in an open letter published in response to Horace Greeley's \"The Prayer of Twenty Millions\"; the letter stated that Lincoln's goal was to save the Union, and that, if he freed the slaves, it would be as a means to that end. He also had a meeting at the White House with five African American representatives on August 14, 1862. Arranging for a reporter to be present, he urged his visitors to agree to the voluntary colonization of black people. Lincoln's motive for both his letter to Greeley and his statement to the black visitors was apparently to make his forthcoming Emancipation Proclamation more palatable to racist white people. A Union victory in the Battle of Antietam on September 17, 1862, provided Lincoln with an opportunity to issue the preliminary Emancipation Proclamation, and the War Governors' Conference added support for the proclamation.\nLincoln issued his preliminary Emancipation Proclamation on September 22, 1862. It stated that slaves in all states in rebellion on January 1, 1863, would be free. He issued his final Emancipation Proclamation on January 1, 1863, keeping his promise. In his letter to Albert G. Hodges, Lincoln explained his belief that \"If slavery is not wrong, nothing is wrong\u00a0... And yet I have never understood that the Presidency conferred upon me an unrestricted right to act officially upon this judgment and feeling\u00a0... I claim not to have controlled events, but confess plainly that events have controlled me.\"\nLincoln's moderate approach succeeded in inducing the border states to remain in the Union and War Democrats to support the Union. The border states, which included Kentucky, Missouri, Maryland, Delaware, and Union-controlled regions around New Orleans, Norfolk, Virginia, and elsewhere, were not covered by the Emancipation Proclamation. Nor was Tennessee, which had come under Union control. Missouri and Maryland abolished slavery on their own; Kentucky and Delaware did not. Still, the proclamation did not enjoy universal support. It caused much unrest in what were then considered western states, where racist sentiments led to a great fear of abolition. There was some concern that the proclamation would lead to the secession of western states, and its issuance prompted the stationing of Union troops in Illinois in case of rebellion.\nSince the Emancipation Proclamation was based on the president's war powers, it applied only in territory held by Confederates at the time it was issued. However, the Proclamation became a symbol of the Union's growing commitment to add emancipation to the Union's definition of liberty. The Emancipation Proclamation greatly reduced the Confederacy's hope of being recognized or otherwise aided by Britain or France. By late 1864, Lincoln was playing a leading role in getting the House of Representatives to vote for the Thirteenth Amendment, which mandated the ending of chattel slavery.\nReconstruction.\nThe war devastated the South and posed serious questions of how it would be reintegrated into the Union. The war destroyed much of the South's wealth, in part because wealth held in enslaved people (at least $1,000 each for a healthy adult prior to the war) was wiped off the books. All accumulated investment in Confederate bonds was forfeited; most banks and railroads were bankrupt. The income per person dropped to less than 40 percent of that of the North, and that lasted into the 20th century. Southern influence in the federal government, previously considerable, was greatly diminished until the second half of the 20th century. Reconstruction began during the war, with the Emancipation Proclamation of January 1863, and it continued until 1877. Its most important elements were the three \"Reconstruction Amendments\" to the Constitution: the 13th outlawing slavery (1865), the 14th guaranteeing citizenship to former slaves (1868), and the 15th prohibiting the denial of voting rights \"on account of race, color, or previous condition of servitude\" (1870). From the Union perspective, the goals of Reconstruction were to consolidate victory by reuniting the Union, to guarantee a \"republican form of government\" for the ex-Confederate states, and to permanently end slavery\u2014and prevent semi-slavery status.\nPresident Johnson, who took office in April 1865, took a lenient approach and saw the achievement of the main war goals as realized in 1865, when each ex-rebel state repudiated secession and ratified the Thirteenth Amendment. Radical Republicans demanded proof that Confederate nationalism was dead and that the slaves were truly free. They overrode Johnson's vetoes of civil rights legislation, and the House impeached him, although the Senate did not convict him. In 1868 and 1872, the Republican candidate Grant won the presidency. In 1872, the \"Liberal Republicans\" argued that the war goals had been achieved and Reconstruction should end. They chose Horace Greeley to head a presidential ticket in 1872 but were decisively defeated. In 1874, Democrats, primarily Southern, took control of Congress and opposed further reconstruction. The Compromise of 1877 closed with a national consensus, except on the part of former slaves, that the war had finally ended. With the withdrawal of federal troops, however, white men retook control of every Southern legislature, and the Jim Crow era of disenfranchisement and legal segregation was ushered in.\nThe war had a demonstrable impact on American politics. Many veterans on both sides were elected to political office, including five US presidents: Ulysses Grant, Rutherford B. Hayes, James A. Garfield, Benjamin Harrison, and William McKinley.\nMemory and historiography.\nThe war is a central event in American collective memory. There are innumerable statues, commemorations, books, and archival collections. The memory includes the home front, military affairs, the treatment of soldiers, both living and dead, in the war's aftermath, depictions of the war in literature and art, evaluations of heroes and villains, and considerations of the moral and political lessons of the war. The last theme includes moral evaluations of racism and slavery, heroism and cowardice in combat and behind the lines, and issues of democracy and minority rights, as well as the notion of an \"Empire of Liberty\" influencing the world.\nHistorians have paid more attention to the causes of the war than to the war itself. Military history has largely developed outside academia, leading to a proliferation of studies by non-scholars who nevertheless are familiar with the primary sources and pay close attention to battles and campaigns and who write for the general public. Practically every major figure in the war, both North and South, has had a serious biographical study.\nEven the name used for the conflict has been controversial, with many names used for it. During and immediately after the war, Northern historians often used a term like \"War of the Rebellion\". Writers in rebel states often referred to the \"War for Southern Independence\". Some Southerners have described it as the \"War of Northern Aggression\".\nLost Cause.\nThe memory of the war in the white South crystallized in the myth of the \"Lost Cause\": that the Confederate cause was just and heroic. The myth shaped regional identity and race relations for generations. Alan T. Nolan notes that the Lost Cause was expressly a rationalization, a cover-up to vindicate the name and fame of those in rebellion. Some claims revolve around the insignificance of slavery as a cause; some appeals highlight cultural differences between North and South; the military conflict by Confederate actors is idealized; in any case, secession was said to be lawful. Nolan argues that the adoption of the Lost Cause perspective facilitated the reunification of the North and the South while excusing the \"virulent racism\" of the 19th century, sacrificing black American progress to white man's reunification. He also deems the Lost Cause \"a caricature of the truth. This caricature wholly misrepresents and distorts the facts of the matter\" in every instance.\nThe Lost Cause myth was formalized by Charles A. Beard and Mary R. Beard, whose \"The Rise of American Civilization\" (1927) spawned Beardian historiography. The Beards downplayed slavery, abolitionism, and issues of morality. Though this interpretation was abandoned by the Beards in the 1940s, and by historians generally by the 1950s, Beardian themes still echo among Lost Cause writers.\nBattlefield preservation.\nThe first efforts at Civil War battlefield preservation and memorialization came during the war, with the establishment of National Cemeteries at Gettysburg, Mill Springs and Chattanooga. Soldiers began erecting markers on battlefields beginning with the First Battle of Bull Run in 1861. The oldest surviving monument is the Hazen Brigade Monument near Murfreesboro in Central Tennessee, built in the summer of 1863 by soldiers in Union Col. William B. Hazen's brigade to mark the spot where they buried their dead, following the Battle of Stones River.\nIn the 1890s, the government established five Civil War battlefield parks under the jurisdiction of the War Department, beginning with the creation of the Chickamauga and Chattanooga National Military Park at Fort Oglethorpe, Georgia, and the Antietam National Battlefield in Sharpsburg, Maryland, in 1890. The Shiloh National Military Park was established in 1894 in Shiloh, Tennessee, followed by the Gettysburg National Military Park in 1895, and Vicksburg National Military Park in 1899. In 1933, these five parks and other national monuments were transferred to the National Park Service. Chief among modern efforts to preserve Civil War sites has been the American Battlefield Trust, with more than 130 battlefields in 24 states. The five major battlefield parks operated by the National Park Service had a combined 3\u00a0million visitors in 2018, down 70% from 10\u00a0million in 1970.\nCommemoration.\nThe Civil War has been commemorated in many ways, ranging from the reenactment of battles, to statues and memorial halls being erected, to films, and to stamps and coins with Civil War themes being issued, all of which helped to shape public memory. These commemorations occurred in greater numbers on the 100th and 150th anniversaries of the war.\nHollywood's take on the war has been especially influential in shaping public memory, as in such film classics as \"The Birth of a Nation\" (1915), \"Gone with the Wind\" (1939), and \"Lincoln\" (2012). Ken Burns's PBS television series \"The Civil War\" (1990) is well-remembered, though criticized for its historical inaccuracy.\nTechnological significance.\nTechnological innovations during the war had a great impact on 19th-century science. The war was an early example of an \"industrial war\", in which technological might is used to achieve military supremacy. New inventions, such as the train and telegraph, delivered soldiers, supplies and messages at a time when horses had been the fastest way to travel. It was also in this war that aerial warfare, in the form of reconnaissance balloons, was first used. It saw the first action involving steam-powered ironclad warships in naval warfare history. Repeating firearms such as the Henry rifle, Spencer rifle, Colt revolving rifle, Triplett &amp; Scott carbine and others, first appeared during the Civil War; they were a revolutionary invention that would soon replace muzzle-loading and single-shot firearms. The war saw the first appearances of rapid-firing weapons and machine guns such as the Agar gun and Gatling gun.\nIn works of culture and art.\nThe Civil War is one of the most studied events in American history, and the collection of cultural works around it is enormous. This section gives an abbreviated overview of the most notable works.\nSee also.\n&lt;templatestyles src=\"Stack/styles.css\"/&gt;\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\nBibliography.\nSources referenced.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nWeb sources.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nSoldier life: North and South.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "864", "revid": "24473539", "url": "https://en.wikipedia.org/wiki?curid=864", "title": "Andy Warhol", "text": "American artist and filmmaker (1928\u20131987)\nAndy Warhol (; born Andrew Warhola Jr.; August 6, 1928 \u2013 February 22, 1987) was an American artist, filmmaker, and impresario. Drawing on imagery from advertising, mass media, and celebrity culture, he transformed everyday consumer goods and familiar icons\u2014such as Campbell's Soup cans, Marilyn Monroe, and Brillo boxes\u2014into renowned artworks, establishing himself as a leading figure in the Pop art movement. Warhol is widely regarded as the most important American artist of the second half of the 20th century.\nBorn to Rusyn immigrant parents in Pittsburgh, Warhol began his career as a successful commercial illustrator in New York before turning to fine art, where his embrace of mechanical reproduction, silkscreen printing, and serial repetition challenged traditional boundaries between high and low culture. His studio, The Factory, became a hub for avant-garde experimentation, bringing together drag queens, poets, bohemians, musicians, and wealthy patrons. He directed numerous underground films\u2014most notably \"Chelsea Girls\" (1966), \"Lonesome Cowboys\" (1968), and Blue Movie (1969)\u2014featuring a shifting group of personalities known as Warhol superstars, and he is often credited with popularizing the expression \"15 minutes of fame.\" Warhol also managed the influential rock band the Velvet Underground, who performed at his multimedia happenings, the \"Exploding Plastic Inevitable\" (1966\u201367). He expressed his queer identity through many of his artworks and films at a time when homosexuality in the United States was heavily stigmatized and legally constrained.\nAfter surviving an assassination attempt by radical feminist Valerie Solanas in June 1968, Warhol shifted his attention toward developing the Factory into a more structured business enterprise. He founded \"Interview\" magazine and published several books, including \"The Philosophy of Andy Warhol\" (1975) and \"Popism\" (1980). During this period, he also expanded into television, hosting the series \"Fashion\" (1979\u201380), \"Andy Warhol's TV\" (1980\u201383), and \"Andy Warhol's Fifteen Minutes\" (1985\u201387). Warhol died of cardiac arrhythmia at the age of 58 following gallbladder surgery in February 1987.\nWarhol has been described as the \"bellwether of the art market\", with several of his works ranking among the most expensive paintings ever sold. In 2013, \"Silver Car Crash (Double Disaster)\" (1963) sold for $105 million. In 2022, \"Shot Sage Blue Marilyn\" (1964) sold for $195 million, the highest price ever paid at auction for a work by an American artist. Warhol has been the subject of numerous retrospective exhibitions, books, and documentary films. The Andy Warhol Museum in Pittsburgh, which holds an extensive permanent collection of his art and archives, is the largest museum in the United States dedicated to a single artist\nEarly life and education.\nWarhol was born on August 6, 1928, in Pittsburgh, Pennsylvania. He was the fourth child of Ondrej Warhola (Americanized as Andrew Warhola Sr.; 1889\u20131942) and Julia Warhola (n\u00e9e\u00a0Zavack\u00e1, 1891\u20131972). His parents were working-class Rusyn emigrants from Mik\u00f3, Austria-Hungary (now Mikov\u00e1 in northeast Slovakia).\nIn 1912, Warhol's father emigrated to the United States and found work in a coal mine. His wife joined him nine years later in 1921. The family lived at 55 Beelen Street and later at 3252 Dawson Street in the Oakland neighborhood of Pittsburgh. They were Ruthenian Catholic and attended St. John Chrysostom Byzantine Catholic Church. Warhol had two older brothers, Paul (1922\u20132014) and John (1925\u20132010), as well as an older sister, Maria (1912; died in infancy). Warhol's nephew James Warhola, became a successful children's book illustrator.\nAt the age of eight, Warhol had a streptococcal infection that led to scarlet fever. Because there were no antibiotics to treat the illness it progressed to rheumatic fever and ultimately the neurological condition Sydenham's chorea, sometimes referred to as St. Vitus' Dance. At times he was confined to bed and made to remain home from school. He would spend these days drawing, creating scrapbooks from Hollywood magazines, and cutting out images from comic books that his mother bought him. He also enjoyed using the family's Kodak Baby Brownie Special camera, and after noticing his passion for photography, his father and brothers built a darkroom in the basement for him.\nWhen Warhol started art classes at Holmes School in 1937, his art teacher saw his potential and got him admitted to Saturday drawing lessons at the Carnegie Institute in Pittsburgh. In 1942, his father died after drinking contaminated water from a coal mine in West Virginia.\nWarhol excelled in school and won a Scholastic Art and Writing Award. After graduating from Schenley High School in 1945, he enrolled at the Carnegie Institute of Technology in Pittsburgh, where he studied commercial art. During his time there, Warhol joined the campus Modern Dance Club and Beaux Arts Society. He also served as art director of the student art magazine, \"Cano\", illustrating a cover in 1948 and a full-page interior illustration in 1949. These are believed to be his first two published artworks. Warhol earned a Bachelor of Fine Arts in pictorial design in 1949.\nCareer.\n1940s.\nWarhol moved to New York City after graduating from the Carnegie Institute of Technology in June 1949. He was accompanied by his classmate Philip Pearlstein. They lived in a sixth-floor walk-up tenement apartment on St. Mark's Place near Tompkins Square Park.\nWarhol went to see Tina Fredericks, the art director of \"Glamour\" magazine, on his second day in New York. He had met Fredericks on his brief visit to New York the year prior. His career as a commercial artist began when she commissioned him to draw shoes for an advertisement after purchasing a small $10 drawing of an orchestra for herself.\n1950s.\nGallerist Alexander Iolas is credited with discovering Warhol. He organized his first solo exhibition, \"Andy Warhol: Fifteen Drawings Based on the Writings of Truman Capote\", at the Hugo Gallery in New York in 1952.\nIn 1955, Warhol began designing advertisements for shoe manufacturer Israel Miller. He developed his \"blotted line\" technique, applying ink to paper and then blotting the ink while still wet, which was akin to a printmaking process on the most rudimentary scale. His use of tracing paper and ink allowed him to repeat the basic image and also to create endless variations on the theme. American photographer John Coplans recalled that \"nobody drew shoes the way Andy did. He somehow gave each shoe a temperament of its own, a sort of sly, Toulouse-Lautrec kind of sophistication, but the shape and the style came through accurately and the buckle was always in the right place. The kids in the apartment [which Andy shared in New York \u2013 note by Coplans] noticed that the vamps on Andy's shoe drawings kept getting longer and longer but [Israel] Miller didn't mind. Miller loved them.\"\nIn 1956, Warhol was included in a group exhibition at the Museum of Modern Art in New York. That year, he traveled around the world with his friend, production designer Charles Lisanby, studying art and culture in several countries. While in Kyoto, Japan, Warhol drew a stylized portrait of business tycoon Madame Helena Rubinstein.\nIn 1956, Warhol began to sketch ornate footwear as a hobby. He designed whimsical shoes that were embellished with gold leaf, and each represented a famous figure such as Truman Capote, Kate Smith, James Dean, Julie Andrews, Elvis Presley, and Zsa Zsa Gabor. They sold for $50 to $225 apiece when they were exhibited at the Bodley Gallery in New York in 1957.\nTo attract attention to himself as an artist, Warhol printed books of his illustrations such as \"25 Cats Name Sam and One Blue Pussy\" (1957), which he would distribute to people, in an attempt to generate work. He would often use his mother Julia Warhol's calligraphy to accompany his illustrations.\nWarhol habitually used the expedient of tracing photographs projected with an epidiascope. Using prints by Edward Wallowitch, the photographs would undergo a subtle transformation during Warhol's often cursory tracing of contours and hatching of shadows. Warhol used Wallowitch's photograph \"Young Man Smoking a Cigarette\" (c.\u20091956) for a 1958 design for a book cover he submitted to Simon and Schuster for the Walter Ross pulp novel \"The Immortal\", and later used others for his series of paintings.\nWith the rapid expansion of the record industry, RCA Records hired Warhol to design album covers and promotional materials. Warhol was also working with high-end advertising clients such as Tiffany &amp; Co. by the late 1950s.\n1960s.\nAt a time when traditional artists did not buy the work of other artists, Warhol collected them. To survive, gallery artists typically did commercial work, such as window displays, and avoided using their real names because it was frowned upon. In contrast, Warhol gained recognition as a commercial artist, which caused tension with other artists.\nThis period was a key moment in the development of his persona. Some have suggested that his frequent refusal to comment on his work, to speak about himself, confining himself in interviews to responses like \"Um, no\" and \"Um, yes\", and often allowing others to speak for him\u2014and even the evolution of his pop style\u2014can be traced to the years when Warhol was first dismissed by the inner circles of the New York art world.\nIn 1960, Warhol purchased a townhouse at 1342 Lexington Avenue in the Carnegie Hill neighborhood of Manhattan, which he also used as his art studio. The Victorian architecture structure included a basement suite for his mother.\nBy 1961, Warhol was well-known as one of \"New York's more stylish window dressers and top shoe illustrators\". His hand-drawn illustrations were receiving placement in the society pages of \"The New York Times\", although competing photography depictions were on the rise. That April, his pop paintings were exhibited for the first time in the window display of the Bonwit Teller department store on Fifth Avenue at 57th Street. Five paintings based on comic strips and newspaper ads served as the backdrop for mannequins wearing spring dresses: \"Saturday's Popeye\", \"Little King\", \"Superman\", \"Before and After\", and \"Advertisement\".\nA significant turning point in Warhol's career was when he began drawing dollar bills, which inspired him to start silkscreening in the spring of 1962. Warhol was taught silkscreen printmaking techniques by Max Arthur Cohn at his graphic arts business in Manhattan. Warhol is often considered to be a pioneer in silkscreen printmaking and his techniques became more elaborate throughout his career.In May 1962, Warhol was featured in an article in \"Time\" with his painting \"Big Campbell's Soup Can with Can Opener (Vegetable)\" (1962), which initiated his most sustained motif, the Campbell's soup can. That painting became Warhol's first to be shown in a museum when it was exhibited at the Wadsworth Atheneum in Hartford in July 1962. On July 9, 1962, Warhol's exhibition opened at the Ferus Gallery in Los Angeles with \"Campbell's Soup Cans\", marking his West Coast debut of pop art.\nIn November 1962, Warhol had an exhibition at Eleanor Ward's Stable Gallery in New York. The exhibit included the works \"Gold Marilyn Monroe\", eight of the classic \"Marilyn\" series also named \"Flavor Marilyns\", \"Marilyn Diptych\", \"100 Soup Cans\", \"100 Coke Bottles\", and \"100 Dollar Bills\". \"Gold Marilyn Monroe\" was bought by the architect Philip Johnson and donated to the Museum of Modern Art.\nIn December 1962, New York City's Museum of Modern Art hosted a symposium on pop art, during which artists such as Warhol were attacked for \"capitulating\" to consumerism. Critics were appalled by Warhol's open acceptance of market culture, which set the tone for his reception.\nIn 1963, Warhol formed The Druds, a short-lived avant-garde noise band that included notable figures from the New York minimal art and proto-conceptual art scenes, including Larry Poons, La Monte Young, Walter De Maria, Jasper Johns, Claes Oldenberg, and Lucas Samaras.\nIn January 1963, Warhol rented his first studio\u2014an old firehouse at 159 East 87th Street\u2014where he created his \"Elvis\" series, which included \"Eight Elvises\" (1963) and \"Triple Elvis\" (1963). These portraits, along with a series of Elizabeth Taylor portraits, were shown at his second exhibition at the Ferus Gallery in Los Angeles. Later that year, Warhol relocated his studio to East 47th Street, which would turn into The Factory. The Factory became a popular gathering spot for a wide range of artists, writers, musicians and underground celebrities.\nWarhol was among the artist commissioned to create an artwork for the New York State Pavilion at the 1964 World's Fair in Queens, New York. He created the mural \"Thirteen Most Wanted Men\" (1964), which was painted over after government officials objected to the images before the fair opened in April 1964.\nWarhol had his second exhibition at the Stable Gallery in the spring of 1964, which featured sculptures of commercial boxes stacked and scattered throughout the space to resemble a warehouse. For the exhibition, Warhol custom ordered wooden boxes and silkscreened graphics onto them. The sculptures\u2014\"Brillo Box\", \"Del Monte Peach Box\", \"Heinz Tomato Ketchup Box\", \"Kellogg's Cornflakes Box\", \"Campbell's Tomato Juice Box\" and \"Mott's Apple Juice Box\"\u2014sold for $200 to $400 depending on the size of the box.\nA pivotal event in Warhol's career was \"The American Supermarket\" exhibition at Paul Bianchini's Upper East Side gallery in late 1964. The show was presented as a typical small supermarket environment, except that everything in it\u2014from the produce, canned goods, meat, posters on the wall, etc.\u2014was created by prominent pop artists of the time, among them sculptor Claes Oldenburg, Mary Inman and Bob Watts. Warhol designed a $12 paper shopping bag\u2014plain white with a red Campbell's soup can. His painting of a can of a Campbell's soup cost $1,500 while each autographed can sold for three for $18, $6.50 each. The exhibit was one of the first mass events that directly confronted the general public with both pop art and the perennial question of what art is.\nWarhol used assistants to increase his productivity and these collaborations would remain a defining and controversial aspect of his working methods throughout his career. One of Warhol's most important collaborators during this period was Gerard Malanga who assisted him with the production of silkscreens and films at The Factory, Warhol's studio that was covered in aluminium foil and painted silver by Billy Name.\nIn November 1964, Warhol's first \"Flowers\" series exhibited at the Leo Castelli Gallery in New York. In May 1965, his second \"Flowers\" series, which had more sizes and color variation that the previous, was shown at Galerie Ileana Sonnabend in Paris. During this trip Warhol announced that he was retiring from painting to focus on film.\nFrom the mid-1960s to the early 1970s, Warhol surrounded himself with a retinue of bohemian and counterculture eccentrics upon whom he bestowed the designation \"superstars\", including Baby Jane Holzer, Brigid Berlin, Ondine, Edie Sedgwick, Ingrid Superstar, Nico, International Velvet, Mary Woronov, Viva, Ultra Violet, Joe Dallesandro, Candy Darling, Holly Woodlawn, Jackie Curtis and Jane Forth. These people participated in the Factory films, and some\u2014like Berlin\u2014remained friends with Warhol until his death. Important figures in the New York underground art/cinema world, such as writer John Giorno and filmmaker Jack Smith, also appear in Warhol films of the 1960s, revealing Warhol's connections to a diverse range of artistic scenes during this time. Less well known was his support and collaboration with several teenagers during this era, who would achieve prominence later in life, including writer David Dalton, photographer Stephen Shore, and artist Bibbe Hansen.The experimental rock group the Velvet Underground was taken on by Warhol around the end of 1965. In his capacity as their manager, he included them as a key component of his \"Exploding Plastic Inevitable\" multimedia performances in 1966 and 1967, and he funded their debut album, \"The Velvet Underground &amp; Nico\" (1967).\nWarhol made a conscious decision to oppose conventional painting, stating that he no longer believed in painting. In response to art dealer Ivan Karp's suggestion to paint cows, Warhol produced \"Cow Wallpaper,\" which covered the walls of the Leo Castelli Gallery during his April 1966 exhibition.\nIn November 1966, Warhol was hired by the Abraham &amp; Straus department store in Brooklyn to promote the \"Paint-your-own-dress\" collection by the Mars Manufacturing Company, which included a white paper dress that came with a paintbrush and a box of watercolors. In a live demonstration, Warhol decorated two dresses at the store that were given to the Brooklyn Museum using Nico as his model.\nIn 1967, Warhol established Factory Additions for his printmaking and publishing enterprise. To duplicate prints for a wide audience, Factory Additions published multiple portfolios of ten images each in editions of 250. These were then printed using professional screen printers.\nWarhol intended to present the film \"Chelsea Girls\" (1966) at the 1967 Cannes Film Festival, but it wasn't shown because \"the festival authorities explained that the film was too long, there were technical problems.\"\nTo finance his film productions, Warhol began going on college lecture tours, where he screened some of his underground films and answered audience questions. Warhol sent actor Allen Midgette to impersonate him during a West Coast college tour in October 1967. Warhol reimbursed the four institutions where he did not appear and returned to the campuses in 1968.\nIn February 1968, Warhol's first solo museum exhibition was mounted at the Moderna Museet in Stockholm.\n1968 assassination attempt\nOn June 3, 1968, radical feminist writer Valerie Solanas shot Warhol and Mario Amaya, art critic and curator, at The Factory. Solanas had been a marginal figure in the Factory scene before the shooting. She authored the \"SCUM Manifesto\", a separatist feminist tract that advocated the elimination of men; and appeared in the Warhol film \"I, a Man\" (1967). Amaya received only minor injuries and was released from the hospital later the same day. Warhol was seriously wounded by the attack and barely survived: he remained in hospital for nearly two months. Solanas turned herself in to the police a few hours after the attack and said that Warhol \"had too much control over my life.\" She was subsequently diagnosed with paranoid schizophrenia and eventually sentenced to three years in prison.\nJed Johnson, an assistant who was at the Factory during the shooting, visited Warhol daily during his hospitalization, and the two developed an intimate relationship. Johnson moved in with Warhol shortly after he was discharged from the hospital to help him recuperate and take care of his ailing mother, Julia Warhola.\nThe assassination attempt had a profound effect on Warhol's life and art. He had physical effects for the rest of his life, including being required to wear a surgical corset. The Factory became more regulated, and Warhol focused on making it a business enterprise. He credited his collaborator Paul Morrissey with transforming the Factory into a \"regular office.\"\nPost-shooting\nIn August 1968, Warhol made an appearance in court after Phillip \"Fufu\" Van Scoy Smith, an investor in a canceled film adaptation of the Charlotte Bront\u00eb novel \"Jane Eyre\", sued him for $80,000. A legal battle ensued for 2 years, ending after the backer failed to show up in court.\nIn September 1968, Warhol and Ultra Violet attended a party to celebrate the completion of the film \"Midnight Cowboy\". In the film, there is a party scene featuring members of the Factory that was filmed during Warhol's hospitalization.\nWarhol hosted a party at the Factory for Nico's album \"The Marble Index\" in September 1968. Warhol, Viva and Ultra Violet appeared on the cover of the November 10, 1968, issue of \"The New York Times Magazine\".\nIn February 1969, Warhol and his entourage traveled to Los Angeles to discuss a prospective movie deal with Columbia Pictures. Warhol, who had always had an interest in photography, used a Polaroid camera to document his recuperation after the shooting. A few of his photographs were published in the May 1969 edition of \"Esquire\" magazine. He would become well known for always carrying his Polaroid camera to chronicle his encounters. Eventually, he used instant photography as the basis for his silkscreen portraits when he resumed painting in the 1970s.\nAfter the release of the erotic film \"Blue Movie\" (1969), Warhol rented the Fortune Theater at 62 East 4th Street, where he screened male pornographic films from June 25 to August 5, 1969. The project was managed by Gerard Malanga under his business, Poetry on Film. The theater was called \"Andy Warhol's Theater: Boys to Adore Galore.\" Morrissey came up with the idea to rent the theater and set the admission price at $5.\nWarhol and British journalist John Wilcock founded \"Interview\" magazine in the fall of 1969. The magazine was initially published as \"inter/VIEW: A Monthly Film Journal\". It was revamped a few years later and came to represent Warhol's social life and fascination with celebrity.\nIn 1969, Warhol received an invitation to curate an exhibition using items from the permanent collection of the RISD Museum in Providence. In October 1969, the exhibition \"Raid the Icebox\" opened at Rice University's Institute for the Arts in Houston. In 1970, the show traveled to the Isaac Delgado Museum in New Orleans before arriving at the RISD Museum.\n1970s.\nCompared to the success and scandal of Warhol's work in the 1960s, the early 1970s were much quieter years, as he became more entrepreneurial. He was generally regarded as quiet, shy and a meticulous observer. Art critic Robert Hughes called him \"the white mole of Union Square\". His fashion evolved from what Warhol called his \"leather look\" to his \"Brooks Brothers look,\" which included a Brooks Brothers shirt and tie, DeNoyer blazer, and Levi jeans.\nAs Warhol continued to forge into filmmaking, he had established himself as \"one of the most celebrated and well-known pop art figures to emerge from the sixties.\" The Pasadena Art Museum in Pasadena organized a major retrospective of his work in 1970. The show traveled to the Museum of Contemporary Art, Chicago; Stedelijk Van Abbemuseum, Eindhoven, The Netherlands; Mus\u00e9e d'Art Moderne de la Ville de Paris; Tate Gallery, London; and Whitney Museum of American Art, New York. The Whitney exhibition in 1971 distinctly featured Warhol's \"Cow Wallpaper\" (1966) as the backdrop for his paintings.\nIn May 1971, Warhol's theater production, \"Andy Warhol's Pork\", opened at the La MaMa Experimental Theatre in New York. In August 1971, it was brought to the Roundhouse in London.\nIn late 1971, Warhol and his business partner Paul Morrissey purchased Eothen, an oceanfront estate in Montauk, New York on Long Island. They began renting the main house on the property in 1972. Lee Radziwill, Jackie Kennedy, The Rolling Stones, Elizabeth Taylor, Truman Capote, and Halston were among the estate's notable guests.\nWarhol is credited with both the cover concept and photography for The Rolling Stones' album \"Sticky Fingers\" (1971). He received a Grammy nomination for Best Album Cover at the 14th Annual Grammy Awards in 1972. \nIn 1972, Warhol planned the Halston runway presentation at the Coty Awards. Although Warhol was considered to be apolitical, he participated in an exhibition with the poster \"Vote McGovern\" (1972) in effort to raise funds for George McGovern's 1972 presidential campaign.\nWarhol and his live-in boyfriend Jed Johnson got a dachshund puppy, Archie, in November 1972. Warhol doted on Archie and took him everywhere: to the studio, parties, restaurants, and on trips to Europe. He created portraits of Johnson, Archie, and Amos\u2014a second dachshund they got a few years later.\nWarhol began traveling to Europe more frequently and developed a fondness for Paris. Warhol had an apartment that he shared with his business manager Fred Hughes on the Left Bank of Paris on Rue du Cherche-Midi.\nIn October 1972, Warhol's work was included in the inaugural show at the Art Museum of South Texas in Corpus Christi, Texas. Between 1972 and 1973, Warhol created a series of portraits of Chinese Communist leader Mao Zedong with funding from two New York galleries, Knoedler &amp; Co. and the Leo Castelli Gallery, as well as art collector Peter Brant. In February 1974, some of the Mao portraits were installed at the Mus\u00e9e Galliera in Paris.\nIn 1974, Warhol and Johnson moved into a townhouse at 57 East 66th Street in Manhattan's Lenox Hill neighborhood. By this time, Warhol's public presence had increased significantly due to his attendance at parties. In 1974, he said, \"I try to go around so often so much and try to go to every party so that they'll be bored with me and stop writing about me.\"\nWarhol designed the sets for the Broadway musical \"Man on the Moon\" by John Philips of the Mamas &amp; the Papas, which opened in January 1975 at the Little Theatre in New York. In May 1975, Warhol attended President Gerald Ford's state dinner in honor of the Shah of Iran, Mohammad Reza Pahlavi, at the White House. In September 1975, he went on an eight-city U.S. book tour for his book \"The Philosophy of Andy Warhol (From A to B &amp; Back Again)\", followed by stops in Italy, France, and England.\nIn 1976, Warhol and painter Jamie Wyeth were commissioned to paint each other's portraits by the Coe Kerr Gallery in Manhattan. In January 1977, Warhol traveled to Kuwait for the opening of his exhibition at the Dhaiat Abdulla Al Salem Gallery. In June 1977, Warhol was invited to a special reception honoring the \"Inaugural Artists\" who had contributed prints to the Jimmy Carter presidential campaign. In 1977, Warhol was commissioned by art collector Richard Weisman to create \"Athletes\", ten portraits consisting of the leading athletes of the day.\nThe opening of Studio 54 in 1977 ushered in a new era in New York City nightlife. Warhol would often socialize at Studio 54 and take note of the drug-fueled activities that his friends engaged in at parties. In 1977, Warhol began taking nude photographs of men in various poses and performing sexual acts\u2014referred to as \"landscapes\"\u2014for what became known as the \"Torsos\" and \"Sex Parts\" series. Most of the men were street hustlers and male prostitutes brought to the Factory by Halston's lover Victor Hugo. This caused tension in Warhol's relationship with Johnson who did not approve of his friendship with Hugo. \"When Studio 54 opened things changed with Andy. That was New York when it was at the height of its most decadent period, and I didn't take part. I never liked that scene, I was never comfortable. \u2026 Andy was just wasting his time, and it was really upsetting. \u2026 He just spent his time with the most ridiculous people,\" said Johnson.\nIn 1979, Warhol formed a publishing company, Andy Warhol Books, and released the book \"Exposures\", which contained his photographs of famous friends and acquaintances. In November 1979, he embarked on a three-week book tour in the US.\nAccording to former \"Interview\" editor Bob Colacello, Warhol devoted much of his time to rounding up new, rich patrons for portrait commissions\u2014including Shah of Iran Mohammad Reza Pahlavi, his wife Empress Farah Pahlavi, his sister Princess Ashraf Pahlavi, Mick Jagger, Liza Minnelli, John Lennon, Diana Ross and Brigitte Bardot. In November 1979, the Whitney Museum of American Art mounted the exhibition \"Andy Warhol: Portraits of the '70s\" to celebrate the \"very commercial celebrity of the '70s, the decade of \"People\" magazine and designer jeans.\" Some critics disliked his exhibits of portraits of personalities and celebrities, calling them superficial, facile and commercial, with no depth or indication of the significance of the subjects.\n1980s.\nWarhol had a re-emergence of critical and financial success in the 1980s, partially due to his affiliation and friendships with a number of prolific younger artists, who were dominating the \"bull market\" of 1980s New York art: Jean-Michel Basquiat, Julian Schnabel, David Salle and other so-called Neo-Expressionists, as well as members of the Transavantgarde movement in Europe, including Francesco Clemente and Enzo Cucchi. Warhol also earned street credibility and graffiti artist Fab Five Freddy paid homage to him by painting an entire train with Campbell soup cans.His 1980 exhibition \"Ten Portraits of Jews of the Twentieth Century\" at the Jewish Museum in Manhattan was panned by critics. Warhol\u2014who was uninterested in Judaism and Jews\u2014had described in his diary as \"They're going to sell.\"\nThe New York Academy of Art was founded in part by Warhol. First established in 1980, the institute's mission was to \"revive traditional methods of training artists.\" According to fellow co-founder Stuart Pivar, \"What happened was that Modernism got boring [for Warhol] \u2026 But his overall game plan, what he really believed, was that the modern age was going away and that we were entering a neoclassical period.\"\nIn 1981, Warhol worked on a project with Peter Sellars and Lewis Allen that would create a traveling stage show called, \"A No Man Show\", with a life-sized animatronic robot in the exact image of Warhol. The \"Andy Warhol Robot\" would then be able to read Warhol's diaries as a theatrical production. Warhol was quoted as saying, \"I'd like to be a machine, wouldn't you?\"\nWarhol also had an appreciation for intense Hollywood glamour. He once said: \"I love Los Angeles. I love Hollywood. They're so beautiful. Everything's plastic, but I love plastic. I want to be plastic.\" Warhol occasionally walked the fashion runways and did product endorsements, represented by Zoli Agency and later Ford Models.\nIn 1983, Warhol was commissioned to create a poster for the centennial of the Brooklyn Bridge. The poster was his contribution to the 1983 New York Art Expo.\nWarhol created a series of endangered species silkscreen prints for his exhibition \"Warhol's Animals: Species at Risk\" at New York City's American Museum of Natural History in April 1983. Warhol donated 10 of the 150 sets he made to wildlife organizations \"so they could sell them to raise money.\"\nPrior to the 1984 Sarajevo Winter Olympics, he teamed with 15 other artists, including David Hockney and Cy Twombly, and contributed a Speed Skater print to the Art and Sport collection. The Speed Skater was used for the official Sarajevo Winter Olympics poster.\nIn 1984, \"Vanity Fair\" commissioned Warhol to produce a portrait of Prince, to accompany an article that celebrated the success of \"Purple Rain\" and its accompanying movie. Referencing the many celebrity portraits produced by Warhol across his career, \"Orange Prince (1984)\" was created using a similar composition to the Marilyn \"Flavors\" series from 1962, among some of Warhol's first celebrity portraits. Prince is depicted in a pop color palette commonly used by Warhol, in bright orange with highlights of bright green and blue. The facial features and hair are screen-printed in black over the orange background.\nIn September 1985, Warhol's joint exhibition with Basquiat, \"Paintings\", opened to negative reviews at the Tony Shafrazi Gallery. That month, despite apprehension from Warhol, his silkscreen series \"Reigning Queens\" was shown at the Leo Castelli Gallery. In the \"Andy Warhol Diaries\", Warhol noted: \"They were supposed to be only for Europe\u2014nobody here cares about royalty and it'll be another bad review.\"\nIn January 1987, Warhol traveled to Milan for the opening of his last exhibition, \"Last Supper\", at the Palazzo delle Stelline. The next month, Warhol modeled with jazz musician Miles Davis for Koshin Satoh's fashion show at the Tunnel in New York City on February 17, 1987.\nDeath.\nWarhol was initially diagnosed with a gallstone in 1973, but he adamantly rejected surgery because he feared hospitals. When he was insistent about avoiding surgery, his internist Denton Cox attempted to obtain an experimental medication from Japan. The artist also sought guidance from a chiropractor and nutritionist, who suggested that he wear a small crystal. Dehydrated and unable to eat, Warhol was in excruciating pain by February 1987.\nWarhol was admitted to New York Hospital in Manhattan on February 20, and he underwent gallbladder surgery on February 21. His surgeon Bjorn Thorbjarnarson found his gallbladder \"on the verge of perforating\" and in danger of \"spilling the infection into (Warhol's) belly.\" Warhol was awake and able to walk about, make phone calls, and watch television when both of his doctors visited him after the four-hour operation. His private nurse, Min Cho, saw his growing pallor at 4:30 the following morning, but she did not call the hospital's cardiac-arrest team until 5:45\u00a0am, when he was \"unresponsive\" and turning blue. He was pronounced dead at 6:31\u00a0a.m. from sudden cardiac arrhythmia.\nWarhol's brothers took his body back to Pittsburgh, where an open-casket wake was held at the Thomas P. Kunsak Funeral Home. The solid bronze casket had gold-plated rails and white upholstery. Warhol was dressed in a black cashmere suit, a paisley tie, and a platinum wig. He was laid out holding a small prayer book and a red rose. The funeral liturgy was held at the Holy Ghost Byzantine Catholic Church on Pittsburgh's North Side on February 26, 1987. Monsignor Peter Tay delivered the eulogy. After the liturgy, the casket, covered with white roses and asparagus ferns, was driven to St. John the Baptist Byzantine Catholic Cemetery in Bethel Park, a south suburb of Pittsburgh, where Warhol was buried near his parents. The priest said a brief prayer at the graveside and sprinkled holy water on the casket. Before the casket was lowered, Warhol's close friend and Interview staffer Paige Powell placed copies of the February and March issues and a bottle of Beautiful Eau de Parfum by Est\u00e9e Lauder into his grave.\nA memorial service for Warhol was held at St. Patrick's Cathedral in Manhattan on April 1, 1987. It was attended by over 2,000 people, including Warhol collaborators and numerous celebrities such as Raquel Welch, Debbie Harry, Liza Minnelli, Claus von B\u00fclow, and Calvin Klein, among others. Eulogies were given by John Richardson and Yoko Ono. Afterwards, there was a luncheon at the Diamond Horseshoe nightclub beneath the Paramount Hotel.\nWrongful death lawsuit.\nIn April 1987, the New York State Health Department released a report that Warhol was given inadequate care by New York Hospital from the time he was admitted until the hours before his death. These included not performing the appropriate work-up tests prior to surgery, giving Warhol antibiotics to which he may have experienced an allergic response, causing him to become overhydrated, and repeatedly failing to take accurate notes on his chart. There were no issues with the procedure itself, according to the report. In response, the hospital dismissed the private nurse who had been employed to care for Warhol and penalized the staff nurse who had been tasked with overseeing her. However, the hospital claimed that the nursing deficiencies were not significant enough to cause Warhol's death.\nIn December 1991, Warhol's family sued the hospital in the New York Supreme Court for inadequate care, before judge Ira Gammerman, saying that the arrhythmia was caused by improper care and water intoxication. The malpractice case was quickly settled out of court; Warhol's family received an undisclosed sum of money.\nPrior to his surgery, doctors expected Warhol to survive, though a re-evaluation of the case about thirty years after his death showed many indications that Warhol's surgery was in fact riskier than originally thought. It was widely reported at the time that Warhol had died of a \"routine\" surgery, though when considering factors such as his age, a family history of gallbladder problems, his previous gunshot wound, and his medical state in the weeks leading up to the procedure, the potential risk of death following the surgery appeared to have been significant.\nArt works.\nPaintings and prints.\nBy the beginning of the 1960s, pop art was an experimental form that several artists were independently adopting; some of these pioneers, such as Roy Lichtenstein, would later become synonymous with the movement. Warhol, who would become famous as the \"Pope of Pop\", turned to this new style, where popular subjects could be part of the artist's palette. His early paintings show images taken from cartoons and advertisements, hand-painted with paint drips. Those drips emulated the style of successful abstract expressionists such as Willem de Kooning.\nFrom these beginnings, he developed his later style and subjects. Instead of working on a signature subject matter, as he started out to do, he worked more and more on a signature style, slowly eliminating the handmade from the artistic process. Warhol was an early adopter of the silkscreen printmaking process as a technique for making paintings. His later drawings were traced from slide projections. Warhol had several assistants through the years, including Gerard Malanga, Ronnie Cutrone, and George Condo, who produced his silkscreen multiples, following his directions to make different versions and variations.\nWarhol's first pop art paintings were displayed in April 1961, serving as the backdrop for New York Department Store Bonwit Teller's window display. For his first major exhibition in 1962, Warhol painted his famous cans of Campbell's soup, which he claimed to have had for lunch for 20 years. Warhol began to make paintings of iconic American objects such as dollar bills, mushroom clouds, electric chairs, cans, Coca-Cola bottles, and celebrities such as Marilyn Monroe, Elvis Presley and Elizabeth Taylor, as well as newspaper headlines. His work became popular and controversial. Warhol had this to say about Coca-Cola:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;What's great about this country is that America started the tradition where the richest consumers buy essentially the same things as the poorest. You can be watching TV and see Coca-Cola, and you know that the President drinks Coca-Cola, Liz Taylor drinks Coca-Cola, and just think, you can drink Coca-Cola, too. A Coke is a Coke and no amount of money can get you a better Coke than the one the bum on the corner is drinking. All the Cokes are the same and all the Cokes are good. In 1962, Warhol created his famous \"Marilyn\" series. The \"Flavor Marilyns\" were selected from a group of fourteen canvases in the sub-series. Some of the canvases were named after Life Savers candy flavors and others are identified by their background colors. Warhol produced both comic and serious works; his subject could be a soup can or an electric chair. Warhol used the same techniques\u2014silkscreens, reproduced serially, and often painted with bright colors\u2014whether he painted celebrities, everyday objects, or images of suicide, car crashes and disasters, as in the 1962\u201363 \"Death and Disaster\" series.\nIn 1970, screenprinting materials from Warhol's 1960s studio were taken to Europe to produce a new series of prints under the name \"Sunday B Morning.\" Warhol initially signed and numbered one edition of 250, but after a dispute with some studio employees, unauthorized unsigned editions were produced in Brussels using the same photo negatives and color codes he had provided. These later prints were stamped \"Sunday B Morning\" or \"Add Your Own Signature Here,\" and some carried Warhol's disclaimer, \"This is not by me, Andy Warhol.\" The most widely known of these are the 1967 \"Marilyn Monroe\" portfolio prints, which continued to be produced into the 2010s. Sunday B Morning editions have also been issued for other works, including \"Flowers, Campbell's Soup I, Campbell's Soup Cans II,Gold Marilyn Monroe\", \"Mao\", and \"Dollar Bill\". Early versions bore black stamps on the verso, shifting to blue by the 1980s.\nIn the 1970s, Warhol evolved into a portraiture artist, painting mostly commissioned portraits of celebrities. In 1979, Warhol was commissioned to paint a BMW M1 Group 4 racing version for the fourth installment of the BMW Art Car project. He was initially asked to paint a BMW 320i in 1978, but the car model was changed and it didn't qualify for the race that year. Warhol was the first artist to paint directly onto the automobile himself instead of letting technicians transfer a scale-model design to the car. Reportedly, it took him only 23 minutes to paint the entire car. Racecar drivers Herv\u00e9 Poulain, Manfred Winkelhock and Marcel Mignot drove the car at the 1979 24 Hours of Le Mans.\nHis oxidation paintings, also known as \"piss paintings,\" such as \"Jean-Michel Basquiat\" (1982), are also noteworthy in this context. It's also important to notice the way these works\u2014and their means of production\u2014mirrored the atmosphere at Warhol's Factory. Former \"Interview\" editor Bob Colacello recalled that Victor Hugo was a \"ghost pisser\" on the Oxidations, urinating on canvases primed with copper paint by Warhol or Ronnie Cutrone\u2014another \"ghost pisser\" whose vitamin B, Warhol said, made the colors prettier. Warhol sometimes used his own urine early on, along with various visitors who found it amusing to help him paint.\nAfter many years of silkscreen, oxidation, photography, etc., Warhol returned to painting with a brush in hand. In 1983, Warhol began collaborating with artists Jean-Michel Basquiat and Francesco Clemente. Warhol and Basquiat created a series of more than 50 large collaborative works between 1984 and 1985. Despite criticism when these were first shown, Warhol called some of them \"masterpieces.\"\nIn 1985, Warhol used Amiga computers to generate digital art, including the short film \"You Are the One\". He also did a demonstration on live TV with singer Debbie Harry as a model.\nWarhol was commissioned by gallerist Alexander Iolas to produce work based on Leonardo da Vinci's \"The Last Supper\". His \"Last Supper\" exhibition opened shortly before his death in 1987. It is the largest series of religious-themed works by an American artist. In the period just before his death, Warhol was also working on \"Cars\", a series of paintings for Mercedes-Benz.\nDrawings.\nDespite being most known for his work in printmaking, particularly silkscreen, Warhol was also a very skilled illustrator and draughtsman. His early drawings on paper provide a feeling of ease and immediacy since they have similarities to both blind contour and continuous line drawing techniques. Warhol pioneered the blotted line technique, which combined aspects of printmaking and graphite drawing on paper, while he was working as a commercial illustrator. Best known of these early works are his drawings of shoes. Some of his personal drawings were self-published in small booklets, such as \"Yum, Yum, Yum\" (about food), \"Ho, Ho, Ho\" (about Christmas) and \"Shoes, Shoes, Shoes\". His most artistically acclaimed book of drawings is probably \"A Gold Book\", compiled of sensitive drawings of young men. \"A Gold Book\" is so named because of the gold leaf that decorates its pages. The drawings from his last years demonstrate the skill and technique that have been refined over the course of his illustrious career.\nSculptures.\nWarhol's most well-known sculptures are his Brillo boxes\u2014silkscreened ink on wood replicas of the large branded cardboard boxes used to hold 24 packages of Brillo soap pads. The original Brillo design was by commercial artist James Harvey. Warhol's Brillo boxes were part of a series of \"grocery carton\" works that also included Heinz ketchup and Campbell's tomato juice boxes. Other famous works include the \"Silver Clouds\"\u2014helium filled, silver mylar, pillow-shaped balloons. A \"Silver Cloud\" was included in the traveling exhibition \"Air Art\" (1968\u20131969) curated by Willoughby Sharp. \"Clouds\" was also adapted by Warhol for avant-garde choreographer Merce Cunningham's dance piece \"RainForest\" (1968).\nArt market.\nIn 1965, Warhol's large \"Flowers\" paintings were sold for $6,000 and the smaller ones for as low as $400. In the 1970s, a commissioned portrait by Warhol cost $25,000, with a discounted rate of $40,000 for two portraits.\nIn 1970, Warhol's painting \"Campbell's Soup Can With Peeling Label\" (1962) sold for $60,000 at an auction by Parke-Bernet Galleries. At the time it was the high price ever paid at a public auction for a work by a living American artist. In 1978, Warhol's painting \"19 Cents\" sold at auction for $95,000\u2014then a record price for the artist\u2014after having originally been purchased for $1,300 in 1962.\nThe value of Warhol's work has been on an endless upward trajectory since his death in 1987. In 2014, his works accumulated $569\u00a0million at auction, which accounted for more than a sixth of the global art market. However, there have been some dips. According to art dealer Dominique L\u00e9vy: \"The Warhol trade moves something like a seesaw being pulled uphill: it rises and falls, but each new high and low is above the last one.\" She attributes this to the consistent influx of new collectors intrigued by Warhol. \"At different moments, you've had different groups of collectors entering the Warhol market, and that resulted in peaks in demand, then satisfaction and a slow down,\" before the process repeats another demographic or the next generation.\nIn 1998, \"Orange Marilyn\" (1964), a depiction of Marilyn Monroe, sold for $17.3\u00a0million, which at the time set a new record as the highest price paid for a Warhol artwork. In 2007, one of Warhol's 1963 paintings of Elizabeth Taylor, \"Liz (Colored Liz)\", which was owned by actor Hugh Grant, sold for $23.7\u00a0million at Christie's.\nIn 2007, Stefan Edlis and Gael Neeson sold Warhol's \"Turquoise Marilyn\" (1964) to financier Steven A. Cohen for $80\u00a0million. In May 2007, \"Green Car Crash\" (1963) sold for $71.1\u00a0million and \"Lemon Marilyn\" (1962) sold for $28\u00a0million at Christie's post-war and contemporary art auction. In 2016, \"Large Campbell's Soup Can\" (1964) was sold at a Sotheby's auction to a South American collector for 7.4\u00a0million. In November 2009, \"200 One Dollar Bills\" (1962) at Sotheby's for $43.8\u00a0million.\nIn 2008, \"Eight Elvises\" (1963) was sold by Annibale Berlingieri for $100\u00a0million to a private buyer. The work depicts Elvis Presley in a gunslinger pose. It was first exhibited in 1963 at the Ferus Gallery in Los Angeles. Warhol made 22 versions of the \"Elvis\" portraits, eleven of which are held in museums. In May 2012, \"Double Elvis (Ferus Type)\" sold at auction at Sotheby's for $37\u00a0million. In November 2014, \"Triple Elvis (Ferus Type)\" sold for $81.9\u00a0million at Christie's.\nIn May 2010, a purple self-portrait of Warhol from 1986 that was owned by fashion designer Tom Ford sold for $32.6\u00a0million at Sotheby's. In November 2010, \"Men in Her Life\" (1962), based on Elizabeth Taylor, sold for $63.4\u00a0million at Phillips de Pury and \"Coca-Cola (4)\" (1962) sold for $35.3\u00a0million at Sotheby's. In May 2011, Warhol's first self-portrait from 1963 to 1964 sold for $38.4\u00a0million and a red self-portrait from 1986 sold for $27.5\u00a0million at Christie's. In May 2011, \"Liz No. 5 (Early Colored Liz)\" sold for $26.9\u00a0million at Phillips.\nIn November 2013, Warhol's rarely seen 1963 diptych, \"Silver Car Crash (Double Disaster)\", sold at Sotheby's for $105.4\u00a0million, a new record for the artist. In November 2013, \"Coca-Cola (3)\" (1962) sold for $57.3\u00a0million at Christie's. In May 2014, \"White Marilyn\" (1962) sold for $41\u00a0million at Christie's. In November 2014, \"Four Marlons\" (1964), which depicts Marlon Brando, sold for $69.6\u00a0million at Christie's. In May 2015, \"Silver Liz (diptych)\", painted in 1963, sold for $28\u00a0million and \"Colored Mona Lisa\" (1963) sold for $56.2\u00a0million at Christie's. In May 2017, Warhol's 1962 painting \"Big Campbell's Soup Can With Can Opener (Vegetable)\" sold for $27.5\u00a0million at Christie's. In 2017, billionaire hedge-fund manager Ken Griffin purchased \"Orange Marilyn\" privately for around $200\u00a0million. In March 2022, \"Silver Liz (Ferus Type)\" sold for 2.3\u00a0billion yen ($18.9\u00a0million) at Shinwa Auction, which set a new record for the highest bid ever at auction in Japan. In May 2022, \"Shot Sage Blue Marilyn\" (1964) sold for $195\u00a0million at Christie's, becoming the most expensive American artwork sold at auction.\nCollectors.\nEmily and Burton Tremaine were among Warhol's early collectors and influential supporters. Among the over 15 artworks purchased, \"Marilyn Diptych\" (now at Tate Modern, London) and \"A boy for Meg\" (now at the National Gallery of Art in Washington, DC), were purchased directly out of Warhol's studio in 1962. One Christmas, Warhol left a small \"Head of Marilyn Monroe\" by the Tremaine's door at their New York apartment in gratitude for their support and encouragement.\nRobert Scull and Ethel Scull were among the first people to support Warhol's artwork. \"Ethel Scull 36 Times\" (1963), which is presently housed in the Metropolitan Museum of Art's collection, was Warhol's first commissioned portrait.\nCreative works.\nWarhol was a fan of \"Business Art\", as he stated in his book \"The Philosophy of Andy Warhol from A to B and Back Again\". \"I went into business art. I wanted to be an art business man or a business artist. Being good in business is the most fascinating kind of art,\" he said. His transformation into a mere business artist was a point of criticism. In hindsight, however, some critics have come to view Warhol's superficiality and commerciality as \"the most brilliant mirror of our times\", contending that \"Warhol had captured something irresistible about the zeitgeist of American culture in the 1970s.\"\nIn addition to his paintings and drawings, Warhol directed and produced films, managed the Velvet Underground, and authored numerous books, as well as producing works in such diverse media as audio, photography, sculpture, theater, fashion and performance art. His ability to blur the lines between art, commerce, and everyday life was central to his creative philosophy. \"That's probably the greatest thing about Warhol: the way he penetrated and summarized our world, to the point that distinguishing between him and our everyday life is basically impossible, and in any case useless,\" said artist Maurizio Cattelan.\nFilmography.\nBetween 1963 and 1968, Warhol made more than 600 underground films, including short black-and-white \"screen test\" portraits of Factory visitors. Many of his films premiered at the New Andy Warhol Garrick Theatre in Greenwich Village and 55th Street Playhouse in Midtown Manhattan.\nHis early experimental films were silent observations of very typical daily life. \"Sleep\" (1964) monitors poet John Giorno sleeping for six hours. \"Kiss\" (1964) shows various couples kissing. The film \"Eat\" (1964) consists of an artist Robert Indiana eating a mushroom for 45 minutes. The 35-minute film \"Blow Job\" (1964) is one continuous shot of the face of DeVeren Bookwalter supposedly receiving oral sex from poet Willard Maas, although the camera never tilts down to prove this.\nFor these efforts, Mekas presented Warhol with the Independent Film Award of 1964, which was \"the underground's answer to Oscar.\" \"Newsday\"'s Mike McGrady hailed Warhol as \"the Cecil B. DeMille of the Off-Hollywood movie makers.\" \"The\" \"Village Voice\" called him one of the \"most exciting\" filmmakers in New York.\nIn 1964 Warhol produced and directed \"Batman Dracula\" without the permission of DC Comics. It was screened only at his art exhibits. A fan of the \"Batman\" series, Warhol's movie was an \"homage\" and is considered the first appearance of a blatantly campy Batman. The film was until recently thought to have been lost, until scenes from the picture were shown at some length in the 2006 documentary \"Jack Smith and the Destruction of Atlantis\".\nWarhol's 1965 film \"Empire\" is an eight-hour view of the Empire State Building, and shortly after he released \"Vinyl\" (1965), an adaptation of Anthony Burgess' popular dystopian novel \"A Clockwork Orange\". His other films show improvised conversations between Factory regulars such as Taylor Mead, Brigid Berlin, Edie Sedgwick, Ondine, Nico, and International Velvet.\nHis film \"Chelsea Girls\" (1966) was the first underground film of the 1960s to reach widespread popularity and capture the attention of notable film critics. The film was highly innovative in that it consisted of two 16 mm-films being projected simultaneously, with two different stories being shown in tandem. From the projection booth, the sound would be raised for one film to elucidate that \"story\" while it was lowered for the other. The multiplication of images evoked Warhol's seminal silkscreen works of the early 1960s.\nThe controversial film \"Blue Movie\" (1969)\u2014in which Warhol superstars Viva and Louis Waldon make love in bed\u2014was Warhol's last film as director. It is a seminal film in the Golden Age of Porn, and at the time it was controversial for its frank approach to a sexual encounter. \"Blue Movie\" was publicly screened in New York City in 2005, for the first time in more than 30 years.\nWhile Warhol recovered from a near-fatal shooting in 1968, his assistant director, Paul Morrissey, took over most of the filmmaking chores for the Factory collective. Morrissey steered the Warhol-branded cinema towards more mainstream, narrative-based, B-movie exploitation fare with \"Flesh\" (1968), \"Trash\" (1970) and \"Heat\" (1972). All of these films, including \"Andy Warhol's Dracula\" (1973) and \"Andy Warhol's Frankenstein\" (1974) starred Joe Dallesandro and are now considered cult classics. The last Warhol-produced film, \"Bad,\" starred Carroll Baker and was made without either Morrissey or Dallesandro. It was directed by Warhol's boyfriend Jed Johnson, who had assisted Morrissey on several films.\nMost of the films directed by Warhol were pulled out of circulation by Warhol and the people around him who ran his business. With assistance from Warhol in 1984, the Whitney Museum and the Museum of Modern Art began to restore his films, which are occasionally shown at museums and film festivals. In 2022, the Andy Warhol Museum announced the launch of The Warhol TV, a streaming platform that allows users to watch free museum content and to rent a selection of Warhol's films from its collection.\nTheater and television.\nWarhol's play \"Andy Warhol's Pork\", premiered at New York's La MaMa Theater in May 1971 and ran for two weeks. It was brought to the Roundhouse in London for a longer run in August 1971. \"Pork\" was based on tape-recorded conversations between Brigid Berlin and Warhol. Berlin would play Warhol tapes she had made of phone conversations between herself and her mother, socialite Honey Berlin. In 1974, Warhol designed the sets for the musical \"Man on the Moon\".\nIn 1968, Warhol produced a TV commercial for Schrafft's Restaurants in New York City, for an ice cream dessert appropriately titled the \"Underground Sundae\". Warhol dreamed of a television special about a favorite subject of his\u00a0\u2013 Nothing\u00a0\u2013 that he would call \"Nothing Special\". Later in his career he created three television shows: \"Fashion\" (1979\u201380), \"Andy Warhol's TV\" (1980\u20131983), and the MTV series \"Andy Warhol's Fifteen Minutes\" (1985\u201387).\nMusic and cover art.\nIn 1963, Warhol founded The Druds, a short-lived avant-garde noise music band that featured prominent members of the New York proto-conceptual art and minimal art community.\nIn 1965, Warhol adopted the band the Velvet Underground, making them a crucial element of the \"Exploding Plastic Inevitable\" multimedia performance art show. His involvement with the musicians of The Velvet Underground was driven by an expressed desire to become a music producer. Warhol and Paul Morrissey acted as the band's manager, introducing them to Nico, who would perform with the band at Warhol's request. While managing the Velvet Underground, Warhol would have them dressed in all black to perform in front of movies that he was also presenting.\nIn 1966, he \"produced\" their first album \"The Velvet Underground &amp; Nico\", as well as providing its album art. His actual participation in the album's production amounted to simply paying for the studio time.\nAfter the band's first album, Warhol and band leader Lou Reed started to disagree more about the direction the band should take, and Warhol was fired in 1967. In 1989, Reed and John Cale reunited for the first time since 1972 to write, perform, record and release the concept album \"Songs for Drella\", as a tribute to Warhol. In October 2019, an audio tape of publicly unknown music by Reed, based on Warhol's 1975 book, \"The Philosophy of Andy Warhol: From A to B and Back Again\", was reported to have been discovered in an archive at the Andy Warhol Museum in Pittsburgh.\nWarhol designed many album covers for various artists beginning during his days as an illustrator in the 1950s. The album covers he designed include for \"I'm Still Swinging\" (1955) by The Joe Newman Octet, \"Blue Lights, Vols. 1 &amp; 2\" (1958) by Kenny Burrell, \"This Is John Wallowitch!!!\" (1964) by John Wallowitch, \"Sticky Fingers\" (1971) and \"Love You Live\" (1977) by The Rolling Stones, \"The Academy in Peril\" (1972) by John Cale, \"Silk Electric\" (1982) by Diana Ross, and \"Aretha\" (1986) by Aretha Franklin.\nIn 1984, Warhol co-directed the music video \"Hello Again\" by the Cars, and he appeared in the video as a bartender. In 1986, Warhol co-directed the music video \"Misfit\" by Curiosity Killed the Cat and he made a cameo in video.\nBooks and magazines.\nBeginning in the 1950s, Warhol produced several unbound portfolios of his work. In 1957, his bound book \"25 Cats Name Sam and One Blue Pussy\" was printed by Seymour Berlin. Berlin also printed some of Warhol's other self-published books, \"including Gold Book (1957) and Wild Raspberries (1959)\". Warhol's book \"A La Recherche du Shoe Perdu\" marked his \"transition from commercial to gallery artist\". (The title is a play on words by Warhol on the title of French author Marcel Proust's \"\u00c0 la recherche du temps perdu\".) In an effort to generate work, the majority of these books were printed to be given out to people to draw attention to his illustrations.\nAfter gaining fame, Warhol \"wrote\" several books that were commercially published:\nWarhol created covers for a number of magazines, including \"Time\" and \"Vogue\". In 1969, his launched \"Interview\" magazine, which was a film critic spread before it became a pop culture magazine in the 1972.\nPhotography and audio.\nWarhol used Polaroid photos as the basis for his silkscreen paintings. These pictures were mostly taken with The Big Shot camera. During the portrait session, Warhol typically shot dozens of photographs of his subject, then selected the best one that would underlie the painting. This photographic approach to painting and his snapshot method of taking pictures has had a great effect on artistic photography. Warhol was also an avid photographer and also used the Polaroid SX-70 as a portable camera. He took an enormous number of photographs of Factory visitors, friends, and celebrities; many of these have been acquired by Stanford University.\nAt one point Warhol carried a portable recorder along with his camera with him wherever he went, taping everything everybody said and did. He referred to this device as his \"wife\". Some of these tapes were the basis for his literary work. Another audio-work of Warhol's was his \"Invisible Sculpture\", a presentation in which burglar alarms would go off when entering the room.\nFashion.\nWarhol is quoted for having said, \"I'd rather buy a dress and put it up on the wall, than put a painting, wouldn't you?\" Warhol has been described as a modern dandy, whose authority \"rested more on presence than on words\". His work in fashion includes department store window displays, illustrations for \"Vogue\" and \"Harper's Bazaar\", and a career as a model.\nIn 1965, Warhol designed furs for Coopchik-Forrest. In 1966, paper dresses had gained such popularity that Brooklyn's Abraham &amp; Straus department store invited Warhol to demonstrate decorating plain white Mars Manufacturing paper dresses, which came with brushes and watercolor sets for personal customization. During the event, he silkscreened \"FRAGILE\" onto Nico's dress as she wore it, signing it \"Dal\u00ed\" humorously, and adorned another dress with large screen-printed bananas. Both pieces were eventually donated to the Brooklyn Museum.\nWarhol formed friendships with prominent figures in the fashion industry, including former \"Vogue\" editor-in-chief Diana Vreeland, fashion designers Karl Lagerfeld, Yves Saint Laurent, Halston, Diane von Furstenberg, and Calvin Klein. In 1972, Warhol collaborated with Halston for the Coty Awards.\nIn 1997, the Whitney Museum in New York mounted the exhibition \"The Warhol Look: Glamour, Style, Fashion\", organized by the Andy Warhol Museum.\nPublic persona.\nEarly in his career, Warhol often gave reporters conflicting accounts of his background, habits, and working methods, treating the press as a study in how information spread. As he told \"People Weekly\" in 1976, \"I used to like to give different information to different magazines because it was like putting a tracer on where people get their information.\" By planting small inconsistencies, he watched how stories circulated and evolved, turning interviews into part of his ongoing play with persona, authorship, and media behavior.\nWarhol also enjoyed having others speak for him. In public, he increasingly relied on an impersonal style of communication, mirroring his impulse to distance himself from the creation of his own artwork. He often hid behind a dazed expression and flat remarks\u2014\"gee,\" \"uh,\" \"really\"\u2014and seemed to relish performing as a kind of \"monosyllabic oddity\" or \"Keatonesque idiot savant\" to the media. He suggested that all one needs to know about his work is \"already there on the surface.\" His boyfriend Jed Johnson said, \"He felt an artist should keep neutral expression on his face when he showed his work to other people, that to betray pleasure or displeasure was, again 'corny.' I'd watch him at many museum and gallery openings of his shows, and he followed that policy consistently.\"\nPersonal life.\nSexuality.\nWarhol lived as a gay man before the gay liberation movement, but he often veiled his personal life in the press. In the 1950s, Warhol submitted homoerotic drawings of male nudes to a fine art gallery, but they were rejected for being too openly gay. In his book \"Popism\", the artist recalls a conversation with the filmmaker Emile de Antonio about the difficulty he had being accepted socially by the then-more-famous (but closeted) gay artists Jasper Johns and Robert Rauschenberg. De Antonio explained that Warhol was \"too swish and that upsets them. \u2026 major painters try to look straight; you play up the swish\u2014it's like an armor with you.\" In response, Warhol said: \"I'd always had a lot of fun with that\u2014just watching the expressions on people's faces. You'd have to have seen the way all the Abstract Expressionist painters carried themselves and the kinds of images they cultivated, to understand how shocked people were to see a painter coming on swish. I certainly wasn't a butch kind of guy by nature, but I must admit, I went out of my way to play up the other extreme.\"\nThe impact of Warhol's homosexuality on his work and connection with the art industry has been extensively studied. Throughout his career, Warhol produced erotic photography and drawings of male nudes. Many of his most famous works\u2014portraits of Liza Minnelli, Judy Garland, and Elizabeth Taylor and films such as \"Blow Job\" (1964), \"My Hustler\" (1965), and \"Lonesome Cowboys\" (1968)\u2014draw from gay underground culture or openly explore the complexity of sexuality and desire. Many of his films premiered in gay porn theaters in the 1960s.\nIn 1980, Warhol proclaimed that he was still a virgin. Former \"Interview\" editor Bob Colacello felt it was probably true and that what little sex he had was probably \"a mixture of voyeurism and masturbation\u2014to use [Warhol's] word \"abstract.\"\" However, this assertion is contradicted by Warhol's hospital treatment in 1960 for condylomata, a sexually transmitted disease. Furthermore, some of his friends claimed to have witnessed Warhol having sex and heard him boasting about his sexual relations. Production designer Charles Lisanby, whom Warhol had unrequited romantic feelings for, said Warhol told him sex was \"messy and distasteful.\" \"He told me he'd had sex a few times, he had tried it and didn't really like it,\" said Lisanby.\nDue to Warhol's own admission that he was asexual, it was assumed that all his relationships were platonic. Warhol superstar Jay Johnson, whose twin brother was Warhol's longtime partner, stated, \"He enjoyed the idea that he was considered a voyeur and that he was considered asexual. That was his mystique.\" According to photographer Billy Name, who was briefly Warhol's lover, \"Andy's idea of sex was to have it once or twice and get it over with\u2014with Andy it wasn't about love, it was about companionship.\" He also said that Warhol's \"personality was so vulnerable that it became a defense to put up the blank front.\" Warhol referred to photographer Edward Wallowitch as his \"first boyfriend.\" He had intimate relationships with artist John Giorno, art historian Robert Pincus-Witten, and aspiring filmmaker . His most enduring romantic relationship was with Jed Johnson, who nursed him back to health after he was shot. Johnson collaborated with him on films and went on to achieve fame as an interior designer. They \"functioned as husband and husband, sharing a bed and a domestic life\" for 12 years. Warhol's close friend Stuart Pivar said he \"had no sex life after Jed.\" His later companions include Paramount Pictures executive Jon Gould and Factory assistant Sam Bolton.\nReligion.\nWarhol was a practicing Ruthenian Catholic. He regularly volunteered at homeless shelters in New York City, particularly during the busier times of the year, and described himself as a religious person. In 1966, his mother Julia Warhola told \"Esquire\" magazine that he was a \"good religious boy\" and he attended one o'clock Mass at St. Paul's every Sunday. The priest at Warhol's church, Saint Vincent Ferrer, said that the artist went there almost daily, and although he was not observed taking Communion or going to Confession, he sat or knelt in the pews at the back. The priest thought he was afraid of being recognized; Warhol said he was self-conscious about being seen in a Latin Catholic church crossing himself \"in the Orthodox way\" (right to left instead of the reverse). In 1980, Warhol met Pope John Paul II in St. Peter's Square.\nMany of Warhol's later works depicted religious subjects, including two series, \"Details of Renaissance Paintings\" (1984) and \"The Last Supper\" (1986). Warhol made almost 100 variations on the theme of the Last Supper, which the Guggenheim felt \"indicates an almost obsessive investment in the subject matter\". In addition, a body of religious-themed works was found posthumously in his estate.\nWarhol's art is noticeably influenced by the Eastern Christian tradition which was so evident in his places of worship. Warhol's brother has described the artist as \"really religious, but he didn't want people to know about that because [it was] private\". Despite the private nature of his faith, in Warhol's eulogy John Richardson depicted it as devout: \"To my certain knowledge, he was responsible for at least one conversion. He took considerable pride in financing his nephew's studies for priesthood\".\nFrom November 2021 to June 2022, the Brooklyn Museum displayed the \"Andy Warhol: Revelation\" exhibition. The exhibition delved at the artist's enduring connection to his faith, which was often reflected in his artwork.\nCollections.\nWarhol was an avid collector and a \"pack rat\" who'd save everything. As he was relocating his Manhattan studio in 1974, Warhol began assembling Time Capsules, a modular sculpture consisting of 610 containers, each holding an average of 800 items. The majority of the containers are standard cardboard boxes, with a large trunk and forty filing cabinet drawers. This also includes the Time Capsules that Warhol created at home, which hold a plethora of personal memorabilia like letters, telephone messages, photographs, and his mother's possessions. The Time Capsules were later transferred to the Andy Warhol Museum.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\n He shopped for two or three hours a day for as many years as I can remember. He started buying American Indian artifacts first \u2026 He bought Americana then, too, because he loved everything he saw at Serendipity. \u2026 the Tiffany lamps, the carousel horses, the Punches and old trade signs that helped propel him toward Pop insights. After that he bought primitive portraits and country painted furniture, then high-style painted furniture. Then on to Federal furniture in 1974 after he bought a Georgian-style townhouse.\n\u2014Jed Johnson (1988)\nHis collection of American items, \"Andy Warhol's Folk and Funk\", were exhibited at the Museum of American Folk Art in 1977, but few people knew the true extent of his collections until after his death. \"Andy had the peasant's wisdom that if people (either the very rich or the very poor) knew that you had anything good, they'd probably try to take it away from you. So he hid what he had. It was inconspicuous consumption,\" said Warhol's partner Jed Johnson. Warhol would wear a diamond necklace under a black turtleneck, conceal his jewelry in Famous Amos cookie tins atop the canopy of his bed, and keep wads of money in his mattress. Although Warhol did not drive, he owned a Mercedes and later a Rolls-Royce Silver Shadow. When he purchased the Rolls-Royce, Johnson was under strict orders to say he traded it for art.\nJohnson organized his collections, and when Warhol realized he needed more room, Johnson found a townhouse on East 66th Street in 1974. Johnson decorated the four-story townhouse, creating several ornate neoclassical period rooms. While residing with Johnson, Warhol kept his promise to keep his shopping bags in the closets and top-floor storage rooms. However, once Johnson moved out in December 1980, the townhouse was overrun by Warhol's acquisitions. Warhol occupied a second-floor bedroom and basement kitchen when he died in February 1987; all other rooms, with the exception of the quarters for his Filipino maids, sisters Nena and Aurora Bugarin, were used for storage.\nDuring the last few years of his life, Warhol was accompanied by chemist and art collector Stuart Pivar on daily shopping excursions. Pivar said they wanted \"to see if we could come across a couple a masterpieces or some amusing junk.\" According to Pivar, Warhol envisioned \"Warhol Hall\" on Madison Avenue, a massive gift shop with a museum where he would display a collection of sculptures he was assembling. Pivar regarded Warhol as the quintessential connoisseur who navigated society through flea markets, antique stores, and Christie's and Sotheby's salerooms. Fred Hughes, Warhol's business manager and estate executor, also affirmed Warhol's idea for \"Warhol Hall,\" adding that they had been thinking of setting up a flea market booth.\nWarhol's enormous collection was auctioned at Sotheby's in 1988. Dealers and collectors were drawn to the 3,436 lots that were sold, totaling almost 10,000 items. A total of $25.3\u00a0million was accumulated during the 10-day sale. His collections included American shop signs, Coca-Cola memorabilia, antique furniture, carousel horses, Navajo blanket rugs, 175 cookie jars, 313 watches, and 332 pieces of Fiesta Ware.\nWarhol enjoyed purchasing artwork and he had a collection of 19th century sculptures by Antoine-Louis Barye, Antonio Canova, Jean-Baptiste Carpeaux, and Jean-L\u00e9on G\u00e9r\u00f4me. Among the paintings in his collection were George Bellows' \"Miss Bentham\" (1906), Man Ray's \"Peinture Feminin\" (1954), Roy Lichtenstein's \"Laughing Cat\" (1961), \"Mirror\" (1971), and \"Sailboats\" (1974), Jasper Johns' \"Screen Piece\" (1967), and Jean-Michel Basquiat's \"All Beef\" (1983). He also had work by Marcel Duchamp, Joseph Whiting Stock, Cy Twombly. Johnson recalled that Warhol refused to hang his own art on the walls, saying it was \"too corny\" to display your own work.\nWarhol collected many books, with more than 1,200 titles in his collection. His collection, which reflects his eclectic taste and interests, included \"The Two Mrs. Grenvilles: A Novel\" by Dominick Dunne, \"Artists in Uniform\" by Max Eastman, \"D.V.\" by Diana Vreeland, \"Blood of a Poet\" by Jean Cocteau, \"Hidden Faces\" by Salvador Dal\u00ed, and \"The Dinah Shore Cookbook\".\nLegacy.\nIn 1991, the Warhol Family Museum of Modern Art was established in Medzilaborce, Slovakia by Warhol's family and the Slovak Ministry of Culture. In 1996, it was renamed the Andy Warhol Museum of Modern Art.\nIn 1992, Warhol's estate donated 15 acres of land on his former property Eothen to The Nature Conservancy. Now called The Andy Warhol Preserve, it is part of a 2,400-acre protected area in Montauk.\nIn 1994, the Andy Warhol Museum opened in Pittsburgh. It holds the largest collection of the artist's works in the world.\nIn 1998, Warhol's Upper East Side townhouse at 57 E 66th Street in Manhattan was designated a cultural landmark by the Historical Landmarks Preservation Center to commemorate the 70th anniversary of his birthday.\nIn 2002, the US Postal Service issued an 18-cent stamp commemorating Warhol. Designed by Richard Sheaff of Scottsdale, Arizona, the stamp was unveiled at a ceremony at The Andy Warhol Museum and features Warhol's painting \"Self-Portrait, 1964\".\nIn 2005, the Seventh Street Bridge in Pittsburgh was renamed the Andy Warhol Bridge in his honor.\nA chrome statue of Andy Warhol and his Polaroid camera was displayed at Union Square in New York City from March to October 2011.\nThe International Astronomical Union named a crater on the planet Mercury after Warhol in 2012.\nIn 2013, to honor the 85th anniversary of Warhol's birthday, The Andy Warhol Museum and EarthCam launched a collaborative project titled \"Figment\", a live feed of Warhol's gravesite.\nIn 2024, Warhol was posthumously awarded the Order of the White Double Cross of the Second Class by the Slovak Republic's ambassador to the U.S. on the 37th anniversary of his death, at the behest of Slovakian President Zuzana \u010caputov\u00e1, \"for promoting the Slovak Republic's good name abroad.\"\nIn 2025, Warhol was selected as one of the first 10 inductees into the Pittsburgh Walk of Fame.\nThe Andy Warhol Foundation for the Visual Arts.\nWarhol's will dictated that his entire estate\u2014with the exception of a few modest legacies to family members\u2014would go to create a foundation dedicated to promoting the visual arts. Warhol had so many possessions that it took Sotheby's 10 days to auction his estate after his death; the auction grossed $25.3\u00a0million.\nIn 1987, in accordance with Warhol's will, the Andy Warhol Foundation for the Visual Arts was formed. The foundation serves as the estate of Andy Warhol, but also has a mission \"to foster innovative artistic expression and the creative process\" and is \"focused primarily on supporting work of a challenging and often experimental nature\".\nThe Artists Rights Society is the US copyright representative for the Andy Warhol Foundation for the Visual Arts for all Warhol works with the exception of Warhol film stills. The US copyright representative for Warhol film stills is the Warhol Museum in Pittsburgh. Additionally, the Andy Warhol Foundation for the Visual Arts has agreements in place for its image archive. All digital images of Warhol are exclusively managed by Corbis, while all transparency images of Warhol are managed by Art Resource.\nThe Andy Warhol Foundation released its \"20th Anniversary Annual Report\" as a three-volume set in 2007: Vol. I, 1987\u20132007; Vol. II, Grants &amp; Exhibitions; and Vol. III, Legacy Program.\nThe Foundation is in the process of compiling its catalogue raisonn\u00e9 of paintings and sculptures in volumes covering blocks of years of the artist's career. Volumes IV and V were released in 2019. The subsequent volumes are still in the process of being compiled.\nThe Foundation remains one of the largest grant-giving organizations for the visual arts in the US.\nMany of Warhol's works and possessions are on display at the Andy Warhol Museum in Pittsburgh. The foundation donated more than 3,000 works of art to the museum.\nIn pop culture.\nWarhol founded \"Interview\", a stage for celebrities he \"endorsed\" and a business staffed by his friends. One might even say that he produced people (as in the Warholian \"Superstar\" and the Warholian portrait). Warhol endorsed products, appeared in commercials, and made frequent celebrity guest appearances on television shows and films.\nFilms.\nWarhol appeared in the films \"Dynamite Chicken\" (1971), \"The Driver's Seat\" (1974), \"Cocaine Cowboys\" (1979) and \"Tootsie\" (1982).\nAfter his death, Warhol was portrayed by Crispin Glover in Oliver Stone's film \"The Doors\" (1991), by Jared Harris in Mary Harron's film \"I Shot Andy Warhol\" (1996), and by David Bowie in Julian Schnabel's film \"Basquiat\" (1996).\nWarhol appeared as a character in Michael Daugherty's opera \"Jackie O\" (1997). Actor Mark Bringleson makes a brief cameo as Warhol in \"\" (1997). Many films by avant-garde cineast Jonas Mekas have caught the moments of Warhol's life. Sean Gregory Sullivan depicted Warhol in the film \"54\" (1998). Guy Pearce portrayed Warhol in the film \"Factory Girl\" (2007) about Edie Sedgwick's life. Actor Greg Travis portrays Warhol in a brief scene from the film \"Watchmen\" (2009). \nIn the movie \"Highway to Hell\" a group of Andy Warhols are part of the \"Good Intentions Paving Company\" where good-intentioned souls are ground into pavement. In the film \"Men in Black 3\" (2012) Andy Warhol turns out to really be undercover MIB Agent W (played by Bill Hader). Warhol is throwing a party at The Factory in 1969, where he is encountered by MIB Agents K and J.Andy Warhol (portrayed by Tom Meeten) is one of main characters of the 2012 British television show \"Noel Fielding's Luxury Comedy\". The character is portrayed as having robot-like mannerisms. \nIn September 2016, it was announced that Jared Leto would portray the title character in \"Warhol\", an upcoming American biographical drama film produced by Michael De Luca and written by Terence Winter, based on the book \"Warhol: The Biography\" by Victor Bockris.\nIn the 2017 film \"The Billionaire Boys Club\", Cary Elwes portrays Warhol in a film based on the true story about Ron Levin, a friend of Warhol's who was murdered in 1986. Comedian Conan O'Brien portrayed Warhol in the film \"\" (2022).\nTelevision.\nIn 1965, Warhol and his muse Edie Sedgwick appeared on \"The Merv Griffin Show\". Warhol doesn't say much save for bashful gestures and whispering \"yes\" or \"no,\" while Sedgwick mediates a conversation on how Pop Art is art without any sense of emotion.\nIn 1969, Warhol was commissioned by Braniff International to appear in two television commercials to promote the luxury airline's \"When You Got It \u2013 Flaunt It\" campaign. The campaign was created by the advertising agency Lois Holland Calloway, which was led by George Lois, creator of a famed series of \"Esquire\" covers. The first commercial series involved the unlikely paring of Warhol and heavyweight boxing champion Sonny Liston who shared the fact that they both flew Braniff Airways. The odd commercial worked and Warhol was featured in another commercial entering a Braniff jet and being greeted by a Braniff hostess, while espousing their like for flying Braniff. The rights to Warhol's films for Braniff and his signed contracts are owned by a private trust and are administered by Braniff Airways Foundation in Dallas, Texas.\nWarhol appeared on the BBC series Arena in a scene with writers William S. Burroughs and Victor Bockris in an episode that aired in January 1981. Warhol filmed a segment for the sketch comedy television show \"Saturday Night Live\", which aired in October 1981. In a 1981 Sony Beta Tapes advertisement, Warhol featured beside a Marilyn image to showcase the tapes' capacity to record \"brilliant color and delicate shading.\" In 1983, he appeared in a commercial for TDK Videotape.\nIn 1985, Warhol appeared in a Diet Coke commercial. He also had a guest appearance on the 200th episode of the television series \"The Love Boat\" wherein a Midwestern wife (Marion Ross) fears Andy Warhol will reveal to her husband (Tom Bosley) her secret past as a Warhol superstar named Marina del Rey.\nIn 1986, Warhol appeared in an ad for the Drexel Burnham Lambert investment group.\nWarhol appeared as a recurring character in TV series \"Vinyl\", played by John Cameron Mitchell. In 2017, Warhol was portrayed by Evan Peters in the \"\" episode \".\"\nMusic.\nWarhol strongly influenced the new wave/punk rock band Devo, as well as David Bowie. Bowie recorded a song called \"Andy Warhol\" for his 1971 album \"Hunky Dory\". Lou Reed wrote the song \"Andy's Chest\" in response to the attempted assassination of Warhol. The song was originally recorded by the Velvet Underground in 1969, but it wasn't released until a version appeared on Reed's solo album \"Transformer\" in 1972. The band Triumph also wrote a song about Andy Warhol, \"Stranger In A Strange Land\" off their 1984 album \"Thunder Seven\".\nBooks.\nMany books have been written about Warhol. Among the most notable books related to Warhol is the authorized biography \"Warhol\" (1989) by his friend, art critic David Bourdon. Writer Victor Bockris released \"\" (1989). The memoir \"Holy Terror: Andy Warhol Close Up\" (1990) was written by Bob Colacello, the former executive editor of Warhol's \"Interview\" magazine. Culture critic and poet Wayne Koestenbaum published the biography \"Andy Warhol\" (2001). Art critic Blake Gopnik, wrote the comprehensive biography \"Warhol\" (2020).\nComic books.\nWarhol is featured as a character in the \"Miracleman\" series of comics. Nick Bertozzi's book \"Becoming Andy Warhol\", which was illustrated by Pierce Hargan, was released by Abrams ComicArts in 2016. In 2018, SelfMadeHero published the graphic novel \"Andy: The Life and Times of Andy Warhol\" by Dutch illustrator Typex.\nVideo games.\nWarhol makes an appearance in the 2003 video game \"\" as the photographer in Studio Town. Warhol (played by Jeff Grace) makes a cameo appearance in the 2022 video game \"Immortality\".\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "868", "revid": "39637521", "url": "https://en.wikipedia.org/wiki?curid=868", "title": "Alp Arslan", "text": "Sultan of the Seljuk Empire from 1063 to 1072\nAlp Arslan (Persian: \u0622\u0644\u067e \u0627\u0631\u0633\u0644\u0627\u0646; full name: Muhammad Alp Arslan bin Dawud Chaghri), was the second sultan of the Seljuk Empire and great-grandson of Seljuk, the eponymous founder of the dynasty and the empire. He reigned from 1063 until his assassination in 1072.\nAlp Arsan greatly expanded Seljuk territories and consolidated his power, defeating rivals to the south, east, and northwest. His victory over the Byzantines at the Battle of Manzikert in 1071 ushered in the Turkoman settlement of Anatolia. For his military achievements, he earned the name \"Alp Arslan\", which means \"Heroic Lion\" in Turkish.\nEarly life.\nHistorical sources differ regarding Alp Arslan's birth date. Some 12th- and 13th-century sources give 1032/1033 as his birth year, while later sources give 1030. According to \u0130brahim Kafeso\u011flu, the most likely date is 20 January 1029 (1 Muharram 420 AH), recorded by the medieval historian Ibn al-Athir. \nAlp Arslan was the son of Chaghri Beg and nephew of Tughril, the founding sultans of the Seljuk Empire. His grandfather was Mikail, who in turn was the son of the warlord Seljuk. He was the father of numerous children, including Malik-Shah I and Tutush I. It is unclear who the mother or mothers of his children were. He was known to have been married at least twice. His wives included the widow of his uncle Tughril, a Kara-Khanid princess known as Aka or Seferiye Khatun, and the daughter or niece of Bagrat IV of Georgia (who would later marry his vizier, Nizam al-Mulk). One of Seljuk's other sons was the Turkic chieftain Arslan Isra'il, whose son, Kutalmish, contested his nephew's succession to the sultanate. Alp Arslan's younger brothers Suleiman ibn Chaghri and Qavurt were his rivals. Kilij Arslan, the son and successor of Suleiman ibn Kutalmish (Kutalmish's son, who would later become Sultan of R\u00fbm), was a major opponent of the Franks during the First Crusade and the Crusade of 1101.\nCampaigns and battles.\nAlp Arslan accompanied his uncle Tughril on campaigns in the south against the Fatimids, while his father Chaghri remained in Khorasan. Upon Alp Arslan's return to Khorasan, he began his work in administration at his father's suggestion. While there, his father introduced him to Nizam al-Mulk, one of the most eminent statesmen in early Muslim history and Alp Arslan's future vizier.\nDefense of Tokharistan (1043\u201344).\nTaking advantage of the illness of the governor of Khorasan Chaghri, the Ghaznavid Sultan Mawdud attacked the Tokharistan region held by the Seljuks with the Ghaznavid army. Alp Arslan, who was in the city of Balkh at the time, defeated the Ghaznavids. A subsequent Ghaznavid attack was also repelled. The defeated Ghaznavids retreated, abandoning the places they had captured. Later, the Seljuk army, which launched an attack under the command of Alp Arslan and Chaghri Beg, captured the cities of Termez, Kubadhiyan, Vakhsh, Kunduz (Valvalic), held by the Ghaznavids, and other Tokharistan lands held by the Ghaznavids.\nCampaign of Kara-Khanids.\nA few years after Mawdud of Ghazni suffered a major defeat against the Seljuks in Tokharistan, he called on the Kara-Khanids and the Buyids to form an alliance against the Seljuks. The Kara-Khanids and the Buyids accepted Mawdud's proposition. Later, the members of this alliance took action to unite their armies. Mawdud also set out with his army to meet the Buyid and Kara-Khanid armies. However, Mawdud fell ill on the way to the meeting place, and the Ghaznavid army was forced to turn back. The Buyids army also set out from Isfahan to the meeting place, but when they passed Tabas and entered the desert, an epidemic broke out in the Buyids army. In this epidemic, the commander of the Buyids army fell ill, and the army suffered great losses. Thereupon, the Buyids turned back. \nThe Kara-Khanid ruler Arslan Khan was unaware of these events. Arslan Khan attacked Termez and plundered the city. Later, Arslan Khan took action to capture Balkh. In the face of these events, Alp Arslan went on an expedition against the Kara-Khanids. Arslan Khan was defeated in the war that broke out between the two sides. The defeated Arslan Khan was forced to retreat, and went to the banks of the Amu Darya River. He then decided to make a peace offer to the Seljuks. When Chaghri Beg heard about this peace offer, he met with the Kara-Khanid ruler Arslan Khan with his soldiers. As a result of this meeting, peace was made between the Seljuk Empire and the Kara-Khanid Khanate.\nRaid of Fasa.\nWhile Tughril I was busy with the Siege of Isfahan (1050\u201351), Alp Arslan attacked and captured the city of Fasa, belonging to the Buyids, with his army, without the knowledge of his uncle Tughril. He then returned to Khorasan to avoid falling under the command of Tughril.\nDefense of Khorasan (1056).\nTaking advantage of the internal turmoil in the Ghaznavid Empire, the Seljuks organized an expedition to Ghazna. The army, under the command of Chaghri, advanced as far as Bust. The Ghaznavids, who solved the problems, enthroned Farrukh-Zad. Farrukh-Zad sent his commander, named Hirhiz, against Chaghri. Hirhiz defeated Chaghri and attacked Khorasan, defeating and capturing Gul-Sarygh and other Seljuk commanders. Thereupon, Alp Arslan received permission from his father to organize an attack to the Ghaznavids, and they were defeated under the command of Hirhiz.\nCapture of Chaghaniyan (1059).\nIn 1059, Alp Arslan launched a campaign against the Kara-Khanids. During this campaign, Alp Arslan captured Chaghaniyan, which belonged to the Kara-Khanids. Following Alp Arslan's capture of Chaghaniyan, the Kara-Khanid ruler Ibrahim ibn Nasr complained against Alp Arslan to the Abbasid caliph, but to no avail. The caliph did nothing but give robes and titles to Ibrahim bin Nasr.\nBattle of Rey (1059).\nAs a result of the rebellion of Ibrahim Yinal, the Seljuk Sultan Tughril I, who was in a difficult situation, asked for help from his brother Chaghri. Chaghri responded to this request for help by sending an army under the command of his sons Alp Arslan, Qavurt, and Yakuti. The army under the command of Ibrahim Yinal and his nephews Mehmed and Ahmed, and the army under the command of Alp Arslan, Qavurt, and Yakuti encountered each other near Rey. Ibrahim Yinal and his nephews, who lost the battle, were taken prisoner.\nCampaign of Khuttal (1063).\nUpon receiving news of the rebellion of the Khuttal Emir, Alp Arslan set out on an expedition against Khuttal. The Seljuk army, under the command of Alp Arslan, laid siege to the Hulbuk Castle, the center of Khuttal. The Hulbuk Castle was built on a mountain and the castle was fortified, which caused the first attacks to be ineffective. Later, as a result of an attack in which Alp Arslan also participated, the Khuttal Emir was killed. Later, the Hulbuk Castle was captured by the Seljuks. Alp Arslan appointed one of his own men as emir to Khuttal.\nBattle of Herat (1063).\nAfter the death of Tughril, Musa Yabghu captured Herat, which was under the rule of Alp Arslan, and rebellion. In the meantime, Alp Arslan, who was dealing with the rebellion of the Khatlon emir, suppressed this rebellion and defeated the Khatlon emir, and then went on an expedition against Musa Yabghu. In the battle between the two armies near Herat, Musa Yabghu was defeated. Alp Arslan regained control of Herat and spared the life of Musa Yabghu, who was taken prisoner.\nCampaign of Chaghaniyan.\nAfter Alp Arslan suppressed Musa Yabghu's rebellion, he marched against Emir Musa, who rebelled in Chaghaniyan. Emir Musa was defeated and captured in the battle near Chaghaniyan. Later, the Seljuk army captured Chaghaniyan Castle. After suppressing this rebellion, Alp Arslan advanced towards Ray with his army.\nBattle of Damghan and Alp Arslan's accession to the throne.\nAfter the death of his father, Alp Arslan succeeded him as governor of Khorasan in 1059. His uncle Tughril died in 1063 and designated his successor as Suleiman, Alp Arslan's infant brother. Alp Arslan and his uncle Kutalmish both contested this succession, which was resolved at the battle of Damghan in 1063. Alp Arslan defeated Kutalmish for the throne and succeeded on 27 April 1064 as sultan of the Seljuk Empire, thus becoming the sole monarch of Seljuk Empire from the river Oxus to the river Tigris.\nCampaign of Northwest (1064).\nIn 1064, he led a campaign in northwestern Along with Nizam al-Mulk and Malik-Shah I, he then marched into Armenia and Georgia, which he conquered in 1064. Alp Arslan and Malik-Shah I captured the regions between Tbilisi and the \u00c7oruh river, many cities and castles, especially Akhalkalaki, Alaverdi, Byurakan (Anberd), Surmari, Hagios Georgios Castle, and Meryemni\u015fin. Alp Arslan went on an expedition to Anatolia and Subizshahr, Akkent, A\u011fcakale, and surrounding Anatolian castles were captured. Ani, the most fortified castle of the Byzantine Empire, was besieged. The city of Ani was defended by two Byzantine generals, Bagrat and Gregor. After a siege of 25 days, the Seljuks captured Ani, the capital city of Armenia.\nAfter the Seljuks captured Ani, Kars surrendered to the Seljuks and was thus taken without a fight. An account of the sack and massacres in Ani is given by the historian Sibt ibn al-Jawzi, who quotes an eyewitness saying:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The army entered the city, massacred its inhabitants, pillaged and burned it, leaving it in ruins and taking prisoner all those who remained alive... The dead bodies were so many that they blocked the streets; one could not go anywhere without stepping over them. And the number of prisoners was not less than 50,000 souls. I was determined to enter the city and see the destruction with my own eyes. I tried to find a street in which I would not have to walk over the corpses, but that was impossible.\nCampaign of Fars.\nDuring Sultan Alp Arslan's Campaign of Northwest, following an argument between Fazluye, the governor of Shiraz, and Alp Arslan's brother Qavurt, the governor of Kerman, Sultan Alp Arslan launched an expedition against Qavurt. When Alp Arslan's army attacked, Qavurt's soldiers pleaded for mercy and were taken captive. Qavurt fled. Alp Arslan appointed Fazluye as governor of Fars and went to Isfahan.\nCampaign of Ustyurt and Mangyshlak (1065).\nIn 1065, Alp Arslan went on an expedition to the Ustyurt and Mangyshlak regions with a Seljuk army of approximately 30,000 men. He defeated the Turkmen, Kipchak, and Jazeks forces. Then he defeated the 30,000 men Kipchak army under the command of Kafshud. Alp Arslan later visited the grave of his grandfather Seljuk in Jand and attributed it to the lands ruled by his son Malik-Shah I. As a result of this expedition of Alp Arslan, the lands from the Caspian Sea to Tashkent came under the rule of the Seljuk Empire.\nCampaign of Kerman (1067).\nAlp Arslan went on an expedition against Qavurt, who rebelled in 1067. Qavurt again asked for forgiveness after the army he sent was defeated by Alp Arslan's vanguard. Alp Arslan forgave him and left him as the prince of Kerman.\nCampaign of Georgia (1068).\nBagrat IV agreed to pay jizya to the Seljuks in 1064, but the Georgians broke the agreement in 1065. Alp Arslan invaded Georgia again in 1068. He captured Tbilisi, Kartli, Shirak, Vanand, Gugark, Arran, Ganja, and Kars after a short battle and obtained the submission of Bagrat IV. However, the Georgians were liberated from Seljuk rule around 1073\u20131074 after Alp Arslan died. As a result of the campaigns carried out during the reign of Malik-Shah I, Georgia became a part of the Seljuk Empire again.\nRaid on Caesarea.\nIn consolidating his empire and subduing contending factions, Alp Arslan was ably assisted by Nizam al-Mulk, and the two are credited with helping to stabilize the empire after the death of Tughril. With peace and security established in his dominions, Alp Arslan convoked an assembly of the states, and in 1066, he declared his son Malik Shah I his heir and successor. With the hope of capturing Caesarea Mazaca, the capital of Cappadocia, he placed himself at the head of the Turkoman cavalry, crossed the Euphrates, and entered and invaded the city.\nThe Raid on Caesarea occurred in 1067, when the Seljuk Turks, under Alp Arslan and Afshin Bey, attacked Caesarea. Caesarea was sacked and its Cathedral of St. Basil was desecrated. This provoked Emperor Romanos IV Diogenes' first campaign in 1068.\nCampaign of Northern Syria and Anatolia.\nIn 1070, the emirs of Mecca and Medina came under the rule of the Seljuk Empire. After Mecca and Medina came under Seljuk Empire rule, the Fatimid Vizier Nasr-Dawla asked for help from Alp Arslan against the Fatimids. Alp Arslan moved with his army upon the call for help and entered Anatolia via Azerbaijan. Alp Arslan first captured the castles of Manzikert and Erci\u015f. Later, he went down to the Silvan and Diyarbekir (Amid) regions and made the emirs there his vassals of Seljuk Empire, then he went to Edessa and besieged the city. When the siege was prolonged, he lifted the siege by receiving a tribute of 50,000 dinars. He advanced to Aleppo, which was in the hands of the Mirdasids, and captured the Byzantine castles on his way. When he arrived in Aleppo, he laid siege to the city due to the disobedience of Rashid al-Dawla Mahmud, the Mirdasid emir of Aleppo. Some time after the siege, Rashid al-Dawla Mahmud came to Alp Arslan, apologized, and became his vassal. Later, as Egypt was preparing to advance, the Byzantine envoy arrived and Alp Arslan turned his attention to Manzikert.\nBattle of Manzikert (1071).\nEn route to fight the Fatimids in Syria in 1068, Alp Arslan invaded the Byzantine Empire. The Emperor Romanos IV Diogenes, assuming command in person, met the invaders in Cilicia. In three arduous campaigns, the Turks were defeated in detail and driven across the Euphrates in 1070. The first two campaigns were conducted by the emperor himself, while the third was directed by Manuel Komnenos, the brother of future emperor Alexios I Komnenos. During this time, Alp Arslan gained the allegiance of Rashid al-Dawla Mahmud, the Mirdasid emir of Aleppo.\nIn 1071, Romanos took the field again and advanced east with his army, including a contingent of Cuman Turks as well as contingents of Franks and Normans, under Ursel de Baieul. Alp Arslan, who had moved his troops south to fight the Fatimids, quickly reversed to meet the Byzantines. When Alp Arslan arrived in Silvan and learned that Romanos Diogenes had captured Manzikert, he set out towards Ahlat. The two armies met at the Rahve Plain near Manzikert. Alp Arslan sent a final ambassador to the Romanos IV Diogenes, offering a peace deal. The Romanos IV Diogenes rejected the peace deal, whereupon Alp Arslan put his army in battle formation and placed some of his cavalry in ambush along the valley. Alp Arslan placed the 4,000-man force he would command in the center line. On the Byzantine side, Emperor Romanos Diogenes also put his army in battle formation. Both armies made their final preparations on August 25. Before the battle on August 26, Alp Arslan gave the following speech to his army:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nOn August 26, the Battle of Manzikert began with a Seljuk attack. The central army, under the command of Alp Arslan, attacked the numerically superior Byzantine army and, after a while, retreated due to war tactics. The central army, led by the Byzantine emperor Romanus Diogenes, started to follow the Seljuk army, and when they reached the ambush point, the army under the command of Alp Arslan turned towards the Byzantine army and other Seljuk soldiers emerged from the hills where they were hiding and surrounded the Byzantine army. The Byzantine army, which fell into the ambush set by the Seljuks, was defeated and for the first time in history, a Byzantine emperor was taken prisoner by a Turkish and Muslim commander. The Byzantines were wholly routed.\nEmperor Romanos himself was captured in battle and presented to Alp Arslan. It is reported that upon seeing the Roman emperor, the sultan leaped from his throne, commanded Romanos to kiss the ground, and stepped on his neck. He repeatedly berated the emperor, including for spurning his emissaries and offers of peace. Romanos remained unrepentant, asserting that he had merely done what was \"possible for a man, and which kings are bound to do, and I have fallen short in nothing. But God has fulfilled his will. And now, do what you wish and abandon recriminations.\" \nPurportedly declaring Romanos \"too trivial... to kill\", Alp Arslan then led him about the camp to sell the prisoner to one of his men. The Seljuk soldiers initially refused to spend any money on buying the emperor, until one man traded a dog for him. Next, wishing to test Romanos, Alp Arslan asked Romanos what he would do if their situation were reversed and Alp Arslan was imprisoned by the Byzantines. Romanos bluntly answered \"The worst!\" His honesty impressed Alp Arslan, who then decided to spare Romanos's life and instead ransom him back to his homeland. After agreeing on a ransom, Alp Arslan sent Romanos to Constantinople with a Turkish escort, carrying a banner above the disgraced emperor that read: \"There is no god but Allah and Muhammad is his messenger\".\nThe reason Alp Arslan spared Romanos was likely to avoid a two-front war. The Fatimids were launching devastating raids on the Seljuk domains during this period, and Alp Arslan may have worried that executing the Roman emperor might escalate his conflict with the Byzantines. Romanos himself had told the sultan that \"killing me will not be of any use to you\".\nAfter hearing of the death of Byzantine Emperor Romanos IV Diogenes, Sultan Alp Arslan pledged: \"The Byzantine nation has no God, so this day the oath of peace and friendship taken by both the Persians and Byzantines is nullified; henceforth I shall consume with the sword all those people who venerate the cross, and all the lands of the Christians shall be enslaved.\"\nAlp Arslan and his successor Malik Shah urged Turkish tribes to invade and settle Anatolia, where they would not only cease to be a problem for the Seljuk Sultanate, but also extend its territory further. Alp Arslan commanded the Turks as follows:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Henceforth all of you be like lion cubs and eagle young, racing through the countryside day and night, slaying the Christians and not sparing any mercy on the Roman nation.\nAlp Arslan's victories changed the balance in western Asia completely in favor of the Seljuq Turks and Sunni Muslims. While the Byzantine Empire was to continue for nearly four more centuries, the victory at Manzikert signalled the beginning of Turkic ascendancy in Anatolia. The victory at Manzikert became so popular among the Turks that later every noble family in Anatolia claimed to have had an ancestor who had fought on that day.\nCampaign of Turkestan (1072).\nAlp Arslan launched an expedition to Turkestan in 1072 with an army of 200,000. The reason for this expedition was that the Seljuk Dynasty's son-in-law, Shams al-Mulk, killed his wife, Alp Arslan's daughter (though some sources say she was his sister). Alp Arslan had ships built to cross the Amu Darya River with his army. Alp Arslan and his army crossed the Amu Darya River with the help of ships in 24 days. Later, Alp Arslan entered the Kara-Khanid lands with his army. Alp Arslan and his army came to the front of Barzem Castle without encountering any resistance or attacks and surrounded the castle. After a while, the castle, unable to withstand the siege, surrendered. The castle commander Yusuf al-Kharezmi came to Alp Arslan, stabbed him, and seriously wounded him. Alp Arslan held out for four days, but then died.\nState organization.\nAlp Arslan's strength lay in the military realm. Domestic affairs were handled by his able vizier, Nizam al-Mulk, the founder of the administrative organization that characterized and strengthened the sultanate during the reigns of Alp Arslan and his son, Malik Shah. Military \"iqtas\", governed by Seljuq princes, were established to provide support for the soldiery and to accommodate the nomadic Turks to the established Anatolian agricultural scene. This type of military fiefdom enabled the nomadic Turks to draw on the resources of the sedentary Persians, Turks, and other established cultures within the Seljuq realm, and allowed Alp Arslan to field a huge standing army without depending on tribute from conquest to pay his soldiers. He not only had enough food from his subjects to maintain his military, but the taxes collected from traders and merchants added to his coffers sufficiently to fund his continuous wars.\nSuleiman ibn Qutalmish was the son of the contender for Arslan's throne; he was appointed governor of the north-western provinces and assigned to complete the invasion of Anatolia. An explanation for this choice can only be conjectured from Ibn al-Athir's account of the battle between Alp Arslan and Kutalmish, in which he writes that Alp Arslan wept for the latter's death and greatly mourned the loss of his kinsman.\nPhysical appearance and personality.\nContemporary descriptions portray Alp Arslan as \"very awe-inspiring, dominating,\" a \"great-formed one, elegant of stature. He had long, thin whiskers, which he used to knot up when shooting arrows. And they say his arrow never went astray... From the top button of his hat to the end of his moustaches it was two yards\".\nMuslim sources show Alp Arslan as fanatically pious but just. Alp Arslan was so dedicated to the Hanafi school of Islamic jurisprudence that he always kept a \"qadi\" by his side, including in battles. Demonstrating his strong adherence to Sunni Islam, Alp Arslan's court was routinely filled with men of religion. His retinue included notable Hanafi imams such as Mushattab b. Muhammad al-Farghani and 'Abd al-Malik al-Bukhari al-Hanafi, the latter of whom served as his personal imam and accompanied him into battle. His vizier, Nizam al-Mulk, described the young sultan in his \"Book of Government\":&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;He was exceedingly imperious and awe-inspiring and, because he was so earnest and fanatical in his beliefs and disapproved of the Shafi\u2018i rite, I lived in constant fear of him.Some authors have doubted whether the Turks, who had adopted Islam recently, completely understood such religious distinctions. Alex Mallett writes, \"Whatever the case, the fact that almost all writers have good things to say about him suggests that he treated everyone more or less equally, in religious terms.\"\nDeath.\nAfter Manzikert, the dominion of Alp Arslan extended over much of western Asia. He soon prepared to march for the conquest of Turkestan, the original seat of his ancestors. With a powerful army, he advanced to the banks of the Oxus. Before he could pass the river safely, however, it was necessary to subdue certain fortresses, one of which was for several days vigorously defended by the rebel, Yusuf al-Kharezmi or Yusuf al-Harani. Perhaps over-eager to press on against his Qarakhanid enemy, Alp Arslan gained the governor's submission by promising the rebel 'perpetual ownership of his lands'. When he was produced a captive in the royal tent, the sultan, instead of praising his valor, severely reproached his obstinate folly: and the insolent replies of the rebel provoked a sentence, that he should be fastened to four stakes, and left to expire in that painful situation.\u00a0 At this command, the desperate Yusuf al-Kharezmi, drawing a dagger, rushed headlong towards the throne. The guards raised their battle-axes; their zeal was checked by Alp Arslan, the most skilful archer of the age. He drew his bow, but his foot slipped, the arrow glanced aside, and he received in his breast the dagger of Yusuf al-Kharezmi, who was instantly cut in pieces.\nThe wound was mortal, and the Turkish sultan bequeathed a dying admonition to the pride of kings.\u00a0\"In my youth,\" said Alp Arslan, \"I was advised by a sage to humble before God; to distrust my own strength; and never to despise the most contemptible foe.\u00a0I have neglected these lessons; and my neglect has been deservedly punished. Yesterday, as from an eminence I beheld the numbers, the discipline, and the spirit, of my armies, the earth seemed to tremble under my feet; and I said in my heart, Surely thou art the king of the world, the greatest and most invincible of warriors. These armies are no longer mine; and, in the confidence of my personal strength, I now fall by the hand of an assassin.\" Four days later, on 24 November 1072, Alp Arslan died and was buried at Merv, having designated his 18-year-old son Malik Shah as his successor.\nFamily.\nOne of his wives was Safariyya Khatun. She had a daughter, Sifri Khatun, who in 1071\u201372, married Abbasid Caliph Al-Muqtadi. Safariyya died in Isfahan in 1073\u201374. Another of his wives was Akka Khatun. She had been formerly the wife of Sultan Tughril. Alp Arslan married her after Tughril's death in 1063. Another of his wives was Shah Khatun. She was the daughter of Qadir Khan Yusuf, and had been formerly married to Ghaznavid Mas'ud I.\nAnother wife was Ummu Hifchaq, also known as Ummu Qipchaq. Another of his wives was the daughter of King of Tashir Kiurike I, who was married to the sister of the Georgian king Bagrat IV. Alp Arslan divorced her, and married her to Nizam al-Mulk. His sons were Malik-Shah I, Tutush I, Arslan Shah, Tekish, Toghan-Shah, Ayaz, and Buibars. One of his daughters married the son of Kurd Surkhab, son of Bard, in 1068.\nAnother daughter, Zulaikha Khatun, was married to Muslim ibn Quraysh in 1086\u201387. Another daughter, Aisha Khatun, married Shams al-Mulk Nasr, son of Ibrahim Khan Tamghach. Another daughter was married to Mas'ud III of Ghazni and was his first wife. Another daughter was Sara Khatun. The son of Alp Arslan's sister, Dev Ali Beg (\"Devle Beg\"), was a royal military general who played a key role in the conquest of Kayseri and gave his name to Develi district of Kayseri. His tribal family later became known as \"Develio\u011flu\" (meaning \"son of Develi\").\nLegacy.\nAlp Arslan's conquest of Anatolia from the Byzantines is also seen as one of the pivotal precursors to the launch of the Crusades.\nFrom 2002 to July 2008 under Turkmen calendar reform, the month of August was named after Alp Arslan.\nThe 2nd Training Motorized Rifle Division of the Turkmen Ground Forces is named in his honor.\nIn popular culture.\nIn 2020, \"Malazgirt 1071\", a TRT co-production film, saw Turkish actor Cengiz Co\u015fkun in the lead role of Sultan Alp Arslan.\nIn the 2021 Turkish historical fiction TV series \"\", Alp Arslan was portrayed by Turkish actor Bar\u0131\u015f Ardu\u00e7.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "869", "revid": "27823944", "url": "https://en.wikipedia.org/wiki?curid=869", "title": "American Film Institute", "text": "Nonprofit educational arts organization\nThe American Film Institute (AFI) is an American nonprofit film organization that educates filmmakers and honors the heritage of the motion picture arts in the United States. AFI is supported by private funding and public membership fees.\nLeadership.\nThe institute is composed of leaders from the film, entertainment, business, and academic communities. The board of trustees is chaired by Kathleen Kennedy and the board of directors chaired by Robert A. Daly guide the organization, which is led by President and CEO, film historian Bob Gazzale. Prior leaders were founding director George Stevens Jr. (from the organization's inception in 1967 until 1980) and Jean Picker Firstenberg (from 1980 to 2007).\nHistory.\nThe American Film Institute was founded by a 1965 presidential mandate announced in the Rose Garden of the White House by Lyndon B. Johnson\u2014to establish a national arts organization to preserve the legacy of American film heritage, educate the next generation of filmmakers, and honor the artists and their work. Two years later, in 1967, AFI was established, supported by the National Endowment for the Arts, the Motion Picture Association of America and the Ford Foundation.\nThe original 22-member Board of Trustees included actor Gregory Peck as chairman and actor Sidney Poitier as vice-chairman, as well as director Francis Ford Coppola, film historian Arthur Schlesinger, Jr., lobbyist Jack Valenti, and other representatives from the arts and academia.\nThe institute established a training program for filmmakers known then as the Center for Advanced Film Studies. Also created in the early years were a repertory film exhibition program at the Kennedy Center for the Performing Arts and the AFI Catalog of Feature Films \u2014 a scholarly source for American film history. The institute moved to its current eight-acre Hollywood campus in 1981. The film training program grew into the AFI Conservatory, an accredited graduate school.\nAFI moved its presentation of first-run and auteur films from the Kennedy Center to the historic AFI Silver Theatre and Cultural Center, which hosts the AFI DOCS film festival, making AFI the largest nonprofit film exhibitor in the world. AFI educates audiences and recognizes artistic excellence through its awards programs and 10 Top 10 Lists.\nIn 2017, then-aspiring filmmaker Ilana Bar-Din Giannini claimed that the AFI expelled her after she accused Dezso Magyar of sexually harassing her in the early 1980s.\nList of programs in brief.\nAFI educational and cultural programs include:\nAFI Conservatory.\nIn 1969, the institute established the AFI Conservatory for Advanced Film Studies at Greystone, the Doheny Mansion in Beverly Hills, California. The first class included filmmakers Terrence Malick, Caleb Deschanel, and Paul Schrader. That program grew into the AFI Conservatory, an accredited graduate film school located in the hills above Hollywood, California, providing training in six filmmaking disciplines: cinematography, directing, editing, producing, production design, and screenwriting. Mirroring a professional production environment, Fellows collaborate to make more films than any other graduate level program. Admission to AFI Conservatory is highly selective, with a maximum of 140 graduates per year.\nIn 2013, Emmy and Oscar-winning director, producer, and screenwriter James L. Brooks (\"As Good as It Gets\", \"Broadcast News\", \"Terms of Endearment\") joined as the artistic director of the AFI Conservatory where he provides leadership for the film program. Brooks' artistic role at the AFI Conservatory has a rich legacy that includes Daniel Petrie, Jr., Robert Wise, and Frank Pierson. Award-winning director Bob Mandel served as dean of the AFI Conservatory for nine years. Jan Schuette took over as dean in 2014 and served until 2017. Film producer Richard Gladstein was dean from 2017 until 2019, when Susan Ruskin was appointed.\nNotable alumni.\nAFI Conservatory's alumni have careers in film, television and on the web. They have been recognized with all of the major industry awards\u2014Academy Award, Emmy Award, guild awards, and the Tony Award.\nAFI Film Festivals.\nAFI operates two film festivals: &lt;templatestyles src=\"Template:Visible anchor/styles.css\" /&gt;AFI Fest in Los Angeles, and AFI Docs (formally known as Silverdocs) in Silver Spring, Maryland, and Washington, D.C.\nAmerican Film Institute Festival.\nCommonly shortened to AFI Fest, it is the American Film Institute's annual celebration of artistic excellence. It is a showcase for the best festival films of the year as selected by AFI and an opportunity for master filmmakers and emerging artists to come together with audiences. It is the only festival of its stature that is free to the public. The Academy of Motion Picture Arts and Sciences recognizes AFI Fest as a qualifying festival for the Short Films category for the annual Academy Awards.\nThe festival was first announced in January 1987 to take the place of Filmex in March 1987 with Ken Wlaschin, former Filmex artistic director, named as director of the new festival. The first festival was funded with a grant of $200,000 from the Interface Group and was to feature 80 films in a non-competitive format with a mix of independent American and foreign films. Its primary venue was the Los Feliz Theater.\nThe festival has paid tribute to numerous influential filmmakers and artists over the years, including Agn\u00e8s Varda, Pedro Almod\u00f3var and David Lynch as guest artistic directors, and has screened scores of films that have gone on to win Oscar nominations and awards.\nThe movies selected by AFI are assigned to different sections for the festival; these include Galas/Red Carpet Premieres, Special Screenings, Documentaries, Discovery, and Short Film Competition.\nRed Carpet Premieres.\nFormerly named Galas, it is AFI Fest's section for the most highly anticipated films at the festival, presenting selected feature-length movies from world-class filmmakers and artisans. Although it is a very restrictive selection, usually presenting between three and seven movies at most, many films selected by AFI for this section eventually also earn an Academy Award Best Picture nomination. Examples include Bradley Cooper's \"Maestro\" (2023), Steven Spielberg's \"The Fabelmans\" (2022), Will Smith's \"King Richard\" (2021), Jane Campion's \"The Power of the Dog\" (2021), Anthony Hopkins's \"The Father\" (2020), Noah Baumbach's \"Marriage Story\" (2019), Peter Farrelly's \"Green Book\" (2018), Luca Guadagnino's \"Call Me by Your Name\" (2017), Damien Chazelle's \"La La Land\" (2016), and Adam McKay's \"The Big Short\" (2015).\nAFI Docs.\nHeld annually in June, AFI Docs (formerly Silverdocs) is a documentary festival in Washington, D.C. The festival attracts over 27,000 documentary enthusiasts.\nAFI programs.\nAFI Catalog of Feature Films.\nThe AFI Catalog, started in 1968, is a web-based filmographic database. A research tool for film historians, the catalog consists of entries on more than 60,000 feature films and 17,000 short films produced from 1893 to 2011, as well as AFI Awards Outstanding Movies of the Year from 2000 through 2010. Early print copies of this catalog may also be found at local libraries.\nAFI Awards.\nCreated in 2000, the AFI Awards honor the ten outstanding films (\"Movies of the Year\") and ten outstanding television programs (\"TV Programs of the Year\"). The awards are a non-competitive acknowledgment of excellence.\nThe awards are announced in December, and a private luncheon for award honorees takes place the following January.\nAFI 100 Years... series.\nThe AFI 100 Years... series, which ran from 1998 to 2008 and created jury-selected lists of America's best movies in categories such as Musicals, Laughs and Thrills, prompted new generations to experience classic American films. The juries consisted of over 1,500 artists, scholars, critics, and historians. \"Citizen Kane\" was voted the greatest American film twice.\nAFI Silver Theatre and Cultural Center.\nThe AFI Silver Theatre and Cultural Center is a moving image exhibition, education and cultural center located in Silver Spring, Maryland. Anchored by the restoration of noted architect John Eberson's historic 1938 Silver Theatre, it features 32,000 square feet of new construction housing two stadium theatres, office and meeting space, and reception and exhibit areas.\nThe AFI Silver Theatre and Cultural Center presents film and video programming, augmented by filmmaker interviews, panels, discussions, and musical performances.\nThe AFI Directing Workshop for Women.\nThe Directing Workshop for Women is a training program committed to educating and mentoring participants in an effort to increase the number of women working professionally in screen directing. In this tuition-free program, each participant is required to complete a short film by the end of the year-long program.\nAlumnae of the program include Maya Angelou, Anne Bancroft, Dyan Cannon, Ellen Burstyn, Jennifer Getzinger, Lesli Linka Glatter, Lily Tomlin, Susan Oliver and Nancy Malone.\nAFI Directors Series.\nAFI released a set of hour-long programs reviewing the career of acclaimed directors. The Directors Series content was copyrighted in 1997 by Media Entertainment Inc and The American Film Institute, and the VHS and DVDs were released between 1999 and 2001 on Winstar TV and Video.\nDirectors featured included:\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "872", "revid": "38658964", "url": "https://en.wikipedia.org/wiki?curid=872", "title": "Akira Kurosawa", "text": "Japanese film director (1910\u20131998)\n was a Japanese filmmaker who directed 30 feature films in a career spanning six decades. With a bold and dynamic style strongly influenced by Western cinema yet distinct from it, he is widely regarded as one of the greatest and most influential filmmakers in the history of cinema. Known as a hands-on filmmaker, he was heavily involved with all aspects of production as a director, writer, producer, and editor.\nFollowing a brief stint as a painter, Kurosawa entered the Japanese film industry in 1936. After years of working on numerous films as an assistant director and screenwriter, he made his directorial debut during World War II with the popular action film \"Sanshiro Sugata\" (1943), released when he was 33 years old. Following the war, he cemented his reputation as one of the most important young filmmakers in Japan with the critically acclaimed \"Drunken Angel\" (1948), in which he cast the then-unknown actor Toshiro Mifune in a starring role; the two men would then collaborate on 15 more films.\n\"Rashomon\" (1950) premiered in Tokyo and became the surprise winner of the Golden Lion at the 1951 Venice Film Festival. The commercial and critical success of the film opened up Western film markets to Japanese films for the first time, which in turn led to international recognition for other Japanese filmmakers. Kurosawa directed approximately one film per year throughout the 1950s and early 1960s, including a number of highly regarded and often adapted films, including (1952), \"Seven Samurai\" (1954), \"Throne of Blood\" (1957), \"The Hidden Fortress\" (1958), \"Yojimbo\" (1961), \"High and Low\" (1963), and \"Red Beard\" (1965). He became much less prolific after the 1960s, though his later work\u2014including two of his final films, \"Kagemusha\" (1980) and \"Ran\" (1985)\u2014continued to receive critical acclaim.\nIn 1990, Kurosawa accepted the Academy Award for Lifetime Achievement. He was posthumously named \"Asian of the Century\" in the \"Arts, Literature, and Culture\" category by \"AsianWeek\" magazine and CNN, who cited him as one of the five people who most prominently contributed to the improvement of Asia in the 20th century. His career has been honored by many releases in many consumer media in addition to retrospectives, critical studies, and biographies in both print and video.\nBiography.\nChildhood to war years (1910\u20131945).\nChildhood and youth (1910\u20131935).\nKurosawa was born on March 23, 1910, in \u014ci Town, Ebara County (now Higashi-\u014ci in the Shinagawa ward of Tokyo). However, he once claimed he was born in Akita and later came to Tokyo as an infant. His mother, Shima (1870\u20131952), came from a merchant's family in Osaka; his father, Isamu (1864\u20131948), was a member of a \"samurai\" family from Akita Prefecture and worked as the director of the Army's Physical Education Institute's lower secondary school. Akira was the eighth and youngest child of the moderately wealthy family, with two of his siblings already grown up at the time of his birth and one deceased, leaving him to grow up with three sisters and a brother.\nIn addition to promoting physical exercise, Isamu was open to Western traditions, and considered theatre and cinema to have educational merit. He encouraged his children to watch films; a young Kurosawa viewed his first films at the age of six. He attended elementary school and became close friends with Keinosuke Uekusa, while an important formative influence was his teacher Mr. Tachikawa, whose progressive educational practices ignited in him first a love of drawing and then an interest in education in general. During this time, he also studied calligraphy and Kendo swordsmanship.\nAnother major childhood influence was Kurosawa's older brother by four years, Heigo (1906\u20131933). In the aftermath of the Great Kant\u014d earthquake and the subsequent Kant\u014d Massacre of 1923, Heigo took the 13-year-old Kurosawa to view the devastation. When Kurosawa wanted to look away from the corpses of humans and animals scattered everywhere, Heigo forbade him to do so, encouraging him to instead face his fears by confronting them directly. Some commentators have suggested that this incident would influence Kurosawa's later artistic career, as he was easily willing to confront and explore unpleasant truths in his work. Heigo was academically gifted, but after failing to secure a place in Tokyo's foremost high school, he began to detach himself from the rest of the family and preferred to concentrate on his interest in foreign literature. In the late 1920s, Heigo quickly made a name for himself as a \"benshi\" (silent film narrator) for Tokyo theaters showing foreign films. Kurosawa, who at this point planned to become a painter, moved in with Heigo and the two became inseparable.\nWith Heigo's guidance, Kurosawa avidly watched not only films but also theater and circus performances, while exhibiting his paintings and working for the left-wing Proletarian Artists' League. He was never able to make a living with his art, and lost his enthusiasm for painting due to this and his growing belief that most of the proletarian movement boiled down to \"putting unfulfilled political ideals directly onto the canvas\". With the increasing production of talking pictures in the early 1930s, film narrators like Heigo began to lose work, and Kurosawa moved back in with his parents. In July 1933, Heigo took his own life; Kurosawa has commented on the lasting sense of loss he felt at his brother's death, and the chapter of \"Something Like an Autobiography\" that describes it\u2014written nearly 50 years after the event\u2014is titled \"A Story I Don't Want to Tell\". Just four months after Heigo's suicide, Kurosawa's eldest brother also died, leaving 23-year-old Kurosawa as the sole surviving brother amongst his three sisters.\nDirector in training (1935\u20131941).\nIn 1935, the new film studio Photo Chemical Laboratories, known as P.C.L. (which later became the major studio Toho), advertised for assistant directors. Although he had demonstrated no previous interest in film as a profession, Kurosawa submitted the required essay, which asked applicants to discuss the fundamental deficiencies of Japanese films and find ways to overcome them. His half-mocking view was that if the deficiencies were fundamental, there was no way to correct them. Kurosawa's essay earned him a call to take the follow-up exams, and director Kajir\u014d Yamamoto, who was among the examiners, took a liking to Kurosawa and insisted that the studio hire him. Kurosawa joined P.C.L. in February 1936, at the age of 25.\nDuring his five years as an assistant director, Kurosawa worked under numerous directors, but by far the most important figure in his development was Yamamoto. Of his 24 films as A.D., he worked on 17 under Yamamoto, many of them comedies featuring the popular actor Ken'ichi Enomoto, known as \"Enoken\". Yamamoto nurtured Kurosawa's talent, promoting him directly from third assistant director to chief assistant director after a year. Kurosawa's responsibilities increased, and he worked at tasks ranging from stage construction and film development to location scouting, script polishing, rehearsals, lighting, dubbing, editing, and second-unit directing. In the last of Kurosawa's films as an assistant director for Yamamoto, \"Horse\" (1941), Kurosawa took over most of the production, as his mentor was occupied with the shooting of another film.\nYamamoto advised Kurosawa that a good director needed to master screenwriting. Kurosawa soon realized that the potential earnings from his scripts were much higher than what he was paid as an assistant director. He later wrote or co-wrote all his films and frequently penned screenplays for other directors such as Satsuo Yamamoto's film, \"A Triumph of Wings\" (\"Tsubasa no gaika\", 1942). This outside scriptwriting would serve Kurosawa as a lucrative sideline lasting well into the 1960s, long after he became famous.\nWartime films and marriage (1942\u20131945).\nIn the two years following the release of \"Horse\" in 1941, Kurosawa searched for a story he could use to launch his directing career. Towards the end of 1942, about a year after the Japanese attack on Pearl Harbor, novelist Tsuneo Tomita published his Musashi Miyamoto-inspired judo novel, \"Sanshiro Sugata\", the advertisements for which intrigued Kurosawa. He bought the book on its publication day, devoured it in one sitting, and immediately asked Toho to secure the film rights. Kurosawa's initial instinct proved correct as, within a few days, three other major Japanese studios also offered to buy the rights. Toho prevailed, and Kurosawa began pre-production on his debut work as director.\nShooting of \"Sanshiro Sugata\" began on location in Yokohama in December 1942. Production proceeded smoothly, but getting the completed film past the censors was an entirely different matter. The censorship office considered the work to be objectionably \"British-American\" by the standards of wartime Japan, and it was only through the intervention of director Yasujir\u014d Ozu, who championed the film, that \"Sanshiro Sugata\" was finally accepted for release on March 25, 1943. (Kurosawa had just turned 33.) The movie became both a critical and commercial success. Nevertheless, the censorship office would later decide to cut out some 18 minutes of footage, much of which is now considered lost.\nHe next turned to the subject of wartime female factory workers in \"The Most Beautiful\", a propaganda film which he shot in a semi-documentary style in early 1944. To elicit realistic performances from his actresses, the director had them live in a real factory during the shoot, eat the factory food and call each other by their character names. He would use similar methods with his performers throughout his career. During production, the actress playing the leader of the factory workers, Y\u014dko Yaguchi, was chosen by her colleagues to present their demands to the director. She and Kurosawa were constantly at odds, and it was through these arguments that the two paradoxically became close. They married on May 21, 1945, with Yaguchi two months pregnant (she never resumed her acting career), and the couple would remain together until her death in 1985. They had two children, both surviving Kurosawa as of 2018[ [update]]: a son, Hisao, born December 20, 1945, who served as producer on some of his father's last projects, and Kazuko, a daughter, born April 29, 1954, who became a costume designer.\nShortly before his marriage, Kurosawa was pressured by the studio against his will to direct a sequel to his debut film. The often blatantly propagandistic \"Sanshiro Sugata Part II\", which premiered in May 1945, is generally considered one of his weakest pictures. Kurosawa decided to write the script for a film that would be both censor-friendly and less expensive to produce. \"The Men Who Tread on the Tiger's Tail\", based on the Kabuki play \"Kanjinch\u014d\" and starring the comedian Enoken, with whom Kurosawa had often worked during his assistant director days, was completed in September 1945. By this time, Japan had surrendered and the occupation of Japan had begun. The new American censors interpreted the values allegedly promoted in the picture as overly \"feudal\" and banned the work. It was not released until 1952, the year another Kurosawa film, , was also released. Ironically, while in production, the film had already been savaged by Japanese wartime censors as too Western and \"democratic\" (they particularly disliked the comic porter played by Enoken), so the movie most probably would not have seen the light of day even if the war had continued beyond its completion.\nEarly postwar years to \"Red Beard\" (1946\u20131965).\nFirst postwar works (1946\u20131950).\nAfter the war, Kurosawa, influenced by the democratic ideals of the Occupation, sought to make films that would establish a new respect towards the individual and the self. The first such film, \"No Regrets for Our Youth\" (1946), inspired by both the 1933 Takigawa incident and the Hotsumi Ozaki wartime spy case, criticized Japan's prewar regime for its political oppression. Atypically for the director, the heroic central character is a woman, Yukie (Setsuko Hara), who, born into upper-middle-class privilege, comes to question her values in a time of political crisis. The original script had to be extensively rewritten and, because of its controversial theme and gender of its protagonist, the completed work divided critics. Nevertheless, it managed to win the approval of audiences, who turned variations on the film's title into a postwar catchphrase.\nHis next film, \"One Wonderful Sunday\", premiered in July 1947 to mixed reviews. It was the result of a collaboration with his childhood friend Keinosuke Uekusa. The film is a sentimental love story dealing with an impoverished couple trying to enjoy their one weekly day off within the devastation of postwar Tokyo. The movie bears the influence of Frank Capra, D. W. Griffith and F. W. Murnau, each of whom was among Kurosawa's favorite directors. Another film released in 1947 with Kurosawa's involvement was the action-adventure thriller, \"Snow Trail\", directed by Senkichi Taniguchi from Kurosawa's screenplay. It marked the debut of the intense young actor Toshiro Mifune. It was Kurosawa who, with his mentor Yamamoto, had intervened to persuade Toho to sign Mifune, during an audition in which the young man greatly impressed Kurosawa, but managed to alienate most of the other judges.\n\"Drunken Angel\" is often considered the director's first major work. Although the script, like all of Kurosawa's occupation-era works, had to go through rewrites due to American censorship, Kurosawa felt that this was the first film in which he was able to express himself freely. A gritty story of a doctor who tries to save a gangster (yakuza) with tuberculosis, it was also the first time that Kurosawa directed Mifune, who went on to play major roles in all but one of the director's next 16 films (the exception being ). While Mifune was not cast as the protagonist in \"Drunken Angel\", his explosive performance as the gangster so dominates the drama that he shifted the focus from the title character, the alcoholic doctor played by Takashi Shimura, who had already appeared in several Kurosawa movies. However, Kurosawa did not want to smother the young actor's immense vitality, and Mifune's rebellious character electrified audiences in much the way that Marlon Brando's defiant stance would startle American film audiences a few years later. The film premiered in Tokyo in April 1948 to rave reviews and was chosen by the prestigious \"Kinema Junpo\" critics poll as the best film of its year, the first of three Kurosawa movies to be so honored.\nAfter the completion of \"Drunken Angel\", Toho became embroiled in a months-long labor strike, in which the Toho union occupied the grounds of the studio. When Toho management ceased paying workers' salaries, Kurosawa formed a touring acting troupe to raise funds, directing Anton Chekhov's \"The Proposal\", and an adaptation of \"Drunken Angel\" starring Mifune and Shimura. Disillusioned by the division and violence between employees at Toho, the underhanded tactics of Toho leadership, and the breaking of the occupation by police and military standoff, Kurosawa left Toho, later recalling: \"I had come to understand that the studio I had thought was my home actually belonged to strangers\". Kurosawa, with producer S\u014djir\u014d Motoki and fellow directors and friends Kajiro Yamamoto, Mikio Naruse and Senkichi Taniguchi, formed a new independent production unit called Film Art Association (Eiga Geijutsu Ky\u014dkai). For this organization's debut work, and first film for Daiei studios, Kurosawa turned to a contemporary play by Kazuo Kikuta and, together with Taniguchi, adapted it for the screen. \"The Quiet Duel\" starred Toshiro Mifune as an idealistic young doctor struggling with syphilis, a deliberate attempt by Kurosawa to break the actor away from being typecast as gangsters. Released in March 1949, it was a box office success, but is generally considered one of the director's lesser achievements.\nHis second film of 1949, also produced by Film Art Association and released by Shintoho, was \"Stray Dog\". It is a detective movie (perhaps the first important Japanese film in that genre) that explores the mood of Japan during its painful postwar recovery through the story of a young detective, played by Mifune, and his fixation on the recovery of his handgun, which was stolen by a penniless war veteran who proceeds to use it to rob and murder. Adapted from an unpublished novel by Kurosawa in the style of a favorite writer of his, Georges Simenon, it was the director's first collaboration with screenwriter Ryuzo Kikushima, who would later help to script eight other Kurosawa films. A famous, virtually wordless sequence, lasting over eight minutes, shows the detective, disguised as an impoverished veteran, wandering the streets in search of the gun thief; it employed actual documentary footage of war-ravaged Tokyo neighborhoods shot by Kurosawa's friend, Ishir\u014d Honda, the future director of \"Godzilla\". The film is considered a precursor to the contemporary police procedural and buddy cop film genres.\n\"Scandal\", released by Shochiku in April 1950, was inspired by the director's personal experiences with (and anger towards) Japanese yellow journalism. The work is an ambitious mixture of courtroom drama and social problem film about free speech and personal responsibility, but even Kurosawa regarded the finished product as dramatically unfocused and unsatisfactory, and almost all critics agree. However, it would be Kurosawa's second film of 1950 that would ultimately win him (and Japanese cinema) a whole new international audience.\nInternational recognition (1950\u20131952).\nAfter finishing \"Scandal\", Kurosawa was approached by Daiei studios to make another film for them. Kurosawa picked a script by an aspiring young screenwriter, Shinobu Hashimoto, who would eventually work on nine of his films. Their first joint effort was based on Ry\u016bnosuke Akutagawa's experimental short story \"In a Grove\", which recounts the murder of a samurai and the rape of his wife from various different and conflicting points of view. Kurosawa saw potential in the script and, with Hashimoto's help, polished and expanded it and then pitched it to Daiei, who were happy to accept the project due to its low budget. The shooting of \"Rashomon\" began on July 7, 1950, and, after extensive location work in the primeval forest of Nara, wrapped on August 17. Just one week was spent in hurried post-production, hampered by a studio fire, and the finished film premiered at Tokyo's Imperial Theatre on August 25, expanding nationwide the following day. The movie was met by lukewarm reviews, with many critics puzzled by its unique theme and treatment, but it was nevertheless a moderate financial success for Daiei.\nKurosawa's next film, for Shochiku, was \"The Idiot\", an adaptation of the novel by the director's favorite writer, Fyodor Dostoevsky. The story is relocated from Russia to Hokkaido, but otherwise adheres closely to the original, a fact seen by many critics as detrimental to the work. A studio-mandated edit shortened it from Kurosawa's original cut of 265 minutes to just 166 minutes, making the resulting narrative exceedingly difficult to follow. The severely edited film version is widely considered to be one of the director's least successful works and the original full-length version no longer exists. Contemporary reviews of the much shortened edited version were very negative, but the film was a moderate success at the box office, largely because of the popularity of one of its stars, Setsuko Hara.\nMeanwhile, unbeknownst to Kurosawa, \"Rashomon\" had been entered in the Venice Film Festival, due to the efforts of Giuliana Stramigioli, a Japan-based representative of an Italian film company, who had seen and admired the movie and convinced Daiei to submit it. On September 10, 1951, \"Rashomon\" was awarded the festival's highest prize, the Golden Lion, shocking not only Daiei but the international film world, which at the time was largely unaware of Japan's decades-old cinematic tradition. After Daiei briefly exhibited a subtitled print of the film in Los Angeles, RKO purchased distribution rights to \"Rashomon\" in the United States. The company was taking a considerable gamble. It had put out only one prior subtitled film in the American market, and the only previous Japanese talkie commercially released in New York had been Mikio Naruse's comedy, \"Wife! Be Like a Rose!\", in 1937: a critical and box-office flop. However, \"Rashomon\"'s commercial run, greatly helped by strong reviews from critics and even the columnist Ed Sullivan, earned $35,000 in its first three weeks at a single New York theatre, an almost unheard-of sum at the time.\nThis success in turn led to a vogue in America and the West for Japanese movies throughout the 1950s, replacing the enthusiasm for Italian neorealist cinema. By the end of 1952 \"Rashomon\" was released in Japan, the United States, and most of Europe. Among the Japanese film-makers whose work, as a result, began to win festival prizes and commercial release in the West were Kenji Mizoguchi (\"The Life of Oharu\", \"Ugetsu\", \"Sansho the Bailiff\") and, somewhat later, Yasujir\u014d Ozu (\"Tokyo Story\", \"An Autumn Afternoon\")\u2014artists highly respected in Japan but, before this period, almost totally unknown in the West.\nContemporary dramas and \"Seven Samurai\" (1953\u20131955).\nHis career boosted by his sudden international fame, Kurosawa, now reunited with his original film studio, Toho (which would go on to produce his next 11 films), set to work on his next project, . Based on Leo Tolstoy's \"The Death of Ivan Ilyich\", the movie stars Takashi Shimura as a cancer-ridden Tokyo bureaucrat, Watanabe, on a final quest for meaning before his death. For the screenplay, Kurosawa brought in Hashimoto as well as writer Hideo Oguni, who would go on to co-write twelve Kurosawa films. Despite the work's grim subject matter, the screenwriters took a satirical approach, which some have compared to the work of Brecht, to both the bureaucratic world of its hero and the U.S. cultural colonization of Japan. (American pop songs figure prominently in the film.) Because of this strategy, the filmmakers are usually credited with saving the picture from the kind of sentimentality common to dramas about characters with terminal illnesses. opened in October 1952 to rave reviews\u2014it won Kurosawa his second Kinema Junpo \"Best Film\" award\u2014and enormous box office success. It remains the most acclaimed of all the artist's films set in the modern era.\nIn December 1952, Kurosawa took his screenwriters, Shinobu Hashimoto and Hideo Oguni, for a forty-five-day secluded residence at an inn to create the screenplay for his next movie, \"Seven Samurai\". The ensemble work was Kurosawa's first proper samurai film, the genre for which he would become most famous. The simple story, about a poor farming village in Sengoku period Japan that hires a group of samurai to defend it against an impending attack by bandits, was given a full epic treatment, with a huge cast (largely consisting of veterans of previous Kurosawa productions) and meticulously detailed action, stretching out to almost three-and-a-half hours of screen time.\nThree months were spent in pre-production and a month in rehearsals. Shooting took up 148 days spread over almost a year, interrupted by production and financing troubles and Kurosawa's health problems. The film finally opened in April 1954, half a year behind its original release date and about three times over budget, making it at the time the most expensive Japanese film ever made. (However, by Hollywood standards, it was a quite modestly budgeted production, even for that time.) The film received positive critical reaction and became a big hit, quickly making back the money invested in it and providing the studio with a product that they could (and did) market internationally\u2014though with extensive edits. Over time\u2014and with the theatrical and home video releases of the uncut version\u2014its reputation has steadily grown. It is now regarded by some commentators as the greatest Japanese film ever made, and in 1999 a poll of Japanese film critics also voted it the best Japanese film ever made. In the most recent (2022) version of the widely respected British Film Institute (BFI) \"Sight &amp; Sound\" \"Greatest Films of All Time\" poll, \"Seven Samurai\" placed 20th among all films from all countries in the critics' and tied at 14th in the directors' polls, receiving a place in the Top Ten lists of 48 critics and 22 directors.\nIn 1954, nuclear tests in the Pacific were causing radioactive rainstorms in Japan and one particular incident in March had exposed a Japanese fishing boat to nuclear fallout, with disastrous results. It is in this anxious atmosphere that Kurosawa's next film, \"I Live in Fear\", was conceived. The story concerned an elderly factory owner (Toshiro Mifune) so terrified of the prospect of a nuclear attack that he becomes determined to move his entire extended family (both legal and extra-marital) to what he imagines is the safety of a farm in Brazil. Production went much more smoothly than the director's previous film, but a few days before shooting ended, Kurosawa's composer, collaborator, and close friend Fumio Hayasaka died (of tuberculosis) at the age of 41. The film's score was finished by Hayasaka's student, Masaru Sato, who would go on to score all of Kurosawa's next eight films. \"I Live in Fear\" opened in November 1955 to mixed reviews and muted audience reaction, becoming the first Kurosawa film to lose money during its original theatrical run. Today, it is considered by many to be among the finest films dealing with the psychological effects of the global nuclear stalemate.\nAdaptations and birth of a company (1956\u20131960).\nKurosawa's next project, \"Throne of Blood\", an adaptation of William Shakespeare's \"Macbeth\"\u2014set, like \"Seven Samurai\", in the Sengoku Era\u2014represented an ambitious transposition of the English work into a Japanese context. Kurosawa instructed his leading actress, Isuzu Yamada, to regard the work as if it were a cinematic version of a \"Japanese\" rather than a European literary classic. Given Kurosawa's appreciation of traditional Japanese stage acting, the acting of the players, particularly Yamada, draws heavily on the stylized techniques of the Noh theater. It was filmed in 1956 and released in January 1957 to a slightly less negative domestic response than had been the case with the director's previous film. Abroad, \"Throne of Blood\", regardless of the liberties it takes with its source material, quickly earned a place among the most celebrated Shakespeare adaptations.\nAnother adaptation of a classic European theatrical work followed almost immediately, with production of \"The Lower Depths\", based on a play by Maxim Gorky, taking place in May and June 1957. In contrast to the Shakespearean sweep of \"Throne of Blood\", \"The Lower Depths\" was shot on only two confined sets, in order to emphasize the restricted nature of the characters' lives. Though faithful to the play, this adaptation of Russian material to a completely Japanese setting\u2014in this case, the late Edo period\u2014unlike his earlier \"The Idiot\", was regarded as artistically successful. The film premiered in September 1957, receiving a mixed response similar to that of \"Throne of Blood\". However, some critics rank it among the director's most underrated works.\nKurosawa's three next movies after \"Seven Samurai\" had not managed to capture Japanese audiences in the way that that film had. The mood of the director's work had been growing increasingly pessimistic and dark even as Japan entered a boom period of high-speed growth and rising standards of living. Out of step with the prevailing mood of the era, Kurosawa's films questioned the possibility of redemption through personal responsibility, particularly in \"Throne of Blood\" and \"The Lower Depths\". He recognized this and deliberately aimed for a more light-hearted and entertaining film for his next production while switching to the new widescreen format that had been gaining popularity in Japan. The resulting film, \"The Hidden Fortress\", is an action-adventure comedy-drama about a medieval princess, her loyal general, and two peasants who all need to travel through enemy lines in order to reach their home region. Released in December 1958, \"The Hidden Fortress\" became an enormous box-office success in Japan and was warmly received by critics both in Japan and abroad. Today, the film is considered one of Kurosawa's most lightweight efforts, though it remains popular, not least because it is one of several major influences on George Lucas's 1977 space opera, \"Star Wars\".\nStarting with \"Rashomon\", Kurosawa's productions had become increasingly large in scope and so had the director's budgets. Toho, concerned about this development, suggested that he might help finance his own works, therefore making the studio's potential losses smaller, while in turn allowing himself more artistic freedom as co-producer. Kurosawa agreed, and the Kurosawa Production Company was established in April 1959, with Toho as the majority shareholder.\nDespite risking his own money, Kurosawa chose a story that was more directly critical of the Japanese business and political elites than any previous work. \"The Bad Sleep Well\", based on a script by Kurosawa's nephew Mike Inoue, is a revenge drama about a young man who is able to infiltrate the hierarchy of a corrupt Japanese company with the intention of exposing the men responsible for his father's death. Its theme proved topical: while the film was in production, the massive Anpo protests were held against the new U.S.\u2013Japan Security treaty, which was seen by many Japanese, particularly the young, as threatening the country's democracy by giving too much power to corporations and politicians. The film opened in September 1960 to positive critical reaction and modest box office success. The 25-minute opening sequence depicting a corporate wedding reception is widely regarded as one of Kurosawa's most skillfully executed set pieces, but the remainder of the film is often perceived as disappointing by comparison. The movie has also been criticized for employing the conventional Kurosawan hero to combat a social evil that cannot be resolved through the actions of individuals, however courageous or cunning.\nBox-office success (1961\u20131964).\n\"Yojimbo\" (\"The Bodyguard\"), Kurosawa Production's second film, centers on a masterless samurai, Sanjuro, who strolls into a 19th-century town ruled by two opposing violent factions and provokes them into destroying each other. The director used this work to play with many genre conventions, particularly the Western, while at the same time offering an unprecedentedly (for the Japanese screen) graphic portrayal of violence. Some commentators have seen the Sanjuro character in this film as a fantasy figure who magically reverses the historical triumph of the corrupt merchant class over the samurai class. Featuring Tatsuya Nakadai in his first major role in a Kurosawa movie, and with innovative photography by Kazuo Miyagawa (who shot \"Rashomon\") and Takao Saito, the film premiered in April 1961 and was a critically and commercially successful venture, earning more than any previous Kurosawa film. The movie and its blackly comic tone were also widely imitated abroad. Sergio Leone's \"A Fistful of Dollars\" was a virtual (unauthorized) scene-by-scene remake with Toho filing a lawsuit on Kurosawa's behalf and prevailing.\nFollowing the success of \"Yojimbo\", Kurosawa found himself under pressure from Toho to create a sequel. Kurosawa turned to a script he had written before \"Yojimbo\", reworking it to include the hero of his previous film. \"Sanjuro\" was the first of three Kurosawa films to be adapted from the work of the writer Sh\u016bgor\u014d Yamamoto (the others would be \"Red Beard\" and \"Dodeskaden\"). It is lighter in tone and closer to a conventional period film than \"Yojimbo\", though its story of a power struggle within a samurai clan is portrayed with strongly comic undertones. The film opened on January 1, 1962, quickly surpassing \"Yojimbo\"'s box office success and garnering positive reviews.\nKurosawa had meanwhile instructed Toho to purchase the film rights to \"King's Ransom\", a novel about a kidnapping written by American author and screenwriter Evan Hunter, under his pseudonym of Ed McBain, as one of his 87th Precinct series of crime books. The director intended to create a work condemning kidnapping, which he considered one of the very worst crimes. The suspense film, titled \"High and Low\", was shot during the latter half of 1962 and released in March 1963. It broke Kurosawa's box office record (the third film in a row to do so), became the highest grossing Japanese film of the year and won glowing reviews. However, his triumph was somewhat tarnished when, ironically, the film was blamed for a wave of kidnappings which occurred in Japan about this time (he himself received kidnapping threats directed at his young daughter, Kazuko). \"High and Low\" is considered by many commentators to be among the director's strongest works.\n\"Red Beard\" (1965).\nKurosawa quickly moved on to his next project, \"Red Beard\". Based on a short story collection by Sh\u016bgor\u014d Yamamoto and incorporating elements from Dostoevsky's novel \"The Insulted and Injured\", it is a period film, set in a mid-nineteenth century clinic for the poor, in which Kurosawa's humanist themes receive perhaps their fullest statement. A conceited and materialistic, foreign-trained young doctor, Yasumoto, is forced to become an intern at the clinic under the stern tutelage of Doctor Niide, known as \"Akahige\" (\"Red Beard\"), played by Mifune. Although he resists Red Beard initially, Yasumoto comes to admire his wisdom and courage and to perceive the patients at the clinic, whom he at first despised, as worthy of compassion and dignity.\nY\u016bz\u014d Kayama, who plays Yasumoto, was an extremely popular film and music star at the time, particularly for his \"Young Guy\" (\"Wakadaish\u014d\") series of musical comedies, so signing him to appear in the film virtually guaranteed Kurosawa strong box-office. The shoot, the filmmaker's longest ever, lasted well over a year (after five months of pre-production) and wrapped in spring 1965, leaving the director, his crew and his actors exhausted. \"Red Beard\" premiered in April 1965, becoming the year's highest-grossing Japanese production and the third (and last) Kurosawa film to top the prestigious \"Kinema Jumpo\" yearly critics poll. It remains one of Kurosawa's best-known and most-loved works in his native country. Outside Japan, critics have been much more divided. Most commentators concede its technical merits and some praise it as among Kurosawa's best, while others insist that it lacks complexity and genuine narrative power, with still others claiming that it represents a retreat from the artist's previous commitment to social and political change.\nThe film marked something of an end of an era for its creator. The director himself recognized this at the time of its release, telling critic Donald Richie that a cycle of some kind had just come to an end and that his future films and production methods would be different. His prediction proved quite accurate. Beginning in the late 1950s, television began increasingly to dominate the leisure time of the formerly large and loyal Japanese cinema audience. And as film company revenues dropped, so did their appetite for risk\u2014particularly the risk represented by Kurosawa's costly production methods. \"Red Beard\" also marked the midway point, chronologically, in the artist's career. During his previous twenty-nine years in the film industry (which includes his five years as assistant director), he had directed twenty-three films, while during the remaining twenty-eight years, for many complex reasons, he would complete only seven more. Also, for reasons never adequately explained, \"Red Beard\" would be his final film starring Toshiro Mifune. Y\u016b Fujiki, an actor who worked on \"The Lower Depths\", observed, regarding the closeness of the two men on the set, \"Mr. Kurosawa's heart was in Mr. Mifune's body.\" Donald Richie has described the rapport between them as a unique \"symbiosis\".\nHollywood ambitions to last films (1966\u20131998).\nHollywood detour (1966\u20131968).\nWhen Kurosawa's exclusive contract with Toho came to an end in 1966, the 56-year-old director was seriously contemplating change. Observing the troubled state of the domestic film industry and having already received dozens of offers from abroad, the idea of working outside Japan appealed to him as never before. For his first foreign project, Kurosawa chose a story based on a \"Life\" magazine article. The Embassy Pictures action thriller, to be filmed in English and called simply \"Runaway Train\", would have been his first in color. But the language barrier proved a major problem, and the English version of the screenplay was not even finished by the time filming was to begin in autumn 1966. The shoot, which required snow, was moved to autumn 1967, then canceled in 1968. Almost two decades later, another foreign director working in Hollywood, Andrei Konchalovsky, finally made \"Runaway Train\" (1985), though from a new script loosely based on Kurosawa's.\nThe director meanwhile had become involved in a much more ambitious Hollywood project. \"Tora! Tora! Tora!\", produced by 20th Century Fox and Kurosawa Production, would be a portrayal of the Japanese attack on Pearl Harbor from both the American and the Japanese points of view, with Kurosawa helming the Japanese half and an Anglophonic film-maker directing the American half. He spent several months working on the script with Ryuzo Kikushima and Hideo Oguni, but very soon the project began to unravel. The director of the American sequences turned out not to be David Lean, as originally planned, but American Richard Fleischer. The budget was also cut, and the screen time allocated for the Japanese segment would now be no longer than 90 minutes\u2014a major problem, considering that Kurosawa's script ran over four hours. After numerous revisions with the direct involvement of Darryl Zanuck, a more or less finalized cut screenplay was agreed upon in May 1968.\nShooting began in early December, but Kurosawa would last only a little over three weeks as director. He struggled to work with an unfamiliar crew and the requirements of a Hollywood production, while his working methods puzzled his American producers, who ultimately concluded that the director must be mentally ill. Kurosawa was examined at Kyoto University Hospital by a neuropsychologist, Dr. Murakami, whose diagnosis was forwarded to Darryl Zanuck and Richard Zanuck at Fox studios indicating a diagnosis of neurasthenia stating that, \"He is suffering from disturbance of sleep, agitated with feelings of anxiety and in manic excitement caused by the above mentioned illness. It is necessary for him to have rest and medical treatment for more than two months.\" On Christmas Eve 1968, the Americans announced that Kurosawa had left the production due to \"fatigue\", effectively firing him. He was ultimately replaced, for the film's Japanese sequences, with two directors, Kinji Fukasaku and Toshio Masuda.\n\"Tora! Tora! Tora!\", finally released to unenthusiastic reviews in September 1970, was, as Donald Richie put it, an \"almost unmitigated tragedy\" in Kurosawa's career. He had spent years of his life on a logistically nightmarish project to which he ultimately did not contribute a foot of film shot by himself. (He had his name removed from the credits, though the script used for the Japanese half was still his and his co-writers'.) He became estranged from his longtime collaborator, writer Ryuzo Kikushima, and never worked with him again. The project had inadvertently exposed corruption in his own production company (a situation reminiscent of his own movie, \"The Bad Sleep Well\"). His very sanity had been called into question. Worst of all, the Japanese film industry\u2014and perhaps Kurosawa himself\u2014began to suspect that he would never make another film.\nA difficult decade (1969\u20131977).\nKnowing that his reputation was at stake following the much publicised \"Tora! Tora! Tora!\" debacle, Kurosawa moved quickly to a new project to prove he was still viable. To his aid came friends and famed directors Keisuke Kinoshita, Masaki Kobayashi and Kon Ichikawa, who together with Kurosawa established in July 1969 a production company called the Club of the Four Knights (Yonki no kai). Although the plan was for the four directors to create a film each, it has been suggested that the real motivation for the other three directors was to make it easier for Kurosawa to successfully complete a film and therefore find his way back into the business.\nThe first project proposed and worked on was a period film to be called \"Dora-heita\", but when this was deemed too expensive, attention shifted to \"Dodesukaden\", an adaptation of yet another Sh\u016bgor\u014d Yamamoto work, again about the poor and destitute. The film was shot quickly (by Kurosawa's standards) in about nine weeks, with Kurosawa determined to show he was still capable of working quickly and efficiently within a limited budget. For his first work in color, the dynamic editing and complex compositions of his earlier pictures were set aside, with the artist focusing on the creation of a bold, almost surreal palette of primary colors, in order to reveal the toxic environment in which the characters live. It was released in Japan in October 1970, but though a minor critical success, it was greeted with audience indifference. The picture lost money and caused the Club of the Four Knights to dissolve. Initial reception abroad was somewhat more favorable, but \"Dodesukaden\" has since been typically considered an interesting experiment not comparable to the director's best work.\nAfter struggling through the production of \"Dodesukaden\", Kurosawa turned to television work the following year for the only time in his career with \"Song of the Horse\", a documentary about thoroughbred race horses. It featured a voice-over narrated by a fictional man and a child (voiced by the same actors as the beggar and his son in \"Dodesukaden\"). It is the only documentary in Kurosawa's filmography; the small crew included his frequent collaborator Masaru Sato, who composed the music. \"Song of the Horse\" is also unique in Kurosawa's oeuvre in that it includes an editor's credit, suggesting that it is the only Kurosawa film that he did not cut himself.\nUnable to secure funding for further work and allegedly having health problems, Kurosawa apparently reached the breaking point: on December 22, 1971, he slit his wrists and throat multiple times. He survived the suicide attempt, with his health recovering fairly quickly. He subsequently took refuge in domestic life, uncertain if he would ever direct another film.\nIn early 1973, the Soviet studio Mosfilm approached the film-maker to ask if he would be interested in working with them. Kurosawa proposed an adaptation of Russian explorer Vladimir Arsenyev's autobiographical work \"Dersu Uzala\". The book, about a Goldi hunter who lives in harmony with nature until destroyed by encroaching civilization, was one that he had wanted to make since the 1930s. In December 1973, the 63-year-old Kurosawa set off for the Soviet Union with four of his closest aides, beginning a year-and-a-half stay in the country. Shooting began in May 1974 in Siberia, with filming in exceedingly harsh natural conditions proving very difficult and demanding. The picture wrapped in April 1975, with a thoroughly exhausted and homesick Kurosawa returning to Japan and his family in June. \"Dersu Uzala\" had its world premiere in Japan on August 2, 1975, and did well at the box office. While critical reception in Japan was muted, the film was better reviewed abroad, winning the Golden Prize at the 9th Moscow International Film Festival, as well as an Academy Award for Best Foreign Language Film. Today, critics remain divided over the film: some see it as an example of Kurosawa's alleged artistic decline, while others count it among his finest works.\nAlthough proposals for television projects were submitted to him, he had no interest in working outside the film world. Nevertheless, the hard-drinking director did agree to appear in a series of television ads for Suntory whiskey, which aired in 1976. While fearing that he might never be able to make another film, Kurosawa nevertheless continued working on various projects, writing scripts and creating detailed illustrations, intending to leave behind a visual record of his plans in case he would never be able to film his stories.\nTwo epics (1978\u20131986).\nIn 1977, George Lucas released \"Star Wars\", a wildly successful science fiction film influenced by Kurosawa's \"The Hidden Fortress\". Lucas, like many other New Hollywood directors, revered Kurosawa and considered him a role model and was shocked to discover that the Japanese film-maker was unable to secure financing for any new work. The two met in San Francisco in July 1978 to discuss the project Kurosawa considered most financially viable: , the epic story of a thief hired as the double of a medieval Japanese lord of a great clan. Lucas, enthralled by the screenplay and Kurosawa's illustrations, leveraged his influence over 20th Century Fox to coerce the studio that had fired Kurosawa just ten years earlier to produce , then recruited fellow fan Francis Ford Coppola as co-producer.\nProduction began the following April, with Kurosawa in high spirits. Shooting lasted from June 1979 through March 1980 and was plagued with problems, not the least of which was the firing of the original lead actor, Shintaro Katsu\u2014known for portraying the popular character Zatoichi\u2014due to an incident in which the actor insisted, against the director's wishes, on videotaping his own performance. (He was replaced by Tatsuya Nakadai, in his first of two consecutive leading roles in a Kurosawa movie.) The film was completed only a few weeks behind schedule and opened in Tokyo in April 1980. It quickly became a massive hit in Japan. The film was also a critical and box office success abroad, winning the coveted at the 1980 Cannes Film Festival in May, though some critics, then and now, have faulted the film for its alleged coldness. Kurosawa spent much of the rest of the year in Europe and America promoting , collecting awards and accolades and exhibiting as art the drawings he had made to serve as storyboards for the film.\nThe international success of allowed Kurosawa to proceed with his next project, , another epic in a similar vein. The script, partly based on Shakespeare's \"King Lear\", depicted a ruthless, bloodthirsty \"daimy\u014d\" (warlord), played by Tatsuya Nakadai, who, after foolishly banishing his one loyal son, surrenders his kingdom to his other two sons, who then betray him, thus plunging the entire kingdom into war. As Japanese studios still felt wary about producing another film that would rank among the most expensive ever made in the country, international help was again needed. This time it came from French producer Serge Silberman, who had produced Luis Bu\u00f1uel's final movies. Filming did not begin until December 1983 and lasted more than a year. In January 1985, production of was halted as Kurosawa's 64-year-old wife Y\u014dko fell ill. She died on February 1. Kurosawa returned to finish his film and premiered at the Tokyo Film Festival on May 31, with a wide release the next day. The film was a moderate financial success in Japan, but a larger one abroad and, as he had done with , Kurosawa embarked on a trip to Europe and America, where he attended the film's premieres in September and October.\n won several awards in Japan, but was not quite as honored there as many of the director's best films of the 1950s and 1960s had been. The film world was surprised, however, when Japan passed over the selection of in favor of another film as its official entry to compete for an Oscar nomination in the Best Foreign Film category, which was ultimately rejected for competition at the 58th Academy Awards. Both the producer and Kurosawa himself attributed the failure to even submit for competition to a misunderstanding: because of the academy's arcane rules, no one was sure whether qualified as a \"Japanese\" film, a \"French\" film (due to its financing), or both, so it was not submitted at all. In response to what at least appeared to be a blatant snub by his own countrymen, the director Sidney Lumet led a successful campaign to have Kurosawa receive an Oscar nomination for Best Director that year (Sydney Pollack ultimately won the award for directing \"Out of Africa\"). 's costume designer, Emi Wada, won the movie's only Oscar.\n and , particularly the latter, are often considered to be among Kurosawa's finest works. After 's release, Kurosawa would point to it as his best film, a major change of attitude for the director who, when asked which of his works was his best, had always previously answered \"my next one\".\nFinal works and last years (1987\u20131998).\nFor his next movie, Kurosawa chose a subject very different from any that he had ever filmed before. While some of his previous pictures (for example, \"Drunken Angel\" and ) had included brief dream sequences, \"Dreams\" was to be entirely based upon the director's own dreams. Significantly, for the first time in over forty years, Kurosawa, for this deeply personal project, wrote the screenplay alone. Although its estimated budget was lower than the films immediately preceding it, Japanese studios were still unwilling to back one of his productions, so Kurosawa turned to another famous American fan, Steven Spielberg, who convinced Warner Bros. to buy the international rights to the completed film. This made it easier for Kurosawa's son, Hisao, as co-producer and soon-to-be head of Kurosawa Production, to negotiate a loan in Japan that would cover the film's production costs. Shooting took more than eight months to complete, and \"Dreams\" premiered at Cannes in May 1990 to a polite but muted reception, similar to the reaction the picture would generate elsewhere in the world. In 1990, he accepted the Academy Award for Lifetime Achievement. In his acceptance speech, he famously said \"I'm a little worried because I don't feel that I understand cinema yet.\" At the time, Bob Thomas of \"The Daily Spectrum\" noted that Kurosawa was \"considered by many critics as the greatest living filmmaker.\"\nKurosawa now turned to a more conventional story with \"Rhapsody in August\"\u2014the director's first film fully produced in Japan since \"Dodeskaden\" over twenty years before\u2014which explored the scars of the nuclear bombing which destroyed Nagasaki at the very end of World War II. It was adapted from a Kiyoko Murata novel, but the film's references to the Nagasaki bombing came from the director rather than from the book. This was his only movie to include a role for an American movie star: Richard Gere, who plays a small role as the nephew of the elderly heroine. Shooting took place in early 1991, with the film opening on May 25 that year to a largely negative critical reaction, especially in the United States, where the director was accused of promulgating na\u00efvely anti-American sentiments, though Kurosawa rejected these accusations.\nKurosawa wasted no time moving onto his next project: \"Madadayo\", or \"Not Yet\". Based on autobiographical essays by Hyakken Uchida, the film follows the life of a Japanese professor of German through the Second World War and beyond. The narrative centers on yearly birthday celebrations with his former students, during which the protagonist declares his unwillingness to die just yet\u2014a theme that was becoming increasingly relevant for the film's 81-year-old creator. Filming began in February 1992 and wrapped by the end of September. Its release on April 17, 1993, was greeted by an even more disappointed reaction than had been the case with his two preceding works.\nKurosawa nevertheless continued to work. He wrote the original screenplays \"The Sea Is Watching\" in 1993 and \"After the Rain\" in 1995. While putting finishing touches on the latter in 1995, he slipped and broke the base of his spine. Following this, he used a wheelchair for the rest of his life, putting an end to any hopes of him directing another film. His longtime wish to die on the set while shooting a film would never be fulfilled. After his accident, his health began to deteriorate. His mind remained sharp and lively but his body was giving up, and he spent the final six months of his life largely confined to bed at home, where he listened to music and watched television. On September 6, 1998, at the age of 88, he died of a stroke in Tokyo's Setagaya ward.\nAt the time of his death, Kurosawa had two children: a son named Hisao, who became a producer and married singer Hiroko Hayashi, and a daughter named Kazuko, who became a costume designer and married Harayuki Kato. Kurosawa was survived by his children and several grandchildren. One of Kazuko's children, Takayuki Kato, later became an actor and had supporting roles in two films posthumously developed from screenplays written by Kurosawa: Takashi Koizumi's \"After the Rain\" (1999) and Kei Kumai's \"The Sea is Watching\" (2002).\nFilmography.\nThe complete list of Kurosawa's works includes his films in addition to his work in television, theater, and literature.\nStyle, themes and techniques.\nKurosawa displayed a bold and dynamic style, strongly influenced by Western cinema yet distinct from it; he was involved with all aspects of production as a writer, director, producer, and editor. He was a gifted screenwriter and worked closely with his co-writers from a film's development onward to ensure a high-quality script, which he considered the firm foundation of a good film. He also frequently edited his own films. His team of frequent collaborators, known as the , included actor Takashi Shimura, cinematographer Asakazu Nakai, and production assistant Teruyo Nogami.\nKurosawa's style is marked by a number of devices and techniques. In his films of the 1940s and 1950s, he frequently employs the \"axial cut\", in which the camera moves toward or away from the subject through a series of matched jump cuts rather than tracking shots or dissolves. Another stylistic trait is \"cut on motion\", which displays the motion on the screen in two or more shots instead of one uninterrupted one. A form of cinematic punctuation strongly identified with Kurosawa is the wipe, an effect created through an optical printer: a line or bar appears to move across the screen, wiping away the end of a scene and revealing the first image of the next. As a transitional device, it is used as a substitute for the straight cut or the dissolve; in his mature work, the wipe became Kurosawa's signature.\nIn the film's soundtrack, Kurosawa favored the sound-image counterpoint, in which the music or sound effects appeared to comment ironically on the image rather than emphasizing it. Teruyo Nogami's memoir gives several such examples from \"Drunken Angel\" and \"Stray Dog\". Kurosawa was also involved with several of Japan's outstanding contemporary composers, including Fumio Hayasaka and T\u014dru Takemitsu.\nKurosawa employed a number of recurring themes in his films: the master-disciple relationship between a usually older mentor and one or more novices, which often involves spiritual as well as technical mastery and self-mastery; the heroic champion, the exceptional individual who emerges from the mass of people to produce something or right some wrong; the depiction of extremes of weather as both dramatic devices and symbols of human passion; and the recurrence of cycles of savage violence within history. According to Stephen Prince, the last theme, which he calls, \"the countertradition to the committed, heroic mode of Kurosawa's cinema,\" began with \"Throne of Blood\" (1957) and recurred in the films of the 1980s.\nLegacy and cultural impact.\nKurosawa is often cited as one of the greatest filmmakers of all time. In 1999, he was named \"Asian of the Century\" in the \"Arts, Literature, and Culture\" category by \"AsianWeek\" magazine and CNN, cited as \"one of the [five] people who contributed most to the betterment of Asia in the past 100 years\". Kurosawa was ranked third in the directors' poll and fifth in the critics' poll in \"Sight &amp; Sound\"'s 2002 list of the greatest directors of all time. In commemoration of the 100th anniversary of Kurosawa's birth in 2010, a project called AK100 was launched in 2008. The AK100 Project aims to \"expose young people who are the representatives of the next generation, and all people everywhere, to the light and spirit of Akira Kurosawa and the wonderful world he created\".\nReputation among filmmakers.\nMany filmmakers have been influenced by Kurosawa's work. Ingmar Bergman called his own film \"The Virgin Spring\" a \"touristic... lousy imitation of Kurosawa\" and added, \"At that time my admiration for the Japanese cinema was at its height. I was almost a samurai myself!\" Federico Fellini considered Kurosawa to be \"the greatest living example of all that an author of the cinema should be\". Steven Spielberg cited Kurosawa's cinematic vision as shaping his own. Satyajit Ray, who was posthumously awarded the \"Akira Kurosawa Award for Lifetime Achievement in Directing\" at the San Francisco International Film Festival in 1992, had said earlier of \"Rashomon\": \n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The effect of the film on me [upon first seeing it in Calcutta in 1952] was electric. I saw it three times on consecutive days and wondered each time if there was another film anywhere which gave such sustained and dazzling proof of a director's command over every aspect of film making.\nRoman Polanski considered Kurosawa to be among the three film-makers he favored most, along with Fellini and Orson Welles, and picked \"Seven Samurai\", \"Throne of Blood\" and \"The Hidden Fortress\" for praise. Bernardo Bertolucci considered Kurosawa's influence to be seminal: \"Kurosawa's movies and \"La Dolce Vita\" of Fellini are the things that pushed me, sucked me into being a film director.\" Andrei Tarkovsky cited Kurosawa as one of his favorites and named \"Seven Samurai\" as one of his ten favorite films. Sidney Lumet called Kurosawa the \"Beethoven of movie directors\". Werner Herzog reflected on film-makers with whom he feels kinship and the movies that he admires:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Griffith \u2013 especially his \"Birth of a Nation\" and \"Broken Blossoms\" \u2013 Murnau, Bu\u00f1uel, Kurosawa and Eisenstein's \"Ivan the Terrible\", ... all come to mind. ... I like Dreyer's \"The Passion of Joan of Arc\", Pudovkin's \"Storm Over Asia\" and Dovzhenko's \"Earth\", ... Mizoguchi's \"Ugetsu Monogatari\", Satyajit Ray's \"The Music Room\" ... I have always wondered how Kurosawa made something as good as \"Rashomon\"; the equilibrium and flow are perfect, and he uses space in such a well-balanced way. It is one of the best films ever made.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nSources.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "873", "revid": "7611264", "url": "https://en.wikipedia.org/wiki?curid=873", "title": "Ancient civilization", "text": ""}
{"id": "874", "revid": "48135522", "url": "https://en.wikipedia.org/wiki?curid=874", "title": "Ancient Egypt", "text": "Cradle of civilization in Northeast Africa\nAncient Egypt was a cradle of civilization concentrated along the lower reaches of the Nile River in Northeast Africa. It emerged from prehistoric Egypt around 3150BC (according to conventional Egyptian chronology), when Upper and Lower Egypt were amalgamated by Menes, who is believed by the majority of Egyptologists to have been the same person as Narmer. The history of ancient Egypt unfolded as a series of stable kingdoms interspersed by the \"Intermediate Periods\" of relative instability. These stable kingdoms existed in one of three periods: the Old Kingdom of the Early Bronze Age; the Middle Kingdom of the Middle Bronze Age; or the New Kingdom of the Late Bronze Age.\nThe pinnacle of ancient Egyptian power was achieved during the New Kingdom, which extended its rule to much of Nubia and a considerable portion of the Levant. After this period, Egypt entered an era of slow decline. Over the course of its history, it was invaded or conquered by a number of foreign civilizations, including the Hyksos, the Kushites, the Assyrians, the Persians, and the Greeks and then the Romans. The end of ancient Egypt is variously defined as occurring with the end of the Late Period during the Wars of Alexander the Great in 332 BC or with the end of the Greek-ruled Ptolemaic Kingdom during the Roman conquest of Egypt in 30 BC. In AD 642, the Arab conquest of Egypt brought an end to the region's millennium-long Greco-Roman period.\nThe success of ancient Egyptian civilization came partly from its ability to adapt to the Nile's conditions for agriculture. The predictable flooding of the Nile and controlled irrigation of its fertile valley produced surplus crops, which supported a more dense population, and thereby substantial social and cultural development. With resources to spare, the administration sponsored the mineral exploitation of the valley and its surrounding desert regions, the early development of an independent writing system, the organization of collective construction and agricultural projects, trade with other civilizations, and a military to assert Egyptian dominance throughout the Near East. Motivating and organizing these activities was a bureaucracy of elite scribes, religious leaders, and administrators under the control of the reigning pharaoh, who ensured the cooperation and unity of the Egyptian people in the context of an elaborate system of religious beliefs.\nAmong the many achievements of ancient Egypt are: the quarrying, surveying, and construction techniques that supported the building of monumental pyramids, temples, and obelisks; a system of mathematics; a practical and effective system of medicine; irrigation systems and agricultural production techniques; the first known planked boats; Egyptian faience and glass technology; new forms of literature; and the earliest known peace treaty, which was ratified with the Anatolia-based Hittite Empire. Its art and architecture were widely copied and its antiquities were carried off to be studied, admired, or coveted in the far corners of the world. Likewise, its monumental ruins inspired the imaginations of travelers and writers for millennia. A newfound European and Egyptian respect for antiquities and excavations that began in earnest in the early modern period has led to much scientific investigation of ancient Egypt and its society, as well as a greater appreciation of its cultural legacy.\nHistory.\nThe Nile has been the lifeline of its region for much of human history. The fertile floodplain of the Nile gave humans the opportunity to develop a settled agricultural economy and a more sophisticated, centralized society that became a cornerstone in the history of human civilization.\nPredynastic period.\nIn Predynastic and Early Dynastic times, the Egyptian climate was much less arid than it is today. Large regions of Egypt were savanna and traversed by herds of grazing ungulates. Foliage and fauna were far more prolific in all environs, and the Nile region supported large populations of waterfowl. Hunting would have been common for Egyptians, and this is also the period when many animals were first domesticated.\nBy about 5500\u00a0BC, small tribes living in the Nile valley had developed into a series of cultures demonstrating firm control of agriculture and animal husbandry, and identifiable by their pottery and personal items, such as combs, bracelets, and beads. The largest of these early cultures in upper (Southern) Egypt was the Badarian culture, which probably originated in the Western Desert; it was known for its high-quality ceramics, stone tools, and its use of copper.\nThe Badari was followed by the Naqada culture: the Naqada I (Amratian), the Naqada II (Gerzeh), and Naqada III (Semainean). These brought a number of technological improvements. As early as the Naqada I Period, predynastic Egyptians imported obsidian from Ethiopia, used to shape blades and other objects from flakes. Mutual trade with the Levant was established during Naqada II (c.\u20093600\u20133350 BC); this period was also the beginning of trade with Mesopotamia, which continued into the early dynastic period and beyond. Over a period of about 1,000 years, the Naqada culture developed from a few small farming communities into a powerful civilization whose leaders were in complete control of the people and resources of the Nile valley. Establishing a power center at Nekhen, and later at Abydos, Naqada III leaders expanded their control of Egypt northwards along the Nile. They also traded with Nubia to the south, the oases of the western desert to the west, and the cultures of the eastern Mediterranean and Near East to the east.\nThe Naqada culture manufactured a diverse selection of material goods, reflective of the increasing power and wealth of the elite, as well as societal personal-use items, which included combs, small statuary, painted pottery, high quality decorative stone vases, cosmetic palettes, and jewelry made of gold, lapis, and ivory. They also developed a ceramic glaze known as faience, which was used well into the Roman Period to decorate cups, amulets, and figurines. During the last predynastic phase, the Naqada culture began using written symbols that eventually were developed into a full system of hieroglyphs for writing the ancient Egyptian language.\nEarly Dynastic Period (c.\u20093150\u20132686 BC).\nThe Early Dynastic Period was approximately contemporary to the early Sumerian-Akkadian civilization of Mesopotamia and of ancient Elam. The third-centuryBC Egyptian priest Manetho grouped the long line of kings from Menes to his own time into 30 dynasties, a system still used today. He began his official history with the king named \"Meni\" (or Menes in Greek), who was believed to have united the two kingdoms of Upper and Lower Egypt.\nThe transition to a unified state happened more gradually than ancient Egyptian writers represented, and there is no contemporary record of Menes. Some scholars now believe, however, that the mythical Menes may have been the king Narmer, who is depicted wearing royal regalia on the ceremonial \"Narmer Palette\", in a symbolic act of unification. In the Early Dynastic Period, which began about 3000BC, the first of the Dynastic kings solidified control over Lower Egypt by establishing a capital at Memphis, from which he could control the labor force and agriculture of the fertile delta region, as well as the lucrative and critical trade routes to the Levant. The increasing power and wealth of the kings during the early dynastic period was reflected in their elaborate mastaba tombs and mortuary cult structures at Abydos, which were used to celebrate the deified king after his death. The strong institution of kingship developed by the kings served to legitimize state control over the land, labor, and resources that were essential to the survival and growth of ancient Egyptian civilization.\nOld Kingdom (2686\u20132181 BC).\nMajor advances in architecture, art, and technology were made during the Old Kingdom, fueled by the increased agricultural productivity and resulting population growth, made possible by a well-developed central administration. Some of ancient Egypt's crowning achievements, the Giza pyramids and Great Sphinx, were constructed during the Old Kingdom. Under the direction of the vizier, state officials collected taxes, coordinated irrigation projects to improve crop yield, and drafted peasants to work on construction projects. \nWith the rise of central administration in Egypt, a new class of educated scribes and officials emerged and were granted estates by the king as payment for their services. Kings also made land grants to their mortuary cults and local temples, to ensure that these institutions had the resources to worship the king after his death. Scholars believe that five centuries of these practices slowly eroded the economic vitality of Egypt, and that the economy could no longer afford to support a large centralized administration. As the power of the kings diminished, regional governors called nomarchs began to challenge the supremacy of the office of king. This, coupled with severe droughts between 2200 and 2150BC, is believed to have caused the country to enter the 140-year period of famine and strife known as the First Intermediate Period.\nFirst Intermediate Period (2181\u20132055 BC).\nAfter Egypt's central government collapsed at the end of the Old Kingdom, the administration could no longer support or stabilize the country's economy. The ensuing food shortages and political disputes escalated into famines and small-scale civil wars. Yet despite difficult problems, local leaders, owing no tribute to the king, used their new-found independence to establish a thriving culture in the provinces. Once in control of their own resources, the provinces became economically richer\u2014which was demonstrated by larger and better burials among all social classes.\nFree from their loyalties to the king, local rulers began competing with each other for territorial control and political power. By 2160BC, rulers in Herakleopolis controlled Lower Egypt in the north, while a rival clan based in Thebes, the Intef family, took control of Upper Egypt in the south. As the Intefs grew in power and expanded their control northward, a clash between the two rival dynasties became inevitable. Around 2055BC the northern Theban forces under Nebhepetre Mentuhotep II finally defeated the Herakleopolitan rulers, reuniting the Two Lands. They inaugurated a period of economic and cultural renaissance known as the Middle Kingdom.\nMiddle Kingdom (2134\u20131690 BC).\nThe kings of the Middle Kingdom restored the country's stability, which saw a resurgence of art and monumental building projects, and a new flourishing of literature. Mentuhotep II and his Eleventh Dynasty successors ruled from Thebes, but the vizier Amenemhat I, upon assuming the kingship at the beginning of the Twelfth Dynasty around 1985BC, shifted the kingdom's capital to the city of Itjtawy, located in Faiyum. From Itjtawy, the kings of the Twelfth Dynasty undertook a far-sighted land reclamation and irrigation scheme to increase agricultural output in the region. Moreover, the military reconquered territory in Nubia that was rich in quarries and gold mines, while laborers built a defensive structure in the Eastern Delta, called the \"Walls of the Ruler\", to defend against foreign attack.\nWith the kings having secured the country militarily and politically and with vast agricultural and mineral wealth at their disposal, the nation's population, arts, and religion flourished. The Middle Kingdom displayed an increase in expressions of personal piety toward the gods. Middle Kingdom literature featured sophisticated themes and characters written in a confident, eloquent style. The relief and portrait sculpture of the period captured subtle, individual details that reached new heights of technical sophistication.\nSecond Intermediate Period (1674\u20131549 BC) and the Hyksos.\nAround 1785BC, as the power of the Middle Kingdom kings weakened, a Western Asian people called the Hyksos, who had already settled in the Delta, seized control of Egypt and established their capital at Avaris, forcing the former central government to retreat to Thebes. The king was treated as a vassal and expected to pay tribute. The Hyksos ('foreign rulers') retained Egyptian models of government and identified as kings, thereby integrating Egyptian elements into their culture.\nAfter retreating south, the native Theban kings found themselves trapped between the Canaanite Hyksos ruling the north and the Hyksos' Nubian allies, the Kushites, to the south. After years of vassalage, Thebes gathered enough strength to challenge the Hyksos in a conflict that lasted more than 30 years, until 1555BC. Ahmose I waged a series of campaigns that permanently eradicated the Hyksos' presence in Egypt. He is considered the founder of the Eighteenth Dynasty, and the military became a central priority for his successors, who sought to expand Egypt's borders and attempted to gain mastery of the Near East.\nNew Kingdom (1549\u20131069 BC).\nThe New Kingdom pharaohs established a period of unprecedented prosperity by securing their borders and strengthening diplomatic ties with their neighbours, including the Mitanni Empire, Assyria, and Canaan. Military campaigns waged under Tuthmosis I and his grandson Tuthmosis III extended the influence of the pharaohs to the largest empire Egypt had ever seen.\nBetween their reigns, Hatshepsut, a queen who established herself as pharaoh, launched many building projects, including the restoration of temples damaged by the Hyksos, and sent trading expeditions to Punt and the Sinai. When Tuthmosis III died in 1425BC, Egypt had an empire extending from Niya in north west Syria to the Fourth Cataract of the Nile in Nubia, cementing loyalties and opening access to critical imports such as bronze and wood.\nThe New Kingdom pharaohs began a large-scale building campaign to promote the god Amun, whose growing cult was based in Karnak. They also constructed monuments to glorify their own achievements, both real and imagined. The Karnak temple is the largest Egyptian temple ever built.\nAround 1350BC, the stability of the New Kingdom was threatened when Amenhotep IV ascended the throne and instituted a series of radical and chaotic reforms. Changing his name to Akhenaten, he touted the previously obscure sun deity Aten as the supreme deity, suppressed the worship of most other deities, and moved the capital to the new city of Akhetaten (modern-day Amarna). He was devoted to his new religion and artistic style. After his death, the cult of the Aten was quickly abandoned and the traditional religious order restored. The subsequent pharaohs, Tutankhamun, Ay, and Horemheb, worked to erase all mention of Akhenaten's heresy, now known as the Amarna Period.\nAround 1279BC, Ramesses II, also known as Ramesses the Great, ascended the throne, and went on to build more temples, erect more statues and obelisks, and sire more children than any other pharaoh in history. A bold military leader, Ramesses II led his army against the Hittites in the Battle of Kadesh (in modern Syria) and, after fighting to a stalemate, finally agreed to the first recorded peace treaty, around 1258BC.\nEgypt's wealth, however, made it a tempting target for invasion, particularly by the Libyan Berbers to the west, and the Sea Peoples, a conjectured confederation of seafarers from the Aegean Sea. Initially, the military was able to repel these invasions, but Egypt eventually lost control of its remaining territories in southern Canaan, much of it falling to the Assyrians. The effects of external threats were exacerbated by internal problems such as corruption, tomb robbery, and civil unrest. After regaining their power, the high priests at the temple of Amun in Thebes accumulated vast tracts of land and wealth, and their expanded power splintered the country during the Third Intermediate Period.\nThird Intermediate Period (1069\u2013653 BC).\nFollowing the death of Ramesses XI in 1078BC, Smendes assumed authority over the northern part of Egypt, ruling from the city of Tanis. The south was effectively controlled by the High Priests of Amun at Thebes, who recognized Smendes in name only. During this time, Libyans had been settling in the western delta, and chieftains of these settlers began increasing their autonomy. Libyan princes took control of the delta under Shoshenq I in 945BC, founding the so-called Libyan or Bubastite dynasty that would rule for some 200 years. Shoshenq also gained control of southern Egypt by placing his family members in important priestly positions. Libyan control began to erode as a rival dynasty in the delta arose in Leontopolis, and Kushites threatened from the south.\nAround 727BC the Kushite king Piye invaded northward, seizing control of Thebes and eventually the Delta, which established the 25th Dynasty. During the 25th Dynasty, Pharaoh Taharqa created an empire nearly as large as the New Kingdom's. Twenty-fifth Dynasty pharaohs built, or restored, temples and monuments throughout the Nile valley, including at Memphis, Karnak, Kawa, and Jebel Barkal. During this period, the Nile valley saw the first widespread construction of pyramids (many in modern Sudan) since the Middle Kingdom.\nEgypt's far-reaching prestige declined considerably toward the end of the Third Intermediate Period. Its foreign allies had fallen into the Assyrian sphere of influence, and by 700BC war between the two states became inevitable. Between 671 and 667BC the Assyrians began the Assyrian conquest of Egypt. The reigns of both Taharqa and his successor, Tanutamun, were filled with frequent conflict with the Assyrians. Ultimately, the Assyrians pushed the Kushites back into Nubia, occupied Memphis, and sacked the temples of Thebes.\nLate Period (653\u2013332 BC).\nThe Assyrians left control of Egypt to a series of vassals who became known as the Saite kings of the Twenty-Sixth Dynasty. By 653BC, the Saite king Psamtik I was able to oust the Assyrians with the help of Greek mercenaries, who were recruited to form Egypt's first navy. Greek influence expanded greatly as the city-state of Naucratis became the home of Greeks in the Nile Delta. The Saite kings based in the new capital of Sais witnessed a brief but spirited resurgence in the economy and culture, but in 525BC, the Persian Empire, led by Cambyses II, began its conquest of Egypt, eventually defeating the pharaoh Psamtik III at the Battle of Pelusium. Cambyses II then assumed the formal title of pharaoh, but ruled Egypt from Iran, leaving Egypt under the control of a satrap. A few revolts against the Persians marked the 5th centuryBC, but Egypt was never able to overthrow the Persians until the end of the century.\nFollowing its annexation by Persia, Egypt was joined with Cyprus and Phoenicia in the sixth satrapy of the Achaemenid Persian Empire. This first period of Persian rule over Egypt, also known as the Twenty-Seventh Dynasty, ended in 402BC, when Egypt regained independence under a series of native dynasties. The last of these dynasties, the Thirtieth, proved to be the last native royal house of ancient Egypt, ending with the kingship of Nectanebo II. A brief restoration of Persian rule, sometimes known as the Thirty-First Dynasty, began in 343BC, but shortly after, in 332BC, the Persian ruler Mazaces handed Egypt over to Alexander the Great without a fight.\nPtolemaic period (332\u201330 BC).\nIn 332BC, Alexander the Great conquered Egypt with little resistance from the Persians and was welcomed by the Egyptians as a deliverer. The administration established by Alexander's successors, the Macedonian Ptolemaic Kingdom, was based on an Egyptian model and based in the new capital city of Alexandria. The city showcased the power and prestige of Hellenistic rule, and became a centre of learning and culture that included the famous Library of Alexandria and the Mouseion. The Lighthouse of Alexandria lit the way for the many ships that kept trade flowing through the city\u2014as the Ptolemies made commerce and revenue-generating enterprises, such as papyrus manufacturing, their top priority.\nHellenistic culture did not supplant native Egyptian culture, as the Ptolemies supported time-honored traditions in an effort to secure the loyalty of the populace. They built new temples in Egyptian style, supported traditional cults, and portrayed themselves as pharaohs. Some traditions merged, as Greek and Egyptian gods were syncretized into composite deities, such as Serapis, and classical Greek forms of sculpture influenced traditional Egyptian motifs. Despite their efforts to appease the Egyptians, the Ptolemies were challenged by native rebellion, bitter family rivalries, and frequent mob violence in Alexandria. In addition, as Rome relied more heavily on imports of grain from Egypt, the Romans took great interest in the political situation in the country. Continued Egyptian revolts, ambitious politicians, and powerful opponents from the Near East made this situation unstable, leading Rome to send forces to secure the country as a province of its empire.\nRoman period (30 BC \u2013 AD 642).\nEgypt became a province of the Roman Empire in 30BC, following the defeat of Mark Antony and Ptolemaic Queen Cleopatra VII by Octavian (later Emperor Augustus) in the Battle of Actium. The Romans relied heavily on grain shipments from Egypt, and the Roman army, under the control of a prefect appointed by the emperor, quelled rebellions, strictly enforced the collection of heavy taxes, and prevented attacks by bandits, which had become a notorious problem during the period. Alexandria became an increasingly important center on the trade route with the orient, as exotic luxuries were in high demand in Rome.\nAlthough the Romans had a more hostile attitude than the Greeks towards the Egyptians, some traditions such as mummification and worship of the traditional gods continued. The art of mummy portraiture flourished, and some Roman emperors had themselves depicted as pharaohs, though not to the extent that the Ptolemies had. The former lived outside Egypt and did not perform the ceremonial functions of Egyptian kingship. Local administration became Roman in style and closed to native Egyptians.\nFrom the mid-first century AD, Christianity took root in Egypt and it was originally seen as another cult that could be accepted. However, it was an uncompromising religion that sought to win converts from the pagan Egyptian and Greco-Roman religions and threatened popular religious traditions. This led to the persecution of converts to Christianity, culminating in the great purges of Diocletian starting in 303, but eventually Christianity won out. In 391, the Christian emperor Theodosius introduced legislation that banned pagan rites and closed temples. Alexandria became the scene of great anti-pagan riots with public and private religious imagery destroyed. As a consequence, Egypt's native religious culture was continually in decline. While the native population continued to speak their language, the ability to read hieroglyphic writing slowly disappeared as the role of the Egyptian temple priests and priestesses diminished. The temples themselves were sometimes converted to churches or abandoned to the desert.\nGovernment and economy.\nAdministration and commerce.\nThe pharaoh was the absolute monarch of the country and, at least in theory, wielded complete control of the land and its resources. The king was the supreme military commander and head of the government, who relied on a bureaucracy of officials to manage his affairs. In charge of the administration was his second in command, the vizier, who acted as the king's representative and coordinated land surveys, the treasury, building projects, the legal system, and the archives. At a regional level, the country was divided into as many as 42 administrative regions called nomes each governed by a nomarch, who was accountable to the vizier for his jurisdiction. The temples formed the backbone of the economy. Not only were they places of worship, but were also responsible for collecting and storing the kingdom's wealth in a system of granaries and treasuries administered by overseers, who redistributed grain and goods.\nMuch of the economy was centrally organized and strictly controlled. Although the ancient Egyptians did not use coinage until the Late period, they did use a type of money-barter system, with standard sacks of grain and the \"deben\", a weight of roughly of copper or silver, forming a common denominator. Workers were paid in grain: A simple laborer might earn &lt;templatestyles src=\"Fraction/styles.css\" /&gt;5+1\u20442 sacks or ca. of grain per month, while a foreman might earn &lt;templatestyles src=\"Fraction/styles.css\" /&gt;7+1\u20442 sacks or roughly . Prices were fixed across the country and recorded in lists to facilitate trading; for example a shirt cost five copper deben, while a cow cost 140deben. Grain could be traded for other goods, according to the fixed price list. During the fifth centuryBC coined money was introduced into Egypt from abroad. At first the coins were used as standardized pieces of precious metal rather than true money, but in the following centuries international traders came to rely on coinage.\nSocial status.\nEgyptian society was highly stratified, and social status was expressly displayed. Farmers made up the bulk of the population, but agricultural produce was owned directly by the state, temple, or noble family that owned the land. Farmers were also subject to a labor tax and were required to work on irrigation or construction projects in a corv\u00e9e system. Artists and craftsmen were of higher status than farmers, but they were also under state control, working in the shops attached to the temples and paid directly from the state treasury. Scribes and officials formed the upper class in ancient Egypt, known as the \"white kilt class\" in reference to the bleached linen garments that served as a mark of their rank. The upper class prominently displayed their social status in art and literature. Below the nobility were the priests, physicians, and engineers with specialized training in their field. It is unclear whether slavery as understood today existed in ancient Egypt; there is difference of opinions among authors.\nThe ancient Egyptians viewed men and women, including people from all social classes, as essentially equal under the law, and even the lowliest peasant was entitled to petition the vizier and his court for redress. Although slaves were mostly used as indentured servants, they were able to buy and sell their servitude, work their way to freedom or nobility, and were usually treated by doctors in the workplace. Both men and women had the right to own and sell property, make contracts, marry and divorce, receive inheritance, and pursue legal disputes in court. Married couples could own property jointly and protect themselves from divorce by agreeing to marriage contracts, which stipulated the financial obligations of the husband to his wife and children should the marriage end. Compared with their counterparts in ancient Greece, Rome, and even more modern places around the world, ancient Egyptian women had a greater range of personal choices, legal rights, and opportunities for achievement. Women such as Hatshepsut and Cleopatra VII even became pharaohs, while others wielded power as Divine Wives of Amun. Despite these freedoms, ancient Egyptian women did not often take part in official roles in the administration, aside from the royal high priestesses, apparently served only secondary roles in the temples (not much data for many dynasties), and were not so probably to be as educated as men.\nLegal system.\nThe head of the legal system was officially the pharaoh, who was responsible for enacting laws, delivering justice, and maintaining law and order, a concept the ancient Egyptians referred to as Ma'at. Although no legal codes from ancient Egypt survive, court documents show that Egyptian law was based on a common-sense view of right and wrong that emphasized reaching agreements and resolving conflicts rather than strictly adhering to a complicated set of statutes. Local councils of elders, known as \"Kenbet\" in the New Kingdom, were responsible for ruling in court cases involving small claims and minor disputes. More serious cases involving murder, major land transactions, and tomb robbery were referred to the \"Great Kenbet\", over which the vizier or pharaoh presided. Plaintiffs and defendants were expected to represent themselves and were required to swear an oath that they had told the truth. In some cases, the state took on both the role of prosecutor and judge, and it could torture the accused with beatings to obtain a confession and the names of any co-conspirators. Whether the charges were trivial or serious, court scribes documented the complaint, testimony, and verdict of the case for future reference.\nPunishment for minor crimes involved either imposition of fines, beatings, facial mutilation, or exile, depending on the severity of the offense. Serious crimes such as murder and tomb robbery were punished by execution, carried out by decapitation, drowning, or impaling the criminal on a stake. Punishment could also be extended to the criminal's family. Beginning in the New Kingdom, oracles played a major role in the legal system, dispensing justice in both civil and criminal cases. The procedure was to ask the god a \"yes\" or \"no\" question concerning the right or wrong of an issue. The god, carried by a number of priests, rendered judgement by choosing one or the other, moving forward or backward, or pointing to one of the answers written on a piece of papyrus or an ostracon.\nAgriculture.\nA combination of favorable geographical features contributed to the success of ancient Egyptian culture, the most important of which was the rich fertile soil resulting from annual inundations of the Nile River. The ancient Egyptians were thus able to produce an abundance of food, allowing the population to devote more time and resources to cultural, technological, and artistic pursuits. Land management was crucial in ancient Egypt because taxes were assessed based on the amount of land a person owned.\nFarming in Egypt was dependent on the cycle of the Nile River. The Egyptians recognized three seasons: \"Akhet\" (flooding), \"Peret\" (planting), and \"Shemu\" (harvesting). The flooding season lasted from June to September, depositing on the river's banks a layer of mineral-rich silt ideal for growing crops. After the floodwaters had receded, the growing season lasted from October to February. Farmers plowed and planted seeds in the fields, which were irrigated with ditches and canals. Egypt received little rainfall, so farmers relied on the Nile to water their crops. From March to May, farmers used sickles to harvest their crops, which were then threshed with a flail to separate the straw from the grain. Winnowing removed the chaff from the grain, and the grain was then ground into flour, brewed to make beer, or stored for later use.\nThe ancient Egyptians cultivated emmer and barley, and several other cereal grains, all of which were used to make the two main food staples of bread and beer. Flax plants, uprooted before they started flowering, were grown for the fibers of their stems. These fibers were split along their length and spun into thread, which was used to weave sheets of linen and to make clothing. Papyrus growing on the banks of the Nile River was used to make paper. Vegetables and fruits were grown in garden plots, close to habitations and on higher ground, and had to be watered by hand. Vegetables included leeks, garlic, melons, squashes, pulses, lettuce, and other crops, in addition to grapes that were made into wine.\nAnimals.\nThe Egyptians believed that a balanced relationship between people and animals was an essential element of the cosmic order; thus humans, animals and plants were believed to be members of a single whole. Animals, both domesticated and wild, were therefore a critical source of spirituality, companionship, and sustenance to the ancient Egyptians. Cattle were the most important livestock; the administration collected taxes on livestock in regular censuses, and the size of a herd reflected the prestige and importance of the estate or temple that owned them. In addition to cattle, the ancient Egyptians kept sheep, goats, and pigs. Poultry, such as ducks, geese, and pigeons, were captured in nets and bred on farms, where they were force-fed with dough to fatten them. The Nile provided a plentiful source of fish. Bees were also domesticated from at least the Old Kingdom, and provided both honey and wax.\nThe ancient Egyptians used donkeys and oxen as beasts of burden, and they were responsible for plowing the fields and trampling seed into the soil. The slaughter of a fattened ox was also a central part of an offering ritual. Horses were introduced by the Hyksos in the Second Intermediate Period. Camels, although known from the New Kingdom, were not used as beasts of burden until the Late Period. There is also evidence to suggest that elephants were briefly used in the Late Period but largely abandoned due to lack of grazing land. Cats, dogs, and monkeys were common family pets, while more exotic pets imported from the heart of Africa, such as Sub-Saharan African lions, were reserved for royalty. Herodotus observed that the Egyptians were the only people to keep their animals with them in their houses. During the Late Period, the worship of the gods in their animal form was extremely popular, such as the cat goddess Bastet and the ibis god Thoth, and these animals were kept in large numbers for the purpose of ritual sacrifice.\nNatural resources.\nEgypt is rich in building and decorative stone, copper and lead ores, gold, and semiprecious stones. These natural resources allowed the ancient Egyptians to build monuments, sculpt statues, make tools, and fashion jewelry. Embalmers used salts from the Wadi Natrun for mummification, which also provided the gypsum needed to make plaster. Ore-bearing rock formations were found in distant, inhospitable wadis in the Eastern Desert and the Sinai, requiring large, state-controlled expeditions to obtain natural resources found there. There were extensive gold mines in Nubia, and one of the first maps known is of a gold mine in this region. The Wadi Hammamat was a notable source of granite, greywacke, and gold. Flint was the first mineral collected and used to make tools, and flint handaxes are the earliest pieces of evidence of habitation in the Nile valley. Nodules of the mineral were carefully flaked to make blades and arrowheads of moderate hardness and durability even after copper was adopted for this purpose. Ancient Egyptians were among the first to use minerals such as sulfur as cosmetic substances.\nThe Egyptians worked deposits of the lead ore galena at Gebel Rosas to make net sinkers, plumb bobs, and small figurines. Copper was the most important metal for toolmaking in ancient Egypt and was smelted in furnaces from malachite ore mined in the Sinai. Workers collected gold by washing the nuggets out of sediment in alluvial deposits, or by the more labor-intensive process of grinding and washing gold-bearing quartzite. Iron deposits found in upper Egypt were used in the Late Period. High-quality building stones were abundant in Egypt; the ancient Egyptians quarried limestone all along the Nile valley, granite from Aswan, and basalt and sandstone from the wadis of the Eastern Desert. Deposits of decorative stones such as porphyry, greywacke, alabaster, and carnelian dotted the Eastern Desert and were collected even before the First Dynasty. In the Ptolemaic and Roman Periods, miners worked deposits of emeralds in Wadi Sikait and amethyst in Wadi el-Hudi.\nTrade.\nThe ancient Egyptians engaged in trade with their foreign neighbors to obtain rare, exotic goods not found in Egypt. In the Predynastic Period, they established trade with Nubia to obtain gold and incense. They also established trade with Palestine, as evidenced by Palestinian-style oil jugs found in the burials of the First Dynasty pharaohs. An Egyptian colony stationed in southern Canaan dates to slightly before the First Dynasty. Tell es-Sakan in present-day Gaza was established as an Egyptian settlement in the late 4th millennium\u00a0BC, and is theorised to have been the main Egyptian colonial site in the region. Narmer had Egyptian pottery produced in Canaan and exported back to Egypt.\nBy the Second Dynasty at latest, ancient Egyptian trade with Byblos yielded a critical source of quality timber not found in Egypt. By the Fifth Dynasty, trade with Punt provided gold, aromatic resins, ebony, ivory, and wild animals such as monkeys and baboons. Egypt relied on trade with Anatolia for essential quantities of tin as well as supplementary supplies of copper, both metals being necessary for the manufacture of bronze. The ancient Egyptians prized the blue stone lapis lazuli, which had to be imported from far-away Afghanistan. Egypt's Mediterranean trade partners also included Greece and Crete, which provided, among other goods, supplies of olive oil.\nLanguage.\nHistorical development.\nThe Egyptian language is a northern Afro-Asiatic language closely related to the Berber and Semitic languages. It has the longest known history of any language having been written from c.\u20093200BC to the Middle Ages and remaining as a spoken language for longer. The phases of ancient Egyptian are Old Egyptian, Middle Egyptian (Classical Egyptian), Late Egyptian, Demotic and Coptic. Egyptian writings do not show dialect differences before Coptic, but it was probably spoken in regional dialects around Memphis and later Thebes.\nAncient Egyptian was a synthetic language, but it became more analytic later on. Late Egyptian developed prefixal definite and indefinite articles, which replaced the older inflectional suffixes. There was a change from the older verb\u2013subject\u2013object word order to subject\u2013verb\u2013object. The Egyptian hieroglyphic, hieratic, and demotic scripts were eventually replaced by the more phonetic Coptic alphabet. Coptic is still used in the liturgy of the Egyptian Orthodox Church, and traces of it are found in modern Egyptian Arabic.\nSounds and grammar.\nAncient Egyptian has 25 consonants similar to those of other Afro-Asiatic languages. These include pharyngeal and emphatic consonants, voiced and voiceless stops, voiceless fricatives and voiced and voiceless affricates. It has three long and three short vowels, which expanded in Late Egyptian to about nine. The basic word in Egyptian, similar to Semitic and Berber, is a triliteral or biliteral root of consonants and semiconsonants. Suffixes are added to form words. The verb conjugation corresponds to the person. For example, the triconsonantal skeleton is the semantic core of the word 'hear'; its basic conjugation is ', 'he hears'. If the subject is a noun, suffixes are not added to the verb: ', 'the woman hears'.\nAdjectives are derived from nouns through a process that Egyptologists call \"nisbation\" because of its similarity with Arabic. The word order is predicate\u2013subject in verbal and adjectival sentences, and subject\u2013predicate in nominal and adverbial sentences. The subject can be moved to the beginning of sentences if it is long and is followed by a resumptive pronoun. Verbs and nouns are negated by the particle \"n\", but \"nn\" is used for adverbial and adjectival sentences. Stress falls on the ultimate or penultimate syllable, which can be open (CV) or closed (CVC).\nWriting.\nHieroglyphic writing dates from c.\u20093000BC, and is composed of hundreds of symbols. A hieroglyph can represent a word, a sound, or a silent determinative; and the same symbol can serve different purposes in different contexts. Hieroglyphs were a formal script, used on stone monuments and in tombs, that could be as detailed as individual works of art. In day-to-day writing, scribes used a cursive form of writing, called hieratic, which was quicker and easier. While formal hieroglyphs may be read in rows or columns in either direction (though typically written from right to left), hieratic was always written from right to left, usually in horizontal rows. A new form of writing, Demotic, became the prevalent writing style, and it is this form of writing\u2014along with formal hieroglyphs\u2014that accompany the Greek text on the Rosetta Stone.\nAround the first century AD, the Coptic alphabet started to be used alongside the Demotic script. Coptic is a modified Greek alphabet with the addition of some Demotic signs. Although formal hieroglyphs were used in a ceremonial role until the fourth century, towards the end only a small handful of priests could still read them. As the traditional religious establishments were disbanded, knowledge of hieroglyphic writing was mostly lost. Attempts to decipher them date to the Byzantine and Islamic periods in Egypt, but only in the 1820s, after the discovery of the Rosetta Stone and years of research by Thomas Young and Jean-Fran\u00e7ois Champollion, were hieroglyphs substantially deciphered.\nLiterature.\nWriting first appeared in association with kingship on labels and tags for items found in royal tombs. It was primarily an occupation of the scribes, who worked out of the \"Per Ankh\" institution or the House of Life. The latter comprised offices, libraries (called House of Books), laboratories and observatories. Some of the best-known pieces of ancient Egyptian literature, such as the Pyramid and Coffin Texts, were written in Classical Egyptian, which continued to be the language of writing until about 1300BC. Late Egyptian was spoken from the New Kingdom onward and is represented in Ramesside administrative documents, love poetry and tales, as well as in Demotic and Coptic texts. During this period, the tradition of writing had evolved into the tomb autobiography, such as those of Harkhuf and Weni. The genre known as \"Sebayt\" ('instructions') was developed to communicate teachings and guidance from famous nobles; the Ipuwer papyrus, a poem of lamentations describing natural disasters and social upheaval, is a famous example.\nThe \"Story of Sinuhe\", written in Middle Egyptian, might be the classic of Egyptian literature. Also written at this time was the Westcar Papyrus, a set of stories told to Khufu by his sons relating the marvels performed by priests. The Instruction of Amenemope is considered a masterpiece of Near Eastern literature. Towards the end of the New Kingdom, the vernacular language was more often employed to write popular pieces such as the Story of Wenamun and the Instruction of Any. The former tells the story of a noble who is robbed on his way to buy cedar from Lebanon and of his struggle to return to Egypt. From about 700BC, narrative stories and instructions, such as the popular Instructions of Onchsheshonqy, as well as personal and business documents were written in the demotic script and phase of Egyptian. Many stories written in demotic during the Greco-Roman period were set in previous historical eras, when Egypt was an independent nation ruled by great pharaohs such as Ramesses II.\nCulture.\nDaily life.\nMost ancient Egyptians were farmers tied to the land. Their dwellings were restricted to immediate family members, and were constructed of mudbrick designed to remain cool in the heat of the day. Each home had a kitchen with an open roof, which contained a grindstone for milling grain and a small oven for baking the bread. Ceramics served as household wares for the storage, preparation, transport, and consumption of food, drink, and raw materials. Walls were painted white and could be covered with dyed linen wall hangings. Floors were covered with reed mats, while wooden stools, beds raised from the floor and individual tables comprised the furniture.\nThe ancient Egyptians placed a great value on hygiene and appearance. Most bathed in the Nile and used a pasty soap made from animal fat and chalk. Men shaved their entire bodies for cleanliness; perfumes and aromatic ointments covered bad odors and soothed skin. Clothing was made from simple linen sheets that were bleached white, and both men and women of the upper classes wore wigs, jewelry, and cosmetics. Children went without clothing until maturity, at about age 12, and at this age males were circumcised and had their heads shaved. Mothers were responsible for taking care of the children, while the father provided the family's income.\nMusic and dance were popular entertainments for those who could afford them. Early instruments included flutes and harps, while instruments similar to trumpets, oboes, and pipes developed later and became popular. In the New Kingdom, the Egyptians played on bells, cymbals, tambourines, drums, and imported lutes and lyres from Asia. The sistrum was a rattle-like musical instrument that was especially important in religious ceremonies.\nThe ancient Egyptians enjoyed a variety of leisure activities, including games and music. Senet, a board game where pieces moved according to random chance, was particularly popular from the earliest times; another similar game was mehen, which had a circular gaming board. \"Hounds and Jackals\" also known as 58 holes is another example of board games played in ancient Egypt. The first complete set of this game was discovered from a Theban tomb of the Egyptian pharaoh Amenemhat IV that dates to the 13th Dynasty. Juggling and ball games were popular with children, and wrestling is also documented in a tomb at Beni Hasan. The wealthy members of ancient Egyptian society enjoyed hunting, fishing, and boating as well.\nThe excavation of the workers' village of Deir el-Medina has resulted in one of the most thoroughly documented accounts of community life in the ancient world, which spans almost four hundred years. There is no comparable site in which the organization, social interactions, and working and living conditions of a community have been studied in such detail.\nCuisine.\nEgyptian cuisine remained remarkably stable over time; indeed, the cuisine of modern Egypt retains some striking similarities to the cuisine of the ancients. The staple diet consisted of bread and beer, supplemented with vegetables such as onions and garlic, and fruit such as dates and figs. Wine and meat were enjoyed by all on feast days while the upper classes indulged on a more regular basis. Fish, meat, and fowl could be salted or dried, and could be cooked in stews or roasted on a grill.\nArchitecture.\nThe architecture of ancient Egypt includes some of the most famous structures in the world: the Great Pyramids of Giza and the temples at Thebes. Building projects were organized and funded by the state for religious and commemorative purposes, but also to reinforce the wide-ranging power of the pharaoh. The ancient Egyptians were skilled builders; using only simple but effective tools and sighting instruments, architects could build large stone structures with great accuracy and precision that is still envied today.\nThe domestic dwellings of elite and ordinary Egyptians alike were constructed from perishable materials such as mudbricks and wood, and have not survived. Peasants lived in simple homes, while the palaces of the elite and the pharaoh were more elaborate structures. A few surviving New Kingdom palaces, such as those in Malkata and Amarna, show richly decorated walls and floors with scenes of people, birds, water pools, deities and geometric designs. Important structures such as temples and tombs that were intended to last forever were constructed of stone instead of mudbricks. The architectural elements used in the world's first large-scale stone building, Djoser's mortuary complex, include post and lintel supports in the papyrus and lotus motif.\nThe earliest preserved ancient Egyptian temples, such as those at Giza, consist of single, enclosed halls with roof slabs supported by columns. In the New Kingdom, architects added the pylon, the open courtyard, and the enclosed hypostyle hall to the front of the temple's sanctuary, a style that was standard until the Greco-Roman period. The earliest and most popular tomb architecture in the Old Kingdom was the mastaba, a flat-roofed rectangular structure of mudbrick or stone built over an underground burial chamber. The step pyramid of Djoser is a series of stone mastabas stacked on top of each other. Pyramids were built during the Old and Middle Kingdoms, but most later rulers abandoned them in favor of less conspicuous rock-cut tombs. The use of the pyramid form continued in private tomb chapels of the New Kingdom and in the royal pyramids of Nubia.\nArt.\nThe ancient Egyptians produced art to serve functional purposes. For over 3500 years, artists adhered to artistic forms and iconography that were developed during the Old Kingdom, following a strict set of principles that resisted foreign influence and internal change. These artistic standards\u2014simple lines, shapes, and flat areas of color combined with the characteristic flat projection of figures with no indication of spatial depth\u2014created a sense of order and balance within a composition. Images and text were intimately interwoven on tomb and temple walls, coffins, stelae, and even statues. The Narmer Palette, for example, displays figures that can also be read as hieroglyphs. Because of the rigid rules that governed its highly stylized and symbolic appearance, ancient Egyptian art served its political and religious purposes with precision and clarity.\nAncient Egyptian artisans used stone as a medium for carving statues and fine reliefs, but used wood as a cheap and easily carved substitute. Paints were obtained from minerals such as iron ores (red and yellow ochres), copper ores (blue and green), soot or charcoal (black), and limestone (white). Paints could be mixed with gum arabic as a binder and pressed into cakes, which could be moistened with water when needed.\nPharaohs used reliefs to record victories in battle, royal decrees, and religious scenes. Common citizens had access to pieces of funerary art, such as shabti statues and books of the dead, which they believed would protect them in the afterlife. During the Middle Kingdom, wooden or clay models depicting scenes from everyday life became popular additions to the tomb. In an attempt to duplicate the activities of the living in the afterlife, these models show laborers, houses, boats, and even military formations that are scale representations of the ideal ancient Egyptian afterlife.\nDespite the homogeneity of ancient Egyptian art, the styles of particular times and places sometimes reflected changing cultural or political attitudes. After the invasion of the Hyksos in the Second Intermediate Period, Minoan-style frescoes were found in Avaris. The most striking example of a politically driven change in artistic forms comes from the Amarna Period, where figures were radically altered to conform to Akhenaten's revolutionary religious ideas. This style, known as Amarna art, was quickly abandoned after Akhenaten's death and replaced by the traditional forms.\nReligious beliefs.\nBeliefs in the divine and in the afterlife were ingrained in ancient Egyptian civilization from its inception; pharaonic rule was based on the divine right of kings. The Egyptian pantheon was populated by gods who had supernatural powers and were called on for help or protection. However, the gods were not always viewed as benevolent, and Egyptians believed they had to be appeased with offerings and prayers. The structure of this pantheon changed continually as new deities were promoted in the hierarchy, but priests made no effort to organize the diverse and sometimes conflicting myths and stories into a coherent system. These various conceptions of divinity were not considered contradictory but rather layers in the multiple facets of reality.\nGods were worshiped in cult temples administered by priests acting on the king's behalf. At the center of the temple was the cult statue in a shrine. Temples were not places of public worship or congregation, and only on select feast days and celebrations was a shrine carrying the statue of the god brought out for public worship. Normally, the god's domain was sealed off from the outside world and was only accessible to temple officials. Common citizens could worship private statues in their homes, and amulets offered protection against the forces of chaos. After the New Kingdom, the pharaoh's role as a spiritual intermediary was de-emphasized as religious customs shifted to direct worship of the gods. As a result, priests developed a system of oracles to communicate the will of the gods directly to the people.\nThe Egyptians believed that every human being was composed of physical and spiritual parts or \"aspects\". In addition to the body, each person had a \"\u0161wt\" (shadow), a \"ba\" (personality or soul), a \"ka\" (life-force), and a \"name\". The heart, rather than the brain, was considered the seat of thoughts and emotions. After death, the spiritual aspects were released from the body and could move at will, but they required the physical remains (or a substitute, such as a statue) as a permanent home. The ultimate goal of the deceased was to rejoin his \"ka\" and \"ba\" and become one of the \"blessed dead\", living on as an \"akh\", or \"effective one\". For this to happen, the deceased had to be judged worthy in a trial, in which the heart was weighed against a \"feather of truth\". If deemed worthy, the deceased could continue their existence on earth in spiritual form. If they were not deemed worthy, their heart was eaten by Ammit the Devourer and they were erased from the Universe.\nBurial customs.\nThe ancient Egyptians maintained an elaborate set of burial customs that they believed were necessary to ensure immortality after death. These customs involved preserving the body by mummification, performing burial ceremonies, and interring with the body goods the deceased would use in the afterlife. Before the Old Kingdom, bodies buried in desert pits were naturally preserved by desiccation. The arid, desert conditions were a boon throughout the history of ancient Egypt for burials of the poor, who could not afford the elaborate burial preparations available to the elite. Wealthier Egyptians began to bury their dead in stone tombs and use artificial mummification, which involved removing the internal organs, wrapping the body in linen, and burying it in a rectangular stone sarcophagus or wooden coffin. Beginning in the Fourth Dynasty, some parts were preserved separately in canopic jars.\nBy the New Kingdom, the ancient Egyptians had perfected the art of mummification; the best technique took 70 days and involved removing the internal organs, removing the brain through the nose, and desiccating the body in a mixture of salts called natron. The body was then wrapped in linen with protective amulets inserted between layers and placed in a decorated anthropoid coffin. Mummies of the Late Period were also placed in painted cartonnage mummy cases. Actual preservation practices declined during the Ptolemaic and Roman eras, while greater emphasis was placed on the outer appearance of the mummy, which was decorated.\nWealthy Egyptians were buried with larger quantities of luxury items, but all burials, regardless of social status, included goods for the deceased. Funerary texts were often included in the grave, and, beginning in the New Kingdom, so were shabti statues that were believed to perform manual labor for them in the afterlife. Rituals in which the deceased was magically re-animated accompanied burials. After burial, living relatives were expected to occasionally bring food to the tomb and recite prayers on behalf of the deceased.\nMilitary.\nThe ancient Egyptian military was responsible for defending Egypt against foreign invasion, and for maintaining Egypt's domination in the ancient Near East. The military protected mining expeditions to the Sinai during the Old Kingdom and fought civil wars during the First and Second Intermediate Periods. The military was responsible for maintaining fortifications along important trade routes, such as those found at the city of Buhen on the way to Nubia. Forts also were constructed to serve as military bases, such as the fortress at Sile, which was a base of operations for expeditions to the Levant. In the New Kingdom, a series of pharaohs used the standing Egyptian army to attack and conquer Kush and parts of the Levant.\nTypical military equipment included bows and arrows, spears, and round-topped shields made by stretching animal skin over a wooden frame. In the New Kingdom, the military began using chariots that had earlier been introduced by the Hyksos invaders. Weapons and armor continued to improve after the adoption of bronze: shields were now made from solid wood with a bronze buckle, spears were tipped with a bronze point, and the khopesh was adopted from Asiatic soldiers. The pharaoh was usually depicted in art and literature riding at the head of the army; it has been suggested that at least a few pharaohs, such as Seqenenre Tao II and his sons, did do so. However, it has also been argued that \"kings of this period did not personally act as frontline war leaders, fighting alongside their troops\". Soldiers were recruited from the general population, but during, and especially after, the New Kingdom, mercenaries from Nubia, Kush, and Libya were hired to fight for Egypt.\nTechnology, medicine and mathematics.\nTechnology.\nIn technology, medicine, and mathematics, ancient Egypt achieved a relatively high standard of productivity and sophistication. Traditional empiricism, as evidenced by the Edwin Smith and Ebers papyri (c.\u20091600 BC), is first credited to Egypt. The Egyptians created their own alphabet and decimal system.\nFaience and glass.\nEven before the Old Kingdom, the ancient Egyptians had developed a glassy material known as faience, which they treated as a type of artificial semi-precious stone. Faience is a non-clay ceramic made of silica, small amounts of lime and soda, and a colorant, typically copper. The material was used to make beads, tiles, figurines, and small wares. Several methods can be used to create faience, but typically production involved application of the powdered materials in the form of a paste over a clay core, which was then fired. By a related technique, the ancient Egyptians produced a pigment known as Egyptian blue, also called blue frit, which is produced by fusing (or sintering) silica, copper, lime, and an alkali such as natron. The product can be ground up and used as a pigment.\nThe ancient Egyptians could fabricate a wide variety of objects from glass with great skill, but it is not clear whether they developed the process independently. It is also unclear whether they made their own raw glass or merely imported pre-made ingots, which they melted and finished. However, they did have technical expertise in making objects, as well as adding trace elements to control the color of the finished glass. A range of colors could be produced, including yellow, red, green, blue, purple, and white, and the glass could be made either transparent or opaque.\nMedicine.\nThe medical problems of the ancient Egyptians stemmed directly from their environment. Living and working close to the Nile brought hazards from malaria and debilitating schistosomiasis parasites, which caused liver and intestinal damage. Dangerous wildlife such as crocodiles and hippos were also a common threat. The lifelong labors of farming and building put stress on the spine and joints, and traumatic injuries from construction and warfare all took a significant toll on the body. The grit and sand from stone-ground flour abraded teeth, leaving them susceptible to abscesses (though caries were rare).\nThe diets of the wealthy were rich in sugars, which promoted periodontal disease. Despite the flattering physiques portrayed on tomb walls, the overweight mummies of many of the upper class show the effects of a life of overindulgence. Adult life expectancy was about 35 for men and 30 for women, but reaching adulthood was difficult as about one-third of the population died in infancy.\nAncient Egyptian physicians were renowned in the ancient Near East for their healing skills, and some, such as Imhotep, remained famous long after their deaths. Herodotus remarked that there was a high degree of specialization among Egyptian physicians, with some treating only the head or the stomach, while others were eye-doctors and dentists. Training of physicians took place at the \"Per Ankh\" or \"House of Life\" institution, most notably those headquartered in Per-Bastet during the New Kingdom and at Abydos and Sa\u00efs in the Late period. Medical papyri show empirical knowledge of anatomy, injuries, and practical treatments.\nWounds were treated by bandaging with raw meat, white linen, sutures, nets, pads, and swabs soaked with honey to prevent infection, while opium, thyme, and belladona were used to relieve pain. The earliest records of burn treatment describe burn dressings that use the milk from mothers of male babies. Prayers were made to the goddess Isis. Moldy bread, honey, and copper salts were also used to prevent infection from dirt in burns. Garlic and onions were used regularly to promote good health and were thought to relieve asthma symptoms. Ancient Egyptian surgeons stitched wounds, set broken bones, and amputated diseased limbs, but they recognized that some injuries were so serious that they could only make the patient comfortable until death occurred.\nMaritime technology.\nEarly Egyptians knew how to assemble planks of wood into a ship hull and had mastered advanced forms of shipbuilding as early as 3000BC. The Archaeological Institute of America reports that the oldest planked ships known are the Abydos boats. A group of 14 discovered ships in Abydos were constructed of wooden planks \"sewn\" together. Discovered by Egyptologist David O'Connor of New York University, woven straps were found to have been used to lash the planks together, and reeds or grass stuffed between the planks helped to seal the seams. Because the ships are all buried together and near a mortuary belonging to Pharaoh Khasekhemwy, originally they were all thought to have belonged to him, but one of the 14 ships dates to 3000BC, and the associated pottery jars buried with the vessels also suggest earlier dating. The ship dating to 3000BC was long and is now thought to perhaps have belonged to an earlier pharaoh, perhaps one as early as Hor-Aha.\nEarly Egyptians also knew how to assemble planks of wood with treenails to fasten them together, using pitch for caulking the seams. The \"Khufu ship\", a vessel sealed into a pit in the Giza pyramid complex at the foot of the Great Pyramid of Giza in the Fourth Dynasty around 2500BC, is a full-size surviving example that may have filled the symbolic function of a solar barque. Early Egyptians also knew how to fasten the planks of this ship together with mortise and tenon joints.\nLarge seagoing ships are known to have been heavily used by the Egyptians in their trade with the city states of the eastern Mediterranean, especially Byblos (on the coast of modern-day Lebanon), and in several expeditions down the Red Sea to the Land of Punt. In fact one of the earliest Egyptian words for a seagoing ship is a \"Byblos Ship\", which originally defined a class of Egyptian seagoing ships used on the Byblos run; however, by the end of the Old Kingdom, the term had come to include large seagoing ships, whatever their destination.\nIn 1977, an ancient north\u2013south canal was discovered extending from Lake Timsah to the Ballah Lakes. It was dated to the Middle Kingdom of Egypt by extrapolating dates of ancient sites constructed along its course.\nIn 2011, archaeologists from Italy, the United States, and Egypt, excavating a dried-up lagoon known as Mersa Gawasis, unearthed traces of an ancient harbor that once launched early voyages, such as Hatshepsut's Punt, expedition onto the open ocean. Some of the site's most evocative evidence for the ancient Egyptians' seafaring prowess include large ship timbers and hundreds of feet of ropes, made from papyrus, coiled in huge bundles. In 2013, a team of Franco-Egyptian archaeologists discovered what is believed to be the world's oldest port, dating back about 4500 years, from the time of King Khufu, on the Red Sea coast, near Wadi el-Jarf (about 110 miles south of Suez).\nMathematics.\nThe earliest attested examples of mathematical calculations date to the predynastic Naqada period, and show a fully developed numeral system. The importance of mathematics to an educated Egyptian is suggested by a New Kingdom fictional letter in which the writer proposes a scholarly competition between himself and another scribe regarding everyday calculation tasks such as accounting of land, labor, and grain. Texts such as the Rhind Mathematical Papyrus and the Moscow Mathematical Papyrus show that the ancient Egyptians could perform the four basic mathematical operations\u2014addition, subtraction, multiplication, and division\u2014use fractions, calculate the areas of rectangles, triangles, and circles and compute the volumes of boxes, columns and pyramids. They understood basic concepts of algebra and geometry, and could solve systems of equations.\nMathematical notation was decimal, and based on hieroglyphic signs for each power of ten up to one million. Each of these could be written as many times as necessary to add up to the desired number; so to write the number eighty or eight hundred, the symbol for ten or one hundred was written eight times respectively. Because their methods of calculation could not handle most fractions with a numerator greater than one, they had to write fractions as the sum of several fractions. For example, they resolved the fraction \"two-fifths\" into the sum of \"one-third\" + \"one-fifteenth\". Standard tables of values facilitated this. Some common fractions, however, were written with a special glyph\u2014the equivalent of the modern two-thirds is shown on the right.\nAncient Egyptian mathematicians knew the Pythagorean theorem as an empirical formula. They were aware, for example, that a triangle had a right angle opposite the hypotenuse when its sides were in a 3\u20134\u20135 ratio. They were able to estimate the area of a circle by subtracting one-ninth from its diameter and squaring the result:\nArea \u2248 [(&lt;templatestyles src=\"Fraction/styles.css\" /&gt;8\u20449)\"D\"]2 = (&lt;templatestyles src=\"Fraction/styles.css\" /&gt;256\u204481)\"r\"2 \u2248 3.16\"r\"2,\na reasonable approximation of the formula \u03c0\"r\"2.\nPopulation.\nEstimates of the size of the population range from 1\u20131.5 million in the 3rd millennium BC to possibly 2\u20133 million by the 1st millennium BC, before growing significantly towards the end of that millennium.\nHistorical scholarship has generally regarded the peopling of the Egyptian Nile Valley from archaeological and biological data, to be the result of interaction between coastal northern Africans, \"neolithic\" Saharans, Nilotic hunters, and riverine proto-Nubians with some influence and migration from the Levant.\nIn 2025, the UNESCO International Scientific Committee members for drafting the General History of Africa Volumes IX-XI reached the view that Egypt had African and Eurasian populations, with Upper Egypt now repositioned as the origin of pharaonic unification, with close archaeological, genetic, linguistic and biological anthropological affinities identified between the Upper Egyptian populations and Sub-Saharan groups.\nArchaeogenetics.\nAccording to historian William Stiebling and archaeologist Susan N. Helft, conflicting DNA analysis on recent genetic samples such as the Amarna royal mummies has led to a lack of consensus on the genetic makeup of the ancient Egyptians and their geographic origins.\nThe genetic history of Ancient Egypt remains a developing field, and is relevant for the understanding of population demographic events connecting Africa and Eurasia. To date, the amount of genome-wide aDNA analyses on ancient specimens from Egypt and Sudan remain scarce, although studies on uniparental haplogroups in ancient individuals have been carried out several times, pointing broadly to affinities with other African and Eurasian groups.\nThe currently most advanced full genome analyses was published in a 2025 article by the scientific journal Nature, a whole-genome genetic study of an Old Kingdom adult male Egyptian of relatively high-status, codenamed \"Old Kingdom individual (NUE001)\", who was radiocarbon-dated to 2855\u20132570 BC, with funerary practices archeologically attributed to the Third and Fourth Dynasty, excavated in Nuwayrat (Nuerat, \u0646\u0648\u064a\u0631\u0627\u062a), in a cliff 265\u2009km south of Cairo. Before this study, whole-genome sequencing of ancient Egyptians from the early periods of Egyptian Dynastic history had not yet been accomplished, mainly because of the problematic DNA preservation conditions in Egypt. The corpse had been placed intact in a large circular clay pot without embalming, and then installed inside a cliff tomb, which accounts for the comparatively good level of conservation of the skeleton and its DNA. Most of his genome was found to be associated with North African Neolithic ancestry, but about 20% of his genetic ancestry could be sourced to the eastern Fertile Crescent, including Mesopotamia. Overall, the 2025 study \"provides direct evidence of genetic ancestry related to the eastern Fertile Crescent in ancient Egypt\". This genetic connection suggests that there had been ancient migration flows from the eastern Fertile Crescent to Egypt, in addition to the exchanges of objects and imagery (domesticated animals and plants, writing systems...) already observed. This suggests a pattern of wide cultural and demographic expansion from the Mesopotamian region, which affected both Anatolia and Egypt during this period. The authors acknowledged some limitations of the study, such as the results deriving from one single Egyptian genome and known limitations predicting specific phenotypic traits in understudied populations.\nAn earlier partial genomic analyses had been made on much later specimens recovered from the Nile River Valley, Abusir el-Meleq, Egypt, dating from the 787 BC-23 AD time period. Two of the individuals were dated to the Pre-Ptolemaic Period (New Kingdom to Late Period), and one individual to the Ptolemaic Period. These results point to a genetic continuity of Ancient Egyptians with modern Egyptians. The results further point to a close genetic affinity between ancient Egyptians and Middle Eastern populations, especially ancient groups from the Levant.\nAncient Egyptians also displayed affinities to Nubians to the south of Egypt, in modern-day Sudan. Archaeological and historical evidence support interactions between Egyptian and Nubian populations more than 5000 years ago, with socio-political dynamics between Egyptians and Nubians ranging from peaceful coexistence to variably successful attempts of conquest. A study on sixty-six ancient Nubian individuals revealed significant contact with ancient Egyptians, characterized by the presence of c.\u200957% Neolithic/Bronze Age Levantine ancestry in these individuals. Such geneflow of Levantine-like ancestry corresponds with archaeological and botanic evidence, pointing to a Neolithic movement around 7,000 years ago.\nModern Egyptians, like modern Nubians, also underwent subsequent admixture events, contributing both \"Sub-Saharan\" African-like and West Asian-like ancestries, since the Roman period, with significance on the African Slave Trade and the Spread of Islam.\nGenetic analysis of a modern Upper Egyptian population in Adaima by Eric Crub\u00e9zy had identified genetic markers common across Africa, with 71% of the Adaima samples carrying E1b1 haplogroup and 3% carrying the L0f mitochondrial haplogroup. A secondary review, published in UNESCO General History of Africa Volume IX, in 2025 noted the results were preliminary and need to be confirmed by other laboratories with new sequencing methods. This was supported by an anthropological study which found the notable presence of dental markers, characteristic of Khoisan people, in a predynastic-era cemetery at Ada\u00efma. The genetic marker E1b1 was identified in a number of genetic studies to have wide distribution across Egypt, with \"P2/215/M35.1 (E1b1b), for short M35, likely also originated in eastern tropical Africa, and is predominantly distributed in an arc from the Horn of Africa up through Egypt\". Multiple STR analyses of the Amarna royal mummies (including Rameses III, Tutankhamun and Amenhotep III) were deployed to estimate their ethnicity have found they had strong affinities with modern Sub-Saharan populations. Nonetheless, these forms of analysis were not exhaustive as only 8 of the 13 CODIS markets were used. \nSome scholars, such as Christopher Ehret, caution that a wider sampling area is needed and argue that the current data is inconclusive on the origin of ancient Egyptians. They also point out issues with the previously used methodology such as the sampling size, comparative approach and a \"biased interpretation\" of the genetic data. They argue in favor for a link between Ancient Egypt and the northern Horn of Africa. This latter view has been attributed to the corresponding archaeological, genetic, linguistic and biological anthropological sources of evidence which broadly indicate that the earliest Egyptians and Nubians were the descendants of populations in northeast Africa.\nLegacy.\nThe culture and monuments of ancient Egypt have left a lasting legacy on the world. Egyptian civilization significantly influenced the Kingdom of Kush and Mero\u00eb with both adopting Egyptian religious and architectural norms (hundreds of pyramids (6\u201330 meters high) were built in Egypt/Sudan), as well as using Egyptian writing as the basis of the Meroitic script. Meroitic is the oldest written language in Africa, other than Egyptian, and was used from the 2nd century BC until the early 5th century AD. The cult of the goddess Isis, for example, became popular in the Roman Empire, as obelisks and other relics were transported back to Rome. The Romans also imported building materials from Egypt to erect Egyptian-style structures. Early historians such as Herodotus, Strabo, and Diodorus Siculus studied and wrote about the land, which Romans came to view as a place of mystery.\nDuring the Middle Ages and the Renaissance, Egyptian pagan culture was in decline after the rise of Christianity and later Islam, but interest in Egyptian antiquity continued in the writings of medieval scholars such as Dhul-Nun al-Misri and al-Maqrizi. In the seventeenth and eighteenth centuries, European travelers and tourists brought back antiquities and wrote stories of their journeys, leading to a wave of Egyptomania across Europe, as evident in symbolism such as the Eye of Providence and the Great Seal of the United States. This renewed interest sent collectors to Egypt, who took, purchased, or were given many important antiquities. Napoleon arranged the first studies in Egyptology when he brought some 150 scientists and artists to study and document Egypt's natural history, which was published in the \"Description de l'\u00c9gypte\".\nIn the 20th century, the Egyptian Government and archaeologists alike recognized the importance of cultural respect and integrity in excavations. Since the 2010s, the Ministry of Tourism and Antiquities has overseen excavations and the recovery of artifacts.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nWorks cited.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "875", "revid": "45417033", "url": "https://en.wikipedia.org/wiki?curid=875", "title": "Analog Brothers", "text": "Experimental hip hop band\nAnalog Brothers were an experimental hip hop band featuring Tracy \"Ice-T\" Marrow (Ice Oscillator) on keyboards, drums and vocals, Keith \"Kool Keith\" Thornton (Keith Korg) on bass, strings and vocals, Marc Live (Marc Moog) on drums, violins and vocals, Christopher \"Black Silver\" Rodgers (Silver Synth) on synthesizer, lazar bell and vocals, and Rex Colonel \"Pimpin' Rex\" Doby Jr. (Rex Roland JX3P) on keyboards, vocals and production. \nMusic.\nThe group's only studio album \"Pimp to Eat\" featured guest appearances by various members of Rhyme Syndicate, Odd Oberheim, Jacky Jasper (who appears as Jacky Jasper on the song \"We Sleep Days\" and H-Bomb on \"War\"), D.J. Cisco from S.M., Synth-A-Size Sisters and Teflon.\nLegacy.\nWhile the group only recorded one album together as the Analog Brothers, a few bootlegs of its live concert performances, including freestyles with original lyrics, have occasionally surfaced online. After \"Pimp to Eat\", the Analog Brothers continued performing together in various line ups. Kool Keith and Marc Live joined with Jacky Jasper to release two albums as KHM. Marc Live rapped with Ice-T's group SMG. Marc also formed a group with Black Silver called Live Black, but while five of their tracks were released on a demo CD sold at concerts, Live Black's first album has yet to be released.\nIn 2008, Ice-T and Black Silver toured together as Black Ice, and released an album together called \"Urban Legends\".\nIn 2013, Black Silver and newest member to Analog Brothers, Kiew Kurzweil (Kiew Nikon of Kinetic) collaborated on the joint album called \"Slang Banging (Return to Analog)\" with production by Junkadelic Music. In addition to all this, the Analog Brothers continue to make frequent appearances on each other's solo albums.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "876", "revid": "10202399", "url": "https://en.wikipedia.org/wiki?curid=876", "title": "Motor neuron diseases", "text": "Group of neurological disorders affecting motor neurons\nMedical condition&lt;templatestyles src=\"Template:Infobox/styles-images.css\" /&gt;\nMotor neuron diseases or motor neurone diseases (MNDs) are a group of rare neurodegenerative disorders that selectively affect motor neurons, the cells which control voluntary muscles of the body. They include amyotrophic lateral sclerosis (ALS), progressive bulbar palsy (PBP), pseudobulbar palsy, progressive muscular atrophy (PMA), primary lateral sclerosis (PLS), spinal muscular atrophy (SMA) and monomelic amyotrophy (MMA), as well as some rarer variants resembling ALS.\nMotor neuron diseases affect both children and adults. While each motor neuron disease affects patients differently, they all cause movement-related symptoms, mainly muscle weakness. Most of these diseases seem to occur randomly without known causes, but some forms are inherited. Studies into these inherited forms have led to discoveries of various genes (e.g. \"SOD1\") that are thought to be important in understanding how the disease occurs.\nSymptoms of motor neuron diseases can be first seen at birth or can come on slowly later in life. Most of these diseases worsen over time; while some, such as ALS, shorten one's life expectancy, others do not. Currently, there are no approved treatments for the majority of motor neuron disorders, and care is mostly symptomatic.\nSigns and symptoms.\nSigns and symptoms depend on the specific disease, but motor neuron diseases typically manifest as a group of movement-related symptoms. They come on slowly, and worsen over the course of more than three months. Various patterns of muscle weakness are seen, and muscle cramps and spasms may occur. One can have difficulty breathing with climbing stairs (exertion), difficulty breathing when lying down (orthopnea), or even respiratory failure if breathing muscles become involved. Bulbar symptoms, including difficulty speaking (dysarthria), difficulty swallowing (dysphagia), and excessive saliva production (sialorrhea), can also occur. Sensation, or the ability to feel, is typically not affected. Emotional disturbance (e.g. pseudobulbar affect) and cognitive and behavioural changes (e.g. problems in word fluency, decision-making, and memory) are also seen. There can be lower motor neuron findings (e.g. muscle wasting, muscle twitching), upper motor neuron findings (e.g. brisk reflexes, Babinski reflex, Hoffman's reflex, increased muscle tone), or both.\nMotor neuron diseases are seen both in children and adults. Those that affect children tend to be inherited or familial, and their symptoms are either present at birth or appear before learning to walk. Those that affect adults tend to appear after age 40. The clinical course depends on the specific disease, but most progress or worsen over the course of months. Some are fatal (e.g. ALS), while others are not (e.g. PLS).\nPatterns of weakness.\nVarious patterns of muscle weakness occur in different motor neuron diseases. Weakness can be symmetric or asymmetric, and it can occur in body parts that are distal, proximal, or both. According to Statland et al., there are three main weakness patterns that are seen in motor neuron diseases, which are:\nLower and upper motor neuron findings.\nMotor neuron diseases are on a spectrum in terms of upper and lower motor neuron involvement. Some have just lower or upper motor neuron findings, while others have a mix of both. Lower motor neuron (LMN) findings include muscle atrophy and fasciculations, and upper motor neuron (UMN) findings include hyperreflexia, spasticity, muscle spasm, and abnormal reflexes.\nPure upper motor neuron diseases, or those with just UMN findings, include PLS.\nPure lower motor neuron diseases, or those with just LMN findings, include PMA.\nMotor neuron diseases with both UMN and LMN findings include both familial and sporadic ALS.\nCauses.\nMost cases are sporadic and their causes are usually not known. It is thought that environmental, toxic, viral, or genetic factors may be involved.\nDNA damage.\nTAR DNA-binding protein 43 (TDP-43), is a critical component of the non-homologous end joining (NHEJ) enzymatic pathway that repairs DNA double-strand breaks in pluripotent stem cell-derived motor neurons. TDP-43 is rapidly recruited to double-strand breaks where it acts as a scaffold for the recruitment of the XRCC4-DNA ligase protein complex that then acts to repair double-strand breaks. About 95% of ALS patients have abnormalities in the nucleus-cytoplasmic localization in spinal motor neurons of TDP43. In TDP-43 depleted human neural stem cell-derived motor neurons, as well as in sporadic ALS patients' spinal cord specimens there is significant double-strand break accumulation and reduced levels of NHEJ.\nAssociated risk factors.\nIn adults, men are more commonly affected than women.\nDiagnosis.\nDifferential diagnosis can be challenging due to the number of overlapping symptoms, shared between several motor neuron diseases. Frequently, the diagnosis is based on clinical findings (i.e. LMN vs. UMN signs and symptoms, patterns of weakness), family history of MND, and a variation of tests, many of which are used to rule out disease mimics, which can manifest with identical symptoms.\nClassification.\nMotor neuron disease describes a collection of clinical disorders, characterized by progressive muscle weakness and the degeneration of the motor neuron on electrophysiological testing. The term \"motor neuron disease\" has varying meanings in different countries. Similarly, the literature inconsistently classifies which degenerative motor neuron disorders can be included under the umbrella term \"motor neuron disease\". The four main types of MND are marked (*) in the table below.\nAll types of MND can be differentiated by two defining characteristics:\nSporadic or acquired MNDs occur in patients with no family history of degenerative motor neuron disease. Inherited or genetic MNDs adhere to one of the following inheritance patterns: autosomal dominant, autosomal recessive, or X-linked. Some disorders, like ALS, can occur sporadically (85%) or can have a genetic cause (15%) with the same clinical symptoms and progression of disease.\nUMNs are motor neurons that project from the cortex down to the brainstem or spinal cord. LMNs originate in the anterior horns of the spinal cord and synapse on peripheral muscles. Both motor neurons are necessary for the strong contraction of a muscle, but damage to an UMN can be distinguished from damage to a LMN by physical exam.\nTreatment.\nThere are no known curative treatments for the majority of motor neuron disorders. \nPhysiotherapy helps maintain movement and function when someone is affected by\ndisability, injury or illness. This is achieved through movement and exercise, manual\ntherapy, education and advice. Although physiotherapy can't reverse the effects of\nMND, or Kennedy's disease, it can help maintain range of movement and comfort\nfor as long as possible.\nPrognosis.\nThe table below lists life expectancy for patients who are diagnosed with MND.\nTerminology.\nIn the United States and Canada, the term \"motor neuron disease\" usually refers to the group of disorders while amyotrophic lateral sclerosis is frequently called \"Lou Gehrig's disease\". In the United Kingdom and Australia, the term \"motor neuron(e) disease\" is used for amyotrophic lateral sclerosis, although is not uncommon to refer to the entire group.\nWhile MND refers to a specific subset of similar diseases, there are numerous other diseases of motor neurons that are referred to collectively as \"motor neuron disorders\", for instance the diseases belonging to the spinal muscular atrophies group. However, they are not classified as \"motor neuron diseases\" by the 11th edition of the International Statistical Classification of Diseases and Related Health Problems (ICD-11), which is the definition followed in this article.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "877", "revid": "140154", "url": "https://en.wikipedia.org/wiki?curid=877", "title": "Abjad", "text": "Writing system where each symbol stands for a consonant\nAn abjad ( or abgad) is a writing system in which only consonants are represented by letter signs, leaving the vowels to be inferred by the reader (unless represented otherwise, such as by diacritics). This contrasts with alphabets that provide graphemes for both consonants and vowels. The term was introduced in 1990 by Peter T. Daniels. Other terms for the same concept include partial phonemic script, segmentally linear defective phonographic script, consonantary, consonant writing, and consonantal alphabet.\nImpure abjads represent vowels with either optional diacritics or a limited number of distinct vowel graphemes, or both.\nEtymology.\nThe name \"abjad\" is based on the Arabic alphabet's first four letters in their original alphabetical order \u2014 corresponding to \"\u02bea\", \"b\", \"j\", and \"d\" \u200a\u2014\u200a which reflects the alphabetical order \"\u02be\"aleph, bet, gimel, dalet in other consonantal Semitic scripts such as Phoenician, Hebrew, and other Semitic proto-alphabets classified within the family of scripts used to write West Semitic languages.\nTerminology.\nAccording to the formulations of Peter T. Daniels, abjads differ from alphabets in that only consonants, not vowels, are represented among the basic graphemes. Abjads differ from abugidas, another category defined by Daniels, in that in abjads, the vowel sound is \"implied\" by phonology, and where vowel marks exist for the system, such as niqqud for Hebrew and \u1e25arak\u0101t for Arabic, their use is optional and not the dominant (or literate) form. Abugidas mark all vowels (other than the \"inherent\" vowel) with a diacritic, a minor attachment to the letter, a standalone grapheme, or (in Canadian Aboriginal syllabics) by rotation of the letter. Some abugidas use a special symbol to \"suppress\" the inherent vowel so that the consonant alone can be properly represented. In a syllabary, a grapheme denotes a complete syllable, that is, either a lone vowel sound or a combination of a vowel sound with one or more consonant sounds.\nThe contrast of abjad versus alphabet has been rejected by other scholars because \"abjad\" is also used as a term for the Arabic numeral system. Also, it may be taken as suggesting that consonantal alphabets, in contrast to e.g. the Greek alphabet, were not yet true alphabets. Florian Coulmas, a critic of Daniels and of the abjad terminology, argues that this terminology can confuse alphabets with \"transcription systems\", and that there is no reason to relegate the Hebrew, Aramaic or Phoenician alphabets to second-class status as an \"incomplete alphabet\".\nHowever, Daniels's terminology has found acceptance in the linguistic community.\nOrigins and history.\nThe Proto-Sinaitic script represents the earliest-known trace of alphabetic writing. This script is generally considered to have been developed around the Sinai Peninsula during the Middle Bronze Age by speakers of an ancient West Semitic language who repurposed pictographic elements of local Egyptian hieroglyphs in order to construct a new script that represented the consonants of their own language using acrophony. The Proto-Sinaitic script is thought to represent, or at least indicate the existence of, an early ancestor of the many later Semitic consonantal scripts which continued to develop over time into more abstract, less visually representational forms, including the Phoenician abjad. \nThe Phoenician abjad was a radical simplification of phonetic writing. Unlike other scripts, such as Mesopotamian cuneiform (logographic and syllabic) and Egyptian hieroglyphs (logographic and consonantal), the Phoenician abjad consisted of only a few dozen symbols. Presumably, the relative simplicity of the Phoenician abjad made this script easy to learn, allowed it to gain widespread usage, and influenced how readily it was adopted or adapted into the development of other scripts by non-Phoenicians who encountered seafaring Phoenician merchants and their script which they brought with them as they traded throughout the ancient Mediterranean world during the first millennium BCE. \nDuring these exchanges, the Phoenician script gave rise to a number of new writing systems, including the widely used Aramaic abjad and the Greek alphabet. The Greek alphabet was later developed into several alphabets, including Etruscan, Coptic, Cyrillic, and Latin (via Etruscan), while Aramaic became the ancestor of many abjads and abugidas of Asia, particularly in and around India, Southeast Asia, and Oceania.\nOther sister scripts to Phoenician, that branched from Proto-Sinaitic script are the South Semitic scripts with its two main branches; the Ancient North Arabian scripts that were used in north and central Arabia, until it was displaced by the Arabic alphabet. and Ancient South Arabian, which evolved later into the Ge\u02bdez script, still being used in Eritrea and Ethiopia.\nImpure abjads.\nImpure abjads have characters for some vowels, optional vowel diacritics, or both. The term pure abjad refers to scripts entirely lacking in vowel indicators. However, most abjads, such as Arabic, Hebrew, Aramaic, and Pahlavi, are \"impure\" abjads\u00a0\u2013 that is, they also contain symbols for some of the vowel phonemes, although the said non-diacritic vowel letters are also used to write certain consonants, particularly approximants that sound similar to long vowels. A \"pure\" abjad is exemplified (perhaps) by very early forms of ancient Phoenician, though at some point (at least by the 9th century BC) it and most of the contemporary Semitic abjads had begun to overload a few of the consonant symbols with a secondary function as vowel markers, called \"matres lectionis\". This practice was at first rare and limited in scope but became increasingly common and more developed in later times.\nAddition of vowels.\nIn the 9th century BC the Greeks adapted the Phoenician script for use in their own language. The phonetic structure of the Greek language created too many ambiguities when vowels went unrepresented, so the script was modified. They did not need letters for the guttural sounds represented by \"aleph\", \"he\", \"heth\" or \"ayin\", so these symbols were assigned vocalic values. The letters \"waw\" and \"yod\" were also adapted into vowel signs; along with \"he\", these were already used as \"matres lectionis\" in Phoenician. The major innovation of Greek was to dedicate these symbols exclusively and unambiguously to vowel sounds that could be combined arbitrarily with consonants (as opposed to syllabaries such as Linear B which usually have vowel symbols but cannot combine them with consonants to form arbitrary syllables).\nAbugidas developed along a slightly different route. The basic consonantal symbol was considered to have an inherent \"a\" vowel sound. Hooks or short lines attached to various parts of the basic letter modify the vowel. In this way, the South Arabian abjad evolved into the Ge\u02bdez script of Ethiopia between the 5th century BC and the 5th century AD. Similarly, the Br\u0101hm\u012b abugida of the Indian subcontinent developed around the 3rd century BC (from the Aramaic abjad, it has been hypothesized).\nAbjads and the structure of Semitic languages.\nThe abjad form of writing is well-adapted to the morphological structure of the Semitic languages it was developed to write. This is because words in Semitic languages are formed from a root consisting of (usually) three consonants, the vowels being used to indicate inflectional or derived forms. For instance, according to Classical Arabic and Modern Standard Arabic, from the Arabic root \"K-T-B\" (to write) can be derived the forms ' (he wrote), ' (you (masculine singular) wrote), ' (he writes), and ' (library). In most cases, the absence of full glyphs for vowels makes the common root clearer, allowing readers to guess the meaning of unfamiliar words from familiar roots (especially in conjunction with context clues) and improving word recognition while reading for practiced readers.\nAdaptation for use as true alphabets.\nThe Arabic abjad has been adapted to perform as true alphabets when used to write several languages, including Kurdish, Swahili, Malay, and Uyghur and historically Bosnian, Mozarabic, Aragonese, Portuguese, Spanish and Afrikaans, with some letters or letter combinations being repurposed to represent vowels. The Hebrew abjad has also been adapted to write Jewish languages like Ladino and Yiddish.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nSources.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "878", "revid": "34434225", "url": "https://en.wikipedia.org/wiki?curid=878", "title": "Abugida", "text": "Syllable-based writing system\nAn abugida (; from Ge\u02bdez: , )\u2014sometimes also called an alphasyllabary, neosyllabary, or pseudo-alphabet\u2014is a segmental writing system in which consonant\u2013vowel sequences are written as units; each unit is based on a consonant letter, and vowel notation is secondary, like a diacritical mark. This contrasts with a full alphabet, in which vowels have status equal to consonants, and with an abjad, in which vowel marking is absent, partial, or optional. In less formal contexts, all three types of script may be termed \"alphabets\". The terms also contrast them with a syllabary, in which a single symbol denotes the combination of a consonant and a vowel.\nRelated concepts were introduced independently in 1948 by James Germain F\u00e9vrier (using the term ) and David Diringer (using the term \"semisyllabary\"), and in 1959 by Fred Householder (introducing the term \"pseudo-alphabet\"). The Ethiopic term \"abugida\" was chosen as a designation for the concept in 1990 by Peter T. Daniels. Faber suggested \"segmentally coded syllabically linear phonographic script\"; William O. Bright used the term \"alphasyllabary\"; and Gnanadesikan and Rimzhim, Katz, &amp; Fowler suggested \"aksara\" or \"\u0101ksharik\".\nAbugidas include the extensive Brahmic family of scripts of Tibet and South and Southeast Asia; Semitic Ethiopic scripts; and Canadian Aboriginal syllabics. As in syllabaries, the writing system's units may consist of representations of both syllables and consonants. For scripts of the Brahmic family, the term \"akshara\" is used for the units.\nEtymology.\nIn several languages of Ethiopia and Eritrea, \"abugida\" traditionally meant letters of the Ethiopic or Ge\u02bdez script in which many of these languages are written. The Ge\u02bdez script is one of several segmental writing systems; others include Indic/Brahmic scripts and Canadian Aboriginal Syllabics. The word \"abugida\" derives from the letters \"'\u00e4, bu, gi,\" and \"da\", in much the same way that \"abecedary\" derives from the Latin letters \"a be ce de\", \"abjad\" derives from the Arabic \"a b j d\", and \"alphabet\" derives from the two first letters in the Greek alphabet, \"alpha\" and \"beta\". \"Abugida\" as a term in linguistics was proposed by Peter T. Daniels in his 1990 typology of writing systems.\nTerminology.\nAs Daniels used the word, an abugida contrasts with a syllabary, where letters with shared consonant or vowel sounds have no particular resemblance. Furthermore, an abugida contrasts with an alphabet proper, where independent letters denote consonants and vowels. The term \"alphasyllabary\" was suggested for the Indic scripts in 1997 by William O. Bright, following South Asian linguistic usage, to convey that \"they share features of both alphabet and syllabary.\"\nThe formal definitions given by Daniels and Bright for abugida and alphasyllabary differ; some writing systems are abugidas but not alphasyllabaries, and some are alphasyllabaries but not abugidas. An abugida is defined as \"a type of writing system whose basic characters denote consonants followed by a particular vowel, and in which diacritics denote other vowels\". (This \"particular vowel\" is called the \"inherent\" or \"implicit\" vowel, as opposed to the \"explicit\" vowels marked by the diacritics.)\nAn alphasyllabary is defined as \"a type of writing system in which the vowels are denoted by subsidiary symbols, not all of which occur in a linear order (with relation to the consonant symbols) that is congruent with their temporal order in speech\". Bright did not require that an alphabet explicitly represent all vowels. \u02bcPhags-pa is an example of an abugida because it has an inherent vowel, but it is not an alphasyllabary because its vowels are written in linear order. Modern Lao is an example of an alphasyllabary that is not an abugida, for there is no inherent vowel and its vowels are always written explicitly and not in accordance to their temporal order in speech, meaning that a vowel can be written before, below, or above a consonant letter, while the syllable is still pronounced in the order of a consonant-vowel combination (CV).\nGeneral description.\nThe fundamental principles of an abugida apply to words made up of consonant-vowel (CV) syllables. The syllables are written as letters in a straight line, where each syllable is either a letter that represents the sound of a consonant and its inherent vowel or a letter modified to indicate the vowel. Letters can be modified either by means of diacritics or by changes in the form of the letter itself. If all modifications are by diacritics and all diacritics follow the direction of the writing of the letters, the abugida is not an alphasyllabary. But most languages have words that are more complicated than a sequence of CV syllables, even ignoring tone.\nThe first complication is syllables that consist of just a vowel (V). In some languages, a zero consonant letter is used as though every syllable began with a consonant. In others, each vowel has a separate letter that is used for each syllable consisting of just the vowel. These are known as \"independent vowels\" and are found in most Indic scripts. They may be quite different from the corresponding diacritics, known as \"dependent vowels\". As a result of the spread of writing systems, independent vowels may be used to represent syllables beginning with a glottal stop, even for non-initial syllables.\nThe next two complications are consonant clusters before a vowel (CCV) and syllables ending in a consonant (CVC). The simplest solution, which is not always available, is to break with the principle of writing words as a sequence of syllables and use a letter representing just a consonant (C). This final consonant may be represented by:\nIn a true abugida, the lack of distinctive vowel marking of the letter may result from the diachronic loss of the inherent vowel, e.g. by syncope and apocope in Hindi.\nWhen not separating syllables containing consonant clusters (CCV) into C + CV, these syllables are often written by combining the two consonants. In Indic scripts, the earliest method was simply to arrange them vertically, writing the second consonant of the cluster below the first. The two consonants may also merge as conjunct consonant letters, where two or more letters are graphically joined in a ligature, or otherwise change their shapes. Rarely, one of the consonants may be replaced by a gemination mark, e.g. the Gurmukhi \"addak\".\nWhen arranged vertically, as in Burmese or Khmer, they are said to be \"stacked\". Often there has been a change to writing the two consonants side by side. In the latter case, this combination may be indicated by a diacritic on one of the consonants or a change in the form of one of the consonants, e.g. the half forms of Devanagari. Generally, the reading order of stacked consonants is top to bottom, or the general reading order of the script, but sometimes the reading order is reversed.\nThe division of a word into syllables for the purposes of writing does not always accord with the language's natural phonetics. For example, Brahmic scripts commonly handle a phonetic sequence CVC-CV as CV-CCV or CV-C-CV, but sometimes phonetic CVC syllables are handled as single units, and the final consonant may be represented:\nMore complicated unit structures (e.g. CC or CCVC) are handled by combining the various techniques above.\nExamples using the Devanagari script\nFamily-specific features.\nThere are three principal families of abugida, distinguished by whether vowels are indicated by modifying consonants by \"diacritics, distortion,\" or \"orientation.\"\nLao and T\u0101na have dependent vowels and a zero vowel sign, but no inherent vowel.\nIndic (Brahmic).\nIndic scripts originated in India and spread to Southeast Asia, Bangladesh, Sri Lanka, Nepal, Bhutan, Tibet, Mongolia, and Russia. All surviving Indic scripts are descendants of the Brahmi alphabet. Today they are used in most languages of South Asia (although replaced by Perso-Arabic in Urdu, Kashmiri, and some other languages of Pakistan and India), mainland Southeast Asia (Myanmar, Thailand, Laos, Cambodia, and Vietnam), Tibet (Tibetan), the Indonesian archipelago (Javanese, Balinese, Sundanese, Batak, Lontara, Rejang, Rencong, Makasar, etc.), Philippines (Baybayin, Buhid, Hanunuo, Kulitan, and Aborlan Tagbanwa), and Malaysia (Rencong).\nThe primary division is between North Indic scripts, used in Northern India, Nepal, Tibet, Bhutan, Mongolia, and Russia, and Southern Indic scripts, used in South India, Sri Lanka and Southeast Asia. South Indic letter forms are more rounded than North Indic forms, though Odia, Golmol and Litumol are rounded. Most North Indic scripts' full letters incorporate a horizontal line at the top, except in Gujarati and Odia; South Indic scripts do not.\nIndic scripts indicate vowels through dependent vowel signs (diacritics) around the consonants, often including a sign that explicitly indicates the lack of a vowel. If a consonant has no vowel sign, this indicates a default vowel. Vowel diacritics may appear above, below, to the left of, to the right of, or around the consonant.\nThe most widely used Indic script is Devanagari, shared by Hindi, Bihari, Marathi, Konkani, Nepali, and often Sanskrit. A basic letter such as \u0915 in Hindi represents a syllable with the default vowel, in this case \"ka\" (). In some languages, including Hindi, it becomes a final closing consonant at the end of a word, in this case \"k\". The inherent vowel may be changed by adding vowel marks (diacritics), producing syllables such as \u0915\u093f \"ki\", \u0915\u0941 \"ku\", \u0915\u0947 \"ke\", \u0915\u094b \"ko\".\nIn many Brahmic scripts, a syllable beginning with a cluster is treated as a single character for purposes of vowel marking, so a vowel marker like \u093f \"-i,\" falling before the character it modifies, may appear several positions before the place where it is pronounced. For example, the game cricket in Hindi is \u0915\u094d\u0930\u093f\u0915\u0947\u091f ; the diacritic for appears before the consonant cluster , not before the . A more unusual example is seen in the Batak alphabet: the syllable \"bim\" is written \"ba-ma-i-(virama)\". That is, the vowel diacritic and virama are both written after the consonants for the whole syllable.\nIn many abugidas, there is also a diacritic to suppress the inherent vowel, yielding the bare consonant. In Devanagari, \u092a\u094d is \"p\", and \u092b\u094d is \"ph\". This is called the \"vir\u0101ma\" or \"halantam\" in Sanskrit. It may be used to form consonant clusters or to indicate that a consonant occurs at the end of a word. Thus in Sanskrit, a default vowel consonant such as \u092b does not take on a final consonant sound. Instead, it keeps its vowel. For writing two consonants without a vowel in between, instead of using diacritics on the first consonant to remove its vowel, another common method of special conjunct forms is used in which two or more consonant characters are merged to express a cluster, as in Devanagari's \u0905\u092a\u094d\u092b \"appha\". (Some fonts display this as \u092a\u094d followed by \u092b, rather than forming a conjunct. This expedient is used by ISCII and South Asian scripts of Unicode.) Thus a closed syllable such as \"pha\u1e63\" requires two \"aksharas\" to write: \u092b\u0937\u094d \"pha\u1e63\".\nThe R\u00f3ng script used for the Lepcha language goes further than other Indic abugidas, in that a single \"akshara\" can represent a closed syllable: Not only the vowel but any final consonant is indicated by a diacritic. For example, the syllable [sok] would be written as something like s\u0325\u033d, here with an underring representing and an overcross representing the diacritic for final . Most other Indic abugidas can indicate only a very limited set of final consonants with diacritics, such as or , if they can indicate any at all.\nEthiopic.\nIn Ge\u02bdez script, \"fidels\" (individual \"letters\" of the script) have diacritics that are fused with the consonants to the point that they must be considered modifications of the form of the letters. Children learn each modification separately, as in a syllabary; nonetheless, the graphic similarities between syllables with the same consonant are readily apparent, unlike in a true syllabary.\nThough now an abugida, the Ge\u02bdez script, until the advent of Christianity (c. AD 350), was what would now be termed an \"abjad\". In the Ge\u02bdez script (or \"fidel\"), the letter's base form (also called \"fidel\") may be altered. For example, \u1200 \"h\u00e4\" (base form), \u1201 \"hu\" (with a right-side diacritic that does not alter the letter), \u1202 \"hi\" (with a subdiacritic that compresses the consonant, so it is the same height), \u1205 \"h\u0259\" or (where the letter is modified with a kink in the left arm).\nCanadian Aboriginal syllabics.\nIn the family known as Canadian Aboriginal syllabics, which was inspired by Devanagari script, vowels are indicated by changing the orientation of the syllabogram. Each vowel has a consistent orientation; for example, Inuktitut \u1431 \"pi\", \u1433 \"pu\", \u1438 \"pa\"; \u144e \"ti\", \u1450 \"tu\", \u1455 \"ta\". Although a vowel is inherent in each, all rotations have equal status and none can be identified as basic. Bare consonants are indicated either by separate diacritics or by superscript versions of the \"aksharas\"; there is no vowel-killer mark.\nBorderline cases.\nVowelled abjads.\nAbjads are typically written without indication of many vowels, but in some contexts, such as teaching materials or scriptures, Arabic and Hebrew are written with full indication of vowels via diacritic marks (\"harakat\", \"niqqud\"), making them effectively alphasyllabaries.\nThe Arabic scripts used for Kurdish in Iraq and for Uyghur in Xinjiang, China, as well as the Hebrew script of Yiddish, are fully vowelled, but because the vowels are written with full letters rather than diacritics (with the exception of distinguishing between /a/ and /o/ in the latter) and there are no inherent vowels, these are considered alphabets, not abugidas.\nThe Arabic script used for South Azerbaijani generally writes the vowel /\u00e6/ (written as \u0259 in North Azerbaijani) as a diacritic but all other vowels as full letters (like Kurdish and Uyghur). This means that when no vowel diacritics are present (most of the time), it technically has an inherent vowel. But like the Phagspa and Meroitic scripts, whose status as abugidas is controversial (see below), all other vowels are written in-line. Additionally, the practice of explicitly writing all-but-one vowel does not apply to loanwords from Arabic and Persian, so the script does not have an inherent vowel for Arabic and Persian words. The inconsistency of its vowel notation makes it difficult to categorize.\nPhagspa.\nThe imperial Mongol script called Phagspa was derived from the Tibetan abugida, but all vowels are written in-line rather than as diacritics. However, it retains the features of having an inherent vowel /a/ and having distinct initial vowel letters.\nPahawh.\nPahawh Hmong is a non-segmental script that indicates syllable onsets and rimes, such as consonant clusters and vowels with final consonants. Thus it is not segmental and cannot be considered an abugida. It superficially resembles an abugida with the roles of consonant and vowel reversed. Most syllables are written with two letters in the order rime\u2013onset (typically vowel-consonant) even though they are pronounced as onset-rime (consonant-vowel), rather like the position of the vowel in Devanagari, which is written before the consonant. Pahawh is also unusual in that, while an inherent rime (with mid tone) is unwritten, it also has an inherent onset . For the syllable , which requires that one of the inherent sounds be overt, it is that is written. Thus the rime (vowel) is basic to the system.\nMeroitic.\nDrawing a dividing line between abugidas and other segmental scripts can be difficult. For example, the Meroitic script of ancient Sudan does not indicate an inherent \"a\" (one symbol stood for both \"m\" and \"ma,\" for example) and is thus similar to Brahmic family of abugidas. But other vowels were indicated with full letters, not diacritics or modification, so the system is essentially an alphabet that does not bother to write the most common vowel.\nShorthand.\nSeveral systems of shorthand use diacritics for vowels, but do not have an inherent vowel, and are thus more similar to Thaana and Kurdish script than to Brahmic scripts. The Gabelsberger shorthand system and its derivatives modify the \"following\" consonant to represent vowels. The Pollard script, which was based on shorthand, also uses diacritics for vowels; the placements of the vowel relative to the consonant indicate tone. Pitman shorthand uses straight strokes and quarter-circle marks in different orientations as the principal \"alphabet\" of consonants; vowels are shown as light and heavy dots, dashes, and other marks in one of three possible positions to indicate the various vowel-sounds. To increase writing speed, Pitman has rules for \"vowel indication\" using the positioning or choice of consonant signs so that writing vowel-marks can be dispensed with.\nDevelopment.\nAs the term \"alphasyllabary\" suggests, abugidas have been considered an intermediate step between alphabets and syllabaries. Historically, abugidas appear to have evolved from abjads (vowelless alphabets). They contrast with syllabaries, where there is a distinct symbol for each syllable or consonant-vowel combination, and where these have no systematic similarity to each other, and typically develop directly from logographic scripts. Compare the examples above to sets of syllables in the Japanese hiragana syllabary: \u304b \"ka\", \u304d \"ki\", \u304f \"ku\", \u3051 \"ke\", \u3053 \"ko\" have nothing in common to indicate \"k\"; while \u3089 \"ra\", \u308a \"ri\", \u308b \"ru\", \u308c \"re\", \u308d \"ro\" have neither anything in common for \"r\" nor anything to indicate that they have the same vowels as the \"k\" set.\nMost Indian and Indochinese abugidas appear to have developed from abjads with the Kharo\u1e63\u1e6dh\u012b and Br\u0101hm\u012b scripts; the abjad in question is usually considered the Aramaic one, but while the link between Aramaic and Kharosthi is more or less undisputed, this is not so with Brahmi. The Kharosthi family does not survive today, but Brahmi's descendants include most of the modern scripts of South and Southeast Asia.\nThe Ge\u02bdez script derives from a different abjad, the Sabean script of Yemen; the advent of vowels coincided with the introduction or adoption of Christianity about AD 350. The Ethiopic script is the elaboration of an abjad.\nThe Cree syllabary was invented with full knowledge of the Devanagari system.\nThe Meroitic script was developed from Egyptian hieroglyphs, in which various schemes of \"group writing\" were used to show vowels.\nList of abugidas.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "880", "revid": "51053197", "url": "https://en.wikipedia.org/wiki?curid=880", "title": "ABBA", "text": "Swedish pop group\nABBA ( ) were a Swedish pop group formed in Stockholm in 1972 by Agnetha F\u00e4ltskog, Bj\u00f6rn Ulvaeus, Benny Andersson, and Anni-Frid Lyngstad. They are among the most renowned and commercially successful musical groups in history.\nIn 1974, ABBA won the Eurovision Song Contest for Sweden with their song \"Waterloo\". In 2005, \"Waterloo\" was chosen as the best song in the competition's history during its . During their peak, ABBA comprised two married couples: F\u00e4ltskog and Ulvaeus, and Lyngstad and Andersson. As their fame grew, their personal lives suffered, leading to the dissolution of both marriages. These relationship changes were reflected in the group's later music, which featured darker and more introspective lyrics. After ABBA disbanded in December 1982, Andersson and Ulvaeus continued their success writing music for stage, musicals, and movies, while F\u00e4ltskog and Lyngstad pursued solo careers. Ten years after the group's breakup, the compilation \"ABBA Gold\" was released and became a worldwide best-seller. In 1999, ABBA's music was adapted into \"Mamma Mia!\", a stage musical that toured globally. As of October 2024, it remains one of the ten longest-running productions on Broadway (closed in 2015) and the West End (still running). A film of the same name, released in 2008, became the highest-grossing film in the United Kingdom that year. A sequel, \"Mamma Mia! Here We Go Again\", was released in 2018.\nABBA have sold an estimated 150 million records worldwide, making them one of the best-selling acts in the history of popular music. The group are ranked as the third best-selling singles artist in the United Kingdom, with a total of 11.3 million singles sold as of November 3, 2012. In May 2023, ABBA received the BRIT Billion Award, which honours artists who have surpassed one billion UK streams in their careers. They were the first group from a non-English-speaking country to achieve consistent success on the charts in English-speaking countries, including the United Kingdom, Australia, the United States, the Republic of Ireland, Canada, New Zealand, and South Africa. ABBA is recognised as the best-selling Swedish band of all time and the best-selling band originating from continental Europe. The group achieved eight consecutive number-one albums in the UK and also enjoyed significant success in Latin America, recording a collection of their hit songs in Spanish. ABBA was inducted into the Vocal Group Hall of Fame in 2002 and the Rock and Roll Hall of Fame in 2010, becoming the first recording artists to receive this honor from outside an Anglophone country. In 2015, their song \"Dancing Queen\" was inducted into the Recording Academy's Grammy Hall of Fame. In 2024, the United States Library of Congress included the album \"Arrival\" (1976) in the National Recording Registry, recognising it as a work \"worthy of preservation for all time based on its cultural, historical, or aesthetic importance in the nation's recorded sound heritage\".\nIn 2016, the group reunited and started working on a digital avatar concert tour. Newly recorded songs were announced in 2018. \"Voyage\", their first new album in 40 years, was released on 5 November 2021, to positive critical reviews and strong sales. ABBA Voyage, a concert residency featuring ABBA as virtual avatars, opened in May 2022 in London.\nHistory.\n1958\u20131970: Before ABBA.\nMember origins and collaboration.\nAgnetha F\u00e4ltskog (born 5 April 1950 in J\u00f6nk\u00f6ping, Sweden) sang with a local dance band headed by Bernt Enghardt, who sent a demo recording of their music to Karl-Gerhard Lundkvist. The demo tape featured a song written and sung by F\u00e4ltskog: \"Jag var s\u00e5 k\u00e4r\" (\"I Was So in Love\"). Lundkvist was impressed by her voice and believed she had the potential to become a star; he sought her out and arranged her to travel to Stockholm to record two of her own compositions. As a result, at the age of 18, F\u00e4ltskog achieved a number-one single in Sweden with a self-written song, which subsequently sold over 80,000 copies. She was soon noticed by critics and songwriters as a talented singer/songwriter of schlager-style songs. Along with her own compositions, she recorded covers of foreign hits and performed them on tours in Swedish folkparks. She achieved a number of successful singles on the Swedish charts, the majority of which were her own compositions. Between 1968 and 1971, F\u00e4ltskog released four solo studio albums.\nBj\u00f6rn Ulvaeus (born 25 April 1945 in Gothenburg, Sweden) also began his musical career at the age of 18, as a singer and guitarist, when he fronted the Hootenanny Singers, a popular Swedish folk-skiffle group. Ulvaeus began composing English-language songs for his group and concurrently pursued a brief solo career. The Hootenanny Singers and Benny Andersson's Hep Stars sometimes crossed paths while touring. In June 1966, Ulvaeus and Andersson decided to write a song together. Their first attempt was \"Isn't It Easy to Say\", a song that was later recorded by the Hep Stars. Stig Anderson was the manager of the Hootenanny Singers and founder of the Polar Music label. He saw potential in the collaboration and encouraged them to write more. The two also began playing occasionally with the other's band on stage and on records, although it was not until 1969 that the pair wrote and produced some of their first hit songs: \"Ljuva sextital\" (\"Sweet Sixties\"), recorded by Brita Borg, and the Hep Stars' 1969 hit \"Speleman\" (\"Fiddler\").\nBenny Andersson (born 16 December 1946 in Stockholm, Sweden) became, at age 18, a member of a popular Swedish pop-rock group, the Hep Stars, that performed, among other things, covers of international hits. The Hep Stars were known as \"the Swedish Beatles\". They also set up Hep House, their equivalent of Apple Corps. Andersson played the keyboard and eventually started writing original songs for his band, many of which became major hits, including \"No Response\", which reached number three on the charts in 1965, \"Sunny Girl\", \"Wedding\", and \"Consolation\", all of which reached number one in 1966. Andersson also had a fruitful songwriting collaboration with Lasse Berghagen, with whom he wrote his first Svensktoppen entry, \"Sagan om lilla Sofie\" (\"The Tale of Little Sophie\"), in 1968.\nAndersson wrote and submitted the song \"Hej, Clown\" for Melodifestivalen 1969, the national festival to select the Swedish entry to the Eurovision Song Contest. The song tied for first place, but re-voting relegated Andersson's song to second place. On that occasion Andersson briefly met his future spouse, singer Anni-Frid Lyngstad, who also participated in the contest. A week later, they met again during a concert tour in southern Sweden, and soon became a couple. As their respective bands began to break up during 1969, Andersson and Ulvaeus teamed up and recorded their first collaborative album in 1970, called \"Lycka\" (\"Happiness\"), which included original songs sung by both musicians. Their partners were often present in the recording studio and sometimes added backing vocals; F\u00e4ltskog co-wrote one of the songs. Ulvaeus still occasionally recorded and performed with the Hootenanny Singers until the middle of 1974, and Andersson took part in producing their records.\nAnni-Frid \"Frida\" Lyngstad (born 15 November 1945 in Bj\u00f8rk\u00e5sen in Ballangen Municipality, Norway) sang from the age of 13 with various dance bands and worked mainly in jazz-orientated cabaret music. She also formed her own band, the Anni-Frid Four. In the middle of 1967, she won a national talent competition with \"En ledig dag\" (\"A Day Off\"), a Swedish version of the bossa nova song \"A Day in Portofino\", which is included in the EMI compilation \"Frida 1967\u20131972\". The first prize was a recording contract with EMI Sweden and the opportunity to perform live on the most popular TV shows in the country. This TV performance, among many others, are included in the &lt;templatestyles src=\"Fraction/styles.css\" /&gt;3+1\u20442-hour documentary \"Frida \u2013 The DVD\". Lyngstad released several schlager style singles on EMI with mixed success. When Benny Andersson started to produce her recordings in 1971, she had her first number-one single, \"Min egen stad\" (\"My Own Town\"), written by Benny and featuring all the future ABBA members on backing vocals. Lyngstad toured and performed regularly on the folkpark circuit and made appearances on radio and TV. She had a second number-one single with \"Man Vill Ju Leva Lite Dessemellan\" in late 1972. She had met Ulvaeus briefly in 1963 during a talent contest and F\u00e4ltskog during a TV show in early 1968.\nAndersson produced Lyngstad's single \"Peter Pan\" in September 1969\u2014her first collaboration with Benny and Bj\u00f6rn, as they had written the song. Andersson would then produce Lyngstad's debut studio album, \"Frida\", which was released in March 1971. Lyngstad also played in several revues and cabaret shows in Stockholm between 1969 and 1973. After ABBA formed, she recorded another album in 1975, \"Frida ensam\", which included the original Swedish rendition of \"Fernando\", a hit on the Swedish radio charts before the English version was released by ABBA.\nDuring filming of a Swedish TV special in May 1969, F\u00e4ltskog met Ulvaeus, and they got married on 6 July 1971. F\u00e4ltskog and Ulvaeus eventually were involved in each other's recording sessions, and soon Andersson and Lyngstad added backing vocals to F\u00e4ltskog's third studio album, \"Som jag \u00e4r\" (\"As I Am\") (1970). In 1972, F\u00e4ltskog starred as Mary Magdalene in the original Swedish production of \"Jesus Christ Superstar\" and attracted favourable reviews.\nFirst live performance and the start of \"Festfolket\".\nAn initial collaboration between the two couples took place in April 1970, when they travelled together to the island of Cyprus. What started as singing for fun on the beach ended up as an improvised live performance in front of the United Nations soldiers stationed on the island. Andersson and Ulvaeus were at this time recording their first album together, \"Lycka\", which was to be released in September 1970. F\u00e4ltskog and Lyngstad added backing vocals on several tracks during June, and the idea of their working together saw them launch a stage act, \"Festfolket\" (which translates from Swedish to \"Party People\" and in pronunciation also \"engaged couples\"), on 1 November 1970 in Gothenburg.\nThe cabaret show attracted predominantly negative reviews, except for the performance of the Andersson and Ulvaeus hit \"Hej, gamle man\" (\"Hello, Old Man\")\u2014the first Bj\u00f6rn and Benny recording to feature all four. They also performed solo numbers from respective albums, but the lukewarm reception convinced the foursome to shelve plans for working together for the time being, and each soon concentrated on individual projects again.\nFirst record together \"Hej, gamle man\".\n\"Hej, gamle man\", a song about an old Salvation Army soldier, became the quartet's first hit. The record was credited to \"Bj\u00f6rn &amp; Benny\" and reached number five on the sales charts and number one on Svensktoppen, staying on the latter chart (which was not a chart linked to sales or airplay) for 15 weeks.\nIn 1971, the four artists began collaborating more frequently, contributing vocals to each other's recordings. F\u00e4ltskog, Andersson, and Ulvaeus toured together in May, while Lyngstad toured on her own. Frequent recording sessions brought the foursome closer together during the summer.\n1970\u20131973: Forming the group.\nAfter the 1970 release of \"Lycka\", two more singles credited to \"Bj\u00f6rn &amp; Benny\" were released in Sweden, \"Det kan ingen doktor hj\u00e4lpa\" (\"No Doctor Can Help with That\") and \"T\u00e4nk om jorden vore ung\" (\"Imagine If Earth Was Young\"), with more prominent vocals by F\u00e4ltskog and Lyngstad\u2013and moderate chart success. F\u00e4ltskog and Ulvaeus, now married, started performing together with Andersson on a regular basis at the Swedish folkparks in the middle of 1971.\nStig Anderson, founder and owner of Polar Music, was committed to achieving mainstream international success with music composed by Andersson and Ulvaeus. \"One day the pair of you will write a song that becomes a worldwide hit\", he predicted. Stig Anderson encouraged Ulvaeus and Andersson to write a song for Melodifestivalen, and after two rejected entries in 1971, Andersson and Ulvaeus submitted their new song \"S\u00e4g det med en s\u00e5ng\" (\"Say It with a Song\") for the 1972 contest, choosing newcomer Lena Anderson to perform. The song came in third place, encouraging Stig Anderson, and became a hit in Sweden.\nThe first signs of foreign success came as a surprise, as the Andersson and Ulvaeus single \"She's My Kind of Girl\" was released through Epic Records in Japan in March 1972, giving the duo a Top 10 hit. Two more singles were released in Japan, \"En Carousel\" (\"En Karusell\" in Scandinavia, an earlier version of \"Merry-Go-Round\") and \"Love Has Its Ways\" (a song they wrote with K\u014dichi Morita).\nFirst hit as Bj\u00f6rn, Benny, Agnetha and Anni-Frid.\nUlvaeus and Andersson persevered with their songwriting and experimented with new sounds and vocal arrangements. \"People Need Love\" was released in June 1972, featuring guest vocals by the women, who were now given much greater prominence. Stig Anderson released it as a single, credited to \"Bj\u00f6rn &amp; Benny, Agnetha &amp; Anni-Frid\". The song peaked at number 17 on the Swedish combined single and album charts, enough to convince them they were on to something.\n\"People Need Love\" also became the first record to chart for the quartet in the United States, where it peaked at number 114 on the \"Cashbox\" singles chart and number 117 on the \"Record World\" singles chart. Labelled as \"Bj\u00f6rn &amp; Benny (with Svenska Flicka)\" (\"Svenska Flicka\" meaning \"Swedish Girl\"), it was released there through Playboy Records. According to Stig Anderson, \"People Need Love\" could have been a much bigger American hit, but a small label like Playboy Records did not have the distribution resources to meet the demand for the single from retailers and radio programmers.\n\"Ring Ring\".\nIn 1973, the band and their manager Stig Anderson decided to have another try at Melodifestivalen, this time with the song \"Ring Ring\". The studio sessions were handled by Michael B. Tretow, who experimented with a \"wall of sound\" production technique that became a distinctive new sound thereafter associated with ABBA. Stig Anderson arranged an English translation of the lyrics by Neil Sedaka and Phil Cody, and they thought this would be a success. However, on 10 February 1973, the song came third in Melodifestivalen; thus it never reached the Eurovision Song Contest itself. Nevertheless, the group released their debut studio album, also called \"Ring Ring\". The album did well, and the \"Ring Ring\" single was a hit in many parts of Europe and also in South Africa. However, Stig Anderson felt that the true breakthrough could only come with a UK or US hit.\nWhen Agnetha F\u00e4ltskog gave birth to her daughter Linda in 1973, she was replaced for a short period by Inger Brundin on a trip to West Germany.\nOfficial naming.\nIn 1973, Stig Anderson, tired of unwieldy names, started to refer to the group privately and publicly as ABBA (a palindrome). At first, this was a play on words, as Abba is also the name of a well-known fish-canning company in Sweden, and itself an abbreviation. However, since the fish-canners were unknown outside Sweden, Anderson came to believe the name would work in international markets. A competition to find a suitable name for the group was held in a Gothenburg newspaper and it was officially announced in the summer that the group were to be known as \"ABBA\". The group negotiated with the canners for the rights to the name. Fred Bronson reported for \"Billboard\" that F\u00e4ltskog told him in a 1988 interview that \"[ABBA] had to ask permission and the factory said, 'O.K., as long as you don't make us feel ashamed for what you're doing'\".\n\"ABBA\" is an acronym formed from the first letters of each group member's first name: Agnetha, Bj\u00f6rn, Benny, Anni-Frid, although there has never been any official confirmation of whom each letter in the sequence refers to. The earliest known example of \"ABBA\" written on paper is on a recording session sheet from the Metronome Studio in Stockholm dated 16 October 1973. This was first written as \"Bj\u00f6rn, Benny, Agnetha &amp; Frida\", but was subsequently crossed out with \"ABBA\" written in large letters on top.\nOfficial logo.\nTheir official logo, with its distinctive backward \"B\", was designed by Rune S\u00f6derqvist, who designed most of ABBA's record sleeves. The ambigram first appeared on the French compilation album \"Golden Double Album\", released in May 1976 by Disques Vogue, and would henceforth be used for all official releases.\nThe idea for the official logo was made by the German photographer Wolfgang \"Bubi\" Heilemann on a velvet jumpsuit photo shoot for the teenage magazine \"Bravo\". In the photo, the ABBA members held giant initial letters of their names. After the pictures were made, Heilemann found out that Benny Andersson had reversed his letter \"B\"; this prompted discussions about the mirrored \"B\", and the members of ABBA agreed on the mirrored letter. From 1976 onward, the first \"B\" in the logo version of the name was \"mirror-image\" reversed on the band's promotional material.\nFollowing their acquisition of the group's catalogue, PolyGram began using variations of the ABBA logo, employing a different font. In 1992, Polygram added a crown emblem to it for the first release of the \"ABBA Gold: Greatest Hits\" compilation. After Universal Music purchased PolyGram (and, thus, ABBA's label, Polar Music International), control of the group's catalogue returned to Stockholm. Since then, the original logo has been reinstated on all official products.\n1973\u20131976: Breakthrough.\nEurovision Song Contest 1974.\nABBA entered the Melodifestivalen with \"Ring Ring\", but the song did not qualify as the 1973 Swedish entry. Stig Anderson then started planning for the 1974 contest. Ulvaeus, Andersson, and Stig Anderson saw possibilities in using the Eurovision Song Contest to make the music business aware of them as songwriters, as well as to publicise the band. In late 1973 they were invited by Swedish television to contribute a song for Melodifestivalen 1974, and the upbeat song \"Waterloo\" was chosen. The group were now inspired by the growing glam rock scene in the UK.\nIn this, their third attempt, ABBA were more experienced and better prepared for the Eurovision Song Contest, and they won the nation's hearts on Swedish television on 9 February 1974. Winning the 1974 Eurovision Song Contest on 6 April 1974, and singing \"Waterloo\" in English instead of their native language, gave them the chance to tour Europe and perform on major television shows, as a result of which the \"Waterloo\" single charted in many European countries. After winning the contest, ABBA spent an evening of glory partying in the appropriately named first-floor Napoleon suite of The Grand Brighton Hotel.\n\"Waterloo\" was ABBA's first major hit and their first number-one single, in nine western and northern European countries, including the major markets of the UK and West Germany, and in South Africa. It made the top ten in other countries, rising to number three in Spain, number four in Australia and France, and number seven in Canada. In the United States, the song peaked at number six on the \"Billboard\" Hot 100 chart, paving the way for their first album and their first trip to the US as a group. Although only a short promotional visit, this included their first performance on American television, on \"The Mike Douglas Show\". The \"Waterloo\" album peaked at only number 145 on the \"Billboard\" 200 chart, but received unanimous praise from US critics. while \"Creem\" said it was \"a perfect blend of exceptional, lovable compositions\".\nABBA's follow-up single, \"Honey, Honey\", peaked at number 27 on the US \"Billboard\" Hot 100, reached the top twenty in several other countries, and was a number-two hit in West Germany, although it only reached the top 30 in Australia and the US. In the UK, ABBA's British record label, Epic, decided to re-release a remixed version of \"Ring Ring\" instead of \"Honey, Honey\". A cover version of \"Honey, Honey\" by Sweet Dreams peaked at number 10, and both records debuted on the UK chart within a week of each other. \"Ring Ring\" failed to reach the Top 30 in the UK, increasing growing speculation that the group were simply a Eurovision one-hit wonder.\nPost-Eurovision.\nIn November 1974, ABBA embarked on their first European tour, performing concerts in Denmark, West Germany, and Austria. The tour was less successful than the band had hoped, as most venues did not sell out. Due to low demand, they had to cancel several shows, including their only scheduled concert in Switzerland. The second leg of the tour, which took them through Scandinavia in January 1975, was very different. They played to full houses everywhere and finally got the reception they had hoped for. Live performances continued in the middle of 1975 when ABBA embarked on a fourteen-day open-air tour of Sweden and Finland. Their Stockholm show at the Gr\u00f6na Lund amusement park had an audience estimated at 19,200. Bj\u00f6rn Ulvaeus later said, \"If you look at the singles we released straight after Waterloo, we were trying to be more like the Sweet, a semi-glam rock group, which was stupid because we were always a pop group.\"\nIn late 1974, \"So Long\" was released as a single in the United Kingdom but received no airplay from Radio 1 and failed to chart in the UK; the only countries in which it was successful were Austria, Sweden, and Germany, reaching the top ten in the first two and number 21 in the latter. In the middle of 1975, ABBA released \"I Do, I Do, I Do, I Do, I Do\", which again received little airplay on Radio 1, but did manage to climb to number 38 on the UK chart, while making the top five in several northern and western European countries, and number one in South Africa. Later that year, the release of their self-titled third studio album and single \"SOS\" brought them back to chart presence in the UK, where the single hit number six and the album peaked at number 13. \"SOS\" also became ABBA's second number-one single in Germany and their third in Australia, and reached number two in several other European countries, including Italy.\nSuccess was further achieved with \"Mamma Mia\" reaching number one in the United Kingdom, Germany, and Australia and the top two in a few other western and northern European countries. In the United States, both \"I Do, I Do, I Do, I Do, I Do\" and \"SOS\" peaked at number 15 on the \"Billboard\" Hot 100 chart, with the latter picking up the BMI Award along the way as one of the most played songs on American radio in 1975. \"Mamma Mia\", however, stalled at number 32. In Canada, the three songs rose to number 12, nine, and 18, respectively.\nThe success of the group in the United States had until that time been limited to single releases. By early 1976, the group already had four Top 30 singles on the US charts, but the album market proved to be tough to crack. The eponymous \"ABBA\" album generated three American hits, but it only peaked at number 165 on the \"Cashbox\" album chart and number 174 on the \"Billboard\" 200 chart. Opinions were voiced, by \"Creem\" in particular, that in the US ABBA had endured \"a very sloppy promotional campaign\". Nevertheless, the group enjoyed warm reviews from the American press. \"Cashbox\" went as far as saying that \"there is a recurrent thread of taste and artistry inherent in Abba's marketing, creativity and presentation that makes it almost embarrassing to critique their efforts\", while \"Creem\" wrote: \"SOS is surrounded on this LP by so many good tunes that the mind boggles.\"\nIn Australia, the airing of the music videos for \"I Do, I Do, I Do, I Do, I Do\" and \"Mamma Mia\" on the nationally broadcast TV pop show \"Countdown\" saw the band rapidly gain enormous popularity, and \"Countdown\" become a key promoter of the group via their distinctive music videos. This led to an immense interest in ABBA in Australia, resulting in \"I Do, I Do, I Do, I Do, I Do\" staying at number one for three weeks, then \"SOS\" spending a week there, followed by \"Mamma Mia\" staying there for ten weeks, and the album holding down the number-one position for months. The three songs were also successful in nearby New Zealand, with the first two topping their chart and the third reaching number two.\n1976\u20131981: Superstardom.\n\"Greatest Hits\" and \"Arrival\".\nIn March 1976, the band released the compilation album \"Greatest Hits\". It became their first UK number-one album, and also took ABBA onto the Top 50 on the US album charts for the first time, with more than a million copies eventually being sold there. Also included on \"Greatest Hits\" was a new single, \"Fernando\", which went to number one in at least thirteen countries all over the world, including the UK, Germany, France, Australia, South Africa, and Mexico, and the top five in most other significant markets, including, at number four, becoming their biggest hit to date in Canada; the single went on to sell over 10\u00a0million copies worldwide.\nIn Australia, \"Fernando\" occupied the top position for a then record-breaking 14 weeks (and stayed on the chart for 40 weeks), and was the longest-running chart-topper there for over 40 years until it was overtaken by Ed Sheeran's \"Shape of You\" in May 2017. It remains one of the best-selling singles of all time in Australia. Also in 1976, the group received its first international prize, with \"Fernando\" being chosen as the \"Best Studio Recording of 1975\". In the United States, \"Fernando\" reached the Top 10 of the \"Cashbox\" Top 100 singles chart and number 13 on the \"Billboard\" Hot 100. It topped the \"Billboard\" Adult Contemporary chart, ABBA's first American number-one single on any chart. At the same time, a compilation named \"The Very Best of ABBA\" was released in Germany, becoming a number-one album there, whereas the \"Greatest Hits\" compilation which followed a few months later ascended to number two in Germany, despite all similarities with \"The Very Best\" album.\nThe group's fourth studio album, \"Arrival\", a number-one best-seller in parts of Europe, the UK, and Australia, and a number-three hit in Canada and Japan, represented a new level of accomplishment in both songwriting and studio work, prompting rave reviews from more rock-orientated UK music weeklies such as \"Melody Maker\" and \"New Musical Express\", and mostly appreciative notices from US critics.\nHit after hit flowed from \"Arrival\": \"Money, Money, Money\", another number one in Germany, France, Australia, and other countries of western and northern Europe, plus number three in the UK; and \"Knowing Me, Knowing You\", ABBA's sixth consecutive German number one, as well as another UK number one, plus a top-five hit in many other countries, although it was only a number-nine hit in Australia and France. The real sensation was the first single, \"Dancing Queen\", not only topping the charts in loyal markets such as the UK, Germany, Sweden, several other western and northern European countries, and Australia, but also reaching number one in the United States, Canada, the Soviet Union, and Japan, and the top ten in France, Spain, and Italy. All three songs were number-one hits in Mexico. In South Africa, ABBA had astounding success with each of \"Fernando\", \"Dancing Queen\" and \"Knowing Me, Knowing You\" being among the top 20 best-selling singles for 1976\u201377. In 1977, \"Arrival\" was nominated for the inaugural BRIT Award in the category Best International Album of the Year. By this time ABBA were popular in the UK, most of Europe, Australia, New Zealand, and Canada. In \"Frida \u2013 The DVD\", Lyngstad explains how she and F\u00e4ltskog developed as singers, as ABBA's recordings grew more complex over the years.\nThe band's mainstream popularity in the United States remained comparatively less, and \"Dancing Queen\" became the only \"Billboard\" Hot 100 number-one single for ABBA, with \"Knowing Me, Knowing You\" later peaking at number seven. \"Money, Money, Money\", however, had barely charted there or in Canada (where \"Knowing Me, Knowing You\" had reached number five). They did, however, get three more singles to the number-one position on other \"Billboard\" US charts, including \"Billboard\" Adult Contemporary and Hot Dance Club Play). Nevertheless, \"Arrival\" finally became a true breakthrough release for ABBA in the US album market, where it peaked at number 20 on the \"Billboard\" 200 chart and was certified gold by the RIAA.\nEuropean and Australian tour.\nIn January 1977, ABBA embarked on their first major tour. They opened their tour in Oslo, Norway, on 28 January, and mounted a spectacle that included a few scenes from their self-written mini-operetta \"The Girl with the Golden Hair\". The concert attracted media attention from across Europe and Australia. They continued the tour through Western Europe, visiting Gothenburg, Copenhagen, Berlin, Cologne, Amsterdam, Antwerp, Essen, Hanover, and Hamburg, and ending with shows in the United Kingdom in Manchester, Birmingham, Glasgow, and two sold-out concerts at London's Royal Albert Hall.\nAlong with praise (\"ABBA turn out to be amazingly successful at reproducing their records\", wrote \"Creem\"), there were complaints that \"ABBA performed slickly...but with a zero personality coming across from a total of 16 people on stage\" (\"Melody Maker\"). One of the Royal Albert Hall concerts was filmed as a reference for the filming of the Australian tour for what became \"\", though it is not exactly known how much of the concert was filmed.\nIn March 1977, after the European leg of the tour, ABBA played 11 dates in Australia before a total of 160,000 people. The opening concert in Sydney at the Sydney Showground on 3 March to an audience of 20,000 was marred by torrential rain, with Lyngstad slipping on the wet stage during the concert. However, all four members would later recall this concert as the most memorable of their careers.\nUpon their arrival in Melbourne, a civic reception was held at the Melbourne Town Hall and ABBA appeared on the balcony to greet an enthusiastic crowd of 6,000. In Melbourne, the group gave three concerts at the Sidney Myer Music Bowl with 14,500 at each, including the Australian Prime Minister Malcolm Fraser and his family. At the first Melbourne concert, an additional 16,000 people gathered outside the fenced-off area to listen to the concert. In Adelaide, the group performed one concert at Football Park in front of 20,000 people, with another 10,000 listening outside. During the first of five concerts in Perth, there was a bomb scare with everyone having to evacuate the Entertainment Centre. The trip was accompanied by mass hysteria and unprecedented media attention (\"Swedish ABBA stirs box-office in Down Under tour...and the media coverage of the quartet rivals that set to cover the upcoming Royal tour of Australia\", wrote \"Variety\"), and is captured on film in \"\", directed by Lasse Hallstr\u00f6m.\nThe Australian tour and its subsequent \"ABBA: The Movie\" produced some ABBA lore, as well. F\u00e4ltskog's blonde good looks had long made her the band's \"pin-up girl\", a role she disdained. During the Australian tour, she performed in a skin-tight white jumpsuit, causing one Australian newspaper to use the headline \"Agnetha's bottom tops dull show\". When asked about this at a news conference, she replied: \"Don't they have bottoms in Australia?\"\n\"ABBA: The Album\".\nIn December 1977, ABBA followed up \"Arrival\" with the more ambitious fifth album, \"\", which was released to coincide with the debut of \"ABBA: The Movie\". Although the album was less well received by UK reviewers, it did spawn more worldwide hits: \"The Name of the Game\" and \"Take a Chance on Me\", both of which topped the UK charts and racked up impressive sales in most countries, although \"The Name of the Game\" was generally the more successful in the Nordic countries and Australia, while \"Take a Chance on Me\" was more successful in North America and the German-speaking countries.\n\"The Name of the Game\" was a number-two hit in the Netherlands, Belgium, and Sweden while also making the Top 5 in Finland, Norway, New Zealand, and Australia, while only peaking at numbers 10, 12, and 15 in Mexico, the US, and Canada. \"Take a Chance on Me\" was a number-one hit in Austria, Belgium, and Mexico, and made the Top 3 in the US, Canada, the Netherlands, Germany, and Switzerland, while only reaching numbers 12 and 14 in Australia and New Zealand, respectively. Both songs were Top 10 hits in countries as far afield as Rhodesia and South Africa, as well as in France. Although \"Take a Chance on Me\" did not top the American charts, it proved to be ABBA's biggest hit single there, selling more copies than \"Dancing Queen\". The drop in sales in Australia was felt to be inevitable by industry observers as an \"Abba-Fever\" that had existed there for almost three years could only last so long as adolescents would naturally move away from a group so deified by both their parents and grandparents.\nA third single, \"Eagle\", was released in continental Europe and Australia becoming a number-one hit in Belgium and a Top 10 hit in the Netherlands, Germany, Switzerland, and South Africa, but barely charting in Australia. The B-side of \"Eagle\" was \"Thank You for the Music\", and it was belatedly released as an A-side single in both the United Kingdom and Ireland in 1983. \"Thank You for the Music\" became one of the best-loved and best-known ABBA songs, without being released as a single during the group's lifetime. \"ABBA: The Album\" topped the album charts in the UK, the Netherlands, New Zealand, Sweden, Norway, and Switzerland, while ascending to the Top 5 in Australia, Germany, Austria, Finland, and Rhodesia, and making the Top 10 in Canada and Japan. Sources also indicate that sales in Poland exceeded 1 million copies and that demand in Russia could not be met by the supply available. The album peaked at number 14 in the US.\nPolar Music Studio formation.\nBy 1978, ABBA had become one of the most prominent bands worldwide. They converted a vacant cinema into the Polar Music Studio, a state-of-the-art studio in Stockholm. The studio was used by several other bands: notably, Genesis' \"Duke\", Led Zeppelin's \"In Through the Out Door\" and Scorpions's \"Lovedrive\" were recorded there. During May 1978, the group went to the United States for a promotional campaign, performing alongside Andy Gibb on Olivia Newton-John's TV show. Recording sessions for the single \"Summer Night City\" were an uphill struggle, but upon release the song became another hit for the group. The track set the stage for ABBA's foray into disco with their next album.\nOn 9 January 1979, the group performed \"Chiquitita\" at the Music for UNICEF Concert held at the United Nations General Assembly to celebrate UNICEF's Year of the Child. ABBA donated the copyright of this worldwide hit to the UNICEF; see Music for UNICEF Concert. The single was released the following week, and reached number one in ten countries.\nNorth American and European tours.\nIn mid-January 1979, Ulvaeus and F\u00e4ltskog announced their divorce, attracting significant media attention and sparking speculation about the band's future. However, ABBA reassured both the press and their fans that they would continue working together as a group and that the divorce would not impact their collaboration. Despite these assurances, the media continued to question them about the situation during interviews. To avoid the ongoing attention and to focus on songwriting, Andersson and Ulvaeus discreetly travelled to Compass Point Studios in Nassau, Bahamas, where they spent two weeks working on material for their next album.\nThe group's sixth studio album, \"Voulez-Vous\", was released in April 1979, with its title track recorded at the renowned Criteria Studios in Miami, Florida, with the assistance of recording engineer Tom Dowd, among others. The album topped the charts across Europe and in Japan and Mexico, hit the Top 10 in Canada and Australia, and the Top 20 in the US. While none of the singles from the album reached number one on the UK chart, the lead single, \"Chiquitita\", and the fourth single, \"I Have a Dream\", both ascended to number two. The other two, \"Does Your Mother Know\" and \"Angeleyes\" (with \"Voulez-Vous\", released as a double A-side) both made the top 5. All four singles reached number one in Belgium, although the last three did not chart in Sweden or Norway. \"Chiquitita\", which was featured in the \"Music for UNICEF Concert\", after which ABBA decided to donate half of the royalties from the song to UNICEF, topped the singles charts in the Netherlands, Switzerland, Finland, Spain, Mexico, South Africa, Rhodesia, and New Zealand, rose to number two in Sweden, and made the Top 5 in Germany, Austria, Norway, and Australia, although it only reached number 29 in the US.\n\"I Have a Dream\" was a significant success, reaching number one in the Netherlands, Switzerland, and Austria, number three in South Africa, and number four in Germany, although it only reached number 64 in Australia. In Canada, \"I Have a Dream\" became ABBA's second number one on the \"RPM\" Adult Contemporary chart (after \"Fernando\" hit the top previously) although it did not chart in the US. \"Does Your Mother Know\", a rare song in which Ulvaeus sings lead vocals, was a Top 5 hit in the Netherlands and Finland, and a Top 10 hit in Germany, Switzerland, and Australia, although it only reached number 27 in New Zealand. It did better in North America than \"Chiquitita\", reaching number 12 in Canada and number 19 in the US, and made the Top 20 in Japan. \"Voulez-Vous\" was a Top 10 hit in the Netherlands and Switzerland, a Top 20 hit in Germany and Finland, but only peaked in the 80s in Australia, Canada, and the US.\nAlso in 1979, the group released their second compilation album, \"Greatest Hits Vol. 2\", which featured a brand-new track: \"Gimme! Gimme! Gimme! (A Man After Midnight)\", which was a Top 3 hit in the UK, Belgium, the Netherlands, Germany, Austria, Switzerland, Finland, and Norway, and returned ABBA to the Top 10 in Australia. \"Greatest Hits Vol. 2\" went to number one in the UK, Belgium, Canada, and Japan while making the Top 5 in several other countries, but only reaching number 20 in Australia and number 46 in the US. In the Soviet Union during the late 1970s, the group were paid in oil commodities because of an embargo of the rouble.\nOn 13 September 1979, ABBA began at Northlands Coliseum in Edmonton, Canada, with a full house of 14,000. \"The voices of the band, Agnetha's high sauciness combined with round, rich lower tones of Anni-Frid, were excellent...Technically perfect, melodically correct and always in perfect pitch...The soft lower voice of Anni-Frid and the high, edgy vocals of Agnetha were stunning\", raved the \"Edmonton Journal\".\nDuring the next four weeks they played 17 sold-out dates, 13 in the United States and four in Canada. The last scheduled ABBA concert in the United States, in Washington, D.C., was cancelled due to emotional distress F\u00e4ltskog experienced during the flight from New York to Boston. The group's private plane was subjected to extreme weather conditions and was unable to land for an extended period. They appeared at the Boston Music Hall for the performance 90 minutes late. The tour ended with a show in Toronto, Canada, at Maple Leaf Gardens before a capacity crowd of 18,000. \"ABBA plays with surprising power and volume; but although they are loud, they're also clear, which does justice to the signature vocal sound... Anyone who's been waiting five years to see Abba will be well satisfied\", wrote \"Record World\". On 19 October 1979, the tour resumed in Western Europe where the band played 23 sold-out gigs, including six sold-out nights at London's Wembley Arena.\nProgression.\nIn March 1980, ABBA travelled to Japan, where they were greeted by thousands of fans upon their arrival at Narita International Airport. The group performed eleven concerts, each to sold-out audiences, including six shows at Tokyo's Budokan. This tour was the last \"on the road\" adventure of their career.\nIn July 1980, ABBA released the single \"The Winner Takes It All\", the group's eighth UK chart topper (and their first since 1978). The song is widely misunderstood as being written about Ulvaeus and F\u00e4ltskog's marital tribulations: Ulvaeus wrote the lyrics, but has stated they were not about his own divorce; F\u00e4ltskog has repeatedly stated she was not the loser in their divorce. In the United States, the single peaked at number eight on the \"Billboard\" Hot 100 chart and became ABBA's second \"Billboard\" Adult Contemporary number one. It was also re-recorded by Andersson and Ulvaeus, with a slightly different backing track by French chanteuse Mireille Mathieu, at the end of 1980\u00a0\u2013 as \"Bravo tu as gagn\u00e9\", with French lyrics by Alain Boublil.\nIn November 1980, ABBA's seventh album, \"Super Trouper\", was released, which reflected a certain change in ABBA's style, with more prominent use of synthesisers and increasingly personal lyrics. It set a record for the most pre-orders ever received for a UK album after one million copies were ordered before release. The second single from the album, \"Super Trouper\", also hit number one in the UK, becoming the group's ninth and final UK chart-topper. Another track from the album, \"Lay All Your Love on Me\", was released in 1981 as a twelve-inch single only in selected territories; it topped the \"Billboard\" Hot Dance Club Play chart and peaked at number seven on the UK singles chart, becoming, at the time, the highest-charting 12-inch release in UK chart history.\nAlso in 1980, ABBA recorded a compilation of Spanish-language versions of their hits, called \"Gracias Por La M\u00fasica\". This was released in Spanish-speaking countries, as well as in Japan and Australia. The album became a major success; and along with the Spanish version of \"Chiquitita\", this signalled the group's breakthrough in Latin America. \"ABBA Oro: Grandes \u00c9xitos\", the Spanish equivalent of \"ABBA Gold: Greatest Hits\", was released in 1999.\n1981\u20131982: \"The Visitors\" and later performances.\nIn January 1981, Ulvaeus married Lena K\u00e4llersj\u00f6, and manager Stig Anderson celebrated his 50th birthday with a party. For this occasion, ABBA recorded the track \"Hovas Vittne\" (a pun on the Swedish name for Jehovah's Witness and Anderson's birthplace, Hova) as a tribute to him, and released it only on 200 red vinyl copies, to be distributed to the guests attending the party. This single has become a sought-after collectible. In mid-February 1981, Andersson and Lyngstad announced they were filing for divorce. Information surfaced that their marriage had been a struggle for years, and that Benny had already met another woman, Mona N\u00f6rklit, whom he married in November 1981.\nAndersson and Ulvaeus had songwriting sessions in early 1981, and recording sessions began in mid-March. At the end of April, the group recorded a TV special, \"Dick Cavett Meets ABBA\", with the US talk-show host Dick Cavett. \"The Visitors\", ABBA's eighth studio album, showed more maturity and depth of feeling than many of their earlier recordings did, but still had pop music's catchy tunes and harmonies. Although not revealed at the time of its release, the album's title track, according to Ulvaeus, refers to the secret meetings held against the approval of totalitarian governments in Soviet-dominated states, while other tracks address topics such as failed relationships, the threat of war, ageing, and loss of innocence. The album's only major single release, \"One of Us\", proved to be the last of ABBA's nine number-one singles in Germany, this being in December 1981, and the swan song of their sixteen Top 5 singles on the South African chart. \"One of Us\" was also ABBA's final Top 3 hit in the UK, reaching number three on the UK Singles Chart.\nAlthough it topped the album charts across most of Europe, including Ireland, the UK, and Germany, \"The Visitors\" was not as commercially successful as its predecessors, showing a commercial decline in France, Australia, and Japan. A track from the album, \"When All Is Said and Done\", was released as a single in North America, Australia, and New Zealand, and fittingly became ABBA's final Top 40 hit in the US (debuting on the US charts on 31 December 1981), while also reaching the US Adult Contemporary Top 10, and number four on the \"RPM\" Adult Contemporary chart in Canada. The song's lyrics, as with \"The Winner Takes It All\" and \"One of Us\", dealt with the painful experience of separating from a long-term partner, though it looked at the trauma more optimistically. With the now publicised story of Andersson and Lyngstad's divorce, speculation increased of tension within the band. Also released in the United States was the title track of \"The Visitors\", which hit the Top Ten on the \"Billboard\" Hot Dance Club Play chart.\nLater recording sessions.\nIn the spring of 1982, songwriting sessions had started, and the group came together for more recordings. Plans were not completely clear, but a new album was discussed and the prospect of a small tour was suggested. The recording sessions in May and June 1982 were a struggle, and only three songs were eventually recorded: \"You Owe Me One\", \"I Am the City\", and \"Just Like That\". Andersson and Ulvaeus were not satisfied with the outcome, so the tapes were shelved and the group took a break for the summer.\nBack in the studio again in early August, the group had changed plans for the rest of the year: they settled for a Christmas release of a double-album compilation of all their past single releases, to be named \"\". New songwriting and recording sessions took place; and during October and December, they released the singles \"The Day Before You Came\"/\"Cassandra\" and \"Under Attack\"/\"You Owe Me One\", the A-sides of which were included on the compilation album. Neither single made the Top 20 in the United Kingdom, though \"The Day Before You Came\" became a Top 5 hit in many European countries, such as Germany, the Netherlands, and Belgium. The album went to number one in the UK and Belgium, Top 5 in the Netherlands and Germany, and Top 20 in many other countries. \"Under Attack\", the group's final release before disbanding, was a Top 5 hit in the Netherlands and Belgium.\n\"I Am the City\" and \"Just Like That\" were left unreleased on \"The Singles: The First Ten Years\" for possible inclusion on the next projected studio album, though this never came to fruition. \"I Am the City\" was eventually released on the compilation album \"\" in 1993, while \"Just Like That\" has been recycled into new songs with other artists produced by Andersson and Ulvaeus. A reworked version of the verses ended up in the musical \"Chess\". The chorus section of \"Just Like That\" was eventually released on a retrospective box set in 1994, as well as in the \"ABBA Undeleted\" medley featured on disc 9 of \"The Complete Studio Recordings\". Despite a number of requests from fans, Ulvaeus and Andersson are still refusing to release ABBA's version of \"Just Like That\" in its entirety, even though the complete version has surfaced on bootlegs.\nThe group travelled to London to promote \"The Singles: The First Ten Years\" in the first week of November 1982, appearing on \"Saturday Superstore\" and \"The Late, Late Breakfast Show\", and also to West Germany in the second week, to perform on \"Show-Express\". On 19 November 1982, ABBA appeared for the last time in Sweden on the TV programme \"N\u00f6jesmaskinen\", and on 11 December 1982, they gave their last performance ever, transmitted to the UK on Noel Edmonds' \"The Late, Late Breakfast Show\", through a live link from a TV studio in Stockholm.\nLater performances.\nIn early 1983, Andersson and Ulvaeus began collaborating with Tim Rice on writing songs for the musical project \"Chess\", while F\u00e4ltskog and Lyngstad both concentrated on international solo careers. While Andersson and Ulvaeus were working on the musical, a further co-operation among the three of them came with the musical \"Abbacadabra\" that was produced in France for television. It was a children's musical using 14\u00a0ABBA songs. Alain and Daniel Boublil, who wrote \"Les Mis\u00e9rables\", had been in touch with Stig Anderson about the project, and the TV musical was aired over Christmas on French TV, and later a Dutch version was also broadcast. Boublil previously also wrote the French lyric for Mireille Mathieu's version of \"The Winner Takes It All\".\nLyngstad, who had recently moved to Paris, participated in the French version, and recorded a single, \"Belle\", a duet with French singer Daniel Balavoine. The song was a cover of ABBA's 1976 instrumental track \"Arrival\". As the single \"Belle\" sold well in France, Cameron Mackintosh wanted to stage an English-language version of the show in London, with the French lyrics translated by David Wood and Don Black; Andersson and Ulvaeus got involved in the project, and contributed one new song, \"I Am the Seeker\". \"Abbacadabra\" premiered on 8 December 1983 at the Lyric Hammersmith Theatre in London, to mixed reviews and full houses for eight weeks, closing on 21 January 1984. Lyngstad was also involved in this production, recording \"Belle\" in English as \"Time\", as a duet with actor and singer B. A. Robertson: the single sold well and was produced and recorded by Mike Batt. In May 1984, Lyngstad performed \"I Have a Dream\" with a children's choir at the United Nations Organisation Gala, in Geneva, Switzerland.\nAll four members made their (at the time, final) public appearance as four friends more than as ABBA in January 1986, when they recorded a video of themselves performing an acoustic version of \"Tivedshambo\" (which was the first song written by their manager Stig Anderson) for a Swedish TV show honouring Anderson on his 55th birthday. The four had not seen each other for more than two years. That same year they also performed privately at another friend's 40th birthday: their old tour manager, Claes af Geijerstam. They sang a self-written song titled \"Der Kleine Franz\" that was later to resurface in \"Chess\". Also in 1986, \"ABBA Live\" was released, featuring selections of live performances from the group's 1977 and 1979 tours. The four members were guests at the 50th birthday of G\u00f6rel Hanser in 1999. Hanser was a long-time friend of all four, and also former secretary of Stig Anderson. Honouring G\u00f6rel, ABBA performed a Swedish birthday song \"Med en enkel tulipan\" a cappella.\nAndersson has on several occasions performed ABBA songs. In June 1992, he and Ulvaeus appeared with U2 at a Stockholm concert, singing the chorus of \"Dancing Queen\", and a few years later, during the final performance of the B &amp; B in Concert in Stockholm, Andersson joined the cast for an encore at the piano. Andersson frequently adds an ABBA song to the playlist when he performs with his BAO band. He also played the piano during new recordings of the ABBA songs \"Like an Angel Passing Through My Room\" with opera singer Anne Sofie von Otter, and \"When All Is Said and Done\" with Swede Viktoria Tolstoy. In 2002, Andersson and Ulvaeus both performed an a cappella rendition of the first verse of \"Fernando\" as they accepted their Ivor Novello award in London. Lyngstad performed and recorded an a cappella version of \"Dancing Queen\" with the Swedish group the Real Group in 1993, and also re-recorded \"I Have a Dream\" with Swiss singer Dan Daniell in 2003.\nBreak and reunion.\nABBA never officially announced the end of the group or an indefinite break, but it was long considered dissolved after their final public performance together in 1982. Their final public performance together as ABBA, before their 2016 reunion, was on the British TV programme \"The Late, Late Breakfast Show\" (live from Stockholm) on 11 December 1982. While reminiscing on \"The Day Before You Came\", Ulvaeus said: \"we might have continued for a while longer if that had been a number one\".\nIn January 1983, F\u00e4ltskog started recording sessions for a solo album, as Lyngstad had successfully released her album \"Something's Going On\" some months earlier. Ulvaeus and Andersson, meanwhile, started songwriting sessions for the musical \"Chess\". In interviews at the time, Bj\u00f6rn and Benny denied that ABBA had split up (\"Who are we without our ladies? Initials of Brigitte Bardot?\"), and during 1983 and 1984 Lyngstad and F\u00e4ltskog kept claiming in interviews that ABBA would come together for a new album. Internal strife between the group and their manager escalated and in 1983 the band members sold their shares in Polar Music. Except for a TV appearance in 1986, the foursome did not come together publicly again until they were reunited at the Swedish premiere of the \"Mamma Mia!\" musical on 14 February 2005. The individual members' endeavours shortly before and after their final public performance, coupled with the collapse of both marriages and the lack of significant activity in the following few years, widely suggested that the group had broken up.\nIn an interview with \"The Sunday Telegraph\", Ulvaeus and Andersson said that there was nothing that could entice them back on stage again. Ulvaeus said: \"We will never appear on stage again. [...] There is simply no motivation to re-group. Money is not a factor and we would like people to remember us as we were. Young, exuberant, full of energy and ambition. I remember Robert Plant saying Led Zeppelin were a cover band now because they cover all their own stuff. I think that hit the nail on the head.\"\nHowever, on 3 January 2011, F\u00e4ltskog, long considered to be the most reclusive member of the group and a major obstacle to any reunion, raised the possibility of reuniting for a one-off engagement. She admitted that she had not yet brought the idea up to the other three members. In April 2013, she reiterated her hopes for reunion during an interview with \"Die Zeit\", stating: \"If they ask me, I'll say yes.\"\nIn a May 2013 interview, F\u00e4ltskog, aged 63 at the time, stated that an ABBA reunion would never occur: \"I think we have to accept that it will not happen, because we are too old and each one of us has their own life. Too many years have gone by since we stopped, and there's really no meaning in putting us together again\". F\u00e4ltskog further explained that the band members remained on amicable terms: \"It's always nice to see each other now and then and to talk a little and to be a little nostalgic.\" In an April 2014 interview, F\u00e4ltskog, when asked about whether the band might reunite for a new recording said: \"It's difficult to talk about this because then all the news stories will be: 'ABBA is going to record another song!' But as long as we can sing and play, then why not? I would love to, but it's up to Bj\u00f6rn and Benny.\"\nResurgence of public interest.\nThe same year the members of ABBA went their separate ways, the French production of a \"tribute\" show (a children's TV musical named \"Abbacadabra\" using 14 ABBA songs) spawned new interest in the group's music.\nAfter receiving little attention during the mid-to-late-1980s, ABBA's music experienced a resurgence in the early 1990s due to the UK synth-pop duo Erasure, who released \"Abba-esque\", a four-track extended play release featuring cover versions of ABBA songs, which topped several European charts in 1992. As U2 arrived in Stockholm for a concert in June of that year, the band paid homage to ABBA by inviting Bj\u00f6rn Ulvaeus and Benny Andersson to join them on stage for a rendition of \"Dancing Queen\", to play guitar and keyboards. September 1992 saw the release of ', a new compilation album. The single \"Dancing Queen\" received radio airplay in the UK in the middle of 1992 to promote the album. The song returned to the Top 20 of the UK singles chart in August that year, this time peaking at number 16. With sales of 30 million, \"Gold\" is the best-selling ABBA album, as well as one of the best-selling albums worldwide. With sales of 5.5\u00a0million copies it is the second-highest-selling album of all time in the UK, after Queen's \"Greatest Hits\". ', a follow-up to \"Gold\", was released in 1993.\nIn 1994, two Australian cult films caught the attention of the world's media, both focusing on admiration for ABBA: \"The Adventures of Priscilla, Queen of the Desert\" and \"Muriel's Wedding\". The same year, \"Thank You for the Music\", a four-disc box set comprising all the group's hits and stand-out album tracks, was released with the involvement of all four members. \"By the end of the twentieth century\", American critic Chuck Klosterman wrote a decade later, \"it was far more contrarian to hate ABBA than to love them.\"\nTwo different compilation albums of ABBA songs have been released. \"ABBA: A Tribute\" coincided with the 25th anniversary celebration and featured 17 songs, some of which were recorded especially for this release. Notable tracks include Go West's \"One of Us\", Army of Lovers' \"Hasta Ma\u00f1ana\", Information Society's \"Lay All Your Love on Me\", Erasure's \"Take a Chance on Me\" (with MC Kinky), and Lyngstad's a cappella duet with the Real Group of \"Dancing Queen\". A second 12-track album was released in 1999, titled \"ABBAmania\", with proceeds going to the Youth Music charity in England. It featured all new cover versions: notable tracks were by Madness (\"Money, Money, Money\"), Culture Club (\"Voulez-Vous\"), the Corrs (\"The Winner Takes It All\"), Steps (\"Lay All Your Love on Me\", \"I Know Him So Well\"), and a medley titled \"Thank ABBA for the Music\" performed by several artists and as featured on the Brits Awards that same year.\nIn 1998, an ABBA tribute group was formed, the ABBA Teens, which was subsequently renamed the A-Teens to allow the group some independence. The group's first album, \"The ABBA Generation\", consisting solely of ABBA covers reimagined as 1990s pop songs, was a worldwide success and so were subsequent albums. The group disbanded in 2004 due to a gruelling schedule and members' intentions to go solo. In Sweden, the growing recognition of the legacy of Andersson and Ulvaeus resulted in the 1998 \"B &amp; B Concerts\", a tribute concert (with Swedish singers who had worked with the songwriters through the years) showcasing not only their ABBA years, but hits both before and after ABBA. The concert was a success and was ultimately released on CD. The singers later toured Scandinavia and even went to Beijing in the People's Republic of China for two concerts. In 2000, ABBA were reported to have turned down an offer of approximately one billion US dollars to do a reunion tour consisting of 100 concerts.\nSince 2000, the official International ABBA Fan Club has held \"International ABBA Day\" celebrations on 12 April.\nFor the semi-final of the Eurovision Song Contest 2004, staged in Istanbul 30 years after ABBA had won the contest in Brighton, all four members made cameo appearances in a special comedy video made for the interval act, titled \"Our Last Video Ever\". Other well-known stars such as Rik Mayall, Cher, and Iron Maiden's Eddie also made appearances in the video. It was not included in the official DVD release of the 2004 Eurovision contest, but was issued as a separate DVD release, retitled \"The Last Video\" at the request of the former ABBA members. The video was made using puppet models of the members of the band. It has surpassed 13 million views on YouTube as of November 2020.\nIn 2005, all four members of ABBA appeared at the Stockholm premiere of the musical \"Mamma Mia!\". On 22 October 2005, at the , \"Waterloo\" was chosen as the best song in the competition's history. In the same month, American singer Madonna released the single \"Hung Up\", which contains a sample of the keyboard melody from ABBA's 1979 song \"Gimme! Gimme! Gimme! (A Man After Midnight)\"; the song was a smash hit, peaking at number one in at least 50 countries. On 4 July 2008, all four ABBA members were reunited at the Swedish premiere of the film \"Mamma Mia!\". It was the second time all of them had appeared together in public since 1986. During the appearance, they re-emphasised that they intended never to officially reunite, citing the opinion of Robert Plant that the re-formed Led Zeppelin was more like a cover band of itself than the original band. Ulvaeus stated that he wanted the band to be remembered as they were during the peak years of their success.\n\"Gold\" returned to number one in the UK album charts for the fifth time on 3 August 2008. On 14 August 2008, the \"Mamma Mia! The Movie\" film soundtrack went to number one on the US \"Billboard\" charts, ABBA's first US chart-topping album. During the band's heyday, the highest album chart position they had achieved in America was number 14. In November 2008, all eight studio albums, together with a ninth of rare tracks, were released as \"The Albums\". It hit several charts, peaking at number four in Sweden and reaching the Top 10 in several other European territories.\nIn 2008, Sony Computer Entertainment Europe, in collaboration with Universal Music Group Sweden AB, released \"SingStar ABBA\" on both the PlayStation 2 and PlayStation 3 game consoles, as part of the SingStar music video games. The PS2 version features 20 ABBA songs, while 25 songs were featured on the PS3 version.\nOn 22 January 2009, F\u00e4ltskog and Lyngstad appeared together on stage to receive the Swedish music award \"Rockbj\u00f6rnen\" (for \"lifetime achievement\"). In an interview, the two women expressed their gratitude for the honorary award and thanked their fans. On 25 November 2009, PRS for Music announced that the British public voted ABBA as the band they would most like to see re-form. On 27 January 2010, ABBAWORLD, a 25-room touring exhibition featuring interactive and audiovisual activities, debuted at Earls Court Exhibition Centre in London. According to the exhibition's website, ABBAWORLD is \"approved and fully supported\" by the band members.\n\"Mamma Mia\" was released as one of the first few non-premium song selections for the online RPG game \"Bandmaster\". On 17 May 2011, \"Gimme! Gimme! Gimme!\" was added as a non-premium song selection for the Bandmaster Philippines server. On 15 November 2011, Ubisoft released a dancing game called \"\" for Wii. In January 2012, Universal Music announced the re-release of ABBA's final album, \"The Visitors\", which featured a previously unheard track \"From a Twinkling Star to a Passing Angel\".\nA book titled \"ABBA: The Official Photo Book\" was published in early 2014 to mark the 40th anniversary of the band's Eurovision victory. The book reveals that part of the reason for the band's outrageous costumes was that Swedish tax laws at the time allowed the cost of garish outfits that were not suitable for daily wear to be tax deductible.\n2016\u20132024: Reunion, \"Voyage\", and ABBAtars.\nOn 20 January 2016, all four members of ABBA made a public appearance at \"Mamma Mia! The Party\" in Stockholm. On 6 June 2016, the quartet appeared together at a private party at Berns Salonger in Stockholm, which was held to celebrate the 50th anniversary of Andersson and Ulvaeus's first meeting. F\u00e4ltskog and Lyngstad performed live, singing \"The Way Old Friends Do\" before they were joined on stage by Andersson and Ulvaeus.\nBritish manager Simon Fuller announced in a statement in October 2016 that the group would be reuniting to work on a new \"digital entertainment experience\". The project would feature the members in their \"life-like\" avatar form, called \"ABBAtars\", based on and would be set to launch by the spring of 2019.\nIn May 2017, a sequel to the 2008 movie \"Mamma Mia!\", titled \"Mamma Mia! Here We Go Again\", was announced; the film was released on 20 July 2018. Cher, who appeared in the movie, also released \"Dancing Queen\", an ABBA cover album, in September 2018. In June 2017, a blue plaque outside Brighton Dome was placed to commemorate their 1974 Eurovision win.\nOn 27 April 2018, all four original members of ABBA made a joint announcement that they had recorded two new songs, titled \"I Still Have Faith in You\" and \"Don't Shut Me Down\", to feature in a TV special set to air later that year. In September 2018, Ulvaeus stated that the two new songs, as well as the TV special, now called \"\", would not be released until 2019. The TV special was later revealed to be scrapped by 2018, as Andersson and Ulvaeus rejected Fuller's project, and instead partnered with visual effects company Industrial Light and Magic to prepare the ABBAtars for a music video and a concert. In January 2019, it was revealed that neither song would be released before the summer. Andersson hinted at the possibility of a third song.\nIn June 2019, Ulvaeus announced that the first new song and video containing the ABBAtars would be released in November 2019. In September, he stated in an interview that there were now five new ABBA songs to be released in 2020. In early 2020, Andersson confirmed that he was aiming for the songs to be released in September 2020.\nIn April 2020, Ulvaeus gave an interview saying that in the wake of the COVID-19 pandemic, the avatar project had been delayed. Five out of the eight original songs written by Benny for the new album had been recorded by the two female members, and the release of a new \u00a315\u00a0million music video with new unseen technology was under consideration. In May 2020, it was announced that ABBA's entire studio discography would be released on coloured vinyl for the first time, in a box set titled \"ABBA: The Studio Albums\". In July 2020, Ulvaeus revealed that the release of the new ABBA recordings had been delayed until 2021.\nOn 22 September 2020, all four ABBA members reunited at Ealing Studios in London to continue working on the avatar project and filming for the tour. Ulvaeus confirmed that the avatar tour would be scheduled for 2022. When questioned if the new recordings were definitely coming out in 2021, Bj\u00f6rn said, \"There will be new music this year, that is definite, it's not a case anymore of it might happen, it will happen.\"\nOn 26 August 2021, a new website was launched, with the title \"ABBA Voyage\". On the page, visitors were prompted to subscribe \"to be the first in line to hear more about \"ABBA Voyage\"\". Simultaneously with the launch of the webpage, new \"ABBA Voyage\" social media accounts were launched, and billboards around London started to appear, all showing the date \"02.09.21\", leading to expectation of what was to be revealed on that date. On 29 August, the band officially joined TikTok with a video of Benny Andersson playing \"Dancing Queen\" on the piano, and media reported on a new album to be announced on 2 September. On that date, \"Voyage\", their first new album in 40 years, was announced for release on 5 November 2021, along with ABBA Voyage, a concert residency in a custom-built venue at Queen Elizabeth Olympic Park in London featuring the motion capture digital avatars of the four band members alongside a 10-piece live band, starting 27 May 2022. F\u00e4ltskog stated that the \"Voyage\" album and concert residency were likely to be their last activity as a group.\nThe announcement of the new album was accompanied by the release of the singles \"I Still Have Faith in You\" and \"Don't Shut Me Down\". The music video for \"I Still Have Faith in You\", featuring footage of the band during their performing years and a first look at the ABBAtars, earned over a million views in its first three hours. \"Don't Shut Me Down\" became the first ABBA release since October 1978 to top the singles chart in Sweden. In October 2021, the third single, \"Just a Notion\", was released, and it was announced that ABBA would split for good after the release of \"Voyage\". However, in an interview with BBC Radio 2 on 11 November, Lyngstad stated \"don't be too sure\" that \"Voyage\" is the final ABBA album. Also, in an interview with BBC News on 5 November, Andersson stated \"if they [the ladies] twist my arm I might change my mind.\" The fourth single from the album, \"Little Things\", was released on 3 December.\nIn May 2022, after the premiere of ABBA Voyage, Andersson stated in an interview with \"Variety\" that \"nothing is going to happen after this\", confirming the residency as ABBA's final group collaboration. In April 2023, longtime ABBA guitarist Lasse Wellander died at the age of 70; Wellander played on seven of the group's nine studio albums, including \"Voyage\".\nOn 21 March 2024, shortly before the 50th anniversary of their win at the Eurovision Song Contest, all four ABBA members were appointed Commander, First Class, of the Royal Order of Vasa by King Carl XVI Gustaf of Sweden. This was the first time in almost 50 years that a Swedish order of knighthood was bestowed on Swedes. ABBA shared the honour with nine other people. They ruled out a reunion at the Eurovision Song Contest 2024 in Malm\u00f6; however, during the final of the contest, a clip from ABBA Voyage was shown, combined with archival footage of their 1974 performance of \"Waterloo\" at the contest and with Charlotte Perrelli, Carola, and Conchita Wurst performing \"Waterloo\" on stage as part of the interval.\nArtistry.\nRecording process.\nABBA were perfectionists in the studio, working on tracks until they got them right, rather than leaving them to come back to later. They spent the bulk of their time within the studio; in separate 2021 interviews Ulvaeus stated they may have toured for only 6 months, while Andersson said they played fewer than 100 shows during the band's career. However, counting shorter 30- to 60-minute concerts during their Folkpark tours, the group in fact played over 200 shows.\nThe band created a basic rhythm track with a drummer, guitarist, and bass player, and overlaid other arrangements and instruments. Vocals were then added, and orchestra overdubs were usually left until last.\nF\u00e4ltskog and Lyngstad contributed ideas at the studio stage. Andersson and Ulvaeus played them the backing tracks, and they made comments and suggestions. According to F\u00e4ltskog, she and Lyngstad had the final say in how the lyrics were shaped.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;When we gather around the piano to get our voices tuned up, we often come up with things we can use in the backing vocals.\nAfter vocals and overdubs were done, the band took up to five days to mix a song.\nFashion, style, videos, advertising campaigns.\nABBA members were widely noted for their colourful and trend-setting costumes. The reason for the wild costumes was Swedish tax law: the cost of the clothes was deductible only if they could not be worn other than for performances. In their early years, group member Anni-Frid Lyngstad designed and even hand-sewed the outfits. Later, as their success grew, they used professional theatrical clothes designer Owe Sandstr\u00f6m together with tailor Lars Wigenius with Lyngstad continuing to suggest ideas while co-ordinating the outfits with concert set designs. Choreography by Graham Tainton also contributed to their performance style.\nThe videos that accompanied some of the band's biggest hits are often cited as some of the earliest examples of the genre. Most of ABBA's videos (and \"ABBA: The Movie\") were directed by Lasse Hallstr\u00f6m, who would later direct the films \"My Life as a Dog\", \"The Cider House Rules\", and \"Chocolat\".\nABBA made videos because their songs were hits in numerous different countries and personal appearances were not always possible. This was also done in an effort to minimise travelling, particularly to countries that would have required extremely long flights. F\u00e4ltskog and Ulvaeus had two young children and F\u00e4ltskog, who was also afraid of flying, was reluctant to leave her children for such a long time. ABBA's manager, Stig Anderson, realised the potential of showing a simple video clip on television to publicise a single or album, thereby allowing easier and quicker exposure than a concert tour. Some of these videos have become classics because of the 1970s-era costumes and early video effects, such as the grouping of the band members in different combinations of pairs, overlapping one singer's profile with the other's full face, and the contrasting of one member with another.\nIn 1976, ABBA participated in an advertising campaign to promote the Matsushita Electric Industrial Co.'s brand, National, in Australia. The campaign was also broadcast in Japan. Five commercial spots, each of approximately one minute, were produced, each presenting the \"National Song\" performed by ABBA using the melody and instrumental arrangements of \"Fernando\" and revised lyrics.\nPolitical use of ABBA's music.\nJohn McCain used the song \"Take a Chance on Me\" for his 2008 presidential campaign. McCain publicly expressed his liking for the band.\nIn September 2010, band members Andersson and Ulvaeus criticised the right-wing Danish People's Party (DF) for using the ABBA song \"Mamma Mia\" (with modified lyrics referencing Pia Kj\u00e6rsgaard) at rallies. The band threatened to file a lawsuit against the DF, saying they never allowed their music to be used politically and that they had absolutely no interest in supporting the party. Their record label Universal Music later stated that no legal action would be taken because an agreement had been reached.\nIn August 2024, after Donald Trump played several of their songs and used footage of the group at a campaign rally, ABBA demanded that Trump stop using their music. Their record company, Universal Music, said they had not been asked for permission to use ABBA music or videos by the Trump campaign and demanded that footage from the event must be \"immediately taken down and removed\".\nSuccess in the United States.\nDuring their active career, from 1972 to 1982, 20 of ABBA's singles entered the \"Billboard\" Hot 100; 14 of these made the Top 40 (13 on the \"Cashbox\" Top 100), with 10 making the Top 20 on both charts. Four of those singles reached the Top 10, including \"Dancing Queen\", which reached number one in April 1977. While \"Fernando\" and \"SOS\" did not break the Top 10 on the \"Billboard\" Hot 100 (reaching number 13 and 15 respectively), they did reach the Top 10 on \"Cashbox\" (\"Fernando\") and \"Record World\" (\"SOS\") charts. Both \"Dancing Queen\" and \"Take a Chance on Me\" were certified gold by the Recording Industry Association of America for sales of over one million copies each.\nThe group also had 12 Top 20 singles on the \"Billboard\" Adult Contemporary chart with two of them, \"Fernando\" and \"The Winner Takes It All\", reaching number one. \"Lay All Your Love on Me\" was ABBA's fourth number-one single on a \"Billboard\" chart, topping the Hot Dance Club Play chart.\nTen ABBA albums have made their way into the top half of the \"Billboard\" 200 album chart, with eight reaching the Top 50, five reaching the Top 20, and one reaching the Top 10. In November 2021, \"Voyage\" became ABBA's highest-charting album on the \"Billboard\" 200, peaking at No. 2. Five albums received RIAA gold certification (more than 500,000 copies sold), while three acquired platinum status (selling more than one million copies).\nThe compilation album \"\" topped the \"Billboard\" Top Pop Catalog Albums chart in August 2008 (15 years after it was first released in the US in 1993), becoming the group's first number-one album on any of the \"Billboard\" album charts. It has sold 6 million copies there.\nOn 15 March 2010, ABBA was inducted into the Rock and Roll Hall of Fame by Bee Gees members Barry Gibb and Robin Gibb. The ceremony was held at the Waldorf Astoria Hotel in New York City. The group was represented by Anni-Frid Lyngstad and Benny Andersson.\nIn November 2021, the group received a Grammy nomination for Record of the Year. The single \"I Still Have Faith in You\", from the album \"Voyage\", was their first ever nomination. In November 2022, \"Don't Shut Me Down\", also from \"Voyage\", was nominated for Best Pop Duo/Group Performance.\n\"Saturday Night Live\" featured a sketch that promoted a fictional ABBA album, which took existing songs and reworked their lyrics to reference common Christmas traditions in the United States. Episode host Kate McKinnon and cast member Bowen Yang were joined by Maya Rudolph and Kristen Wiig, both former cast members on the show. The episode aired on 16 December 2023.\nMembers.\nThe members of ABBA were married as follows: Agnetha F\u00e4ltskog and Bj\u00f6rn Ulvaeus from 1971 to 1979; Benny Andersson and Anni-Frid Lyngstad from 1978 to 1981.\nIn addition to the four members of ABBA, other people regularly did significant work on their studio recordings, live appearances, and concert performances. These include:\nDiscography.\nStudio albums\nDocumentaries.\nDocumentaries often profess to show the \"real ABBA\" and may employ several methods of legitimising such claims, such as the use of archival documents, testimonies from \"music and cultural 'experts'\", and interviews with the group members and fans.\nReferences.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nExternal links.\nrole=\"presentation\" class=\"wikitable succession-box noprint\" style=\"margin:0.5em auto; font-size:small;clear:both;\""}
{"id": "881", "revid": "19553220", "url": "https://en.wikipedia.org/wiki?curid=881", "title": "Allegiance", "text": "Duty of fidelity, typically to a country\nAn allegiance is a duty of fidelity said to be owed, or freely committed, by the people, subjects or citizens to their state or sovereign.\nEtymology.\nThe word \"allegiance\" comes from Middle English ' (see Medieval Latin ', \"a liegance\"). The \"al-\" prefix was probably added through confusion with another legal term, \"allegation\". The connection with Latin \"\", \"to bind,\" is erroneous.\nUsage.\nTraditionally, English legal commentators used the term \"allegiance\" in two ways. One referred to \"local allegiance\"\u2014the deference expected even from foreigners within a country. Another sense was \"natural allegiance,\" owed by native-born citizens.\nUnited Kingdom.\nThe English doctrine once held that allegiance was indelible: \"Nemo potest exuere patriam\". Before 1870, anyone born or naturalized in Britain owed lifelong allegiance unless parliament permitted otherwise. This doctrine was a factor in the War of 1812.\nAllegiance bound subject to monarch, and monarch to subject: \"duplex et reciprocum ligamen\" (\"double and reciprocal bond\").\nFour types of allegiance were recognized:\nThe Naturalization Act 1870 allowed British subjects to renounce nationality under specified conditions.\nUnited States.\nThe U.S. rejected indelible allegiance early. John Rutledge declared in \"Talbot v. Janson\" that dual citizenship was possible. The Expatriation Act of 1868 declared expatriation a natural right. Dual allegiance can lead to conflicting duties, possibly treason, so renunciation may be necessary.\nIn Islam.\nIn Arabic, allegiance is \"bay'ah\" (\u0628\u064a\u0639\u0629), meaning \"taking hand.\" The Quran references it in .\nOath of allegiance.\nAn oath of allegiance pledges fidelity to the sovereign (or nation in republics). In the U.S., this is embodied in the Pledge of Allegiance, which is voluntary due to the First Amendment.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "882", "revid": "14371489", "url": "https://en.wikipedia.org/wiki?curid=882", "title": "Absolute majority", "text": ""}
{"id": "885", "revid": "46949569", "url": "https://en.wikipedia.org/wiki?curid=885", "title": "Altenberg", "text": "Altenberg (German for \"old mountain\" or \"mountain of the old\") may refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "887", "revid": "35498457", "url": "https://en.wikipedia.org/wiki?curid=887", "title": "MessagePad", "text": "1993 personal digital assistant\nThe MessagePad is a series of personal digital assistant devices developed by Apple Computer for the Newton platform, first released in 1993. Some electronic engineering and the manufacture of Apple's MessagePad devices was undertaken in Japan by Sharp. The devices are based on the ARM 610 RISC processor, run Newton OS, and all feature handwriting recognition software. Alongside the MessagePad series, Apple also developed and released the eMate 300 Newton device.\nHistory.\nThe development of the Newton MessagePad first began with Apple's former senior vice president of research and development, Jean-Louis Gass\u00e9e; his team included Steve Capps, co-writer of Mac OS Finder, and an employed engineer named Steve Sakoman. The development of the Newton MessagePad operated in secret until it was eventually revealed to the Apple Board of Directors in late 1990.\nWhen Gass\u00e9e resigned from his position due to a significant disagreement with the board, seeing how his employer was treated, Sakoman also stopped developing the MessagePad on March 2, 1990.\nBill Atkinson, an Apple Executive responsible for the company's Lisa graphical interface, invited Steve Capps, John Sculley, Andy Hertzfeld, Susan Kare, and Marc Porat to a meeting on March 11, 1990. There, they brainstormed a way of saving the MessagePad. Sculley suggested adding new features, including libraries, museums, databases, or institutional archives features, allowing customers to navigate through various window tabs or opened galleries/stacks. The Board later approved his suggestion; he then gave the Newton his official and full backing.\nThe first MessagePad was unveiled by Sculley on the 29th of May 1992 at the summer Consumer Electronics Show (CES) in Chicago. Sculley caved in to pressure to unveil the product early because the Newton did not officially ship until 14 months later on the 2nd of August 1993, starting at a price of . Over 50,000 units were sold by late November 1993.\nDetails.\nScreen and input.\nWith the MessagePad 120 with Newton OS 2.0, the Newton Keyboard by Apple became available, which can also be used via the dongle on Newton devices with a Newton InterConnect port, most notably the Apple MessagePad 2000/2100 series, as well as the Apple eMate 300.\nNewton devices featuring Newton OS 2.1 or higher can be used with the screen turned horizontally (\"landscape\") as well as vertically (\"portrait\"). A change of a setting rotates the contents of the display by 90, 180 or 270 degrees. Handwriting recognition still works properly with the display rotated, although display calibration is needed when rotation in any direction is used for the first time or when the Newton device is reset.\nHandwriting recognition.\nIn initial versions (Newton OS 1.x) the handwriting recognition gave extremely mixed results for users and was sometimes inaccurate. The original handwriting recognition engine was called Calligrapher, and was licensed from a Russian company called . Calligrapher's design was quite sophisticated; it attempted to learn the user's natural handwriting, using a database of known words to make guesses as to what the user was writing, and could interpret writing anywhere on the screen, whether hand-printed, in cursive, or a mix of the two. By contrast, Palm Pilot's Graffiti had a less sophisticated design than Calligrapher, but was sometimes found to be more accurate and precise due to its reliance on a fixed, predefined stroke alphabet. The stroke alphabet used letter shapes which resembled standard handwriting, but which were modified to be both simple and very easy to differentiate. Palm Computing also released two versions of Graffiti for Newton devices. The Newton version sometimes performed better and could also show strokes as they were being written as input was done on the display itself, rather than on a silkscreen area.\nFor editing text, Newton had a very intuitive system for handwritten editing, such as scratching out words to be deleted, circling text to be selected, or using written carets to mark inserts.\nLater releases of the Newton operating system retained the original recognizer for compatibility, but added a hand-printed-text-only (not cursive) recognizer, called \"Rosetta\", which was developed by Apple, included in version 2.0 of the Newton operating system, and refined in Newton 2.1. Rosetta is generally considered a significant improvement and many reviewers, testers, and most users consider the Newton 2.1 handwriting recognition software better than any of the alternatives even 10 years after it was introduced. Recognition and computation of handwritten horizontal and vertical formulas such as \"1 + 2 =\" was also under development but never released. However, users wrote similar programs which could evaluate mathematical formulas using the Newton OS Intelligent Assistant, a unique part of every Newton device.\nThe handwriting recognition and parts of the user interface for the Newton are best understood in the context of the broad history of pen computing, which is quite extensive.\nA vital feature of the Newton handwriting recognition system is the modeless error correction. That is, correction done \"in situ\" without using a separate window or widget, using a minimum of gestures. If a word is recognized improperly, the user could double-tap the word and a list of alternatives would pop up in a menu under the stylus. Most of the time, the correct word will be in the list. If not, a button at the bottom of the list allows the user to edit individual characters in that word. Other pen gestures could do such things as transpose letters (also \"in situ\"). The correction popup also allowed the user to revert to the original, un-recognized letter shapes - this would be useful in note-taking scenarios if there was insufficient time to make corrections immediately. To conserve memory and storage space, alternative recognition hypotheses would not be saved indefinitely. If the user returned to a note a week later, for example, they would only see the best match. Error correction in many current handwriting systems provides such functionality but adds more steps to the process, greatly increasing the interruption to a user's workflow that a given correction requires.\nUser interface.\nText could also be entered by tapping with the stylus on a small on-screen pop-up QWERTY virtual keyboard, although more layouts were developed by users. Newton devices could also accept free-hand \"Sketches\", \"Shapes\", and \"Ink Text\", much like a desktop computer graphics tablet. With \"Shapes\", Newton could recognize that the user was attempting to draw a circle, a line, a polygon, etc., and it would clean them up into perfect vector representations (with modifiable control points and defined vertices) of what the user was attempting to draw. \"Shapes\" and \"Sketches\" could be scaled or deformed once drawn. \"Ink text\" captured the user's free-hand writing but allowed it to be treated somewhat like recognized text when manipulating for later editing purposes (\"ink text\" supported word wrap, could be formatted to be bold, italic, etc.). At any time a user could also direct their Newton device to recognize selected \"ink text\" and turn it into recognized text (deferred recognition). A Newton note (or the notes attached to each contact in Names and each Dates calendar or to-do event) could contain any mix of interleaved text, Ink Text, Shapes, and Sketches.\nWhile the Newton offered handwriting recognition training and would clean up sketches into vector shapes, both were unreliable and required much rewriting and redrawing. The most reliable application of the Newton was collecting and organizing address and phone numbers. While handwritten messages could be stored, they could not be easily filed, sorted or searched. While the technology was a probable cause for the failure of the device (which otherwise met or exceeded expectations), the technology has been instrumental in producing the future generation of handwriting software that realizes the potential and promise that began in the development of Newton-Apple's Ink Handwriting Recognition.\nConnectivity.\nThe MessagePad 100 series of devices used Macintosh's proprietary serial ports\u2014round Mini-DIN 8 connectors. The MessagePad 2000/2100 models (as well as the eMate 300) have a small, proprietary \"Newton InterConnect\" port. However, the development of the Newton hardware/software platform was canceled by Steve Jobs on February 27, 1998, so the InterConnect port, while itself very advanced, can only be used to connect a serial dongle. A prototype multi-purpose InterConnect device containing serial, audio in, audio out, and other ports was also discovered. In addition, all Newton devices have infrared connectivity, initially only the Sharp ASK protocol, but later also IrDA, though the Sharp ASK protocol was kept in for compatibility reasons. Unlike the Palm Pilot, all Newton devices are equipped with a standard PC Card expansion slot (two on the 2000/2100). This allows native modem and even Ethernet connectivity; Newton users have also written drivers for 802.11b wireless networking cards and ATA-type flash memory cards (including the popular CompactFlash format), as well as for Bluetooth cards. Newton can also dial a phone number through the built-in speaker of the Newton device by simply holding a telephone handset up to the speaker and transmitting the appropriate tones. Fax and printing support is also built in at the operating system level, although it requires peripherals such as parallel adapters, PCMCIA cards, or serial modems, the most notable of which is the lightweight Newton Fax Modem released by Apple in 1993. It is powered by 2 AA batteries, and can also be used with a power adapter. It provides data transfer at 2,400 bit/s, and can also send and receive fax messages at 9,600 and 4,800 bit/s respectively.\nPower options.\nThe original Apple MessagePad and MessagePad 100 used four AAA batteries. They were eventually replaced by AA batteries with the release of the Apple MessagePad 110.\nThe use of 4 AA NiCd (MessagePad 110, 120 and 130) and 4x AA NiMH cells (MP2x00 series, eMate 300) give a runtime of up to 30 hours (MP2100 with two 20\u00a0MB Linear Flash memory PC Cards, no backlight usage) and up to 24 hours with backlight on. While adding more weight to the handheld Newton devices than AAA batteries or custom battery packs, the choice of an easily replaceable/rechargeable cell format gives the user a still unsurpassed runtime and flexibility of power supply. This, together with the flash memory used as internal storage starting with the Apple MessagePad 120 (if all cells lost their power, no data was lost due to the non-volatility of this storage), gave birth to the slogan \"Newton never dies, it only gets new batteries\".\nLater efforts and improvements.\nThe Apple MessagePad 2000/2100, with a vastly improved handwriting recognition system, 162\u00a0MHz StrongARM SA-110 RISC processor, Newton OS 2.1, and a better, clearer, backlit screen, attracted critical plaudits.\neMate 300.\nThe eMate 300 was a Newton device in a laptop form factor offered to schools in 1997 as an inexpensive ($799 US, originally sold to education markets only) and durable computer for classroom use. However, in order to achieve its low price, the eMate 300 did not have all the speed and features of the contemporary MessagePad equivalent, the MessagePad 2000. The eMate was cancelled along with the rest of the Newton products in 1998. It is the only Newton device to use the ARM710 microprocessor (running at 25\u00a0MHz), have an integrated keyboard, use Newton OS 2.2 (officially numbered 2.1), and its batteries are officially irreplaceable, although several users replaced them with longer-lasting ones without any damage to the eMate hardware whatsoever.\nPrototypes.\nMany prototypes of additional Newton devices were spotted. Most notable was a Newton tablet or \"slate\", a large, flat screen that could be written on. Others included a \"Kids Newton\" with side handgrips and buttons, \"VideoPads\" which would have incorporated a video camera and screen on their flip-top covers for two-way communications, the \"Mini 2000\" which would have been very similar to a Palm Pilot, and the NewtonPhone developed by Siemens, which incorporated a handset and a keyboard.\nMarket reception.\nFourteen months after Sculley demoed it at the May 1992, Chicago CES, the MessagePad was first offered for sale on August 2, 1993, at the Boston Macworld Expo. The hottest item at the show, it cost $900. 50,000 MessagePads were sold in the device's first three months on the market.\nThe original Apple MessagePad and MessagePad 100 were limited by the very short lifetime of their inadequate AAA batteries.\nLater versions of Newton OS offered improved handwriting recognition, quite possibly a leading reason for the continued popularity of the devices among Newton users. Even given the age of the hardware and software, Newtons still demand a sale price on the used market far greater than that of comparatively aged PDAs produced by other companies. In 2006, CNET compared an Apple MessagePad 2000 to a Samsung Q1, and the Newton was declared better. In 2009, CNET compared an Apple MessagePad 2000 to an iPhone 3GS, and the Newton was declared more innovative at its time of release.\nA chain of dedicated Newton-only stores called Newton Source, independently run by Stephen Elms, existed from 1994 until 1998. Locations included New York, Los Angeles, San Francisco, Chicago and Boston. The Westwood Village, California, near UCLA featured the trademark red and yellow light bulb Newton logo in neon. The stores provided an informative educational venue to learn about the Newton platform in a hands on relaxed fashion. The stores had no traditional computer retail counters and featured oval desktops where interested users could become intimately involved with the Newton product range. The stores were a model for the later Apple Stores.\nNewton device models.\nNotes: The eMate 300 actually has ROM chips silk screened with 2.2 on them. Stephanie Mak on her website discusses this:\nIf one removes all patches to the eMate 300 (by replacing the ROM chip, and then putting in the original one again, as the eMate and the MessagePad 2000/2100 devices erase their memory completely after replacing the chip), the result will be the Newton OS saying that this is version 2.2.00. Also, the Original MessagePad and the MessagePad 100 share the same model number, as they only differ in the ROM chip version. (The OMP has OS versions 1.0 to 1.05, or 1.10 to 1.11, while the MP100 has 1.3 that can be upgraded with various patches.)\nThird party licenses.\nThe Newton OS was also licensed to a number of third-party developers including Sharp and Motorola who developed additional PDA devices based on the Newton platform. Motorola added wireless connectivity, as well as made a unique two-part design, and shipped additional software with its Newton device, called the Marco. Sharp developed a line of Newton devices called the ExpertPad PI-7000/7100; those were the same as Apple's MessagePad and MessagePad 100, the only difference is the physical design (the ExpertPads feature a screen lid, which Apple added in 1994 with the release of the MessagePad 110) and the naming.\nOther uses.\nThere were a number of projects that used the Newton as a portable information device in cultural settings such as museums. For example, Visible Interactive created a walking tour in San Francisco's Chinatown but the most significant effort took place in Malaysia at the Petronas Discovery Center, known as Petrosains.\nIn 1995, an exhibit design firm, DMCD Inc., was awarded the contract to design a new science museum in the Petronas Towers in Kuala Lumpur. A major factor in the award was the concept that visitors would use a Newton device to access additional information, find out where they were in the museum, listen to audio, see animations, control robots and other media, and to bookmark information for printout at the end of the exhibit.\nThe device became known as the ARIF, a Malay word for \"wise man\" or \"seer\" and it was also an acronym for A Resourceful Informative Friend. Some 400 ARIFS were installed and over 300 are still in use today. The development of the ARIF system was extremely complex and required a team of hardware and software engineers, designers, and writers. ARIF is an ancestor of the PDA systems used in museums today and it boasted features that have not been attempted since.\nAnyway &amp; Company firm was involved with the Petronas Discovery Center project back in 1998 and NDAs were signed which prevents getting to know more information about this project. It was confirmed that they purchased of MP2000u or MP2100's by this firm on the behalf of the project under the name of \"Petrosains Project Account\". By 1998 they had invested heavily into the R&amp;D of this project with the Newton at the center. After Apple officially cancelled the Newton in 1998 they had to acquire as many Newtons as possible for this project. It was estimated initially 1000 Newtons, but later readjusted the figure to possibly 750 Newtons. They placed an \"Internet Call\" for Newtons. They purchased them in large and small quantities.\nThe Newton was also used in healthcare applications, for example in collecting data directly from patients. Newtons were used as electronic diaries, with patients entering their symptoms and other information concerning their health status on a daily basis. The compact size of the device and its ease of use made it possible for the electronic diaries to be carried around and used in the patients' everyday life setting. This was an early example of electronic patient-reported outcomes (ePRO).\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "888", "revid": "27823944", "url": "https://en.wikipedia.org/wiki?curid=888", "title": "A. E. van Vogt", "text": "Canadian-American science fiction writer (1912\u20132000)\nAlfred Elton van Vogt ( ; April 26, 1912\u00a0\u2013 January 26, 2000) was a Canadian-born American science fiction writer. His fragmented, bizarre narrative style influenced later science fiction writers, including Philip K. Dick. He was one of the most popular and influential practitioners of science fiction in the mid-twentieth century, the genre's so-called Golden Age, and one of the most complex. The Science Fiction Writers of America named him their 14th Grand Master in 1995 (presented 1996).\nEarly life.\nAlfred Vogt (both \"Elton\" and \"van\" were added much later) was born on April 26, 1912, on his grandparents' farm in Edenburg, Manitoba, a tiny (and now defunct) Russian Mennonite community east of Gretna, Manitoba, Canada, in the Mennonite West Reserve. He was the third of six children born to Heinrich \"Henry\" Vogt and Aganetha \"Agnes\" Vogt (n\u00e9e Buhr), both of whom were born in Manitoba and grew up in heavily immigrant communities. Until he was four, van Vogt spoke only Plautdietsch at home.\nFor the first dozen or so years of his life, van Vogt's father, Henry Vogt, a lawyer, moved his family several times within the Prairies, moving to Neville, Saskatchewan; Morden, Manitoba; and finally Swift Current, Saskatchewan, where the family spent the majority of the 1920s. Alfred Vogt found these moves difficult, later remarking:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nBy the late 1920s, living in Saskatchewan, his father Henry worked as an agent for a steamship company, but the stock market crash of 1929 proved financially disastrous, and the family could not afford to send Alfred to college. During his teen years, Alfred worked as a farmhand and a truck driver, and by the age of 19, he was working in Ottawa for the Canadian Census Bureau.\nIn \"the dark days of '31 and '32,\" van Vogt took a correspondence course in writing from the Palmer Institute of Authorship. He sold his first story in fall 1932. His early published works were stories in the true confession style of magazines such as \"True Story\". Most of these stories were published anonymously, with the first-person narratives allegedly being written by people (often women) in extraordinary, emotional, and life-changing circumstances.\nAfter a year in Ottawa, he moved to Winnipeg, Manitoba, where he sold newspaper advertising space and continued to write. While continuing to pen melodramatic \"true confessions\" stories through 1937, he also began writing short radio dramas for local radio station CKY, as well as conducting interviews published in trade magazines. He added the middle name \"Elton\" at some point in the mid-1930s, and at least one confessional story (1937's \"To Be His Keeper\") was sold to the \"Toronto Star\", who misspelled his name \"Alfred Alton Bogt\" in the byline. Shortly thereafter, he added the \"van\" to his surname, and from that point forward he used the name \"A. E. van Vogt\" both personally and professionally.\nCareer.\nBy 1938, van Vogt decided to switch to writing science fiction, a genre he enjoyed reading. He was inspired by the August 1938 issue of \"Astounding Science Fiction,\" which he picked up at a newsstand. John W. Campbell's novelette \"Who Goes There?\" (later adapted into \"The Thing from Another World\" and \"The Thing\") inspired van Vogt to write \"Vault of the Beast\", which he submitted to that same magazine. Campbell, who edited \"Astounding\" (and had written the story under a pseudonym), sent van Vogt a rejection letter in which Campbell encouraged van Vogt to try again. Van Vogt sent another story, entitled \"Black Destroyer\", which was accepted. It featured a fierce, carnivorous alien stalking the crew of a spaceship, and served as the inspiration for multiple science fiction movies, including \"Alien\" (1979). A revised version of \"Vault of the Beast\" was published in 1940.\nWhile still living in Winnipeg, in 1939 van Vogt married Edna Mayne Hull, a fellow Manitoban. Hull, who had previously worked as a private secretary, went on to act as van Vogt's typist, and was credited with writing several SF stories of her own throughout the early 1940s.\nThe outbreak of World War II in September 1939 caused a change in van Vogt's circumstances. Ineligible for military service due to his poor eyesight, he accepted a clerking job with the Canadian Department of National Defence. This necessitated a move back to Ottawa, where he and his wife stayed for the next year and a half.\nMeanwhile, his writing career continued. \"Discord in Scarlet\" was van Vogt's second story to be published, also appearing as the cover story. It was accompanied by interior illustrations created by Frank Kramer and Paul Orban. (Van Vogt and Kramer thus debuted in the issue of \"Astounding\" that is sometimes identified as the start of the Golden Age of Science Fiction.) Among his most famous works of this era, \"Far Centaurus\" appeared in the January 1944 edition of \"Astounding\".\nVan Vogt's first completed novel, and one of his most famous, is \"Slan\" (Arkham House, 1946), which Campbell serialized in \"Astounding\" (September to December 1940). Using what became one of van Vogt's recurring themes, it told the story of a nine-year-old superman living in a world in which his kind are slain by \"Homo sapiens\".\nOthers saw van Vogt's talent from his first story, and in May 1941 van Vogt decided to become a full-time writer, quitting his job at the Canadian Department of National Defence. Freed from the necessity of living in Ottawa, he and his wife lived for a time in the Gatineau region of Quebec before moving to Toronto in the fall of 1941.\nProlific throughout this period, van Vogt wrote many of his more famous short stories and novels in the years from 1941 through 1944. The novels \"The Book of Ptath\" and \"The Weapon Makers\" both appeared in magazines in serial form during this period; they were later published in book form after World War II. As well, several (though not all) of the stories that were compiled to make up the novels \"The Weapon Shops of Isher\", \"The Mixed Men\" and \"The War Against the Rull\" were published during this time.\nCalifornia and post-war writing (1944\u20131950).\nIn November 1944, van Vogt and Hull moved to Hollywood; van Vogt would spend the rest of his life in California. He had been using the name \"A. E. van Vogt\" in his public life for several years, and as part of the process of obtaining American citizenship in 1945 he finally and formally changed his legal name from Alfred Vogt to Alfred Elton van Vogt. To his friends in the California science fiction community, he was known as \"Van\".\nMethod and themes.\nVan Vogt systematized his writing method, using scenes of 800 words or so where a new complication was added or something resolved. Several of his stories hinge on temporal conundra, a favorite theme. He stated that he acquired many of his writing techniques from three books: \"Narrative Technique\" by Thomas Uzzell, \"The Only Two Ways to Write a Story\" by John Gallishaw, and \"Twenty Problems of the Fiction Writer\" by Gallishaw. He also claimed many of his ideas came from dreams; throughout his writing life he arranged to be awakened every 90\u00a0minutes during his sleep period so he could write down his dreams.\nVan Vogt was also always interested in the idea of all-encompassing systems of knowledge (akin to modern meta-systems). The characters in his very first story used a system called \"Nexialism\" to analyze the alien's behavior. Around this time, he became particularly interested in the general semantics of Alfred Korzybski.\nHe subsequently wrote a novel merging these overarching themes, \"The World of \u0100\", originally serialized in \"Astounding\" in 1945. \u0100 (often rendered as \"Null-A\"), or non-Aristotelian logic, refers to the capacity for, and practice of, using intuitive, inductive reasoning (compare fuzzy logic), rather than reflexive, or conditioned, deductive reasoning. The novel recounts the adventures of an individual living in an apparent Utopia, where those with superior brainpower make up the ruling class... though all is not as it seems. A sequel, \"The Players of \u0100\" (later re-titled \"The Pawns of Null-A\") was serialized in 1948\u201349.\nAt the same time, in his fiction, van Vogt was consistently sympathetic to absolute monarchy as a form of government. This was the case, for instance, in the \"Weapon Shop\" series, the \"Mixed Men\" series, and in single stories such as \"Heir Apparent\" (1945), whose protagonist was described as a \"benevolent dictator\". These sympathies were the subject of much critical discussion during van Vogt's career, and afterwards.\nVan Vogt published \"Enchanted Village\" in the July 1950 issue of \"Other Worlds Science Stories\". It was reprinted in over 20 collections or anthologies, and appeared many times in translation.\nDianetics and fix-ups (1950\u20131961).\nIn 1950, van Vogt was briefly appointed as head of L. Ron Hubbard's Dianetics operation in California. Van Vogt had first met Hubbard in 1945, and became interested in his theories, which were published shortly thereafter. Dianetics was the secular precursor to Hubbard's Church of Scientology; van Vogt would have no association with Scientology, as he did not approve of its mysticism.\nThe California Dianetics operation went broke nine months later, but never went bankrupt, due to van Vogt's arrangements with creditors. Shortly afterward, van Vogt and his wife opened their own Dianetics center, partly financed by his writings, until he \"signed off\" around 1961. From 1951 until 1961, van Vogt's focus was on Dianetics, and he produced no new fiction.\nFix-ups.\nHowever, during the 1950s, van Vogt retrospectively patched together many of his previously published stories into novels, sometimes creating new interstitial material to help bridge gaps in the narrative. Van Vogt referred to the resulting books as \"fix-ups\", a term that entered the vocabulary of science-fiction criticism. When the original stories were closely related this was often successful, although some van Vogt fix-ups featured disparate stories thrown together that bore little relation to each other, generally making for a less coherent plot. One of his best-known (and well-regarded) novels, \"The Voyage of the Space Beagle\" (1950) was a fix-up of four short stories including \"Discord in Scarlet\"; it was published in at least five European languages by 1955.\nAlthough Van Vogt averaged a new book title every ten months from 1951 to 1961, none of them were entirely new content; they were all fix-ups, collections of previously published stories, expansions of previously published short stories to novel length, or republications of previous books under new titles and all based on story material written and originally published between 1939 and 1950. Examples include \"The Weapon Shops of Isher\" (1951), \"The Mixed Men\" (1952), \"The War Against the Rull\" (1959), and the two \"Clane\" novels, \"Empire of the Atom\" (1957) and \"The Wizard of Linn\" (1962), which were inspired (like Asimov's Foundation series) by Roman imperial history; specifically, as Damon Knight wrote, the plot of \"Empire of the Atom\" was \"lifted almost bodily\" from that of Robert Graves' \"I, Claudius\". (Also, one non-fiction work, \"The Hypnotism Handbook\", appeared in 1956, though it had apparently been written much earlier.)\nAfter more than a decade of running their Dianetics center, Hull and van Vogt closed it in 1961. Nevertheless, van Vogt maintained his association with the organization and was still president of the Californian Association of Dianetic Auditors into the 1980s.\nReturn to writing and later career (1962\u20131986).\nThough the constant re-packaging of his older work meant that he had never really been away from the book publishing world, van Vogt had not published any wholly new fiction for almost 12 years when he decided to return to writing in 1962. He did not return immediately to science fiction, but instead wrote the only mainstream, non-sf novel of his career.\nVan Vogt was profoundly affected by revelations of totalitarian police states that emerged after World War II. Accordingly, he wrote a mainstream novel that he set in Communist China, \"The Violent Man\" (1962). Van Vogt explained that to research this book he had read 100 books about China. Into this book he incorporated his view of \"the violent male type\", which he described as a \"man who had to be right\", a man who \"instantly attracts women\" and who he said were the men who \"run the world\". Contemporary reviews were lukewarm at best, and van Vogt thereafter returned to science fiction.\nFrom 1963 through the mid-1980s, van Vogt once again published new material on a regular basis, though fix-ups and reworked material also appeared relatively often. His later novels included fix-ups such as \"The Beast\" (also known as \"Moonbeast\") (1963), \"Rogue Ship\" (1965), \"Quest for the Future\" (1970) and \"Supermind\" (1977). He also wrote novels by expanding previously published short stories; works of this type include \"The Darkness on Diamondia\" (1972) and \"Future Glitter\" (also known as \"Tyranopolis\"; 1973).\nNovels that were written simply as novels, and not serialized magazine pieces or fix-ups, had been very rare in van Vogt's oeuvre, but began to appear regularly beginning in the 1970s. Van Vogt's original novels included \"Children of Tomorrow\" (1970), \"The Battle of Forever\" (1971) and \"The Anarchistic Colossus\" (1977). Over the years, many sequels to his classic works were promised, but only one appeared: \"Null-A Three\" (1984; originally published in French). Several later books were initially published in Europe, and at least one novel only ever appeared in foreign language editions and was never published in its original English.\nFinal years.\nWhen the 1979 film \"Alien\" appeared, it was noted that the plot closely matched the plots of both \"Black Destroyer\" and \"Discord in Scarlet\", both published in \"Astounding magazine\" in 1939, and then later published in the 1950 book \"Voyage of the Space Beagle\". Van Vogt sued the production company for plagiarism, and eventually collected an out-of-court settlement of $50,000 from 20th Century Fox. \nIn increasingly frail health, van Vogt published his final short story in 1986. Van Vogt's first wife, Edna Mayne Hull, died in 1975. Van Vogt married Lydia Bereginsky in 1979; they remained together until his death. On January 26, 2000, A. E. van Vogt died in Los Angeles from Alzheimer's disease. He was survived by his second wife.\nCritical reception.\nCritical opinion about the quality of van Vogt's work is sharply divided. An early and articulate critic was Damon Knight. In a 1945 chapter-long essay reprinted in \"In Search of Wonder,\" entitled \"Cosmic Jerrybuilder: A. E. van Vogt\", Knight described van Vogt as \"no giant; he is a pygmy who has learned to operate an overgrown typewriter\". Knight described \"The World of Null-A\" as \"one of the worst allegedly adult science fiction stories ever published\". Concerning van Vogt's writing, Knight said:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;In general van Vogt seems to me to fail consistently as a writer in these elementary ways: 1. His plots do not bear examination. 2. His choice of words and his sentence-structure are fumbling and insensitive. 3. He is unable either to visualize a scene or to make a character seem real.\nAbout \"Empire of the Atom\" Knight wrote:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;If you can only throw your reasoning powers out of gear\u2014something many van Vogt fans find easy to do\u2014you'll enjoy this one.\nKnight also expressed misgivings about van Vogt's politics. He noted that van Vogt's stories almost invariably present absolute monarchy in a favorable light. In 1974, Knight retracted some of his criticism after finding out about Vogt's writing down his dreams as a part of his working methods:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;This explains a good deal about the stories, and suggests that it is really useless to attack them by conventional standards. If the stories have a dream consistency which affects readers powerfully, it is probably irrelevant that they lack ordinary consistency.\nKnight's criticism greatly damaged van Vogt's reputation. On the other hand, when science fiction author Philip K. Dick was asked which science fiction writers had influenced his work the most, he replied:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;I started reading [science fiction] when I was about twelve and I read all I could, so any author who was writing about that time, I read. But there's no doubt who got me off originally and that was A. E. van Vogt. There was in van Vogt's writing a mysterious quality, and this was especially true in \"The World of Null-A\". All the parts of that book did not add up; all the ingredients did not make a coherency. Now some people are put off by that. They think that's sloppy and wrong, but the thing that fascinated me so much was that this resembled reality more than anybody else's writing inside or outside science fiction.\nDick also defended van Vogt against Damon Knight's criticisms:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Damon feels that it's bad artistry when you build those funky universes where people fall through the floor. It's like he's viewing a story the way a building inspector would when he's building your house. But reality really is a mess, and yet it's exciting. The basic thing is, how frightened are you of chaos? And how happy are you with order? Van Vogt influenced me so much because he made me appreciate a mysterious chaotic quality in the universe which is not to be feared.\nIn a review of \"Transfinite: The Essential A. E. van Vogt\", science fiction writer Paul Di Filippo said:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Van Vogt knew precisely what he was doing in all areas of his fiction writing. There's hardly a wasted word in his stories. ... His plots are marvels of interlocking pieces, often ending in real surprises and shocks, genuine paradigm shifts, which are among the hardest conceptions to depict. And the intellectual material of his fictions, the conceits and tossed-off observations on culture and human and alien behavior, reflect a probing mind. ... Each tale contains a new angle, a unique slant, that makes it stand out.\nIn \"The John W. Campbell Letters\", Campbell says, \"The son-of-a-gun gets hold of you in the first paragraph, ties a knot around you, and keeps it tied in every paragraph thereafter\u2014including the ultimate last one\".\nHarlan Ellison (who had begun reading van Vogt as a teenager) wrote, \"Van was the first writer to shine light on the restricted ways in which I had been taught to view the universe and the human condition\".\nWriting in 1984, David Hartwell said:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;No one has taken van Vogt seriously as a writer for a long time. Yet he has been read and \"still\" is. What no one seems to have noticed is that van Vogt, more than any other single SF writer, is the conduit through which the energy of Gernsbackian, primitive wonder stories have been transmitted through the Campbellian age, when earlier styles of SF were otherwise rejected, and on into SF of the present.\nThe literary critic Leslie A. Fiedler said something similar:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Van Vogt is a test case ... since an apology for or analysis of science fiction which fails to come to terms with his appeal and major importance, defends or defines the genre by falsifying it.\nAmerican literary critic Fredric Jameson says of van Vogt:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;that van Vogt's work clearly prepares the way for that of the greatest of all Science Fiction writers, Philip K. Dick, whose extraordinary novels and stories are inconceivable without the opening onto that play of unconscious materials and fantasy dynamics released by van Vogt, and very different from the more hard-science aesthetic ideologies of his contemporaries (from Campbell to Heinlein).\nVan Vogt still has his critics. For example, Darrell Schweitzer, writing to \"The New York Review of Science Fiction\" in 1999, quoted a passage from the original van Vogt novelette \"The Mixed Men\", which he was then reading, and remarked:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;This is the realism, and logic, of a small boy playing with toy soldiers in a sandbox. I'm tougher than you. I've got a \"billion\" spaceships! They're brand-new. They only took 800 years to develop.\nAnd this is a story in which most of the cast either have two brains or are really robots ... and even the emotions of the human characters are programmed or deprogrammed as part of plots within counter plots. Next to this, Doc Smith was an icy realist. There is \"no\" intersection with adult reality at any point, for all van Vogt was able to write was that small boy's sandbox game with an adult level of intensity. This is, I think, the secret of van Vogt's bizarre fascination, as awful as his actual writing might be, and why he appealed so strongly to Philip K. Dick, who managed to put more adult characters and emotions into equally crazy situations. It's ultimately very strange to find this sort of writing so prominently sponsored by supposedly rational and scientifically minded John W. Campbell, when it seems to contravene everything the Golden Age stood for.\nRecognition.\nIn 1946, van Vogt and his first wife, Edna Mayne Hull, were Guests of Honor at the fourth World Science Fiction Convention.\nIn 1980, van Vogt received a \"Casper Award\" (precursor to the Canadian Prix Aurora Awards) for Lifetime Achievement.\nThe Science Fiction Writers of America (SFWA) named him its 14th Grand Master in 1995 (presented 1996). Great controversy within SFWA accompanied its long wait in bestowing its highest honor (limited to living writers, no more than one annually). Writing an obituary of van Vogt, Robert J. Sawyer, a fellow Canadian writer of science fiction, remarked:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;There was no doubt that van Vogt should have received this honor much earlier\u2014the injustice of him being overlooked, at least in part because of damnable SFWA politics, had so incensed Harlan Ellison, a man with an impeccable moral compass, that he'd lobbied hard on the Sci-Fi Channel and elsewhere on van Vogt's behalf.\nIt is generally held that a key factor in the delay was \"damnable SFWA politics\" reflecting the concerns of Damon Knight, the founder of the SFWA, who abhorred van Vogt's style and politics and thoroughly demolished his literary reputation in the 1950s.\nHarlan Ellison was more explicit in 1999 introduction to \"Futures Past: The Best Short Fiction of A. E. van Vogt\":\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;[A]t least I was able to make enough noise to get Van the Science Fiction Writers of America Grand Master Award, which was presented to him in full ceremony during one of the last moments when he was cogent and clearheaded enough to understand that finally, at last, dragged kicking and screaming to honor him, the generation that learned from what he did and what he had created had, at last, 'fessed up to his importance.\n... were the same ones who assured me that Van would never get the Grand Master until Damon Knight had gotten it first, because Damon had loathed Van's work and had, in fact written the essay that ridiculed Van and held him up to opprobrium for decades thereafter, and Damon having founded SFWA it would be an affront to him if Van got it first. Well, I don't know if that's true or not, though it was common coin in the field for years; but Damon got the Grand Master award in 1994. And Van got it in 1995. As they say during sweeps week on television: coincidence or conspiracy?\nIn 1996, van Vogt received a Special Award from the World Science Fiction Convention \"for six decades of golden age science fiction\". That same year, the Science Fiction and Fantasy Hall of Fame inducted him in its inaugural class of two deceased and two living persons, along with writer Jack Williamson (also living) and editors Hugo Gernsback and John W. Campbell.\nThe works of van Vogt were translated into French by the surrealist Boris Vian (\"The World of Null-A\" as \"Le Monde des \u00c5\" in 1958), and van Vogt's works were \"viewed as great literature of the surrealist school\". In addition, \"Slan\" was published in French, translated by Jean Rosenthal, under the title \"\u00c0 la poursuite des Slans\", as part of the paperback series 'Editions J'ai Lu: Romans-Texte Integral' in 1973. This edition also listing the following works by van Vogt as having been published in French as part of this series: \"Le Monde des \u00c5\", \"La faune de l'espace\", \"Les joueurs du \u00c5\", \"L'empire de l'atome\", \"Le sorcier de Linn\", \"Les armureries d'Isher\", \"Les fabricants d'armes\", and \"Le livre de Ptath\". Van Vogt's last novel, 1985's \"To Conquer Kiber\", has only been released in French (as \"\u00c0 la conqu\u00eate de Kiber\".)\nExplanatory notes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "890", "revid": "15881234", "url": "https://en.wikipedia.org/wiki?curid=890", "title": "Anna Kournikova", "text": "Russian tennis player and model (born 1981)\nAnna Sergeyevna Kournikova Iglesias (n\u00e9e Kournikova; ; ; born 7 June 1981) is a Russian model and television personality, and former professional tennis player. Her appearance and celebrity status made her one of the best known tennis stars worldwide. At the peak of her fame, fans looking for images of Kournikova made her name one of the most common search strings on Google Search.\nDespite never winning a singles title, she reached No.\u00a08 in the world in 2000. She achieved greater success playing doubles, where she was at times the world No.\u00a01 player. With Martina Hingis as her partner, she won Grand Slam titles in Australia in 1999 and 2002, and the WTA Championships in 1999 and 2000. They referred to themselves as the \"Spice Girls of Tennis\".\nKournikova retired from professional tennis in 2003 due to serious back and spinal problems, including a herniated disk. She lives in Miami Beach, Florida, and played in occasional exhibitions and in doubles for the St.\u00a0Louis Aces of World TeamTennis before the team folded in 2011. She was a new trainer for season 12 of the television show \"The Biggest Loser\", replacing Jillian Michaels, but did not return for season 13. In addition to her tennis and television work, Kournikova serves as a Global Ambassador for Population Services International's \"Five &amp; Alive\" program, which addresses health crises facing children under the age of five and their families.\nEarly life.\nKournikova was born in Moscow, Russia, on 7 June 1981. Her father, Sergei Kournikov (born 1961), a former Greco-Roman wrestling champion, eventually earned a PhD and was a professor at the University of Physical Culture and Sport in Moscow. As of 2001, he was still a part-time martial arts instructor there. Her mother Alla (born 1963) had been a 400-metre runner. Her younger half-brother, Allan, is a youth golf world champion who was featured in the 2013 documentary film \"The Short Game\".\nSergei Kournikov has said, \"We were young and we liked the clean, physical life, so Anna was in a good environment for sport from the beginning\".\nKournikova received her first tennis racquet as a New Year gift in 1986 at the age of five. Describing her early regimen, she said, \"I played two times a week from age six. It was a children's program. And it was just for fun; my parents didn't know I was going to play professionally, they just wanted me to do something because I had lots of energy. It was only when I started playing well at seven that I went to a professional academy. I would go to school, and then my parents would take me to the club, and I'd spend the rest of the day there just having fun with the kids.\" In 1986, Kournikova became a member of the Spartak Tennis Club, coached by Larissa Preobrazhenskaya. In 1989, at the age of eight, Kournikova began appearing in junior tournaments, and by the following year, was attracting attention from tennis scouts across the world. She signed a management deal at age ten and went to Bradenton, Florida, to train at Nick Bollettieri's celebrated tennis academy.\nTennis career.\n1989\u20131997: early years and breakthrough.\nFollowing her arrival in the United States, she became prominent on the tennis scene. At the age of 14, she won the European Championships and the Italian Open Junior tournament. In December 1995, she became the youngest player to win the 18-and-under division of the Junior Orange Bowl tennis tournament. By the end of the year, Kournikova was crowned the ITF Junior World Champion U-18 and Junior European Champion U-18.\nEarlier, in September 1995, Kournikova, still only 14 years of age, debuted in the WTA Tour, when she received a wildcard into the qualifications at the WTA tournament in Moscow, the Moscow Ladies Open, and qualified before losing in the second round of the main draw to third-seeded Sabine Appelmans. She also reached her first WTA Tour doubles final in that debut appearance \u2013 partnering with 1995 Wimbledon girls' champion in both singles and doubles Aleksandra Olsza, she lost the title match to Meredith McGrath and Larisa Savchenko-Neiland.\nIn February\u2013March 1996, Kournikova won two ITF titles, in Midland, Michigan and Rockford, Illinois. Still only 14 years of age, in April 1996 she debuted at the Fed Cup for Russia, the youngest player ever to participate and win a match.\nIn 1996, she started playing under a new coach, Ed Nagel. Her six-year association with Nagel was successful. At 15, she made her Grand Slam debut, reaching the fourth round of the 1996 US Open, losing to Steffi Graf, the eventual champion. After this tournament, Kournikova's ranking jumped from No.\u00a0144 to debut in the Top 100 at\u00a0No. 69. Kournikova was a member of the Russian delegation to the 1996 Olympic Games in Atlanta, Georgia. In 1996, she was named WTA Newcomer of the Year, and she was ranked No. 57 in the end of the season.\nKournikova entered the 1997 Australian Open as world No. 67, where she lost in the first round to world No. 12, Amanda Coetzer. At the Italian Open, Kournikova lost to Amanda Coetzer in the second round. She reached the semi-finals in the doubles partnering with Elena Likhovtseva, before losing to the sixth seeds Mary Joe Fern\u00e1ndez and Patricia Tarabini.\nAt the French Open, Kournikova made it to the third round before losing to world No. 1, Martina Hingis. She also reached the third round in doubles with Likhovtseva. At the Wimbledon Championships, Kournikova became only the second woman in the open era to reach the semi-finals in her Wimbledon debut, the first being Chris Evert in 1972. There she lost to eventual champion Martina Hingis.\nAt the US Open, she lost in the second round to the eleventh seed Irina Sp\u00eerlea. Partnering with Likhovtseva, she reached the third round of the women's doubles event. Kournikova played her last WTA Tour event of 1997 at Porsche Tennis Grand Prix in Filderstadt, losing to Amanda Coetzer in the second round of singles, and in the first round of doubles to Lindsay Davenport and Jana Novotn\u00e1 partnering with Likhovtseva. She broke into the top 50 on 19 May, and was ranked No. 32 in singles and No. 41 in doubles at the end of the season.\n1998\u20132000: success and stardom.\nIn 1998, Kournikova broke into the WTA's top 20 rankings for the first time, when she was ranked No. 16. At the Australian Open, Kournikova lost in the third round to world No. 1 player, Martina Hingis. She also partnered with Larisa Savchenko-Neiland in women's doubles, and they lost to eventual champions Hingis and Mirjana Lu\u010di\u0107 in the second round. Although she lost in the second round of the Paris Open to Anke Huber in singles, Kournikova reached her second doubles WTA Tour final, partnering with Larisa Savchenko-Neiland. They lost to Sabine Appelmans and Miriam Oremans. Kournikova and Savchenko-Neiland reached their second consecutive final at the Linz Open, losing to Alexandra Fusai and Nathalie Tauziat. At the Miami Open, Kournikova reached her first WTA Tour singles final, before losing to Venus Williams in the final.\nKournikova then reached two consecutive quarterfinals, at Amelia Island and the Italian Open, losing respectively to Lindsay Davenport and Martina Hingis. At the German Open, she reached the semi-finals in both singles and doubles, partnering with Larisa Savchenko-Neiland. At the French Open Kournikova had her best result at this tournament, making it to the fourth round before losing to Jana Novotn\u00e1. She also reached her first Grand Slam doubles semi-finals, losing with Savchenko-Neiland to Lindsay Davenport and Natasha Zvereva. During her quarterfinals match at the grass-court Eastbourne Open versus Steffi Graf, Kournikova injured her thumb, which would eventually force her to withdraw from the 1998 Wimbledon Championships. However, she won that match, but then withdrew from her semi-finals match against Arantxa S\u00e1nchez Vicario. Kournikova returned for the Du Maurier Open and made it to the third round, before losing to Conchita Mart\u00ednez. At the US Open Kournikova reached the fourth round before losing to Arantxa S\u00e1nchez Vicario. Her strong year qualified her for the year-end 1998 WTA Tour Championships, but she lost to Monica Seles in the first round. However, with Seles, she won her first WTA doubles title, in Tokyo, beating Mary Joe Fern\u00e1ndez and Arantxa S\u00e1nchez Vicario in the final. At the end of the season, she was ranked No. 10 in doubles.\nAt the start of the 1999 season, Kournikova advanced to the fourth round in singles at the Australian Open before losing to Mary Pierce. In the doubles Kournikova won her first Grand Slam title, partnering with Martina Hingis to defeat Lindsay Davenport and Natasha Zvereva in the final. At the Tier I Family Circle Cup, Kournikova reached her second WTA Tour final, but lost to Martina Hingis. She then defeated Jennifer Capriati, Lindsay Davenport and Patty Schnyder on her route to the Bausch &amp; Lomb Championships semi-finals, losing to Ruxandra Dragomir. At The French Open, Kournikova reached the fourth round before losing to eventual champion Steffi Graf. Once the grass-court season commenced in England, Kournikova lost to Nathalie Tauziat in the semi-finals in Eastbourne. At Wimbledon, Kournikova lost to Venus Williams in the fourth round. She also reached the final in mixed doubles, partnering with Jonas Bj\u00f6rkman, but they lost to Leander Paes and Lisa Raymond. Kournikova again qualified for year-end WTA Tour Championships, but lost to Mary Pierce in the first round, and ended the season as World No. 12.\nWhile Kournikova had a successful singles season, she was even more successful in doubles. After their victory at the Australian Open, she and Martina Hingis won tournaments in Indian Wells, Rome, Eastbourne and the WTA Tour Championships, and reached the final of The French Open where they lost to Serena and Venus Williams. Partnering with Elena Likhovtseva, Kournikova also reached the final in Stanford. On 22 November 1999 she reached the world No. 1 ranking in doubles, and ended the season at this ranking. Kournikova and Hingis were presented with the WTA Award for Doubles Team of the Year.\nKournikova opened her 2000 season winning the Gold Coast Open doubles tournament partnering with Julie Halard. She then reached the singles semi-finals at the Medibank International Sydney, losing to Lindsay Davenport. At the Australian Open, she reached the fourth round in singles and the semi-finals in doubles. That season, Kournikova reached eight semi-finals (Sydney, Scottsdale, Stanford, San Diego, Luxembourg, Leipzig and Tour Championships), seven quarterfinals (Gold Coast, Tokyo, Amelia Island, Hamburg, Eastbourne, Z\u00fcrich and Philadelphia) and one final. On 20 November 2000 she broke into top 10 for the first time, reaching No. 8. She was also ranked No. 4 in doubles at the end of the season. Kournikova was once again, more successful in doubles. She reached the final of the US Open in mixed doubles, partnering with Max Mirnyi, but they lost to Jared Palmer and Arantxa S\u00e1nchez Vicario. She also won six doubles titles \u2013 Gold Coast (with Julie Halard), Hamburg (with Natasha Zvereva), Filderstadt, Z\u00fcrich, Philadelphia and the Tour Championships (with Martina Hingis).\n2001\u20132003: injuries and final years.\nHer 2001 season was plagued by injuries, including a left foot stress fracture which made her withdraw from 12 tournaments, including the French Open and Wimbledon. She underwent surgery in April. She reached her second career grand slam quarterfinals, at the Australian Open. Kournikova then withdrew from several events due to continuing problems with her left foot and did not return until Leipzig. With Barbara Schett, she won the doubles title in Sydney. She then lost in the finals in Tokyo, partnering with Iroda Tulyaganova, and at San Diego, partnering with Martina Hingis. Hingis and Kournikova also won the Kremlin Cup. At the end of the 2001 season, she was ranked No. 74 in singles and No. 26 in doubles.\nKournikova regained some success in 2002. She reached the semi-finals of Auckland, Tokyo, Acapulco and San Diego, and the final of the China Open, losing to Anna Smashnova. This was Kournikova's last singles final. With Martina Hingis, she lost in the final at Sydney, but they won their second Grand Slam title together, the Australian Open. They also lost in the quarterfinals of the US Open. With Chanda Rubin, Kournikova played the semi-finals of Wimbledon, but they lost to Serena and Venus Williams. Partnering with Janet Lee, she won the Shanghai title. At the end of 2002 season, she was ranked No. 35 in singles and No. 11 in doubles.\nIn 2003, Anna Kournikova achieved her first Grand Slam match victory in two years at the Australian Open. She defeated Henrieta Nagyov\u00e1 in the first round, and then lost to Justine Henin-Hardenne in the 2nd round. She withdrew from Tokyo due to a sprained back suffered at the Australian Open and did not return to Tour until Miami. On 9 April, in what would be the final WTA match of her career, Kournikova dropped out in the first round of the Family Circle Cup in Charleston, due to a left adductor strain. Her singles world ranking was 67. She reached the semi-finals at the ITF tournament in Sea Island, before withdrawing from a match versus Maria Sharapova due to the adductor injury. She lost in the first round of the ITF tournament in Charlottesville. She did not compete for the rest of the season due to a continuing back injury. At the end of the 2003 season and her professional career, she was ranked No. 305 in singles and No. 176 in doubles.\nKournikova's two Grand Slam doubles titles came in 1999 and 2002, both at the Australian Open in the Women's Doubles event with partner Martina Hingis. Kournikova proved a successful doubles player on the professional circuit, winning 16 tournament doubles titles, including two Australian Opens and being a finalist in mixed doubles at the US Open and at Wimbledon, and reaching the No. 1 ranking in doubles in the WTA Tour rankings. Her pro career doubles record was 200\u201371. However, her singles career plateaued after 1999. For the most part, she managed to retain her ranking between 10 and 15 (her career high singles ranking was No.8), but her expected finals breakthrough failed to occur; she only reached four finals out of 130 singles tournaments, never in a Grand Slam event, and never won one.\nHer singles record is 209\u2013129. Her final playing years were marred by a string of injuries, especially back injuries, which caused her ranking to erode gradually. As a personality Kournikova was among the most common search strings for both articles and images in her prime.\n2004\u2013present: exhibitions and World Team Tennis.\nKournikova has not played on the WTA Tour since 2003, but still plays exhibition matches for charitable causes. In late 2004, she participated in three events organized by Elton John and by fellow tennis players Serena Williams and Andy Roddick. In January 2005, she played in a doubles charity event for the Indian Ocean tsunami with John McEnroe, Andy Roddick, and Chris Evert. In November 2005, she teamed up with Martina Hingis, playing against Lisa Raymond and Samantha Stosur in the WTT finals for charity. Kournikova is also a member of the St. Louis Aces in the World Team Tennis (WTT), playing doubles only.\nIn September 2008, Kournikova showed up for the 2008 Nautica Malibu Triathlon held at Zuma Beach in Malibu, California. The Race raised funds for children's Hospital Los Angeles. She won that race for women's K-Swiss team. On 27 September 2008, Kournikova played exhibition mixed doubles matches in Charlotte, North Carolina, partnering with Tim Wilkison and Karel Nov\u00e1\u010dek. Kournikova and Wilkison defeated Jimmy Arias and Chanda Rubin, and then Kournikova and Novacek defeated Rubin and Wilkison.\nOn 12 October 2008, Anna Kournikova played one exhibition match for the annual charity event, hosted by Billie Jean King and Elton John, and raised more than $400,000 for the Elton John AIDS Foundation and Atlanta AIDS Partnership Fund. She played doubles with Andy Roddick (they were coached by David Chang) versus Martina Navratilova and Jesse Levine (coached by Billie Jean King); Kournikova and Roddick won.\nKournikova was one of \"four former world No. 1 players\" who participated in \"Legendary Night\", held on 2 May 2009, at the Turning Stone Event Center in Verona, New York, the others being John McEnroe (who had been No. 1 in both singles and doubles), Tracy Austin and Jim Courier (both of whom who had been No. 1 in singles but not doubles). The exhibition included a mixed doubles match in which McEnroe and Kournikova defeated Courier and Austin.\nIn 2008, she was named a spokesperson for K-Swiss. In 2005, Kournikova stated that if she were 100% fit, she would like to come back and compete again.\nIn June 2010, Kournikova reunited with her doubles partner Martina Hingis to participate in competitive tennis for the first time in seven years in the Invitational Ladies Doubles event at Wimbledon. On 29 June 2010 they defeated the British pair Samantha Smith and Anne Hobbs.\nPlaying style.\nKournikova plays right-handed with a two-handed backhand. She is a great player at the net. She can hit forceful groundstrokes and also drop shots.\nHer playing style fits the profile for a doubles player, and is complemented by her height. She has been compared to such doubles specialists as Pam Shriver and Peter Fleming.\nPersonal life.\nKournikova was in a relationship with fellow Russian Pavel Bure, an NHL ice hockey player. The two met in 1999, when Kournikova was still linked to Bure's former Russian teammate Sergei Fedorov. Bure and Kournikova were reported to have been engaged in 2000 after a reporter took a photo of them together in a Florida restaurant where Bure supposedly asked Kournikova to marry him. As the story made headlines in Russia, where they were both heavily followed in the media as celebrities, Bure and Kournikova both denied any engagement. Kournikova, 10 years younger than Bure, was 18 years old at the time.\nFedorov claimed that he and Kournikova were married in 2001, and divorced in 2003. Kournikova's representatives deny any marriage to Fedorov; however, Fedorov's agent Pat Brisson claims that although he does not know when they got married, he knew \"Fedorov was married\".\nKournikova started dating singer Enrique Iglesias in late 2001 after she had appeared in his music video for \"Escape\". The couple have three children together: fraternal twins, a son and daughter, born on 16 December 2017; and another daughter born on 30 January 2020.\nIt was reported in 2010 that Kournikova had become an American citizen.\nMedia publicity.\nIn 2000, Kournikova became the new face for Berlei's shock absorber sports bras, and appeared in the \"only the ball should bounce\" billboard campaign. Following that, she was cast by the Farrelly brothers for a minor role in the 2000 film \"Me, Myself &amp; Irene\" starring Jim Carrey and Ren\u00e9e Zellweger. Photographs of her have appeared on covers of various publications, including men's magazines, such as one in the much-publicized 2004 \"Sports Illustrated Swimsuit Issue\", where she posed in bikinis and swimsuits, as well as in \"FHM\" and \"Maxim\".\nKournikova was named one of \"People\"'s 50 Most Beautiful People in 1998 and was voted \"hottest female athlete\" on ESPN.com. In 2002, she also placed first in \"FHM's 100 Sexiest Women in the World\" in US and UK editions. By contrast, ESPN \u2013 citing the degree of hype as compared to actual accomplishments as a singles player \u2013 ranked Kournikova 18th in its \"25 Biggest Sports Flops of the Past 25 Years\". Kournikova was also ranked No.\u00a01 in the ESPN Classic series \"Who's number 1?\" when the series featured sport's most overrated athletes.\nIn 2002, \"Penthouse\" magazine published paparazzi photographs that purported to show Kournikova sunbathing topless on a Florida beach. Stating that the images were not of her, Kournikova sued the magazine's parent company, seeking damages of $10 million. The woman featured in the images, Judith E. Soltesz-Benetton, daughter-in-law of fashion designer Luciano Benetton, also sued for $10 million, saying the photos had been taken without her knowledge seven years earlier. \"Penthouse\" issued apologies to both women, withdrew the issue from further distribution, and settled the cases out of court.\nShe continued to be the most searched athlete on the Internet through 2008 even though she had retired from the professional tennis circuit years earlier. After slipping from first to sixth among athletes in 2009, she moved back up to third place among athletes in terms of search popularity in 2010.\nIn October 2010, Kournikova headed to NBC's \"The Biggest Loser\" where she led the contestants in a tennis-workout challenge. In May 2011, it was announced that Kournikova would join \"The Biggest Loser\" as a regular celebrity trainer in season 12. She did not return for season 13.\nCareer statistics and awards.\nDoubles performance timeline.\n&lt;templatestyles src=\"Template:Performance key/styles.css\"/&gt;\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;(W) winner; (F) finalist; (SF) semifinalist; (QF) quarterfinalist; (#R) rounds 4, 3, 2, 1; (RR) round-robin stage; (Q#) qualification round; (DNQ) did not qualify; (A) absent; (NH) not held; (SR) strike rate (events won / competed); (W\u2013L) win\u2013loss record.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "891", "revid": "1091098113", "url": "https://en.wikipedia.org/wiki?curid=891", "title": "Accountancy", "text": ""}
{"id": "892", "revid": "45880546", "url": "https://en.wikipedia.org/wiki?curid=892", "title": "Alfons Maria Jakob", "text": "German neurologist (1884\u20131931)\nAlfons Maria Jakob (2 July 1884 \u2013 17 October 1931) was a German neurologist who worked in the field of neuropathology.\nHe was born on 2 July 1884 in Aschaffenburg, Bavaria and educated in medicine at the universities of Munich, Berlin, and Strasbourg, where he received his doctorate in 1908. During the following year, he began clinical work under the psychiatrist Emil Kraepelin and did laboratory work with Franz Nissl and Alois Alzheimer in Munich.\nIn 1911, by way of an invitation from Wilhelm Weygandt, he relocated to Hamburg, where he worked with Theodor Kaes and eventually became head of the laboratory of anatomical pathology at the psychiatric State Hospital Hamburg-Friedrichsberg. Following the death of Kaes in 1913, Jakob succeeded him as prosector. During World War I he served as an army physician in Belgium, and afterwards returned to Hamburg. In 1919, he obtained his habilitation for neurology and in 1924 became a professor of neurology. Under Jakob's guidance the department grew rapidly. He made significant contributions to knowledge on concussion and secondary nerve degeneration and became a doyen of neuropathology.\nJakob was the author of five monographs and nearly 80 scientific papers. His neuropathological research contributed greatly to the delineation of several diseases, including multiple sclerosis and Friedreich's ataxia. He first recognised and described Alper's disease and Creutzfeldt\u2013Jakob disease (named along with Munich neuropathologist Hans Gerhard Creutzfeldt). He gained experience in neurosyphilis, having a 200-bed ward devoted entirely to that disorder. Jakob made a lecture tour of the United States (1924) and South America (1928), of which, he wrote a paper on the neuropathology of yellow fever.\nHe suffered from chronic osteomyelitis for the last seven years of his life. This eventually caused a retroperitoneal abscess and paralytic ileus from which he died following operation on 17 October 1931.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "894", "revid": "35393771", "url": "https://en.wikipedia.org/wiki?curid=894", "title": "Agnosticism", "text": "View that the existence of God or the supernatural are unknown or unknowable\nAgnosticism is the view or belief that the existence of God, the divine, or the supernatural is either unknowable in principle or unknown in fact. It can also mean an apathy towards such religious belief and refer to personal limitations rather than a worldview. Another definition is the view that \"human reason is incapable of providing sufficient rational grounds to justify either the belief that God exists or the belief that God does not exist.\"\nThe English biologist Thomas Henry Huxley said that he originally coined the word \"agnostic\" in 1869 \"to denote people who, like [himself], confess themselves to be hopelessly ignorant concerning a variety of matters [including the matter of God's existence], about which metaphysicians and theologians, both orthodox and heterodox, dogmatise with the utmost confidence.\" Earlier thinkers had written works that promoted agnostic points of view, such as Sanjaya Belatthiputta, a 5th-century BCE Indian philosopher who expressed agnosticism about any afterlife; and Protagoras, a 5th-century BCE Greek philosopher who expressed agnosticism about the existence of \"the gods\".\n&lt;templatestyles src=\"Template:TOC limit/styles.css\" /&gt;\nDefining agnosticism.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Thomas Henry Huxley\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Agnosticism, in fact, is not a creed, but a method, the essence of which lies in the rigorous application of a single principle\u00a0... Positively the principle may be expressed: In matters of the intellect, follow your reason as far as it will take you, without regard to any other consideration. And negatively: In matters of the intellect do not pretend that conclusions are certain which are not demonstrated or demonstrable.\u2014\u200a\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Thomas Henry Huxley\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Consequently, agnosticism puts aside not only the greater part of popular theology, but also the greater part of anti-theology. On the whole, the \"bosh\" of heterodoxy is more offensive to me than that of orthodoxy, because heterodoxy professes to be guided by reason and science, and orthodoxy does not.\u2014\u200a\nBeing a scientist, above all else, Huxley presented agnosticism as a form of demarcation. A hypothesis with no supporting, objective, testable evidence is not an objective, scientific claim. As such, there would be no way to test said hypotheses, leaving the results inconclusive. His agnosticism was not compatible with forming a belief as to the truth, or falsehood, of the claim at hand. Karl Popper would also describe himself as an agnostic. According to philosopher William L. Rowe, in this strict sense, agnosticism is the view that human reason is incapable of providing sufficient rational grounds to justify either the belief that God exists or the belief that God does not exist.\nGeorge H. Smith, while admitting that the narrow definition of atheist was the common usage definition of that word, and admitting that the broad definition of agnostic was the common usage definition of that word, promoted broadening the definition of atheist and narrowing the definition of agnostic. Smith rejects agnosticism as a third alternative to theism and atheism and promotes terms such as agnostic atheism (the view of those who do not hold a belief in the existence of any deity but claim that the existence of a deity is unknown or inherently unknowable) and agnostic theism (the view of those who believe in the existence of a deity(s) but claim that the existence of a deity is unknown or inherently unknowable).\nEtymology.\n\"Agnostic\" (from grc \" \u1f00- (a-)\"\u00a0'without' and \" \u03b3\u03bd\u1ff6\u03c3\u03b9\u03c2 (gn\u014dsis)\"\u00a0'knowledge') was used by Thomas Henry Huxley in a speech at a meeting of the Metaphysical Society in 1869 to describe his philosophy, which rejects all claims of spiritual or mystical knowledge.\nEarly Christian church leaders used the Greek word \"gnosis\" (knowledge) to describe \"spiritual knowledge\". Agnosticism is not to be confused with religious views opposing the ancient religious movement of Gnosticism in particular; Huxley used the term in a broader, more abstract sense. Huxley identified agnosticism not as a creed but rather as a method of skeptical, evidence-based inquiry.\nThe term \"agnostic\" is also cognate with the Sanskrit word \"aj\u00f1asi\", which translates literally to \"not knowable\", and relates to the ancient Indian philosophical school of Aj\u00f1ana, which proposes that it is impossible to obtain knowledge of metaphysical nature or ascertain the truth value of philosophical propositions; and even if knowledge were possible, it is useless and disadvantageous for final salvation.\nIn recent years, scientific literature dealing with neuroscience and psychology has used the word to mean \"not knowable\". In technical and marketing literature, \"agnostic\" can also mean independence from some parameters\u2014for example, \"platform agnostic\" (referring to cross-platform software), or \"hardware-agnostic\".\nQualifying agnosticism.\nScottish Enlightenment philosopher David Hume contended that meaningful statements about the universe are always qualified by some degree of doubt. He asserted that the fallibility of human beings means that they cannot obtain absolute certainty except in trivial cases where a statement is true by definition (e.g. tautologies such as \"all bachelors are unmarried\" or \"all triangles have three corners\").\nTypes.\nStrong agnosticism.\nAlso called \"hard\", \"closed\", \"strict\", or \"permanent agnosticism\", strong agnosticism is the view that the question of the existence or nonexistence of a deity or deities, and the nature of ultimate reality is unknowable by reason of our natural inability to verify any subjective experience with anything but another subjective experience. A strong agnostic would say, \"I cannot know whether a deity exists or not, and neither can you.\"\nWeak agnosticism.\nAlso called \"soft\", \"open\", \"empirical\", \"hopeful\", or \"temporal agnosticism\", weak agnosticism is the view that the existence or nonexistence of any deities is currently unknown but is not necessarily unknowable; therefore, one will withhold judgement until evidence, if any, becomes available. A weak agnostic would say, \"I don't know whether any deities exist or not, but maybe one day, if there is evidence, we can find something out.\"\nApathetic agnosticism.\nThe view that no amount of debate can prove or disprove the existence of one or more deities, and if one or more deities exist, they do not appear to be concerned about the fate of humans. Therefore, some may feel their existence has little to no impact on personal human affairs and should be of little interest. An apathetic agnostic would say, \"I don't know whether any deity exists or not, and I don't care if any deity exists or not.\"\nHistory.\nHindu philosophy.\nThroughout the history of Hinduism there has been a strong tradition of philosophic speculation and skepticism.\nThe Rig Veda takes an agnostic view on the fundamental question of how the universe and the gods were created. Nasadiya Sukta (\"Creation Hymn\") in the tenth chapter of the Rig Veda says:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;&lt;poem&gt;But, after all, who knows, and who can say\nWhence it all came, and how creation happened?\nThe gods themselves are later than creation,\nso who knows truly whence it has arisen?\nWhence all creation had its origin,\nHe, whether he fashioned it or whether he did not,\nHe, who surveys it all from highest heaven,\nHe knows \u2013 or maybe even he does not know.&lt;/poem&gt;\nHume, Kant, and Kierkegaard.\nAristotle,\nAnselm,\nAquinas,\nDescartes,\nand G\u00f6del presented arguments attempting to rationally prove the existence of God. The skeptical empiricism of David Hume, the antinomies of Immanuel Kant, and the existential philosophy of S\u00f8ren Kierkegaard convinced many later philosophers to abandon these attempts, regarding it impossible to construct any unassailable proof for the existence or non-existence of God.\nIn his 1844 book \"Philosophical Fragments\", Kierkegaard writes:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Let us call this unknown something: God. It is nothing more than a name we assign to it. The idea of demonstrating that this unknown something (God) exists, could scarcely suggest itself to Reason. For if God does not exist it would of course be impossible to prove it; and if he does exist it would be folly to attempt it. For at the very outset, in beginning my proof, I would have presupposed it, not as doubtful but as certain (a presupposition is never doubtful, for the very reason that it is a presupposition), since otherwise I would not begin, readily understanding that the whole would be impossible if he did not exist. But if when I speak of proving God's existence I mean that I propose to prove that the Unknown, which exists, is God, then I express myself unfortunately. For in that case I do not prove anything, least of all an existence, but merely develop the content of a conception.\nHume was Huxley's favourite philosopher, calling him \"the Prince of Agnostics\". Diderot wrote to his mistress, telling of a visit by Hume to the Baron D'Holbach, and describing how a word for the position that Huxley would later describe as agnosticism did not seem to exist, or at least was not common knowledge, at the time.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The first time that M. Hume found himself at the table of the Baron, he was seated beside him. I don't know for what purpose the English philosopher took it into his head to remark to the Baron that he did not believe in atheists, that he had never seen any. The Baron said to him: \"Count how many we are here.\" We are eighteen. The Baron added: \"It isn't too bad a showing to be able to point out to you fifteen at once: the three others haven't made up their minds.\"\u2014\u200a\nUnited Kingdom.\nCharles Darwin.\nRaised in a religious environment, Charles Darwin (1809\u20131882) studied to be an Anglican clergyman. While eventually doubting parts of his faith, Darwin continued to help in church affairs, even while avoiding church attendance. Darwin stated that it would be \"absurd to doubt that a man might be an ardent theist and an evolutionist\". Although reticent about his religious views, in 1879 he wrote that \"I have never been an atheist in the sense of denying the existence of a God. \u2013 I think that generally ... an agnostic would be the most correct description of my state of mind.\"\nThomas Henry Huxley.\nAgnostic views are as old as philosophical skepticism, but the terms agnostic and agnosticism were created by Huxley (1825\u20131895) to sum up his thoughts on contemporary developments of metaphysics about the \"unconditioned\" (William Hamilton) and the \"unknowable\" (Herbert Spencer). Though Huxley began to use the term \"agnostic\" in 1869, his opinions had taken shape some time before that date. In a letter of September 23, 1860, to Charles Kingsley, Huxley discussed his views extensively:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;I neither affirm nor deny the immortality of man. I see no reason for believing it, but, on the other hand, I have no means of disproving it. I have no \"a priori\" objections to the doctrine. No man who has to deal daily and hourly with nature can trouble himself about \"a priori\" difficulties. Give me such evidence as would justify me in believing in anything else, and I will believe that. Why should I not? It is not half so wonderful as the conservation of force or the indestructibility of matter\u00a0...\nIt is no use to talk to me of analogies and probabilities. I know what I mean when I say I believe in the law of the inverse squares, and I will not rest my life and my hopes upon weaker convictions\u00a0...\nThat my personality is the surest thing I know may be true. But the attempt to conceive what it is leads me into mere verbal subtleties. I have champed up all that chaff about the ego and the non-ego, noumena and phenomena, and all the rest of it, too often not to know that in attempting even to think of these questions, the human intellect flounders at once out of its depth.\nAnd again, to the same correspondent, May 6, 1863:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;I have never had the least sympathy with the \"a priori\" reasons against orthodoxy, and I have by nature and disposition the greatest possible antipathy to all the atheistic and infidel school. Nevertheless I know that I am, in spite of myself, exactly what the Christian would call, and, so far as I can see, is justified in calling, atheist and infidel. I cannot see one shadow or tittle of evidence that the great unknown underlying the phenomenon of the universe stands to us in the relation of a Father [who] loves us and cares for us as Christianity asserts. So with regard to the other great Christian dogmas, immortality of soul and future state of rewards and punishments, what possible objection can I\u2014who am compelled perforce to believe in the immortality of what we call Matter and Force, and in a very unmistakable present state of rewards and punishments for our deeds\u2014have to these doctrines? Give me a scintilla of evidence, and I am ready to jump at them.\nOf the origin of the name agnostic to describe this attitude, Huxley gave the following account:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;When I reached intellectual maturity and began to ask myself whether I was an atheist, a theist, or a pantheist; a materialist or an idealist; Christian or a freethinker; I found that the more I learned and reflected, the less ready was the answer; until, at last, I came to the conclusion that I had neither art nor part with any of these denominations, except the last. The one thing in which most of these good people were agreed was the one thing in which I differed from them. They were quite sure they had attained a certain \"gnosis\"\u2014had, more or less successfully, solved the problem of existence; while I was quite sure I had not, and had a pretty strong conviction that the problem was insoluble. And, with Hume and Kant on my side, I could not think myself presumptuous in holding fast by that opinion\u00a0...\nSo I took thought, and invented what I conceived to be the appropriate title of \"agnostic\". It came into my head as suggestively antithetic to the \"gnostic\" of Church history, who professed to know so much about the very things of which I was ignorant.\u00a0... To my great satisfaction the term took.\nWilliam Stewart Ross.\nWilliam Stewart Ross (1844\u20131906) wrote under the name of Saladin. He was associated with Victorian Freethinkers and the organization the British Secular Union. He edited the \"Secular Review\" from 1882; it was renamed \"Agnostic Journal and Eclectic Review\" and closed in 1907. Ross championed agnosticism in opposition to the atheism of Charles Bradlaugh as an open-ended spiritual exploration.\nIn \"Why I am an Agnostic\" (c.\u20091889) he claims that agnosticism is \"the very reverse of atheism\".\nBertrand Russell.\nBertrand Russell (1872\u20131970) declared \"Why I Am Not a Christian\" in 1927, a classic statement of agnosticism.\nHe calls upon his readers to \"stand on their own two feet and look fair and square at the world with a fearless attitude and a free intelligence\".\nIn 1939, Russell gave a lecture on \"The existence and nature of God\", in which he characterized himself as an atheist. He said:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The existence and nature of God is a subject of which I can discuss only half. If one arrives at a negative conclusion concerning the first part of the question, the second part of the question does not arise; and my position, as you may have gathered, is a negative one on this matter.\nHowever, later in the same lecture, discussing modern non-anthropomorphic concepts of God, Russell states:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;That sort of God is, I think, not one that can actually be disproved, as I think the omnipotent and benevolent creator can.\nIn Russell's 1947 pamphlet, \"Am I An Atheist or an Agnostic?\" (subtitled \"A Plea For Tolerance in the Face of New Dogmas\"), he ruminates on the problem of what to call himself:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;As a philosopher, if I were speaking to a purely philosophic audience I should say that I ought to describe myself as an Agnostic, because I do not think that there is a conclusive argument by which one can prove that there is not a God. On the other hand, if I am to convey the right impression to the ordinary man in the street I think I ought to say that I am an Atheist, because when I say that I cannot prove that there is not a God, I ought to add equally that I cannot prove that there are not the Homeric gods.\nIn his 1953 essay, \"What Is An Agnostic?\" Russell states:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;An agnostic thinks it impossible to know the truth in matters such as God and the future life with which Christianity and other religions are concerned. Or, if not impossible, at least impossible at the present time.\nAre Agnostics Atheists?\nNo. An atheist, like a Christian, holds that we can know whether or not there is a God. The Christian holds that we can know there is a God; the atheist, that we can know there is not. The Agnostic suspends judgment, saying that there are not sufficient grounds either for affirmation or for denial.\nLater in the essay, Russell adds:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;I think that if I heard a voice from the sky predicting all that was going to happen to me during the next twenty-four hours, including events that would have seemed highly improbable, and if all these events then produced to happen, I might perhaps be convinced at least of the existence of some superhuman intelligence.\nLeslie Weatherhead.\nIn 1965, Christian theologian Leslie Weatherhead (1893\u20131976) published \"The Christian Agnostic\", in which he argues:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;...\u00a0many professing agnostics are nearer belief in the true God than are many conventional church-goers who believe in a body that does not exist whom they miscall God.\nAlthough radical and unpalatable to conventional theologians, Weatherhead's \"agnosticism\" falls far short of Huxley's, and short even of \"weak agnosticism\":\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Of course, the human soul will always have the power to reject God, for choice is essential to its nature, but I cannot believe that anyone will finally do this.\nUnited States.\nRobert G. Ingersoll.\nRobert G. Ingersoll (1833\u20131899), an Illinois lawyer and politician who evolved into a well-known and sought-after orator in 19th-century America, has been referred to as the \"Great Agnostic\".\nIn an 1896 lecture titled \"Why I Am An Agnostic\", Ingersoll stated this: \n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Is there a supernatural power\u2014an arbitrary mind\u2014an enthroned God\u2014a supreme will that sways the tides and currents of the world\u2014to which all causes bow? I do not deny. I do not know\u2014but I do not believe. I believe that the natural is supreme\u2014that from the infinite chain no link can be lost or broken\u2014that there is no supernatural power that can answer prayer\u2014no power that worship can persuade or change\u2014no power that cares for man.\nI believe that with infinite arms Nature embraces the all\u2014that there is no interference\u2014no chance\u2014that behind every event are the necessary and countless causes, and that beyond every event will be and must be the necessary and countless effects.\nIs there a God? I do not know. Is man immortal? I do not know. One thing I do know, and that is, that neither hope, nor fear, belief, nor denial, can change the fact. It is as it is, and it will be as it must be.\nIn the conclusion of the speech he simply sums up the agnostic position as:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;We can be as honest as we are ignorant. If we are, when asked what is beyond the horizon of the known, we must say that we do not know.\nIn 1885, Ingersoll explained his comparative view of agnosticism and atheism as follows:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The Agnostic is an Atheist. The Atheist is an Agnostic. The Agnostic says, 'I do not know, but I do not believe there is any God.' The Atheist says the same.\nBernard Iddings Bell.\nCanon Bernard Iddings Bell (1886\u20131958), a popular cultural commentator, Episcopal priest, and author, lauded the necessity of agnosticism in \"Beyond Agnosticism: A Book for Tired Mechanists\", calling it the foundation of \"all intelligent Christianity\". Agnosticism was a temporary mindset in which one rigorously questioned the truths of the age, including the way in which one believed God. His view of Robert Ingersoll and Thomas Paine was that they were not denouncing true Christianity but rather \"a gross perversion of it\". Part of the misunderstanding stemmed from ignorance of the concepts of God and religion. Historically, a god was any real, perceivable force that ruled the lives of humans and inspired admiration, love, fear, and homage; religion was the practice of it. Ancient peoples worshiped gods with real counterparts, such as Mammon (money and material things), Nabu (rationality), or Ba'al (violent weather); Bell argued that modern peoples were still paying homage\u2014with their lives and their children's lives\u2014to these old gods of wealth, physical appetites, and self-deification. Thus, if one attempted to be agnostic passively, he or she would incidentally join the worship of the world's gods.\nIn \"Unfashionable Convictions\" (1931), he criticized the Enlightenment's complete faith in human sensory perception, augmented by scientific instruments, as a means of accurately grasping Reality. Firstly, it was fairly new, an innovation of the Western World, which Aristotle invented and Thomas Aquinas revived among the scientific community. Secondly, the divorce of \"pure\" science from human experience, as manifested in American Industrialization, had completely altered the environment, often disfiguring it, so as to suggest its insufficiency to human needs. Thirdly, because scientists were constantly producing more data\u2014to the point where no single human could grasp it all at once\u2014it followed that human intelligence was incapable of attaining a complete understanding of universe; therefore, to admit the mysteries of the unobserved universe was to be \"actually\" scientific.\nBell believed that there were two other ways that humans could perceive and interact with the world. \"Artistic experience\" was how one expressed meaning through speaking, writing, painting, gesturing\u2014any sort of communication which shared insight into a human's inner reality. \"Mystical experience\" was how one could \"read\" people and harmonize with them, being what we commonly call love. In summary, man was a scientist, artist, and lover. Without exercising all three, a person became \"lopsided\".\nBell considered a humanist to be a person who cannot rightly ignore the other ways of knowing. However, humanism, like agnosticism, was also temporal, and would eventually lead to either scientific materialism or theism. He lays out the following thesis:\nDemographics.\nDemographic research services normally do not differentiate between various types of non-religious respondents, so agnostics are often classified in the same category as atheists or other non-religious people.\nA 2010 survey published in \"Encyclop\u00e6dia Britannica\" found that the non-religious people or the agnostics made up about 9.6% of the world's population.\nA November\u2013December 2006 poll published in the \"Financial Times\" gives rates for the United States and five European countries. The rates of agnosticism in the United States were at 14%, while the rates of agnosticism in the European countries surveyed were considerably higher: Italy (20%), Spain (30%), Great Britain (35%), Germany (25%), and France (32%).\nA study conducted by the Pew Research Center found that about 16% of the world's people, the third largest group after Christianity and Islam, have no religious affiliation.\nAccording to a 2012 report by the Pew Research Center, agnostics made up 3.3% of the US adult population.\nIn the \"U.S. Religious Landscape Survey\", conducted by the Pew Research Center, 55% of agnostic respondents expressed \"a belief in God or a universal spirit\",\nwhereas 41% stated that they thought that they felt a tension \"being non-religious in a society where most people are religious\".\nAccording to the 2021 Australian Bureau of Statistics, 38.9% of Australians have \"no religion\", a category that includes agnostics.\nBetween 64% and 65% of Japanese, and up to 81% of Vietnamese, are atheists, agnostics, or do not believe in a god. An official European Union survey reported that 3% of the EU population is unsure about their belief in a god or spirit.\nPsychology.\nRecent psychological studies in European secularized countries compared agnostics to atheists\u2014and sometimes to Christians too\u2014on their personality characteristics and various beliefs and worldviews. It was found that agnostics, compared to atheists, tend to be more prosocial; and, compared to atheists and Christians, they tend to be more open-minded and curious and to self-enhance less, i.e., do not overestimate themselves compared to other people in general. Also compared to both atheists and Christians, they may be more neurotic and indecisive in general in life, thus unhappier, across the European countries of Protestant or Catholic religious heritage. Furthermore, agnostics, compared to atheists, tend to value science, individualism, and materialism less, and have less negative attitudes regarding religion, spirituality, paranormal beliefs, and intuitive (non-analytic) thinking. Finally, an analysis of European Values Study data from Western European secularized countries showed that the more societies secularize, more nonreligious people report being atheist rather than agnostic; nevertheless, the agnostics continue to be an important part of the nonreligious. \nCriticism.\nAgnosticism is criticized from a variety of standpoints. Some atheists criticize the use of the term agnosticism as functionally indistinguishable from atheism; this results in frequent criticisms of those who adopt the term as avoiding the atheist label.\nTheistic.\nTheistic critics claim that agnosticism is impossible in practice, since a person can live only either as if God did not exist (\"etsi deus non-daretur\"), or as if God did exist (\"etsi deus daretur\").\nChristian.\nAccording to Pope Benedict XVI, strong agnosticism in particular contradicts itself in affirming the power of reason to know scientific truth. He blames the exclusion of reasoning from religion and ethics for dangerous pathologies such as crimes against humanity and ecological disasters.\n\"Agnosticism\", said Benedict, \"is always the fruit of a refusal of that knowledge which is in fact offered to man\u00a0... The knowledge of God has always existed\". He asserted that agnosticism is a choice of comfort, pride, dominion, and utility over truth, and is opposed by the following attitudes: the keenest self-criticism, humble listening to the whole of existence, the persistent patience and self-correction of the scientific method, a readiness to be purified by the truth.\nThe Catholic Church sees merit in examining what it calls \"partial agnosticism\", specifically those systems that \"do not aim at constructing a complete philosophy of the unknowable, but at excluding special kinds of truth, notably religious, from the domain of knowledge\". However, the Church is historically opposed to a full denial of the capacity of human reason to know God. The Council of the Vatican declares, \"God, the beginning and end of all, can, by the natural light of human reason, be known with certainty from the works of creation\".\nBlaise Pascal argued that even if there were truly no evidence for God, agnostics should consider what is now known as Pascal's Wager: the infinite expected value of acknowledging God is always greater than the finite expected value of not acknowledging his existence, and thus it is a safer \"bet\" to choose God.\nAtheistic.\nAccording to Richard Dawkins, a distinction between agnosticism and atheism is unwieldy and depends on how close to zero a person is willing to rate the probability of existence for any given god-like entity. About himself, Dawkins continues, \"I am agnostic only to the extent that I am agnostic about fairies at the bottom of the garden.\" Dawkins also identifies two categories of agnostics; \"Temporary Agnostics in Practice\" (TAPs), and \"Permanent Agnostics in Principle\" (PAPs). He states that \"agnosticism about the existence of God belongs firmly in the temporary or TAP category. Either he exists or he doesn't. It is a scientific question; one day we may know the answer, and meanwhile we can say something pretty strong about the probability\", and considers PAP a \"deeply inescapable kind of fence-sitting\".\nIgnosticism.\nA related concept is ignosticism, the view that a coherent definition of a deity must be put forward before the question of the existence of a deity can be meaningfully discussed. If the chosen definition is not coherent, the ignostic holds the noncognitivist view that the existence of a deity is meaningless or empirically untestable. A.\u00a0J. Ayer, Theodore Drange, and other philosophers see both atheism and agnosticism as incompatible with ignosticism on the grounds that atheism and agnosticism accept the statement \"a deity exists\" as a meaningful proposition that can be argued for or against.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "896", "revid": "7903804", "url": "https://en.wikipedia.org/wiki?curid=896", "title": "Argon", "text": "element with atomic number 18 (Ar)\nArgon is a chemical element; it has symbol Ar and atomic number 18. It is in group 18 of the periodic table and is a noble gas. Argon is the third most abundant gas in Earth's atmosphere, at 0.934% (9340 ppmv). It is more than twice as abundant as water vapor (which averages about 4000 ppmv, but varies greatly), 23 times as abundant as carbon dioxide (400 ppmv), and more than 500 times as abundant as neon (18 ppmv). Argon is the most abundant noble gas in Earth's crust, comprising 0.00015% of the crust.\nNearly all argon in Earth's atmosphere is radiogenic argon-40, derived from the decay of potassium-40 in Earth's crust. In the universe, argon-36 is by far the most common argon isotope, as it is the most easily produced by stellar nucleosynthesis in supernovas.\nThe name \"argon\" is derived from the Ancient Greek word , neuter singular form of meaning 'lazy' or 'inactive', as a reference to the fact that the element undergoes almost no chemical reactions. The complete octet (eight electrons) in the outer atomic shell makes argon stable and resistant to bonding with other elements. Its triple point temperature of 83.8058\u00a0K is a defining fixed point in the International Temperature Scale of 1990.\nArgon is extracted industrially by the fractional distillation of liquid air. It is mostly used as an inert shielding gas in welding and other high-temperature industrial processes where ordinarily unreactive substances become reactive; for example, an argon atmosphere is used in graphite electric furnaces to prevent the graphite from burning. It is also used in incandescent and fluorescent lighting, and other gas-discharge tubes. It makes a distinctive blue-green gas laser. It is also used in fluorescent glow starters.\nCharacteristics.\nArgon has approximately the same solubility in water as oxygen and is 2.5 times more soluble in water than nitrogen. Argon is colorless, odorless, nonflammable and nontoxic as a solid, liquid or gas. Argon is chemically inert under most conditions and forms no confirmed stable compounds at room temperature.\nAlthough argon is a noble gas, it can form some compounds under various extreme conditions. Argon fluorohydride (HArF), a compound of argon with fluorine and hydrogen that is stable below , has been demonstrated. Although the neutral ground-state chemical compounds of argon are presently limited to HArF, argon can form clathrates with water when atoms of argon are trapped in a lattice of water molecules. Ions, such as ArH+, and excited-state complexes, such as ArF, have been demonstrated. Theoretical calculation predicts several more argon compounds that should be stable but have not yet been synthesized.\nHistory.\n\"Argon\" (Ancient Greek , neuter singular form of meaning \"lazy\" or \"inactive\") is named in reference to its chemical inactivity. This chemical property of this first noble gas to be discovered impressed the namers. An unreactive gas was suspected to be a component of air by Henry Cavendish in 1785.\nArgon was first isolated from air in 1894 by Lord Rayleigh and Sir William Ramsay at University College London by removing oxygen, carbon dioxide, water, and nitrogen from a sample of clean air. They first accomplished this by replicating an experiment of Henry Cavendish's. They trapped a mixture of atmospheric air with additional oxygen in a test-tube (A) upside-down over a large quantity of dilute alkali solution (B), which in Cavendish's original experiment was potassium hydroxide, and conveyed a current through wires insulated by U-shaped glass tubes (CC) which sealed around the platinum wire electrodes, leaving the ends of the wires (DD) exposed to the gas and insulated from the alkali solution. The arc was powered by a battery of five Grove cells and a Ruhmkorff coil of medium size. The alkali absorbed the oxides of nitrogen produced by the arc and also carbon dioxide. They operated the arc until no more reduction of volume of the gas could be seen for at least an hour or two and the spectral lines of nitrogen disappeared when the gas was examined. The remaining oxygen was reacted with alkaline pyrogallate to leave behind an apparently non-reactive gas which they called argon.\nBefore isolating the gas, they had determined that nitrogen produced from chemical compounds was 0.5% lighter than nitrogen from the atmosphere. The difference was slight, but it was important enough to attract their attention for many months. They concluded that there was another gas in the air mixed in with the nitrogen. Argon was also encountered in 1882 through independent research of H. F. Newall and W. N. Hartley. Each observed new lines in the emission spectrum of air that did not match known elements.\nPrior to 1957, the symbol for argon was \"A\". This was changed to Ar after the International Union of Pure and Applied Chemistry published the work \"Nomenclature of Inorganic Chemistry\" in 1957.\nOccurrence.\nArgon constitutes 0.934% by volume and 1.288% by mass of Earth's atmosphere. Air is the primary industrial source of purified argon products. Argon is isolated from air by fractionation, most commonly by cryogenic fractional distillation, a process that also produces purified nitrogen, oxygen, neon, krypton and xenon. Earth's crust and seawater contain 1.2 ppm and 0.45 ppm of argon, respectively.\nIsotopes.\nThe main isotopes of argon found on Earth are 40Ar (99.6%), 36Ar (0.34%), and 38Ar (0.06%). Naturally occurring 40K, with a half-life of 1.25\u00d7109 years, decays to stable 40Ar (11.2%) by electron capture or positron emission, and also to stable 40Ca (88.8%) by beta decay. These properties and ratios are used to determine the age of rocks by K\u2013Ar dating.\nIn Earth's atmosphere, 39Ar is made by cosmic ray activity, primarily by neutron capture of 40Ar followed by two-neutron emission. In the subsurface environment, it is also produced through neutron capture by 39K, followed by proton emission. 37Ar is created from the neutron capture by 40Ca followed by an alpha particle emission as a result of subsurface nuclear explosions. It has a half-life of 35 days.\nBetween locations in the Solar System, the isotopic composition of argon varies greatly. Where the major source of argon is the decay of 40K in rocks, 40Ar will be the dominant isotope, as it is on Earth. Argon produced directly by stellar nucleosynthesis is dominated by the alpha-process nuclide 36Ar. Correspondingly, solar argon contains 84.6% 36Ar (according to solar wind measurements), and the ratio of the three isotopes 36Ar\u00a0:\u00a038Ar\u00a0:\u00a040Ar in the atmospheres of the outer planets is 8400\u00a0:\u00a01600\u00a0:\u00a01. This contrasts with the low abundance of primordial 36Ar in Earth's atmosphere, which is only 31.5 ppmv (= 9340 ppmv \u00d7 0.337%), comparable with that of neon (18.18 ppmv) on Earth and with interplanetary gasses, measured by probes.\nThe atmospheres of Mars, Mercury and Titan (the largest moon of Saturn) contain argon, predominantly as 40Ar.\nThe predominance of radiogenic 40Ar is the reason the standard atomic weight of terrestrial argon is greater than that of the next element, potassium, a fact that was puzzling when argon was discovered. Mendeleev positioned the elements on his periodic table in order of atomic weight, but the inertness of argon suggested a placement \"before\" the reactive alkali metal. Henry Moseley later solved this problem by showing that the periodic table is actually arranged in order of atomic number (see History of the periodic table).\nCompounds.\nArgon's complete octet of electrons indicates full s and p subshells. This full valence shell makes argon very stable and extremely resistant to bonding with other elements. Before 1962, argon and the other noble gases were considered to be chemically inert and unable to form compounds; however, compounds of the heavier noble gases have since been synthesized. The first argon compound with tungsten pentacarbonyl, W(CO)5Ar, was isolated in 1975. However, it was not widely recognised at that time. In August 2000, another argon compound, argon fluorohydride (HArF), was formed by researchers at the University of Helsinki, by shining ultraviolet light onto frozen argon containing a small amount of hydrogen fluoride with caesium iodide. This discovery caused the recognition that argon could form weakly bound compounds, even though it was not the first. It is stable up to 17\u00a0kelvins (\u2212256\u00a0\u00b0C). The metastable ArCF22+ dication, which is valence-isoelectronic with carbonyl fluoride and phosgene, was observed in 2010. Argon-36, in the form of argon hydride (argonium) ions, has been detected in interstellar medium associated with the Crab Nebula supernova; this was the first noble-gas molecule detected in outer space.\nSolid argon hydride (Ar(H2)2) has the same crystal structure as the MgZn2 Laves phase. It forms at pressures between 4.3 and 220 GPa, though Raman measurements suggest that the H2 molecules in Ar(H2)2 dissociate above 175 GPa.\nProduction.\nArgon is extracted industrially by the fractional distillation of liquid air in a cryogenic air separation unit; a process that separates liquid nitrogen, which boils at 77.3\u00a0K, from argon, which boils at 87.3\u00a0K, and liquid oxygen, which boils at 90.2\u00a0K. About 700,000 tonnes of argon are produced worldwide every year.\nApplications.\nArgon has several desirable properties:\nOther noble gases would be equally suitable for most of these applications, but argon is by far the cheapest. It is inexpensive, since it occurs naturally in air and is readily obtained as a byproduct of cryogenic air separation in the production of liquid oxygen and liquid nitrogen: the primary constituents of air are used on a large industrial scale. The other noble gases (except helium) are produced this way as well, but argon is the most plentiful by far. The bulk of its applications arise simply because it is inert and relatively cheap.\nIndustrial processes.\nArgon is used in some high-temperature industrial processes where ordinarily non-reactive substances become reactive. For example, an argon atmosphere is used in graphite electric furnaces to prevent the graphite from burning.\nFor some of these processes, the presence of nitrogen or oxygen gases might cause defects within the material. Argon is used in some types of arc welding such as gas metal arc welding and gas tungsten arc welding, as well as in the processing of titanium and other reactive elements. An argon atmosphere is also used for growing crystals of silicon and germanium.\nArgon is used in the poultry industry to asphyxiate birds, either for mass culling following disease outbreaks, or as a means of slaughter more humane than electric stunning. Argon is denser than air and displaces oxygen close to the ground during inert gas asphyxiation. Its non-reactive nature makes it suitable in a food product, and since it replaces oxygen within the dead bird, argon also enhances shelf life.\nArgon is sometimes used for extinguishing fires where valuable equipment may be damaged by water or foam.\nScientific research.\nLiquid argon is used as the target for neutrino experiments and direct dark matter searches. The interaction between the hypothetical WIMPs and an argon nucleus produces scintillation light that is detected by photomultiplier tubes. Two-phase detectors containing argon gas are used to detect the ionized electrons produced during the WIMP\u2013nucleus scattering. As with most other liquefied noble gases, argon has a high scintillation light yield (about 51 photons/keV), is transparent to its own scintillation light, and is relatively easy to purify. Compared to xenon, argon is cheaper and has a distinct scintillation time profile, which allows the separation of electronic recoils from nuclear recoils. On the other hand, its intrinsic beta-ray background is larger due to 39Ar contamination, unless one uses argon from underground sources, which has much less 39Ar contamination. Most of the argon in Earth's atmosphere was produced by electron capture of long-lived 40K (40K + e\u2212 \u2192 40Ar + \u03bd) present in natural potassium within Earth. The 39Ar activity in the atmosphere is maintained by cosmogenic production through the knockout reaction 40Ar(n,2n)39Ar and similar reactions. The half-life of 39Ar is only 269\u00a0years. As a result, the underground Ar, shielded by rock and water, has much less 39Ar contamination. Dark-matter detectors currently operating with liquid argon include DarkSide, WArP, ArDM, microCLEAN and DEAP. Neutrino experiments include ICARUS and MicroBooNE, both of which use high-purity liquid argon in a time projection chamber for fine grained three-dimensional imaging of neutrino interactions.\nAt Link\u00f6ping University, Sweden, the inert gas is being utilized in a vacuum chamber in which plasma is introduced to ionize metallic films. This process results in a film usable for manufacturing computer processors. The new process would eliminate the need for chemical baths and use of expensive, dangerous and rare materials.\nPreservative.\nArgon is used to displace oxygen- and moisture-containing air in packaging material to extend the shelf-lives of the contents (argon has the European food additive code E938). Aerial oxidation, hydrolysis, and other chemical reactions that degrade the products are retarded or prevented entirely. High-purity chemicals and pharmaceuticals are sometimes packed and sealed in argon.\nIn winemaking, argon is used in a variety of activities to provide a barrier against oxygen at the liquid surface, which can spoil wine by fueling both microbial metabolism (as with acetic acid bacteria) and standard redox chemistry.\nArgon is sometimes used as the propellant in aerosol cans.\nArgon is also used as a preservative for such products as varnish, polyurethane, and paint, by displacing air to prepare a container for storage.\nSince 2002, the American National Archives stores important national documents such as the Declaration of Independence and the Constitution within argon-filled cases to inhibit their degradation. Argon is preferable to the helium that had been used in the preceding five decades, because helium gas escapes through the intermolecular pores in most containers and must be regularly replaced.\nLaboratory equipment.\nArgon may be used as the inert gas within Schlenk lines and gloveboxes. Argon is preferred to less expensive nitrogen in cases where nitrogen may react with the reagents or apparatus.\nArgon may be used as the carrier gas in gas chromatography and in electrospray ionization mass spectrometry; it is the gas of choice for the plasma used in ICP spectroscopy. Argon is preferred for the sputter coating of specimens for scanning electron microscopy. Argon gas is also commonly used for sputter deposition of thin films as in microelectronics and for wafer cleaning in microfabrication.\nMedical use.\nCryosurgery procedures such as cryoablation use liquid argon to destroy tissue such as cancer cells. It is used in a procedure called \"argon-enhanced coagulation\", a form of argon plasma beam electrosurgery. The procedure carries a risk of producing gas embolism and has resulted in the death of at least one patient.\nBlue argon lasers are used in surgery to weld arteries, destroy tumors, and correct eye defects.\nArgon has also been used experimentally to replace nitrogen in the breathing or decompression mix known as Argox, to speed the elimination of dissolved nitrogen from the blood.\nLighting.\nIncandescent lights are filled with argon, to preserve the filaments at high temperature from oxidation. It is used for the specific way it ionizes and emits light, such as in plasma globes and calorimetry in experimental particle physics. Gas-discharge lamps filled with pure argon provide lilac/violet light; with argon and some mercury, blue light. Argon is also used for blue and green argon-ion lasers.\nMiscellaneous uses.\nArgon is used for thermal insulation in energy-efficient windows. Argon is also used in technical scuba diving to inflate a dry suit because it is inert and has low thermal conductivity.\nArgon is used as a propellant in the development of the Variable Specific Impulse Magnetoplasma Rocket (VASIMR). Compressed argon gas is allowed to expand, to cool the seeker heads of some versions of the AIM-9 Sidewinder missile and other missiles that use cooled thermal seeker heads. The gas is stored at high pressure.\nArgon-39, with a half-life of 269 years, has been used for a number of applications, primarily ice core and ground water dating. Also, potassium\u2013argon dating and related argon-argon dating are used to date sedimentary, metamorphic, and igneous rocks.\nArgon has been used by athletes as a doping agent to simulate hypoxic conditions. In 2014, the World Anti-Doping Agency (WADA) added argon and xenon to the list of prohibited substances and methods, although at this time there is no reliable test for abuse.\nSafety.\nAlthough argon is non-toxic, it is 38% more dense than air and therefore considered a dangerous asphyxiant in closed areas. It is difficult to detect because it is colorless, odorless, and tasteless. A 1994 incident, in which a man was asphyxiated after entering an argon-filled section of oil pipe under construction in Alaska, highlights the dangers of argon tank leakage in confined spaces and emphasizes the need for proper use, storage and handling.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "897", "revid": "14383484", "url": "https://en.wikipedia.org/wiki?curid=897", "title": "Arsenic", "text": "element with atomic number 33 (As)\nArsenic is a chemical element; it has symbol As and atomic number\u00a033. It is a metalloid and one of the pnictogens, and therefore shares many properties with its group 15 neighbors phosphorus and antimony. Arsenic is notoriously toxic. It occurs naturally in many minerals, usually in combination with sulfur and metals, but also as a pure elemental crystal. It has various allotropes, but only the grey form, which has a metallic appearance, is important to industry.\nThe primary use of arsenic is in alloys of lead (for example, in car batteries and ammunition). Arsenic is also a common n-type dopant in semiconductor electronic devices, and a component of the III\u2013V compound semiconductor gallium arsenide. Arsenic and its compounds, especially the trioxide, are used in the production of pesticides, treated wood products, herbicides, and insecticides. These applications are declining with the increasing recognition of the persistent toxicity of arsenic and its compounds.\nArsenic has been known since ancient times to be poisonous to humans. However, a few species of bacteria are able to use arsenic compounds as respiratory metabolites. Trace quantities of arsenic have been proposed to be an essential dietary element in rats, hamsters, goats, and chickens. Research has not been conducted to determine whether small amounts of arsenic may play a role in human metabolism. However, arsenic poisoning occurs in multicellular life if quantities are larger than needed. Arsenic contamination of groundwater is a problem that affects millions of people across the world.\nThe United States' Environmental Protection Agency states that all forms of arsenic are a serious risk to human health. The United States Agency for Toxic Substances and Disease Registry ranked arsenic number\u00a01 in its 2001 prioritized list of hazardous substances at Superfund sites. Arsenic is classified as a group-A carcinogen.\nCharacteristics.\nPhysical characteristics.\nThe three most common arsenic allotropes are grey, yellow, and black arsenic, with grey being the most common. Grey arsenic (\u03b1-As, space group R3m No. 166) adopts a double-layered structure consisting of many interlocked, ruffled, six-membered rings. Because of weak bonding between the layers, grey arsenic is brittle and has a relatively low Mohs hardness of 3.5. Nearest and next-nearest neighbors form a distorted octahedral complex, with the three atoms in the same double-layer being slightly closer than the three atoms in the next. This relatively close packing leads to a high density of 5.73\u00a0g/cm3. Grey arsenic is a semimetal, but becomes a semiconductor with a bandgap of 1.2\u20131.4\u00a0eV if amorphized. Grey arsenic is also the most stable form. Yellow arsenic is soft and waxy, and somewhat similar to tetraphosphorus (). Both have four atoms arranged in a tetrahedral structure in which each atom is bound to each of the other three atoms by a single bond. This unstable allotrope, being molecular, is the most volatile, least dense, and most toxic. Solid yellow arsenic is produced by rapid cooling of arsenic vapor, . It is rapidly transformed into grey arsenic by light. The yellow form has a density of 1.97\u00a0g/cm3. Black arsenic is similar in structure to black phosphorus.\nBlack arsenic can also be formed by cooling vapor at around 100\u2013220\u00a0\u00b0C and by crystallization of amorphous arsenic in the presence of mercury vapors. It is glassy and brittle. Black arsenic is also a poor electrical conductor.\nArsenic sublimes upon heating at atmospheric pressure, converting directly to a gaseous form without an intervening liquid state at . However, at 817\u00a0\u00b0C and 28 atm, arsenic melts. The triple point is at 3.63\u00a0MPa and .\nIsotopes.\nArsenic occurs naturally as a single stable isotope, 75As. Synthetic radioisotopes are known from 64As to 95As, as well as at least 11 isomers.\nThe most stable of these are 73As with a half-life of 80.30 days and 74As with a half-life of 17.77 days, followed by 71As (65.30 hours), 77As (38.79 hours), 76As (26.24 hours), and 72As (26.0 hours). All others have half-lives under 100 minutes and most under one minute. Isotopes lighter than the stable one generally decay by positron emission or electron capture to germanium isotopes, while those heavier beta decay to selenium isotopes. A notable exception is that 74As decays both ways.\nChemistry.\nArsenic has a similar electronegativity and ionization energies to its lighter pnictogen congener phosphorus and therefore readily forms covalent molecules with most of the nonmetals. Though stable in dry air, arsenic forms a golden-bronze tarnish upon exposure to humidity which eventually becomes a black surface layer. When heated in air, arsenic oxidizes to arsenic trioxide; the fumes from this reaction have an odor resembling garlic. This odor can be detected on striking arsenide minerals such as arsenopyrite with a hammer. It burns in oxygen to form arsenic trioxide and arsenic pentoxide, which have the same structure as the more well-known phosphorus compounds, and in fluorine to give arsenic pentafluoride. Arsenic makes arsenic acid with concentrated nitric acid, arsenous acid with dilute nitric acid, and arsenic trioxide with concentrated sulfuric acid; however, it does not react with water, alkalis, or non-oxidising acids. Arsenic reacts with metals to form arsenides, though these are not ionic compounds containing the As3\u2212 ion as the formation of such an anion would be highly endothermic and even the group 1 arsenides have properties of intermetallic compounds. Like germanium, selenium, and bromine, which like arsenic succeed the 3d transition series, arsenic is much less stable in the +5 oxidation state than its vertical neighbors phosphorus and antimony, and hence arsenic pentoxide and arsenic acid are potent oxidizers.\nCompounds.\nCompounds of arsenic resemble, in some respects, those of phosphorus, which occupies the same group (column) of the periodic table. The most common oxidation states for arsenic are: \u22123 in the arsenides, which are alloy-like intermetallic compounds, +3 in the arsenites, and +5 in the arsenates and most organoarsenic compounds. Arsenic also bonds readily to itself as seen in the square ions in the mineral skutterudite. In the +3 oxidation state, arsenic is typically pyramidal owing to the influence of the lone pair of electrons.\nInorganic compounds.\nOne of the simplest arsenic compounds is the trihydride, the highly toxic, flammable, pyrophoric arsine (AsH3). This compound is generally regarded as stable, since at room temperature it decomposes only slowly. At temperatures of 250\u2013300\u00a0\u00b0C decomposition to arsenic and hydrogen is rapid. Several factors, such as humidity, presence of light and certain catalysts (namely aluminium) facilitate the rate of decomposition. It oxidises readily in air to form arsenic trioxide and water, and analogous reactions take place with sulfur and selenium instead of oxygen.\nArsenic forms colorless, odorless, crystalline oxides As2O3 (\"white arsenic\") and As2O5 which are hygroscopic and readily soluble in water to form acidic solutions. Arsenic(V) acid is a weak acid and its salts, known as arsenates, are a major source of arsenic contamination of groundwater in regions with high levels of naturally occurring arsenic minerals. Synthetic arsenates include Scheele's Green (cupric hydrogen arsenate, acidic copper arsenate), calcium arsenate, and lead hydrogen arsenate. These three have been used as agricultural insecticides and poisons.\nThe protonation steps between the arsenate and arsenic acid are similar to those between phosphate and phosphoric acid. Unlike phosphorous acid, arsenous acid is genuinely tribasic, with the formula As(OH)3.\nA broad variety of sulfur compounds of arsenic are known. Orpiment (As2S3) and realgar (As4S4) are somewhat abundant and were formerly used as painting pigments. In As4S10, arsenic has a formal oxidation state of +2 in As4S4 which features As-As bonds so that the total covalency of As is still 3. Both orpiment and realgar, as well as As4S3, have selenium analogs; the analogous As2Te3 is known as the mineral kalgoorlieite, and the anion As2Te\u2212 is known as a ligand in cobalt complexes.\nAll trihalides of arsenic(III) are well known except the astatide, which is unknown. Arsenic pentafluoride (AsF5) is the only important pentahalide, reflecting the lower stability of the +5 oxidation state; even so, it is a very strong fluorinating and oxidizing agent. (The pentachloride is a kind of yellow solid that is only stable below \u221250\u00a0\u00b0C, at which temperature it decomposes to the trichloride, releasing chlorine gas.)\nAlloys.\nArsenic is used as the group 5 element in the III-V semiconductors gallium arsenide, indium arsenide, and aluminium arsenide. The valence electron count of GaAs is the same as a pair of Si atoms, but the band structure is completely different which results in distinct bulk properties. Other arsenic alloys include the II-V semiconductor cadmium arsenide.\nOrganoarsenic compounds.\nA large variety of organoarsenic compounds are known. Several were developed as chemical warfare agents during World War I, including vesicants such as lewisite and vomiting agents such as adamsite. Cacodylic acid, which is of historic and practical interest, arises from the methylation of arsenic trioxide, a reaction that has no analogy in phosphorus chemistry. Cacodyl was the first organometallic compound known (even though arsenic is not a true metal) and was named from the Greek \"\u03ba\u03b1\u03ba\u03c9\u03b4\u03af\u03b1\" \"stink\" for its offensive, garlic-like odor; it is very toxic.\nOccurrence and production.\nArsenic is the 53rd most abundant element in the Earth's crust, comprising about 1.5\u00a0parts per million\u00a0(0.00015%). Typical background concentrations of arsenic do not exceed 3\u00a0ng/m3 in the atmosphere; 100\u00a0mg/kg in soil; 400\u00a0\u03bcg/kg in vegetation; 10\u00a0\u03bcg/L in freshwater and 1.5\u00a0\u03bcg/L in seawater. Arsenic is the 22nd most abundant element in seawater and ranks 41st in abundance in the universe.\nMinerals with the formula MAsS and MAs2 (M = Fe, Ni, Co) are the dominant commercial sources of arsenic, together with realgar (an arsenic sulfide mineral) and native (elemental) arsenic. An illustrative mineral is arsenopyrite (FeAsS), which is structurally related to iron pyrite. Many minor As-containing minerals are known. Arsenic also occurs in various organic forms in the environment.\nIn 2014, China was the top producer of white arsenic with almost 70% world share, followed by Morocco, Russia, and Belgium, according to the British Geological Survey and the United States Geological Survey. Most arsenic refinement operations in the US and Europe have closed over environmental concerns. Arsenic is found in the smelter dust from copper, gold, and lead smelters, and is recovered primarily from copper refinement dust. Arsenic is the main impurity found in copper concentrates to enter copper smelting facilities. There has been an increase in arsenic in copper concentrates over the years since copper mining has moved into deep high-impurity ores as shallow, low-arsenic copper deposits have been progressively depleted.\nOn roasting arsenopyrite in air, arsenic sublimes as arsenic(III) oxide leaving iron oxides, while roasting without air results in the production of gray arsenic. Further purification from sulfur and other chalcogens is achieved by sublimation in vacuum, in a hydrogen atmosphere, or by distillation from molten lead-arsenic mixture.\nHistory.\nThe word \"arsenic\" has its origin in the Syriac word \"zarnika\", from Arabic al-zarn\u012b\u1e35 'the orpiment', based on Persian zar (\"gold\") from the word \"zarnikh\", meaning \"yellow\" (literally \"gold-colored\") and hence \"(yellow) orpiment\". It was adopted into Greek (using folk etymology) as \"arsenikon\" () \u2013 a neuter form of the Greek adjective \"arsenikos\" (), meaning \"male\", \"virile\".\nLatin-speakers adopted the Greek term as , which in French ultimately became , whence the English word \"arsenic\".\nArsenic sulfides (orpiment, realgar) and oxides have been known and used since ancient times. Zosimos (c.\u2009300 AD) describes roasting \"sandarach\" (realgar) to obtain \"cloud of arsenic\" (arsenic trioxide), which he then reduces to gray arsenic. As the symptoms of arsenic poisoning are not very specific, the substance was frequently used for murder until the advent in the 1830s of the Marsh test, a sensitive chemical test for its presence. (Another less sensitive but more general test is the Reinsch test.) Owing to its use by the ruling class to murder one another and its potency and discreetness, arsenic has been called the \"poison of kings\" and the \"king of poisons\". Arsenic became known as \"the inheritance powder\" due to its use in killing family members in the Renaissance era.\nDuring the Bronze Age, arsenic was melted with copper to make arsenical bronze.\nJabir ibn Hayyan described the isolation of arsenic before 815 AD.\nAlbertus Magnus (Albert the Great, 1193\u20131280) later isolated the element from a compound in 1250, by heating soap together with arsenic trisulfide. In 1649, Johann Schr\u00f6der published two ways of preparing arsenic. Crystals of elemental (native) arsenic are found in nature, although rarely.\nCadet's fuming liquid (impure cacodyl), often claimed as the first synthetic organometallic compound, was synthesized in 1760 by Louis Claude Cadet de Gassicourt through the reaction of potassium acetate with arsenic trioxide.\nIn the Victorian era, women would eat \"arsenic\" (\"white arsenic\" or arsenic trioxide) mixed with vinegar and chalk to improve the complexion of their faces, making their skin paler (to show they did not work in the fields). The accidental use of arsenic in the adulteration of foodstuffs led to the Bradford sweet poisoning in 1858, which resulted in 21 deaths. From the late 18th\u00a0century wallpaper production began to use dyes made from arsenic,\nwhich was thought to increase the pigment's brightness. One account of the illness and 1821 death of Napoleon implicates arsenic poisoning involving wallpaper.\nTwo arsenic pigments have been widely used since their discovery \u2013 Paris Green in 1814 and Scheele's Green in 1775. After the toxicity of arsenic became widely known, these chemicals were used less often as pigments and more often as insecticides. In the 1860s, an arsenic byproduct of dye production, London Purple, was widely used. This was a solid mixture of arsenic trioxide, aniline, lime, and ferrous oxide, insoluble in water and very toxic by inhalation or ingestion But it was later replaced with Paris Green, another arsenic-based dye. With better understanding of the toxicology mechanism, two other compounds were used starting in the 1890s. Arsenite of lime and arsenate of lead were used widely as insecticides until the discovery of DDT in 1942.\nIn small doses, soluble arsenic compounds act as stimulants, and were once popular as medicine by people in the mid-18th to 19th centuries; this use was especially prevalent for sport animals such as race horses or work dogs and continued into the 20th century.\nA 2006 study of the remains of the Australian racehorse Phar Lap determined that its 1932 death was caused by a massive overdose of arsenic. Sydney veterinarian Percy Sykes stated,\nIn those days, arsenic was quite a common tonic, usually given in the form of a solution (Fowler's Solution) ... It was so common that I'd reckon 90\u00a0per cent of the horses had arsenic in their system.\nApplications.\nAgricultural.\nThe toxicity of arsenic to insects, bacteria, and fungi led to its use as a wood preservative. In the 1930s, a process of treating wood with chromated copper arsenate (also known as CCA or Tanalith) was invented, and for decades, this treatment was the most extensive industrial use of arsenic. An increased appreciation of the toxicity of arsenic led to a ban of CCA in consumer products in 2004, initiated by the European Union and United States. However, CCA remains in heavy use in other countries (such as on Malaysian rubber plantations).\nArsenic was also used in various agricultural insecticides and poisons. For example, lead hydrogen arsenate was a common insecticide on fruit trees, but contact with the compound sometimes resulted in brain damage among those working the sprayers. In the second half of the 20th century, monosodium methyl arsenate (MSMA) and disodium methyl arsenate (DSMA) \u2013 less toxic organic forms of arsenic \u2013 replaced lead arsenate in agriculture. These organic arsenicals were in turn phased out in the United States by 2013 in all agricultural activities except cotton farming.\nThe biogeochemistry of arsenic is complex and includes various adsorption and desorption processes. The toxicity of arsenic is connected to its solubility and is affected by pH. Arsenite () is more soluble than arsenate () and is more toxic; however, at a lower pH, arsenate becomes more mobile and toxic. It was found that addition of sulfur, phosphorus, and iron oxides to high-arsenite soils greatly reduces arsenic phytotoxicity.\nArsenic is used as a feed additive in poultry and swine production, in particular it was used in the U.S. until 2015 to increase weight gain, improve feed efficiency, and prevent disease. An example is roxarsone, which had been used as a broiler starter by about 70% of U.S. broiler growers. In 2011, Alpharma, a subsidiary of Pfizer Inc., which produces roxarsone, voluntarily suspended sales of the drug in response to studies showing elevated levels of inorganic arsenic, a carcinogen, in treated chickens. A successor to Alpharma, Zoetis, continued to sell nitarsone until 2015, primarily for use in turkeys.\nMedical use.\nDuring the 17th, 18th, and 19th centuries, a number of arsenic compounds were used as medicines, including arsphenamine (by Paul Ehrlich) and arsenic trioxide (by Thomas Fowler), for treating diseases such as cancer or psoriasis. Arsphenamine, as well as neosalvarsan, was indicated for syphilis, but has been superseded by modern antibiotics. However, arsenicals such as melarsoprol are still used for the treatment of trypanosomiasis in spite of their severe toxicity, since the disease is almost uniformly fatal if untreated. In 2000 the US Food and Drug Administration approved arsenic trioxide for the treatment of patients with acute promyelocytic leukemia that is resistant to all-trans retinoic acid.\nA 2008 paper reports success in locating tumors using arsenic-74 (a positron emitter). This isotope produces clearer PET scan images than the previous radioactive agent, iodine-124, because the body tends to transport iodine to the thyroid gland producing signal noise. Nanoparticles of arsenic have shown ability to kill cancer cells with lesser cytotoxicity than other arsenic formulations.\nAlloys.\nThe main use of arsenic is in alloying with lead. Lead components in car batteries are strengthened by the presence of a very small percentage of arsenic. Dezincification of brass (a copper-zinc alloy) is greatly reduced by the addition of arsenic. \"Phosphorus Deoxidized Arsenical Copper\" with an arsenic content of 0.3% has an increased corrosion stability in certain environments. Gallium arsenide is an important semiconductor material, used in integrated circuits. Circuits made from GaAs are much faster (but also much more expensive) than those made from silicon. Unlike silicon, GaAs has a direct bandgap, and can be used in laser diodes and LEDs to convert electrical energy directly into light.\nMilitary.\nAfter World War I, the United States built a stockpile of 20,000 tons of weaponized lewisite (ClCH=CHAsCl2), an organoarsenic vesicant (blister agent) and lung irritant. The stockpile was neutralized with bleach and dumped into the Gulf of Mexico in the 1950s. Lewisite, the chemical warfare agent, is known for its acute toxicity to aquatic organisms. However, studies assessing the environmental impact of this disposal in the Gulf are lacking. During the Vietnam War, the United States used Agent Blue, a mixture of sodium cacodylate and its acid form, as one of the rainbow herbicides to deprive North Vietnamese soldiers of foliage cover and rice.\nBiological role.\nBacteria.\nSome species of bacteria obtain their energy in the absence of oxygen by oxidizing various fuels while reducing arsenate to arsenite. Under oxidative environmental conditions some bacteria use arsenite as fuel, which they oxidize to arsenate. The enzymes involved are known as arsenate reductases (Arr).\nIn 2008, bacteria were discovered that employ a version of photosynthesis in the absence of oxygen with arsenites as electron donors, producing arsenates (just as ordinary photosynthesis uses water as electron donor, producing molecular oxygen). Researchers conjecture that, over the course of history, these photosynthesizing organisms produced the arsenates that allowed the arsenate-reducing bacteria to thrive. One strain, PHS-1, has been isolated and is related to the gammaproteobacterium \"Ectothiorhodospira shaposhnikovii\". The mechanism is unknown, but an encoded Arr enzyme may function in reverse to its known homologues.\nIn 2010, researchers reported the discovery of a strain of the bacterium \"Halomonas\" (designated GFAJ-1) that was allegedly capable of substituting arsenic for phosphorus in its biomolecules, including DNA, when grown in an arsenic-rich, phosphate-limited environment. This claim, published in \"Science\", suggested that arsenic could potentially serve as a building block of life in place of phosphorus, challenging long-standing assumptions about biochemical requirements for life on Earth.\nThe claim was met with widespread skepticism. Subsequent studies provided evidence contradicting the initial findings. One follow-up study published in \"Science\" in 2011 demonstrated that GFAJ-1 still requires phosphate to grow and does not incorporate arsenate into its DNA in any biologically significant way. Another independent investigation in 2012 used more sensitive techniques to purify and analyze the DNA of GFAJ-1 and found no detectable arsenate incorporated into the DNA backbone. The authors concluded that the original observations were likely due to experimental contamination or insufficient purification methods. Together, these studies reaffirmed phosphorus as an essential element for all known forms of life. In 2025, the journal \"Science\" formally retracted the original paper, citing a lack of sufficient experimental support for its key conclusions, though the authors continued to stand by their data.\nPotential role in higher animals.\nArsenic may be an essential trace mineral in birds, involved in the synthesis of methionine metabolites. However, the role of arsenic in bird nutrition is disputed, as other authors state that arsenic is toxic in small amounts.\nSome evidence indicates that arsenic is an essential trace mineral in mammals.\nExperimental studies in rodents and livestock have shown that arsenic deprivation can lead to impaired growth, reduced reproductive performance, and abnormal glucose metabolism, suggesting it may play a role in essential metabolic processes. Arsenic has been proposed to participate in methylation reactions, possibly influencing gene regulation and detoxification pathways. However, because the threshold between beneficial and toxic exposure is extremely narrow, arsenic is not currently classified as an essential element for humans, and its physiological role in higher animals remains uncertain.\nHeredity.\nArsenic has been linked to epigenetic changes, heritable changes in gene expression that occur without changes in DNA sequence. These include DNA methylation, histone modification, and RNA interference. Toxic levels of arsenic cause significant DNA hypermethylation of tumor suppressor genes p16 and p53, thus increasing risk of carcinogenesis. These epigenetic events have been studied \"in vitro\" using human kidney cells and \"in vivo\" using rat liver cells and peripheral blood leukocytes in humans. Inductively coupled plasma mass spectrometry (ICP-MS) is used to detect precise levels of intracellular arsenic and other arsenic bases involved in epigenetic modification of DNA. Studies investigating arsenic as an epigenetic factor can be used to develop precise biomarkers of exposure and susceptibility.\nThe Chinese brake fern (\"Pteris vittata\") hyperaccumulates arsenic from the soil into its leaves and has a proposed use in phytoremediation.\nBiomethylation.\nInorganic arsenic and its compounds, upon entering the food chain, are progressively metabolized through a process of methylation. For example, the mold \"Scopulariopsis brevicaulis\" produces trimethylarsine if inorganic arsenic is present. The organic compound arsenobetaine is found in some marine foods such as fish and algae, and also in mushrooms in larger concentrations. The average person's intake is about 10\u201350\u00a0\u03bcg/day. Values about 1000\u00a0\u03bcg are not unusual following consumption of fish or mushrooms, but there is little danger in eating fish because this arsenic compound is nearly non-toxic.\nEnvironmental issues.\nExposure.\nNaturally occurring sources of human exposure include volcanic ash, weathering of minerals and ores, and mineralized groundwater. Arsenic is also found in food, water, soil, and air. Arsenic is absorbed by all plants, but is more concentrated in leafy vegetables, rice, apple and grape juice, and seafood. An additional route of exposure is inhalation of atmospheric gases and dusts.\nDuring the Victorian era, arsenic was widely used in home decor, especially wallpapers. In Europe, an analysis based on 20,000\u00a0soil samples across all 28\u00a0countries show that 98% of sampled soils have concentrations less than 20\u00a0mg/kg. In addition, the arsenic hotspots are related to both frequent fertilization and close distance to mining activities. Chronic exposure to arsenic, particularly through contaminated drinking water and food, has also been linked to long-term impacts on cognitive function, including reduced verbal IQ and memory.\nOccurrence in drinking water.\nExtensive arsenic contamination of groundwater has led to widespread arsenic poisoning in Bangladesh and neighboring countries. It is estimated that approximately 57\u00a0million people in the Bengal basin are drinking groundwater with arsenic concentrations elevated above the World Health Organization's standard of 10\u00a0parts per billion (ppb). However, a study of cancer rates in Taiwan suggested that significant increases in cancer mortality appear only at levels above 150\u00a0ppb. The arsenic in the groundwater is of natural origin, and is released from the sediment into the groundwater, caused by the anoxic conditions of the subsurface. This groundwater was used after local and western NGOs and the Bangladeshi government undertook a massive shallow tube well drinking-water program in the late twentieth century. This program was designed to prevent drinking of bacteria-contaminated surface waters, but failed to test for arsenic in the groundwater. Many other countries and districts in Southeast Asia, such as Vietnam and Cambodia, have geological environments that produce groundwater with a high arsenic content. was reported in Nakhon Si Thammarat, Thailand, in 1987, and the Chao Phraya River probably contains high levels of naturally occurring dissolved arsenic without being a public health problem because much of the public uses bottled water. In Pakistan, more than 60\u00a0million people are exposed to arsenic polluted drinking water indicated by a 2017 report in \"Science\". Podgorski's team investigated more than 1200\u00a0samples and more than 66% exceeded the WHO contamination limits of 10 micrograms per liter.\nSince the 1980s, residents of the Ba Men region of Inner Mongolia, China have been chronically exposed to arsenic through drinking water from contaminated wells. A 2009 research study observed an elevated presence of skin lesions among residents with well water arsenic concentrations between 5 and 10\u00a0\u03bcg/L, suggesting that arsenic-induced toxicity may occur at relatively low concentrations with chronic exposure. Overall, 20 of China's 34 provinces have high arsenic concentrations in the groundwater supply, potentially exposing 19\u00a0million people to hazardous drinking water.\nA study by IIT Kharagpur found high levels of Arsenic in groundwater of 20% of India's land, exposing more than 250\u00a0million people. States such as Punjab, Bihar, West Bengal, Assam, Haryana, Uttar Pradesh, and Gujarat have highest land area exposed to arsenic.\nIn the United States, arsenic is most commonly found in the ground waters of the southwest. Parts of New England, Michigan, Wisconsin, Minnesota and the Dakotas are also known to have significant concentrations of arsenic in ground water. Increased levels of skin cancer have been associated with arsenic exposure in Wisconsin, even at levels below the 10\u00a0ppb drinking water standard. According to a recent film funded by the US Superfund, millions of private wells have unknown arsenic levels, and in some areas of the US, more than 20% of the wells may contain levels that exceed established limits.\nLow-level exposure to arsenic at concentrations of 100\u00a0ppb (i.e., above the 10\u00a0ppb drinking water standard) compromises the initial immune response to H1N1 or swine flu infection according to NIEHS-supported scientists. The study, conducted in laboratory mice, suggests that people exposed to arsenic in their drinking water may be at increased risk for more serious illness or death from the virus.\nSome Canadians are drinking water that contains inorganic arsenic. Private-dug\u2013well waters are most at risk for containing inorganic arsenic. Preliminary well water analysis typically does not test for arsenic. Researchers at the Geological Survey of Canada have modeled relative variation in natural arsenic hazard potential for the province of New Brunswick. This study has important implications for potable water and health concerns relating to inorganic arsenic.\nEpidemiological evidence from Chile shows a dose-dependent connection between chronic arsenic exposure and various forms of cancer, in particular when other risk factors, such as cigarette smoking, are present. These effects have been demonstrated at contaminations less than 50\u00a0ppb. Arsenic is itself a constituent of tobacco smoke.\nAnalyzing multiple epidemiological studies on inorganic arsenic exposure suggests a small but measurable increase in risk for bladder cancer at 10\u00a0ppb. According to Peter Ravenscroft of the Department of Geography at the University of Cambridge, roughly 80\u00a0million people worldwide consume between 10 and 50\u00a0ppb arsenic in their drinking water. If they all consumed exactly 10\u00a0ppb arsenic in their drinking water, the previously cited multiple epidemiological study analysis would predict an additional 2,000 cases of bladder cancer alone. This represents a clear underestimate of the overall impact, since it does not include lung or skin cancer, and explicitly underestimates the exposure. Those exposed to levels of arsenic above the current WHO standard should weigh the costs and benefits of arsenic remediation.\nEarly (1973) evaluations of the processes for removing dissolved arsenic from drinking water demonstrated the efficacy of co-precipitation with either iron or aluminium oxides. In particular, iron as a coagulant was found to remove arsenic with an efficacy exceeding 90%. Several adsorptive media systems have been approved for use at point-of-service in a study funded by the United States Environmental Protection Agency (US EPA) and the National Science Foundation (NSF). A team of European and Indian scientists and engineers have set up six arsenic treatment plants in West Bengal based on in-situ remediation method (SAR Technology). This technology does not use any chemicals and arsenic is left in an insoluble form (+5 state) in the subterranean zone by recharging aerated water into the aquifer and developing an oxidation zone that supports arsenic oxidizing micro-organisms. This process does not produce any waste stream or sludge and is relatively cheap.\nAnother effective and inexpensive method to avoid arsenic contamination is to sink wells 500\u00a0feet or deeper to reach purer waters. A recent 2011 study funded by the US National Institute of Environmental Health Sciences' Superfund Research Program shows that deep sediments can remove arsenic and take it out of circulation. In this process, called \"adsorption\", arsenic sticks to the surfaces of deep sediment particles and is naturally removed from the ground water.\nMagnetic separations of arsenic at very low magnetic field gradients with high-surface-area and monodisperse magnetite (Fe3O4) nanocrystals have been demonstrated in point-of-use water purification. Using the high specific surface area of Fe3O4 nanocrystals, the mass of waste associated with arsenic removal from water has been dramatically reduced.\nEpidemiological studies have suggested a correlation between chronic consumption of drinking water contaminated with arsenic and the incidence of all leading causes of mortality. The literature indicates that arsenic exposure is causative in the pathogenesis of diabetes.\nChaff-based filters have recently been shown to reduce the arsenic content of water to 3\u00a0\u03bcg/L. This may find applications in areas where the potable water is extracted from underground aquifers.\nSan Pedro de Atacama.\nFor several centuries, the people of San Pedro de Atacama in Chile have been drinking water that is contaminated with arsenic, and some evidence suggests they have developed some immunity. Genetic studies indicate that certain populations in this region have undergone natural selection for gene variants that enhance arsenic metabolism and detoxification. This adaptation is considered one of the few documented cases of human evolution in response to chronic environmental arsenic exposure.\nHazard maps for contaminated groundwater.\nAround one-third of the world's population drinks water from groundwater resources. Of this, about 10 percent, approximately 300\u00a0million people, obtains water from groundwater resources that are contaminated with unhealthy levels of arsenic or fluoride. These trace elements derive mainly from minerals and ions in the ground.\nRedox transformation of arsenic in natural waters.\nArsenic is unique among the trace metalloids and oxyanion-forming trace metals (e.g. As, Se, Sb, Mo, V, Cr, U, Re). It is sensitive to mobilization at pH values typical of natural waters (pH 6.5\u20138.5) under both oxidizing and reducing conditions. Arsenic can occur in the environment in several oxidation states (\u22123, 0, +3 and +5), but in natural waters it is mostly found in inorganic forms as oxyanions of trivalent arsenite [As(III)] or pentavalent arsenate [As(V)]. Organic forms of arsenic are produced by biological activity, mostly in surface waters, but are rarely quantitatively important. Organic arsenic compounds may, however, occur where waters are significantly impacted by industrial pollution.\nArsenic may be solubilized by various processes. When pH is high, arsenic may be released from surface binding sites that lose their positive charge. When water level drops and sulfide minerals are exposed to air, arsenic trapped in sulfide minerals can be released into water. When organic carbon is present in water, bacteria are fed by directly reducing As(V) to As(III) or by reducing the element at the binding site, releasing inorganic arsenic.\nThe aquatic transformations of arsenic are affected by pH, reduction-oxidation potential, organic matter concentration and the concentrations and forms of other elements, especially iron and manganese. The main factors are pH and the redox potential. Generally, the main forms of arsenic under oxic conditions are , , , and at pH 2, 2\u20137, 7\u201311 and 11, respectively. Under reducing conditions, is predominant at pH 2\u20139.\nOxidation and reduction affects the migration of arsenic in subsurface environments. Arsenite is the most stable soluble form of arsenic in reducing environments and arsenate, which is less mobile than arsenite, is dominant in oxidizing environments at neutral pH. Therefore, arsenic may be more mobile under reducing conditions. The reducing environment is also rich in organic matter which may enhance the solubility of arsenic compounds. As a result, the adsorption of arsenic is reduced and dissolved arsenic accumulates in groundwater. That is why the arsenic content is higher in reducing environments than in oxidizing environments.\nThe presence of sulfur is another factor that affects the transformation of arsenic in natural water. Arsenic can precipitate when metal sulfides form. In this way, arsenic is removed from the water and its mobility decreases. When oxygen is present, bacteria oxidize reduced sulfur to generate energy, potentially releasing bound arsenic.\nRedox reactions involving Fe also appear to be essential factors in the fate of arsenic in aquatic systems. The reduction of iron oxyhydroxides plays a key role in the release of arsenic to water. So arsenic can be enriched in water with elevated Fe concentrations. Under oxidizing conditions, arsenic can be mobilized from pyrite or iron oxides especially at elevated pH. Under reducing conditions, arsenic can be mobilized by reductive desorption or dissolution when associated with iron oxides. The reductive desorption occurs under two circumstances. One is when arsenate is reduced to arsenite which adsorbs to iron oxides less strongly. The other results from a change in the charge on the mineral surface which leads to the desorption of bound arsenic.\nSome species of bacteria catalyze redox transformations of arsenic. Dissimilatory arsenate-respiring prokaryotes (DARP) speed up the reduction of As(V) to As(III). DARP use As(V) as the electron acceptor of anaerobic respiration and obtain energy to survive. Other organic and inorganic substances can be oxidized in this process. Chemoautotrophic arsenite oxidizers (CAO) and heterotrophic arsenite oxidizers (HAO) convert As(III) into As(V). CAO combine the oxidation of As(III) with the reduction of oxygen or nitrate. They use obtained energy to fix produce organic carbon from CO2. HAO cannot obtain energy from As(III) oxidation. This process may be an arsenic detoxification mechanism for the bacteria.\nEquilibrium thermodynamic calculations predict that As(V) concentrations should be greater than As(III) concentrations in all but strongly reducing conditions, i.e. where sulfate reduction is occurring. However, abiotic redox reactions of arsenic are slow. Oxidation of As(III) by dissolved O2 is a particularly slow reaction. For example, Johnson and Pilson (1975) gave half-lives for the oxygenation of As(III) in seawater ranging from several months to a year. In other studies, As(V)/As(III) ratios were stable over periods of days or weeks during water sampling when no particular care was taken to prevent oxidation, again suggesting relatively slow oxidation rates. Cherry found from experimental studies that the As(V)/As(III) ratios were stable in anoxic solutions for up to 3 weeks but that gradual changes occurred over longer timescales. Sterile water samples have been observed to be less susceptible to speciation changes than non-sterile samples. Oremland found that the reduction of As(V) to As(III) in Mono Lake was rapidly catalyzed by bacteria with rate constants ranging from 0.02 to 0.3-day\u22121.\nWood preservation in the US.\nAs of 2002, US-based industries consumed 19,600 metric tons of arsenic. Ninety percent of this was used for treatment of wood with chromated copper arsenate (CCA). In 2007, 50% of the 5,280 metric tons of consumption was still used for this purpose. In the United States, the voluntary phasing-out of arsenic in production of consumer products and residential and general consumer construction products began on 31 December 2003, and alternative chemicals are now used, such as Alkaline Copper Quaternary, borates, copper azole, cyproconazole, and propiconazole.\nAlthough discontinued, this application is also one of the most concerning to the general public. The vast majority of older pressure-treated wood was treated with CCA. CCA lumber is still in widespread use in many countries, and was heavily used during the latter half of the 20th century as a structural and outdoor building material. Although the use of CCA lumber was banned in many areas after studies showed that arsenic could leach out of the wood into the surrounding soil (from playground equipment, for instance), a risk is also presented by the burning of older CCA timber. The direct or indirect ingestion of wood ash from burnt CCA lumber has caused fatalities in animals and serious poisonings in humans; the lethal human dose is approximately 20\u00a0grams of ash. Scrap CCA lumber from construction and demolition sites may be inadvertently used in commercial and domestic fires. Protocols for safe disposal of CCA lumber are not consistent throughout the world. Widespread landfill disposal of such timber raises some concern, but other studies have shown no arsenic contamination in the groundwater.\nMapping of industrial releases in the US.\nOne tool that maps the location (and other information) of arsenic releases in the United States is TOXMAP. TOXMAP is a Geographic Information System (GIS) from the Division of Specialized Information Services of the United States National Library of Medicine (NLM) funded by the US Federal Government. With marked-up maps of the United States, TOXMAP enables users to visually explore data from the United States Environmental Protection Agency's (EPA) Toxics Release Inventory and Superfund Basic Research Programs. TOXMAP's chemical and environmental health information is taken from NLM's Toxicology Data Network (TOXNET), PubMed, and from other authoritative sources.\nBioremediation.\nPhysical, chemical, and biological methods have been used to remediate arsenic contaminated water. Bioremediation is said to be cost-effective and environmentally friendly. Bioremediation of ground water contaminated with arsenic aims to convert arsenite, the toxic form of arsenic to humans, to arsenate. Arsenate (+5 oxidation state) is the dominant form of arsenic in surface water, while arsenite (+3 oxidation state) is the dominant form in hypoxic to anoxic environments. Arsenite is more soluble and mobile than arsenate. Many species of bacteria can transform arsenite to arsenate in anoxic conditions by using arsenite as an electron donor. This is a useful method in ground water remediation. Another bioremediation strategy is to use plants that accumulate arsenic in their tissues via phytoremediation but the disposal of contaminated plant material needs to be considered.\nBioremediation requires careful evaluation and design in accordance with existing conditions. Some sites may require the addition of an electron acceptor while others require microbe supplementation (bioaugmentation). Regardless of the method used, only constant monitoring can prevent future contamination.\nArsenic removal.\nCoagulation and flocculation are closely related processes common in arsenate removal from water. Due to the net negative charge carried by arsenate ions, they settle slowly or not at all due to charge repulsion. In coagulation, a positively charged coagulent such as iron and aluminum (commonly used salts: FeCl3, Fe2(SO4)3, Al2(SO4)3) neutralize the negatively charged arsenate, enable it to settle. Flocculation follows where a flocculant bridges smaller particles and allows the aggregate to precipitate out from water. However, such methods may not be efficient on arsenite as As(III) exists in uncharged arsenious acid, H3AsO3, at near-neutral pH.\nThe major drawbacks of coagulation and flocculation are the costly disposal of arsenate-concentrated sludge, and possible secondary contamination of environment. Moreover, coagulents such as iron may produce ion contamination that exceeds safety levels.\nToxicity and precautions.\n&lt;templatestyles src=\"Chembox/styles.css\"/&gt;\nChemical compound\nArsenic and many of its compounds (arsine, for instance) are potent poisons.\nClassification.\nElemental arsenic and arsenic sulfate and trioxide compounds are classified as \"toxic\" and \"dangerous for the environment\" in the European Union under directive 67/548/EEC.\nThe International Agency for Research on Cancer (IARC) recognizes arsenic and inorganic arsenic compounds as group 1 carcinogens, and the EU lists arsenic trioxide, arsenic pentoxide, and arsenate salts as category 1 carcinogens.\nArsenic is known to cause arsenicosis when present in drinking water, \"the most common species being arsenate [; As(V)] and arsenite [; As(III)]\".\nLegal limits, food, and drink.\nIn the United States since 2006, the maximum concentration in drinking water allowed by the Environmental Protection Agency (EPA) is 10\u00a0ppb and the FDA set the same standard in 2005 for bottled water. The Department of Environmental Protection for New Jersey set a drinking water limit of 5\u00a0ppb in 2006. The IDLH (immediately dangerous to life and health) value for arsenic metal and inorganic arsenic compounds is 5\u00a0mg/m3 (5\u00a0ppb). The Occupational Safety and Health Administration has set the permissible exposure limit (PEL) to a time-weighted average (TWA) of 0.01\u00a0mg/m3 (0.01\u00a0ppb), and the National Institute for Occupational Safety and Health (NIOSH) has set the recommended exposure limit (REL) to a 15-minute constant exposure of 0.002\u00a0mg/m3 (0.002\u00a0ppb). The PEL for organic arsenic compounds is a TWA of 0.5\u00a0mg/m3. (0.5\u00a0ppb).\nIn 2008, based on its ongoing testing of a wide variety of American foods for toxic chemicals, the U.S. Food and Drug Administration set the \"level of concern\" for inorganic arsenic in apple and pear juices at 23\u00a0ppb, based on non-carcinogenic effects, and began blocking importation of products in excess of this level; it also required recalls for non-conforming domestic products. In 2011, the national \"Dr. Oz\" television show broadcast a program highlighting tests performed by an independent lab hired by the producers. Though the methodology was disputed (it did not distinguish between organic and inorganic arsenic) the tests showed levels of arsenic up to 36\u00a0ppb. In response, the FDA tested the worst brand from the \"Dr.\" \"Oz\" show and found much lower levels. Ongoing testing found 95% of the apple juice samples were below the level of concern. Later testing by Consumer Reports showed inorganic arsenic at levels slightly above 10\u00a0ppb, and the organization urged parents to reduce consumption. In July 2013, on consideration of consumption by children, chronic exposure, and carcinogenic effect, the FDA established an \"action level\" of 10\u00a0ppb for apple juice, the same as the drinking water standard.\nConcern about arsenic in rice in Bangladesh was raised in 2002, but at the time only Australia had a legal limit for food (one milligram per kilogram, or 1000 ppb). Concern was raised about people who were eating U.S. rice exceeding WHO standards for personal arsenic intake in 2005. In 2011, the People's Republic of China set a food standard of 150\u00a0ppb for arsenic.\nIn the United States in 2012, testing by separate groups of researchers at the Children's Environmental Health and Disease Prevention Research Center at Dartmouth College (early in the year, focusing on urinary levels in children) and Consumer Reports (in November) found levels of arsenic in rice that resulted in calls for the FDA to set limits. The FDA released some testing results in September 2012, and as of July 2013, is still collecting data in support of a new potential regulation. It has not recommended any changes in consumer behavior.\nConsumer Reports recommended:\nA 2014 World Health Organization advisory conference was scheduled to consider limits of 200\u2013300\u00a0ppb for rice.\nReducing arsenic content in rice.\nIn 2020, scientists assessed multiple preparation procedures of rice for their capacity to reduce arsenic content and preserve nutrients, recommending a procedure involving parboiling and water-absorption.\nEcotoxicity.\nArsenic is bioaccumulative in many organisms, marine species in particular, but it does not appear to biomagnify significantly in food webs. In polluted areas, plant growth may be affected by root uptake of arsenate, which is a phosphate analog and therefore readily transported in plant tissues and cells. In polluted areas, uptake of the more toxic arsenite ion (found more particularly in reducing conditions) is likely in poorly drained soils.\nBiological mechanism.\nArsenic's toxicity comes from the affinity of arsenic(III) oxides for thiols. Thiols, in the form of cysteine residues and cofactors such as lipoic acid and coenzyme A, are situated at the active sites of many important enzymes.\nArsenic disrupts ATP production through several mechanisms. At the level of the citric acid cycle, arsenic inhibits lipoic acid, which is a cofactor for pyruvate dehydrogenase. By competing with phosphate, arsenate uncouples oxidative phosphorylation, thus inhibiting energy-linked reduction of NAD+, mitochondrial respiration and ATP synthesis. Hydrogen peroxide production is also increased, which, it is speculated, has potential to form reactive oxygen species and oxidative stress. These metabolic interferences lead to death from multi-system organ failure. The organ failure is presumed to be from necrotic cell death, not apoptosis, since energy reserves have been too depleted for apoptosis to occur.\nExposure risks and remediation.\nOccupational exposure and arsenic poisoning may occur in people working in industries involving the use of inorganic arsenic and its compounds, such as wood preservation, glass production, nonferrous metal alloys, and electronic semiconductor manufacturing. Inorganic arsenic is also found in coke oven emissions associated with the smelter industry.\nThe conversion between As(III) and As(V) is a large factor in arsenic environmental contamination. According to Croal, Gralnick, Malasarn and Newman, \"[the] understanding [of] what stimulates As(III) oxidation and/or limits As(V) reduction is relevant for bioremediation of contaminated sites (Croal). The study of chemolithoautotrophic As(III) oxidizers and the heterotrophic As(V) reducers can help the understanding of the oxidation and/or reduction of arsenic.\nTreatment.\nTreatment of chronic arsenic poisoning is possible. British anti-lewisite (dimercaprol) is prescribed in doses of 5\u00a0mg/kg up to 300\u00a0mg every 4\u00a0hours for the first day, then every 6\u00a0hours for the second day, and finally every 8\u00a0hours for 8 additional days. However the USA's Agency for Toxic Substances and Disease Registry (ATSDR) states that the long-term effects of arsenic exposure cannot be predicted. Blood, urine, hair, and nails may be tested for arsenic; however, these tests cannot foresee possible health outcomes from the exposure. Long-term exposure and consequent excretion through urine has been linked to bladder and kidney cancer in addition to cancer of the liver, prostate, skin, lungs, and nasal cavity.\nFootnotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "898", "revid": "203434", "url": "https://en.wikipedia.org/wiki?curid=898", "title": "Antimony", "text": "element with atomic number 51 (Sb)\nAntimony is a chemical element; it has symbol Sb (from la \" stibium\") and atomic number 51. A lustrous grey metal or metalloid, it is found in nature mainly as the sulfide mineral stibnite (). Antimony compounds have been known since ancient times and were powdered for use as medicine and cosmetics, often known by the Arabic name kohl. The earliest known description of this metalloid in the West was written in 1540 by Vannoccio Biringuccio.\nChina is the largest producer of antimony and its compounds, with most production coming from the Xikuangshan Mine in Hunan. The industrial methods for refining antimony from stibnite are roasting followed by reduction with carbon, or direct reduction of stibnite with iron.\nThe most common applications for metallic antimony are in alloys with lead and tin, which have improved properties for solders, bullets, and plain bearings. It improves the rigidity of lead-alloy plates in lead\u2013acid batteries. Antimony trioxide is a prominent additive for halogen-containing flame retardants. Antimony is used as a dopant in semiconductor devices.\nCharacteristics.\nProperties.\nAntimony is a member of group 15 of the periodic table. As one of the elements called pnictogens, it has an electronegativity of 2.05. In accordance with periodic trends, it is more electronegative than tin or bismuth, and less electronegative than tellurium or arsenic. As a metalloid, it has a Mohs scale hardness of 3.\nAntimony is a silvery, lustrous gray solid that is stable in air at room temperature. If heated, it reacts with oxygen to produce antimony trioxide. Antimony is attacked by oxidizing acids.\nThe stable allotrope of antimony crystallises in a trigonal cell, isomorphic with bismuth and the gray allotrope of arsenic.\nA yellow allotrope of antimony, assumed to be analogous to yellow arsenice, forms by oxidation of stibine () with air or oxygen at \u221290\u00a0\u00b0C. At ambient temperatures and in ambient light, it transforms into the more stable black allotrope. A rare explosive form of antimony can be formed from the electrolysis of antimony trichloride, but it always contains appreciable chlorine and is not really an antimony allotrope. When scratched with a sharp implement, an exothermic reaction occurs and white fumes are given off as metallic antimony forms; when rubbed with a pestle in a mortar, a strong detonation occurs.\nElemental antimony adopts a layered structure (space group R3m No. 166) whose layers consist of fused, ruffled, six-membered rings. The nearest and next-nearest neighbors form an irregular octahedral complex, with the three atoms in each double layer slightly closer than the three atoms in the next. This relatively close packing leads to a high density of 6.697\u00a0g/cm3, but the weak bonding between the layers leads to the low hardness and brittleness of antimony.\nIsotopes.\nAntimony has two stable isotopes: with a natural abundance of 57.21% and with a natural abundance of 42.79%. There are 37 artificial radioactive isotopes known with mass numbers 104 to 142, of which the longest-lived is the fission product with a half-life of 2.758\u00a0years. Numerous meta states are known, of which the most stable is with a half-life of 5.76\u00a0days. Isotopes that are lighter than the stable tend to undergo \u03b2+ decay, and those that are heavier \u03b2\u2212 decay, with some exceptions.\nOccurrence.\nThe abundance of antimony in the Earth's crust is estimated at 0.2 parts per million, comparable to thallium at 0.5\u00a0ppm and silver at 0.07\u00a0ppm. It is the 63rd most abundant element in the crust. Even though this element is not abundant, it is found in more than 100 mineral species. Antimony is sometimes found natively (e.g. on Antimony Peak), but more frequently it is found in the sulfide stibnite () which is the predominant ore mineral.\nCompounds.\nAntimony compounds are often classified according to their oxidation state: Sb(III) and Sb(V). The +5 oxidation state is more common.\nOxides and hydroxides.\nAntimony trioxide is formed when antimony is burnt in air. In the gas phase, the molecule of the compound is , but it polymerizes upon condensing. Antimony pentoxide () can be formed only by oxidation with concentrated nitric acid. Antimony also forms a mixed-valence oxide, antimony tetroxide (), which features both Sb(III) and Sb(V). Unlike oxides of phosphorus and arsenic, these oxides are amphoteric, do not form well-defined oxoacids, and react with acids to form antimony salts.\nAntimonous acid is unknown, but the conjugate base sodium antimonite () forms upon fusing sodium oxide and . Transition metal antimonites are also known. Antimonic acid exists only as the hydrate , forming salts as the antimonate anion . When a solution containing this anion is dehydrated, the precipitate contains mixed oxides.\nThe most important antimony ore is stibnite (). Other sulfide minerals include pyrargyrite (), zinkenite, jamesonite, and boulangerite. Antimony pentasulfide is non-stoichiometric, which features antimony in the +3 oxidation state and S\u2013S bonds. Several thioantimonides are known, such as and .\nHalides.\nAntimony forms two series of halides: and . The trihalides , , , and are all molecular compounds having trigonal pyramidal molecular geometry. The trifluoride is prepared by the reaction of antimony trioxide with hydrofluoric acid:\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\nIt is Lewis acidic and readily accepts fluoride ions to form the complex anions and . Molten antimony trifluoride is a weak electrical conductor. The trichloride is prepared by dissolving stibnite in hydrochloric acid:\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\nArsenic sulfides are not readily attacked by the hydrochloric acid, so this method offers a route to As-free Sb.\nThe pentahalides and have trigonal bipyramidal molecular geometry in the gas phase, but in the liquid phase, is polymeric, whereas is monomeric. Antimony pentafluoride is a powerful Lewis acid used to make the superacid fluoroantimonic acid ().\nOxyhalides are more common for antimony than for arsenic and phosphorus. Antimony trioxide dissolves in concentrated acid to form oxoantimonyl compounds such as SbOCl and .\nAntimonides, hydrides, and organoantimony compounds.\nCompounds in this class generally are described as derivatives of . Antimony forms antimonides with metals, such as indium antimonide (InSb) and silver antimonide (). The alkali metal and zinc antimonides, such as and , are more reactive. Treating these antimonides with acid produces the highly unstable gas stibine, :\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\nStibine can also be produced by treating salts with hydride reagents such as sodium borohydride. Stibine decomposes spontaneously at room temperature. Because stibine has a positive heat of formation, it is thermodynamically unstable and thus antimony does not react with hydrogen directly.\nOrganoantimony compounds are typically prepared by alkylation of antimony halides with Grignard reagents. A large variety of compounds are known with both Sb(III) and Sb(V) centers, including mixed chloro-organic derivatives, anions, and cations. Examples include triphenylstibine () and pentaphenylantimony ().\nHistory.\nAntimony(III) sulfide, , was recognized in predynastic Egypt as an eye cosmetic (kohl) as early as about 3100\u00a0BC, when the cosmetic palette was invented.\nAn artifact, said to be part of a vase, made of antimony dating to about 3000\u00a0BC was found at Telloh, Chaldea (part of present-day Iraq), and a copper object plated with antimony dating between 2500\u00a0BC and 2200\u00a0BC has been found in Egypt. Austen, at a lecture by Herbert Gladstone in 1892, commented that \"we only know of antimony at the present day as a highly brittle and crystalline metal, which could hardly be fashioned into a useful vase, and therefore this remarkable 'find' (artifact mentioned above) must represent the lost art of rendering antimony malleable.\"\nThe British archaeologist Roger Moorey was unconvinced the artifact was indeed a vase, mentioning that Selimkhanov, after his analysis of the Tello object (published in 1975), \"attempted to relate the metal to Transcaucasian natural antimony\" (i.e. native metal) and that \"the antimony objects from Transcaucasia are all small personal ornaments.\" This weakens the evidence for a lost art \"of rendering antimony malleable\".\nThe Roman scholar Pliny the Elder described several ways of preparing antimony sulfide for medical purposes in his treatise \"Natural History\", around 77\u00a0AD. Pliny the Elder also made a distinction between \"male\" and \"female\" forms of antimony; the male form is probably the sulfide, while the female form, which is superior, heavier, and less friable, has been suspected to be native metallic antimony.\nThe Greek naturalist Pedanius Dioscorides mentioned that antimony sulfide could be roasted by heating by a current of air. It is thought that this produced metallic antimony.\nAntimony was frequently described in alchemical manuscripts, including the \"Summa Perfectionis\" of Pseudo-Geber, written around the 14th century. A description of a procedure for isolating antimony is later given in the 1540 book \"De la pirotechnia\" by Vannoccio Biringuccio, predating the more famous 1556 book by Agricola, \"De re metallica\". In this context Agricola has been often incorrectly credited with the discovery of metallic antimony. The book \"Currus Triumphalis Antimonii\" (The Triumphal Chariot of Antimony), describing the preparation of metallic antimony, was published in Germany in 1604. It was purported to be written by a Benedictine monk, writing under the name Basilius Valentinus in the 15th century; if it were authentic, which it is not, it would predate Biringuccio.\nThe metal antimony was known to German chemist Andreas Libavius in 1615 who obtained it by adding iron to a molten mixture of antimony sulfide, salt and potassium tartrate. This procedure produced antimony with a crystalline or starred surface.\nWith the advent of challenges to phlogiston theory, it was recognized that antimony is an element forming sulfides, oxides, and other compounds, as do other metals.\nThe first discovery of naturally occurring pure antimony in the Earth's crust was described by the Swedish scientist and local mine district engineer Anton von Swab in 1783; the type-sample was collected from the Sala Silver Mine in the Bergslagen mining district of Sala, V\u00e4stmanland, Sweden.\nCoins of antimony were issued in China's Guizhou in 1931; durability was poor, and minting was soon discontinued because of its softness and toxicity.\nEtymology.\nThe medieval Latin form, from which the modern languages and late Byzantine Greek take their names for antimony, is \"\". The origin of that is uncertain, and all suggestions have some difficulty either of form or interpretation. The popular etymology, from \u1f00\u03bd\u03c4\u03af\u03bc\u03bf\u03bd\u03b1\u03c7\u03cc\u03c2 \"anti-monachos\" or French , would mean \"monk-killer\", which is explained by the fact that many early alchemists were monks, and some antimony compounds were poisonous.\nAnother popular etymology is the hypothetical Greek word \u1f00\u03bd\u03c4\u03af\u03bc\u03cc\u03bd\u03bf\u03c2 \"antimonos\", \"against aloneness\", explained as \"not found as metal\", or \"not found unalloyed\". However, ancient Greek would more naturally express the pure negative as \"\u03b1-\" (\"not\"). Edmund Oscar von Lippmann conjectured a hypothetical Greek word \u03b1\u03bd\u03b8\u03ae\u03bc\u03cc\u03bd\u03b9\u03bf\u03bd \"anthemonion\", which would mean \"floret\", and cites several examples of related Greek words (but not that one) which describe chemical or biological efflorescence.\nThe early uses of \"antimonium\" include the translations, in 1050\u20131100, by Constantine the African of Arabic medical treatises. Several authorities believe \"antimonium\" is a scribal corruption of some Arabic form; Meyerhof derives it from \"ithmid\"; other possibilities include \"athimar\", the Arabic name of the metalloid, and a hypothetical \"as-stimmi\", derived from or parallel to the Greek.\nThe standard chemical symbol for antimony (Sb) is credited to J\u00f6ns Jakob Berzelius, who derived the abbreviation from \"stibium\".\nThe ancient words for antimony mostly have, as their chief meaning, kohl, the sulfide of antimony.\nThe Egyptians called antimony \"m\u015bdmt\" or \"stm\".\nThe Arabic word for the substance, as opposed to the cosmetic, can appear as \"ithmid, athmoud, othmod\", or \"uthmod\". Littr\u00e9 suggests the first form, which is the earliest, derives from \"stimmida\", an accusative for \"stimmi\". The Greek word \u03c3\u03c4\u03af\u03bc\u03bc\u03b9 (stimmi) is used by Attic tragic poets of the 5th century BC, and is possibly a loan word from Arabic or from Egyptian \"stm\".\nProduction.\nProcess.\nThe extraction of antimony from ores depends on the quality and composition of the ore. Most antimony is mined as the sulfide; lower-grade ores are concentrated by froth flotation, while higher-grade ores are heated to 500\u2013600\u00a0\u00b0C, the temperature at which stibnite melts and separates from the gangue minerals. Antimony can be isolated from the crude antimony sulfide by reduction with scrap iron:\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\nThe sulfide is converted to an oxide by roasting. The product is further purified by vaporizing the volatile antimony(III) oxide, which is recovered. This sublimate is often used directly for the main applications, impurities being arsenic and sulfide. Antimony is isolated from the oxide by a carbothermal reduction:\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\nThe lower-grade ores are reduced in blast furnaces while the higher-grade ores are reduced in reverberatory furnaces.\nTop producers and production volumes.\nIn 2022, according to the US Geological Survey, China accounted for 54.5% of total antimony production, followed in second place by Russia with 18.2% and Tajikistan with 15.5%.\nChinese production of antimony is expected to decline in the future as mines and smelters are closed down by the government as part of pollution control and stricter environmental rules. Especially due to an environmental protection law having gone into effect in January 2015 and revised \"Emission Standards of Pollutants for Stanum, Antimony, and Mercury\" having gone into effect, hurdles for economic production are higher.\nReported production of antimony in China has fallen and is unlikely to increase in the coming years, according to the Roskill report. No significant antimony deposits in China have been developed for about ten years, and the remaining economic reserves are being rapidly depleted. Myanmar is also facing supply disruptions due to political unrest.\nSupply risk.\nFor antimony-importing regions, such as Europe and the U.S., antimony is considered to be a critical mineral for industrial manufacturing that is at risk of supply chain disruption. \nWith global production (in 2019) coming mainly from China (74%), Tajikistan (8%), and Russia (4%), these sources are critical to supply.\nIn December 2024, the PR China has banned export of critical minerals.\nApplications.\nIn 2017, approximately 48% of antimony was consumed in flame retardants, 33% in lead\u2013acid batteries, and 8% in plastics.\nFlame retardants.\nAntimony is mainly used as the trioxide for flame-proofing compounds, always in combination with halogenated flame retardants except in halogen-containing polymers. The flame retarding effect of antimony trioxide is produced by the formation of halogenated antimony compounds, which react with hydrogen atoms, and probably also with oxygen atoms and OH radicals, thus inhibiting fire. Markets for these flame-retardants include children's clothing, toys, aircraft, and automobile seat covers. They are also added to polyester resins in fiberglass composites for such items as light aircraft engine covers. The resin will burn in the presence of an externally generated flame, but will extinguish when the external flame is removed. Antimony trioxide is also used as a synergist with brominated flame retardants in housings and plastic parts for electrical and electronic equipment (e.g., HIPS/ABS enclosures) to meet flammability standards such as UL 94.\nAlloys.\nAntimony forms a highly useful alloy with lead, increasing its hardness and mechanical strength. When casting it increases fluidity of the melt and reduces shrinkage during cooling. For most applications involving lead, varying amounts of antimony are used as alloying metal. In lead\u2013acid batteries, this addition improves plate strength and charging characteristics. For sailboats, lead keels are used to provide righting moment, ranging from 600 lbs to over 200 tons for the largest sailing superyachts; to improve hardness and tensile strength of the lead keel, antimony is mixed with lead between 2% and 5% by volume. Antimony is used in antifriction alloys (such as Babbitt metal), in bullets and lead shot, electrical cable sheathing, type metal (for example, for Linotype printing machines), solder (some \"lead-free\" solders contain 5% Sb), in pewter, and in hardening alloys with low tin content in the manufacturing of organ pipes.\nOther applications.\nThree other applications consume nearly all the rest of the world's supply. One application is as a stabilizer and catalyst for the production of polyethylene terephthalate. Another is as a fining agent to remove microscopic bubbles in glass, mostly for TV screens \u2013 antimony ions interact with oxygen, suppressing the tendency of the latter to form bubbles. This also prevents discolouration. The third application is pigments, Antimony also helps to maintain color stability and surface smoothness when it is used with certain types of ceramics and enamels.\nIn the 1990s antimony was increasingly being used in semiconductors as a dopant in n-type silicon wafers for diodes, infrared detectors, and Hall-effect devices. In the 1950s, the emitters and collectors of n-p-n alloy junction transistors were doped with tiny beads of a lead-antimony alloy. Indium antimonide (InSb) is used as a material for mid-infrared detectors.\nThe material is used as for phase-change memory, a type of computer memory.\nBiology and medicine have few uses for antimony. Treatments containing antimony, known as antimonials, are used as emetics. Antimony compounds are used as antiprotozoan drugs. Potassium antimonyl tartrate, or tartar emetic, was once used as an anti-schistosomal drug from 1919 on. It was subsequently replaced by praziquantel. Antimony and its compounds are used in several veterinary preparations, such as anthiomaline and lithium antimony thiomalate, as a skin conditioner in ruminants. Antimony has a nourishing or conditioning effect on keratinized tissues in animals.\nAntimony-based drugs, such as meglumine antimoniate, are also considered the drugs of choice for treatment of leishmaniasis. Early treatments used antimony(III) species (trivalent antimonials), but in 1922 Upendranath Brahmachari invented a much safer antimony(V) drug, and since then so-called pentavalent antimonials have been the standard first-line treatment. However, \"Leishmania\" strains in Bihar and neighboring regions have developed resistance to antimony. Elemental antimony as an antimony pill was once used as a medicine. It could be reused by others after ingestion and elimination.\nAntimony(III) sulfide is used in the heads of some safety matches. Antimony sulfides help to stabilize the friction coefficient in automotive brake pad materials. Antimony is used in bullets, bullet tracers, paint, glass art, and as an opacifier in enamel. Antimony-124 is used together with beryllium in neutron sources; the gamma rays emitted by antimony-124 initiate the photodisintegration of beryllium. The emitted neutrons have an average energy of 24\u00a0keV. Natural antimony is used in startup neutron sources.\nThe powder derived from crushed antimony sulfide (\"kohl\") has been used for millennia as an eye cosmetic. Historically it was applied to the eyes with a metal rod and with one's spittle, and was thought by the ancients to aid in curing eye infections. The practice is still seen in Yemen and in other Muslim countries.\nPrecautions.\n&lt;templatestyles src=\"Chembox/styles.css\"/&gt;\nChemical compound\nAntimony and many of its compounds are toxic, and the effects of antimony poisoning are similar to arsenic poisoning. The toxicity of antimony is far lower than that of arsenic; this might be caused by the significant differences of uptake, metabolism and excretion between arsenic and antimony. The uptake of antimony(III) or antimony(V) in the gastrointestinal tract is at most 20%. Antimony(V) is not quantitatively reduced to antimony(III) in the cell (in fact antimony(III) is oxidised to antimony(V) instead).\nSince methylation of antimony does not occur, the excretion of antimony(V) in urine is the main way of elimination. Like arsenic, the most serious effect of acute antimony poisoning is cardiotoxicity and the resulting myocarditis; however, it can also manifest as Adams\u2013Stokes syndrome, which arsenic does not. Reported cases of intoxication by antimony equivalent to 90\u00a0mg antimony potassium tartrate dissolved from enamel has been reported to show only short term effects. An intoxication with 6\u00a0g of antimony potassium tartrate was reported to result in death after three days.\nInhalation of antimony dust is harmful and in certain cases may be fatal; in small doses, antimony causes headaches, dizziness, and depression. Larger doses such as prolonged skin contact may cause dermatitis, or damage the kidneys and the liver, causing violent and frequent vomiting, leading to death in a few days.\nAntimony is incompatible with strong oxidizing agents, strong acids, halogen acids, chlorine, or fluorine. It should be kept away from heat.\nAntimony leaches from polyethylene terephthalate (PET) bottles into liquids. While levels observed for bottled water are below drinking water guidelines, fruit juice concentrates (for which no guidelines are established) produced in the UK were found to contain up to 44.7\u00a0\u03bcg/L of antimony, well above the EU limits for tap water of 5\u00a0\u03bcg/L. The guidelines are:\nThe tolerable daily intake (TDI) proposed by WHO is 6\u00a0\u03bcg antimony per kilogram of body weight. The immediately dangerous to life or health (IDLH) value for antimony is 50\u00a0mg/m3 (50\u00a0\u03bcg/L).\nToxicity.\nCertain compounds of antimony appear to be toxic, particularly antimony trioxide and antimony potassium tartrate. Effects may be similar to arsenic poisoning. Occupational exposure may cause respiratory irritation, pneumoconiosis, antimony spots on the skin, gastrointestinal symptoms, and cardiac arrhythmias. In addition, antimony trioxide is potentially carcinogenic to humans.\nAdverse health effects have been observed in humans and animals following inhalation, oral, or dermal exposure to antimony and antimony compounds. Antimony toxicity typically occurs either due to occupational exposure, during therapy or from accidental ingestion. It is unclear if antimony can enter the body through the skin. The presence of low levels of antimony in saliva may also be associated with dental decay.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "899", "revid": "43762107", "url": "https://en.wikipedia.org/wiki?curid=899", "title": "Actinium", "text": "element with atomic number 89 (Ac)\nActinium is a chemical element; it has symbol Ac and atomic number\u00a089. It was discovered by Friedrich Oskar Giesel in 1902, who gave it the name \"emanium\"; the element got its name by being wrongly identified with a substance Andr\u00e9-Louis Debierne found in 1899 and called actinium. The actinide series, a set of 15 elements between actinium and lawrencium in the periodic table, is named after actinium. Together with polonium, radium, and radon, actinium was one of the first non-primordial radioactive elements to be discovered.\nA soft, silvery-white radioactive metal, actinium reacts rapidly with oxygen and moisture in air, forming a white coating of actinium oxide that prevents further oxidation. As with most lanthanides and many actinides, actinium assumes oxidation state +3 in nearly all its chemical compounds. Actinium is found only in traces in uranium and thorium ores as the isotope 227Ac, which decays with a half-life of 21.772 years, predominantly emitting beta and sometimes alpha particles, and 228Ac, which is beta active with a half-life of 6.15 hours. One tonne of natural uranium in ore contains about 0.2 milligrams of actinium-227, and one tonne of thorium contains about 5 nanograms of actinium-228. The close similarity of physical and chemical properties of actinium and lanthanum makes the separation of actinium from the ore impractical. Instead, the element is prepared, in milligram amounts, by the neutron irradiation of in a nuclear reactor. Owing to its scarcity, high price, and radioactivity, actinium has no significant industrial use. Its current applications include a neutron source and an agent for radiation therapy.\nHistory.\nAndr\u00e9-Louis Debierne, a French chemist, announced the discovery of a new element in 1899. He separated it from pitchblende residues left by Marie and Pierre Curie after they had extracted radium. In 1899, Debierne described the substance as similar to titanium and (in 1900) as similar to thorium. Friedrich Oskar Giesel found in 1902 a substance similar to lanthanum and called it \"emanium\" in 1904. After a comparison of the substances' half-lives determined by Debierne, Harriet Brooks in 1904, and Otto Hahn and Otto Sackur in 1905, Debierne's chosen name for the new element was retained because it had seniority, despite the contradicting chemical properties he claimed for the element at different times.\nArticles published in the 1970s and later suggest that Debierne's results published in 1904 conflict with those reported in 1899 and 1900. Furthermore, the now-known chemistry of actinium precludes its presence as anything other than a minor constituent of Debierne's 1899 and 1900 results; in fact, the chemical properties he reported make it likely that he had, instead, accidentally identified protactinium, which would not be discovered for another fourteen years, only to have it disappear due to its hydrolysis and adsorption onto his laboratory equipment. This has led some authors to advocate that Giesel alone should be credited with the discovery. A less confrontational vision of scientific discovery is proposed by Adloff. He suggests that hindsight criticism of the early publications should be mitigated by the then nascent state of radiochemistry: highlighting the prudence of Debierne's claims in the original papers, he notes that nobody can contend that Debierne's substance did not contain actinium. Debierne, who is now considered by the vast majority of historians as the discoverer, lost interest in the element and left the topic. Giesel, on the other hand, can rightfully be credited with the first preparation of radiochemically pure actinium and with the identification of its atomic number 89.\nThe name actinium originates from the Ancient Greek \"aktis, aktinos\" (\u03b1\u03ba\u03c4\u03af\u03c2, \u03b1\u03ba\u03c4\u03af\u03bd\u03bf\u03c2), meaning beam or ray. Its symbol Ac is also used in abbreviations of other compounds that have nothing to do with actinium, such as acetyl, acetate and sometimes acetaldehyde.\nProperties.\nActinium is a soft, silvery-white, radioactive, metallic element. Its estimated shear modulus is similar to that of lead. Owing to its strong radioactivity, actinium glows in the dark with a pale blue light, which originates from the surrounding air ionized by the emitted energetic particles. Actinium has similar chemical properties to lanthanum and other lanthanides, and therefore these elements are difficult to separate when extracting from uranium ores. Solvent extraction and ion chromatography are commonly used for the separation.\nThe first element of the actinides, actinium, gave the set its name, much as lanthanum had done for the lanthanides. The actinides are much more diverse than the lanthanides and therefore it was not until 1945 that the most significant change to Dmitri Mendeleev's periodic table since the recognition of the lanthanides, the introduction of the actinides, was generally accepted after Glenn T. Seaborg's research on the transuranium elements (although it had been proposed as early as 1892 by British chemist Henry Bassett).\nActinium reacts rapidly with oxygen and moisture in air, forming a white coating of actinium oxide that impedes further oxidation. As with most lanthanides and actinides, actinium exists in the oxidation state +3, and the Ac3+ ions are colorless in solutions. The oxidation state +3 originates from the [Rn] 6d17s2 electronic configuration of actinium, with three valence electrons that are easily donated to give the stable closed-shell structure of the noble gas radon. Although the 5f orbitals are unoccupied in an actinium atom, it can be used as a valence orbital in actinium complexes and hence it is generally considered the first 5f element by authors working on it. Ac3+ is the largest of all known tripositive ions and its first coordination sphere contains approximately 10.9 \u00b1 0.5 water molecules.\nChemical compounds.\nDue to actinium's intense radioactivity, only a limited number of actinium compounds are known. These include: AcF3, AcCl3, AcBr3, AcOF, AcOCl, AcOBr, Ac2S3, Ac2O3, AcPO4 and Ac(NO3)3. They all contain actinium in the oxidation state +3. In particular, the lattice constants of the analogous lanthanum and actinium compounds differ by only a few percent.\nHere \"a\", \"b\" and \"c\" are lattice constants, No is the space group number, and \"Z\" is the number of formula units per unit cell. Density was not measured directly but calculated from the lattice parameters.\nOxides.\nActinium oxide (Ac2O3) can be obtained by heating the hydroxide at or the oxalate at , in vacuum. Its crystal lattice is isotypic with the oxides of most trivalent rare-earth metals.\nHalides.\nActinium trifluoride can be produced either in solution or in solid reaction. The former reaction is carried out at room temperature, by adding hydrofluoric acid to a solution containing actinium ions. In the latter method, actinium metal is treated with hydrogen fluoride vapors at in an all-platinum setup. Treating actinium trifluoride with ammonium hydroxide at yields oxyfluoride AcOF. Whereas lanthanum oxyfluoride can be easily obtained by burning lanthanum trifluoride in air at for an hour, similar treatment of actinium trifluoride yields no AcOF and only results in melting of the initial product.\nAcF3 + 2 NH3 + H2O \u2192 AcOF + 2 NH4F\nActinium trichloride is obtained by reacting actinium hydroxide or oxalate with carbon tetrachloride vapors at temperatures above . Similarly to the oxyfluoride, actinium oxychloride can be prepared by hydrolyzing actinium trichloride with ammonium hydroxide at . However, in contrast to the oxyfluoride, the oxychloride could well be synthesized by igniting a solution of actinium trichloride in hydrochloric acid with ammonia.\nReaction of aluminium bromide and actinium oxide yields actinium tribromide:\nAc2O3 + 2 AlBr3 \u2192 2 AcBr3 + Al2O3\nand treating it with ammonium hydroxide at results in the oxybromide AcOBr.\nOther compounds.\nActinium hydride was obtained by reduction of actinium trichloride with potassium at , and its structure was deduced by analogy with the corresponding LaH2 hydride. The source of hydrogen in the reaction was uncertain.\nMixing monosodium phosphate (NaH2PO4) with a solution of actinium in hydrochloric acid yields white-colored actinium phosphate hemihydrate (AcPO4\u00b70.5H2O), and heating actinium oxalate with hydrogen sulfide vapors at for a few minutes results in a black actinium sulfide Ac2S3. It may be produced by acting with a mixture of hydrogen sulfide and carbon disulfide on actinium oxide at .\nIsotopes.\nNaturally occurring actinium is principally composed of two radioactive isotopes; (from the radioactive family of ) and (a granddaughter of ). decays mainly as a beta emitter with a very small energy, but in 1.38% of cases it emits an alpha particle, so it can readily be identified through alpha spectrometry. Thirty-three radioisotopes have been identified, the most stable being with a half-life of 21.772 years, with a half-life of 10.0 days and with a half-life of 29.37 hours. All remaining radioactive isotopes have half-lives that are less than 10 hours, and the majority of them have half-lives shorter than one minute. The shortest-lived known isotope of actinium is (half-life of 69 nanoseconds) which decays through alpha decay. Actinium also has two known meta states. The most significant isotopes for chemistry are , , and .\nPurified comes into equilibrium with its decay products after about a half-year. It decays according to its 21.772-year half-life, emitting mostly beta (98.62%) and some alpha particles (1.38%); the successive decay products are part of the actinium series. Owing to the low available amounts, low energy of its beta particles (maximum 44.8\u00a0keV) and low intensity of alpha radiation, is difficult to detect directly by its emission, and it is therefore traced via its decay products. The isotopes of actinium range in atomic weight from () to ().\nOccurrence and synthesis.\nActinium is found only in traces in uranium ores\u00a0\u2013 one tonne of uranium in ore contains about 0.2 milligrams of 227Ac \u2013 and in thorium ores, which contain about 5 nanograms of 228Ac per one tonne of thorium. The actinium isotope 227Ac is a transient member of the uranium-actinium series decay chain, which begins with the parent isotope 235U (or 239Pu) and ends with the stable lead isotope 207Pb. The isotope 228Ac is a transient member of the thorium series decay chain, which begins with the parent isotope 232Th and ends with the stable lead isotope 208Pb. Another actinium isotope (225Ac) is transiently present in the neptunium series decay chain, beginning with 237Np (or 233U) and ending with thallium (205Tl) and near-stable bismuth (209Bi); even though all primordial 237Np has decayed away, it is continuously produced by neutron knock-out reactions on natural 238U.\nThe low natural concentration and the close similarity of physical and chemical properties to those of lanthanum and other lanthanides, which are always abundant in actinium-bearing ores, render separation of actinium from the ore impractical. The most concentrated actinium sample prepared from raw material consisted of 7 micrograms of 227Ac in less than 0.1 milligrams of La2O3, and complete separation was never achieved. Instead, actinium is prepared, in milligram amounts, by the neutron irradiation of in a nuclear reactor.\n&lt;chem&gt;^{226}_{88}Ra + ^{1}_{0}n -&gt; ^{227}_{88}Ra -&gt;[\\beta^-][42.2 \\ \\ce{min}] ^{227}_{89}Ac&lt;/chem&gt;\nThe reaction yield is about 2% of the radium weight. 227Ac can further capture neutrons resulting in small amounts of 228Ac. After the synthesis, actinium is separated from radium and from the products of decay and nuclear fusion, such as thorium, polonium, lead, and bismuth. The extraction can be performed with thenoyltrifluoroacetone-benzene solution from an aqueous solution of the radiation products, and the selectivity to a certain element is achieved by adjusting the pH (to about 6.0 for actinium). An alternative procedure is anion exchange with an appropriate resin in nitric acid, which can result in a separation factor of 1,000,000 for radium and actinium vs. thorium in a two-stage process. Actinium can then be separated from radium, with a ratio of about 100, using a low cross-linking cation exchange resin and nitric acid as eluant.\n225Ac was first produced artificially at the Institute for Transuranium Elements (ITU) in Germany using a cyclotron and at St George Hospital in Sydney using a linac in 2000. This rare isotope has potential applications in radiation therapy and is most efficiently produced by bombarding a radium-226 target with 20\u201330\u00a0MeV deuterium ions. This reaction also yields 226Ac which however decays with a half-life of 29 hours and thus does not contaminate 225Ac.\nActinium metal has been prepared by the reduction of actinium fluoride with lithium vapor in vacuum at a temperature between . Higher temperatures resulted in evaporation of the product, and lower temperatures led to an incomplete transformation. Lithium was chosen among other alkali metals because its fluoride is the most volatile.\nApplications.\nOwing to its scarcity, high price and radioactivity, 227Ac currently has no significant industrial use, but 225Ac is currently being studied for use in cancer treatments such as targeted alpha therapies.\n227Ac is highly radioactive and was therefore studied for use as an active element of radioisotope thermoelectric generators, for example, in spacecraft. The oxide of 227Ac pressed with beryllium is also an efficient neutron source with the activity exceeding that of the standard americium-beryllium and radium-beryllium pairs. In all those applications, 227Ac (a beta source) is merely a progenitor which generates alpha-emitting isotopes upon its decay. Beryllium captures alpha particles and emits neutrons owing to its large cross-section for the (\u03b1,n) nuclear reaction:\n &lt;chem&gt;^{9}_{4}Be + ^{4}_{2}He -&gt; ^{12}_{6}C + ^{1}_{0}n + \\gamma&lt;/chem&gt;\nThe 227AcBe neutron sources can be applied in a neutron probe\u00a0\u2013 a standard device for measuring the quantity of water present in soil, as well as moisture/density for quality control in highway construction. Such probes are also used in well logging applications, in neutron radiography, tomography, and other radiochemical investigations.\n225Ac is applied in medicine to produce in a reusable generator or can be used alone as an agent for radiation therapy, in particular targeted alpha therapy (TAT). This isotope has a half-life of 10 days, making it much more suitable for radiation therapy than 213Bi (half-life 46 minutes). Additionally, 225Ac decays to nontoxic 209Bi rather than toxic lead, which is the final product in the decay chains of several other candidate isotopes, namely 227Th, 228Th, and 230U. Not only 225Ac itself, but also its daughters, emit alpha particles which kill cancer cells in the body. The major difficulty with the application of 225Ac was that intravenous injection of simple actinium complexes resulted in their accumulation in the bones and liver for a period of tens of years. As a result, after the cancer cells were quickly killed by alpha particles from 225Ac, the radiation from the actinium and its daughters might induce new mutations. To solve this problem, 225Ac was bound to a chelating agent, such as citrate, ethylenediaminetetraacetic acid (EDTA) or diethylene triamine pentaacetic acid (DTPA). This reduced actinium accumulation in the bones, but the excretion from the body remained slow. Much better results were obtained with such chelating agents as HEHA (1,4,7,10,13,16-hexaazacyclohexadecane-N,N\u2032,N\u2033,N\u2034,N\u2034\u2032,N\u2034\u2033-hexaacetic acid) or DOTA (1,4,7,10-tetraazacyclododecane-1,4,7,10-tetraacetic acid) coupled to trastuzumab, a monoclonal antibody that interferes with the HER2/neu receptor. The latter delivery combination was tested on mice and proved to be effective against leukemia, lymphoma, breast, ovarian, neuroblastoma and prostate cancers.\nThe medium half-life of 227Ac (21.77 years) makes it a very convenient radioactive isotope in modeling the slow vertical mixing of oceanic waters. The associated processes cannot be studied with the required accuracy by direct measurements of current velocities (of the order 50 meters per year). However, evaluation of the concentration depth profiles for different isotopes allows estimating the mixing rates. The physics behind this method is as follows: oceanic waters contain homogeneously dispersed 235U. Its decay product, 231Pa, gradually precipitates to the bottom, so that its concentration first increases with depth and then stays nearly constant. 231Pa decays to 227Ac; however, the concentration of the latter isotope does not follow the 231Pa depth profile, but instead increases toward the sea bottom. This occurs because of the mixing processes, which raise some additional 227Ac from the sea bottom. Thus, analysis of both 231Pa and 227Ac depth profiles allows researchers to model the mixing behavior.\nThere are theoretical predictions that AcHx hydrides (in this case with very high pressure) are a candidate for a near room-temperature superconductor as they have Tc significantly higher than H3S, possibly near 250\u00a0K.\nPrecautions.\n227Ac is highly radioactive and experiments with it are carried out in a specially designed laboratory equipped with a tight glove box. When actinium trichloride is administered intravenously to rats, about 33% of actinium is deposited into the bones and 50% into the liver. Its toxicity is comparable to, but slightly lower than, that of americium and plutonium. For trace quantities, fume hoods with good aeration suffice; for gram amounts, hot cells with shielding from the intense gamma radiation emitted by 227Ac are necessary.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "900", "revid": "50711986", "url": "https://en.wikipedia.org/wiki?curid=900", "title": "Americium", "text": "element with atomic number 95 (Am)\nAmericium is a synthetic chemical element; it has symbol Am and atomic number 95. It is radioactive and a transuranic member of the actinide series in the periodic table, located under the lanthanide element europium and was thus named after the Americas by analogy.\nAmericium was first produced in 1944 by the group of Glenn T. Seaborg from Berkeley, California, at the Metallurgical Laboratory of the University of Chicago, as part of the Manhattan Project. Although it is the third element in the transuranic series, it was discovered fourth, after the heavier curium. The discovery was kept secret and released to the public only in November 1945. Most americium is produced by uranium or plutonium being bombarded with neutrons in nuclear reactors \u2013 one tonne of spent nuclear fuel contains about 100 grams of americium. It is widely used in commercial ionization chamber smoke detectors, as well as in neutron sources and industrial gauges. Several unusual applications, such as nuclear batteries or fuel for space ships with nuclear propulsion, have been proposed for the isotope 242mAm, but they are as yet hindered by the scarcity and high price of this nuclear isomer.\nAmericium is a relatively soft radioactive metal with a silvery appearance. Its most common isotopes are 241Am and 243Am. In chemical compounds, americium usually assumes the oxidation state +3, especially in solutions. Several other oxidation states are known, ranging from +2 to +7, and can be identified by their characteristic optical absorption spectra. The crystal lattices of solid americium and its compounds contain small intrinsic radiogenic defects, due to metamictization induced by self-irradiation with alpha particles, which accumulates with time; this can cause a drift of some material properties over time, more noticeable in older samples.\nHistory.\nAlthough americium was likely produced in previous nuclear experiments, it was first intentionally synthesized, isolated and identified in late autumn 1944, at the University of California, Berkeley, by Glenn T. Seaborg, Leon O. Morgan, Ralph A. James, and Albert Ghiorso. They used a 60-inch cyclotron at the University of California, Berkeley. The element was chemically identified at the Metallurgical Laboratory (now Argonne National Laboratory) of the University of Chicago. Following the lighter neptunium, plutonium, and heavier curium, americium was the fourth transuranium element to be discovered. At the time, the periodic table had been restructured by Seaborg to its present layout, containing the actinide row below the lanthanide one. This led to americium being located right below its twin lanthanide element europium; it was thus by analogy named after the Americas: \"The name americium (after the Americas) and the symbol Am are suggested for the element on the basis of its position as the sixth member of the actinide rare-earth series, analogous to europium, Eu, of the lanthanide series.\"\nThe new element was isolated from its oxides in a complex, multi-step process. First plutonium-239 nitrate (239PuNO3) solution was coated on a platinum foil of about 0.5\u00a0cm2 area, the solution was evaporated and the residue was converted into plutonium dioxide (PuO2) by calcining. After cyclotron irradiation, the coating was dissolved with nitric acid, and then precipitated as the hydroxide using concentrated aqueous ammonia solution. The residue was dissolved in perchloric acid. Further separation was carried out by ion exchange, yielding a certain isotope of curium. The separation of curium and americium was so painstaking that those elements were initially called by the Berkeley group as \"pandemonium\" (from Greek for \"all demons\" or \"hell\") and \"delirium\" (from Latin for \"madness\").\nInitial experiments yielded four americium isotopes: 241Am, 242Am, 239Am and 238Am. Americium-241 was directly obtained from plutonium upon absorption of two neutrons. It decays by emission of a \u03b1-particle to 237Np; the half-life of this decay was first determined as years but then corrected to 432.2 years.\nformula_1\nThe second isotope 242Am was produced upon neutron bombardment of the already-created 241Am. Upon rapid \u03b2-decay, 242Am converts into the isotope of curium 242Cm (which had been discovered previously). The half-life of this decay was initially determined at 17 hours, which was close to the presently accepted value of 16.02 h.\n formula_2\nThe discovery of americium and curium in 1944 was closely related to the Manhattan Project; the results were confidential and declassified only in 1945. Seaborg leaked the synthesis of the elements 95 and 96 on the U.S. radio show for children \"Quiz Kids\" five days before the official presentation at an American Chemical Society meeting on 11 November 1945, when one of the listeners asked whether any new transuranium element besides plutonium and neptunium had been discovered during the war. After the discovery of americium isotopes 241Am and 242Am, their production and compounds were patented listing only Seaborg as the inventor. The initial americium samples weighed a few micrograms; they were barely visible and were identified by their radioactivity. The first substantial amounts of metallic americium weighing 40\u2013200 micrograms were not prepared until 1951 by reduction of americium(III) fluoride with barium metal in high vacuum at 1100\u00a0\u00b0C.\nOccurrence.\nThe longest-lived and most common isotopes of americium, 241Am and 243Am, have half-lives of 432.6 and 7,350 years, respectively. Therefore, any primordial americium (americium that was present on Earth during its formation) should have decayed by now. Trace amounts of americium probably occur naturally in uranium minerals as a result of neutron capture and beta decay (238U \u2192 239Pu \u2192 240Pu \u2192 241Am), though the quantities would be tiny and this has not been confirmed. Extraterrestrial long-lived 247Cm is probably also deposited on Earth and has 243Am as one of its intermediate decay products, but again this has not been confirmed.\nExisting americium is concentrated in the areas used for the atmospheric nuclear weapons tests conducted between 1945 and 1980, as well as at the sites of nuclear incidents, such as the Chernobyl disaster. For example, the analysis of the debris at the testing site of the first U.S. hydrogen bomb, Ivy Mike, (1 November 1952, Enewetak Atoll), revealed high concentrations of various actinides including americium; but due to military secrecy, this result was not published until later, in 1956. Trinitite, the glassy residue left on the desert floor near Alamogordo, New Mexico, after the plutonium-based Trinity nuclear bomb test on 16 July 1945, contains traces of americium-241. Elevated levels of americium were also detected at the crash site of a US Boeing B-52 bomber aircraft, which carried four hydrogen bombs, in 1968 in Greenland.\nIn other regions, the average radioactivity of surface soil due to residual americium is only about 0.01\u00a0picocuries per gram (0.37\u00a0mBq/g). Atmospheric americium compounds are poorly soluble in common solvents and mostly adhere to soil particles. Soil analysis revealed about 1,900 times higher concentration of americium inside sandy soil particles than in the water present in the soil pores; an even higher ratio was measured in loam soils.\nAmericium is produced mostly artificially in small quantities, for research purposes. A tonne of spent nuclear fuel contains about 100\u00a0grams of various americium isotopes, mostly 241Am and 243Am. Their prolonged radioactivity is undesirable for the disposal, and therefore americium, together with other long-lived actinides, must be neutralized. The associated procedure may involve several steps, where americium is first separated and then converted by neutron bombardment in special reactors to short-lived nuclides. This procedure is well known as nuclear transmutation, but it is still being developed for americium.\nThe transuranic elements up to fermium, including americium, should have been present in the natural nuclear fission reactor at Oklo, but any quantities produced then would have long since decayed away.\nSynthesis and extraction.\nIsotope nucleosynthesis.\nAmericium has been produced in small quantities in nuclear reactors for decades, and kilograms of its 241Am and 243Am isotopes have been accumulated by now. Nevertheless, since it was first offered for sale in 1962, its price, about of 241Am, remains almost unchanged owing to the very complex separation procedure. The heavier isotope 243Am is produced in much smaller amounts; it is thus more difficult to separate, resulting in a higher cost of the order .\nAmericium is not synthesized directly from uranium \u2013 the most common reactor material \u2013 but from the plutonium isotope 239Pu. The latter needs to be produced first, according to the following nuclear process:\n &lt;chem&gt;^{238}_{92}U -&gt;[\\ce{(n,\\gamma)}] ^{239}_{92}U -&gt;[\\beta^-][23.5 \\ \\ce{min}] ^{239}_{93}Np -&gt;[\\beta^-][2.3565 \\ \\ce{d}] ^{239}_{94}Pu&lt;/chem&gt;\nThe capture of two neutrons by 239Pu (a so-called (n,\u03b3) reaction), followed by a \u03b2-decay, results in 241Am:\n &lt;chem&gt;^{239}_{94}Pu -&gt;[\\ce{2(n,\\gamma)}] ^{241}_{94}Pu -&gt;[\\beta^-][14.35 \\ \\ce{yr}] ^{241}_{95}Am&lt;/chem&gt;\nThe plutonium present in spent nuclear fuel contains about 12% of 241Pu. Because it beta-decays to 241Am, 241Pu can be extracted and may be used to generate further 241Am. However, this process is rather slow: half of the original amount of 241Pu decays to 241Am after about 15 years, and the 241Am amount reaches a maximum after 70 years.\nThe obtained 241Am can be used for generating heavier americium isotopes by further neutron capture inside a nuclear reactor. In a light water reactor (LWR), 79% of 241Am converts to 242Am and 10% to its nuclear isomer 242mAm:\nformula_3\nAmericium-242 has a half-life of only 16 hours, which makes its further conversion to 243Am extremely inefficient. The latter isotope is produced instead in a process where 239Pu captures four neutrons under high neutron flux:\n &lt;chem&gt;^{239}_{94}Pu -&gt;[\\ce{4(n,\\gamma)}] \\ ^{243}_{94}Pu -&gt;[\\beta^-][4.956 \\ \\ce{h}] ^{243}_{95}Am&lt;/chem&gt;\nMetal generation.\nMost synthesis routines yield a mixture of different actinide isotopes in oxide forms, from which isotopes of americium can be separated. In a typical procedure, the spent reactor fuel (e.g. MOX fuel) is dissolved in nitric acid, and the bulk of uranium and plutonium is removed using a PUREX-type extraction (Plutonium\u2013URanium EXtraction) with tributyl phosphate in a hydrocarbon. The lanthanides and remaining actinides are then separated from the aqueous residue (raffinate) by a diamide-based extraction, to give, after stripping, a mixture of trivalent actinides and lanthanides. Americium compounds are then selectively extracted using multi-step chromatographic and centrifugation techniques with an appropriate reagent. A large amount of work has been done on the solvent extraction of americium. For example, a 2003 EU-funded project codenamed \"EUROPART\" studied triazines and other compounds as potential extraction agents. A \"bis\"-triazinyl bipyridine complex was proposed in 2009 as such a reagent is highly selective to americium (and curium). Separation of americium from the highly similar curium can be achieved by treating a slurry of their hydroxides in aqueous sodium bicarbonate with ozone, at elevated temperatures. Both Am and Cm are mostly present in solutions in the +3 valence state; whereas curium remains unchanged, americium oxidizes to soluble Am(IV) complexes which can be washed away.\nMetallic americium is obtained by reduction from its compounds. Americium(III) fluoride was first used for this purpose. The reaction was conducted using elemental barium as reducing agent in a water- and oxygen-free environment inside an apparatus made of tantalum and tungsten.\n formula_4\nAn alternative is the reduction of americium dioxide by metallic lanthanum or thorium:\n formula_5\nPhysical properties.\nIn the periodic table, americium is located to the right of plutonium, to the left of curium, and below the lanthanide europium, with which it shares many physical and chemical properties. Americium is a highly radioactive element. When freshly prepared, it has a silvery-white metallic lustre, but then slowly tarnishes in air. With a density of 12\u00a0g/cm3, americium is less dense than both curium (13.52\u00a0g/cm3) and plutonium (19.8\u00a0g/cm3); but has a higher density than europium (5.264\u00a0g/cm3)\u2014mostly because of its higher atomic mass. Americium is relatively soft and easily deformable and has a significantly lower bulk modulus than the actinides before it: Th, Pa, U, Np and Pu. Its melting point of 1173\u00a0\u00b0C is significantly higher than that of plutonium (639\u00a0\u00b0C) and europium (826\u00a0\u00b0C), but lower than for curium (1340\u00a0\u00b0C).\nAt ambient conditions, americium is present in its most stable \u03b1 form which has a hexagonal crystal symmetry, and a space group P63/mmc with cell parameters \"a\"\u00a0= 346.8\u00a0pm and \"c\"\u00a0= 1124\u00a0pm, and four atoms per unit cell. The crystal consists of a double-hexagonal close packing with the layer sequence ABAC and so is isotypic with \u03b1-lanthanum and several actinides such as \u03b1-curium. The crystal structure of americium changes with pressure and temperature. When compressed at room temperature to 5 GPa, \u03b1-Am transforms to the \u03b2 modification, which has a face-centered cubic (\"fcc\") symmetry, space group Fm3m and lattice constant \"a\"\u00a0= 489\u00a0pm. This \"fcc\" structure is equivalent to the closest packing with the sequence ABC. Upon further compression to 23 GPa, americium transforms to an orthorhombic \u03b3-Am structure similar to that of \u03b1-uranium. There are no further transitions observed up to 52 GPa, except for an appearance of a monoclinic phase at pressures between 10 and 15 GPa. There is no consistency on the status of this phase in the literature, which also sometimes lists the \u03b1, \u03b2 and \u03b3 phases as I, II and III. The \u03b2-\u03b3 transition is accompanied by a 6% decrease in the crystal volume; although theory also predicts a significant volume change for the \u03b1-\u03b2 transition, it is not observed experimentally. The pressure of the \u03b1-\u03b2 transition decreases with increasing temperature, and when \u03b1-americium is heated at ambient pressure, at 770\u00a0\u00b0C it changes into an \"fcc\" phase which is different from \u03b2-Am, and at 1075\u00a0\u00b0C it converts to a body-centered cubic structure. The pressure-temperature phase diagram of americium is thus rather similar to those of lanthanum, praseodymium and neodymium.\nAs with many other actinides, self-damage of the crystal structure due to alpha-particle irradiation is intrinsic to americium. It is especially noticeable at low temperatures, where the mobility of the produced structure defects is relatively low, by broadening of X-ray diffraction peaks. This effect makes somewhat uncertain the temperature of americium and some of its properties, such as electrical resistivity. So for americium-241, the resistivity at 4.2 K increases with time from about 2\u00a0\u03bcOhm\u00b7cm to 10\u00a0\u03bcOhm\u00b7cm after 40 hours, and saturates at about 16\u00a0\u03bcOhm\u00b7cm after 140 hours. This effect is less pronounced at room temperature, due to annihilation of radiation defects; also heating to room temperature the sample which was kept for hours at low temperatures restores its resistivity. In fresh samples, the resistivity gradually increases with temperature from about 2 \u03bcOhm\u00b7cm at liquid helium to 69\u00a0\u03bcOhm\u00b7cm at room temperature; this behavior is similar to that of neptunium, uranium, thorium and protactinium, but is different from plutonium and curium which show a rapid rise up to 60\u00a0K followed by saturation. The room temperature value for americium is lower than that of neptunium, plutonium and curium, but higher than for uranium, thorium and protactinium.\nAmericium is paramagnetic in a wide temperature range, from that of liquid helium, to room temperature and above. This behavior is markedly different from that of its neighbor curium which exhibits antiferromagnetic transition at 52\u00a0K. The thermal expansion coefficient of americium is slightly anisotropic and amounts to along the shorter \"a\" axis and for the longer \"c\" hexagonal axis. The enthalpy of dissolution of americium metal in hydrochloric acid at standard conditions is , from which the standard enthalpy change of formation (\u0394f\"H\"\u00b0) of aqueous Am3+ ion is . The standard potential Am3+/Am0 is .\nChemical properties.\nAmericium metal readily reacts with oxygen and dissolves in aqueous acids. The most stable oxidation state for americium is +3. The chemistry of americium(III) has many similarities to the chemistry of lanthanide(III) compounds. For example, trivalent americium forms insoluble fluoride, oxalate, iodate, hydroxide, phosphate and other salts. Compounds of americium in oxidation states +2, +4, +5, +6 and +7 have also been studied. This is the widest range that has been observed with actinide elements. The color of americium compounds in aqueous solution is as follows: Am3+ (yellow-reddish), Am4+ (yellow-reddish), ; (yellow), (brown) and (dark green). The absorption spectra have sharp peaks, due to \"f\"-\"f\" transitions' in the visible and near-infrared regions. Typically, Am(III) has absorption maxima at ca. 504 and 811\u00a0nm, Am(V) at ca. 514 and 715\u00a0nm, and Am(VI) at ca. 666 and 992\u00a0nm.\nAmericium compounds with oxidation state +4 and higher are strong oxidizing agents, comparable in strength to the permanganate ion () in acidic solutions. Whereas the Am4+ ions are unstable in solutions and readily convert to Am3+, compounds such as americium dioxide (AmO2) and americium(IV) fluoride (AmF4) are stable in the solid state.\nThe pentavalent oxidation state of americium was first observed in 1951. In acidic aqueous solution the ion is unstable with respect to disproportionation. The reaction\nis typical. The chemistry of Am(V) and Am(VI) is comparable to the chemistry of uranium in those oxidation states. In particular, compounds like and are comparable to uranates and the ion is comparable to the uranyl ion, . Such compounds can be prepared by oxidation of Am(III) in dilute nitric acid with ammonium persulfate. Other oxidising agents that have been used include silver(I,III) oxide, ozone and sodium persulfate.\nChemical compounds.\nOxygen compounds.\nThree americium oxides are known, with the oxidation states +2 (AmO), +3 (Am2O3) and +4 (AmO2). Americium(II) oxide was prepared in minute amounts and has not been characterized in detail. Americium(III) oxide is a red-brown solid with a melting point of 2205\u00a0\u00b0C. Americium(IV) oxide is the main form of solid americium which is used in nearly all its applications. As most other actinide dioxides, it is a black solid with a cubic (fluorite) crystal structure.\nThe oxalate of americium(III), vacuum dried at room temperature, has the chemical formula Am2(C2O4)3\u00b77H2O. Upon heating in vacuum, it loses water at 240\u00a0\u00b0C and starts decomposing into AmO2 at 300\u00a0\u00b0C, the decomposition completes at about 470\u00a0\u00b0C. The initial oxalate dissolves in nitric acid with the maximum solubility of 0.25\u00a0g/L.\nHalides.\nHalides of americium are known for the oxidation states +2, +3 and +4, where the +3 is most stable, especially in solutions.\nReduction of Am(III) compounds with sodium amalgam yields Am(II) salts \u2013 the black halides AmCl2, AmBr2 and AmI2. They are very sensitive to oxygen and oxidize in water, releasing hydrogen and converting back to the Am(III) state. Specific lattice constants are:\n &lt;chem&gt;{Am} + \\underset{mercury\\ halide}{HgX2} -&gt;[{} \\atop 400 - 500 ^\\circ \\ce C] {AmX2} + {Hg}&lt;/chem&gt;\nAmericium(III) fluoride (AmF3) is poorly soluble and precipitates upon reaction of Am3+ and fluoride ions in weak acidic solutions:\n &lt;chem&gt;Am^3+ + 3F^- -&gt; AmF3(v)&lt;/chem&gt;\nThe tetravalent americium(IV) fluoride (AmF4) is obtained by reacting solid americium(III) fluoride with molecular fluorine:\n &lt;chem&gt;2AmF3 + F2 -&gt; 2AmF4&lt;/chem&gt;\nAnother known form of solid tetravalent americium fluoride is KAmF5. Tetravalent americium has also been observed in the aqueous phase. For this purpose, black Am(OH)4 was dissolved in 15-M NH4F with the americium concentration of 0.01 M. The resulting reddish solution had a characteristic optical absorption spectrum which is similar to that of AmF4 but differed from other oxidation states of americium. Heating the Am(IV) solution to 90\u00a0\u00b0C did not result in its disproportionation or reduction, however a slow reduction was observed to Am(III) and assigned to self-irradiation of americium by alpha particles.\nMost americium(III) halides form hexagonal crystals with slight variation of the color and exact structure between the halogens. So, chloride (AmCl3) is reddish and has a structure isotypic to uranium(III) chloride (space group P63/m) and the melting point of 715\u00a0\u00b0C. The fluoride is isotypic to LaF3 (space group P63/mmc) and the iodide to BiI3 (space group R3). The bromide is an exception with the orthorhombic PuBr3-type structure and space group Cmcm. Crystals of americium(III) chloride hexahydrate (AmCl3\u00b76H2O) can be prepared by dissolving americium dioxide in hydrochloric acid and evaporating the liquid. Those crystals are hygroscopic and have yellow-reddish color and a monoclinic crystal structure.\nOxyhalides of americium in the form AmVIO2X2, AmVO2X, AmIVOX2 and AmIIIOX can be obtained by reacting the corresponding americium halide with oxygen or Sb2O3, and AmOCl can also be produced by vapor phase hydrolysis:\n AmCl3 + H2O -&gt; AmOCl + 2HCl\nChalcogenides and pnictides.\nThe known chalcogenides of americium include the sulfide AmS2, selenides AmSe2 and Am3Se4, and tellurides Am2Te3 and AmTe2. The pnictides of americium (243Am) of the AmX type are known for the elements phosphorus, arsenic, antimony and bismuth. They crystallize in the rock-salt lattice.\nSilicides and borides.\nAmericium monosilicide (AmSi) and \"disilicide\" (nominally AmSix with: 1.87 &lt; x &lt; 2.0) were obtained by reduction of americium(III) fluoride with elementary silicon in vacuum at 1050\u00a0\u00b0C (AmSi) and 1150\u22121200\u00a0\u00b0C (AmSix). AmSi is a black solid isomorphic with LaSi, it has an orthorhombic crystal symmetry. AmSix has a bright silvery lustre and a tetragonal crystal lattice (space group \"I\"41/amd), it is isomorphic with PuSi2 and ThSi2. Borides of americium include AmB4 and AmB6. The tetraboride can be obtained by heating an oxide or halide of americium with magnesium diboride in vacuum or inert atmosphere.\nOrganoamericium compounds.\nAnalogous to uranocene, americium is predicted to form the organometallic compound amerocene with two cyclooctatetraene ligands, with the chemical formula (\u03b78-C8H8)2Am. A cyclopentadienyl complex is also known that is likely to be stoichiometrically AmCp3.\nFormation of the complexes of the type Am(n-C3H7-BTP)3, where BTP stands for 2,6-di(1,2,4-triazin-3-yl)pyridine, in solutions containing n-C3H7-BTP and Am3+ ions has been confirmed by EXAFS. Some of these BTP-type complexes selectively interact with americium and therefore are useful in its selective separation from lanthanides and another actinides.\nBiological aspects.\nAmericium is an artificial element of recent origin, and thus does not have a biological requirement. It is harmful to life. It has been proposed to use bacteria for removal of americium and other heavy metals from rivers and streams. Thus, Enterobacteriaceae of the genus \"Citrobacter\" precipitate americium ions from aqueous solutions, binding them into a metal-phosphate complex at their cell walls. Several studies have been reported on the biosorption and bioaccumulation of americium by bacteria and fungi. In the laboratory, both americium and curium were found to support the growth of methylotrophs.\nFission.\nThe isotope 242mAm (half-life 141 years) has the largest cross sections for absorption of thermal neutrons (5,700 barns), that results in a small critical mass for a sustained nuclear chain reaction. The critical mass for a bare 242mAm sphere is about 9\u201314\u00a0kg (the uncertainty results from insufficient knowledge of its material properties). It can be lowered to 3\u20135\u00a0kg with a metal reflector and should become even smaller with a water reflector. Such small critical mass is favorable for portable nuclear weapons, but those based on 242mAm are not known yet, probably because of its scarcity and high price. The critical masses of the two readily available isotopes, 241Am and 243Am, are relatively high \u2013 57.6 to 75.6\u00a0kg for 241Am and 209\u00a0kg for 243Am. Scarcity and high price yet hinder application of americium as a nuclear fuel in nuclear reactors.\nThere has been a proposal for very compact 10-kW high-flux reactors using as little as 20\u00a0grams of 242mAm. Such low-power reactors would be relatively safe to use as neutron sources for radiation therapy in hospitals.\nIsotopes.\nAbout 18 isotopes and 11 nuclear isomers are known for americium, having mass numbers 229, 230, and 232 through 247. There are two long-lived alpha-emitters; 243Am has a half-life of 7,350\u00a0years and is the most stable isotope, and 241Am has a half-life of 432.6\u00a0years. The most stable nuclear isomer is 242m1Am - generally called simply 242mAm - with a long half-life of 141\u00a0years. The half-lives of other isotopes and isomers are much shorter with a maximum of 50.8\u00a0hours for 240Am. As with most other actinides, the isotopes of americium with odd number of neutrons have relatively high fissionability with thermal neutrons and low critical mass.\nAmericium-241 decays to 237Np emitting alpha particles of several different energies, mostly at 5.486\u00a0MeV (85.2%) and 5.443\u00a0MeV (12.8%). Becausethe resulting states are metastable, gamma rays are also emitted at discrete energies between 26.3 and 158.5\u00a0keV, by far the strongest is at 59.5 keV.\nAmericium-242 is a short-lived isotope with a half-life of 16.02\u00a0h. It mostly (82.7%) converts by \u03b2-decay to 242Cm, but also by electron capture to 242Pu (17.3%). Though both will join the uranium decay chain, they do not do so on any practical timescale because of the life of 238U generated by the former but not the latter.\nNearly all (99.55%) of 242mAm decays by internal conversion to 242Am and the remaining 0.45% by \u03b1-decay to 238Np. The latter subsequently decays to 238Pu and then to 234U, as with the main branch of the ground state.\nAmericium-243 transforms by \u03b1-emission into 239Np, which converts by \u03b2-decay to 239Pu, and further decay follows the actinium series.\nApplications.\nIonization-type smoke detector.\nAmericium is used in the most common type of household smoke detector, which uses 241Am in the form of americium dioxide as its source of ionizing radiation. This isotope is preferred over 226Ra because it emits 5 times more alpha particles and relatively little harmful gamma radiation.\nThe amount of americium in a typical new smoke detector is 1\u00a0microcurie (37\u00a0kBq) or 0.29 microgram. This amount declines slowly as the americium decays into neptunium-237, a different transuranic element with a much longer half-life (about 2.14 million years). With its half-life of 432.2 years, the americium in a smoke detector includes about 3% neptunium after 19 years, and about 5% after 32 years. The radiation passes through an ionization chamber, an air-filled space between two electrodes, and permits a small, constant current between the electrodes. Any smoke that enters the chamber absorbs the alpha particles, which reduces the ionization and affects this current, triggering the alarm. Compared to the alternative optical smoke detector, the ionization smoke detector is cheaper and can detect particles which are too small to produce significant light scattering; however, it is more prone to false alarms.\nRadionuclide.\nAs 241Am has a half-life roughly similar to 238Pu (432.2 years vs. 87 years), it has been proposed as an active element of radioisotope thermoelectric generators, for example in spacecraft. Although americium produces less heat and electricity \u2013 the power yield is 114.7\u00a0mW/g for 241Am and 6.31\u00a0mW/g for 243Am (cf. 390\u00a0mW/g for 238Pu) \u2013 and its radiation poses more threat to humans owing to neutron emission, the European Space Agency is considering using americium for its space probes.\nAnother proposed space-related application of americium is a fuel for space ships with nuclear propulsion. It relies on the very high rate of nuclear fission of 242mAm, which can be maintained even in a micrometer-thick foil. Small thickness avoids the problem of self-absorption of emitted radiation. This problem is pertinent to uranium or plutonium rods, in which only surface layers provide alpha-particles. The fission products of 242mAm can either directly propel the spaceship or they can heat a thrusting gas. They can also transfer their energy to a fluid and generate electricity through a magnetohydrodynamic generator.\nOne more proposal which utilizes the high nuclear fission rate of 242mAm is a nuclear battery. Its design relies not on the energy of the emitted by americium alpha particles, but on their charge, that is the americium acts as the self-sustaining \"cathode\". A single 3.2\u00a0kg 242mAm charge of such battery could provide about 140\u00a0kW of power over a period of 80 days. Even with all the potential benefits, the current applications of 242mAm are as yet hindered by the scarcity and high price of this particular nuclear isomer.\nIn 2019, researchers at the UK National Nuclear Laboratory and the University of Leicester demonstrated the use of heat generated by americium to illuminate a small light bulb. This technology could lead to systems to power missions with durations up to 400 years into interstellar space, where solar panels do not function.\nNeutron source.\nThe oxide of 241Am pressed with beryllium is an efficient neutron source. Here americium acts as the alpha source, and beryllium produces neutrons owing to its large cross-section for the (\u03b1,n) nuclear reaction:\n &lt;chem&gt;^{241}_{95}Am -&gt; ^{237}_{93}Np + ^{4}_{2}He + \\gamma&lt;/chem&gt;\n &lt;chem&gt;^{9}_{4}Be + ^{4}_{2}He -&gt; ^{12}_{6}C + ^{1}_{0}n + \\gamma&lt;/chem&gt;\nThe most widespread use of 241AmBe neutron sources is a neutron probe \u2013 a device used to measure the quantity of water present in soil, as well as moisture/density for quality control in highway construction. 241Am neutron sources are also used in well logging applications, as well as in neutron radiography, tomography and other radiochemical investigations.\nProduction of other elements.\nAmericium is a starting material for the production of other transuranic elements and transactinides \u2013 for example, 82.7% of 242Am decays to 242Cm and 17.3% to 242Pu. In the nuclear reactor, 242Am is also up-converted by neutron capture to 243Am and 244Am, which transforms by \u03b2-decay to 244Cm:\n &lt;chem&gt;^{243}_{95}Am -&gt;[\\ce{(n,\\gamma)}] ^{244}_{95}Am -&gt;[\\beta^-][10.1 \\ \\ce{h}] ^{244}_{96}Cm&lt;/chem&gt;\nIrradiation of 241Am by 12C or 22Ne ions yields the isotopes 247Es (einsteinium) or 260Db (dubnium), respectively. Furthermore, the element berkelium (243Bk isotope) had been first intentionally produced and identified by bombarding 241Am with alpha particles, in 1949, by the same Berkeley group, using the same 60-inch cyclotron. Similarly, nobelium was produced at the Joint Institute for Nuclear Research, Dubna, Russia, in 1965 in several reactions, one of which included irradiation of 243Am with 15N ions. Besides, one of the synthesis reactions for lawrencium, discovered by scientists at Berkeley and Dubna, included bombardment of 243Am with 18O.\nSpectrometer.\nAmericium-241 has been used as a portable source of both gamma rays and alpha particles for a number of medical and industrial uses. The 59.5409\u00a0keV gamma ray emissions from 241Am in such sources can be used for indirect analysis of materials in radiography and X-ray fluorescence spectroscopy, as well as for quality control in fixed nuclear density gauges and nuclear densometers. For example, the element has been employed to gauge glass thickness to help create flat glass. Americium-241 is also suitable for calibration of gamma-ray spectrometers in the low-energy range, since its spectrum consists of nearly a single peak and negligible Compton continuum (at least three orders of magnitude lower intensity). Americium-241 gamma rays were also used to provide passive diagnosis of thyroid function. This medical application is however obsolete.\nHealth concerns.\nAs a highly radioactive element, americium and its compounds must be handled only in an appropriate laboratory under special arrangements. Although most americium isotopes predominantly emit alpha particles which can be blocked by thin layers of common materials, many of the daughter products emit gamma-rays and neutrons which have a long penetration depth.\nIf consumed, most of the americium is excreted within a few days, with only 0.05% absorbed in the blood, of which roughly 45% goes to the liver and 45% to the bones, and the remaining 10% is excreted. The uptake to the liver depends on the individual and increases with age. In the bones, americium is first deposited over cortical and trabecular surfaces and slowly redistributes over the bone with time. The biological half-life of 241Am is 50 years in the bones and 20 years in the liver, whereas in the gonads (testicles and ovaries) it remains permanently; in all these organs, americium promotes formation of cancer cells as a result of its radioactivity.\nAmericium often enters landfills from discarded smoke detectors. The rules associated with the disposal of smoke detectors are relaxed in most jurisdictions. In 1994, 17-year-old David Hahn extracted the americium from about 100 smoke detectors in an attempt to build a breeder nuclear reactor. There have been a few cases of exposure to americium, the worst case being that of chemical operations technician Harold McCluskey, who at the age of 64 was exposed to 500 times the occupational standard for americium-241 as a result of an explosion in his lab. McCluskey died at the age of 75 of unrelated pre-existing disease.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "901", "revid": "20483999", "url": "https://en.wikipedia.org/wiki?curid=901", "title": "Astatine", "text": "element with atomic number 85 (At)\nAstatine is a chemical element; it has symbol At and atomic number 85. It is the rarest naturally occurring element in the Earth's crust, occurring only as the decay product of various heavier elements. All of astatine's isotopes are short-lived; the most stable is astatine-210, with a half-life of 8.1\u00a0hours. Consequently, a solid sample of the element has never been seen, because any macroscopic specimen would be immediately vaporized by the heat of its radioactivity.\nThe bulk properties of astatine are not known with certainty. Many of them have been estimated from its position on the periodic table as a heavier analog of fluorine, chlorine, bromine, and iodine, the four stable halogens. However, astatine also falls roughly along the dividing line between metals and nonmetals, and some metallic behavior has also been observed and predicted for it. Astatine is likely to have a dark or lustrous appearance and may be a semiconductor or possibly a metal. Chemically, several anionic species of astatine are known and most of its compounds resemble those of iodine, but it also sometimes displays metallic characteristics and shows some similarities to silver.\nThe first synthesis of astatine was in 1940 by Dale R. Corson, Kenneth Ross MacKenzie, and Emilio G. Segr\u00e8 at the University of California, Berkeley. They named it from the Ancient Greek () 'unstable'. Four isotopes of astatine were subsequently found to be naturally occurring, although much less than one gram is present at any given time in the Earth's crust. Neither the most stable isotope, astatine-210, nor the medically useful astatine-211 occur naturally; they are usually produced by bombarding bismuth-209 with alpha particles.\nCharacteristics.\nAstatine is an extremely radioactive element; all its isotopes have half-lives of 8.1 hours or less, decaying into other astatine isotopes, bismuth, polonium, or radon. Most of its isotopes are very unstable, with half-lives of seconds or less. Of the first 101 elements in the periodic table, only francium is less stable, and all the astatine isotopes more stable than the longest-lived francium isotopes (205\u2013211At) are synthetic and do not occur in nature.\nThe bulk properties of astatine are not known with any certainty. Research is limited by its short half-life, which prevents the creation of weighable quantities. A visible piece of astatine would immediately vaporize itself because of the heat generated by its intense radioactivity. It remains to be seen if, with sufficient cooling, a macroscopic quantity of astatine could be deposited as a thin film. Astatine is usually classified as either a nonmetal or a metalloid; metal formation has also been predicted.\nPhysical.\nMost of the physical properties of astatine have been estimated (by interpolation or extrapolation), using theoretically or empirically derived methods. For example, halogens get darker with increasing atomic weight\u00a0\u2013 fluorine is nearly colorless, chlorine is yellow-green, bromine is red-brown, and iodine is dark gray/violet. Astatine is sometimes described as probably being a black solid (assuming it follows this trend), or as having a metallic appearance (if it is a metalloid or a metal).\nAstatine sublimes less readily than iodine, having a lower vapor pressure. Even so, half of a given quantity of astatine will vaporize in approximately an hour if put on a clean glass surface at room temperature. The absorption spectrum of astatine in the middle ultraviolet region has lines at 224.401 and 216.225\u00a0nm, suggestive of 6p to 7s transitions.\nThe structure of solid astatine is unknown. As an analog of iodine it may have an orthorhombic crystalline structure composed of diatomic astatine molecules, and be a semiconductor (with a band gap of 0.7\u00a0eV). Alternatively, if condensed astatine forms a metallic phase, as has been predicted, it may have a monatomic face-centered cubic structure; in this structure, it may well be a superconductor, like the similar high-pressure phase of iodine. Metallic astatine is expected to have a density of 8.91\u20138.95\u00a0g/cm3.\nEvidence for (or against) the existence of diatomic astatine (At2) is sparse and inconclusive. Some sources state that it does not exist, or at least has never been observed, while other sources assert or imply its existence. Despite this controversy, many properties of diatomic astatine have been predicted; for example, its bond length would be , dissociation energy &lt;, and heat of vaporization (\u2206Hvap) 54.39\u00a0kJ/mol. Many values have been predicted for the melting and boiling points of astatine, but only for At2.\nChemical.\nThe chemistry of astatine is \"clouded by the extremely low concentrations at which astatine experiments have been conducted, and the possibility of reactions with impurities, walls and filters, or radioactivity by-products, and other unwanted nano-scale interactions\". Many of its apparent chemical properties have been observed using tracer studies on extremely dilute astatine solutions, typically less than 10\u221210 mol\u00b7L\u22121. Some properties, such as anion formation, align with other halogens. Astatine has some metallic characteristics as well, such as plating onto a cathode, and coprecipitating with metal sulfides in hydrochloric acid. It forms complexes with EDTA, a metal chelating agent, and is capable of acting as a metal in antibody radiolabeling; in some respects, astatine in the +1 state is akin to silver in the same state. Most of the organic chemistry of astatine is, however, analogous to that of iodine. It has been suggested that astatine can form a stable monatomic cation in aqueous solution.\nAstatine has an electronegativity of 2.2 on the revised Pauling scale\u00a0\u2013 lower than that of iodine (2.66) and the same as hydrogen. In hydrogen astatide (HAt), the negative charge is predicted to be on the hydrogen atom, implying that this compound could be referred to as astatine hydride according to certain nomenclatures. That would be consistent with the electronegativity of astatine on the Allred\u2013Rochow scale (1.9) being less than that of hydrogen (2.2). However, official IUPAC stoichiometric nomenclature is based on an idealized convention of determining the relative electronegativities of the elements by the mere virtue of their position within the periodic table. According to this convention, astatine is handled as though it is more electronegative than hydrogen, irrespective of its true electronegativity. The electron affinity of astatine, at 233 kJ mol\u22121, is 21% less than that of iodine. In comparison, the value of Cl (349) is 6.4% higher than F (328); Br (325) is 6.9% less than Cl; and I (295) is 9.2% less than Br. The marked reduction for At was predicted as being due to spin\u2013orbit interactions. The first ionization energy of astatine is about 899\u00a0kJ mol\u22121, which continues the trend of decreasing first ionization energies down the halogen group (fluorine, 1681; chlorine, 1251; bromine, 1140; iodine, 1008).\nCompounds.\nLess reactive than iodine, astatine is the least reactive of the halogens; the chemical properties of tennessine, the next-heavier group 17 element, have not yet been investigated, however. Astatine compounds have been synthesized in nano-scale amounts and studied as intensively as possible before their radioactive disintegration. The reactions involved have been typically tested with dilute solutions of astatine mixed with larger amounts of iodine. Acting as a carrier, the iodine ensures there is sufficient material for laboratory techniques (such as filtration and precipitation) to work. Like iodine, astatine has been shown to adopt odd-numbered oxidation states ranging from \u22121 to +7.\nOnly a few compounds with metals have been reported, in the form of astatides of sodium, palladium, silver, thallium, and lead. Some characteristic properties of silver and sodium astatide, and the other hypothetical alkali and alkaline earth astatides, have been estimated by extrapolation from other metal halides.\nThe formation of an astatine compound with hydrogen\u00a0\u2013 usually referred to as hydrogen astatide\u00a0\u2013 was noted by the pioneers of astatine chemistry. As mentioned, there are grounds for instead referring to this compound as astatine hydride. It is easily oxidized; acidification by dilute nitric acid gives the At0 or At+ forms, and the subsequent addition of silver(I) may only partially, at best, precipitate astatine as silver(I) astatide (AgAt). Iodine, in contrast, is not oxidized, and precipitates readily as silver(I) iodide.\nAstatine is known to bind to boron, carbon, and nitrogen. Various boron cage compounds have been prepared with At\u2013B bonds, these being more stable than At\u2013C bonds. Astatine can replace a hydrogen atom in benzene to form astatobenzene C6H5At; this may be oxidized to C6H5AtCl2 by chlorine. By treating this compound with an alkaline solution of hypochlorite, C6H5AtO2 can be produced. The dipyridine-astatine(I) cation, [At(C5H5N)2]+, forms ionic compounds with perchlorate (a non-coordinating anion) and with nitrate, [At(C5H5N)2]NO3. This cation exists as a coordination complex in which two dative covalent bonds separately link the astatine(I) centre with each of the pyridine rings via their nitrogen atoms.\nWith oxygen, there is evidence of the species AtO\u2212 and AtO+ in aqueous solution, formed by the reaction of astatine with an oxidant such as elemental bromine or (in the last case) by sodium persulfate in a solution of perchloric acid. The species previously thought to be has since been determined to be , a hydrolysis product of AtO+ (another such hydrolysis product being AtOOH). The well characterized anion can be obtained by, for example, the oxidation of astatine with potassium hypochlorite in a solution of potassium hydroxide. Preparation of lanthanum triastatate La(AtO3)3, following the oxidation of astatine by a hot Na2S2O8 solution, has been reported. Further oxidation of , such as by xenon difluoride (in a hot alkaline solution) or periodate (in a neutral or alkaline solution), yields the perastatate ion ; this is only stable in neutral or alkaline solutions. Astatine is also thought to be capable of forming cations in salts with oxyanions such as iodate or dichromate; this is based on the observation that, in acidic solutions, monovalent or intermediate positive states of astatine coprecipitate with the insoluble salts of metal cations such as silver(I) iodate or thallium(I) dichromate.\nAstatine may form bonds to the other chalcogens; these include S7At+ and with sulfur, a coordination selenourea compound with selenium, and an astatine\u2013tellurium colloid with tellurium.\nAstatine is known to react with its lighter homologs iodine, bromine, and chlorine in the vapor state; these reactions produce diatomic interhalogen compounds with formulas AtI, AtBr, and AtCl. The first two compounds may also be produced in water\u00a0\u2013 astatine reacts with iodine/iodide solution to form AtI, whereas AtBr requires (aside from astatine) an iodine/iodine monobromide/bromide solution. The excess of iodides or bromides may lead to and ions, or in a chloride solution, they may produce species like or via equilibrium reactions with the chlorides. Oxidation of the element with dichromate (in nitric acid solution) showed that adding chloride turned the astatine into a molecule likely to be either AtCl or AtOCl. Similarly, or may be produced. The polyhalides PdAtI2, CsAtI2, TlAtI2, and PbAtI are known or presumed to have been precipitated. In a plasma ion source mass spectrometer, the ions [AtI]+, [AtBr]+, and [AtCl]+ have been formed by introducing lighter halogen vapors into a helium-filled cell containing astatine, supporting the existence of stable neutral molecules in the plasma ion state. No astatine fluorides have been discovered yet. Their absence has been speculatively attributed to the extreme reactivity of such compounds, including the reaction of an initially formed fluoride with the walls of the glass container to form a non-volatile product. Thus, although the synthesis of an astatine fluoride is thought to be possible, it may require a liquid halogen fluoride solvent, as has already been used for the characterization of radon fluoride.\nHistory.\n Dmitri Mendeleev's table of 1871, with an empty space at the eka-iodine position\nIn 1869, when Dmitri Mendeleev published his periodic table, the space under iodine was empty; after Niels Bohr established the physical basis of the classification of chemical elements, it was suggested that the fifth halogen belonged there. Before its officially recognized discovery, it was called \"eka-iodine\" (from Sanskrit 'one') to imply it was one space under iodine (in the same manner as eka-silicon, eka-boron, and others). Scientists tried to find it in nature; given its extreme rarity, these attempts resulted in several false discoveries.\nThe first claimed discovery of eka-iodine was made by Fred Allison and his associates at the Alabama Polytechnic Institute (now Auburn University) in 1931. The discoverers named element 85 \"alabamine\", and assigned it the symbol Ab, designations that were used for a few years. In 1934, H. G. MacPherson of University of California, Berkeley disproved Allison's method and the validity of his discovery. There was another claim in 1937, by the chemist Rajendralal De. Working in Dacca in British India (now Dhaka in Bangladesh), he chose the name \"dakin\" for element 85, which he claimed to have isolated as the thorium series equivalent of radium F (polonium-210) in the radium series. The properties he reported for dakin do not correspond to those of astatine, and astatine's radioactivity would have prevented him from handling it in the quantities he claimed. Moreover, astatine is not found in the thorium series, and the true identity of dakin is not known.\nIn 1936, the team of Romanian physicist Horia Hulubei and French physicist Yvette Cauchois claimed to have discovered element 85 by observing its X-ray emission lines. In 1939, they published another paper which supported and extended previous data. In 1944, Hulubei published a summary of data he had obtained up to that time, claiming it was supported by the work of other researchers. He chose the name \"dor\", presumably from the Romanian for \"longing\" [for peace], as World War II had started five years earlier. As Hulubei was writing in French, a language which does not accommodate the \"-ine\" suffix, dor would likely have been rendered in English as \"dorine\", had it been adopted. In 1947, Hulubei's claim was effectively rejected by the Austrian chemist Friedrich Paneth, who would later chair the IUPAC committee responsible for recognition of new elements. Even though Hulubei's samples did contain astatine-218, his means to detect it were too weak, by current standards, to enable correct identification; moreover, he could not perform chemical tests on the element. He had also been involved in an earlier false claim as to the discovery of element 87 (francium) and this is thought to have caused other researchers to downplay his work.\nIn 1940, the Swiss chemist Walter Minder announced the discovery of element 85 as the beta decay product of radium A (polonium-218), choosing the name \"helvetium\" (from , the Latin name of Switzerland). Berta Karlik and Traude Bernert were unsuccessful in reproducing his experiments, and subsequently attributed Minder's results to contamination of his radon stream (radon-222 is the parent isotope of polonium-218). In 1942, Minder, in collaboration with the English scientist Alice Leigh-Smith, announced the discovery of another isotope of element 85, presumed to be the product of thorium A (polonium-216) beta decay. They named this substance \"anglo-helvetium\", but Karlik and Bernert were again unable to reproduce these results.\nLater in 1940, Dale R. Corson, Kenneth Ross MacKenzie, and Emilio Segr\u00e8 isolated the element at the University of California, Berkeley. Instead of searching for the element in nature, the scientists created it by bombarding bismuth-209 with alpha particles in a cyclotron (particle accelerator) to produce, after emission of two neutrons, astatine-211. The discoverers, however, did not immediately suggest a name for the element. The reason for this was that at the time, an element created synthetically in \"invisible quantities\" that had not yet been discovered in nature was not seen as a completely valid one; in addition, chemists were reluctant to recognize radioactive isotopes as legitimately as stable ones. In 1943, astatine was found as a product of two naturally occurring decay chains by Berta Karlik and Traude Bernert, first in the so-called uranium series, and then in the actinium series. (Since then, astatine was also found in a third decay chain, the neptunium series.) Friedrich Paneth in 1946 called to finally recognize synthetic elements, quoting, among other reasons, recent confirmation of their natural occurrence, and proposed that the discoverers of the newly discovered unnamed elements name these elements. In early 1947, \"Nature\" published the discoverers' suggestions; a letter from Corson, MacKenzie, and Segr\u00e8 suggested the name \"astatine\" coming from the Ancient Greek () meaning 'unstable', because of its propensity for radioactive decay, with the ending \"-ine\", found in the names of the four previously discovered halogens. The name was also chosen to continue the tradition of the four stable halogens, where the name referred to a property of the element.\nCorson and his colleagues classified astatine as a metal on the basis of its analytical chemistry. Subsequent investigators reported iodine-like, cationic, or amphoteric behavior. In a 2003 retrospective, Corson wrote that \"some of the properties [of astatine] are similar to iodine\u00a0... it also exhibits metallic properties, more like its metallic neighbors Po and Bi.\"\nIsotopes.\nThere are 41 known isotopes of astatine, with mass numbers of 188 and 190\u2013229. Theoretical modeling suggests that about 37 more isotopes could exist. No stable or long-lived astatine isotope has been observed, nor is one expected to exist.\nAstatine's alpha decay energies follow the same trend as for other heavy elements. Lighter astatine isotopes have quite high energies of alpha decay, which become lower as the nuclei become heavier. Astatine-211 has a significantly higher energy than the previous isotope, because it has a nucleus with 126 neutrons, and 126 is a magic number corresponding to a filled neutron shell. Despite having a similar half-life to the previous isotope (8.1\u00a0hours for astatine-210 and 7.2\u00a0hours for astatine-211), the alpha decay probability is much higher for the latter: 41.81% against only 0.18%. The two following isotopes release even more energy, with astatine-213 releasing the most energy. For this reason, it is the shortest-lived astatine isotope. Even though heavier astatine isotopes release less energy, no long-lived astatine isotope exists, because of the increasing role of beta decay (electron emission). This decay mode is especially important for astatine; as early as 1950 it was postulated that all isotopes of the element undergo beta decay, though nuclear mass measurements indicate that 215At is in fact beta-stable, as it has the lowest mass of all isobars with \"A\"\u00a0=\u00a0215. Astatine-210 and most of the lighter isotopes exhibit beta plus decay (positron emission), astatine-217 and heavier isotopes except astatine-218 exhibit beta minus decay, while astatine-211 undergoes electron capture.\nThe most stable isotope is astatine-210, which has a half-life of 8.1\u00a0hours. The primary decay mode is beta plus, to the relatively long-lived (in comparison to astatine isotopes) alpha emitter polonium-210. In total, only five isotopes have half-lives exceeding one hour (astatine-207 to -211). The least stable ground state isotope is astatine-213, with a half-life of 125 nanoseconds. It undergoes alpha decay to the extremely long-lived bismuth-209.\nAstatine has 24 known nuclear isomers, which are nuclei with one or more nucleons (protons or neutrons) in an excited state. A nuclear isomer may also be called a \"meta-state\", meaning the system has more internal energy than the \"ground state\" (the state with the lowest possible internal energy), making the former likely to decay into the latter. There may be more than one isomer for each isotope. The most stable of these nuclear isomers is astatine-202m1, which has a half-life of about 3 minutes, longer than those of all the ground states bar those of isotopes 203\u2013211 and 220. The least stable is astatine-213m1; its half-life of 110 nanoseconds is shorter than 125 nanoseconds for astatine-213, the shortest-lived ground state.\nNatural occurrence.\nAstatine is the rarest naturally occurring element. The total amount of astatine in the Earth's crust (quoted mass 2.36 \u00d7 1025 grams) is estimated by some to be less than one gram at any given time. Other sources estimate the amount of ephemeral astatine, present on earth at any given moment, to be up to one ounce (about 28 grams).\nAny astatine present at the formation of the Earth has long since disappeared; the four naturally occurring isotopes (astatine-215, -217, -218 and -219) are instead continuously produced as a result of the decay of radioactive thorium and uranium ores, and trace quantities of neptunium-237. The landmass of North and South America combined, to a depth of 16 kilometers (10 miles), contains only about one trillion astatine-215 atoms at any given time (around 3.5 \u00d7 10\u221210 grams). Astatine-217 is produced via the radioactive decay of neptunium-237. Primordial remnants of the latter isotope\u2014due to its relatively short half-life of 2.14 million years\u2014are no longer present on Earth. However, trace amounts occur naturally as a product of transmutation reactions in uranium ores. Astatine-218 was the first astatine isotope discovered in nature. Astatine-219, with a half-life of 56 seconds, is the longest lived of the naturally occurring isotopes.\nIsotopes of astatine are sometimes not listed as naturally occurring because of misconceptions that there are no such isotopes, or discrepancies in the literature. Astatine-216 has been counted as a naturally occurring isotope but reports of its observation (which were described as doubtful) have not been confirmed.\nSynthesis.\nFormation.\nAstatine was first produced by bombarding bismuth-209 with energetic alpha particles, and this is still the major route used to create the relatively long-lived isotopes astatine-209 through astatine-211. Astatine is only produced in minuscule quantities, with modern techniques allowing production runs of up to 6.6\u00a0gigabecquerels (about 86\u00a0nanograms or 2.47\u00d71014 atoms). Synthesis of greater quantities of astatine using this method is constrained by the limited availability of suitable cyclotrons and the prospect of melting the target. Solvent radiolysis due to the cumulative effect of astatine decay is a related problem. With cryogenic technology, microgram quantities of astatine might be able to be generated via proton irradiation of thorium or uranium to yield radon-211, in turn decaying to astatine-211. Contamination with astatine-210 is expected to be a drawback of this method.\nThe most important isotope is astatine-211, the only one in commercial use. To produce the bismuth target, the metal is sputtered onto a gold, copper, or aluminium surface at 50 to 100 milligrams per square centimeter. Bismuth oxide can be used instead; this is forcibly fused with a copper plate. The target is kept under a chemically neutral nitrogen atmosphere, and is cooled with water to prevent premature astatine vaporization. In a particle accelerator, such as a cyclotron, alpha particles are collided with the bismuth. Even though only one bismuth isotope is used (bismuth-209), the reaction may occur in three possible ways, producing astatine-209, astatine-210, or astatine-211. Although higher energies can produce more astatine-211, it will produce unwanted astatine-210 that decays to toxic polonium-210 as well. Instead, the maximum energy of the particle accelerator is set to be below or slightly above the threshold of astatine-210 production, in order to maximize the production of astatine-211 while keeping the amount of astatine-210 at an acceptable level.\nSeparation methods.\nSince astatine is the main product of the synthesis, after its formation it must only be separated from the target and any significant contaminants. Several methods are available, \"but they generally follow one of two approaches\u2014dry distillation or [wet] acid treatment of the target followed by solvent extraction.\" The methods summarized below are modern adaptations of older procedures, as reviewed by Kugler and Keller. Pre-1985 techniques more often addressed the elimination of co-produced toxic polonium; this requirement is now mitigated by capping the energy of the cyclotron irradiation beam.\nDry.\nThe astatine-containing cyclotron target is heated to a temperature of around 650\u00a0\u00b0C. The astatine volatilizes and is condensed in (typically) a cold trap. Higher temperatures of up to around 850\u00a0\u00b0C may increase the yield, at the risk of bismuth contamination from concurrent volatilization. Redistilling the condensate may be required to minimize the presence of bismuth (as bismuth can interfere with astatine labeling reactions). The astatine is recovered from the trap using one or more low concentration solvents such as sodium hydroxide, methanol or chloroform. Astatine yields of up to around 80% may be achieved. Dry separation is the method most commonly used to produce a chemically useful form of astatine.\nWet.\nThe irradiated bismuth (or sometimes bismuth trioxide) target is first dissolved in, for example, concentrated nitric or perchloric acid. Following this first step, the acid can be distilled away to leave behind a white residue that contains both bismuth and the desired astatine product. This residue is then dissolved in a concentrated acid, such as hydrochloric acid. Astatine is extracted from this acid using an organic solvent such as dibutyl ether, diisopropyl ether (DIPE), or thiosemicarbazide. Using liquid-liquid extraction, the astatine product can be repeatedly washed with an acid, such as HCl, and extracted into the organic solvent layer. A separation yield of 93% using nitric acid has been reported, falling to 72% by the time purification procedures were completed (distillation of nitric acid, purging residual nitrogen oxides, and redissolving bismuth nitrate to enable liquid\u2013liquid extraction). Wet methods involve \"multiple radioactivity handling steps\" and have not been considered well suited for isolating larger quantities of astatine. However, wet extraction methods are being examined for use in production of larger quantities of astatine-211, as it is thought that wet extraction methods can provide more consistency. They can enable the production of astatine in a specific oxidation state and may have greater applicability in experimental radiochemistry.\nUses and precautions.\nNewly formed astatine-211 is the subject of ongoing research in nuclear medicine. It must be used quickly as it decays with a half-life of 7.2\u00a0hours; this is long enough to permit multistep labeling strategies. Astatine-211 has potential for targeted alpha-particle therapy, since it decays either via emission of an alpha particle (to bismuth-207), or via electron capture (to an extremely short-lived nuclide, polonium-211, which undergoes further alpha decay), very quickly reaching its stable granddaughter lead-207. Polonium X-rays emitted as a result of the electron capture branch, in the range of 77\u201392\u00a0keV, enable the tracking of astatine in animals and patients. Although astatine-210 has a slightly longer half-life, it is wholly unsuitable because it usually undergoes beta plus decay to the extremely toxic polonium-210.\nThe principal medicinal difference between astatine-211 and iodine-131 (a radioactive iodine isotope also used in medicine) is that iodine-131 emits high-energy beta particles, and astatine does not. Beta particles have much greater penetrating power through tissues than do the much heavier alpha particles. An average alpha particle released by astatine-211 can travel up to 70\u00a0\u03bcm through surrounding tissues; an average-energy beta particle emitted by iodine-131 can travel nearly 30 times as far, to about 2\u00a0mm. The short half-life and limited penetrating power of alpha radiation through tissues offers advantages in situations where the \"tumor burden is low and/or malignant cell populations are located in close proximity to essential normal tissues.\" Significant morbidity in cell culture models of human cancers has been achieved with from one to ten astatine-211 atoms bound per cell.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\nAstatine\u00a0... [is] miserable to make and hell to work with.\nP Durbin, \"Human Radiation Studies: Remembering the Early Years\", 1995\nSeveral obstacles have been encountered in the development of astatine-based radiopharmaceuticals for cancer treatment. World War II delayed research for close to a decade. Results of early experiments indicated that a cancer-selective carrier would need to be developed and it was not until the 1970s that monoclonal antibodies became available for this purpose. Unlike iodine, astatine shows a tendency to dehalogenate from molecular carriers such as these, particularly at sp3 carbon sites (less so from sp2 sites). Given the toxicity of astatine accumulated and retained in the body, this emphasized the need to ensure it remained attached to its host molecule. While astatine carriers that are slowly metabolized can be assessed for their efficacy, more rapidly metabolized carriers remain a significant obstacle to the evaluation of astatine in nuclear medicine. Mitigating the effects of astatine-induced radiolysis of labeling chemistry and carrier molecules is another area requiring further development. A practical application for astatine as a cancer treatment would potentially be suitable for a \"staggering\" number of patients; production of astatine in the quantities that would be required remains an issue.\nAnimal studies show that astatine, similarly to iodine\u2014although to a lesser extent, perhaps because of its slightly more metallic nature\u2014is preferentially (and dangerously) concentrated in the thyroid gland. Unlike iodine, astatine also shows a tendency to be taken up by the lungs and spleen, possibly because of in-body oxidation of At\u2013 to At+. If administered in the form of a radiocolloid it tends to concentrate in the liver. Experiments in rats and monkeys suggest that astatine-211 causes much greater damage to the thyroid gland than does iodine-131, with repetitive injection of the nuclide resulting in necrosis and cell dysplasia within the gland. Early research suggested that injection of astatine into female rodents caused morphological changes in breast tissue; this conclusion remained controversial for many years. General agreement was later reached that this was likely caused by the effect of breast tissue irradiation combined with hormonal changes due to irradiation of the ovaries. Trace amounts of astatine can be handled safely in fume hoods if they are well-aerated; biological uptake of the element must be avoided.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "902", "revid": "39999417", "url": "https://en.wikipedia.org/wiki?curid=902", "title": "Atom", "text": "Smallest unit of a chemical element\nAtoms are the basic particles of the chemical elements and the fundamental building blocks of matter. An atom consists of a nucleus of protons and generally neutrons, surrounded by an electromagnetically bound swarm of electrons. The chemical elements are distinguished from each other by the number of protons that are in their atoms. For example, any atom that contains 11 protons is sodium, and any atom that contains 29 protons is copper. Atoms with the same number of protons but a different number of neutrons are called isotopes of the same element.\nAtoms are extremely small, typically around 100\u00a0picometers across. A human hair is about a million carbon atoms wide. Atoms are smaller than the shortest wavelength of visible light, which means humans cannot see atoms with conventional microscopes. They are so small that accurately predicting their behavior using classical physics is not possible due to quantum effects.\nMore than 99.94% of an atom's mass is in the nucleus. Protons have a positive electric charge and neutrons have no charge, so the nucleus is positively charged. The electrons are negatively charged, and this opposing charge is what binds them to the nucleus. If the numbers of protons and electrons are equal, as they normally are, then the atom is electrically neutral as a whole. A charged atom is called an ion. If an atom has more electrons than protons, then it has an overall negative charge and is called a negative ion (or anion). Conversely, if it has more protons than electrons, it has a positive charge and is called a positive ion (or cation).\nThe electrons of an atom are attracted to the protons in an atomic nucleus by the electromagnetic force. The protons and neutrons in the nucleus are attracted to each other by the nuclear force. This force is usually stronger than the electromagnetic force that repels the positively charged protons from one another. Under certain circumstances, the repelling electromagnetic force becomes stronger than the nuclear force. In this case, the nucleus splits and leaves behind different elements. This is a form of nuclear decay.\nAtoms can attach to one or more other atoms by chemical bonds to form chemical compounds such as molecules or crystals. The ability of atoms to attach and detach from each other is responsible for most of the physical changes observed in nature. Chemistry is the science that studies these changes.\nHistory of atomic theory.\nIn philosophy.\nThe basic idea that matter is made up of tiny indivisible particles is an old idea that appeared in many ancient cultures. Maharashi Kan\u0101d's atomic theory dating back to 2600 years from India is notable in this respect. According to him, 'paramanu' (lit. The smallest particle of matter) is atom. He used the example of rice, when ground into a fine powder, a stage is reached, where it cannot be ground further. Though, in modern sense, this is not the exact meaning of atom, but it somewhat aligns with Daltons theory. The word \"atom\" is derived from the ancient Greek word \"atomos\", which means \"uncuttable\". However, this ancient idea was based in philosophical reasoning rather than scientific reasoning. Modern atomic theory is not based on these old concepts. In the early 19th century, the scientist John Dalton found evidence that matter really is composed of discrete units, and so applied the word \"atom\" to those units.\nDalton's law of multiple proportions.\nIn the early 1800s, John Dalton compiled experimental data gathered by him and other scientists and discovered a pattern now known as the \"law of multiple proportions\". He noticed that in any group of chemical compounds which all contain two particular chemical elements, the amount of Element A per measure of Element B will differ across these compounds by ratios of small whole numbers. This pattern suggested that each element combines with other elements in multiples of a basic unit of weight, with each element having a unit of unique weight. Dalton decided to call these units \"atoms\".\nFor example, there are two types of tin oxide: one is a grey powder that is 88.1% tin and 11.9% oxygen, and the other is a white powder that is 78.7% tin and 21.3% oxygen. Adjusting these figures, in the grey powder there is about 13.5\u00a0g of oxygen for every 100\u00a0g of tin, and in the white powder there is about 27\u00a0g of oxygen for every 100\u00a0g of tin. 13.5 and 27 form a ratio of 1:2. Dalton concluded that in the grey oxide there is one atom of oxygen for every atom of tin, and in the white oxide there are two atoms of oxygen for every atom of tin (SnO and SnO2).\nDalton also analyzed iron oxides. There is one type of iron oxide that is a black powder which is 78.1% iron and 21.9% oxygen; and there is another iron oxide that is a red powder which is 70.4% iron and 29.6% oxygen. Adjusting these figures, in the black powder there is about 28\u00a0g of oxygen for every 100\u00a0g of iron, and in the red powder there is about 42\u00a0g of oxygen for every 100\u00a0g of iron. 28 and 42 form a ratio of 2:3. Dalton concluded that in these oxides, for every two atoms of iron, there are two or three atoms of oxygen respectively. These substances are known today as iron(II) oxide and iron(III) oxide, and their formulas are FeO and Fe2O3 respectively. Iron(II) oxide's formula is normally written as FeO, but since it is a crystalline substance we could alternately write it as Fe2O2, and when we contrast that with Fe2O3, the 2:3 ratio for the oxygen is plain to see.\nAs a final example: nitrous oxide is 63.3% nitrogen and 36.7% oxygen, nitric oxide is 44.05% nitrogen and 55.95% oxygen, and nitrogen dioxide is 29.5% nitrogen and 70.5% oxygen. Adjusting these figures, in nitrous oxide there is 80\u00a0g of oxygen for every 140\u00a0g of nitrogen, in nitric oxide there is about 160\u00a0g of oxygen for every 140\u00a0g of nitrogen, and in nitrogen dioxide there is 320\u00a0g of oxygen for every 140\u00a0g of nitrogen. 80, 160, and 320 form a ratio of 1:2:4. The respective formulas for these oxides are N2O, NO, and NO2.\nDiscovery of the electron.\nIn 1897, J. J. Thomson discovered that cathode rays can be deflected by electric and magnetic fields, which meant that cathode rays are not a form of light but made of electrically charged particles, and their charge was negative given the direction the particles were deflected in. He measured these particles to be 1,700 times lighter than hydrogen (the lightest atom). He called these new particles \"corpuscles\" but they were later renamed \"electrons\" since these are the particles that carry electricity. Thomson also showed that electrons were identical to particles given off by photoelectric and radioactive materials. Thomson explained that an electric current is the passing of electrons from one atom to the next, and when there was no current the electrons embedded themselves in the atoms. This in turn meant that atoms were not indivisible as scientists thought. The atom was composed of electrons whose negative charge was balanced out by some source of positive charge to create an electrically neutral atom. Ions, Thomson explained, must be atoms which have an excess or shortage of electrons.\nDiscovery of the nucleus.\nThe electrons in the atom logically had to be balanced out by a commensurate amount of positive charge, but Thomson had no idea where this positive charge came from, so he tentatively proposed that it was everywhere in the atom, the atom being in the shape of a sphere. This was the mathematically simplest hypothesis to fit the available evidence, or lack thereof. Following from this, Thomson imagined that the balance of electrostatic forces would distribute the electrons throughout the sphere in a more or less even manner. Thomson's model is popularly known as the plum pudding model, though neither Thomson nor his colleagues used this analogy. Thomson's model was incomplete, it was unable to predict any other properties of the elements such as emission spectra and valencies. It was soon rendered obsolete by the discovery of the atomic nucleus.\nBetween 1908 and 1913, Ernest Rutherford and his colleagues Hans Geiger and Ernest Marsden performed a series of experiments in which they bombarded thin foils of metal with a beam of alpha particles. They did this to measure the scattering patterns of the alpha particles. They spotted a small number of alpha particles being deflected by angles greater than 90\u00b0. This shouldn't have been possible according to the Thomson model of the atom, whose charges were too diffuse to produce a sufficiently strong electric field. The deflections should have all been negligible. Rutherford proposed that the positive charge of the atom is concentrated in a tiny volume at the center of the atom and that the electrons surround this nucleus in a diffuse cloud. This nucleus carried almost all of the atom's mass. Only such an intense concentration of charge, anchored by its high mass, could produce an electric field that could deflect the alpha particles so strongly.\nBohr model.\nA problem in classical mechanics is that an accelerating charged particle radiates electromagnetic radiation, causing the particle to lose kinetic energy. Circular motion counts as acceleration, which means that an electron orbiting a central charge should spiral down into that nucleus as it loses speed. In 1913, the physicist Niels Bohr proposed a new model in which the electrons of an atom were assumed to orbit the nucleus but could only do so in a finite set of orbits, and could jump between these orbits only in discrete changes of energy corresponding to absorption or radiation of a photon. This quantization was used to explain why the electrons' orbits are stable and why elements absorb and emit electromagnetic radiation in discrete spectra. Bohr's model could only predict the emission spectra of hydrogen, not atoms with more than one electron.\nDiscovery of protons and neutrons.\nBack in 1815, William Prout observed that the atomic weights of many elements were multiples of hydrogen's atomic weight, which is in fact true for all of them if one takes isotopes into account. In 1898, J. J. Thomson found that the positive charge of a hydrogen ion is equal to the negative charge of an electron, and these were then the smallest known charged particles. Thomson later found that the positive charge in an atom is a positive multiple of an electron's negative charge. In 1913, Henry Moseley discovered that the frequencies of X-ray emissions from an excited atom were a mathematical function of its atomic number and hydrogen's nuclear charge. In 1919, Rutherford bombarded nitrogen gas with alpha particles and detected hydrogen ions being emitted from the gas, and concluded that they were produced by alpha particles hitting and splitting the nuclei of the nitrogen atoms.\nThese observations led Rutherford to conclude that the hydrogen nucleus is a singular particle with a positive charge equal to the electron's negative charge. He named this particle \"proton\" in 1920. The number of protons in an atom (which Rutherford called the \"atomic number\") was found to be equal to the element's ordinal number on the periodic table and therefore provided a simple and clear-cut way of distinguishing the elements from each other. The atomic weight of each element is higher than its proton number, so Rutherford hypothesized that the surplus weight was carried by unknown particles with no electric charge and a mass equal to that of the proton.\nIn 1928, Walter Bothe observed that beryllium emitted a highly penetrating, electrically neutral radiation when bombarded with alpha particles. It was later discovered that this radiation could knock hydrogen atoms out of paraffin wax. Initially it was thought to be high-energy gamma radiation, since gamma radiation had a similar effect on electrons in metals, but James Chadwick found that the ionization effect was too strong for it to be due to electromagnetic radiation, so long as energy and momentum were conserved in the interaction. In 1932, Chadwick exposed various elements, such as hydrogen and nitrogen, to the mysterious \"beryllium radiation\", and by measuring the energies of the recoiling charged particles, he deduced that the radiation was actually composed of electrically neutral particles which could not be massless like the gamma ray, but instead were required to have a mass similar to that of a proton. Chadwick now claimed these particles as Rutherford's neutrons.\nThe current consensus model.\nIn 1925, Werner Heisenberg published the first consistent mathematical formulation of quantum mechanics (matrix mechanics). One year earlier, Louis de Broglie had proposed that all particles behave like waves to some extent, and in 1926 Erwin Schr\u00f6dinger used this idea to develop the Schr\u00f6dinger equation, which describes electrons as three-dimensional waveforms rather than points in space. A consequence of using waveforms to describe particles is that it is mathematically impossible to obtain precise values for both the position and momentum of a particle at a given point in time. This became known as the uncertainty principle, formulated by Werner Heisenberg in 1927. In this concept, for a given accuracy in measuring a position one could only obtain a range of probable values for momentum, and vice versa. Thus, the planetary model of the atom was discarded in favor of one that described atomic orbital zones around the nucleus where a given electron is most likely to be found. This model was able to explain observations of atomic behavior that previous models could not, such as certain structural and spectral patterns of atoms larger than hydrogen.\nStructure.\nSubatomic particles.\nThough the word \"atom\" originally denoted a particle that cannot be cut into smaller particles, in modern scientific usage the atom is composed of various subatomic particles. The constituent particles of an atom are the electron, the proton, and the neutron.\nThe electron is the least massive of these particles by four orders of magnitude at , with a negative electrical charge and a size that is too small to be measured using available techniques. It was the lightest particle with a positive rest mass measured, until the discovery of neutrino mass. Under ordinary conditions, electrons are bound to the positively charged nucleus by the attraction created from opposite electric charges. Electrons have been known since the late 19th century, mostly thanks to J.J. Thomson; see history of subatomic physics for details.\nProtons have a positive charge and a mass of . The number of protons in an atom is called its atomic number. Ernest Rutherford (1919) observed that nitrogen under alpha-particle bombardment ejects what appeared to be hydrogen nuclei. By 1920 he had accepted that the hydrogen nucleus is a distinct particle within the atom and named it proton.\nNeutrons have no electrical charge and have a mass of . Neutrons are the heaviest of the three constituent particles, but their mass can be reduced by the nuclear binding energy. Neutrons and protons (collectively known as nucleons) have comparable dimensions\u2014on the order of \u2014although the 'surface' of these particles is not sharply defined. The neutron was discovered in 1932 by the English physicist James Chadwick.\nIn the Standard Model of physics, electrons are truly elementary particles with no internal structure, whereas protons and neutrons are composite particles composed of elementary particles called quarks. There are two types of quarks in atoms, each having a fractional electric charge. Protons are composed of two up quarks (each with charge +) and one down quark (with a charge of \u2212). Neutrons consist of one up quark and two down quarks. This distinction accounts for the difference in mass and charge between the two particles.\nThe quarks are held together by the strong interaction (or strong force), which is mediated by gluons. The protons and neutrons, in turn, are held to each other in the nucleus by the nuclear force, which is a residuum of the strong force that has somewhat different range-properties (see the article on the nuclear force for more). The gluon is a member of the family of gauge bosons, which are elementary particles that mediate physical forces.\nNucleus.\nAll the bound protons and neutrons in an atom make up a tiny atomic nucleus, and are collectively called nucleons. The radius of a nucleus is approximately equal to formula_1\u00a0femtometres, where formula_2 is the total number of nucleons. This is much smaller than the radius of the atom, which is on the order of 105\u00a0fm. The nucleons are bound together by a short-ranged attractive potential called the residual strong force. At distances smaller than 2.5\u00a0fm this force is much more powerful than the electrostatic force that causes positively charged protons to repel each other.\nAtoms of the same element have the same number of protons, called the atomic number. Within a single element, the number of neutrons may vary, determining the isotope of that element. The total number of protons and neutrons determine the nuclide. The number of neutrons relative to the protons determines the stability of the nucleus, with certain isotopes undergoing radioactive decay.\nThe proton, the electron, and the neutron are classified as fermions. Fermions obey the Pauli exclusion principle which prohibits \"identical\" fermions, such as multiple protons, from occupying the same quantum state at the same time. Thus, every proton in the nucleus must occupy a quantum state different from all other protons, and the same applies to all neutrons of the nucleus and to all electrons of the electron cloud.\nA nucleus that has a different number of protons than neutrons can potentially drop to a lower energy state through a radioactive decay that causes the number of protons and neutrons to more closely match. As a result, atoms with matching numbers of protons and neutrons are more stable against decay, but with increasing atomic number, the mutual repulsion of the protons requires an increasing proportion of neutrons to maintain the stability of the nucleus.\nThe number of protons and neutrons in the atomic nucleus can be modified, although this can require very high energies because of the strong force. Nuclear fusion occurs when multiple atomic particles join to form a heavier nucleus, such as through the energetic collision of two nuclei. For example, at the core of the Sun protons require energies of 3 to 10\u00a0keV to overcome their mutual repulsion\u2014the coulomb barrier\u2014and fuse together into a single nucleus. Nuclear fission is the opposite process, causing a nucleus to split into two smaller nuclei\u2014usually through radioactive decay. The nucleus can also be modified through bombardment by high energy subatomic particles or photons. If this modifies the number of protons in a nucleus, the atom changes to a different chemical element.\nIf the mass of the nucleus following a fusion reaction is less than the sum of the masses of the separate particles, then the difference between these two values can be emitted as a type of usable energy (such as a gamma ray, or the kinetic energy of a beta particle), as described by Albert Einstein's mass\u2013energy equivalence formula, \"E = mc2\", where \"m\" is the mass loss and \"c\" is the speed of light. This deficit is part of the binding energy of the new nucleus, and it is the non-recoverable loss of the energy that causes the fused particles to remain together in a state that requires this energy to separate.\nThe fusion of two nuclei that create larger nuclei with lower atomic numbers than iron and nickel\u2014a total nucleon number of about 60\u2014is usually an exothermic process that releases more energy than is required to bring them together. It is this energy-releasing process that makes nuclear fusion in stars a self-sustaining reaction. For heavier nuclei, the binding energy per nucleon begins to decrease. That means that a fusion process producing a nucleus that has an atomic number higher than about 26, and a mass number higher than about 60, is an endothermic process. Thus, more massive nuclei cannot undergo an energy-producing fusion reaction that can sustain the hydrostatic equilibrium of a star.\nElectron cloud.\nThe electrons in an atom are attracted to the protons in the nucleus by the electromagnetic force. This force binds the electrons inside an electrostatic potential well surrounding the smaller nucleus, which means that an external source of energy is needed for the electron to escape. The closer an electron is to the nucleus, the greater the attractive force. Hence electrons bound near the center of the potential well require more energy to escape than those at greater separations.\nElectrons, like other particles, have properties of both a particle and a wave. The electron cloud is a region inside the potential well where each electron forms a type of three-dimensional standing wave\u2014a wave form that does not move relative to the nucleus. This behavior is defined by an atomic orbital, a mathematical function that characterises the probability that an electron appears to be at a particular location when its position is measured. Only a discrete (or quantized) set of these orbitals exist around the nucleus, as other possible wave patterns rapidly decay into a more stable form. Orbitals can have one or more ring or node structures, and differ from each other in size, shape and orientation.\nEach atomic orbital corresponds to a particular energy level of the electron. The electron can change its state to a higher energy level by absorbing a photon with sufficient energy to boost it into the new quantum state. Likewise, through spontaneous emission, an electron in a higher energy state can drop to a lower energy state while radiating the excess energy as a photon. These characteristic energy values, defined by the differences in the energies of the quantum states, are responsible for atomic spectral lines.\nThe amount of energy needed to remove or add an electron\u2014the electron binding energy\u2014is far less than the binding energy of nucleons. For example, it requires only 13.6\u00a0eV to strip a ground-state electron from a hydrogen atom, compared to 2.23\u00a0\"million\" eV for splitting a deuterium nucleus. Atoms are electrically neutral if they have an equal number of protons and electrons. Atoms that have either a deficit or a surplus of electrons are called ions. Electrons that are farthest from the nucleus may be transferred to other nearby atoms or shared between atoms. By this mechanism, atoms are able to bond into molecules and other types of chemical compounds like ionic and covalent network crystals.\nProperties.\nNuclear properties.\nBy definition, any two atoms with an identical number of \"protons\" in their nuclei belong to the same chemical element. Atoms with equal numbers of protons but a different number of \"neutrons\" are different isotopes of the same element. For example, all hydrogen atoms admit exactly one proton, but isotopes exist with no neutrons (hydrogen-1, by far the most common form, also called protium), one neutron (deuterium), two neutrons (tritium) and more than two neutrons. The known elements form a set of atomic numbers, from the single-proton element hydrogen up to the 118-proton element oganesson. All known isotopes of elements with atomic numbers greater than 82 are radioactive, although the radioactivity of element 83 (bismuth) is so slight as to be practically negligible.\nAbout 339 nuclides occur naturally on Earth, of which 251 (about 74%) have not been observed to decay, and are referred to as \"stable isotopes\". Only 90 nuclides are stable theoretically, while another 161 (bringing the total to 251) have not been observed to decay, even though in theory it is energetically possible. These are also formally classified as \"stable\". An additional 35 radioactive nuclides have half-lives longer than 100 million years, and are long-lived enough to have been present since the birth of the Solar System. This collection of 286 nuclides are known as primordial nuclides. Finally, an additional 53 short-lived nuclides are known to occur naturally, as daughter products of primordial nuclide decay (such as radium from uranium), or as products of natural energetic processes on Earth, such as cosmic ray bombardment (for example, carbon-14).\nFor 80 of the chemical elements, at least one stable isotope exists. As a rule, there is only a handful of stable isotopes for each of these elements, the average being 3.1 stable isotopes per element. Twenty-six \"monoisotopic elements\" have only a single stable isotope, while the largest number of stable isotopes observed for any element is ten, for the element tin. Elements 43, 61, and all elements numbered 83 or higher have no stable isotopes.\nStability of isotopes is affected by the ratio of protons to neutrons, and also by the presence of certain \"magic numbers\" of neutrons or protons that represent closed and filled quantum shells. These quantum shells correspond to a set of energy levels within the shell model of the nucleus; filled shells, such as the filled shell of 50 protons for tin, confers unusual stability on the nuclide. Of the 251 known stable nuclides, only four have both an odd number of protons \"and\" odd number of neutrons: hydrogen-2 (deuterium), lithium-6, boron-10, and nitrogen-14. (Tantalum-180m is odd-odd and observationally stable, but is predicted to decay with a very long half-life.) Also, only four naturally occurring, radioactive odd-odd nuclides have a half-life over a billion years: potassium-40, vanadium-50, lanthanum-138, and lutetium-176. Most odd-odd nuclei are highly unstable with respect to beta decay, because the decay products are even-even, and are therefore more strongly bound, due to nuclear pairing effects.\nMass.\nThe large majority of an atom's mass comes from the protons and neutrons that make it up. The total number of these particles (called \"nucleons\") in a given atom is called the mass number. It is a positive integer and dimensionless (instead of having dimension of mass), because it expresses a count. An example of use of a mass number is \"carbon-12,\" which has 12 nucleons (six protons and six neutrons).\nThe actual mass of an atom at rest is often expressed in daltons (Da), also called the unified atomic mass unit (u). This unit is defined as a twelfth of the mass of a free neutral atom of carbon-12, which is approximately . Hydrogen-1 (the lightest isotope of hydrogen which is also the nuclide with the lowest mass) has an atomic weight of 1.007825\u00a0Da. The value of this number is called the atomic mass. A given atom has an atomic mass approximately equal (within 1%) to its mass number times the dalton (for example the mass of a nitrogen-14 is roughly 14\u00a0Da), but this number will not be exactly an integer except (by definition) in the case of carbon-12. The heaviest stable atom is lead-208, with a mass of .\nAs even the most massive atoms are far too light to work with directly, chemists instead use the unit of moles. One mole of atoms of any element always has the same number of atoms (about ). This number was chosen so that if an element has an atomic mass of 1\u00a0u, a mole of atoms of that element has a mass close to one gram. Because of the definition of the dalton, each carbon-12 atom has an atomic mass of exactly 12\u00a0Da, and so a mole of carbon-12 atoms weighs exactly 0.012\u00a0kg.\nShape and size.\nAtoms lack a well-defined outer boundary, so their dimensions are usually described in terms of an atomic radius. This is a measure of the distance out to which the electron cloud extends from the nucleus. This assumes the atom to exhibit a spherical shape, which is only obeyed for atoms in vacuum or free space. Atomic radii may be derived from the distances between two nuclei when the two atoms are joined in a chemical bond. The radius varies with the location of an atom on the atomic chart, the type of chemical bond, the number of neighboring atoms (coordination number) and a quantum mechanical property known as spin. On the periodic table of the elements, atom size tends to increase when moving down columns, but decrease when moving across rows (left to right). Consequently, the smallest atom is helium with a radius of 32\u00a0pm, while one of the largest is caesium at 225\u00a0pm.\nWhen subjected to external forces, like electrical fields, the shape of an atom may deviate from spherical symmetry. The deformation depends on the field magnitude and the orbital type of outer shell electrons, as shown by group-theoretical considerations. Aspherical deviations might be elicited for instance in crystals, where large crystal-electrical fields may occur at low-symmetry lattice sites. Significant ellipsoidal deformations have been shown to occur for sulfur ions and chalcogen ions in pyrite-type compounds.\nAtomic dimensions are thousands of times smaller than the wavelengths of light (400\u2013700\u00a0nm) so they cannot be viewed using an optical microscope, although individual atoms can be observed using a scanning tunneling microscope. To visualize the minuteness of the atom, consider that a typical human hair is about 1\u00a0million carbon atoms in width. A single drop of water contains about 2\u00a0sextillion () atoms of oxygen, and twice the number of hydrogen atoms. A single carat diamond with a mass of contains about 10\u00a0sextillion (1022) atoms of carbon. If an apple were magnified to the size of the Earth, then the atoms in the apple would be approximately the size of the original apple.\nRadioactive decay.\nEvery element has one or more isotopes that have unstable nuclei that are subject to radioactive decay, causing the nucleus to emit particles or electromagnetic radiation. Radioactivity can occur when the radius of a nucleus is large compared with the radius of the strong force, which only acts over distances on the order of 1\u00a0fm.\nThe most common forms of radioactive decay are:\nOther more rare types of radioactive decay include ejection of neutrons or protons or clusters of nucleons from a nucleus, or more than one beta particle. An analog of gamma emission which allows excited nuclei to lose energy in a different way, is internal conversion\u2014a process that produces high-speed electrons that are not beta rays, followed by production of high-energy photons that are not gamma rays. A few large nuclei explode into two or more charged fragments of varying masses plus several neutrons, in a decay called spontaneous nuclear fission.\nEach radioactive isotope has a characteristic decay time period\u2014the half-life\u2014that is determined by the amount of time needed for half of a sample to decay. This is an exponential decay process that steadily decreases the proportion of the remaining isotope by 50% every half-life. Hence after two half-lives have passed only 25% of the isotope is present, and so forth.\nMagnetic moment.\nElementary particles possess an intrinsic quantum mechanical property known as spin. This is analogous to the angular momentum of an object that is spinning around its center of mass, although strictly speaking these particles are believed to be point-like and cannot be said to be rotating. Spin is measured in units of the reduced Planck constant (\u0127), with electrons, protons and neutrons all having spin &lt;templatestyles src=\"Fraction/styles.css\" /&gt;1\u20442\u00a0\u0127, or \"spin-&lt;templatestyles src=\"Fraction/styles.css\" /&gt;1\u20442\". In an atom, electrons in motion around the nucleus possess orbital angular momentum in addition to their spin, while the nucleus itself possesses angular momentum due to its nuclear spin.\nThe magnetic field produced by an atom\u2014its magnetic moment\u2014is determined by these various forms of angular momentum, just as a rotating charged object classically produces a magnetic field, but the most dominant contribution comes from electron spin. Due to the nature of electrons to obey the Pauli exclusion principle, in which no two electrons may be found in the same quantum state, bound electrons pair up with each other, with one member of each pair in a spin up state and the other in the opposite, spin down state. Thus these spins cancel each other out, reducing the total magnetic dipole moment to zero in some atoms with even number of electrons.\nIn ferromagnetic elements such as iron, cobalt and nickel, an odd number of electrons leads to an unpaired electron and a net overall magnetic moment. The orbitals of neighboring atoms overlap and a lower energy state is achieved when the spins of unpaired electrons are aligned with each other, a spontaneous process known as an exchange interaction. When the magnetic moments of ferromagnetic atoms are lined up, the material can produce a measurable macroscopic field. Paramagnetic materials have atoms with magnetic moments that line up in random directions when no magnetic field is present, but the magnetic moments of the individual atoms line up in the presence of a field.\nThe nucleus of an atom will have no spin when it has even numbers of both neutrons and protons, but for other cases of odd numbers, the nucleus may have a spin. Normally nuclei with spin are aligned in random directions because of thermal equilibrium, but for certain elements (such as xenon-129) it is possible to polarize a significant proportion of the nuclear spin states so that they are aligned in the same direction\u2014a condition called hyperpolarization. This has important applications in magnetic resonance imaging.\nEnergy levels.\nThe potential energy of an electron in an atom is negative relative to when the distance from the nucleus goes to infinity; its dependence on the electron's position reaches the minimum inside the nucleus, roughly in inverse proportion to the distance. In the quantum-mechanical model, a bound electron can occupy only a set of states centered on the nucleus, and each state corresponds to a specific energy level; see time-independent Schr\u00f6dinger equation for a theoretical explanation. An energy level can be measured by the amount of energy needed to unbind the electron from the atom, and is usually given in units of electronvolts (eV). The lowest energy state of a bound electron is called the ground state, i.e., stationary state, while an electron transition to a higher level results in an excited state. The electron's energy increases along with \"n\" because the (average) distance to the nucleus increases. Dependence of the energy on \u2113 is caused not by the electrostatic potential of the nucleus, but by interaction between electrons.\nFor an electron to transition between two different states, e.g. ground state to first excited state, it must absorb or emit a photon at an energy matching the difference in the potential energy of those levels, according to the Niels Bohr model, what can be precisely calculated by the Schr\u00f6dinger equation. Electrons jump between orbitals in a particle-like fashion. For example, if a single photon strikes the electrons, only a single electron changes states in response to the photon; see Electron properties.\nThe energy of an emitted photon is proportional to its frequency, so these specific energy levels appear as distinct bands in the electromagnetic spectrum. Each element has a characteristic spectrum that can depend on the nuclear charge, subshells filled by electrons, the electromagnetic interactions between the electrons and other factors.\nWhen a continuous spectrum of energy is passed through a gas or plasma, some of the photons are absorbed by atoms, causing electrons to change their energy level. Those excited electrons that remain bound to their atom spontaneously emit this energy as a photon, traveling in a random direction, and so drop back to lower energy levels. Thus the atoms behave like a filter that forms a series of dark absorption bands in the energy output. An observer viewing the atoms from a view that does not include the continuous spectrum in the background, instead sees a series of emission lines from the photons emitted by the atoms. Spectroscopic measurements of the strength and width of atomic spectral lines allow the composition and physical properties of a substance to be determined.\nClose examination of the spectral lines reveals that some display a fine structure splitting. This occurs because of spin\u2013orbit coupling, which is an interaction between the spin and motion of the outermost electron. When an atom is in an external magnetic field, spectral lines become split into three or more components; a phenomenon called the Zeeman effect. This is caused by the interaction of the magnetic field with the magnetic moment of the atom and its electrons. Some atoms can have multiple electron configurations with the same energy level, which thus appear as a single spectral line. The interaction of the magnetic field with the atom shifts these electron configurations to slightly different energy levels, resulting in multiple spectral lines. The presence of an external electric field can cause a comparable splitting and shifting of spectral lines by modifying the electron energy levels, a phenomenon called the Stark effect.\nIf a bound electron is in an excited state, an interacting photon with the proper energy can cause stimulated emission of a photon with a matching energy level. For this to occur, the electron must drop to a lower energy state that has an energy difference matching the energy of the interacting photon. The emitted photon and the interacting photon then move off in parallel and with matching phases. That is, the wave patterns of the two photons are synchronized. This physical property is used to make lasers, which can emit a coherent beam of light energy in a narrow frequency band.\nValence and bonding behavior.\nValency is the combining power of an element. It is determined by the number of bonds it can form to other atoms or groups. The outermost electron shell of an atom in its uncombined state is known as the valence shell, and the electrons in\nthat shell are called valence electrons. The number of valence electrons determines the bonding\nbehavior with other atoms. Atoms tend to chemically react with each other in a manner that fills (or empties) their outer valence shells. For example, a transfer of a single electron between atoms is a useful approximation for bonds that form between atoms with one-electron more than a filled shell, and others that are one-electron short of a full shell, such as occurs in the compound sodium chloride and other chemical ionic salts. Many elements display multiple valences, or tendencies to share differing numbers of electrons in different compounds. Thus, chemical bonding between these elements takes many forms of electron-sharing that are more than simple electron transfers. Examples include the element carbon and the organic compounds.\nThe chemical elements are often displayed in a periodic table that is laid out to display recurring chemical properties, and elements with the same number of valence electrons form a group that is aligned in the same column of the table. (The horizontal rows correspond to the filling of a quantum shell of electrons.) The elements at the far right of the table have their outer shell completely filled with electrons, which results in chemically inert elements known as the noble gases.\nStates.\nQuantities of atoms are found in different states of matter that depend on the physical conditions, such as temperature and pressure. By varying the conditions, materials can transition between solids, liquids, gases, and plasmas. Within a state, a material can also exist in different allotropes. An example of this is solid carbon, which can exist as graphite or diamond. Gaseous allotropes exist as well, such as dioxygen and ozone.\nAt temperatures close to absolute zero, atoms can form a Bose\u2013Einstein condensate, at which point quantum mechanical effects, which are normally only observed at the atomic scale, become apparent on a macroscopic scale. This super-cooled collection of atoms then behaves as a single super atom, which may allow fundamental checks of quantum mechanical behavior.\nIdentification.\nWhile atoms are too small to be seen, devices such as the scanning tunneling microscope (STM) enable their visualization at the surfaces of solids. The microscope uses the quantum tunneling phenomenon, which allows particles to pass through a barrier that would be insurmountable in the classical perspective. Electrons tunnel through the vacuum between two biased electrodes, providing a tunneling current that is exponentially dependent on their separation. One electrode is a sharp tip ideally ending with a single atom. At each point of the scan of the surface the tip's height is adjusted so as to keep the tunneling current at a set value. How much the tip moves to and away from the surface is interpreted as the height profile. For low bias, the microscope images the averaged electron orbitals across closely packed energy levels\u2014the local density of the electronic states near the Fermi level. Because of the distances involved, both electrodes need to be extremely stable; only then periodicities can be observed that correspond to individual atoms. The method alone is not chemically specific, and cannot identify the atomic species present at the surface.\nAtoms can be easily identified by their mass. If an atom is ionized by removing one of its electrons, its trajectory when it passes through a magnetic field will bend. The radius by which the trajectory of a moving ion is turned by the magnetic field is determined by the mass of the atom. The mass spectrometer uses this principle to measure the mass-to-charge ratio of ions. If a sample contains multiple isotopes, the mass spectrometer can determine the proportion of each isotope in the sample by measuring the intensity of the different beams of ions. Techniques to vaporize atoms include inductively coupled plasma atomic emission spectroscopy and inductively coupled plasma mass spectrometry, both of which use a plasma to vaporize samples for analysis.\nThe atom-probe tomograph has sub-nanometer resolution in 3-D and can chemically identify individual atoms using time-of-flight mass spectrometry.\nElectron emission techniques such as X-ray photoelectron spectroscopy (XPS) and Auger electron spectroscopy (AES), which measure the binding energies of the core electrons, are used to identify the atomic species present in a sample in a non-destructive way. With proper focusing both can be made area-specific. Another such method is electron energy loss spectroscopy (EELS), which measures the energy loss of an electron beam within a transmission electron microscope when it interacts with a portion of a sample.\nSpectra of excited states can be used to analyze the atomic composition of distant stars. Specific light wavelengths contained in the observed light from stars can be separated out and related to the quantized transitions in free gas atoms. These colors can be replicated using a gas-discharge lamp containing the same element. Helium was discovered in this way in the spectrum of the Sun 23\u00a0years before it was found on Earth.\nOrigin and current state.\nBaryonic matter forms about 4% of the total energy density of the observable universe, with an average density of about 0.25\u00a0particles/m3 (mostly protons and electrons). Within a galaxy such as the Milky Way, particles have a much higher concentration, with the density of matter in the interstellar medium (ISM) ranging from 105 to 109 atoms/m3. The Sun is believed to be inside the Local Bubble, so the density in the solar neighborhood is only about 103 atoms/m3. Stars form from dense clouds in the ISM, and the evolutionary processes of stars result in the steady enrichment of the ISM with elements more massive than hydrogen and helium.\nUp to 95% of the Milky Way's baryonic matter are concentrated inside stars, where conditions are unfavorable for atomic matter. The total baryonic mass is about 10% of the mass of the galaxy; the remainder of the mass is an unknown dark matter. High temperature inside stars makes most \"atoms\" fully ionized, that is, separates \"all\" electrons from the nuclei. In stellar remnants\u2014with exception of their surface layers\u2014an immense pressure make electron shells impossible.\nFormation.\nElectrons are thought to exist in the Universe since early stages of the Big Bang. Atomic nuclei forms in nucleosynthesis reactions. In about three minutes Big Bang nucleosynthesis produced most of the helium, lithium, and deuterium in the Universe, and perhaps some of the beryllium and boron.\nUbiquitousness and stability of atoms relies on their binding energy, which means that an atom has a lower energy than an unbound system of the nucleus and electrons. Where the temperature is much higher than ionization potential, the matter exists in the form of plasma\u2014a gas of positively charged ions (possibly, bare nuclei) and electrons. When the temperature drops below the ionization potential, atoms become statistically favorable. Atoms (complete with bound electrons) became to dominate over charged particles 380,000\u00a0years after the Big Bang\u2014an epoch called recombination, when the expanding Universe cooled enough to allow electrons to become attached to nuclei.\nSince the Big Bang, which produced no carbon or heavier elements, atomic nuclei have been combined in stars through the process of nuclear fusion to produce more of the element helium, and (via the triple-alpha process) the sequence of elements from carbon up to iron; see stellar nucleosynthesis for details.\nIsotopes such as lithium-6, as well as some beryllium and boron are generated in space through cosmic ray spallation. This occurs when a high-energy proton strikes an atomic nucleus, causing large numbers of nucleons to be ejected.\nElements heavier than iron were produced in supernovae and colliding neutron stars through the r-process, and in AGB stars through the s-process, both of which involve the capture of neutrons by atomic nuclei. Elements such as lead formed largely through the radioactive decay of heavier elements.\nEarth.\nMost of the atoms that make up the Earth and its inhabitants were present in their current form in the nebula that collapsed out of a molecular cloud to form the Solar System. The rest are the result of radioactive decay, and their relative proportion can be used to determine the age of the Earth through radiometric dating. Most of the helium in the crust of the Earth (about 99% of the helium from gas wells, as shown by its lower abundance of helium-3) is a product of alpha decay.\nThere are a few trace atoms on Earth that were not present at the beginning (i.e., not \"primordial\"), nor are results of radioactive decay. Carbon-14 is continuously generated by cosmic rays in the atmosphere. Some atoms on Earth have been artificially generated either deliberately or as by-products of nuclear reactors or explosions. Of the transuranic elements\u2014those with atomic numbers greater than 92\u2014only plutonium and neptunium occur naturally on Earth. Transuranic elements have radioactive lifetimes shorter than the current age of the Earth and thus identifiable quantities of these elements have long since decayed, with the exception of traces of plutonium-244 possibly deposited by cosmic dust. Natural deposits of plutonium and neptunium are produced by neutron capture in uranium ore.\nThe Earth contains approximately atoms. Although small numbers of independent atoms of noble gases exist, such as argon, neon, and helium, 99% of the atmosphere is bound in the form of molecules, including carbon dioxide and diatomic oxygen and nitrogen. At the surface of the Earth, an overwhelming majority of atoms combine to form various compounds, including water, salt, silicates, and oxides. Atoms can also combine to create materials that do not consist of discrete molecules, including crystals and liquid or solid metals. This atomic matter forms networked arrangements that lack the particular type of small-scale interrupted order associated with molecular matter.\nRare and theoretical forms.\nSuperheavy elements.\nAll nuclides with atomic numbers higher than 82 (lead) are known to be radioactive. No nuclide with an atomic number exceeding 92 (uranium) exists on Earth as a primordial nuclide, and heavier elements generally have shorter half-lives. Nevertheless, an \"island of stability\" encompassing relatively long-lived isotopes of superheavy elements with atomic numbers 110 to 114 might exist. Predictions for the half-life of the most stable nuclide on the island range from a few minutes to millions of years. In any case, superheavy elements (with \"Z\"\u00a0&gt;\u00a0104) would not exist due to increasing Coulomb repulsion (which results in spontaneous fission with increasingly short half-lives) in the absence of any stabilizing effects.\nExotic matter.\nEach particle of matter has a corresponding antimatter particle with the opposite electrical charge. Thus, the positron is a positively charged antielectron and the antiproton is a negatively charged equivalent of a proton. When a matter and corresponding antimatter particle meet, they annihilate each other. Because of this, along with an imbalance between the number of matter and antimatter particles, the latter are rare in the universe. The first causes of this imbalance are not yet fully understood, although theories of baryogenesis may offer an explanation. As a result, no antimatter atoms have been discovered in nature. In 1996, the antimatter counterpart of the hydrogen atom (antihydrogen) was synthesized at the CERN laboratory in Geneva.\nOther exotic atoms have been created by replacing one of the protons, neutrons or electrons with other particles that have the same charge. For example, an electron can be replaced by a more massive muon, forming a muonic atom. These types of atoms can be used to test fundamental predictions of physics.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "903", "revid": "4897226", "url": "https://en.wikipedia.org/wiki?curid=903", "title": "Arable land", "text": "Land capable of being ploughed and used to grow crops\nArable land (from la\u00a0'able to be ploughed or farmed') is any land capable of being ploughed and used to grow crops. Alternatively, for the purposes of agricultural statistics, the term often has a more precise definition:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Arable land is the land under temporary agricultural crops (multiple-cropped areas are counted only once), temporary meadows for mowing or pasture, land under market and kitchen gardens and land temporarily fallow (less than five years). The abandoned land resulting from shifting cultivation is not included in this category. Data for 'Arable land' are not meant to indicate the amount of land that is potentially cultivable.\nA more concise definition appearing in the Eurostat glossary similarly refers to actual rather than potential uses: \"land worked (ploughed or tilled) regularly, generally under a system of crop rotation\". In Britain, arable land has traditionally been contrasted with pasturable land such as heaths, which could be used for sheep-rearing but not as farmland.\nArable land is vulnerable to land degradation and some types of un-arable land can be enriched to create useful land. Climate change and biodiversity loss are driving pressure on arable land.\nBy country.\nAccording to the Food and Agriculture Organization of the United Nations, in 2013, the world's arable land amounted to 1.407\u00a0billion hectares, out of a total of 4.924\u00a0billion hectares of land used for agriculture.\nNon-arable land.\nAgricultural land that is not arable according to the FAO definition above includes:\nOther non-arable land includes land that is not suitable for any agricultural use. Land that is not arable, in the sense of lacking capability or suitability for cultivation for crop production, has one or more limitations\u00a0\u2013 a lack of sufficient freshwater for irrigation, stoniness, steepness, adverse climate, excessive wetness with the impracticality of drainage, excessive salts, or a combination of these, among others. Although such limitations may preclude cultivation, and some will in some cases preclude any agricultural use, large areas unsuitable for cultivation may still be agriculturally productive. For example, United States NRCS statistics indicate that about 59 percent of US non-federal pasture and unforested rangeland is unsuitable for cultivation, yet such land has value for grazing of livestock. In British Columbia, Canada, 41 percent of the provincial Agricultural Land Reserve area is unsuitable for the production of cultivated crops, but is suitable for uncultivated production of forage usable by grazing livestock. Similar examples can be found in many rangeland areas elsewhere.\nChanges in arability.\nLand conversion.\nLand incapable of being cultivated for the production of crops can sometimes be converted to arable land. New arable land makes more food and can reduce starvation. This outcome also makes a country more self-sufficient and politically independent, because food importation is reduced. Making non-arable land arable often involves digging new irrigation canals and new wells, aqueducts, desalination plants, planting trees for shade in the desert, hydroponics, fertilizer, nitrogen fertilizer, pesticides, reverse osmosis water processors, PET film insulation or other insulation against heat and cold, digging ditches and hills for protection against the wind, and installing greenhouses with internal light and heat for protection against the cold outside and to provide light in cloudy areas. Such modifications are often prohibitively expensive. An alternative is the seawater greenhouse, which desalinates water through evaporation and condensation using solar energy as the only energy input. This technology is optimized to grow crops on desert land close to the sea.\nThe use of artifices does not make the land arable. Rock still remains rock, and shallow\u00a0\u2013 less than \u00a0\u2013 turnable soil is still not considered toilable. The use of artifice is an open-air non-recycled water hydroponics relationship. The below described circumstances are not in perspective, have limited duration, and have a tendency to accumulate trace materials in soil that either there or elsewhere cause deoxygenation. The use of vast amounts of fertilizer may have unintended consequences for the environment by devastating rivers, waterways, and river endings through the accumulation of non-degradable toxins and nitrogen-bearing molecules that remove oxygen and cause non-aerobic processes to form.\nExamples of infertile non-arable land being turned into fertile arable land include:\nLand degradation.\nExamples.\nExamples of fertile arable land being turned into infertile land include:\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
